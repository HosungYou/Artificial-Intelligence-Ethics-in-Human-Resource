
OWN - ERIC
TI  - Exploring the Role of ChatGPT in Higher Education: Opportunities, Challenges and Ethical Considerations
AU  - Ali Zeb
AU  - Rafid Ullah
AU  - Rehmat Karim
OT  - Artificial Intelligence
OT  - Higher Education
OT  - Technology Uses in Education
OT  - Barriers
OT  - Opportunities
OT  - Risk
OT  - Ethics
OT  - Cheating
OT  - Prevention
OT  - Influence of Technology
JT  - International Journal of Information and Learning Technology
SO  - v41 n1 p99-111 2024
AID - http://dx.doi.org/10.1108/IJILT-04-2023-0046
OID - EJ1410074
VI  - 41
IP  - 1
PG  - 99-111
DP  - 2024
LID - http://eric.ed.gov/?id=EJ1410074
AB  - Purpose: This paper aims to examine the opportunities and challenges of using ChatGPT in higher education. Furthermore, it is also discuss the potential risks and plunders of these tools. Design/methodology/approach: The paper discuss the use of artificial intelligence (AI) in academia and explores the opportunities and challenges of using ChatGPT in higher education. It also highlights the difficulties of detecting and preventing academic dishonesty and suggests strategies that universities can adopt to ensure ethical and useful use of these tools. Findings: The paper concludes that while the use of AI tools, ChatGPT in higher education presents both opportunities and challenges. The universities can effectively address these concerns by taking a proactive and ethical approach to the use of these tools. This paper further suggests that universities should develop policies and procedures, provide training and support, to detect and prevent cheating intentions. Originality/value: The paper provides insights into the opportunities and challenges of using ChatGPT in higher education, as well as strategies for addressing concerns related to academic dishonesty. The paper further adds importance to the discussion on the ethical and responsible use of AI tools in higher education.
ISSN - ISSN-2056-4880
LA  - English
PT  - Journal Articles
PT  - Reports - Research

OWN - ERIC
TI  - Bridging the Gap: Preparing Delaware K-12 Teachers for AI Integration
AU  - Matthew Kelso
OT  - Elementary Secondary Education
OT  - Artificial Intelligence
OT  - Readiness
OT  - Technology Integration
OT  - Educational Technology
OT  - Pedagogical Content Knowledge
OT  - Technological Literacy
OT  - Barriers
OT  - Teacher Competencies
JT  - ProQuest LLC
SO  - Ed.D. Dissertation, Wilmington University (Delaware)
AID - https://gateway.proquest.com/openurl?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&res_dat=xri:pqm&rft_dat=xri:pqdiss:31240511
OID - ED657229
DP  - 2024
LID - http://eric.ed.gov/?id=ED657229
AB  - The potential of AI in K-12 education is vast, promising personalized learning experiences, enhanced engagement, and innovative instructional tools. However, its introduction into classrooms brings forth concerns ranging from ethics to teacher preparedness. Drawing on Christensen's concept of disruptive innovation, this study aims to assess and improve Delaware teachers' readiness for AI integration, using AI-based TPACK as a theoretical framework. Through a survey instrument tailored for Delaware K-12 educators, the research uncovers gaps in AI literacy and identifies barriers to effective implementation. The findings underscore the urgent need for guidance and support from the Delaware Department of Education (DDOE) to equip teachers with the necessary literacy for ethical and practical AI integration. Recommendations include strategic guidance, professional development initiatives, and frameworks for ethical AI integration, paving the way for transformative teaching methodologies in Delaware's K-12 landscape. [The dissertation citations contained here are published with the permission of ProQuest LLC. Further reproduction is prohibited without permission. Copies of dissertations may be obtained by Telephone (800) 1-800-521-0600. Web page: http://www.proquest.com/en-US/products/dissertations/individuals.shtml.]
ISBN - 979-8-3828-4014-7
PT  - Dissertations/Theses - Doctoral Dissertations

OWN - ERIC
TI  - A Qualitative Survey on Perception of Medical Students on the Use of Large Language Models for Educational Purposes
AU  - Himel Mondal
AU  - Juhu Kiran Krushna Karri
AU  - Swaminathan Ramasubramanian
AU  - Shaikat Mondal
AU  - Ayesha Juhi
AU  - Pratima Gupta
OT  - Computational Linguistics
OT  - Physiology
OT  - Teaching Methods
OT  - Artificial Intelligence
OT  - Technology Uses in Education
OT  - Linguistic Input
OT  - Medical Education
OT  - Educational Benefits
OT  - Telecommunications
OT  - Student Attitudes
OT  - Feedback (Response)
OT  - Indians
OT  - Learning Processes
OT  - Computer Software
OT  - Multiple Choice Tests
OT  - Assignments
OT  - Usability
OT  - Privacy
OT  - Information Security
OT  - Technology Integration
OT  - Technological Literacy
OT  - Barriers
OT  - Medical Students
OT  - Foreign Countries
JT  - Advances in Physiology Education
SO  - v49 n1 p27-36 2025
AID - https://doi.org/10.1152/advan.00088.2024
OID - EJ1463722
VI  - 49
IP  - 1
PG  - 27-36
DP  - 2025
LID - http://eric.ed.gov/?id=EJ1463722
AB  - Large language models (LLMs)-based chatbots use natural language processing and are a type of generative artificial intelligence (AI) that is capable of comprehending user input and generating output in various formats. They offer potential benefits in medical education. This study explored the student's feedback on the utilization of LLMs in medical education. We conducted an in-depth interview with open-ended questions with Indian medical students via telephone conversation. The recording (average time: 55.28 ± 18.04 min) was transcribed and thematically analyzed to find major themes and subthemes. We used QDA Miner Lite v.2.0.8 (Provalis Research, Montreal, Canada) for the thematic analysis of the text. A total of 25 students from eight Indian states studying from the first to final year of studies participated in this study. Three major themes were identified: usage scenario, augmented learning, and limitation of LLMs. Students use LLMs for clarifying complex topics, searching for customized answers, solving multiple-choice questions, making simplified notes, and streamlining assignments. While they appreciated the ease of access, ready reference for getting clarity on doubts, lucid explanation of questions, and time-saving aspects of LLMs, concerns were raised regarding erroneous results, limited usage due to reliability and privacy issues, and the overreliance on chatbots for educational needs. Hence, they emphasized the need for training for the integration of LLM in medical education. In conclusion, according to students' perception, LLMs have the potential to enhance medical education. However, addressing challenges and leveraging the strengths of LLMs are crucial for optimizing their integration into medical education.
ISSN - ISSN-1043-4046
ISSN - EISSN-1522-1229
LA  - English
PT  - Journal Articles
PT  - Reports - Research

OWN - ERIC
TI  - Gender Prediction Based on University Students' Complex Thinking Competency: An Analysis from Machine Learning Approaches
AU  - Gerardo Ibarra-Vazquez
AU  - María Soledad Ramí­rez-Montoya
AU  - Hugo Terashima
OT  - Foreign Countries
OT  - College Students
OT  - Private Colleges
OT  - Gender Bias
OT  - Gender Issues
OT  - Difficulty Level
OT  - Thinking Skills
OT  - Competence
OT  - Classification
OT  - Metacognition
OT  - Artificial Intelligence
JT  - Education and Information Technologies
SO  - v29 n3 p2721-2739 2024
AID - http://dx.doi.org/10.1007/s10639-023-11831-4
OID - EJ1414349
VI  - 29
IP  - 3
PG  - 2721-2739
DP  - 2024
LID - http://eric.ed.gov/?id=EJ1414349
AB  - This article aims to study machine learning models to determine their performance in classifying students by gender based on their perception of complex thinking competency. Data were collected from a convenience sample of 605 students from a private university in Mexico with the eComplexity instrument. In this study, we consider the following data analyses: (1) predict students' gender based on their perception of complex thinking competency and sub-competencies from a 25 items questionnaire, (2) analyze models' performance during training and testing stages, and (3) study the models' prediction bias through a confusion matrix analysis. Our results confirm the hypothesis that the four machine learning models (Random Forest, Support Vector Machines, Multi-layer Perception, and One-Dimensional Convolutional Neural Network) can find sufficient differences in the eComplexity data to classify correctly up to 96.94% and 82.14% of the students' gender in the training and testing stage, respectively. The confusion matrix analysis revealed partiality in gender prediction among all machine learning models, even though we have applied an oversampling method to reduce the imbalance dataset. It showed that the most frequent error was to predict Male students as Female class. This paper provides empirical support for analyzing perception data through machine learning models in survey research. This work proposed a novel educational practice based on developing complex thinking competency and machine learning models to facilitate educational itineraries adapted to the training needs of each group to reduce social gaps existing due to gender.
ISSN - ISSN-1360-2357
ISSN - EISSN-1573-7608
LA  - English
PT  - Journal Articles
PT  - Reports - Research

OWN - ERIC
TI  - Unlocking AI Potential: Effort Expectancy, Satisfaction, and Usage in Research
AU  - Nurul Ashikin Izhar
AU  - Wendy Ven Ye Teh
AU  - Anita Adnan
OT  - Artificial Intelligence
OT  - Computer Software
OT  - Technology Uses in Education
OT  - Technology Integration
OT  - Usability
OT  - Barriers
OT  - Educational Benefits
OT  - Ethics
OT  - Plagiarism
OT  - Integrity
OT  - Efficiency
OT  - Researchers
OT  - Research Methodology
OT  - Models
OT  - Cognitive Ability
OT  - Technical Support
OT  - Technological Literacy
OT  - Faculty Development
OT  - Doctoral Students
OT  - Graduate Students
OT  - Student Research
JT  - Journal of Information Technology Education: Innovations in Practice
SO  - v24 Article 5 2025
AID - https://doi.org/10.28945/5450
OID - EJ1464831
VI  - 24
DP  - Article 2025
LID - http://eric.ed.gov/?id=EJ1464831
AB  - Aim/Purpose: This study investigates the key factors influencing the adoption and use of artificial intelligence (AI) applications among researchers, focusing on effort expectancy, satisfaction, perceived ease of use, and perceived usefulness, which shaped attitudes and drove AI adoption as a research assistant. Background: AI tools have rapidly become game-changers in academic research, transforming tasks such as literature retrieval, writing, editing, and data analysis. Despite their potential, barriers like high effort expectancy, inconsistent user satisfaction, and ethical concerns regarding over-reliance and plagiarism continue to hinder widespread adoption. A pressing gap exists in understanding how AI impacts the efficiency and integrity of academic research workflows. Methodology: A quantitative approach using structural equation modeling (SEM) was employed. Data was collected from 120 active researchers who use AI tools for academic tasks, including literature reviews, writing support, and data visualization. Contribution: This study contributes to the understanding of how key factors, such as effort expectancy and satisfaction, affect AI adoption in academic research. It emphasizes the importance of reducing cognitive load and improving user satisfaction to promote widespread AI adoption. It also underscores the importance of intuitive AI design and institutional support in shaping researchers' engagement with AI tools, which could enhance productivity and research outcomes. Findings: The findings reveal that effort expectancy, satisfaction, perceived ease of use, and perceived usefulness significantly influence attitude and actual use of AI tools, with attitude serving as a key mediator. The model demonstrated moderate to high explanatory power (R[superscript 2] = 0.409 to 0.459) and predictive relevance (Q[superscript 2] = 0.171 to 0.409), highlighting the substantial role of effort expectancy and satisfaction in shaping perceived ease of use and usefulness. These findings emphasize the importance of reducing cognitive load and improving user satisfaction to encourage the adoption of AI tools in research. Recommendations for Practitioners: Institutions and AI developers should focus on reducing the learning curve of AI tools by enhancing their intuitiveness and providing targeted training and technical support. Ethical AI use should also be promoted to address concerns about over-reliance and plagiarism. Institutions should foster a culture that normalizes AI integration in research practices. Recommendation for Researchers: Researchers should be informed of the long-term effects of AI adoption on research quality and integrity and how institutional support can foster positive attitudes toward AI tools in academic research. Impact on Society: The broader adoption of AI tools in academic research could enhance productivity and efficiency, leading to more breakthroughs in various fields and benefiting society by accelerating research and innovation. Additionally, AI can democratize access to research resources, particularly for underfunded institutions and early-career researchers, by enabling broader participation in cutting-edge research and fostering equity and diversity in academic contributions. Future Research: Future studies should focus on the role of user experience in AI adoption, particularly how different user groups interact with AI tools. Longitudinal studies could provide insights into how attitudes toward AI change as users become more familiar with the tools.
ISSN - ISSN-2165-3151
ISSN - EISSN-2165-316X
LA  - English
PT  - Journal Articles
PT  - Reports - Research
PT  - Tests/Questionnaires

OWN - ERIC
TI  - Teaching AI-Enabled Business Communication in Higher Education: A Practical Framework
AU  - Natalia Riapina
OT  - Artificial Intelligence
OT  - Business Communication
OT  - Higher Education
OT  - Technology Uses in Education
OT  - Theories
OT  - Educational Technology
OT  - Learner Engagement
OT  - Learning Experience
OT  - Constructivism (Learning)
OT  - Cognitive Processes
OT  - Difficulty Level
OT  - Models
JT  - Business and Professional Communication Quarterly
SO  - v87 n3 p511-521 2024
AID - http://dx.doi.org/10.1177/23294906231199249
OID - EJ1433980
VI  - 87
IP  - 3
PG  - 511-521
DP  - 2024
LID - http://eric.ed.gov/?id=EJ1433980
AB  - This article presents a conceptual framework for integrating AI-enabled business communication in higher education. Drawing on established theories from business communication and educational technology, the framework provides comprehensive guidance for designing engaging learning experiences. It emphasizes the significance of social presence, cognitive load management, and constructivist learning principles. The framework is exemplified through various tasks, including role-playing with AI chatbots, analyzing nonverbal cues, communication simulations, interactive presentation assessments, and collaborative AI-supported projects. Practical considerations for implementation, including technological infrastructure, faculty training, ethics, curriculum integration, and assessment strategies, are discussed. Future directions and implications for business communication education are also explored.
ISSN - ISSN-2329-4922
ISSN - EISSN-2329-4906
LA  - English
PT  - Journal Articles
PT  - Reports - Descriptive

OWN - ERIC
TI  - Teacher and Student Perspectives of Technology Use in Elementary School Classrooms
AU  - Anthony Oskar Alvarado
OT  - Elementary School Teachers
OT  - Influence of Technology
OT  - Elementary School Students
OT  - Teacher Attitudes
OT  - Technology Uses in Education
OT  - Student Attitudes
OT  - Educational Technology
OT  - Grade 3
OT  - Grade 4
OT  - Grade 5
OT  - Grade 6
OT  - Grade 2
OT  - Grade 1
OT  - Interests
OT  - Learner Engagement
OT  - Student Interests
JT  - ProQuest LLC
SO  - Ed.D. Dissertation, San Jose State University
AID - https://gateway.proquest.com/openurl?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&res_dat=xri:pqm&rft_dat=xri:pqdiss:31488474
OID - ED659969
DP  - 2024
LID - http://eric.ed.gov/?id=ED659969
AB  - This study explored student and teacher perspectives of technology use at Franklin Elementary School in South San Jose, CA, using qualitative, quantitative, and observational methods, including interviews, observations, and surveys. Thirteen teachers responded to a survey on educational technology use. Among this group, eleven provided interviews, and nine invited classroom observations from 1st through 6th grades. Additionally, sixty-nine 3rd to 6th-grade students were surveyed about their views on technology use. The study found that technology use in teaching is widespread and integral, not just an add-on. Observations and teacher interviews showed high engagement and interest in technology tools, primarily supporting the lower levels of Bloom's Digital Taxonomy (BDT). Recommendations include professional development and collaboration opportunities for teachers to integrate activities engaging Bloom's higher levels of thinking, such as analyzing and evaluating. Teachers also called for better vetting of products to ensure ethical and safe technology use in schools. Due to the limited and small sample size, findings may not be generalizable. Given the rapid pace of technological evolution, highlighted by the fast adoption of artificial intelligence (AI) tools in education during the research period, the study concludes with a need for ongoing research into the ethical and privacy implications of technology use in education. [The dissertation citations contained here are published with the permission of ProQuest LLC. Further reproduction is prohibited without permission. Copies of dissertations may be obtained by Telephone (800) 1-800-521-0600. Web page: http://www.proquest.com/en-US/products/dissertations/individuals.shtml.]
ISBN - 979-8-3836-2703-7
PT  - Dissertations/Theses - Doctoral Dissertations

OWN - ERIC
TI  - Exploring the Factors Affecting the Adoption AI Techniques in Higher Education: Insights from Teachers' Perspectives on ChatGPT
AU  - Habiba Al-Mughairi
AU  - Preeti Bhaskar
OT  - Educational Technology
OT  - Technology Uses in Education
OT  - Technology Integration
OT  - Artificial Intelligence
OT  - College Faculty
OT  - Teacher Attitudes
OT  - Barriers
OT  - Motivation
OT  - Foreign Countries
JT  - Journal of Research in Innovative Teaching & Learning
SO  - v18 n2 p232-247 2025
AID - https://doi.org/10.1108/JRIT-09-2023-0129
OID - EJ1491337
VI  - 18
IP  - 2
PG  - 232-247
DP  - 2025
LID - http://eric.ed.gov/?id=EJ1491337
AB  - Purpose: ChatGPT, an artificial intelligence (AI)-powered chatbot, has gained substantial attention in the academic world for its potential to transform the education industry. While ChatGPT offers numerous benefits, concerns have also been raised regarding its impact on the quality of education. This study aims to bridge the gap in research by exploring teachers' perspectives on the adoption of ChatGPT, with a focus on identifying factors that motivate and inhibit them to adopt ChatGPT for educational purposes. Design/methodology/approach: This research has employed a interpretative phenomenological analysis (IPA) qualitative approach. Through in-depth interviews among the teachers, data will be collected to identify the motivating and inhibiting factors that impact teachers' willingness to adopt ChatGPT. The data was collected from 34 teachers working across 10 branches of the University of Technology and Applied Sciences (UTAS) in Oman. Findings: The analysis revealed four themes under motivating factors that encourage teachers to adopt ChatGPT for their educational purpose. These include Theme 1: Exploration of innovative education technologies, Theme 2: Personalization teaching and learning, Theme 3: Time-saving and Theme 4: Professional development. On the other hand, inhibiting factors includes five themes which includes Theme 1: Reliability and accuracy concerns, Theme 2: Reduced human interaction, Theme 3: Privacy and data security, Theme 4: lack of institutional support and Theme 5: Overreliance on ChatGPT. Practical implications: This study contributes to the understanding of teachers' perspectives on the adoption of ChatGPT in education. By understanding teachers' perspectives, policymakers can design appropriate policies and service providers can customize their offerings to meet teachers' requirements. The study's findings will be valuable for higher education institutions (HEIs) in formulating policies to ensure the appropriate and effective utilization of ChatGPT. The study will provide suggestions to ChatGPT service providers, enabling them to focus on motivating factors and address inhibiting factors, thereby facilitating the seamless adoption of ChatGPT among teachers. Originality/value: In comparison to previous studies, this study goes beyond merely discussing the possible benefits and limitations of ChatGPT in education. This research significantly contributes to the understanding of ChatGPT adoption among teachers by identifying specific motivating and inhibiting factors that influence teachers to adopt ChatGPT for educational purposes. The research enables to gain important new insights that were not previously found, giving a fresh dimension to the existing literature.
ISSN - ISSN-1947-1017
LA  - English
PT  - Journal Articles
PT  - Reports - Research

OWN - ERIC
TI  - A Comprehensive AI Policy Education Framework for University Teaching and Learning
AU  - Chan, Cecilia Ka Yuk
OT  - Artificial Intelligence
OT  - Educational Policy
OT  - College Instruction
OT  - Higher Education
OT  - Foreign Countries
OT  - Ecology
OT  - Governance
OT  - Technology Uses in Education
OT  - Instructional Improvement
OT  - Privacy
OT  - Information Security
OT  - Accountability
OT  - Technology Integration
OT  - Ethics
JT  - International Journal of Educational Technology in Higher Education
SO  - v20 Article 38 2023
AID - http://dx.doi.org/10.1186/s41239-023-00408-3
OID - EJ1383549
VI  - 20
DP  - Article 38 2023
LID - http://eric.ed.gov/?id=EJ1383549
AB  - This study aims to develop an AI education policy for higher education by examining the perceptions and implications of text generative AI technologies. Data was collected from 457 students and 180 teachers and staff across various disciplines in Hong Kong universities, using both quantitative and qualitative research methods. Based on the findings, the study proposes an AI Ecological Education Policy Framework to address the multifaceted implications of AI integration in university teaching and learning. This framework is organized into three dimensions: Pedagogical, Governance, and Operational. The Pedagogical dimension concentrates on using AI to improve teaching and learning outcomes, while the Governance dimension tackles issues related to privacy, security, and accountability. The Operational dimension addresses matters concerning infrastructure and training. The framework fosters a nuanced understanding of the implications of AI integration in academic settings, ensuring that stakeholders are aware of their responsibilities and can take appropriate actions accordingly.
ISSN - EISSN-2365-9440
LA  - English
PT  - Journal Articles
PT  - Reports - Research

OWN - ERIC
TI  - The Educational Affordances and Challenges of ChatGPT: State of the Field
AU  - Helen Crompton
AU  - Diane Burke
OT  - Artificial Intelligence
OT  - Barriers
OT  - Technology Uses in Education
OT  - Natural Language Processing
OT  - Teaching Methods
OT  - Students
OT  - Teachers
OT  - Affordances
JT  - TechTrends: Linking Research and Practice to Improve Learning
SO  - v68 n2 p380-392 2024
AID - http://dx.doi.org/10.1007/s11528-024-00939-0
OID - EJ1414180
VI  - 68
IP  - 2
PG  - 380-392
DP  - 2024
LID - http://eric.ed.gov/?id=EJ1414180
AB  - ChatGPT was released to the public in November 30, 2022. This study examines how ChatGPT can be used by educators and students to promote learning and what are the challenges and limitations. This study is unique in providing one of the first systematic reviews using peer review studies to provide an early examination of the field. Using PRISMA principles, 44 articles were selected for review. Grounded coding was then used to reveal trends in the data. The findings show that educators can use ChatGPT for teaching support, task automation, and professional development. These were further delineated further by axial sub codes. Eight student uses were 24/7 support, explain difficult concepts, conversational partner, personalized feedback and materials, provide writing support, offer self-assessment, facilitate engagement, and self-determination. In addition to be affordances of the AI, the data from the articles also showed limitations to ChatGPT and misuses, specifically, inaccuracies and hallucinations, potential bias, and tool limitations. Misuses are plagiarism and cheating, privacy issues and spread of false information. This study is a springboard for researchers, practitioners, policy makers and funders in understanding the emerging state of the field of ChatGPT.
ISSN - ISSN-8756-3894
ISSN - EISSN-1559-7075
LA  - English
PT  - Journal Articles
PT  - Reports - Research

OWN - ERIC
TI  - Superficially Plausible Outputs from a Black Box: Problematising GenAI Tools for Analysing Qualitative SoTL Data
AU  - Mirjam Sophia Glessmer
AU  - Rachel Forsyth
OT  - Artificial Intelligence
OT  - Research Methodology
OT  - Data Analysis
OT  - Scholarship
OT  - Instruction
OT  - Learning
OT  - Reliability
OT  - Validity
OT  - Ethics
OT  - Educational Development
OT  - Algorithms
JT  - Teaching & Learning Inquiry
SO  - v13 2025
OID - EJ1460022
VI  - 13
DP  - 2025
LID - http://eric.ed.gov/?id=EJ1460022
AB  - Generative AI tools (GenAI) are increasingly used for academic tasks, including qualitative data analysis for the Scholarship of Teaching and Learning (SoTL). In our practice as academic developers, we are frequently asked for advice on whether this use for GenAI is reliable, valid, and ethical. Since this is a new field, we have not been able to answer this confidently based on published literature, which depicts both very positive as well as highly cautionary accounts. To fill this gap, we experiment with the use of chatbot style GenAI (namely ChatGPT 4, ChatGPT 4o, and Microsoft Copilot) to support or conduct qualitative analysis of survey and interview data from a SoTL project, which had previously been analysed by experienced researchers using thematic analysis. At first sight, the output looked plausible, but the results were incomplete and not reproducible. In some instances, interpretations and extrapolations of data happened when it was clearly stated in the prompt that the tool should only analyse a specified dataset based on explicit instructions. Since both algorithm and training data of the GenAI tools are undisclosed, it is impossible to know how the outputs had been arrived at. We conclude that while results may look plausible initially, digging deeper soon reveals serious problems; the lack of transparency about how analyses are conducted and results are generated means that no reproducible method can be described. We therefore warn against an uncritical use of GenAI in qualitative analysis of SoTL data.
ISSN - ISSN-2167-4779
ISSN - EISSN-2167-4787
LA  - English
PT  - Journal Articles
PT  - Reports - Research

OWN - ERIC
TI  - Unraveling the Influential Factors Driving Persistent Adoption of ChatGPT in Learning Environments
AU  - Sedigheh Moghavvemi
AU  - Farooq Ahmed Jam
OT  - Artificial Intelligence
OT  - Technology Uses in Education
OT  - Technology Integration
OT  - Privacy
OT  - Risk
OT  - College Students
OT  - Foreign Countries
OT  - Intention
OT  - Usability
OT  - Problem Solving
OT  - Concept Formation
OT  - Information Technology
OT  - Educational Benefits
JT  - Education and Information Technologies
SO  - v30 n15 p22443-22470 2025
AID - http://dx.doi.org/10.1007/s10639-025-13662-x
OID - EJ1491764
VI  - 30
IP  - 15
PG  - 22443-22470
DP  - 2025
LID - http://eric.ed.gov/?id=EJ1491764
AB  - AI has transformed education by reshaping teaching and learning processes. ChatGPT plays a significant role in enhancing these processes; however, effective educator training is essential for its optimal use. Educators and researchers are increasingly adopting AI chatbots, expecting them to improve learning experiences and reduce teacher workload. This study aims to identify the factors contributing to ChatGPT's perceived value and analyze their impact on its continued usage among students. Additionally, the study introduces a new model and investigates the moderating effect of privacy risk on the relationship between perceived value and the continued use of ChatGPT. A total of 600 questionnaires were distributed to students enrolled in various universities in Malaysia, with 244 students indicating their willingness to continue using ChatGPT. Partial Least Squares Structural Equation Modeling was used to analyze the data. The findings suggest that perceived usefulness, perceived ease of use, problem-solving, idea generation, information quality, and effective learning are significant determinants of ChatGPT's continuous use among students, both directly and indirectly through perceived value. The results show that students benefit from ChatGPT in enhancing their performance, problem-solving, and idea generation. In line with concerns about privacy risks in online applications, the study reveals that privacy concerns affect ChatGPT's perceived value. Students prioritize its effectiveness as a study aid. Academic institutions can train students to use ChatGPT as a complementary learning tool, while instructors can leverage it to enhance their teaching practices.
ISSN - ISSN-1360-2357
ISSN - EISSN-1573-7608
LA  - English
PT  - Journal Articles
PT  - Reports - Research

OWN - ERIC
TI  - Bridging Resource Gaps in Adult Education: The Role of Generative AI
AU  - Sarah Cacicio
AU  - Rachel Riggs
OT  - Adult Education
OT  - Artificial Intelligence
OT  - Educational Technology
OT  - Adult Educators
OT  - Teacher Attitudes
OT  - Visual Aids
OT  - Bias
OT  - Instructional Materials
OT  - Design
OT  - Technology Uses in Education
JT  - Adult Literacy Education
SO  - v5 n3 p80-86 2023
OID - EJ1408776
VI  - 5
IP  - 3
PG  - 80-86
DP  - 2023
LID - http://eric.ed.gov/?id=EJ1408776
AB  - Generative AI (GenAI) refers to the production of entirely new creative works, such as text, pictures, music, or poetry, in response to simple prompts (Lanxon et al., 2023). Some view GenAI as a disruption to our education system, pointing to biases in the training data, concerns about misleading or inaccurate information, challenges to educators, as well as issues of personal safety and privacy (Weil, 2023, Yu & Guo, 2023). In adult foundational education, where teacher capacity and resources are limited, AI-powered edtech tools have the potential to support the rapid creation of high quality, tailored, and engaging materials for instruction and assessment in any learning context. This article aims to provide insight into adult educator perspectives on the use of GenAI as well as highlight edtech tools and features that educators can use to strengthen their instructional design skills and more effectively meet diverse learner needs.
ISSN - EISSN-2642-3669
PT  - Journal Articles
PT  - Reports - Descriptive

OWN - ERIC
TI  - Ethical Limits and Suggestions for Improving the Use of AI in Scientific Research, Academic Publishing, and the Peer Review Process, Based on Deontological and Consequentialist Viewpoints
AU  - Mohammed Daoudi
OT  - Ethics
OT  - Artificial Intelligence
OT  - Technology Uses in Education
OT  - Scientific Research
OT  - Faculty Publishing
OT  - Writing for Publication
OT  - Peer Evaluation
OT  - Computer Attitudes
OT  - Efficiency
OT  - Data Analysis
OT  - Hypothesis Testing
OT  - Accountability
OT  - Trust (Psychology)
OT  - Supervision
OT  - Barriers
OT  - Access to Computers
OT  - Costs
OT  - Technological Literacy
OT  - Training
OT  - Interdisciplinary Approach
JT  - Discover Education
SO  - v4 Article 241 2025
AID - http://dx.doi.org/10.1007/s44217-025-00696-z
OID - EJ1477382
VI  - 4
DP  - Article 241 2025
LID - http://eric.ed.gov/?id=EJ1477382
AB  - This study provides a comprehensive analysis of researchers' perspectives on AI integration across theoretical and practical research, academic publishing, and its future role, highlighting ethical considerations shaping its adoption. The methodology used a mixed approach, using a questionnaire distributed to researchers from various scientific disciplines. Quantitative data were analyzed statistically, and qualitative responses underwent thematic analysis to ensure a robust understanding of the findings. Results reveal that AI is viewed as a powerful tool for enhancing efficiency in research, particularly in data analysis (61.9%) and hypothesis generation (45.2%). However, ethical concerns, including bias, transparency, and trust, were noted as significant challenges, with 38.1% emphasizing the need for improved ethical frameworks. In academic writing, 81% of respondents supported AI use with proper acknowledgment, while 76.2% expressed openness to AI-assisted peer review under human supervision. The future of AI is seen as complementary to human expertise (69%), with its potential strongest in data analysis, simulations, and innovation in research tools (57.1%). Key barriers include limited access to AI tools (47.6%), high costs (38.1%), and insufficient technical skills (45.2%). This study's innovation lies in its integration of ethical theories, deontology and consequentialism, as a framework to evaluate AI's role in research. It offers practical recommendations to foster responsible AI adoption, including ethical training, interdisciplinary collaboration, and enhanced accessibility to AI tools. Addressing gaps in ethical guidelines and emphasizing AI's potential to complement human creativity, this research contributes valuable insights to the evolving discourse on AI in scientific research.
ISSN - EISSN-2731-5525
LA  - English
PT  - Journal Articles
PT  - Reports - Research

OWN - ERIC
TI  - Using Machine Learning Methods to Detect Heterogeneous Treatment Effects for Multilevel Randomized Controlled Trials: A Review and Empirical Comparison
AU  - Wei Li
AU  - Walter Leite
AU  - Jia Quan
OT  - Artificial Intelligence
OT  - Identification
OT  - Hierarchical Linear Modeling
OT  - Randomized Controlled Trials
OT  - Comparative Analysis
OT  - Educational Research
OT  - Algorithms
JT  - Society for Research on Educational Effectiveness
AID - https://www.sree.org/2023-conference
OID - ED659733
DP  - 2023
LID - http://eric.ed.gov/?id=ED659733
AB  - Background: Multilevel randomized controlled trials (MRCTs) have been widely used to evaluate the causal effects of educational interventions. Traditionally, educational researchers and policymakers focused on the average treatment effects (ATE) of the intervention. Recently there has been an increasing interest in evaluating the heterogeneity of treatment effects (HTEs) among intervention participants for several reasons. First, it allows researchers to understand how treatment effects vary among subgroups to address questions about "for whom and under what conditions" an intervention works. These individual and cluster characteristics used to identify subgroups are called moderators and can augment or reduce the treatment effects. Also, it helps researchers to examine whether an intervention increase or decreases the gaps in the outcomes of interest and thus identifies the interventions that can improve fairness and equity in education. Educational researchers commonly incorporate a treatment by moderator interaction within OLS regression or multilevel models (MLMs) to explore the moderator effects (e.g., Dong et al., 2022). Recent development in statistics and econometrics (e.g., Athey & Wager, 2019; Chernozhukov et al., 2020) proposed to use machine learning (ML) methods to explore the HTEs by estimating the conditional average treatment (CATE). Compared to traditional interaction analysis, these methods have some advantages. For example, the interaction analysis cannot identify causal relationships because of the potential correlations between the moderators and the omitted variables in the error term (Dong et al., 2022), while some ML methods (e.g., causal forest) can facilitate causal inference under regular assumptions. Also, traditional moderator analysis usually requires specifying the moderators in the design phase and thus may miss important sources of HTEs. However, ML methods can select moderators from a potentially large number of covariates. To deal with the potential dependency of students within the same schools, MLMs are widely used for moderation analysis. Similarly, when applying ML methods to estimate CATE, applied researchers still need to consider the nested data structure. However, most prior literature assumes the participants are independent. There is a lack of literature to guide educational researchers in appropriately applying ML methods for clustered data when evaluating HTEs. Purpose and Significance: This study contributes to the literature on the design and analysis of MRCTs by reviewing the current available ML methods and tools that account for the nested data structure when estimating CATE and provides recommendations to applied researchers on how to choose the appropriate methods and statistical package among alternative ML methods. Specifically, this study will focus on two ML methods -- Causal Forest (CF) and the GenericML methods and demonstrate the application of these two methods using the dataset from a large multisite experimental study (Leite et al., 2023). Research Design and Methods: Many ML methods have been proposed to estimate CATE in the past decade (see Caron et al., 2020 and Jacob, 2021, for recent reviews). In general, these methods include three main steps: (1) splitting the data into training and test sets, (2) using the training set and ML algorithms to build a prediction model, and (3) using the test set to estimate HTEs and the standard errors (SEs). Based on our review of all the currently available methods and packages, only two algorithms --CF and the GenericML consider the nested data structure in at least one step. Specifically, the CF algorithm estimates CATE through honest causal trees (Wager & Athey, 2018). When analyzing data from MRCTs, the cluster-robust CF algorithm estimates CATE by making predictions as an average of b trees (Athey & Wager, 2019). It considers the nested data structure in all three steps: (1) for each b= 1, ..., B, draw a subsample of clusters and then draw a random sample from each cluster as the training data; (2) grow a tree via recursive partitioning on each such subsample of the data; (3) make the out-of-bag predictions. It should be noted that to account for the potential within cluster dependency, an observation "i" is considered to be out-of-bag if its cluster was not drawn in step (1). Similarly, the GenericML algorithm (Chernozhukov et al., 2020) estimates the best linear predictor of CATE through the following steps: (1) randomly split the data into training and test sets; (2) estimates the CATE with any number of selected ML methods (e.g., LASSO, SVM, etc.) using the training data; (3) use OLS regression to obtain the BLP of the CATE using the test data. Note that, for multisite designs, OLS with site dummy variables is used in the third step, but it does not consider nested data structure in the first and second steps. The cluster-robust CF algorithm can be applied through the R package "grf", and the GenericML algorithm can be implemented through the "GenericML" R package. Both packages report cluster-Robust SEs. Besides, the "GenericML" package can also estimate the Sorted group average treatment effects (GATEs) that consisted of creating five groups of participants using quintiles of the CATE distribution and perform classification analysis (CLAN) to explore the relationships between covariates and the CATE. In contrast, the "grf" package cannot automatically report GATEs or CLAN. Preliminary Results: We applied the cluster-robust CF and the GenericML algorithms to the data from a large-scale three-level multisite experimental study. This study included 52 math teachers and 2,936 students from three school districts and randomly assigned students of participating teachers to see video recommendations. Our analysis includes 516 predictors, with 484 consisting of dummy-coded indicators. The Appendix Table 1 summarizes GATEs using the "GenericML" package, showing the difference between the group that benefitted the most (Group 5) and the least (Group 1) from the intervention. The 516 predictors were sorted based on their mean differences between Groups 1 and 5. A thematic analysis of the most important predictors showed that teachers of students who benefitted most reported spending more time using the videos of the VLE and following student progress on the dashboard. We will manually estimate GATE and CLAN based on the CATE estimates from the "grf" package and then compare the results from two packages regarding CATE, GATE, and CLAN.
PT  - Reports - Research

OWN - ERIC
TI  - A Future-Focused Lens to Equipping Biomedical Engineering Graduates for an Evolving Field
AU  - Gabrielle Lam
AU  - Isgard Hueck
AU  - Christian Rivera
AU  - Patricia Widder
OT  - Biomedicine
OT  - Engineering Education
OT  - College Graduates
OT  - Futures (of Society)
OT  - Job Skills
OT  - Technological Literacy
OT  - Data Science
OT  - Ethics
OT  - Critical Thinking
JT  - Biomedical Engineering Education
SO  - v5 n2 p177-188 2025
AID - http://dx.doi.org/10.1007/s43683-025-00186-6
OID - EJ1482504
VI  - 5
IP  - 2
PG  - 177-188
DP  - 2025
LID - http://eric.ed.gov/?id=EJ1482504
AB  - Biomedical engineering is a rapidly evolving field, with the pace of evolution spurred by technological advancements, the increasing complexity of human health challenges, and globalization of the workforce. It is timely for biomedical engineering educators to explore afresh the competencies that graduates need at present, but more importantly, those they need to adapt to an ever-evolving BME field. Here, we use a future-focused lens in our exploration, drawing upon industry and academic perspectives from sessions at recent Biomedical Engineering Education Summits, together with findings from literature over the past 5 years. A synthesis of perspectives revealed that certain professional competencies--namely communication, collaboration, leadership, and ethical understanding--were viewed as "difficult to teach," yet critical to adapting to evolutions in the field and the growing need to work effectively in interdisciplinary contexts. Technical competencies were seen as expected outcomes of graduates' educational training, yet there was strong emphasis on the importance of critical thinking and data science skills. Importantly, it is the interconnection between professional and technical competencies that enable future BME graduates to contribute in an ethical and socially responsible manner, especially in light of the field's growing use of large patient-derived datasets and rapid advancements in technologies like Artificial Intelligence. From this, we propose three approaches for BME educational programs to better equip BME graduates: (1) enhancing engagement with industry and alumni to evolve the curriculum, (2) augmenting opportunities for interdisciplinary student collaboration, and (3) integrating data science and ethics training throughout the curriculum.
ISSN - ISSN-2730-5937
ISSN - EISSN-2730-5945
LA  - English
PT  - Journal Articles
PT  - Reports - Evaluative

OWN - ERIC
TI  - Differential Impact of Gender and Academic Background on Complex Thinking Development in Engineering Students: A Machine Learning Perspective
AU  - Paloma Suárez-Brito
AU  - Armando Elizondo-Noriega
AU  - Jenny Paola Lis-Gutiérrez
AU  - Carolina Henao-Rodríguez
AU  - María Rubi Forte-Celaya
AU  - José Carlos Vázquez-Parra
OT  - Foreign Countries
OT  - Engineering Education
OT  - Undergraduate Students
OT  - Sex
OT  - Educational Background
OT  - Problem Solving
OT  - Critical Thinking
OT  - Creative Thinking
OT  - Cognitive Processes
OT  - Science Process Skills
OT  - Professional Education
OT  - Likert Scales
JT  - On the Horizon
SO  - v33 n1 p14-31 2025
AID - http://dx.doi.org/10.1108/OTH-11-2023-0036
OID - EJ1459737
VI  - 33
IP  - 1
PG  - 14-31
DP  - 2025
LID - http://eric.ed.gov/?id=EJ1459737
AB  - Purpose: The purpose of this paper is to present the results of measuring a sample of engineering students' perceived achievement of complex thinking at different stages of their professional training. This study intended to analyze and predict the differences in the self-perception of achieved complex thinking competency by gender, semester, course of study and high school of origin. Design/methodology/approach: The methodology included applying the E-Complexity instrument to 225 university students from northern Mexico. The initial comparison of groups used the chi-square test and two supervised learning algorithms (logit regression with Lasso regularization and a classification tree). Findings: The findings of this study indicated that the selected undergraduate degree did not reveal differences in self-perceived performance in complex thinking, while gender, semester and high school of origin had significant differences. Research limitations/implications: Among the limitations of the study is the size of the sample and the fact that it only focused on engineering students from a single educational institution; however, this limitation responds to the exploratory nature of this study and the guidance of the institutional ethics committee. With these results, it is feasible to request an extension of the sample to include other disciplines to evaluate these findings, which, although relevant, cannot be considered exhaustive. Originality/value: Regarding possible lines of research, the authors propose that given the difference between students who graduated from the high school of the same institution and those who did not, a possible line of research could explore new hypotheses on whether the policies and practices of the institution's high school emphasize the development of complex thinking skills; the teachers of this high school are trained to teach complex thinking; and the learning materials of this high school are designed to develop complex thinking skills.
ISSN - ISSN-1074-8121
ISSN - EISSN-2054-1708
LA  - English
PT  - Journal Articles
PT  - Reports - Research

OWN - ERIC
TI  - Training Humans to Detect Children's Lies through Their Facial Expressions
AU  - Alison M. O'Connor
AU  - Jennifer Gongola
AU  - Kaila C. Bruer
AU  - Thomas D. Lyon
AU  - Angela D. Evans
OT  - Deception
OT  - Nonverbal Communication
OT  - Recognition (Psychology)
OT  - Children
OT  - Interviews
OT  - Accuracy
OT  - Ethics
OT  - Artificial Intelligence
OT  - Comparative Analysis
OT  - Training
OT  - Video Technology
OT  - Adults
JT  - Applied Cognitive Psychology
SO  - v39 n1 e70024 2025
AID - http://dx.doi.org/10.1002/acp.70024
OID - EJ1460825
VI  - 39
IP  - 1
DP  - e70024 2025
LID - http://eric.ed.gov/?id=EJ1460825
AB  - The accurate detection of children's truthful and dishonest reports is essential as children can serve as important providers of information. Research using automated facial coding and machine learning found that children who were asked to lie about an event were more likely to look surprised when hearing the first question during an interview about said event. The present studies explored if humans can be trained to look for surprised expressions to detect children's deception. Participants made lie-detection judgments after seeing children's expressions in very brief clips. In Study 1, we compared performance across a training condition and control condition, and in Study 2 we modified the training. With training, adults could detect children's lies at above-chance levels by viewing their facial expressions. Detection accuracy was further improved with modified training (Study 2), but participants held a consistent lie bias. Challenges with using facial expressions to detect deceit are discussed.
ISSN - ISSN-0888-4080
ISSN - EISSN-1099-0720
GR  - HD101617
LA  - English
PT  - Journal Articles
PT  - Reports - Research

OWN - ERIC
TI  - Massive Omission of Consent (MOOC): Ethical Research in Educational Big Data Studies
AU  - Costello, Eamon
AU  - Brunton, James
AU  - Bolger, Richard
AU  - Soverino, Tiziana
AU  - Juillerac, Clément
OT  - MOOCs
OT  - Informed Consent
OT  - Educational Research
OT  - Ethics
OT  - Educational Researchers
OT  - Authors
OT  - Research Committees
OT  - Integrity
JT  - Online Learning
SO  - v27 n2 p67-87 Jun 2023
OID - EJ1392879
VI  - 27
IP  - 2
PG  - 67-87
DP  - Jun 2023
LID - http://eric.ed.gov/?id=EJ1392879
AB  - Ethical reviews of research plans function as a cornerstone of good research practice in order that no harm should come to participants. Ethical concerns have taken on a new salience in a digital world where data can be generated at scale. Big data research has grown rapidly, raising increased ethical concerns. Several intersecting areas of big data research exist within educational research, such as learning analytics, artificial intelligence (AI), and Massive Open Online Courses (MOOCs). In the current study, an investigation was made of peer-reviewed papers on MOOC teaching and learning to determine if they explicitly refer to (a) ethical considerations in their studies, and (b) obtaining formal ethical approval for their research. This investigation was accomplished through a review of MOOC-related, English-language papers available in Scopus database, over the course of a year. The review produced a total of 1,249 articles, of which, 826 articles related to empirical studies involving human participants where full text of the articles could be obtained. The string "ethic" was searched for within these articles, and resulting articles analyzed, which found that a small fraction, 42 articles (5.08%), mention ethics in relation to the study presented in the article, and only 13 articles (1.57%) explicitly mention obtaining formal ethical approval for the research. The findings show a lack of transparency in reporting on and/or engagement with ethical considerations in MOOC teaching and learning research. These findings indicate the need for further stakeholder engagement and sectoral dialogue in relation to ethics education and training for researchers; consideration of ethics in big data studies in education; and norms/policies in academic publishing for authors to report how ethical issues have been considered.
ISSN - ISSN-2472-5749
ISSN - EISSN-2472-5730
LA  - English
PT  - Journal Articles
PT  - Reports - Research

OWN - ERIC
TI  - Exploring the Impact of Integrating AI Tools in Higher Education Using the Zone of Proximal Development
AU  - Lianyu Cai
AU  - Mgambi Msambwa Msafiri
AU  - Daniel Kangwa
OT  - Artificial Intelligence
OT  - Technology Uses in Education
OT  - Technology Integration
OT  - Higher Education
OT  - Problem Solving
OT  - Cooperative Learning
OT  - Scaffolding (Teaching Technique)
OT  - Faculty Development
OT  - Ethics
OT  - Learning Experience
OT  - Learner Engagement
OT  - Critical Thinking
JT  - Education and Information Technologies
SO  - v30 n6 p7191-7264 2025
AID - http://dx.doi.org/10.1007/s10639-024-13112-0
OID - EJ1467947
VI  - 30
IP  - 6
PG  - 7191-7264
DP  - 2025
LID - http://eric.ed.gov/?id=EJ1467947
AB  - This systematic literature review explored the impact of integrating AI tools in higher education using the Zone of Proximal Development (ZPD) by Lev Vygotsky. It examined how AI tools assist the students in identifying and operating within their ZPD, how to create and facilitate a collaborative learning environment, and how to provide the necessary scaffolding for effective learning. The sample included 158 empirical studies which were retrieved from Web of Science, Scopus, and ERIC, published between 2021 and 2024. Findings indicated that AI tools assist learners in personalising their self-assessment through social and technological interactions, and effective communication; they improve motivation, learning engagement, and learning support, which leads to better academic performance, student maturation, and development. Additionally, AI tools were found suitable for creating collaborative learning environments, empowering learners, and facilitating meaningful interactions. Furthermore, results emphasise the need for educator's professional development, ethical AI deployment, and the integration of AI into designing meaningful learning experiences. These results indicate that there should be equitable access to training and effective resolutions for ethical challenges that may undermine the integrity of the learning process. The study highlights strategic AI integration to significantly enhance learning outcomes and student engagement, focusing on academic integrity and complementing traditional educational methods. Recommendations are that there is a need for longitudinal studies to assess the long-term impact of AI on learning outcomes, student engagement, and the development of critical thinking and problem-solving skills.
ISSN - ISSN-1360-2357
ISSN - EISSN-1573-7608
LA  - English
PT  - Journal Articles
PT  - Reports - Research

OWN - ERIC
TI  - Communicating Clear Guidance: Advice for Generative AI Policy Development in Higher Education
AU  - Sarah Moore
AU  - Kathryn Lookadoo
OT  - Artificial Intelligence
OT  - Educational Policy
OT  - Course Descriptions
OT  - Audience Awareness
OT  - Ethics
OT  - Policy Formation
OT  - Higher Education
OT  - Student Needs
OT  - Equal Education
OT  - Cheating
OT  - Academic Standards
JT  - Business and Professional Communication Quarterly
SO  - v87 n4 p610-629 2024
AID - http://dx.doi.org/10.1177/23294906241254786
OID - EJ1447650
VI  - 87
IP  - 4
PG  - 610-629
DP  - 2024
LID - http://eric.ed.gov/?id=EJ1447650
AB  - This article presents the ongoing conversation about generative AI guidance and policy in higher education. The article examines syllabus policies, including analyzing sentiment, emotion, and common themes in GenAI policies. Findings show that policies should be audience-focused, clearly written, and grounded in strategies to promote ethical AI use in academia and the workforce. Practical tips for policy writing and sample policies are provided.
ISSN - ISSN-2329-4922
ISSN - EISSN-2329-4906
LA  - English
PT  - Journal Articles
PT  - Reports - Research
PT  - Information Analyses

OWN - ERIC
TI  - Preserving the Integrity of Study Behaviour in Online Retrieval Practice Using Quantified Learner Dynamics
AU  - Maarten van der Velde
AU  - Malte Krambeer
AU  - Hedderik van Rijn
OT  - Artificial Intelligence
OT  - Technology Uses in Education
OT  - Student Behavior
OT  - Information Retrieval
OT  - Integrity
OT  - Keyboarding (Data Entry)
OT  - Secondary School Students
OT  - Foreign Countries
OT  - Cheating
OT  - Prevention
OT  - Deception
JT  - International Educational Data Mining Society
SO  - Paper presented at the International Conference on Educational Data Mining (EDM) (18th, Palermo, Italy, Jul 20-23, 2025)
OID - ED675635
DP  - 2025
LID - http://eric.ed.gov/?id=ED675635
AB  - Ensuring the integrity of results in online learning and assessment tools is a challenge, due to the lack of direct supervision increasing the risk of fraud. We propose and evaluate a machine learning-based method for detecting anomalous behaviour in an online retrieval practice task, using an XGBoost classifier trained on keystroke dynamics and task performance features to distinguish between genuine and fraudulent responses. The classifier requires only a modest amount of training data--approximately 100 short-answer responses, typically collected within 10 minutes of practice-- and maintains good performance when not all feature types are available. This method enhances the reliability of online learning and assessment by identifying anomalous response behaviour in a way that preserves learners' privacy. [For the complete proceedings, see ED675583.]
PT  - Speeches/Meeting Papers
PT  - Reports - Research

OWN - ERIC
TI  - Predictive Algorithms and Racial Bias: A Qualitative Descriptive Study on the Perceptions of Algorithm Accuracy in Higher Education
AU  - Stacey Lynn von Winckelmann
OT  - Prediction
OT  - Algorithms
OT  - Racism
OT  - Accuracy
OT  - Higher Education
OT  - Social Justice
OT  - Student Records
OT  - Privacy
JT  - Information and Learning Sciences
SO  - v124 n9-10 p349-371 2023
AID - http://dx.doi.org/10.1108/ILS-05-2023-0045
OID - EJ1399216
VI  - 124
PG  - 349-371
DP  - 2023
LID - http://eric.ed.gov/?id=EJ1399216
AB  - Purpose: This study aims to explore the perception of algorithm accuracy among data professionals in higher education. Design/methodology/approach: Social justice theory guided the qualitative descriptive study and emphasized four principles: access, participation, equity and human rights. Data collection included eight online open-ended questionnaires and six semi-structured interviews. Participants included higher education professionals who have worked with predictive algorithm (PA) recommendations programmed with student data. Findings: Participants are aware of systemic and racial bias in their PA inputs and outputs and acknowledge their responsibility to ethically use PA recommendations with students in historically underrepresented groups (HUGs). For some participants, examining these topics through the lens of social justice was a new experience, which caused them to look at PAs in new ways. Research limitations/implications: Small sample size is a limitation of the study. Implications for practice include increased stakeholder training, creating an ethical data strategy that protects students, incorporating adverse childhood experiences data with algorithm recommendations, and applying a modified critical race theory framework to algorithm outputs. Originality/value: The study explored the perception of algorithm accuracy among data professionals in higher education. Examining this topic through a social justice lens contributes to limited research in the field. It also presents implications for addressing racial bias when using PAs with students in HUGs.
ISSN - ISSN-2398-5348
ISSN - EISSN-2398-5356
LA  - English
PT  - Journal Articles
PT  - Reports - Research

OWN - ERIC
TI  - Threats and Opportunities of Students' Use of AI-Integrated Technology (ChatGPT) in Online Higher Education: Saudi Arabian Educational Technologists' Perspectives
AU  - Mesfer Mihmas Mesfer Aldawsari
AU  - Nouf Rashed Ibrahim Almohish
OT  - Artificial Intelligence
OT  - Computer Software
OT  - Synchronous Communication
OT  - Technology Uses in Education
OT  - Electronic Learning
OT  - Higher Education
OT  - Computers
OT  - Information Systems
OT  - Teaching Methods
OT  - Educational Needs
OT  - Foreign Countries
JT  - International Review of Research in Open and Distributed Learning
SO  - v25 n3 p19-36 2024
OID - EJ1441384
VI  - 25
IP  - 3
PG  - 19-36
DP  - 2024
LID - http://eric.ed.gov/?id=EJ1441384
AB  - This research study explored the perspectives of 20 educational technologists from four Saudi Arabian universities regarding the integration of AI-powered technology, particularly ChatGPT, into online higher education. The study used a qualitative research method that relied on the principles of theoretical sampling to select participants and conducted in-depth interviews to collect their insights. The approach taken for data analysis was thematic analysis, which uncovered a rich range of insights on both the challenges and opportunities associated with students' use of AI-integrated technology in the context of online higher education. Ten significant challenges emerged that shed light on the complexities and intricacies of integrating AI-powered technology into educational environments. These challenges included issues related to technological infrastructure, pedagogical adaptation, and the need for comprehensive training programs to empower both teachers and learners. Additionally, eight threats were examined that highlighted concerns about data security, privacy, and potential risks associated with AI technology in educational institutions. This study not only provided a comprehensive overview of the current landscape of AI-integrated technology in Saudi Arabian higher education, but also provided valuable insights for education stakeholders, technologists, and policy makers. It underscored the necessity of proactive measures to mitigate challenges and threats while harnessing the opportunities presented by AI technology to enhance the quality and effectiveness of online higher education.
ISSN - EISSN-1492-3831
LA  - English
PT  - Journal Articles
PT  - Reports - Research

OWN - ERIC
TI  - Predictive Algorithms and Racial Bias: A Qualitative Descriptive Study on the Perceptions of Algorithm Accuracy in Higher Education
AU  - Stacey von Winckelmann
OT  - Prediction
OT  - Algorithms
OT  - Racism
OT  - Accuracy
OT  - Higher Education
OT  - Social Justice
OT  - Student Records
OT  - Privacy
JT  - ProQuest LLC
SO  - Ed.D. Dissertation, Northcentral University
AID - http://gateway.proquest.com/openurl?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&res_dat=xri:pqm&rft_dat=xri:pqdiss:30490052
OID - ED644591
DP  - 2023
LID - http://eric.ed.gov/?id=ED644591
AB  - The research problem addressed in this study is that racial bias programmed into predictive algorithm recommendations negatively impacts students in historically underrepresented groups. The purpose of this qualitative descriptive study was to explore the perception of algorithm accuracy among data professionals in higher education and explore the potential application of a modified critical race theory framework to the design of predictive algorithms used in higher education to reduce instances of racial bias from negatively impacting students from historically underrepresented groups. Social justice theory guided this study and emphasized four principles: access, participation, equity, and human rights. Three research questions steered this study. RQ1 addressed how data professionals in higher education perceived the accuracy of predictive algorithm recommendations used at higher education institutions. RQ2 considered how institutions vet the accuracy of their recommendations to protect students in historically underrepresented groups. RQ3 examined the process higher education institutions use to address racially biased predictive algorithm recommendations to protect students in historically underrepresented groups. This study included eight higher education professionals who currently work or have recently worked with predictive algorithm recommendations. Data collection initially occurred through an online Qualtrics questionnaire, with six of these participants volunteering to participate in online one-on-one semi-structured interviews through Zoom. NVivo directed thematic analysis by identifying codes, categories, and themes. Themes centered on the prevalence of systemic and racial bias in algorithm inputs and outputs (recommendations). Four implications for practice include the need for social justice and data literacy training for stakeholders, increased student participation in an institution's data strategy, including adverse childhood experiences data, and incorporating critical race theory tenets into the predictive algorithm design process. Future research should center on data justice and predictive algorithm recommendations, integrating critical race theory tenets into predictive algorithm inputs and outputs, and interviewing college students in historically underrepresented groups on their perception of predictive algorithms used at higher education institutions. Increased research in these areas can support social justice and guide institutions in the ethical use of predictive algorithm recommendations. [The dissertation citations contained here are published with the permission of ProQuest LLC. Further reproduction is prohibited without permission. Copies of dissertations may be obtained by Telephone (800) 1-800-521-0600. Web page: http://www.proquest.com/en-US/products/dissertations/individuals.shtml.]
ISBN - 979-8-3814-2692-2
PT  - Dissertations/Theses - Doctoral Dissertations

OWN - ERIC
TI  - Experiential Learning: Exploring Nuances When Making Ethical Decisions in a Capstone Design Course
AU  - Holly Golecki
AU  - Joe Bradley
OT  - Experiential Learning
OT  - Decision Making
OT  - Ethics
OT  - Capstone Experiences
OT  - Biomedicine
OT  - Engineering Education
OT  - Bias
OT  - Design
OT  - Technology
OT  - Equipment
OT  - Social Justice
OT  - Inclusion
OT  - Data
OT  - Learning Modules
OT  - Artificial Intelligence
JT  - Biomedical Engineering Education
SO  - v4 n1 p163-170 2024
AID - http://dx.doi.org/10.1007/s43683-023-00126-2
OID - EJ1430989
VI  - 4
IP  - 1
PG  - 163-170
DP  - 2024
LID - http://eric.ed.gov/?id=EJ1430989
AB  - Biomedical engineering capstone design courses provide a salient opportunity to discuss ethical considerations in engineering. As technology and society develop and change, new challenges constantly arise related to how society and technology inform each other. In this space, ethical training for engineering students is critically important for future practicing engineers who may face significant once-in-a-career ethical challenges as well as the smaller compounding daily decisions that impact biomedical research and device design. In this context, topics of social justice as well as bias and inclusion in data and design are particularly important for biomedical engineers to understand the given the human-centered approach to engineering practice. To engage biomedical engineering students in discussion and practice of these concepts, we present a capstone course module to teach traditional ethics studies while exposing students to cases of bias in design in modern technologies including AI, sensors, and devices. This curriculum engages students in discussion of these topics facilitated by biotechnology case studies. All together, we see the curriculum presented here as a response to the need for biomedical engineers to understand the human-centered data in ethical decision-making as well as to meet the desires of students to put engineering in the context of human-centered design and social justice.
ISSN - ISSN-2730-5937
ISSN - EISSN-2730-5945
LA  - English
PT  - Journal Articles
PT  - Reports - Descriptive

OWN - ERIC
TI  - Internet-Based Testing: A Solution for the New Normal
AU  - Langenfeld, Thomas
OT  - Internet
OT  - Computer Assisted Testing
OT  - COVID-19
OT  - Pandemics
OT  - Observation
OT  - Artificial Intelligence
OT  - Privacy
OT  - Cheating
JT  - Journal of Applied Testing Technology
SO  - v23 spec iss p5-14 2022
AID - http://www.jattjournal.com/index.php/atp/article/view/168522
OID - EJ1342166
VI  - 23
PG  - 5-14
DP  - spec iss 2022
LID - http://eric.ed.gov/?id=EJ1342166
AB  - The turn to online learning and training programs as a response to challenging times (i.e., the COVID-19 crisis) necessitated the need for internet-based testing solutions. Researchers generally have found that Unproctored Internet Testing (UIT) for high-stakes cognitive ability assessments results in higher scores than proctored assessments. Live or Artificial Intelligence (AI) remote proctoring are possible solutions for the secure administrations. Vendors have developed live and AI remote proctoring with service levels ranging from minimal to top-tier security. Added security comes with a price, and these services quickly become expensive. Institutions need to identify a level of security that is commensurate with the stakes and uses of test scores. Researchers are finding that combining live remote proctoring with specific design features minimizes cheating and other unauthorized behaviors. As institutions consider live remote proctoring, they need to be cognizant of not only ensuring security, but also ensuring the opportunity to test for all students.
ISSN - EISSN-2375-5636
LA  - English
PT  - Journal Articles
PT  - Reports - Descriptive

OWN - ERIC
TI  - ChatGPT in Language Education: Applications and Implications for Teaching and Learning
AU  - Hung Thanh Nguyen
AU  - Phuoc Tai Nguyen
OT  - Artificial Intelligence
OT  - Man Machine Systems
OT  - Natural Language Processing
OT  - Language Teachers
OT  - Teacher Attitudes
OT  - Student Attitudes
OT  - Learner Engagement
OT  - Feedback (Response)
OT  - Accuracy
OT  - Ethics
OT  - English (Second Language)
OT  - Second Language Instruction
OT  - College Students
OT  - Foreign Countries
JT  - Educational Process: International Journal
SO  - v18 Article e2025464 2025
OID - EJ1485249
VI  - 18
DP  - Article e2025464 2025
LID - http://eric.ed.gov/?id=EJ1485249
AB  - Background/purpose: Artificial intelligence, namely ChatGPT, has garnered significant interest in language education due to its potential to enhance instruction and learning. Three primary topics are highlighted in this study's analysis of recent research on ChatGPT's use in language instruction: Reflection on instruction, instructor feedback, and adaptation of reading texts. Materials/methods: Ten language instructors and twenty students who had been using ChatGPT in language sessions for at least one semester participated in semi-structured interviews. A detailed understanding of ChatGPT's integration into language teaching and learning methods is made possible by the interviews, which captured the breadth and complexity of participants' experiences. Results: The results showed that feedback facilitated by ChatGPT enhanced student engagement and encouraged better writing abilities. Personalized reading tasks were made easier by AI-driven text adaptation, but questions about accuracy, prejudice, and ethical use surfaced. Conclusion: Notwithstanding these difficulties, ChatGPT offers a wealth of opportunities for customized language learning teaching. Clear ethical standards and focused teacher training are necessary for effective implementation. In order to evaluate the tool's long-term educational impact, more longitudinal study is required.
ISSN - ISSN-2147-0901
ISSN - EISSN-2564-8020
LA  - English
PT  - Journal Articles
PT  - Reports - Research

OWN - ERIC
TI  - Bridging the Gap for Contingent Faculty: An Analysis of the Professional Development and Growth Resources Used in Public Universities across Michigan
AU  - Caryl Lynn Walling
OT  - Public Colleges
OT  - Universities
OT  - Faculty Development
OT  - Teacher Attitudes
OT  - Inservice Teacher Education
OT  - Teacher Improvement
OT  - Nontenured Faculty
OT  - Teacher Motivation
OT  - Environmental Influences
JT  - ProQuest LLC
SO  - Ph.D. Dissertation, The University of Toledo
AID - https://gateway.proquest.com/openurl?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&res_dat=xri:pqm&rft_dat=xri:pqdiss:31480123
OID - ED658942
DP  - 2023
LID - http://eric.ed.gov/?id=ED658942
AB  - The purpose of this study was to explore the extent that contingent faculty from Michigan's 15 public universities engage with on and off-campus professional development (PD) to improve their teaching practice. Addressing a spectrum of research questions, this study utilized an explanatory sequential mixed-methods approach, combining quantitative surveys and qualitative interviews, to provide a nuanced understanding of the experiences and motivations of contingent faculty members. The initial quantitative phase surveyed 4,745 contingent faculty members through a web- based survey, exploring the availability of on and off-campus PD offerings and the factors influencing their participation. The subsequent qualitative phase was conducted through ten Zoom interviews with contingent faculty from nine universities. This phase delved into the various PD resources utilized by contingent faculty and the underlying motivations driving their engagement. The on-campus exploration revealed the prevalence of in-person seminars and computer-based training from Centers for Teaching and Learning (CTLs), that aligned with broader institutional trends. However, faculty interviews exposed discontent rooted in CTL unfulfilled promises, insufficient communication, and a perceived emphasis on theory over practical application. Contingent faculty expressed a strong desire for peer interactions, mentorship, and discipline-specific development, emphasizing the importance of immediately applicable knowledge. The study further explored on-campus factors influencing contingent faculty.Transitioning to off-campus PD, the study uncovered a significant commitment to continuous learning among contingent faculty. Engagement in live in-person seminars, conferences, social media, and internet resources emerged as critical elements in their professional growth. Notably, the unexpected involvement with artificial intelligence (AI) in discussions around lesson planning and academic integrity reflected the faculty's adaptability to emerging technologies. The examination of off-campus factors influencing contingent faculty engagement revealed a variety of influencers on faculty behavior.Concluding with an exploration of contingent faculty's professionalism traits, the study identified ethics, credentials, innovation and research, professional autonomy, and expertise as central motivators. Contingent faculty perceived themselves as dedicated professionals actively seeking PD to enhance their teaching expertise. This dissertation contributed valuable insights for university leadership, external PD providers, and contingent faculty. The findings advocated for a collaborative and supportive academic environment that understands and addresses the unique needs of contingent faculty in Michigan. [The dissertation citations contained here are published with the permission of ProQuest LLC. Further reproduction is prohibited without permission. Copies of dissertations may be obtained by Telephone (800) 1-800-521-0600. Web page: http://www.proquest.com/en-US/products/dissertations/individuals.shtml.]
ISBN - 979-8-3828-3372-9
PT  - Dissertations/Theses - Doctoral Dissertations

OWN - ERIC
TI  - Face Anonymization in Intelligent Experiment Education
AU  - Jiangyi Cui
AU  - Ruijiao Li
AU  - Qiushu Chen
AU  - Libin Liu
AU  - Xuan Zhao
AU  - Kai Liu
AU  - Huiliang Shang
OT  - Privacy
OT  - Experiments
OT  - Confidentiality
OT  - Ethics
OT  - Human Body
OT  - Algorithms
OT  - Artificial Intelligence
OT  - Technology Uses in Education
OT  - Video Technology
OT  - Computer Software
JT  - International Journal of Technology in Education and Science
SO  - v9 n3 p434-449 2025
OID - EJ1482816
VI  - 9
IP  - 3
PG  - 434-449
DP  - 2025
LID - http://eric.ed.gov/?id=EJ1482816
AB  - Face anonymization in intelligent experimental education is crucial for privacy protection. This paper presents a novel, real-time face blurring system for smart experimental settings. Our key contributions include: 1) customized YOLOv8 (Multi-Scale Feature Fusion YOLOv8) algorithm achieving 96% accuracy at 22.67 fps for 1080p video. 2) An annotation dilation preprocessing method, Contour-Adaptive Occlusion Refinement (CAOR), to address instrument occlusion issues for training. 3) A specialized dataset of 51 experimental videos with dense annotations. Our system tackles the unique challenge of preserving experimental details while anonymizing faces. We introduce two metrics, Sensitivity of Blur Accuracy (SOBA) and Over Blurred Rate (OBR), to evaluate performance. Our work demonstrates robustness across physics, biology, and chemistry experiments, maintaining a low mis-blur rate of 0.02 for instruments.
ISSN - EISSN-2651-5369
LA  - English
PT  - Journal Articles
PT  - Reports - Research

OWN - ERIC
TI  - Integration of Learning Technologies in Medical Students' Curriculum: A Systematic Review
AU  - Soleiman Ahmady
AU  - SeyedAhmad SeyedAlinaghi
AU  - Soudabeh Yarmohammadi
AU  - Amir Masoud Afsahi
AU  - Parisa Matini
AU  - Faeze Abbaspour
AU  - Pedram Habibi
AU  - Pegah Mirzapour
AU  - Sepide Ahmadi
AU  - Elaheh Karimi
AU  - Parnian Haghi
AU  - Ayoob Molla
AU  - Sara Shahbazi
AU  - Esmaeil Mehraeen
OT  - Literature Reviews
OT  - Medical Education
OT  - Technology Uses in Education
OT  - Educational Technology
OT  - Information Technology
OT  - Teaching Methods
OT  - Artificial Intelligence
OT  - Computer Simulation
OT  - Handheld Devices
OT  - Technology Integration
OT  - Meta Analysis
OT  - Curriculum
JT  - Health Education
SO  - v125 n6 p672-719 2025
AID - http://dx.doi.org/10.1108/HE-10-2024-0117
OID - EJ1491600
VI  - 125
IP  - 6
PG  - 672-719
DP  - 2025
LID - http://eric.ed.gov/?id=EJ1491600
AB  - Purpose: This paper highlights the transformative impact of information and communication technologies (ICTs) on education, focusing on their potential to revolutionize teaching methods. It also explores the global trend of integrating technology-based learning into educational curricula. Design/methodology/approach: A comprehensive literature search, using combinations of relevant keywords such as educational technology, learning technology, curriculum, and medical curriculum, was conducted in PubMed/MEDLINE, Embase, and Scopus databases for articles published in English until July 24, 2023. We appraised the quality and bias risk of included studies using the National Institute of Health (NIH) quality assessment tool. Findings: The study's findings highlight the significant impact of integrating new technologies into medical education. The selection of 56 articles that focused on implementing new curricula and modules in medical training provided a comprehensive analysis of how virtual patient simulations, 3D modeling software, augmented reality, and video conferencing platforms enhanced learning and clinical skills. Integrating these technologies yielded promising outcomes, including improved knowledge retention, self-directed learning, and increased motivation among students. This evolution of educational technology in medical education indicates a clear shift towards more interactive, personalized, and advanced digital learning experiences. The incorporation of simulation, Artificial Intelligence (AI), Virtual Reality (VR), and mobile technologies has not only transformed the learning process for medical students but also influenced the way professionals engage with educational content, ultimately enhancing patient care and medical practice. Originality/value: Integrating learning technologies into the education curriculum provides valuable opportunities to enhance medical students' capabilities, self-confidence, and knowledge. Also, learning technologies provide practical applications such as producing audio and video films about nasogastric intubation, online recording of students' feedback, full-body simulator and guided trainer, live demonstrations, and covering general surgery by audio-visual podcasts.
ISSN - ISSN-0965-4283
ISSN - EISSN-1758-714X
LA  - English
PT  - Journal Articles
PT  - Information Analyses
PT  - Reports - Research

OWN - ERIC
TI  - Enhancing Collaborative Learning Practices via Chatbots: Insights from an EFL Context
AU  - Ferit Kiliçkaya
AU  - Joanna Kic-Drgas
OT  - Cooperative Learning
OT  - English (Second Language)
OT  - Artificial Intelligence
OT  - Language Teachers
OT  - Computer Uses in Education
OT  - Preservice Teachers
JT  - SAGE Open
SO  - v15 n3 2025
AID - http://dx.doi.org/10.1177/21582440251369189
OID - EJ1487031
VI  - 15
IP  - 3
DP  - 2025
LID - http://eric.ed.gov/?id=EJ1487031
AB  - The study explores the role of AI-driven chatbots in fostering collaborative learning among English as a Foreign Language (EFL) teachers. By examining the experiences of 25 pre-service EFL teachers who used a chatbot as part of their teacher training, the study investigates how the tool supports peer interactions, enhances collaborative learning, and addresses challenges related to group work and knowledge sharing. Through semi-structured interviews and chatbot interaction logs, the qualitative analysis identified key contributions of the chatbot. Participants reported that the chatbot facilitated peer collaboration by generating discussion prompts, supporting collective tasks, and encouraging shared learning. Additionally, the chatbot promoted accountability by tracking progress and enhancing communication, particularly for participants who found face-to-face collaboration challenging. Despite these benefits, participants highlighted challenges such as occasional inaccuracies in chatbot responses, a lack of personalized suggestions, and concerns about data privacy. The findings emphasize the potential of chatbots to transform collaborative learning environments when integrated thoughtfully into the curriculum, with improvements needed in tailoring responses and ensuring data security. This study provides concrete evidence of the chatbot's capacity to enhance teamwork, task management, and communication among future teachers, offering valuable insights for implementing AI tools in teacher training programs.
ISSN - EISSN-2158-2440
LA  - English
PT  - Journal Articles
PT  - Reports - Research

OWN - ERIC
TI  - Towards a Machine Learning-Based Constructive Alignment Approach for Improving Outcomes Composure of Engineering Curriculum
AU  - Wai Tong Chor
AU  - Kam Meng Goh
AU  - Li Li Lim
AU  - Kin Yun Lum
AU  - Tsung Heng Chiew
OT  - Artificial Intelligence
OT  - Engineering Education
OT  - Taxonomy
OT  - Educational Objectives
OT  - Program Descriptions
OT  - Course Objectives
OT  - Alignment (Education)
OT  - Automation
OT  - Natural Language Processing
OT  - Error Correction
OT  - Bias
OT  - Classification
OT  - Models
OT  - Foreign Countries
OT  - Universities
OT  - College Curriculum
JT  - Education and Information Technologies
SO  - v29 n7 p8925-8959 2024
AID - http://dx.doi.org/10.1007/s10639-023-12180-y
OID - EJ1424295
VI  - 29
IP  - 7
PG  - 8925-8959
DP  - 2024
LID - http://eric.ed.gov/?id=EJ1424295
AB  - The programme outcomes are broad statements of knowledge, skills, and competencies that the students should be able to demonstrate upon graduation from a programme, while the Educational Taxonomy classifies learning objectives into different domains. The precise mapping of a course outcomes to the programme outcome and the educational taxonomy (Cognitive, Psychomotor and Affective) level is crucial to ensure Constructive Alignment at the fundamental level of a course and to ensure meaningful outcome measurements. Unfortunately, this effort is often subject to bias and human error while the use of information technologies as a mediator in this area remains unexplored. This research paper proposes an automatic learning-based advisory system for engineering curriculum to ensure constructive alignment with programme outcomes and educational taxonomy. We demonstrated the use of natural language processing and machine learning techniques to mitigate human error and bias that is often present in such classification tasks. Textual/semantic embeddings, including Term Frequency-Inverse Document Frequency (TF-IDF), Universal Sentence Encoder (USE), and Word2Vec (W2V), machine learning models (Random Forest, Support Vector Machine, Logistic Regression, and Light Gradient Boosting Machine), and their corresponding techniques for optimizing the training process are extensively investigated. In terms of accuracy, we obtained an encouraging result of 78.83%, and 78.71% for TF-IDF with Random Forest, and USE with Support Vector Machine classifier, respectively. We transformed our work into a web-based solution named the Course Outcomes Diagnostic Tool, embedded in the faculty education web platform, Edu Centre that is ubiquitously adopted by the members in the Faculty of Engineering and Technology, Tunku Abdul Rahman University of Management and Technology. The proposed solution has demonstrated great potential in reducing subjectivity, ambiguity, and human error, thereby improving the constructive alignment at the root level of course design to ensures teaching-learning activities are aligned with regulatory body expectations.
ISSN - ISSN-1360-2357
ISSN - EISSN-1573-7608
LA  - English
PT  - Journal Articles
PT  - Reports - Research

OWN - ERIC
TI  - The Use of Deep Learning in Open Learning: A Systematic Review (2019 to 2023)
AU  - Odiel Estrada-Molina
AU  - Juanjo Mena
AU  - Alexander López-Padrón
OT  - Artificial Intelligence
OT  - Intelligent Tutoring Systems
OT  - Open Education
OT  - Educational Trends
OT  - Technology Uses in Education
OT  - Journal Articles
OT  - Potential Dropouts
OT  - Predictor Variables
OT  - Automation
OT  - Grading
OT  - MOOCs
OT  - Course Selection (Students)
OT  - Algorithms
OT  - Prediction
OT  - Decision Support Systems
OT  - Barriers
OT  - Individualized Instruction
OT  - Bias
OT  - Course Content
JT  - International Review of Research in Open and Distributed Learning
SO  - v25 n3 p371-393 2024
OID - EJ1441369
VI  - 25
IP  - 3
PG  - 371-393
DP  - 2024
LID - http://eric.ed.gov/?id=EJ1441369
AB  - No records of systematic reviews focused on deep learning in open learning have been found, although there has been some focus on other areas of machine learning. Through a systematic review, this study aimed to determine the trends, applied computational techniques, and areas of educational use of deep learning in open learning. The PRISMA protocol was used, and the Web of Science Core Collection (2019-2023) was searched. VOSviewer was used for networking and clustering, and in-depth analysis was employed to answer the research questions. Among the main results, it is worth noting that the scientific literature has focused on the following areas: (a) predicting student dropout, (b) automatic grading of short answers, and (c) recommending MOOC courses. It was concluded that pedagogical challenges have included the effective personalization of content for different learning styles and the need to address possible inherent biases in the datasets (e.g., socio-demographics, traces, competencies, learning objectives) used for training. Regarding deep learning, we observed an increase in the use of pre-trained models, the development of more efficient architectures, and the growing use of interpretability techniques. Technological challenges related to the use of large datasets, intensive computation, interpretability, knowledge transfer, ethics and bias, security, and cost of implementation were also evident.
ISSN - EISSN-1492-3831
LA  - English
PT  - Journal Articles
PT  - Information Analyses

OWN - ERIC
TI  - Generative AI in Education and Research: A Systematic Mapping Review
AU  - Abdullahi Yusuf
AU  - Nasrin Pervin
AU  - Marcos Román-González
AU  - Norah Md Noor
OT  - Artificial Intelligence
OT  - Educational Technology
OT  - Technology Uses in Education
OT  - Elementary Secondary Education
OT  - Ethics
OT  - Technology Integration
OT  - Experience
OT  - Teaching Methods
OT  - Productivity
OT  - Interdisciplinary Approach
JT  - Review of Education
SO  - v12 n2 Article e3489 2024
AID - http://dx.doi.org/10.1002/rev3.3489
OID - EJ1436570
VI  - 12
IP  - 2
DP  - Article e3489 2024
LID - http://eric.ed.gov/?id=EJ1436570
AB  - Given the potential applications of generative AI (GenAI) in education and its rising interest in research, this systematic review mapped the thematic landscape of 407 publications indexed in the Web of Science, ScienceDirect and Scopus. Using EPPI Reviewer, publication type, educational level, disciplines, research areas and applications of GenAI were extracted. Eight discursive themes were identified, predominantly focused on 'application, impact and potential', 'ethical implication and risks', 'perspectives and experiences', 'institutional and individual adoption', and 'performance and intelligence'. GenAI was conceptualised as a tool for 'pedagogical enhancement', 'specialised training and practices', 'writing assistance and productivity', 'professional skills and development', and as an 'interdisciplinary learning tool'. Key gaps highlighted include a paucity of research and discussions on GenAI in K-12 education; a limited exploration of GenAI's impact using experimental procedures; and a limited exploration of the potential and ethical concerns of GenAI from the lens of cultural dimensions. Promising opportunities for future research are highlighted.
ISSN - EISSN-2049-6613
LA  - English
PT  - Journal Articles
PT  - Information Analyses

OWN - ERIC
TI  - 2024 EDUCAUSE Horizon Report: Cybersecurity and Privacy Edition
AU  - Jenay Robert
AU  - Nicole Muscanell
AU  - Nichole Arbino
AU  - Mark McCormack
AU  - Jamie Reeves
OT  - Information Security
OT  - Computer Security
OT  - Privacy
OT  - Higher Education
OT  - School Safety
OT  - Trend Analysis
OT  - Social Influences
OT  - Information Technology
OT  - Economic Factors
OT  - Environmental Influences
OT  - Political Influences
OT  - Intervention
OT  - Artificial Intelligence
OT  - Governance
OT  - Training
JT  - EDUCAUSE
AID - https://library.educause.edu/resources/2024/9/2024-educause-horizon-report-cybersecurity-and-privacy-edition
OID - ED671063
DP  - 2024
LID - http://eric.ed.gov/?id=ED671063
AB  - This report profiles the trends and key technologies and practices shaping the future of cybersecurity and privacy, and envisions a number of scenarios for that future. It is based on the perspectives and expertise of a global panel of leaders from across the higher education landscape. These are, in many ways, tumultuous times. Global political movements and ideologies continue to erode social ties and disrupt state and national legislative processes. Wars in Eastern Europe and the Middle East threaten to destabilize the global order. And new AI-powered technologies are evolving at breakneck speed, offering the world both the promise of new utopian capabilities and the threat of dystopian collapse. Against this backdrop of seismic change, higher education cybersecurity and privacy professionals must navigate new questions around what needs to be done to keep our institutions and our students safe and secure. This report summarizes expert panelist discussions on these and other emerging trends and offers reflections on where the future of higher education may be headed. [Boldyn Networks sponsored this report.]
ISBN - 978-1-933046-21-1
PT  - Reports - Research

OWN - ERIC
TI  - A Systematic Review of Teaching and Learning Machine Learning in K-12 Education
AU  - Sanusi, Ismaila Temitayo
AU  - Oyelere, Solomon Sunday
AU  - Vartiainen, Henriikka
AU  - Suhonen, Jarkko
AU  - Tukiainen, Markku
OT  - Elementary Secondary Education
OT  - Artificial Intelligence
OT  - Educational Research
OT  - Research Needs
OT  - Curriculum Development
OT  - Educational Technology
OT  - Instructional Development
OT  - Faculty Development
OT  - Educational Resources
OT  - Kindergarten
OT  - Middle Schools
OT  - Informal Education
OT  - Ethics
OT  - Social Change
OT  - Educational Trends
OT  - Educational Practices
OT  - Learning
JT  - Education and Information Technologies
SO  - v28 n5 p5967-5997 May 2023
AID - http://dx.doi.org/10.1007/s10639-022-11416-7
OID - EJ1377521
VI  - 28
IP  - 5
PG  - 5967-5997
DP  - May 2023
LID - http://eric.ed.gov/?id=EJ1377521
AB  - The increasing attention to Machine Learning (ML) in K-12 levels and studies exploring a different aspect of research on K-12 ML has necessitated the need to synthesize this existing research. This study systematically reviewed how research on ML teaching and learning in K-12 has fared, including the current area of focus, and the gaps that need to be addressed in the literature in future studies. We reviewed 43 conference and journal articles to analyze specific focus areas of ML learning and teaching in K-12 from four perspectives as derived from the data: curriculum development, technology development, pedagogical development, and teacher training/professional development. The findings of our study reveal that (a) additional ML resources are needed for kindergarten to middle school and informal settings, (b) further studies need to be conducted on how ML can be integrated into subject domains other than computing, (c) most of the studies focus on pedagogical development with a dearth of teacher professional development programs, and (d) more evidence of societal and ethical implications of ML should be considered in future research. While this study recognizes the present gaps and direction for future research, these findings provide insight for educators, practitioners, instructional designers, and researchers into K-12 ML research trends to advance the quality of the emerging field.
ISSN - ISSN-1360-2357
ISSN - EISSN-1573-7608
LA  - English
PT  - Journal Articles
PT  - Reports - Research

OWN - ERIC
TI  - A Within-Group Approach to Ensemble Machine Learning Methods for Causal Inference in Multilevel Studies
AU  - Youmi Suk
OT  - Artificial Intelligence
OT  - Causal Models
OT  - Statistical Inference
OT  - Maximum Likelihood Statistics
OT  - Statistical Bias
OT  - Regression (Statistics)
OT  - Robustness (Statistics)
OT  - Mathematics Achievement
OT  - Algebra
OT  - Grade 8
OT  - Children
OT  - Longitudinal Studies
OT  - Surveys
JT  - Journal of Educational and Behavioral Statistics
SO  - v49 n1 p61-91 2024
AID - http://dx.doi.org/10.3102/10769986231162096
OID - EJ1405824
VI  - 49
IP  - 1
PG  - 61-91
DP  - 2024
LID - http://eric.ed.gov/?id=EJ1405824
AB  - Machine learning (ML) methods for causal inference have gained popularity due to their flexibility to predict the outcome model and the propensity score. In this article, we provide a within-group approach for ML-based causal inference methods in order to robustly estimate average treatment effects in multilevel studies when there is cluster-level unmeasured confounding. We focus on one particular ML-based causal inference method based on the targeted maximum likelihood estimation (TMLE) with an ensemble learner called SuperLearner. Through our simulation studies, we observe that training TMLE within groups of similar clusters helps remove bias from cluster-level unmeasured confounders. Also, using within-group propensity scores estimated from fixed effects logistic regression increases the robustness of the proposed within-group TMLE method. Even if the propensity scores are partially misspecified, the within-group TMLE still produces robust ATE estimates due to double robustness with flexible modeling, unlike parametric-based inverse propensity weighting methods. We demonstrate our proposed methods and conduct sensitivity analyses against the number of groups and individual-level unmeasured confounding to evaluate the effect of taking an eighth-grade algebra course on math achievement in the Early Childhood Longitudinal Study.
ISSN - ISSN-1076-9986
ISSN - EISSN-1935-1054
GR  - 1749275
LA  - English
PT  - Journal Articles
PT  - Reports - Research

OWN - ERIC
TI  - ChatGPT Unveiled: Understanding Perceptions of Academic Integrity in Higher Education -- A Qualitative Approach
AU  - Silva Karkoulian
AU  - Niveen Sayegh
AU  - Nadeen Sayegh
OT  - Artificial Intelligence
OT  - Technology Uses in Education
OT  - Higher Education
OT  - Integrity
OT  - College Students
OT  - Student Attitudes
OT  - College Faculty
OT  - Teacher Attitudes
OT  - Foreign Countries
OT  - Productivity
OT  - Technology Integration
OT  - Ethics
JT  - Journal of Academic Ethics
SO  - v23 n3 p1171-1188 2025
AID - http://dx.doi.org/10.1007/s10805-024-09543-6
OID - EJ1485556
VI  - 23
IP  - 3
PG  - 1171-1188
DP  - 2025
LID - http://eric.ed.gov/?id=EJ1485556
AB  - The purpose of this research is to gain a complete understanding of how students and faculty in higher education perceive the role of AI tools, their impact on academic integrity, and their potential benefits and threats in the educational milieu, while taking into account ways to help curb its disadvantages. Drawing upon a qualitative approach, this study conducted in-depth interviews with a diverse sample of faculty members and students in higher education, in universities across Lebanon. These interviews were analyzed and coded using NVivo software, allowing for the identification of recurring themes and the extraction of rich qualitative data. The findings of this study illuminated a spectrum of perceptions. While ChatGPT and AI tools are recognized for their potential in enhancing productivity, promoting interactive learning experiences, and providing tailored support, they also raise significant concerns regarding academic integrity. This research underscores the need for higher education institutions to carefully navigate the integration of AI tools like ChatGPT. It calls for the formulation of clear policies and guidelines for their ethical and responsible use, along with comprehensive support and training. This study contributes to the existing literature by presenting a comprehensive exploration of the perceptions of both students and faculty regarding AI tools in higher education, through a qualitative rich approach. By delving into the intricate dynamics of ChatGPT and academic integrity, this study offers fresh insights into the evolving educational landscape and the ongoing dialogue between technology and ethics.
ISSN - ISSN-1570-1727
ISSN - EISSN-1572-8544
LA  - English
PT  - Journal Articles
PT  - Reports - Research

OWN - ERIC
TI  - Blueprinting the Future: Automatic Item Categorisation Using Hierarchical Zero-Shot and Few-Shot Classifiers
AU  - Ting Wang
AU  - Keith Stelter
AU  - Thomas O’Neill
AU  - Nathaniel Hendrix
AU  - Andrew Bazemore
AU  - Kevin Rode
AU  - Warren P. Newton
OT  - Test Items
OT  - Automation
OT  - Classification
OT  - Artificial Intelligence
OT  - Achievement Tests
OT  - Family Practice (Medicine)
JT  - Journal of Applied Testing Technology
SO  - v26 n1 p1-13 2025
AID - https://jattjournal.net/index.php/atp/article/view/173220
OID - EJ1489531
VI  - 26
IP  - 1
PG  - 1-13
DP  - 2025
LID - http://eric.ed.gov/?id=EJ1489531
AB  - Precise item categorisation is essential in aligning exam questions with content domains outlined in assessment blueprints. Traditional methods, such as manual classification or supervised machine learning, are often time-consuming, error-prone, or limited by the need for large training datasets. This study presents a novel approach using zero-shot and few-shot Generative Pretrained Transformer (GPT) models for hierarchical item categorisation. By leveraging human-readable language descriptions within a structured Python dictionary, the model navigates complex blueprint hierarchies without requiring extensive training data. An initial simulation with synthetic items demonstrated the method's effectiveness, achieving an average F1 score of 92.91%. The approach was then applied to 200 real exam items from the 2022 In-Training Examination (ITE) by the American Board of Family Medicine (ABFM), reclassifying them according to a newly developed blueprint in just 15 minutes--a process that would typically take several days of expert review. This technique offers rapid, consistent, and scalable item categorisation, minimises human bias, and allows for iterative refinement through simple adjustments to category definitions, enhancing both efficiency and sustainability in assessment design.
ISSN - EISSN-2375-5636
LA  - English
PT  - Journal Articles
PT  - Reports - Research

OWN - ERIC
TI  - Exploring the Frontiers of Generative AI in Assessment: Is There Potential for a Human-AI Partnership?
AU  - David DiSabito
AU  - Lisa Hansen
AU  - Thomas Mennella
AU  - Josephine Rodriguez
OT  - Artificial Intelligence
OT  - Technology Uses in Education
OT  - Man Machine Systems
OT  - Educational Assessment
OT  - Student Evaluation
OT  - Technology Integration
OT  - Efficiency
OT  - Writing Assignments
OT  - Coding
OT  - Data Collection
OT  - Scoring Rubrics
OT  - Scoring
OT  - Bias
OT  - Stakeholders
OT  - Educational Improvement
JT  - New Directions for Teaching and Learning
SO  - n182 p81-96 2025
AID - http://dx.doi.org/10.1002/tl.20630
OID - EJ1475101
DP  - 2025
LID - http://eric.ed.gov/?id=EJ1475101
AB  - This chapter investigates the integration of generative AI (GenAI), specifically ChatGPT, into institutional and course-level assessment at Western New England University. It explores the potential of GenAI to streamline the assessment process, making it more efficient, equitable, and objective. Through the development of a proprietary GenAI tool, the study examines GenAI's assessment of student evidence, including written assignments and computer coding tasks, against human assessment. It addresses challenges such as data collection, coordination, and the need for well-defined and precise rubrics. We found notable differences in GenAI and human scoring in some cases, indicating GenAI's potential in certain assessment contexts while also acknowledging its limitations in others. Our research suggests that GenAI could enhance educational assessment processes, but its integration requires addressing biases in training data and securing buy-in from various stakeholders. Using GenAI to handle particular routine tasks can potentially free up faculty to engage in richer discussions and educational improvements.
ISSN - ISSN-0271-0633
ISSN - EISSN-1536-0768
LA  - English
PT  - Journal Articles
PT  - Reports - Research

OWN - ERIC
TI  - Reducing Workload in Short Answer Grading Using Machine Learning
AU  - Rebecka Weegar
AU  - Peter Idestam-Almquist
OT  - Grading
OT  - Computer Assisted Testing
OT  - Introductory Courses
OT  - Computer Science Education
OT  - Artificial Intelligence
OT  - Ethics
OT  - Scoring
OT  - Computer Software
OT  - Test Format
OT  - Undergraduate Students
JT  - International Journal of Artificial Intelligence in Education
SO  - v34 n2 p247-273 2024
AID - http://dx.doi.org/10.1007/s40593-022-00322-1
OID - EJ1426294
VI  - 34
IP  - 2
PG  - 247-273
DP  - 2024
LID - http://eric.ed.gov/?id=EJ1426294
AB  - Machine learning methods can be used to reduce the manual workload in exam grading, making it possible for teachers to spend more time on other tasks. However, when it comes to grading exams, fully eliminating manual work is not yet possible even with very accurate automated grading, as any grading mistakes could have significant consequences for the students. Here, the evaluation of an automated grading approach is therefore extended from measuring workload in relation to the accuracy of automated grading, to also measuring the overall workload required to correctly grade a full exam, with and without the support of machine learning. The evaluation was performed during an introductory computer science course with over 400 students. The exam consisted of 64 questions with relatively short answers and a two-step approach for automated grading was applied. First, a subset of answers to the exam questions was manually graded and next used as training data for machine learning models classifying the remaining answers. A number of different strategies for how to select which answers to include in the training data were evaluated. The time spent on different grading actions was measured along with the reduction of effort using clustering of answers and automated scoring. Compared to fully manual grading, the overall reduction of workload was substantial--between 64% and 74%--even with a complete manual review of all classifier output to ensure a fair grading.
ISSN - ISSN-1560-4292
ISSN - EISSN-1560-4306
LA  - English
PT  - Journal Articles
PT  - Reports - Research

OWN - ERIC
TI  - Threats to Validity in the Application of Machine Learning in Education
AU  - Kylie Anglin
OT  - Artificial Intelligence
OT  - Educational Technology
OT  - Technology Uses in Education
OT  - Validity
OT  - Research Methodology
OT  - Educational Research
OT  - Inferences
OT  - Construct Validity
OT  - Reliability
OT  - Models
OT  - Causal Models
JT  - Society for Research on Educational Effectiveness
AID - https://www.sree.org/2022-conference
OID - ED658699
DP  - 2022
LID - http://eric.ed.gov/?id=ED658699
AB  - Background: For decades, education researchers have relied on the work of Campbell, Cook, and Shadish to help guide their thinking about valid impact estimates in the social sciences (Campbell & Stanley, 1963; Shadish et al., 2002). The foundation of this work is the "validity typology" and its associated "threats to validity." In this framework, researchers consider the validity of inferences regarding the constructs represented by operationalized variables (construct validity), the strength of association between two variables (statistical validity), the causal relationship of those variables (internal validity), and the generalizability of that relationship (external validity). In each of these validity types (construct, statistical, internal, external), Shadish, Cook, and Campbell outline key threats to validity so that researchers may make design choices that improve their inferences. The framework has had a meaningful influence on the rigor of education research, resulting in a methodological transformation over the past fifteen years towards randomized trials and quasiexperimental designs (Reardon & Stuart, 2019). Today, education research is in the midst of a second transformation as new data sources like natural language and text data have required new methodological approaches (Reardon & Stuart, 2019). Key among these approaches is the application of machine learning to educational data. In supervised machine learning approaches, researchers typically; 1) sample a subset of the data for manual analysis, labelling the data according to the construct of interest; 2) split the labelled data into a training and validation set; 3) use the training dataset to train a model to learn the features that are predictive of the labels; 4) calculate performance statistics on the validation set; 4) apply the model to unlabeled data; and 5) use the model to label unseen data and make inferences regarding educational processes. There are key threats to validity at each of these stages. This paper argues that given the importance of valid inferences is not diminished with new data sources and techniques, the validity types framework can continue to be useful in the application of machine learning to educational impact analyses. Purpose: This paper builds on the validity types framework by considering the key threats to validity in inferences drawn from machine learning. While the majority of these threats have been discussed outside of education, they are rarely discussed within the validity types framework. By bringing each these threats into a single framework, well known by education researchers, we hope to encourage researchers using machine learning to systematically consider plausible threats to validity and the design choices they can make to rule those threats. Methods: We draw on the writings of Shadish, Cook, and Campbell (2002), methodological work from machine learning scholars (Hastie et al., 2009; Jurafsky et al., 2018), and recent applications of machine learning in education to categorize threats in the validity types framework and to demonstrate these threats commonly operate in educational contexts, as well as how they may be ruled out. While the full paper includes definitions, examples, and design solutions, here we simply list a few key threats in each category. Results: Construct Validity: Researchers need to consider construct validity when labelling data manually and when considering how the meaning of those labels change with the machine learning model. Key threats include: (1) Researchers only calculate reliability between the machine learning model and one human labeler, without considering the validity of the training and validation data; (2) Model features are not (or cannot be) examined for construct validity; (3) Model features are not examined in context (and are thus misinterpreted); (4) Model performance is related to unknown characteristics, including potentially important linguistic subgroups; (5) Participants learn how to game the model; (6) Unsupervised machine learning results are interpreted by a single researcher. (Mono-interpreter bias.); and (7) Unsupervised machine learning results are the sole outcome or predictor included in a study. (Mono-operation bias.) Statistical Validity: Researchers need to consider statistical validity at two points: in measuring the performance of the machine learning model and in using the result of the model in correlational, quasi-experimental, and experimental analyses. Key threats include: (1) Researchers do not calculate the most policy relevant performance statistics; (2) Researchers "peek" at the validation data set; (3) Researchers do not examine the sensitivity of results to hyper-parameters; (4) Researchers do not acknowledge uncertainty surrounding performance estimates; and (5) Null conclusions regarding a causal estimand are drawn from a noisy measure labelled using a machine learning model. Internal Validity: Researchers need to consider internal validity when inferring a causal relationship between the text features identified by a model and the outcome of interest. In all but a few cases, causal inferences are unlikely to be warranted. Most text data -- whether collected for the purpose of understanding variations in units, treatment, outcomes, or settings (UTOS) -- are non-experimental in nature. The most prevalent threat in this case is selection bias; a predictive relationship between a text feature and an outcome may very well be due other differences between groups. External Validity: Before generalizing inferences regarding a causal estimand, researchers relying on machine learning also need to consider external validity when they generalize performance statistics from a validation set to other data. Thus, threats to external validity occur when there is a difference between the validation dataset and the data to which the researcher wishes to apply the model. This occurs when: (1) Performance statistics are calculated on a convenience sample, rather than a representative sample; (2) Performance statistics are calculated at a single point in time and generalized to new time points; (3) New performance statistics are not calculated when the model is applied to a new setting; and (4) There is dependence between the training and validation datasets. Conclusions: Given the exciting and complicated nature of machine learning, researchers can too often focus on the details of the algorithm overlooking the validity of the resulting inferences (Geiger et al., 2020; Hagen, 2018). Here, we unify machine learning validity concerns under the validity types framework in order to encourage researchers to systematically consider these threats, and to improve research design in order to protect against them.
PT  - Reports - Research

OWN - ERIC
TI  - AI Chatbot Adoption in Academia: Task Fit, Usefulness, and Collegial Ties
AU  - Vishal Soodan
AU  - Avinash Rana
AU  - Anurag Jain
AU  - Deeksha Sharma
OT  - Artificial Intelligence
OT  - Social Networks
OT  - College Faculty
OT  - Computer Software
OT  - Universities
OT  - Intention
OT  - Technology Uses in Education
OT  - Peer Groups
OT  - Foreign Countries
OT  - Technology Integration
OT  - Teacher Attitudes
OT  - Models
OT  - Validity
OT  - Risk
OT  - Plagiarism
OT  - Interdisciplinary Approach
OT  - Privacy
OT  - Barriers
OT  - Ethics
OT  - Leadership Role
OT  - Productivity
OT  - Equal Education
OT  - Access to Education
OT  - Time Management
OT  - Educational Quality
OT  - Learner Engagement
OT  - Familiarity
OT  - Critical Thinking
OT  - Thinking Skills
OT  - Collegiality
OT  - Goodness of Fit
JT  - Journal of Information Technology Education: Innovations in Practice
SO  - v23 Article 1 2024
AID - https://doi.org/10.28945/5260
OID - EJ1427732
VI  - 23
DP  - Article 2024
LID - http://eric.ed.gov/?id=EJ1427732
AB  - Aim/Purpose: This mixed-methods study aims to examine factors influencing academicians' intentions to continue using AI-based chatbots by integrating the Task-Technology Fit (TTF) model and social network characteristics. Background: AI-powered chatbots are gaining popularity across industries, including academia. However, empirical research on academicians' adoption behavior is limited. This study proposes an integrated model incorporating TTF factors and social network characteristics like density, homophily, and connectedness to understand academics' continuance intentions. Methodology: A qualitative study involving 31 interviews of academics from India examined attitudes and the potential role of social network characteristics like density, homophily, and connectedness in adoption. Results showed positive sentiment towards chatbots and themes on how peer groups accelerate diffusion. In the second phase, a survey of 448 faculty members from prominent Indian universities was conducted to test the proposed research model. Contribution: The study proposes and validates an integrated model of TTF and social network factors that influence academics' continued usage intentions toward AI chatbots. It highlights the nuanced role of peer networks in shaping adoption. Findings: Task and technology characteristics positively affected academics' intentions to continue AI chatbot usage. Among network factors, density showed the strongest effect on TTF and perceived usefulness, while homophily and connectedness had partial effects. The study provides insights into designing appropriate AI tools for the academic context. Recommendations for Practitioners: AI chatbot designers should focus on aligning features to academics' task needs and preferences. Compatibility with academic work culture is critical. Given peer network influences, training and demonstrations to user groups can enhance adoption. Platforms should have capabilities for collaborative use. Targeted messaging customized to disciplines can resonate better with academic subgroups. Multidisciplinary influencers should be engaged. Concerns like plagiarism risks, privacy, and job impacts should be transparently addressed. Recommendation for Researchers: More studies are needed across academic subfields to understand nuanced requirements and barriers. Further studies are recommended to investigate differences across disciplines and demographics, relative effects of specific network factors like size, proximity, and frequency of interaction, the role of academic leadership and institutional policies in enabling chatbot adoption, and how AI training biases impact usefulness perceptions and ethical issues. Impact on Society: Increased productivity in academia through the appropriate and ethical use of AI can enhance quality, access, and equity in education. AI can assist in mundane tasks, freeing academics' time for higher-order objectives like critical thinking development. Responsible AI design and policies considering socio-cultural aspects will benefit sustainable growth. With careful implementation, it can make positive impacts on student engagement, learning support, and research efficiency. Future Research: Conduct longitudinal studies to examine the long-term impacts of AI chatbot usage in academia. Track usage behaviors over time as familiarity develops. Investigate differences across academic disciplines and roles. Requirements may vary for humanities versus STEM faculty or undergraduate versus graduate students. Assess user trust in AI and how it evolves with repeated usage, and examine trust-building strategies. Develop frameworks to assess pedagogical effectiveness and ethical risks of conversational agents in academic contexts.
ISSN - ISSN-2165-3151
ISSN - EISSN-2165-316X
LA  - English
PT  - Journal Articles
PT  - Reports - Research

OWN - ERIC
TI  - Towards Development of Models That Learn New Tasks from Instructions
AU  - Mishra, Swaroop
OT  - Natural Language Processing
OT  - Models
OT  - Readability
OT  - Mathematical Logic
OT  - Mathematics Instruction
OT  - Instructional Materials
JT  - ProQuest LLC
SO  - Ph.D. Dissertation, Arizona State University
AID - http://gateway.proquest.com/openurl?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&res_dat=xri:pqm&rft_dat=xri:pqdiss:30313219
OID - ED633941
DP  - 2023
LID - http://eric.ed.gov/?id=ED633941
AB  - Humans have the remarkable ability to solve different tasks by simply reading textual instructions that define the tasks and looking at a few examples. Natural Language Processing (NLP) models built with the conventional machine learning paradigm, however, often struggle to generalize across tasks (e.g., a question-answering system cannot solve classification tasks) despite training with lots of examples. A long-standing challenge in Artificial Intelligence (AI) is to build a model that learns a new task by understanding the human-readable instructions that define it. To study this, I led the development of NATURAL INSTRUCTIONS and SUPERNATURAL INSTRUCTIONS, large-scale datasets of diverse tasks, their human-authored instructions, and instances. I adopt generative pre-trained language models to encode task-specific instructions along with input and generate task output. Empirical results in my experiments indicate that the instruction-tuning helps models achieve cross-task generalization. This leads to the question: how to write good instructions? Backed by extensive empirical analysis on large language models, I observe important attributes for successful instructional prompts and propose several reframing techniques for model designers to create such prompts. Empirical results in my experiments show that reframing notably improves few-shot learning performance; this is particularly important on large language models, such as GPT3 where tuning models or prompts on large datasets is expensive. In another experiment, I observe that representing a chain of thought instruction of mathematical reasoning questions as a program improves model performance significantly. This observation leads to the development of a large scale mathematical reasoning model BHASKAR and a unified benchmark LILA. In case of program synthesis tasks, however, summarizing a question (instead of expanding as in chain of thought) helps models significantly. This thesis also contains the study of instruction-example equivalence, power of decomposition instruction to replace the need for new models and origination of dataset bias from crowdsourcing instructions to better understand the advantages and disadvantages of instruction paradigm. Finally, I apply the instruction paradigm to match real user needs and introduce a new prompting technique HELP ME THINK to help humans perform various tasks by asking questions. [The dissertation citations contained here are published with the permission of ProQuest LLC. Further reproduction is prohibited without permission. Copies of dissertations may be obtained by Telephone (800) 1-800-521-0600. Web page: http://www.proquest.com/en-US/products/dissertations/individuals.shtml.]
ISBN - 979-8-3795-2567-5
PT  - Dissertations/Theses - Doctoral Dissertations

OWN - ERIC
TI  - Perceptions and Use of AI in Higher Education Students: Impact on Teaching, Learning, and Ethical Considerations
AU  - Luis Medina-Gual
AU  - José-Luis Parejo
OT  - Artificial Intelligence
OT  - Teaching Methods
OT  - Ethics
OT  - Learning Processes
OT  - Higher Education
OT  - Undergraduate Students
OT  - Foreign Countries
OT  - Technology Uses in Education
JT  - European Journal of Education
SO  - v60 n1 e12919 2025
AID - https://onlinelibrary.wiley.com/doi/10.1111/ejed.12919
OID - EJ1461385
VI  - 60
IP  - 1
DP  - e12919 2025
LID - http://eric.ed.gov/?id=EJ1461385
AB  - The present research explores AI's impact on education among Mexican undergraduate students through a non-experimental, correlational, cross-sectional study. A validated public questionnaire was distributed to 840 students via Google Forms from February to May 2024. Analysis revealed significant AI exposure and use patterns, primarily influenced by mass media and personal connections. Psychometric evaluations showed strong internal consistency (Cronbach's alpha = 0.97), with PCA and clustering identifying two student profiles: a knowledgeable majority and an optimistic minority with lower formal knowledge. Significant correlations were found between AI familiarity and perceived educational impact. These findings underscore the need for integrating formal AI training into curricula to bridge the gap between enthusiasm and practical knowledge, promoting ethical and effective AI use in higher education. This study informs policy and practice for aligning AI technologies with educational goals.
ISSN - ISSN-0141-8211
ISSN - EISSN-1465-3435
LA  - English
PT  - Journal Articles
PT  - Reports - Research

OWN - ERIC
TI  - Exploring Pre-Service Teachers' Engagement with Generative AI for Multiple-Choice Question Generation
AU  - Kübra Karakaya Özyer
OT  - Preservice Teachers
OT  - Preservice Teacher Education
OT  - Artificial Intelligence
OT  - Multiple Choice Tests
OT  - Student Attitudes
OT  - Test Construction
OT  - Test Items
OT  - Pedagogical Content Knowledge
OT  - Technological Literacy
OT  - Foreign Countries
OT  - Ethics
JT  - International Journal of Technology in Education and Science
SO  - v9 n3 p322-353 2025
OID - EJ1482815
VI  - 9
IP  - 3
PG  - 322-353
DP  - 2025
LID - http://eric.ed.gov/?id=EJ1482815
AB  - This study aims to delve into the process and perceptions of pre-service teachers as they engage in generating multiple-choice questions with the assistance of generative AI tools. Adopting a single-case study design, the research involved the participation of 35 pre-service teachers. The participants were tasked with utilizing generative AI tools to create multiple-choice questions and evaluate the generated items. Following this, a four-hour training session on item writing was provided to the participants. Post-training, they were asked to reassess the AI-generated products. The final phase involved collecting their reflective thoughts on this experience in writing. The qualitative data gathered were subjected to thematic analysis. A comparative examination of the participants' evaluations indicated a shift towards more detailed assessments that adhered more closely to measurement and evaluation standards. Reflective insights highlighted their positive perceptions of generative AI.
ISSN - EISSN-2651-5369
LA  - English
PT  - Journal Articles
PT  - Reports - Research

OWN - ERIC
TI  - Scalable and Equitable Math Problem Solving Strategy Prediction in Big Educational Data
AU  - Shakya, Anup
AU  - Rus, Vasile
AU  - Venugopal, Deepak
OT  - Equal Education
OT  - Mathematics Education
OT  - Word Problems (Mathematics)
OT  - Problem Solving
OT  - Prediction
OT  - Intelligent Tutoring Systems
OT  - Artificial Intelligence
OT  - Accuracy
OT  - Mastery Learning
OT  - Middle School Students
JT  - International Educational Data Mining Society
SO  - Paper presented at the International Conference on Educational Data Mining (EDM) (16th, Bengaluru, India, Jul 11-14, 2023)
OID - ED630876
DP  - 2023
LID - http://eric.ed.gov/?id=ED630876
AB  - Understanding a student's problem-solving strategy can have a significant impact on effective math learning using Intelligent Tutoring Systems (ITSs) and Adaptive Instructional Systems (AISs). For instance, the ITS/AIS can better personalize itself to correct specific misconceptions that are indicated by incorrect strategies, specific problems can be designed to improve strategies and frustration can be minimized by adapting to a student's natural way of thinking rather than trying to fit a standard strategy for all. While it may be possible for human experts to identify strategies manually in classroom settings with sufficient student interaction, it is not possible to scale this up to big data. Therefore, we leverage advances in Machine Learning and AI methods to perform scalable strategy prediction that is also fair to students at all skill levels. Specifically, we develop an embedding called MVec where we learn a representation based on the mastery of students. We then cluster these embeddings with a non-parametric clustering method where we progressively learn clusters such that we group together instances that have approximately symmetrical strategies. The strategy prediction model is trained on instances sampled from these clusters. This ensures that we train the model over diverse strategies and also that strategies from a particular group do not bias the DNN model, thus allowing it to optimize its parameters over all groups. Using real world large-scale student interaction datasets from MATHia, we implement our approach using transformers and Node2Vec for learning the mastery embeddings and LSTMs for predicting strategies. We show that our approach can scale up to achieve high accuracy by training on a small sample of a large dataset and also has predictive equality, i.e., it can predict strategies equally well for learners at diverse skill levels. [For the complete proceedings, see ED630829.]
GR  - 2008812
GR  - 1934745
PT  - Speeches/Meeting Papers
PT  - Reports - Research

OWN - ERIC
TI  - Data-Related Ethics Issues in Technologies for Informal Professional Learning
AU  - Pammer-Schindler, Viktoria
AU  - Rosé, Carolyn
OT  - Data
OT  - Ethics
OT  - Informal Education
OT  - Professional Development
OT  - Data Collection
OT  - Natural Language Processing
OT  - Design
OT  - Employees
OT  - Situated Learning
OT  - Artificial Intelligence
JT  - International Journal of Artificial Intelligence in Education
SO  - v32 n3 p609-635 Sep 2022
AID - http://dx.doi.org/10.1007/s40593-021-00259-x
OID - EJ1346943
VI  - 32
IP  - 3
PG  - 609-635
DP  - Sep 2022
LID - http://eric.ed.gov/?id=EJ1346943
AB  - Professional and lifelong learning are a necessity for workers. This is true both for re-skilling from disappearing jobs, as well as for staying current within a professional domain. AI-enabled scaffolding and just-in-time and situated learning in the workplace offer a new frontier for future impact of AIED. The hallmark of this community's work has been i) data-driven design of learning technology and ii) machine-learning enabled personalized interventions. In both cases, data are the foundation of AIED research and data-related ethics are thus central to AIED research. In this paper we formulate a vision how AIED research could address data-related ethics issues in informal and situated professional learning. The foundation of our vision is a secondary analysis of five research cases that offer insights related to data-driven adaptive technologies for informal professional learning. We describe the encountered data-related ethics issues. In our interpretation, we have developed three themes: Firstly, in informal and situated professional learning, relevant data about professional learning -- to be used as a basis for learning analytics and reflection or as a basis for adaptive systems - is not only about learners. Instead, due to the situatedness of learning, relevant data is also about others (colleagues, customers, clients) and other objects from the learner's context. Such data may be private, proprietary, or both. Secondly, manual tracking comes with high learner control over data. Thirdly, learning is not necessarily a shared goal in informal professional learning settings. From an ethics perspective, this is particularly problematic as much data that would be relevant for use within learning technologies hasn't been collected for the purposes of learning. These three themes translate into challenges for AIED research that need to be addressed in order to successfully investigate and develop AIED technology for informal and situated professional learning. As an outlook of this paper, we connect these challenges to ongoing research directions within AIED -- natural language processing, socio-technical design, and scenario-based data collection - that might be leveraged and aimed towards addressing data-related ethics challenges.
ISSN - ISSN-1560-4292
ISSN - EISSN-1560-4306
GR  - 1917955
GR  - 1822831
LA  - English
PT  - Journal Articles
PT  - Reports - Research

OWN - ERIC
TI  - AI-Powered Pedagogy and Curriculum Design: Practical Insights for Educators
AU  - Geoff Baker, Editor
AU  - Lucy Caton, Editor
OT  - Artificial Intelligence
OT  - Technology Uses in Education
OT  - Curriculum Design
OT  - Technology Integration
OT  - Educational Practices
OT  - Teaching Methods
OT  - Best Practices
OT  - Academic Standards
OT  - Alignment (Education)
OT  - Foreign Countries
OT  - Teacher Empowerment
OT  - Student Participation
OT  - Ethics
OT  - Social Justice
JT  - Routledge, Taylor & Francis Group
AID - https://www.routledge.com/AI-Powered-Pedagogy-and-Curriculum-Design-Practical-Insights-for-Educators/Baker-Caton/p/book/9781032898506
OID - ED676976
DP  - 2025
LID - http://eric.ed.gov/?id=ED676976
AB  - "AI-Powered Pedagogy and Curriculum Design" offers practical insights and guidance on the effective integration of AI tools into teaching practices and curriculum design. While numerous claims exist as to the validity and authenticity of the applications of AI in schools, too little attention has been paid to empirical research conducted with and by teachers in real-world classrooms. This book synthesises diverse viewpoints from teacher educators across disciplines and levels toward a comprehensive, context-specific understanding of the challenges and best practices for responsibly leveraging Generative AI to enhance outcomes in classrooms. Contributors further shed light on how Generative AI can align with standards, assessment practices, and teacher training programs in different settings. Firsthand classroom experiences and experimental approaches of educators in the United Kingdom and Europe will provide current and aspiring teachers with insights into the intersection between AI and teacher empowerment, student participation, ethical implications, and socially just approaches.
ISBN - 978-1-03-289474-4
PT  - Books
PT  - Collected Works - General

OWN - ERIC
TI  - Introduction: Pedagogical Crossroads: Higher Education in the Age of Generative AI
AU  - Marc Watkins
AU  - Stephen Monroe
OT  - Higher Education
OT  - Technology Uses in Education
OT  - Artificial Intelligence
OT  - Accountability
OT  - Ethics
OT  - Educational Benefits
OT  - Integrity
OT  - Computer Attitudes
JT  - Thresholds in Education
SO  - v48 n1 p1-6 2025
OID - EJ1468034
VI  - 48
IP  - 1
PG  - 1-6
DP  - 2025
LID - http://eric.ed.gov/?id=EJ1468034
AB  - We begin our introduction by acknowledging the valid anxieties of faculty who face rapid technological change brought on by Generative AI (GenAI) tools without adequate institutional support or training. While some scholars advocate for GenAI resistance and others for wholesale adoption, the voices included within this volume argue for a balanced, pragmatic approach that emphasizes transparency, ethical usage, and thoughtful engagement with these powerful new tools. Despite concerns about GenAI's limitations and potential negative impacts, we recognize its remarkable capabilities and argue that higher education is uniquely positioned to critically engage with this technology through its diverse disciplinary perspectives and research methods. In seven collected essays, educators move beyond initial worries to explore creative pedagogical applications that can enhance student learning while maintaining academic integrity.
ISSN - ISSN-0196-9641
ISSN - EISSN-2381-5485
LA  - English
PT  - Journal Articles
PT  - Reports - Descriptive

OWN - ERIC
TI  - Implicit Bias Training: Understanding the Posttraining Experiences of Individuals within an Organization--A Phenomenological Study
AU  - Stephanie N. Van Ginkel
OT  - Bias
OT  - Training
OT  - Public Colleges
OT  - Professional Personnel
OT  - Experience
OT  - Employee Attitudes
OT  - Association Measures
JT  - ProQuest LLC
SO  - Ed.D. Dissertation, University of La Verne
AID - http://gateway.proquest.com/openurl?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&res_dat=xri:pqm&rft_dat=xri:pqdiss:30527216
OID - ED636631
DP  - 2023
LID - http://eric.ed.gov/?id=ED636631
AB  - Purpose: The purpose of this transcendental phenomenological study was to understand and systematically describe the essence of the experience of professional staff members at a public university who received implicit bias training (IBT) that includes the Implicit Association Test (IAT).Theoretical Framework. Appreciative Inquiry (AI) was used, specific to the Discovery and Dream phases. Methodology: A phenomenological design was used in this qualitative study. The researcher interviewed a purposeful, criterion-based sample of 10 participants. Moustakas's research design method (1994) using a psychological approach focused on systematic steps in analysis procedures and guidelines. To build trustworthiness in the research, four criteria were established: credibility, transferability, dependability, and confirmability (Amankwaa, 2016; Connelly, 2016; Creswell & Poth, 2018; Guba, 1981; Lincoln & Guba, 1985). Bracketing was performed to focus on describing the participant's experiences versus the researcher's interpretation (Creswell & Poth, 2018). Findings: The researcher reviewed transcripts to reveal 69 significant statements. Nine formulated meanings were constructed from the significant statements, and three themes emerged. The essence of the experience of receiving IBT that includes the IAT by the participants was described. Conclusions: The study's results support the key themes of IBT's effectiveness that continues to be questioned with two themes: the ineffectiveness of IBT and the lack of changes in behavior, attitude, and beliefs after taking IBT. Another result supports the key theme of the need to reevaluate and reassess IBT with one theme: the need for and development of a successful IBT. Recommendations: Future research could involve a larger sample size and/or participants from different divisions or the entirety of the university. Demographical data could be collected and analyzed for relational findings between the participants' experience and demographics. Physical, mental, and emotional states, such as stress and anxiety, could be measured and analyzed in relation to taking the training with pretests and posttests. Research could be conducted using a shorter timeframe of when the participant took IBT for improved experience recall, or it could be conducted while the participant is taking IBT for immediate feedback. Further research could use the entire AI model to include the Design and Destiny phases and differing methodologies. [The dissertation citations contained here are published with the permission of ProQuest LLC. Further reproduction is prohibited without permission. Copies of dissertations may be obtained by Telephone (800) 1-800-521-0600. Web page: http://www.proquest.com/en-US/products/dissertations/individuals.shtml.]
ISBN - 979-8-3797-8301-3
PT  - Dissertations/Theses - Doctoral Dissertations

OWN - ERIC
TI  - Enhancing Competence for a Sustainable Future: Integrating Artificial Intelligence-Supported Educational Technologies in Pre-Service Teacher Training for Sustainable Development
AU  - Fatih Kayaalp
AU  - Mehmet Durnali
AU  - Bayram Gökbulut
OT  - Artificial Intelligence
OT  - Sustainable Development
OT  - Educational Technology
OT  - Technology Uses in Education
OT  - Preservice Teacher Education
OT  - Preservice Teachers
OT  - Student Attitudes
OT  - Knowledge Level
OT  - Productivity
OT  - Innovation
OT  - Ethics
JT  - European Journal of Education
SO  - v60 n1 e12865 2025
AID - http://dx.doi.org/10.1111/ejed.12865
OID - EJ1461307
VI  - 60
IP  - 1
DP  - e12865 2025
LID - http://eric.ed.gov/?id=EJ1461307
AB  - With the mounting urgency to achieve a sustainable future, it is of paramount importance to provide pre-service teachers with a robust understanding of de facto. The present study investigated the potential of ChatGPT-supported educational technologies to enhance the understanding of sustainable development among 20 pre-service teachers at a university during the 2023-2024 academic year. Over a period of 14 weeks of intervention, participants employed ChatGPT and Web 2.0 tools (Pixton) to create digital comic stories focused on sustainable development goals. The study employed an explanatory sequential mixed-method design, utilising evaluation forms, semi-structured interviews, inferential statistics and content analysis. The results revealed significant improvements in sustainability perspectives, awareness and knowledge, despite concerns about productivity, originality and ethical issues.
ISSN - ISSN-0141-8211
ISSN - EISSN-1465-3435
LA  - English
PT  - Journal Articles
PT  - Reports - Research

OWN - ERIC
TI  - Promoting the Culture of Academic and Research Integrity in a Higher Education Environment in Pakistan: A Qualitative Study
AU  - Ejaz Ullah Cheema
AU  - Sarah Rehman
AU  - Rabia Altaf
AU  - Zaheer Ahmad
OT  - Higher Education
OT  - Foreign Countries
OT  - Student Attitudes
OT  - College Faculty
OT  - Teacher Attitudes
OT  - Stakeholders
OT  - Integrity
OT  - Educational Environment
OT  - Ethics
OT  - College Students
OT  - Academic Achievement
OT  - Research
JT  - Journal of Academic Ethics
SO  - v24 n1 Article 11 2026
AID - http://dx.doi.org/10.1007/s10805-025-09690-4
OID - EJ1491913
VI  - 24
IP  - 1
DP  - Article 11 2026
LID - http://eric.ed.gov/?id=EJ1491913
AB  - Given the evolution in the global educational landscape coupled with the emergence of various Artificial Intelligence tools, academic and research integrity has gained significant importance. This study aims to qualitatively explore the views of stakeholders including students and faculty members about the challenges to academic and research integrity and the possible strategies to strengthen the integrity culture in a higher education environment in Pakistan. The study used a qualitative approach by conducting a focus group discussion using pre-defined interview topics. Thematic analysis of the qualitative data led to generation of four major themes with respective subthemes. Inadequate support from the institute regarding awareness and resources, fear of failure, lack of plagiarism detection tools and quest for promotion were identified as contributing factors towards academic misconduct. Participants supported the role of continuous professional development in promoting academic integrity. Most of the participants suggested that institutes should take the responsibility of organizing awareness sessions about plagiarism and other forms of dishonesty. The findings of this study suggests that establishment of a culture of academic integrity and ethical research is challenging and requires a sustained effort to raise awareness and transform the attitudes and behaviors of students and researchers.
ISSN - ISSN-1570-1727
ISSN - EISSN-1572-8544
LA  - English
PT  - Journal Articles
PT  - Reports - Research

OWN - ERIC
TI  - ChatGPT and Imaginaries of the Future of Education: Insights of Finnish Teacher Educators
AU  - Henriikka Vartiainen
AU  - Teemu Valtonen
AU  - Juho Kahila
AU  - Matti Tedre
OT  - Foreign Countries
OT  - Artificial Intelligence
OT  - Computer Software
OT  - Technology Uses in Education
OT  - Teacher Education Programs
OT  - Teacher Educators
OT  - Teacher Attitudes
OT  - Futures (of Society)
OT  - Educational Trends
OT  - Personal Autonomy
OT  - Metacognition
OT  - Teacher Workshops
OT  - Teacher Collaboration
OT  - Technological Literacy
OT  - Pedagogical Content Knowledge
OT  - Educational Policy
OT  - Formative Evaluation
OT  - Teaching Methods
OT  - Ethics
OT  - Professional Autonomy
JT  - Information and Learning Sciences
SO  - v126 n1-2 p75-90 2025
AID - http://dx.doi.org/10.1108/ILS-10-2023-0146
OID - EJ1464546
VI  - 126
PG  - 75-90
DP  - 2025
LID - http://eric.ed.gov/?id=EJ1464546
AB  - Purpose: In 2022 generative AI took the Internet world by storm. Free access to tools that can generate text and images that pass for human creations triggered fiery debates about the potential uses and misuses of generative AI in education. There has risen a need to check the popular utopian and dystopian narratives about AI against the diversity of hopes, concerns and future imaginaries that educators themselves associate with generative AI. The purpose of this study is to investigate the perspectives of Finnish teacher educators on the use of AI in education. Design/methodology/approach: This article reports findings from a hands-on workshop in teacher training, where participants learned about how generative AI works, collaboratively explored generative AI and then reflected on its potential and challenges. Findings: The results reveal nuanced, calm and thoughtful imaginaries rooted in deep understanding of educational policy, evaluation and the sociocultural context of education. The results cover teachers' views on the impact of AI on learners' agency, metacognition, self-regulation and more. Originality/value: This article offers a unique exploration into the perceptions and imaginaries of educators regarding generative AI in specific (instead of "monolithic AI"), moving beyond dystopian views and instead focusing on the potential of AI to align with existing pedagogical practices. The educators contrasted the common techno-deterministic narratives and perceived AI as an avenue to support formative assessment practices and development of metacognition, self-regulation, responsibility and well-being. The novel insights also include the need for AI education that critically incorporates social and ethical viewpoints and fosters visions for a future with culturally, socially and environmentally sustainable AI.
ISSN - ISSN-2398-5348
ISSN - EISSN-2398-5356
LA  - English
PT  - Journal Articles
PT  - Reports - Research

OWN - ERIC
TI  - Thematic Synthesis and Future Outlook in Digital Entrepreneurial Education
AU  - Finnah Fourqoniah
AU  - Muhammad Fikry Aransyah
AU  - Lilia Pasca Riani
OT  - Physical Environment
OT  - Simulated Environment
OT  - Synthesis
OT  - Information Technology
OT  - Computer Simulation
OT  - Artificial Intelligence
OT  - Entrepreneurship
OT  - Educational Research
OT  - Experiential Learning
OT  - Active Learning
OT  - Student Projects
OT  - Gamification
OT  - Sustainability
OT  - Global Approach
OT  - Ethics
OT  - Social Influences
OT  - Educational Trends
OT  - Foreign Countries
JT  - Electronic Journal of e-Learning
SO  - v23 n3 p30-44 2025
OID - EJ1477073
VI  - 23
IP  - 3
PG  - 30-44
DP  - 2025
LID - http://eric.ed.gov/?id=EJ1477073
AB  - The rapidly evolving field of digital entrepreneurial education has been significantly shaped by advancements in technologies such as augmented reality (AR), virtual reality (VR), and artificial intelligence (AI). While these technologies have opened new possibilities for entrepreneurial learning, much of the existing research is fragmented, focusing on isolated tools or specific interventions. This piecemeal approach complicates efforts to identify overarching trends, theoretical frameworks, and practical applications relevant to educators, policymakers, and researchers. To address these challenges, this study employs a Bibliometric-Systematic Literature Review (B-SLR) methodology, combining quantitative bibliometric analysis with qualitative synthesis to offer a comprehensive and balanced perspective on the field. We reviewed 261 articles published between 2005 and 2024, capturing diverse geographical regions, subject areas, and publication outlets. This approach enabled us to identify prevalent research themes, uncover emerging methodologies, and highlight areas that warrant deeper investigation. Our analysis revealed four main clusters: (1) Technology-Enhanced Entrepreneurship Education, examining how AR, VR, AI, and digital platforms foster engagement and skill-building; (2) Experiential and Project-Based Learning Approaches, highlighting gamification, simulations, and collaborative projects that stimulate practical competencies and adaptability; (3) Entrepreneurial Competencies, Mindset, and Social Dimensions, exploring cultural, generational, and gender-related factors that shape learner readiness and intentions; and (4) Future-Oriented and Transformative Approaches, emphasizing sustainability, global collaborations, and ethical considerations that guide the long-term evolution of entrepreneurial learning. The findings indicate that technological tools alone do not guarantee enhanced entrepreneurial outcomes. Instead, successful digital entrepreneurial education relies on cultural relevance, supportive policies, comprehensive educator training, and inclusive pedagogical designs. The study proposes an integrative framework that synthesizes technological, experiential, socio-cultural, and forward-looking strategies, offering actionable insights for improving educational practices and advancing theoretical understanding in the field. This research highlights critical areas for future exploration, including the development of learner-centred curricula, investments in digital infrastructure, and the promotion of international collaborations. By addressing these gaps, stakeholders can establish adaptable, inclusive, and ethically grounded ecosystems that equip learners with the skills and mindset needed to navigate the complexities of entrepreneurship in an increasingly dynamic global environment.
ISSN - EISSN-1479-4403
LA  - English
PT  - Journal Articles
PT  - Reports - Research

OWN - ERIC
TI  - Deep Learning Imputation for Asymmetric and Incomplete Likert-Type Items
AU  - Zachary K. Collier
AU  - Minji Kong
AU  - Olushola Soyoye
AU  - Kamal Chawla
AU  - Ann M. Aviles
AU  - Yasser Payne
OT  - Likert Scales
OT  - Test Items
OT  - Item Analysis
OT  - Evaluation Methods
OT  - Regression (Statistics)
OT  - Research Problems
OT  - Maximum Likelihood Statistics
OT  - Artificial Intelligence
JT  - Journal of Educational and Behavioral Statistics
SO  - v49 n2 p241-267 2024
AID - http://dx.doi.org/10.3102/10769986231176014
OID - EJ1415930
VI  - 49
IP  - 2
PG  - 241-267
DP  - 2024
LID - http://eric.ed.gov/?id=EJ1415930
AB  - Asymmetric Likert-type items in research studies can present several challenges in data analysis, particularly concerning missing data. These items are often characterized by a skewed scaling, where either there is no neutral response option or an unequal number of possible positive and negative responses. The use of conventional techniques, such as discriminant analysis or logistic regression imputation, for handling missing data in asymmetric items may result in significant bias. It is also recommended to exercise caution when employing alternative strategies, such as listwise deletion or mean imputation, because these methods rely on assumptions that are often unrealistic in surveys and rating scales. This article explores the potential of implementing a deep learning-based imputation method. Additionally, we provide access to deep learning-based imputation to a broader group of researchers without requiring advanced machine learning training. We apply the methodology to the Wilmington Street Participatory Action Research Health Project.
ISSN - ISSN-1076-9986
ISSN - EISSN-1935-1054
LA  - English
PT  - Journal Articles
PT  - Reports - Evaluative

OWN - ERIC
TI  - AI Literacy, Self-Efficacy, and Self-Competence among College Students: Variances and Interrelationships among Variables
AU  - John Mark R. Asio
OT  - Artificial Intelligence
OT  - Computer Software
OT  - Technological Literacy
OT  - Self Esteem
OT  - Self Concept
OT  - College Students
OT  - Student Attitudes
OT  - Correlation
OT  - Self Efficacy
OT  - Self Evaluation (Individuals)
OT  - Gender Differences
OT  - Institutional Characteristics
OT  - Student Characteristics
OT  - Technology Uses in Education
OT  - Computer Science Education
OT  - School Policy
OT  - Ethics
OT  - Foreign Countries
JT  - Malaysian Online Journal of Educational Sciences
SO  - v12 n3 p44-60 2024
OID - EJ1457242
VI  - 12
IP  - 3
PG  - 44-60
DP  - 2024
LID - http://eric.ed.gov/?id=EJ1457242
AB  - Understanding and securely using AI systems and tools requires AI literacy. In contrast, AI self-efficacy is a person's confidence in completing an AI task. Also, AI self-competence is the ability to explain how AI technologies are used at work and how they affect society. This study examines college students' AI literacy, self-efficacy, and self-competence. Using a descriptive-correlational approach, the proponent assessed respondents' AI literacy, self-efficacy, and self-competence. The study also examined variations and connections between factors. The study participants were 1000 college students selected by purposive sampling. Before data collection, the proponent employed a modified instrument that was validated. Data was descriptively and inferentially analyzed using SPSS 23. Results suggest most pupils were "somewhat literate" in AI. They regarded themselves as "somewhat self-efficient" but "self-competent" in AI. The inferential analysis showed substantial differences in AI literacy by college, year level, and birth sex. Self-efficacy varied by college, year, age, and birth sex. The study found college and year-level differences in self-competence. Demographic traits and study variables were associated to some extent. According to the study's findings, the proponent recommended AI training programs, skill development for students and teachers, and institution-wide policy development and implementation to maximize AI's use in learning.
ISSN - EISSN-2289-3024
LA  - English
PT  - Journal Articles
PT  - Reports - Research

OWN - ERIC
TI  - Leveraging VR/AR/MR/XR Technologies to Improve Cybersecurity Education, Training, and Operations
AU  - Paul Wagner
AU  - Dalal Alharthi
OT  - Artificial Intelligence
OT  - Computer Simulation
OT  - Information Technology
OT  - Computer Security
OT  - Computer Science Education
OT  - Technology Uses in Education
OT  - Distance Education
OT  - Technology Integration
OT  - Barriers
OT  - Influence of Technology
OT  - Labor Force Development
OT  - Career Development
JT  - Journal of Cybersecurity Education, Research and Practice
SO  - v2024 n1 Article 7 2024
OID - EJ1430168
VI  - 2024
IP  - 1
DP  - Article 2024
LID - http://eric.ed.gov/?id=EJ1430168
AB  - The United States faces persistent threats conducting malicious cyber campaigns that threaten critical infrastructure, companies and their intellectual property, and the privacy of its citizens. Additionally, there are millions of unfilled cybersecurity positions, and the cybersecurity skills gap continues to widen. Most companies believe that this problem has not improved and nearly 44% believe it has gotten worse over the past 10 years. Threat actors are continuing to evolve their tactics, techniques, and procedures for conducting attacks on public and private targets. Education institutions and companies must adopt emerging technologies to develop security professionals and to increase cybersecurity awareness holistically. Leveraging Virtual/Augmented/Mixed/Extended Reality technologies for education, training, and awareness can augment traditional learning methodologies and improve the nation's cybersecurity posture. This paper reviews previous research to identify how distance and remote education are conducted generally, and how Virtual/Augmented/Extended/Mixed reality technologies are used to conduct cybersecurity awareness training, cybersecurity training, and conduct operations. Finally, barriers to adopting these technologies will be discussed. Understanding how these technologies can be developed and implemented provides one potential way of overcoming the cybersecurity workforce gap and increasing the competencies and capabilities of cybersecurity professionals.
ISSN - EISSN-2472-2707
LA  - English
PT  - Journal Articles
PT  - Information Analyses

OWN - ERIC
TI  - Redefining Engineering Education: The Transformative Role of Generative AI Technologies
AU  - Amjad Almusaed
AU  - Marisol Rico Cortez
AU  - Asaad Almssad
OT  - Engineering Education
OT  - Artificial Intelligence
OT  - Computer Software
OT  - Educational Change
OT  - Instructional Innovation
OT  - Active Learning
OT  - Standards
OT  - Outcomes of Education
OT  - Cooperative Learning
OT  - Ethics
OT  - Barriers
OT  - Interdisciplinary Approach
OT  - Technology Integration
JT  - International Society for Technology, Education, and Science
SO  - Paper presented at the International Conference on Humanities, Social and Education Sciences (iHSES) (San Francisco, CA, Apr 16-19, 2024)
OID - ED673061
DP  - 2024
LID - http://eric.ed.gov/?id=ED673061
AB  - AI is a rapidly advancing technology, especially in education. "Generative AI" is particularly notable for revolutionizing how we teach and learn, prompting a reevaluation of teacher training. Engineering education is at the forefront of pedagogical innovation, enhancing learning tools, and fostering a new educational mindset. This transition makes problem-solving more straightforward for teachers and encourages the revision of teaching methods, thus enhancing student-teacher relationships. Teaching space with AI integration transforms students into active learners, deeply involved in shaping their educational paths. This paper will explore the influence of generative AI on engineering education through a literature review, demonstrating how it contributes to more flexible, advanced, and engaging learning spaces. It will draw attention to the urgent need for educators to embrace and actively participate in these emerging dynamics. Specifically, the paper will focus on CDIO Standards 2 and 8, evaluating generative AI's impact on learning outcomes and promoting active learning. It aims to reveal how fertile AI can synchronize educational objectives with hands-on, collaborative student experiences. [For the complete proceedings, see ED672800.]
PT  - Speeches/Meeting Papers
PT  - Reports - Research

OWN - ERIC
TI  - The Role of Perceived Utility and Ethical Concerns in the Adoption of AI-Based Data Analysis Tools: A Multi-Group Structural Equation Model Analysis among Academic Researchers
AU  - Xintong Zhang
AU  - Jiangwei Hu
AU  - Yunqian Zhou
OT  - Usability
OT  - Ethics
OT  - Artificial Intelligence
OT  - Technology Uses in Education
OT  - Learning Analytics
OT  - Educational Research
OT  - Educational Researchers
OT  - Structural Equation Models
OT  - Social Influences
OT  - Technology Integration
OT  - Barriers
OT  - Accountability
OT  - Training
OT  - Productivity
OT  - Foreign Countries
JT  - Education and Information Technologies
SO  - v30 n13 p18819-18851 2025
AID - http://dx.doi.org/10.1007/s10639-025-13535-3
OID - EJ1480914
VI  - 30
IP  - 13
PG  - 18819-18851
DP  - 2025
LID - http://eric.ed.gov/?id=EJ1480914
AB  - This study explores the role of perceived utility, social influence, and ethical concerns in the adoption of AI-based data analysis tools among academic researchers in China, focusing on differences between public and private universities. The research aims to identify key drivers and barriers influencing the integration of AI technology in academic settings. A quantitative approach was employed, using a multi-group structural equation model (SEM) analysis to assess data collected from 750 academic researchers across various disciplines (N[subscript pvt] = 402; N[subscript pub] = 348). The findings reveal that both perceived utility and social influence significantly influence the adoption of AI tools. Higher perceived utility and stronger social influence lead to greater adoption. However, ethical concerns were found to moderate these relationships, particularly in public universities, where researchers with high ethical concerns perceived greater risks, thereby reducing their likelihood of adoption. In contrast, private university researchers showed a higher tolerance for perceived risks when utility and social influence were evident. The study's implications suggest that to promote AI adoption, institutions must address ethical concerns and perceived risks, particularly in public universities, by enhancing transparency, providing ethical guidelines, and offering comprehensive training. These efforts can lead to more effective integration of AI technologies, ultimately enhancing research productivity and innovation across diverse academic environments.
ISSN - ISSN-1360-2357
ISSN - EISSN-1573-7608
LA  - English
PT  - Journal Articles
PT  - Reports - Research
PT  - Tests/Questionnaires

OWN - ERIC
TI  - The Impact of Generative AI Tools on Researchers and Research: Implications for Academia in Higher Education
AU  - Abdulrahman M. Al-Zahrani
OT  - Artificial Intelligence
OT  - Technology Uses in Education
OT  - Foreign Countries
OT  - College Students
OT  - Student Attitudes
OT  - Student Research
OT  - Opportunities
OT  - Positive Attitudes
OT  - Student Experience
OT  - Futures (of Society)
OT  - Ethics
OT  - Self Efficacy
OT  - Student Characteristics
OT  - Age Differences
OT  - Research Methodology
OT  - Efficiency
JT  - Innovations in Education and Teaching International
SO  - v61 n5 p1029-1043 2024
AID - http://dx.doi.org/10.1080/14703297.2023.2271445
OID - EJ1438892
VI  - 61
IP  - 5
PG  - 1029-1043
DP  - 2024
LID - http://eric.ed.gov/?id=EJ1438892
AB  - This study explores the impact of Generative AI tools on researchers and research in the context of higher education in Saudi Arabia. An online survey questionnaire was used to collect data on higher education students' perspectives (N = 505). The findings indicate that participants hold positive attitudes and possess a high level of awareness regarding GenAI in research. They recognise the potential of these tools to revolutionise academic research. Participants report highly beneficial experiences using GenAI tools to expand project scope and improve efficiency. Additionally, participants expressed optimism about the future role of GenAI tools, expecting them to become more prevalent and transform the research landscape. However, participants emphasised the importance of adequate training, support, and guidance in using GenAI tools. Ethical considerations emerged as a significant concern, highlighting the participants' commitment to responsible research practices and the need for transparency and addressing potential biases associated with these tools.
ISSN - ISSN-1470-3297
ISSN - EISSN-1470-3300
LA  - English
PT  - Journal Articles
PT  - Reports - Research
PT  - Tests/Questionnaires

OWN - ERIC
TI  - A Mobile-Based System for Preventing Online Abuse and Cyberbullying
AU  - Semiu Salawu
AU  - Jo Lumsden
AU  - Yulan He
OT  - Computer Mediated Communication
OT  - Bullying
OT  - Computer Software
OT  - Computational Linguistics
OT  - Social Media
OT  - Antisocial Behavior
OT  - Algorithms
OT  - Artificial Intelligence
OT  - Identification
OT  - Taxonomy
OT  - Ethics
OT  - Prevention
JT  - International Journal of Bullying Prevention
SO  - v4 n1 p66-88 2022
AID - http://dx.doi.org/10.1007/s42380-021-00115-5
OID - EJ1420456
VI  - 4
IP  - 1
PG  - 66-88
DP  - 2022
LID - http://eric.ed.gov/?id=EJ1420456
AB  - A negative consequence of the proliferation of social media is the increase in online abuse. Bullying, once restricted to the playground, has found a new home on social media. Online social networks on their part have intensified efforts to tackle online abuse, but unfortunately, such is the scale of the problem that many young people are still regularly subjected to a wide range of abuse online. Research in automated detection of online abuse has increased considerably in recent times. However, existing studies on online abuse detection typically focus on developing newer algorithms to improve predictions, and little research is done on developing impactful tools that leverage these algorithms to tackle online abuse. In this paper, we present BullStop, a mobile application that can use different machine learning models to detect cyberbullying. A new cyberbullying dataset containing 62,587 tweets annotated using a taxonomy of different cyberbullying types was created to facilitate the classifier's training. BullStop was developed using a participatory and user-centred design approach involving young people, parents, educators, law enforcement and mental health professionals. Additionally, the application incorporates online training for the ML models using ground truth supplied by the user as additional training data, and in this way, it can create a personalised classifier for each user. Furthermore, on detecting online abuse, the application automatically initiates punitive actions such as deleting offensive messages and blocking cyberbullies on behalf of the user. BullStop is freely available on the Google Play Store and has been downloaded by hundreds of users.
ISSN - ISSN-2523-3653
ISSN - EISSN-2523-3661
LA  - English
PT  - Journal Articles
PT  - Reports - Descriptive

OWN - ERIC
TI  - ChatGPT in Education: A Discourse Analysis of Worries and Concerns on Social Media
AU  - Lingyao Li
AU  - Zihui Ma
AU  - Lizhou Fan
AU  - Sanggyu Lee
AU  - Huizi Yu
AU  - Libby Hemphill
OT  - Artificial Intelligence
OT  - Man Machine Systems
OT  - Natural Language Processing
OT  - Social Media
OT  - Discourse Analysis
OT  - Technology Uses in Education
OT  - Integrity
OT  - Ethics
OT  - Skill Development
OT  - Outcomes of Education
OT  - Labor Force
JT  - Education and Information Technologies
SO  - v29 n9 p10729-10762 2024
AID - http://dx.doi.org/10.1007/s10639-023-12256-9
OID - EJ1430139
VI  - 29
IP  - 9
PG  - 10729-10762
DP  - 2024
LID - http://eric.ed.gov/?id=EJ1430139
AB  - The rapid advancements in generative AI models present new opportunities in the education sector. However, it is imperative to acknowledge and address the potential risks and concerns that may arise with their use. We analyzed Twitter data to identify critical concerns related to the use of ChatGPT in education. We employed BERT-based topic modeling to conduct a discourse analysis and social network analysis to identify influential users in the conversation. While Twitter users generally expressed a positive attitude toward using ChatGPT, their concerns converged into five categories: academic integrity, impact on learning outcomes and skill development, limitation of capabilities, policy and social concerns, and workforce challenges. We also found that users from the tech, education, and media fields were often implicated in the conversation, while education and tech individual users led the discussion of concerns. Based on these findings, the study provides several implications for policymakers, tech companies and individuals, educators, and media agencies. In summary, our study underscores the importance of responsible and ethical use of AI in education and highlights the need for collaboration among stakeholders to regulate AI policy.
ISSN - ISSN-1360-2357
ISSN - EISSN-1573-7608
GR  - 1928434
LA  - English
PT  - Journal Articles
PT  - Reports - Research

OWN - ERIC
TI  - Advancing Healthcare Practice and Education via Data Sharing: Demonstrating the Utility of Open Data by Training an Artificial Intelligence Model to Assess Cardiopulmonary Resuscitation Skills
AU  - Merryn D. Constable
AU  - Francis Xiatian Zhang
AU  - Tony Conner
AU  - Daniel Monk
AU  - Jason Rajsic
AU  - Claire Ford
AU  - Laura Jillian Park
AU  - Alan Platt
AU  - Debra Porteous
AU  - Lawrence Grierson
AU  - Hubert P. H. Shum
OT  - Data Use
OT  - Artificial Intelligence
OT  - First Aid
OT  - Ethics
OT  - Legal Problems
OT  - Allied Health Occupations Education
OT  - Video Technology
OT  - Foreign Countries
JT  - Advances in Health Sciences Education
SO  - v30 n1 p15-35 2025
AID - http://dx.doi.org/10.1007/s10459-024-10369-5
OID - EJ1484794
VI  - 30
IP  - 1
PG  - 15-35
DP  - 2025
LID - http://eric.ed.gov/?id=EJ1484794
AB  - Health professional education stands to gain substantially from collective efforts toward building video databases of skill performances in both real and simulated settings. An accessible resource of videos that demonstrate an array of performances -- both good and bad -- provides an opportunity for interdisciplinary research collaborations that can advance our understanding of movement that reflects technical expertise, support educational tool development, and facilitate assessment practices. In this paper we raise important ethical and legal considerations when building and sharing health professions education data. Collective data sharing may produce new knowledge and tools to support healthcare professional education. We demonstrate the utility of a data-sharing culture by providing and leveraging a database of cardio-pulmonary resuscitation (CPR) performances that vary in quality. The CPR skills performance database (collected for the purpose of this research, hosted at UK Data Service's ReShare Repository) contains videos from 40 participants recorded from 6 different angles, allowing for 3D reconstruction for movement analysis. The video footage is accompanied by quality ratings from 2 experts, participants' self-reported confidence and frequency of performing CPR, and the demographics of the participants. From this data, we present an Automatic Clinical Assessment tool for Basic Life Support that uses pose estimation to determine the spatial location of the participant's movements during CPR and a deep learning network that assesses the performance quality.
ISSN - ISSN-1382-4996
ISSN - EISSN-1573-1677
LA  - English
PT  - Journal Articles
PT  - Reports - Research

OWN - ERIC
TI  - Growing Interest in AI in Education: Systematic Literature Review
AU  - Danijela Blanuša Trošelj
AU  - Sven Maricic
AU  - Antonia Curic
OT  - Artificial Intelligence
OT  - Technology Uses in Education
OT  - Educational Research
OT  - Definitions
OT  - Ethics
OT  - Man Machine Systems
OT  - Natural Language Processing
OT  - Elementary Secondary Education
OT  - Higher Education
OT  - Professional Development
JT  - International Society for Technology, Education, and Science
SO  - Paper presented at the International Conference on Research in Education and Science (ICRES) (Antalya, Turkey, Apr 27-30, 2024)
OID - ED673118
DP  - 2024
LID - http://eric.ed.gov/?id=ED673118
AB  - Although AI in education has been written about for decades, recent years have seen exponential growth in this area. The aim of this paper was to determine the distribution of content and areas of education in which AI is researched. The article provides an overview of the newest research in the field of AI in education, available in open access journals. In the theoretical part, an overview of the historical context is given. Also, key definitions and approaches for understanding the topic are listed. In the methodological part, Systematic Literature Review was used, with AI and education as search words. Publish research studies between January 2023 and December 2023. The research found that there is a difference in the amount of AI research at certain degrees and fields of education. The application of AI is particularly explored in higher education. As specific areas of research, the ethical issues of applying AI in education and the possibilities of applying AI in the learning and teaching process appear. [For the complete proceedings, see ED672804.]
PT  - Speeches/Meeting Papers
PT  - Information Analyses

OWN - ERIC
TI  - Leveraging ChatGPT for Enhancing Critical Thinking Skills
AU  - Ying Guo
AU  - Daniel Lee
OT  - Artificial Intelligence
OT  - Computer Software
OT  - Synchronous Communication
OT  - Critical Thinking
OT  - Thinking Skills
OT  - Skill Development
OT  - Public Colleges
OT  - Open Education
OT  - Hispanic American Students
OT  - Minority Serving Institutions
OT  - Higher Education
OT  - Introductory Courses
OT  - Chemistry
OT  - College Science
OT  - Science Education
OT  - Technology Uses in Education
OT  - Technological Literacy
OT  - Computer Assisted Instruction
OT  - Student Centered Learning
JT  - Journal of Chemical Education
SO  - v100 n12 p4876-4883 2023
AID - http://dx.doi.org/10.1021/acs.jchemed.3c00505
OID - EJ1447404
VI  - 100
IP  - 12
PG  - 4876-4883
DP  - 2023
LID - http://eric.ed.gov/?id=EJ1447404
AB  - This article presents a study conducted at Georgia Gwinnett College (GGC) to explore the use of ChatGPT, a large language model, for fostering critical thinking skills in higher education. The study implemented a ChatGPT-based activity in introductory chemistry courses, where students engaged with ChatGPT in three stages: account setup and orientation, essay creation, and output revision and validation. The results showed significant improvements in students' confidence to ask insightful questions, analyze information, and comprehend complex concepts. Students reported that ChatGPT provided diverse perspectives and challenged their current ways of thinking. They also expressed an increased utilization of ChatGPT to enhance critical thinking skills and a willingness to recommend it to others. However, challenges included low-quality student comments and difficulties in validating information sources. The study highlights the importance of comprehensive training for educators and access to reliable resources. Future research should focus on training educators in integrating ChatGPT effectively and ensuring student awareness of privacy and security considerations. In conclusion, this study provides valuable insights for leveraging AI technologies like ChatGPT to foster critical thinking skills in higher education.
ISSN - ISSN-0021-9584
ISSN - EISSN-1938-1328
LA  - English
PT  - Journal Articles
PT  - Reports - Research

OWN - ERIC
TI  - Constructing an Edu-Metaverse Ecosystem: A New and Innovative Framework
AU  - Wang, Minjuan
AU  - Yu, Haiyang
AU  - Bell, Zerla
AU  - Chu, Xiaoyan
OT  - Technology Uses in Education
OT  - Computer Simulation
OT  - Educational Environment
OT  - Best Practices
OT  - Instructional Design
OT  - Access to Computers
OT  - Computer Security
OT  - Privacy
OT  - Educational Innovation
JT  - IEEE Transactions on Learning Technologies
SO  - v15 n6 p685-696 Dec 2022
AID - http://dx.doi.org/10.1109/TLT.2022.3210828
OID - EJ1360022
VI  - 15
IP  - 6
PG  - 685-696
DP  - Dec 2022
LID - http://eric.ed.gov/?id=EJ1360022
AB  - The Metaverse is a network of 3-D virtual worlds supporting social connections among its users and enabling them to participate in activities mimicking real life. It merges physical and virtual reality and provides channels for multisensory interactions and immersions in a variety of environments (Mystakidis, 2022). The Metaverse is considered the third wave of the Internet revolution, and it is built on new and emerging technologies such as extended reality and artificial intelligence. Research on the impact of the Metaverse on education exploded in 2022. Here, we explore learning across the Metaverse and propose a new and innovative theoretical framework by reviewing literature and synthesizing best practices in designing metaverse learning environments. This ecosystem consists of four major hubs: (1) instructional design and performance technology hub; (2) knowledge hub; (3) research and technology hub; and (4) talent and training hub. Common to all four hubs are the factors in the three wheels: (1) infrastructure, business industry, and communication; (2) technology access and equity; and (3) user rights, data security, and privacy policy. We believe that this framework can help guide emerging research and development on the applications of the Metaverse in education. We also hope this article can serve as a launch pad for the special issue on the Metaverse and the Future of Education supported by the IEEE Education Society.
ISSN - EISSN-1939-1382
LA  - English
PT  - Journal Articles
PT  - Reports - Evaluative

OWN - ERIC
TI  - The Upstream Sources of Bias: Investigating Theory, Design, and Methods Shaping Adaptive Learning Systems
AU  - Shamya Chodumada Karumbaiah
OT  - Equal Education
OT  - Social Bias
OT  - Assistive Technology
OT  - Electronic Learning
OT  - Artificial Intelligence
OT  - Educational Technology
OT  - Research Methodology
OT  - Educational Research
JT  - ProQuest LLC
SO  - Ph.D. Dissertation, University of Pennsylvania
AID - http://gateway.proquest.com/openurl?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&res_dat=xri:pqm&rft_dat=xri:pqdiss:29164231
OID - ED646468
DP  - 2022
LID - http://eric.ed.gov/?id=ED646468
AB  - Adaptive systems in education need to ensure population validity to meet the needs of all students for an equitable outcome. Recent research highlights how these systems encode societal biases leading to discriminatory behaviors towards specific student subpopulations. However, the focus has mostly been on investigating bias in predictive modeling, particularly its downstream stages like model development and evaluation. My dissertation work hypothesizes that the upstream sources (i.e., theory, design, training data collection method) in the development of adaptive systems also contribute to the bias in these systems, highlighting the need for a nuanced approach to conducting fairness research. By empirically analyzing student data previously collected from various virtual learning environments, I investigate demographic disparities in three cases representative of the aspects that shape technological advancements in education: (1) non-conformance of data to a widely-accepted theoretical model of emotion, (2) differing implications of technology design on student outcomes, and (3) varying effectiveness of methodological improvements in annotated data collection. In doing so, I challenge implicit assumptions of generalizability in theory, design, and methods and provide an evidence-based commentary on future research and design practices in adaptive and artificially intelligent educational systems surrounding how we consider diversity in our investigations. [The dissertation citations contained here are published with the permission of ProQuest LLC. Further reproduction is prohibited without permission. Copies of dissertations may be obtained by Telephone (800) 1-800-521-0600. Web page: http://www.proquest.com/en-US/products/dissertations/individuals.shtml.]
ISBN - 979-8-8375-0315-3
GR  - 3456768
GR  - 1917545
GR  - 1917713
PT  - Dissertations/Theses - Doctoral Dissertations

OWN - ERIC
TI  - Examining School Principals' and Teachers' Perceptions of Using ChatGPT in Education
AU  - Yasemin Cetin
AU  - Özgür Tas
AU  - Halil Alakus
AU  - Halil Ibrahim Kaplan
OT  - Principals
OT  - Administrator Attitudes
OT  - Teacher Attitudes
OT  - Artificial Intelligence
OT  - Natural Language Processing
OT  - Technology Uses in Education
OT  - Public Schools
OT  - Elementary School Teachers
OT  - Secondary School Teachers
OT  - High School Teachers
OT  - Opportunities
OT  - Risk
OT  - Ethics
OT  - Foreign Countries
OT  - Computer Use
JT  - Educational Process: International Journal
SO  - v13 n3 p85-96 2024
OID - EJ1447510
VI  - 13
IP  - 3
PG  - 85-96
DP  - 2024
LID - http://eric.ed.gov/?id=EJ1447510
AB  - Background/purpose: ChatGPT has become one of the groundbreaking examples of artificial intelligence-based chatbots with its capacity to produce texts and engage in human-like conversations. Therefore, it has garnered the attention of people with diverse backgrounds, including educational professionals. The current study aims to investigate how school principals and teachers perceived the use of ChatGPT in education and reveal their attitudes towards using AI-based tools to facilitate the teaching-learning experience. Materials/methods: The study was designed using the qualitative case study method since it aimed to gather detailed information regarding school principals' and teachers' perceptions of ChatGPT. Data was collected from 80 teachers and school principals selected purposefully from public primary, secondary, and high schools. Data was analyzed using content analysis techniques by synthesizing codes into categories and themes. Results: The study revealed four major themes regarding school principals' and teachers' perceptions of ChatGPT: overall perceptions, perceived opportunities, perceived risks, and the effective use of ChatGPT. The participants referred to several advantages of using ChatGPT in education such as lesson planning, offering customized learning, and enabling easy and fast access to information. They were also cautious about some risks such as ethical and responsible use, the likelihood of encouraging dishonesty, free-riding, cheating, or plagiarism as well as weakening students' cognitive skills. Due to its potential to provide inaccurate information depending on the reliability of its data source, they were also doubtful that it could provide students with false guidance in its current form. The participants also made some recommendations to make better and more effective use of ChatGPT in education such as providing ongoing training for both teachers and students on recent developments, increasing the reliability of its data sources through continuous tests, and aligning its capacity with the readiness and age of students. Conclusion: The current study showed that school principals and teachers had sufficient knowledge of ChatGPT and mostly had a positive attitude towards its use in education despite some risks. Combined with the findings of prior studies, the current results suggest taking several steps to minimize the risks and offering both pre-and in-service training to teachers for more effective use.
ISSN - ISSN-2147-0901
ISSN - EISSN-2564-8020
LA  - English
PT  - Journal Articles
PT  - Reports - Research

OWN - ERIC
TI  - Educating Students about the Ethical Principles Underlying the Interpretation of Infographics
AU  - Salma Banu Nazeer Khan
AU  - Ayse Aysin Bilgin
AU  - Deborah Richards
AU  - Paul Formosa
OT  - Ethics
OT  - Visual Aids
OT  - Statistics Education
OT  - Design
OT  - Teaching Methods
OT  - Misinformation
OT  - Models
OT  - Intention
OT  - Knowledge Level
OT  - Guidelines
JT  - Teaching Statistics: An International  Journal for Teachers
SO  - v46 n2 p69-94 2024
AID - http://dx.doi.org/10.1111/test.12362
OID - EJ1420866
VI  - 46
IP  - 2
PG  - 69-94
DP  - 2024
LID - http://eric.ed.gov/?id=EJ1420866
AB  - Infographics are visual storytelling techniques used to communicate complex information. However, infographics can be misleading if they are not created ethically. When universities teach how to create infographics, they often do so without emphasizing the ethical issues underlying infographics. To address this gap, we designed a study to educate statistics and data science students about the ethics of infographics by using Rest model's three stages: awareness, orientation, and intention. Students' awareness of the ethical issues underlying infographics was captured before and after sensitizing them to five ethical principles derived from the AI4People's framework applied to a data science context. The students were then exposed to scenarios with ethical dilemmas. Their identification of the ethical principles in these scenarios was measured. The results showed a significant increase in students' awareness of the ethical issues underpinning the interpretation of infographics, suggesting that ethical training of current users and future designers would be beneficial.
ISSN - ISSN-0141-982X
ISSN - EISSN-1467-9639
LA  - English
PT  - Journal Articles
PT  - Reports - Research
PT  - Tests/Questionnaires

OWN - ERIC
TI  - Predicting Teachers' Intentions for AIGC Integration in Preschool Education: A Hybrid SEM-ANN Approach
AU  - Yuxin Zhang
OT  - Preschool Teachers
OT  - Artificial Intelligence
OT  - Technology Integration
OT  - Technology Uses in Education
OT  - Preschool Education
OT  - Intention
OT  - Predictor Variables
OT  - Teacher Attitudes
OT  - Satisfaction
OT  - Expectation
OT  - Experience
OT  - Participation
OT  - Value Judgment
OT  - Usability
OT  - Foreign Countries
JT  - Journal of Information Technology Education: Research
SO  - v24 Article 16 2025
AID - https://doi.org/10.28945/5502
OID - EJ1477690
VI  - 24
DP  - Article 16 2025
LID - http://eric.ed.gov/?id=EJ1477690
AB  - Aim/Purpose: This study investigates the key factors influencing preschool teachers' sustained use of Artificial Intelligence-Generated Content (AIGC) technology in educational settings. While prior research has extensively examined initial adoption, little attention has been given to understanding the continuous intention of preschool teachers with AIGC. To bridge this gap, this study integrates the Technology Acceptance Model (TAM), Expectation-Confirmation Model (ECM), and Flow Theory to develop a comprehensive framework that captures cognitive, affective, and experiential factors shaping continued AIGC adoption. Background: AIGC has demonstrated immense educational potential, providing personalized learning experiences, real-time feedback, and intelligent student progress tracking. However, most existing research focuses primarily on system usability and feasibility, neglecting the motivational and psychological aspects that determine continuous intention to use AIGC. Specifically, satisfaction, expectation confirmation, and flow experience have been largely overlooked as key determinants of sustained technology use. Given that preschool educators face unique pedagogical challenges, such as adapting AIGC content to young learners and maintaining engagement, understanding the drivers of long-term AIGC use is essential for optimizing its integration into preschool education. Methodology: This study employs a mixed-method approach to ensure a rigorous and comprehensive analysis. A total of 433 preschool teachers participated in the survey, and Partial Least Squares-Structural Equation Modeling (PLS-SEM) was used to test the hypothesized relationships. To complement structural modeling, Artificial Neural Network (ANN) modeling was applied to uncover non-linear relationships that traditional statistical methods might overlook. By integrating PLS-SEM and ANN, this study provides a more robust, predictive, and holistic understanding of the factors driving sustained AIGC adoption. Contribution: This study makes significant theoretical and practical contributions. Theoretically, it extends TAM and ECM by incorporating Flow Theory. Unlike prior studies focusing primarily on perceived usefulness and ease of use, this research identifies confirmation and satisfaction as the strongest predictors of continued intention to use AIGC. Practically, the findings provide valuable insights for policymakers, school administrators, and ed-tech developers, offering recommendations for designing more engaging, sustainable, and user-friendly AIGC solutions tailored for preschool education. Findings: The results indicate that satisfaction ([beta] = 0.280, p < 0.001) is the strongest predictor of continued AIGC use, followed by attitude ([beta] = 0.262, p < 0.001) and flow experience ([beta] = 0.223, p < 0.001). Expectation confirmation significantly enhances perceived usefulness ([beta] = 0.505, p < 0.001) and satisfaction ([beta] = 0.349, p < 0.001), reinforcing the importance of aligning AIGC tools with teachers' expectations. ANN analysis further highlights confirmation (95.28%) and satisfaction (82.41%) as the most influential factors, whereas perceived ease of use (22.35%) has a relatively minor impact. These findings suggest that positive user experience, engagement, and expectation fulfillment are key drivers of long-term AIGC adoption. Moreover, ANN analysis revealed complex nonlinear relationships, demonstrating that traditional statistical methods might underestimate the true impact of psychological and experiential factors on technology retention. Recommendations for Practitioners: For practitioners, this study provides several actionable recommendations. First, AIGC tools should be designed to enhance engagement and intrinsic motivation, integrating gamification elements, interactive features, and adaptive learning support to sustain user interest. Second, ongoing professional development programs should be implemented to train teachers on the pedagogical applications of AIGC, addressing any concerns related to usability or long-term feasibility. Third, AIGC platforms should incorporate customization features, allowing educators to tailor content based on their specific classroom needs and teaching styles. By addressing these factors, AIGC adoption in preschool education can be more sustainable and impactful. Recommendation for Researchers: For researchers, this study opens multiple avenues for future exploration. First, future research should adopt a longitudinal approach to examine how preschool teachers' attitudes and behaviors toward AIGC evolve over time. Second, more research is needed to explore the role of teacher personality traits and digital literacy levels in shaping AIGC adoption patterns. Third, cross-cultural studies could provide deeper insights into how different educational systems and socio-cultural contexts influence preschool teachers' responses to AIGC technologies. Furthermore, AI-driven predictive analytics should be explored to model behavioral trends and optimize AIGC implementations across diverse learning environments. Impact on Society: This study has significant implications for educational equity, teacher workload, and early childhood learning experiences. By empowering preschool teachers with AIGC, this research promotes more inclusive and accessible preschool education, reducing disparities in educational resources and opportunities. Additionally, AI-driven teaching solutions can alleviate teacher workload, enabling educators to focus on creative and interactive pedagogical strategies rather than administrative tasks. As AIGC continues to evolve, its potential to transform preschool education into a more engaging, adaptive, and learner-centered experience becomes increasingly evident. Future Research: While this study provides valuable insights into preschool teachers' sustained use of AIGC, several areas require further exploration. First, objective usage data should be incorporated into future research rather than relying solely on self-reported surveys to enhance validity. Second, longitudinal studies should examine how teachers' continuous intention to use AIGC evolves over time in response to technological advancements and policy shifts. Third, as this study focuses on preschool educators, future research should explore whether the identified factors apply to primary and secondary education teachers. Additionally, ethical concerns, AI trust, and data privacy issues should be further investigated, as they may significantly impact the long-term adoption of AIGC in educational settings.
ISSN - ISSN-1547-9714
ISSN - EISSN-1539-3585
LA  - English
PT  - Journal Articles
PT  - Reports - Research

OWN - ERIC
TI  - Building Capacity in Practice: Using AI to Study the Implementation of California's Community Schools Strategies
AU  - Andrés Fernández-Vergara
OT  - Capacity Building
OT  - Artificial Intelligence
OT  - Technology Uses in Education
OT  - Program Implementation
OT  - Community Schools
OT  - Educational Strategies
OT  - Grants
OT  - Technical Assistance
OT  - Accountability
OT  - Educational Development
OT  - Community Education
JT  - Society for Research on Educational Effectiveness
AID - https://www.sree.org/2025-conference
OID - ED677645
DP  - 2025
LID - http://eric.ed.gov/?id=ED677645
AB  - Background: California's unprecedented grant investment in the community school strategy through the California Community Schools Partnership Program (CCSPP) offers a significant opportunity for transformative, equity-centered, whole-child school reform (Maier & Niebuhr, 2021). Community schools are grounded in partnerships that schools establish with their communities, engaging families' social and cultural backgrounds as assets to develop teaching and learning suited for their students' needs (Blank, et al., 2003). The community school strategy has been proven to be effective in transforming schools, with justice and fairness as key pillars (Maier et al., 2017; Oaks et al., 2017). However, the specific processes by which schools enact such transformation remain underexplored. In 2022, at the beginning of the CCSPP grant, the State Transformational Assistance Center (STAC) released a rubric to guide and gauge the process of transforming schools into Community Schools (STAC, 2024). This rubric outlines five capacity-building strategies that integrate goals and actions that should drive improvements for community schools, describing practices that have been proven effective in meeting schools' needs (Oakes, et al., 2017). These five strategies are: (1) 'Shared Commitment, Understanding, and Priorities'; (2) 'Centering Community-based Learning'; (3) 'Collaborative Leadership'; (4) 'Sustaining Staff and Resources'; and (5) 'Strategic Community Partnerships' (STAC, 2024). These strategies are further elaborated in the "California Community School Framework" (California Department of Education, 2024). This set of strategies offers a "how" for schools to build the structural and organizational capacity for collective efficacy and action aiming at shared goals (STAC, 2024). To support schools through this transformation, the rubric outlines three growth stages for schools: visioning (e.g., communicating, designing, planning, etc.); engaging (e.g., having discussions, collecting data, creating spaces or councils, etc.); and transforming (e.g., expanding, evaluating, presenting, showcasing, etc.). Research Question: This article examines how CCSPP schools are implementing these strategies, identifying which are most commonly reported and how implementation varies across grantees. Although it is still too early to evaluate the results of the implementation of these strategies on educational outcomes, monitoring how they are put into practice offers valuable insight into how schools are implementing the CCSPP grant. To address this, this study uses the CCSPP Annual Progress Report (APR) -- a required survey-style report that all grantees submit annually. It monitors the implementation of the Community School strategy and informs the technical assistance that is provided through the STAC and the broader support system (i.e., regional centers, county offices, and districts). Designed as a reflective rather than accountability tool, the APR favors open-ended questions, which yield rich narrative data but also pose challenges for systematic analysis. Population and Methods: This study focuses on the first cohort of CCSPP grantee school sites and their first two rounds of APR (2022-23 and 2023-24), analyzing their reported implementation of the capacity-building strategies. The APR asks grantees where they position themselves in the growth rubric (visioning, engaging, or transforming) and what accomplishments they showed during the academic year (open-ended). These data are linked to grantees' original application type--whether they identified as a "new," "expanding," or "continuing" community school. To analyze the open-ended responses, this study employs a large language model (GPT-4o) to code the text and identify references to the five strategies. The validity and reliability of using AI for text annotation are evaluated using intercoder agreement and other standard indicators, following current best practices (Törnberg, 2023, 2024; Gilardi et al., 2023; Laurer, 2024). Findings: Preliminary analysis examines both the growth phase in which schools position themselves and whether they mention specific strategies in their reported accomplishments. Findings suggest that schools identifying as "continuing" community schools at the time of their grant application are more likely to report being in the transforming phase by their second year compared to new or expanding community schools. This trend is consistent across all five strategies but is particularly evident for "Sustaining Staff and Resources" and "Strategic Community Partnerships." However, when analyzing which strategies are explicitly mentioned in the accomplishments narratives, "Sustaining Staff and Resources" emerges as the least frequently cited--even among continuing schools. In contrast, "Strategic Community Partnerships" is the most commonly mentioned strategy. In addition, the "Centering Community-Based Learning" strategy appears particularly challenging for schools to operationalize. Only 10% of continuing schools report being in the transformative phase by the end of their second year and just 49% mention it on the accomplishments -- compared to 79% mentioning the other strategies. Taken together, these findings suggest that while schools across California are making progress in building partnerships, there is significant variation in their experiences with implementing strategies aimed at long-term sustainability and staff support. When looking at the open-ended responses with more detail, it provides information on how these strategies look in practice and why continuing schools seem to manage the implementation more thoroughly. For example, from the responses, it can be seen that many schools report that they have accomplished establishing strong partnerships that address community needs. These partnerships look very different and are context-specific, ranging from local businesses that provide career exploration opportunities to higher education institutions that implement mentoring or early college programs. In addition, some schools report that they have accomplished listening to teachers' voices regarding their needs and professional development opportunities, and students' and families' perspectives about the needs of the community. Although accomplishments were achieved, there are still many challenges to sustaining "community-based learning" in the center of Community Schooling. Many schools still face limited resources, scheduling conflicts, and difficulties in maintaining consistent community involvement, which hinders the possibility of bringing the community into the teaching and learning processes. Conclusions: These findings contribute to the literature on school effectiveness along two key dimensions. First, the analysis explores how community schools build the capacity to connect and engage their surrounding communities and systems, and how state-level policy--specifically, the CCSPP grant--can guide the support of school practices. Second, this study highlights a concrete example of a novel methodological contribution by using AI for text annotation. Discussing its results, validity, and limitations would show important implications for the use of AI to code open-ended questions in educational research.
PT  - Reports - Research

OWN - ERIC
TI  - Ethics, Education and Machine Intelligence
AU  - Zorislav Šojat
AU  - Gordana Gredicak Šojat
OT  - Ethics
OT  - Artificial Intelligence
OT  - Technology Uses in Education
OT  - Morale
OT  - Teaching Methods
OT  - Computer Software
OT  - Futures (of Society)
OT  - Commercialization
OT  - Trust (Psychology)
OT  - Intellectual Development
OT  - Bias
OT  - Barriers
OT  - Computational Linguistics
OT  - Learning Processes
OT  - Man Machine Systems
OT  - Academic Education
OT  - Peer Evaluation
OT  - Scientific Research
OT  - Open Source Technology
OT  - Faculty Publishing
OT  - Professional Recognition
OT  - Scholarship
JT  - International Society for Technology, Education, and Science
SO  - Paper presented at the International Conference on Research in Education and Science (ICRES) (Cappadocia, Turkey, May 18-21, 2023)
OID - ED654536
DP  - 2023
LID - http://eric.ed.gov/?id=ED654536
AB  - The sudden, unexpected breakthrough in the intelligence shown by machines, as a wished for, but very disruptive element, will shape the future of our civilisation and Humans as individuals and collectives. The extreme drive towards commercialisation of newest developments already led to an extremely wide spread of Machine Intelligence Assistants (and chatbots), with plans of many companies to include them into everything they produce. This puts Humans in a very precarious situation, specifically regarding ethics and morale, trustworthiness and confidence. Suddenly we found ourselves in a situation that Education has to be extended to cater for two types of intelligences: the Humans and the Machines. On the Machine side, it has been shown that it is very difficult to obtain a trustworthy and highly ethical non-biased intelligence. The present day approach of "training" the "models" must be overcome by the realisation that MI is based on collected Human knowledge, but initially "trained" without any regard to the order of learning, which directly influences the initial alignment of the emerging intelligence, the same way learning does in Humans. On the Human side, it is getting obvious that this disruptive development was generally completely unexpected, and no educational preparation was ever envisioned for this situation. However, between others, a good example of possible positive cooperation of Humans and Machines, which necessitates proper MI ethics, is Democratisation of Academic Publishing, where, based on blockchain trustworthiness, Open Access publishing is done in such a way that all stakeholders in the process get appropriate recognition and reward. The use of well educated Ethical Machine Intelligence in this process of management of an enormous amount of academic work and peer reviews will enable academic education and scientific development to be ethical, transparent, fair, trustworthy and accessible to all authors and readers throughout their life. [For the full proceedings, see ED654100.]
PT  - Speeches/Meeting Papers
PT  - Reports - Descriptive

OWN - ERIC
TI  - Enhancing Reflective Practice in Language Teacher Education: Technology as a Critical Reflective Partner
AU  - Daniel Xerri
OT  - Technology Uses in Education
OT  - Language Teachers
OT  - Teacher Education
OT  - Artificial Intelligence
OT  - Portfolios (Background Materials)
OT  - Electronic Publishing
OT  - Video Technology
OT  - Online Systems
OT  - Technology Integration
OT  - Reflective Teaching
OT  - Cooperation
OT  - Professional Identity
OT  - Well Being
OT  - Psychological Patterns
OT  - Ethics
OT  - Risk
OT  - Models
JT  - Technology in Language Teaching & Learning
SO  - v7 n2 Article 103214 2025
OID - EJ1484511
VI  - 7
IP  - 2
DP  - Article 103214 2025
LID - http://eric.ed.gov/?id=EJ1484511
AB  - This article explores how technology can serve as a critical partner in enhancing reflective practice in language teacher education. Drawing on recent studies, it examines the potential of AI tools, digital portfolios, video-based analysis, and online collaborative platforms. The argument hinges on the need to move toward a human-centred integration of digital tools that support metacognitive growth, emotional resilience, and professional identity development. The article proposes a five-principle framework for technology-enhanced reflection, emphasising pedagogical alignment, depth, collaboration, transparency, and teacher agency. While acknowledging risks related to over-automation and ethical ambiguity, the article contends that well-designed technologies, when critically embedded in reflective ecosystems, can deepen inquiry, foster contextualised insight, and support more dialogic and sustainable teacher learning. Ultimately, it advocates for technology that amplifies human reflection, positioning language educators as co-constructors of meaning in digitally mediated learning environments.
ISSN - EISSN-2652-1687
LA  - English
PT  - Journal Articles
PT  - Reports - Evaluative

OWN - ERIC
TI  - Zero- and Few-Shot Prompting of Generative Large Language Models Provides Weak Assessment of Risk of Bias in Clinical Trials
AU  - Simon Šuster
AU  - Timothy Baldwin
AU  - Karin Verspoor
OT  - Medical Research
OT  - Safety
OT  - Experimental Groups
OT  - Control Groups
OT  - Drug Therapy
OT  - Artificial Intelligence
OT  - Prompting
OT  - Risk
OT  - Bias
OT  - Evaluation
OT  - Prediction
JT  - Research Synthesis Methods
SO  - v15 n6 p988-1000 2024
AID - http://dx.doi.org/10.1002/jrsm.1749
OID - EJ1447297
VI  - 15
IP  - 6
PG  - 988-1000
DP  - 2024
LID - http://eric.ed.gov/?id=EJ1447297
AB  - Existing systems for automating the assessment of risk-of-bias (RoB) in medical studies are supervised approaches that require substantial training data to work well. However, recent revisions to RoB guidelines have resulted in a scarcity of available training data. In this study, we investigate the effectiveness of generative large language models (LLMs) for assessing RoB. Their application requires little or no training data and, if successful, could serve as a valuable tool to assist human experts during the construction of systematic reviews. Following Cochrane's latest guidelines (RoB2) designed for human reviewers, we prepare instructions that are fed as input to LLMs, which then infer the risk associated with a trial publication. We distinguish between two modelling tasks: directly predicting RoB2 from text; and employing decomposition, in which a RoB2 decision is made after the LLM responds to a series of signalling questions. We curate new testing data sets and evaluate the performance of four general- and medical-domain LLMs. The results fall short of expectations, with LLMs seldom surpassing trivial baselines. On the direct RoB2 prediction test set (n = 5993), LLMs perform akin to the baselines (F1: 0.1-0.2). In the decomposition task setup (n = 28,150), similar F1 scores are observed. Our additional comparative evaluation on RoB1 data also reveals results substantially below those of a supervised system. This testifies to the difficulty of solving this task based on (complex) instructions alone. Using LLMs as an assisting technology for assessing RoB2 thus currently seems beyond their reach.
ISSN - ISSN-1759-2879
ISSN - EISSN-1759-2887
LA  - English
PT  - Journal Articles
PT  - Reports - Research

OWN - ERIC
TI  - The Sentiments and the Impact of ChatGPT on Computer Programming Learning: Data Mining from Comments on YouTube Videos
AU  - Meina Zhu
OT  - Computer Science Education
OT  - Programming
OT  - Social Media
OT  - Video Technology
OT  - Data Collection
OT  - Computer Mediated Communication
OT  - Artificial Intelligence
OT  - Synchronous Communication
OT  - Computer Software
OT  - Individualized Instruction
OT  - Technology Uses in Education
JT  - Journal of Computer Assisted Learning
SO  - v41 n2 e70013 2025
AID - http://dx.doi.org/10.1111/jcal.70013
OID - EJ1464369
VI  - 41
IP  - 2
DP  - e70013 2025
LID - http://eric.ed.gov/?id=EJ1464369
AB  - Background: Computer programming learning and education play a critical role in preparing a workforce equipped with the necessary skills for diverse fields. ChatGPT and YouTube are technologies that support self-directed programming learning. Objectives: This study aims to examine the sentiments and primary topics discussed in YouTube comments about ChatGPT's impact on learning and writing computer programming. Methods: The data were collected from 30 November 2022 to 11 January 2024, by extracting 30,773 comments from 57 YouTube videos. Sentiment analysis, topic modelling and thematic analysis were used for data analysis. Results and Conclusions: Through sentiment analysis and thematic analysis, a positive attitude among YouTube self-directed learners towards employing ChatGPT for learning and writing computer programming was identified. The results of topic modelling and thematic analysis revealed that these learners recognise both the perceived advantages and limitations of using ChatGPT for learning and writing computer programming. The advantages include creating learning plans, generating code, self-correction, explaining code and saving programming time, while the limitations are incorrect information, challenges in debugging programmes, perceived inefficiency and ineffectiveness and the absence of intelligence. Diverse perspectives regarding the impact of ChatGPT on programming professions and education were discussed. Some ethical concerns regarding data privacy, code copyright and equity issues were raised and needed further exploration. The findings imply the importance of computer programming education and integrating ChatGPT into programming education. Guidelines and instructions regarding using ChatGPT for programming learning are needed.
ISSN - ISSN-0266-4909
ISSN - EISSN-1365-2729
LA  - English
PT  - Journal Articles
PT  - Reports - Research

OWN - ERIC
TI  - A Bibliometric Analysis of Soft Computing Technology Applications Trends and Characterisation in Educational Research: Africa
AU  - Isaac Kofi Nti
AU  - Faiza Umar Bawah
AU  - Juanita Ahia Quarcoo
AU  - Favour Kalos
OT  - Bibliometrics
OT  - Computer Uses in Education
OT  - Artificial Intelligence
OT  - Educational Research
OT  - Educational Trends
OT  - Educational Technology
OT  - Learning Analytics
OT  - Foreign Countries
OT  - Authors
OT  - Computer Oriented Programs
JT  - Africa Education Review
SO  - v19 n3 p55-77 2022
AID - http://dx.doi.org/10.1080/18146627.2023.2284744
OID - EJ1406123
VI  - 19
IP  - 3
PG  - 55-77
DP  - 2022
LID - http://eric.ed.gov/?id=EJ1406123
AB  - Computers in education, along with soft-computing technology applications, have revolutionised global interconnectedness and the need for a well-educated workforce. Many studies worldwide explore technology in education, often relying on systematic reviews, though concerns about selection bias have emerged. This article takes a different approach, employing bibliometric analysis to delve into the trends, key authors, institutions, and themes of soft-computing technology applications in education (SCTAE) research in Africa. Initially, 7,435 papers were downloaded from Scopus and then narrowed down to 1,358 using the PRISMA model and defined criteria. Utilising the VOSViewer text mining tool, the article maps out prolific authors, institutions, and thematic networks. It provides detailed findings and outlines opportunities, challenges, and future research prospects in SCTAE in the African context.
ISSN - ISSN-1814-6627
ISSN - EISSN-1753-5921
LA  - English
PT  - Journal Articles
PT  - Reports - Research

OWN - ERIC
TI  - Using Automated Analysis to Assess Middle School Students' Competence with Scientific Argumentation
AU  - Christopher D. Wilson
AU  - Kevin C. Haudek
AU  - Jonathan F. Osborne
AU  - Zoë E. Buck Bracey
AU  - Tina Cheuk
AU  - Brian M. Donovan
AU  - Molly A. M. Stuhlsatz
AU  - Marisol M. Santiago
AU  - Xiaoming Zhai
OT  - Middle School Students
OT  - Competence
OT  - Science Process Skills
OT  - Persuasive Discourse
OT  - Secondary School Science
OT  - Automation
OT  - Computer Assisted Testing
OT  - Scoring
OT  - Prediction
OT  - Scores
OT  - Models
OT  - English Language Learners
OT  - Test Bias
JT  - Journal of Research in Science Teaching
SO  - v61 n1 p38-69 2024
AID - http://dx.doi.org/10.1002/tea.21864
OID - EJ1405261
VI  - 61
IP  - 1
PG  - 38-69
DP  - 2024
LID - http://eric.ed.gov/?id=EJ1405261
AB  - Argumentation is fundamental to science education, both as a prominent feature of scientific reasoning and as an effective mode of learning--a perspective reflected in contemporary frameworks and standards. The successful implementation of argumentation in school science, however, requires a paradigm shift in science assessment from the measurement of knowledge and understanding to the measurement of performance and knowledge in use. Performance tasks requiring argumentation must capture the many ways students can construct and evaluate arguments in science, yet such tasks are both expensive and resource-intensive to score. In this study we explore how machine learning text classification techniques can be applied to develop efficient, valid, and accurate constructed-response measures of students' competency with written scientific argumentation that are aligned with a validated argumentation learning progression. Data come from 933 middle school students in the San Francisco Bay Area and are based on three sets of argumentation items in three different science contexts. The findings demonstrate that we have been able to develop computer scoring models that can achieve substantial to almost perfect agreement between human-assigned and computer-predicted scores. Model performance was slightly weaker for harder items targeting higher levels of the learning progression, largely due to the linguistic complexity of these responses and the sparsity of higher-level responses in the training data set. Comparing the efficacy of different scoring approaches revealed that breaking down students' arguments into multiple components (e.g., the presence of an accurate claim or providing sufficient evidence), developing computer models for each component, and combining scores from these analytic components into a holistic score produced better results than holistic scoring approaches. However, this analytical approach was found to be differentially biased when scoring responses from English learners (EL) students as compared to responses from non-EL students on some items. Differences in the severity between human and computer scores for EL between these approaches are explored, and potential sources of bias in automated scoring are discussed.
ISSN - ISSN-0022-4308
ISSN - EISSN-1098-2736
GR  - 1561159
GR  - 1561150
GR  - 1561149
GR  - 1561155
LA  - English
PT  - Journal Articles
PT  - Reports - Research

OWN - ERIC
TI  - Investigating Automatic Dialogue Act Classification in Collaborative Learning through Federated Transfer Learning and Cross-Corpora Domain Adaptation
AU  - Gloria Ashiya Katuka
OT  - Dialogs (Language)
OT  - Classification
OT  - Intention
OT  - Natural Language Processing
OT  - Computational Linguistics
OT  - Taxonomy
OT  - Speech Communication
OT  - Models
OT  - Computer Software
OT  - Cooperative Learning
OT  - Pragmatics
OT  - Learning Processes
OT  - Prediction
OT  - Artificial Intelligence
OT  - Task Analysis
OT  - Data Use
OT  - Privacy
OT  - Accuracy
OT  - Scores
OT  - Comparative Analysis
OT  - Benchmarking
OT  - Educational Technology
JT  - ProQuest LLC
SO  - Ph.D. Dissertation, University of Florida
AID - https://gateway.proquest.com/openurl?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&res_dat=xri:pqm&rft_dat=xri:pqdiss:31147245
OID - ED659351
DP  - 2024
LID - http://eric.ed.gov/?id=ED659351
AB  - Dialogue act (DA) classification plays an important role in understanding, interpreting and modeling dialogue. Dialogue acts (DAs) represent the intended meaning of an utterance, which is associated with the illocutionary force (or the speaker's intention), such as greetings, questions, requests, statements, and agreements. In natural language processing (NLP) applications, developing a DA annotation scheme or A taxonomy is often a first step in working with a corpus. The development of these annotation schemes provides a set of DA labels that are used to manually label a specific corpus, thus capturing the fine-grained intended meanings of utterances. However, dialogue act annotation is a complex task that requires not only an understanding of the linguistic content of an utterance but also of the context in which it was uttered. Researchers who wish to annotate a new corpus are thus tasked with developing a new taxonomy based on a subset of an existing taxonomy, a combination of two or more existing taxonomies, or creating an entirely new taxonomy. Consequently, researchers are more commonly inclined toward developing newer dialogue act annotation schemes, further increasing the number of distinct DA labels and making it difficult to effectively train DA classification models that can be generalized across related or different corpora. Moreover, without access to the specific corpora, it is even more difficult to define and agree upon a fixed dialogue act annotation scheme that can be applied across different corpora, even within similar domains. In collaborative learning, DAs are used to represent the pragmatic goals of utterances. They offer many cues for assessing the effectiveness of collaboration and understanding the kinds of dialogue behaviors that impact learning, performance, and problem-solving abilities. By assigning DAs to collaborative dialogue, researchers can better assess the effectiveness of collaborative learning efforts. They also allow researchers to identify the kinds of dialogue patterns or behaviors that may have a positive or negative effect on the collaborative learning process, such as predicting learners' satisfaction with their partners. However, collaborative learning dialogue takes place in highly domain-specific contexts, which makes DA classification particularly challenging. To mitigate the manual effort required for dialogue act classification, the rise of more advanced machine learning and deep learning text classification models holds potential for training DA classification models for the automatic classification of dialogue acts in the collaborative learning context. However, existing dialogue act classification models often struggle to generalize effectively, even within similar domains or collaborative learning contexts, due to variations in dialogue patterns, domain-specific tasks, dialogue act labels, and the insufficient amount of data needed to train the classification models. This dissertation aims to investigate four main challenges for dialogue act classification in collaborative learning contexts: 1) limited data to adequately train a high performance classification model; 2) too many classes to train a high performance classifier due to fine-grained DA labels; 3) difficulty in mapping dialogue act labels across corpora due to variations in dialogue act annotation schemes; and 4) data privacy concerns restricting data sharing, which limits opportunities for model improvement via cross-corpora training. This dissertation work addresses these challenges by investigating two main transfer learning approaches: cross-corpora domain adaptation, which aims to mitigate the problem of insufficient unique data, and federated transfer learning, which aims to address the data privacy concerns that arise during DA classification model training. To examine the impact of the cross-corpora domain adaptation approach on DA classification, experiments were conducted using fine-tuned pretrained transformer models across three corpora of collaborative learning data. Experimental results showed that the cross-corpora fine-tuned models resulted in an overall improvement in accuracy and F1-scores compared to baseline models fine-tuned using any individual corpus. Additionally, the cross-corpora fine-tuned models outperformed baselines in scenarios with limited dialogue act representation. The results show that this approach has the potential to improve classification performance, especially when a corpus has limited representation of certain dialogue acts. This work highlights the potential benefits of this approach for future domain-specific dialogue act classification tasks. To investigate the impact of the federated transfer learning (FTL) approach on DA classification, I implemented FTL using two standard aggregation methods and conducted experiments using BERT and RoBERTa models. Taking the three corpora as representative of physically separate data locations, the results showed the feasibility of training a global model from multiple, distributed datasets concurrently. Although the experimental results showed that the FTL models underperformed in comparison to the baseline models, the findings represent a possibility for improvement for the FTL models. The protection of data privacy afforded by FTL is important for future data-driven investigations. Meanwhile, using a domain-related model as the global model during the federated transfer learning produced improved performance compared to using the original pretrained model. The main contributions of this research include the novel finding that shows cross-corpora domain adaptation approach produces improved performance for dialogue act classification in collaborative learning context. Contributions also include the implementation of FTL for DA classification. These approaches could potentially set a new benchmark for future work in cross-corpora domain adaptation, federated transfer learning, and dialogue act classification in the context of collaborative learning. This work could also serve as a helpful reference for NLP researchers using transfer learning to improve performance in downstream tasks. In addition, this work may have practical implications for various NLP applications in educational contexts, including the design and development of dialogue systems to support learners, educational technologies using collaborative techniques, and collaborative learning environments. [The dissertation citations contained here are published with the permission of ProQuest LLC. Further reproduction is prohibited without permission. Copies of dissertations may be obtained by Telephone (800) 1-800-521-0600. Web page: http://www.proquest.com/en-US/products/dissertations/individuals.shtml.]
ISBN - 979-8-3836-7732-2
GR  - 1814083
GR  - 1640141
GR  - 2048480
GR  - 2147810
GR  - 2147811
PT  - Dissertations/Theses - Doctoral Dissertations

OWN - ERIC
TI  - Neural Language Models and Human Linguistic Knowledge
AU  - Jennifer Hu
OT  - Linguistic Theory
OT  - Computational Linguistics
OT  - Models
OT  - Language Research
OT  - Artificial Intelligence
OT  - Learning Processes
OT  - Linguistic Input
OT  - Algorithms
OT  - Case Studies
OT  - Language Acquisition
OT  - Syntax
OT  - Language Processing
OT  - Generalization
OT  - Computer Software
OT  - Training
OT  - Inferences
OT  - Interpersonal Competence
OT  - Pragmatics
OT  - Prediction
OT  - Cognitive Structures
OT  - Figurative Language
OT  - Task Analysis
OT  - Comparative Analysis
OT  - Behavior Patterns
JT  - ProQuest LLC
SO  - Ph.D. Dissertation, Massachusetts Institute of Technology
AID - https://gateway.proquest.com/openurl?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&res_dat=xri:pqm&rft_dat=xri:pqdiss:31091159
OID - ED651539
DP  - 2023
LID - http://eric.ed.gov/?id=ED651539
AB  - Language is one of the hallmarks of intelligence, demanding explanation in a theory of human cognition. However, language presents unique practical challenges for quantitative empirical research, making many linguistic theories difficult to test at naturalistic scales. Artificial neural network language models (LMs) provide a new tool for studying language with mathematical precision and control, as they exhibit remarkably sophisticated linguistic behaviors while being fully intervenable. While LMs differ from humans in many ways, the learning outcomes of these models can reveal the behaviors that may emerge through expressive statistical learning algorithms applied to linguistic input. In this thesis, I demonstrate this approach through three case studies using LMs to investigate open questions in language acquisition and comprehension. First, I use LMs to perform controlled manipulations of language learning, and find that syntactic generalizations depend more on a learner's inductive bias than on training data size. Second, I use LMs to explain systematic variation in scalar inferences by approximating human listeners' expectations over unspoken alternative sentences (e.g., "The bill was supported overwhelmingly" implies that the bill was not supported unanimously). Finally, I show that LMs and humans exhibit similar behaviors on a set of non-literal comprehension tasks which are hypothesized to require social reasoning (e.g., inferring a speaker's intended meaning from ironic statements). These findings suggest that certain aspects of linguistic knowledge could emerge through domain-general prediction mechanisms, while other aspects may require specific inductive biases and conceptual structures. [The dissertation citations contained here are published with the permission of ProQuest LLC. Further reproduction is prohibited without permission. Copies of dissertations may be obtained by Telephone (800) 1-800-521-0600. Web page: http://www.proquest.com/en-US/products/dissertations/individuals.shtml.]
ISBN - 979-8-3819-5503-3
PT  - Dissertations/Theses - Doctoral Dissertations

OWN - ERIC
TI  - Stench of Errors or the Shine of Potential: The Challenge of (Ir)Responsible Use of ChatGPT in Speech-Language Pathology
AU  - Mytsyk Hanna
AU  - Suchikova Yana
OT  - Artificial Intelligence
OT  - Speech Language Pathology
OT  - Natural Language Processing
OT  - Technology Integration
OT  - Allied Health Personnel
OT  - Responsibility
OT  - Ethics
OT  - Allied Health Occupations Education
JT  - International Journal of Language & Communication Disorders
SO  - v60 n4 e70088 2025
AID - http://dx.doi.org/10.1111/1460-6984.70088
OID - EJ1478113
VI  - 60
IP  - 4
DP  - e70088 2025
LID - http://eric.ed.gov/?id=EJ1478113
AB  - Background: Integrating large language models (LLMs), such as ChatGPT, into speech-language pathology (SLP) presents promising opportunities and notable challenges. While these tools can support diagnostics, streamline documentation and assist in therapy planning, they also raise concerns related to misinformation, cultural insensitivity, overreliance and ethical ambiguity. Current discourse often centres on technological capabilities, overlooking how future speech-language pathologists (SLPs) are being prepared to use such tools responsibly. Aims: This paper examines the pedagogical, ethical and professional implications of integrating LLMs into SLP. It emphasizes the need to cultivate professional responsibility, ethical awareness and critical engagement amongst student SLPs, ensuring that such technologies are applied thoughtfully, appropriately and in accordance with evidence-based and contextually relevant therapeutic standards. Methods: The paper combines a review of recent interdisciplinary research with reflective insights from academic practice. It presents documented cases of student SLPs' overreliance on ChatGPT, analyzes common pitfalls through a structured table of examples and synthesizes perspectives from SLP, education, data ethics and linguistics. Main Contribution: Reflective examples presented in the article illustrate challenges that arise when LLMs are used without sufficient oversight or a clear understanding of their limitations. Rather than questioning the value of LLMs, these cases emphasize the importance of ensuring that student SLPs are guided towards thoughtful, ethical and clinically sound use. To support this, the paper offers a set of pedagogical recommendations--including ethics integration, reflective assignments, case-based learning, peer critique and interdisciplinary collaboration--aimed at embedding critical engagement with tools such as ChatGPT into professional training. Conclusions: LLMs are becoming an integral part of SLP. Their impact, however, will depend on how effectively student SLPs are trained to balance technological innovation with professional responsibility. Higher education institutions (HEIs) must take an active role in embedding responsible engagement with LLMs into pre-service training and SLP curricula. Through intentional and early preparation, the field can move beyond the risks associated with automation and towards a future shaped by reflective, informed and ethically grounded use of generative tools.
ISSN - ISSN-1368-2822
ISSN - EISSN-1460-6984
LA  - English
PT  - Journal Articles
PT  - Reports - Evaluative

OWN - ERIC
TI  - ELT Teachers' Perception and Usage of ChatGPT as a Teaching Tool in the Bangladeshi EFL Context
AU  - Tasnia Tarannum
AU  - Risala Ahmed
AU  - Prodhan Mahbub Ibna Seraj
AU  - Tasneem Shereen Khan
OT  - English (Second Language)
OT  - Second Language Instruction
OT  - Second Language Learning
OT  - Artificial Intelligence
OT  - Computer Software
OT  - Technology Integration
OT  - Private Colleges
OT  - Language Teachers
OT  - Teacher Attitudes
OT  - Teaching Methods
OT  - Ethics
OT  - Technological Literacy
OT  - Pedagogical Content Knowledge
OT  - College Students
OT  - Feedback (Response)
OT  - Foreign Countries
OT  - Educational Benefits
OT  - Plagiarism
OT  - Misinformation
JT  - Education and Information Technologies
SO  - v30 n13 p19269-19295 2025
AID - http://dx.doi.org/10.1007/s10639-025-13515-7
OID - EJ1480850
VI  - 30
IP  - 13
PG  - 19269-19295
DP  - 2025
LID - http://eric.ed.gov/?id=EJ1480850
AB  - ChatGPT, developed by OpenAI, is the most buzzing word in academia recently. Due to its ability to provide instant language support and generate diverse educational resources, it has emerged as a powerful tool in ELT (English language teaching). This study aims to explore ELT teachers' perception and usage of ChatGPT as a teaching tool in the Bangladeshi EFL context. To do this, a concurrent mixed-method research design was employed using interviews and a survey questionnaire. 54 ELT teachers for the survey questionnaire, and 7 teachers interviewed participated from the department of English from 5 different private universities in Bangladesh. The results revealed that ELT teachers used ChatGPT for generating practice tasks, preparing question materials for quizzes or examinations, and providing automated feedback. The teachers highlighted several benefits, such as saving time, having unlimited resources, and easy accessibility, while they noted students' overdependence and plagiarism, misinterpreted instruction, faulty information, and similar and repetitive structure and language as the potential drawbacks. The teachers opined that for using ChatGPT both teachers and students need proper training and ethical awareness. The findings bring forth valuable insights for teachers, students, and policymakers.
ISSN - ISSN-1360-2357
ISSN - EISSN-1573-7608
LA  - English
PT  - Journal Articles
PT  - Reports - Research

OWN - ERIC
TI  - Using Auxiliary Data to Boost Precision in the Analysis of Educational RCTs: New Data and New Results
AU  - Adam Sales
AU  - Ethan Prihar
AU  - Johann Gagnon-Bartsch
AU  - Neil Heffernan
OT  - Learning Analytics
OT  - Randomized Controlled Trials
OT  - Data Use
OT  - Accuracy
OT  - Research Problems
OT  - Computation
OT  - Artificial Intelligence
OT  - Statistical Bias
JT  - Society for Research on Educational Effectiveness
AID - https://www.sree.org/2023-conference
OID - ED659741
DP  - 2023
LID - http://eric.ed.gov/?id=ED659741
AB  - Background: Randomized controlled trials (RCTs) give unbiased estimates of average effects. However, positive effects for the majority of students may mask harmful effects for smaller subgroups, and RCTs often have too small a sample to estimate these subgroup effects. In many RCTs, covariate and outcome data are drawn from a larger database. For instance, educational efficacy studies may target state standardized tests scores while adjusting for student demographics and prior achievement, all of which are drawn from a state longitudinal data system. In these situations, typically only a subset of students in the database participate in the RCT. We refer to RCT non-participants in the database as the "remnant" from the RCT. The remnant often includes a larger sample size than the RCT--especially when estimating subgroup effects--but is not randomized, so including may cause bias. This talk will describe and illustrate a method incorporating the remnant into the analysis of RCTs that gives unbiased estimates and conservative standard errors and has the potential to improve the precision of effect estimates from an RCT, sometimes dramatically. Research Questions: The talk will use data from RCTs that were run within an online tutoring system to answer three research questions: (1) To what extent might remnant data improve the precision of effect estimates from RCTs? (2) Can incorporating the remnant improve estimation of subgroup effects? (3) If the remnant is known to be drawn from a different population than the participants in A/B tests, can it still be useful? Data: E-Trials is a platform that allows researchers to design educational experiments that will then be run within the ASSISTments online tutor. Students working on "skill-builder" modules are randomized between two or more conditions, such as how subject matter is portrayed, available hints, and feedback to students. We analyzed data from 277 contrasts between pairs of treatment arms drawn from 68 multi-armed RCTs, including 113,963 students. We also collected rich clickstream-level log data from RCT participants as well as from a remnant of 193,218 ASSISTments users who did not participate in any of the RCTs we analyzed. Assignment completion was the outcome of interest across RCTs. Methodology: The methodology (Gagnon-Bartsch et al. 2023) builds on prior literature including Sales, et al (2018ab), Wu and Gagnon-Bartsch (2018), and Aronow and Middleton (2013). It involves three steps: (1) using only remnant data, train a model $f^R(\cdot):\mathbb{R}^p\rightarrow\mathbb{R}$ predicting outcomes Y as a function of a pdimensional covariate matrix X. This model can be of any form, including machine learning algorithms, and may be fit and tested multiple times, as long as only remnant data is used. It need not be correct, unbiased, or consistent in any sense, but should ideally yield accurate out-of-sample predictions. (2) Use the fitted model $\hat{f}(\cdot)$, along with covariate data from RCT participants X^{RCT} to predict RCT outcomes as $\hat{y}_C=\hat{f}(X^{RCT})$. (3) Use $\hat{y}_C$, as a covariate in a design-based covariate-adjusted effect estimator (e.g. Rosenbaum 2002, Wager, et al. 2016) perhaps alongside other covariates. In our analysis we use the LOOP estimator of Wu and Gagnon-Bartsch (2018), and refer to the estimator including only $\hat{y}_C$ as a covariate as "ReLOOP" (i.e. Remnant-based LOOP) and the estimator also including other covariates as "ReLOOP+." To carry out the method, we fit an ensemble model (Fig. 1) including three deep neural networks (e.g. Goodfellow, et al. 2016), each trained on a different set of covariates: data on each of the previous 20 assignments each students started, actions students took on each of the prior 60 days, and aggregated student-level data. These three models were then ensembled via a fourth feed-forward neural network. The same fitted model was used for all subgroup comparisons. To test the performance of our methods when the remnant is demographically distinct from the RCT, we used the "gender guesser" python script https://pypi.org/project/gender-guesser/ using students' first names, categorizing students as Male, Female, or Unknown. We fit a model to the subset of the remnant categorized as "Male"--since gender guesser is imperfect and trained using Eurasian names, we assume this group is mostly male and disproportionally white or Asian--and estimated effects for RCT participants from the other categories. Results: All of the estimators we consider are exactly unbiased, so our results focus on estimated sampling-variance of ReLOOP, ReLOOP+, the difference-in-means estimator (Neyman 2023) or the LOOP estimator without remnant data. Specifically, we consider sampling-variance ratios: since sampling-variance scales as 1/n, these can be thought of as "sample size multipliers." RQ1: Figure 2 shows boxplots of sampling variance ratios comparing ReLOOP or ReLOOP+ to difference-in-means (Labeled "T-Test") or LOOP. Incorporating $\hat{y}_C$ into the analysis never substantially hurt precision, but in many cases improved precision by as much as 30% or more. RQ2: Figures 3 shows boxplots of sampling-variance ratios for subgroup effects, and Figure 4 plots these ratios as a function of sample size within the subgroup. On average, ReLOOP+ improved precision for subgroup estimation for all sample sizes. For small subgroup samples, the improvement could be dramatic--equivalent to more than doubling the sample size in some cases--but in some other cases it hurt precision noticeably. RQ3: Figure 5 shows results from the experiment using the "male" remnant to estimate effects in the non-"male" subset of the RCTs. Surprisingly, ReLOOP improved precision roughly equally among "male" and non-"male" subgroups of the RCT, and ReLOOP+ improved precision more in the non-"male" subgroup, despite the unrepresentativeness of the remnant. Conclusion: Machine learning methods have an impressive potential, but can also reproduce biases present in their training samples (e.g. Bolukbasi et al. 2016). Randomized Controlled Trials give unbiased estimates (for the RCT participants) but these may be imprecise and mask treatment effect heterogeneity. The methods we propose, ReLOOP and ReLOOP+ use machine learning models fit to auxiliary data that are unbiased, like RCTs, but can also be more precise--especially for subgroup estimates, even when the remnant is itself biased. They can be valuable tools for using all available data to evaluate programs for both the majority of students as well as for vulnerable minorities.
PT  - Reports - Research

OWN - ERIC
TI  - ChatGPT for Learning HCI Techniques: A Case Study on Interviews for Personas
AU  - Jose Barambones
AU  - Cristian Moral
AU  - Angelica de Antonio
AU  - Ricardo Imbert
AU  - Loic Martinez-Normand
AU  - Elena Villalba-Mora
OT  - Artificial Intelligence
OT  - Synchronous Communication
OT  - Computer Mediated Communication
OT  - Man Machine Systems
OT  - Computer Software
OT  - Users (Information)
OT  - User Needs (Information)
OT  - Audience Awareness
OT  - Design
JT  - IEEE Transactions on Learning Technologies
SO  - v17 p1486-1501 2024
AID - http://dx.doi.org/10.1109/TLT.2024.3386095
OID - EJ1422393
VI  - 17
PG  - 1486-1501
DP  - 2024
LID - http://eric.ed.gov/?id=EJ1422393
AB  - Before interacting with real users, developers must be proficient in human--computer interaction (HCI) so as not to exhaust user patience and availability. For that, substantial training and practice are required, but it is costly to create a variety of high-quality HCI training materials. In this context, chat generative pretrained transformer (ChatGPT) and other chatbots based on large language models (LLMs) offer an opportunity to generate training materials of acceptable quality without foregoing specific human characteristics present in real-world scenarios. Personas is a user-centered design method that encompasses fictitious but believable user archetypes to help designers understand and empathize with their target audience during product design. We conducted an exploratory study on the Personas technique, addressing the validity and believability of interviews designed by HCI trainers and answered by ChatGPT-simulated users, which can be used as training material for persona creation. Specifically, we employed ChatGPT to respond to interviews designed by user experience (UX) experts. Two groups, HCI professors and professionals, then evaluated the validity of the generated materials considering quality, usefulness, UX, and ethics. The results show that both groups rated the interviews as believable and helpful for Personas training. However, some concerns about response repetition and low response variability suggested the need for further research on improved prompt design in order to generate more diverse and well-developed responses. The findings of this study provide insight into how HCI trainers can use ChatGPT to help their students master persona creation skills before working with real users in real-world scenarios for the first time.
ISSN - EISSN-1939-1382
LA  - English
PT  - Journal Articles
PT  - Reports - Research

OWN - ERIC
TI  - The Leadership Tree Model: A Global and AI-Enhanced Framework for Leadership Development
AU  - Yihe Yang
AU  - Antonio Jimenez-Luque
OT  - Transformational Leadership
OT  - Leadership Training
OT  - Models
OT  - Higher Education
OT  - Social Justice
OT  - Ethics
OT  - Curriculum Development
OT  - College Students
OT  - Student Leadership
OT  - Diversity Equity and Inclusion
OT  - Well Being
JT  - New Directions for Student Leadership
SO  - n186 p97-104 2025
AID - http://dx.doi.org/10.1002/yd.20674
OID - EJ1474960
DP  - 2025
LID - http://eric.ed.gov/?id=EJ1474960
AB  - This article presents the Leadership Tree Model, a metaphorical and conceptual framework for transformative leadership development in higher education. Rooted in critical pedagogy and social justice, the model encourages educators to create inclusive, reflective, and action-oriented learning environments. It positions leadership as a relational and ethical process that challenges systemic inequities and centers marginalized voices. The article outlines applications for curricular and co-curricular programming and highlights the model's relevance across diverse institutional contexts. Ultimately, the Leadership Tree Model aims to support students in becoming transformative leaders committed to equity, inclusion, and collective well-being.
ISSN - ISSN-2373-3349
ISSN - EISSN-2373-3357
LA  - English
PT  - Journal Articles
PT  - Reports - Descriptive

OWN - ERIC
TI  - Optimization of Piano Performance Teaching Mode Using Network Big Data Analysis Technology
AU  - Xiang Wei
AU  - Shuping Sun
OT  - Musical Instruments
OT  - Music Education
OT  - Teaching Methods
OT  - Educational Technology
OT  - Artificial Intelligence
OT  - Instructional Effectiveness
OT  - Performance Based Assessment
JT  - International Journal of Information and Communication Technology Education
SO  - v20 n1 2024
AID - https://doi.org/10.4018/IJICTE.341266
OID - EJ1426682
VI  - 20
IP  - 1
DP  - 2024
LID - http://eric.ed.gov/?id=EJ1426682
AB  - To effectively avoid subjective bias in manual evaluation. This article proposes a MIDI piano teaching performance evaluation method based on bidirectional LSTM. This method utilizes a three-layer bidirectional LSTM neural network mechanism to make it easier for the model to capture useful information. In addition, the Spark clustering training model is constructed using the deeplearning4j deep learning framework, and the model parameters are adjusted through the UI dependency relationships provided by deeplearning4j to improve work efficiency. The experimental results verified the superiority of the bidirectional LSTM model. The methods provided in this article can improve students' independent practical abilities and reduce the pressure on teachers during the teaching process. These measures can promote the development of music education, improve students' music literacy and learning skills, and make positive contributions to the music education industry.
ISSN - ISSN-1550-1876
ISSN - EISSN-1550-1337
LA  - English
PT  - Journal Articles
PT  - Reports - Research

OWN - ERIC
TI  - ChatGPT in Higher Education: Opportunities, Challenges, and Required Competencies in the Absence of Guiding Policies
AU  - Ahmed Alkaabi
AU  - Asma Abdallah
AU  - Shamma Alblooshi
AU  - Fatima Alomari
AU  - Sara Alneaimi
OT  - Artificial Intelligence
OT  - Teaching Methods
OT  - Computer Software
OT  - Higher Education
OT  - College Faculty
OT  - Teacher Attitudes
OT  - Technology Integration
OT  - Ethics
OT  - Educational Policy
OT  - College Students
OT  - Student Attitudes
OT  - Misinformation
OT  - Algorithms
OT  - Teacher Workshops
OT  - Curriculum Development
OT  - Risk
OT  - Cost Effectiveness
OT  - Barriers
OT  - Educational Benefits
OT  - Addictive Behavior
OT  - Integrity
OT  - Cheating
OT  - Foreign Countries
JT  - Journal of Education and e-Learning Research
SO  - v12 n2 p153-164 2025
OID - EJ1477232
VI  - 12
IP  - 2
PG  - 153-164
DP  - 2025
LID - http://eric.ed.gov/?id=EJ1477232
AB  - This study examines the opportunities and challenges of employing ChatGPT in higher education, identifies essential user competencies, and evaluates its impact in the absence of formal policy guidelines. A qualitative case study design involved interviews with 10 faculty members and 10 students at a federal university in the United Arab Emirates. Documentation of live ChatGPT usage was also analyzed to triangulate findings. Thematic analysis revealed the following eight core themes: (1) Cost-effectiveness and time savings. (2) ChatGPT as a source of information and a flexible tool. (3) ChatGPT's ability to adapt to the user. (4) Prompt engineering competencies in ChatGPT. (5) Addiction to ChatGPT. (6) The misinformation risks with ChatGPT. (7) Academic integrity concerns. (8) A lack of consensus on how to utilize ChatGPT appropriately. The findings underscore an urgent need for formal policies to guide the ethical and responsible use of ChatGPT in higher education. The study also emphasizes the necessity of targeted training workshops for teachers, curriculum integration, and adapting pedagogical approaches. It also calls for proactive attention to ethical concerns including misinformation, algorithmic bias, and overreliance to ensure that the educational benefits of ChatGPT are realized responsibly and sustainably.
ISSN - ISSN-2518-0169
ISSN - EISSN-2410-9991
LA  - English
PT  - Journal Articles
PT  - Reports - Research

OWN - ERIC
TI  - From the Lab to the Wild: Examining Generalizability of Video-Based Mind Wandering Detection
AU  - Babette Bühler
AU  - Efe Bozkir
AU  - Patricia Goldberg
AU  - Ömer Sümer
AU  - Sidney D'Mello
AU  - Peter Gerjets
AU  - Ulrich Trautwein
AU  - Enkelejda Kasneci
OT  - Attention
OT  - Automation
OT  - Identification
OT  - Video Technology
OT  - Artificial Intelligence
OT  - Sex Fairness
OT  - Prediction
OT  - Generalization
OT  - College Students
OT  - Foreign Countries
JT  - International Journal of Artificial Intelligence in Education
SO  - v35 n2 p823-857 2025
AID - http://dx.doi.org/10.1007/s40593-024-00412-2
OID - EJ1488234
VI  - 35
IP  - 2
PG  - 823-857
DP  - 2025
LID - http://eric.ed.gov/?id=EJ1488234
AB  - Student's shift of attention away from a current learning task to task-unrelated thought, also called mind wandering, occurs about 30% of the time spent on education-related activities. Its frequent occurrence has a negative effect on learning outcomes across learning tasks. Automated detection of mind wandering might offer an opportunity to assess the attentional state continuously and non-intrusively over time and hence enable large-scale research on learning materials and responding to inattention with targeted interventions. To achieve this, an accessible detection approach that performs well for various systems and settings is required. In this work, we explore a new, generalizable approach to video-based mind wandering detection that can be transferred to naturalistic settings across learning tasks. Therefore, we leverage two datasets, consisting of facial videos during reading in the lab (N = 135) and lecture viewing in-the-wild (N = 15). When predicting mind wandering, deep neural networks (DNN) and long short-term memory networks (LSTMs) achieve F[subscript 1] scores of 0.44 (AUC-PR = 0.40) and 0.459 (AUC-PR = 0.39), above chance level, with latent features based on transfer-learning on the lab data. When exploring generalizability by training on the lab dataset and predicting on the in-the-wild dataset, BiLSTMs on latent features perform comparably to the state-of-the-art with an F[subscript 1] score of 0.352 (AUC-PR = 0.26). Moreover, we investigate the fairness of predictive models across gender and show based on post-hoc explainability methods that employed latent features mainly encode information on eye and mouth areas. We discuss the benefits of generalizability and possible applications.
ISSN - ISSN-1560-4292
ISSN - EISSN-1560-4306
GR  - 1920510
LA  - English
PT  - Journal Articles
PT  - Reports - Research

OWN - ERIC
TI  - Towards Learning with Limited Supervision: Efficient Few-Shot and Semi-Supervised Classification for Vision Tasks
AU  - Ran Tao
OT  - Classification
OT  - Vision
OT  - Documentation
OT  - Data Collection
OT  - Data Use
OT  - Supervision
OT  - Training
OT  - Computers
OT  - Artificial Intelligence
JT  - ProQuest LLC
SO  - Ph.D. Dissertation, Carnegie Mellon University
AID - http://gateway.proquest.com/openurl?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:dissertation&res_dat=xri:pqm&rft_dat=xri:pqdiss:30988668
OID - ED645091
DP  - 2023
LID - http://eric.ed.gov/?id=ED645091
AB  - Vision classification tasks, a fundamental and transformative aspect of deep learning and computer vision, play a pivotal role in our ability to understand the visual world. Deep learning techniques have revolutionized the field, enabling unprecedented accuracy and efficiency in vision classification. However, deep learning models, especially supervised models, require large amounts of labeled data to learn effectively. The acquisition of large-scale datasets meets many difficulties considering the dynamics in real-world applications. Collecting and annotating data is a time-consuming and expensive process, which sometimes requires domain-specific expertise to provide a sufficient quantity of high-quality labeled data. Meanwhile, privacy and ethical concerns hinder data acquisition in certain domains, such as healthcare or finance. Learning with limited supervision addresses these challenges by developing techniques that allow models to learn and make predictions with only a partial or a small number of supervision. In this presentation, we will introduce our research, which encompasses several advancements within the domain of learning with limited supervision. Initially, we introduce a novel fine-tuning method tailored to enhance the efficiency of few-shot learning, particularly in cross-domain scenarios. Building upon this, we extend our comprehension of few-shot fine-tuning into the transductive setting. Here, we present innovative weighting techniques to harness the potential of unlabeled data during the testing phase. In addition, we confront the intricate balance between data quality and quantity when leveraging unlabeled training data in semi-supervised learning. To address this challenge, we introduce the SoftMatch method, which allows for the adaptive integration of unlabeled data during training. [The dissertation citations contained here are published with the permission of ProQuest LLC. Further reproduction is prohibited without permission. Copies of dissertations may be obtained by Telephone (800) 1-800-521-0600. Web page: http://www.proquest.com/en-US/products/dissertations/individuals.shtml.]
ISBN - 979-8-3814-0170-7
GR  - W911NF20D0002
GR  - AWD00000001
GR  - A025452
PT  - Dissertations/Theses - Doctoral Dissertations

OWN - ERIC
TI  - An Exploratory Study of the ChatGPT Use of Vietnamese Graduate Students in a Research Writing Course
AU  - Vu Phi Ho Pham
AU  - Nhung Hong Nguyen
OT  - Graduate Students
OT  - Writing Instruction
OT  - Technology Integration
OT  - Computer Software
OT  - Artificial Intelligence
OT  - Feedback (Response)
OT  - Research Training
OT  - Foreign Countries
OT  - Universities
OT  - Student Attitudes
OT  - Help Seeking
OT  - College Faculty
OT  - Teacher Role
OT  - Second Language Learning
OT  - Second Language Instruction
OT  - English (Second Language)
OT  - Masters Programs
OT  - Metacognition
OT  - Critical Thinking
OT  - Task Analysis
OT  - Ethics
OT  - Majors (Students)
OT  - Academic Language
JT  - Online Submission
OID - ED672945
DP  - 2025
LID - http://eric.ed.gov/?id=ED672945
AB  - This exploratory qualitative study aims to explore the ChatGPT use of Van-Lang-University graduate students in a research writing course and the cognitive levels of their reactions to its responses. The data was collected from observations and interviews with twelve Vietnamese graduate students studying in a research writing class at this university. According to the findings, the participants opted for ChatGPT as a help-seeking strategy during their course due to several reasons including its convenience, instant feedback, and multifunction. Additionally, they had critical reactions to ChatGPT's feedback and advocated that ChatGPT could not replace lecturers' roles in future language classrooms. To develop the growth of critical ChatGPT use for research writing in Master's programs in English Language Studies at Van Lang University, actions from relevant stakeholders is required, including policymakers, lecturers teaching research writing, and MA students. [This chapter was published in: "Implementing AI Tools for Language Teaching and Learning," edited by Vu Phi Ho Pham, Andrew Lian, Ania Lian, and Sandro R. Barros, IGI Global Scientific Publishing, 2025, pp. 199-224.]
PT  - Reports - Research

OWN - ERIC
TI  - Developing and Validating the Competency Profile for Teaching and Learning Research Integrity
AU  - Jurij Selan
AU  - Mira Metljak
OT  - Profiles
OT  - Integrity
OT  - Content Validity
OT  - Questionnaires
OT  - Student Attitudes
OT  - Undergraduate Students
OT  - Graduate Students
OT  - Doctoral Students
OT  - Comparative Analysis
OT  - Scores
OT  - Item Analysis
OT  - Research Methodology
OT  - Research Training
OT  - Factor Analysis
OT  - Artificial Intelligence
OT  - Foreign Countries
OT  - Ethics
JT  - Center for Educational Policy Studies Journal
SO  - v13 n3 p33-74 2023
OID - EJ1406825
VI  - 13
IP  - 3
PG  - 33-74
DP  - 2023
LID - http://eric.ed.gov/?id=EJ1406825
AB  - Since research integrity is not external to research but an integral part of it, it should be integrated into research training. However, several hindrances regarding contemporary research integrity education exist. To address them, we have developed a competency profile for teaching and learning research integrity based on four assumptions: 1) to include all levels of study (BA, MA, and PhD); 2) to integrate research integrity into research education itself; 3) to address research integrity issues in context-specific practices; and 4) to pay particular attention to the "grey zone" or questionable research practices. To assess the validity of the content of the competency profile and to determine if some adjustments to the profile are needed, we translated the competencies of the profile into items of a measurement instrument (a questionnaire) and conducted a survey amongst University of Ljubljana students that allowed us to: 1) obtain information about students' attitudes toward issues of integrity in research; 2) analyse differences in these attitudes among BA, MA, and PhD students; and 3) statistically validate the competency profile and suggest possible improvements. The results showed that: 1) students are highly aware of research integrity issues, as scores were high on all items assessed. However, there were some deviations to lower scores, especially in relation to questionable research practises, confirming our assumption that the "grey zone" issues are those that should be particularly addressed and given special attention in contemporary research integrity education. 2) The differences in the attitudes of BA, MA, and PhD students showed that higher-level students showed significantly more awareness of integrity issues than lower-level students did, suggesting that research integrity issues should be given special attention at the BA study level. 3) The measurement characteristics showed that the reliability of the questionnaire was very high, suggesting a good overall structure of the competency profile. The principal component analysis also confirmed the four-field structure of the Competency profile (Values and Principles, Research Practise, Publication and Dissemination, and Violations). However, the analysis also showed that the substructure of the four main areas of the profile did not fully match the results of the factor analysis, suggesting that the distribution of competencies in the competency profile could be reconsidered, especially in the area of Research Practice. The most recent developments in the field of research integrity also suggest that the competency profile should be updated with issues regarding the impact of artificial intelligence on research integrity.
ISSN - ISSN-1855-9719
ISSN - EISSN-2232-2647
PT  - Journal Articles
PT  - Reports - Research
PT  - Tests/Questionnaires

OWN - ERIC
TI  - Beyond Single-Axis Analysis: Applying the Intersectional MAIHDA Method to Examine Disparities in Subjective Disciplinary Incidents
AU  - Anwesha Guha
AU  - Janette Avelar
AU  - Keith Zvoch
OT  - Discipline
OT  - Disproportionate Representation
OT  - Suspension
OT  - Intersectionality
OT  - Sex
OT  - Race
OT  - Ethnicity
OT  - English Learners
OT  - Students with Disabilities
OT  - Hierarchical Linear Modeling
OT  - Student Characteristics
JT  - Society for Research on Educational Effectiveness
AID - https://www.sree.org/2025-conference
OID - ED677715
DP  - 2025
LID - http://eric.ed.gov/?id=ED677715
AB  - Background: In the 2017-2018 school year, the Civil Rights Data Collection (CRDC) reported that more than 2.5 million students across the United States received at least one out-of-school suspension -- totaling to over 11 million days of learning loss from suspensions alone (Losen & Whitaker, 2018). While some of the reasons for suspension include "objective" incidents like tardiness and fighting, the most frequent types of offenses are "subjective," requiring an interpretation to evaluate whether a school behavior expectation has been violated (i.e., disruption and disobedience; Girvan et al., 2017). Exclusionary discipline -- defined as procedures that remove students from class as a form of disciplinary action -- impacts youth disproportionately across intersecting lines of marginalization, including gender, race, disability, and language (Muniz, 2021). While many studies have examined intersections along one or two axes of difference (e.g., Addington, 2023), few studies have been able to identify how the intersections of different sociodemographic identities together, or strata, correlate with subjective discipline incident (SDI) experiences. To investigate the specific axes of inequality along which SDIs operate, we apply the Intersectional Multilevel Analysis of Individual Heterogeneity and Discriminatory Accuracy (IMAIHDA) modeling framework. I-MAIHDA nests individual students within intersectional strata, partitioning variance within and between strata (Evans et al., 2018) to identify the specific identity combinations most associated with exclusionary outcomes and the disparities between and within them. Purpose: This descriptive study used I-MAIHDA to examine how suspensions due to SDIs varied across student identities of gender, race/ethnicity, language status, and disability status simultaneously. Integrating theories of intersectionality and building on MAIHDA and multilevel analytic frameworks, we used I-MAIHDA to examine 1) the extent to which both in-school and out-of-school suspensions vary across intersectional strata, and 2) if disparities in discipline are more pronounced for certain intersections. We hypothesized that multiply marginalized students would be subject to the most SDIs, as suggested by previous literature. However, we were also interested in how patterns shift when examined in tandem. This study is exploratory in identifying which axes, when combined with others, were subject to the most inequality. Setting and Participants: The study drew on statewide student-level administrative data from Oregon's state longitudinal data system (SLDS). The sample included six 9th grade cohorts (2013-14 to 2018-19), totaling about 263,000 students across the state. Outcome: SDIs rely on staff judgment to determine behavior violations (Skiba et al., 2002), allowing for bias to impact decision-making (McIntosh et al., 2018). Yet, SDIs were among the most frequently selected offense type in the dataset. In the SLDS, these included the following codes: Disorderly Conduct (Disruptive Behavior); Insubordination (Disobedience); and Violation of School Rules (Disobeying School Policy). The primary outcome compared students who received one or more SDIs at all to peers who received no disciplinary action. Method: Intersectionality is essential in theorizing inequities (Collins et al., 2021; Crenshaw, 1991).To quantitatively operationalize this framework, we applied I-MAIHDA, an interdisciplinary multilevel modeling approach developed in the health and social sciences to an education context (Evans et al., 2018; Keller et al., 2023; Prior et al., 2024). I-MAIHDA nests individuals (Level 1) within intersectional strata (Level 2) defined by combinations of identity markers to examine the extent to which complex interactions of individual characteristics associate with patterns of inequality, and if the observed inequities are more or less pronounced for certain intersectional identities. Compared to other linear regression and machine learning methods, I-MAIHDA provides estimates of heterogeneity between strata to quantify disparities in an outcome of interest (e.g., exclusionary discipline), while preserving its scalability and model parsimony (Mahendran et al., 2022). Although I-MAIHDA has been increasingly used in epidemiology to identify patterns of inequality across health outcomes (Axelsson Fisk et al., 2018; Evans et al., 2018), the method has not been used to examine exclusionary discipline in school-based contexts. We estimated two models. The level 1 random-intercept null model estimates the extent to which intersectional strata explain overall variation in student outcomes and quantifies the total degree of inequality between strata. Level 2 incorporates sociodemographic characteristics to evaluate the relative contribution of main effects versus interactive effects in explaining variation in individual outcomes (e.g., exclusionary discipline) across intersectional strata. By partitioning the variance within and between strata, the I-MAIHDA approach facilitates the identification of intersectional effects at the strata level and estimates the discriminatory accuracy of these strata for predicting individual outcomes across multiple axes of social identity. Findings/Results: The I-MAIHDA models identified substantial heterogeneity in discipline across strata. The most frequently suspended strata included Black boys with special education (SPED) services, regardless of English learner (EL) classification, with a predicted suspension probability of over 80% (see Figure 1). All the top ten most suspended strata include male-identifying students in SPED, with race and language status varying across groups. In contrast, the two least frequently suspended strata were Asian-identifying and female-identifying students, regardless of language status. Conclusions: The relationship between schools and discipline has been defined as "a web of intertwined, punitive threads [that] captures the historic, systemic, and multifaceted nature of the intersections of education and incarceration" (Meiners, 2010, p. 32). This study endorses the complex frame of discipline by showing how multiple axes of identity shape students' likelihood of receiving SDIs -- fitting well into the 2025 conference theme of "Education in Context." Findings affirm prior research on the overrepresentation of male-identifying students, students of color, and students with disabilities in exclusionary discipline and highlight the unique risk facing students at the intersection of these identities. Patterns were especially pronounced for boys receiving SPED services, suggesting that ableism and sexism may compound risk and are important context in designing and interpreting targeted causal studies. The results underscore the need for professional learning that engages with multiple, intersecting forms of bias that may surface at vulnerable decision points (Sanchez et al., 2025). For example, implicit bias trainings could inform how deficit-based beliefs about masculinity, disability, race, and language shape disciplinary practices. For instance, empowering students through self-advocacy and broadening teacher knowledge of learning styles is critical for Black boys with disabilities (Banks, 2017).
GR  - R305S210005
PT  - Reports - Research

OWN - ERIC
TI  - Cognification in Learning, Teaching, and Training
AU  - Kumar, Vivekanandan
AU  - Ally, Mohamed
AU  - Tsinakos, Avgoustos
AU  - Norman, Helmi
OT  - Electronic Learning
OT  - Cognitive Processes
OT  - Artificial Intelligence
OT  - Educational Technology
OT  - Blended Learning
OT  - Data Analysis
OT  - Educational Change
OT  - Educational Trends
OT  - Models
OT  - Democracy
OT  - Lifelong Learning
OT  - Ethics
OT  - Decision Making
JT  - Canadian Journal of Learning and Technology
SO  - v48 n4 2022
OID - EJ1374731
VI  - 48
IP  - 4
DP  - 2022
LID - http://eric.ed.gov/?id=EJ1374731
AB  - Over the past decade, opportunities for online learning have dramatically increased. Learners around the world now have digital access to a wide array of corporate trainings, certifications, comprehensive academic degree programs, and other educational and training options. Some organizations are blending traditional instruction methods with online technologies. Blended learning generates large volumes of data about both the content (quality and usage) and the learners (study habits and learning outcomes). Correspondingly, the need to properly process voluminous, continuous, and often disparate data has prompted the advent of cognification. Cognification techniques design complex data analytic models that allow natural intelligence to engage artificial smartness in ways that can enhance the learning experience. Cognification is the approach to make something increasingly, ethically, and regulatably smarter. This article highlights how emerging trends in cognification could disrupt online education.
ISSN - ISSN-1499-6677
ISSN - EISSN-1499-6685
LA  - English
PT  - Journal Articles
PT  - Reports - Descriptive

OWN - ERIC
TI  - Estimating the Treatment Effect Heterogeneity of Providing Performance Information in Education: A Causal Forests Approach
AU  - Xinjie Zhang
AU  - Yi Wei
AU  - Yingquan Song
AU  - Feifan Zhang
OT  - Foreign Countries
OT  - Artificial Intelligence
OT  - Randomized Controlled Trials
OT  - Research Methodology
OT  - Low Income
OT  - Rural Areas
OT  - Elementary School Students
OT  - Middle School Students
OT  - High School Students
OT  - Academic Achievement
OT  - Parent Student Relationship
OT  - Intervention
OT  - Parent Attitudes
OT  - Family Characteristics
JT  - Society for Research on Educational Effectiveness
AID - https://www.sree.org/2025-conference
OID - ED677798
DP  - 2025
LID - http://eric.ed.gov/?id=ED677798
AB  - Background/Context: Efforts to mitigate information asymmetry between parents and their children regarding academic performance have become a common practice among governments and K-12 educational institutions globally, with the aim of improving educational outcomes (Barrera-Osorio et al., 2020; Berlinski et al., 2022; Dizon-Ross, 2019; Kraft & Dougherty, 2013). These efforts are grounded in evidence from simple average treatment effect estimations, which suggest that, on average, providing parents with information about their children's academic progress can improve educational investments made by families (Andrabi et al., 2017), thereby enhancing children's academic achievement (Barrera-Osorio et al., 2020). However, the simple average treatment effect estimations are limited in their ability to identify critical heterogeneities in the changes of family educational investment that may result from such information interventions. That is, families exhibit significant variability in their characteristics, which may differently respond to such interventions and moderate their treatment effects on family educational investment. Understanding these heterogeneities is crucial, particularly in the context of large-scale educational policies like the widespread distribution of report cards to parents. It is possible that some families may significantly increase their educational investment when provided with better information about their children's academic performance, indicating that such families could benefit most from targeted interventions. Conversely, certain families may not increase, or may even decrease, their educational investment in response to the same information, suggesting that these families might not benefit from, or could even be adversely affected by, such interventions. This underscores the importance of tailoring educational policies to account for the diverse ways in which different families respond to academic information. Purpose/Objective/Research Question: Classical approaches to estimating heterogeneity using ordinary least squares (OLS) are prone to producing spurious findings due to insufficient statistical power (Assmann et al., 2000) or model misspecification (Zheng & Yin, 2023) and may miss valuable but unexpected treatment effect heterogeneity because of pre-analysis plan constraints (Wager & Athey, 2018). To address the limitations of the OLS estimator, this study employs a novel approach that integrates Randomized Controlled Trials (RCTs) with Machine Learning (ML) techniques. This combined methodology aims to more accurately estimate the heterogeneous treatment effects of reducing information frictions between parents and children regarding academic performance, specifically on families' human capital investments. RCT is widely recognized as the gold standard in social sciences due to their ability to provide robust causal evidence by eliminating confounding factors. ML has become a powerful tool for drawing statistical inference in high dimensional and complex covariate interactions settings (Chernozhukov et al., 2018; Wager & Athey, 2018). Setting: The setting for the experiment is in Yunxian County in southwestern China, which is among the 585 poorest counties in the country. The per capita annual income in this county is RMB 2,300 (approximately 328.57 US dollars). Population/Participants/Subjects: The research focuses on 201 low-income villages along the Myanmar border in one of 585 poorest counties in rural China. Most of the research participants have limited educational attainment: 51.98% of parents have only elementary education, and 31.02% have completed middle school. Additionally, approximately 80% of the parents are villagers. 52.31% of the families belong to ethnic minorities. The annual household income is approximately RMB21,650 ($3,092). These families face significant barriers to education and economic mobility. The research participants also include 7,500 children in grades 3 through 10, whose ages primarily range from 9 to 16 at the baseline in 2023. Among these children, 51.19% are primary school students aged 9 to 13, 43.29% are middle school students aged 13 to 15, and 5.52% are high school students aged 16. Intervention/Program/Practice: The intervention begins in January 2024. Parents in the treatment group receive information about their children's academic performance from the 2023 fall midterm, fall final, and 2024 spring midterm exams through three rounds of phone call interventions. The control group does not receive this information. For each of the three exams (2023 fall midterm, 2023 fall final, and 2024 spring midterm) during the intervention phase, this study conducts two contacts with the parents from whom the baseline data is collected: an initial contact and a follow-up contact. During the initial contact, enumerators first assess parents' beliefs about their children's performance on a specific exam for both the treatment and control groups. Parents in the treatment group are then provided with actual academic performance information about their children. The follow-up contact takes place one month after the initial contact, during which enumerators ask the same questions to assess how parents update their beliefs. Both the initial and follow-up contacts are conducted for parents in both the treatment and control groups, with the only difference being that parents in the treatment group are provided with their children's actual academic performance information. Each subsequent contact is conducted with parents who are successfully contacted during the previous round. Research Design: This study takes an innovative approach by using a simple yet effective intervention--providing parents with academic information--to address a longstanding economic question: the relationship between children's academic ability and family educational investment. By leveraging randomized information shocks, the study mitigates endogeneity concerns, offering a clearer understanding of how parental investment decisions respond to new information. The experiment is conducted across all 201 villages in the county and consists of five phases: sample selection, baseline data collection, randomization, intervention, and endline data collection. Sample selection: This study's sample inclusion criteria requires that households have two children enrolled in 3rd through 10th grade during the 2023-2024 academic year at the research site. This study screens 4,809 eligible households using administrative records on school attendance from the local Education Bureau. Of these, 3,750 households (77.98%) agree to participate and complete the baseline surveys. Therefore, the research sample comprises 7,500 parent-child pairs from 3,750 households. Table A.1 presents the statistical power of the experiment, with a minimum detectable effect size of 0.064 standard deviations. In the study, the sampled parents predominantly belong to low-SES populations (Table A.2). 63% of the parents have attained only a primary school education. Approximately 80% of the parents are villagers. The annual household income is approximately RMB21,650 to RMB22,337 ($3,092 to $3,191). Baseline data collection: The baseline data collection begins in May 2023, gathering survey data from 3,750 households through either a parent or legal guardian. Randomization: After the baseline, I conduct a stratified randomization at the household level, assigning 1,878 households to the treatment group and 1,872 households to the control group. The stratification variables used include: 1) villages, 2) belief bias below the lower bound of the tri-sectional quantile, 3) belief bias above the higher bound of the tri-sectional quantile, and 4) median income. After randomization, I employ two methods to test the equivalence between the two groups: 1) individual regressions of each variable on a treatment dummy, and 2) a joint F-test. The balance check confirms that the two groups are equivalent: 1) none of the 90 variables is statistically significant at the 10% level in the individual regressions, and 2) the p - value of the joint F-test for the 90 variables is 0.7024, failing to reject the null hypothesis that there are no differences between the groups. Table A.2 presents the summary statistics and balance test results. Intervention: The intervention is launched in January 2024. Parents in the treatment group receive information about their children's academic performance from the 2023 fall semester's midterm, final, and 2024 spring semester's midterm exams during the 2023-2024 academic year. This information is communicated through three rounds of phone call interventions. The remaining households in the control group do not receive this information. Endline data collection: The endline data collection is scheduled to take place from November 2024 to May 2025. Data Collection and Analysis: This study collects household survey data across three phases of the experiment: baseline, intervention, and endline. This study collects the following information from household surveys at the baseline and endline: 1) socioeconomic status, such as parents' income and educational attainment; 2) perceptions about education, school, and teachers, 3) beliefs about the children's academic performance, 4) allocation of educational investments (time, energy, and finances) between siblings, and 5) ticket allocation between siblings in the lab-in-the-field experiment. Moreover, during the intervention phase, we gather data on parents' test score perceptions, grade ranking, and estimated college admission probabilities. Finally, this study collects student academic performance data for each child from the unified exams administered by the local education bureau throughout the entire experiment. This data includes the absolute test scores in Chinese, math, and English, as well as each student's ranking within their class, grade
PT  - Reports - Research

OWN - ERIC
TI  - Supporting Students' Math Achievement with Adaptive and Game-Based EdTech: A Longitudinal Efficacy Study of ExploreLearning's Frax Program
AU  - Megan Conrad
AU  - David Shuster
OT  - Mathematics Achievement
OT  - Game Based Learning
OT  - Educational Technology
OT  - Fractions
OT  - Intervention
OT  - Program Effectiveness
OT  - Elementary School Students
OT  - Mathematics Education
OT  - Student Improvement
OT  - Academic Ability
OT  - Grade 3
OT  - Grade 4
OT  - Suburban Schools
OT  - Public Schools
JT  - Society for Research on Educational Effectiveness
AID - https://www.sree.org/2024-conference
OID - ED663574
DP  - 2024
LID - http://eric.ed.gov/?id=ED663574
AB  - Background: Performance with fractions has been a weak point in U.S. education for decades and has not improved in recent years (Siegler, 2017). High School math teachers frequently rate their students' knowledge of fractions as "poor" and see this lack of foundational knowledge as one of the top barriers to students mastering algebra (Hoffer et al., 2007). Prior research has found that fractions knowledge in 5th grade uniquely predicts mathematics achievement in high school, even after controlling for variables like general intellectual ability, working memory, and family income and education levels (Siegler et al., 2012). EdTech has the potential to deliver personalized classroom interventions at scale to improve fractions knowledge in a manner that is both efficient and effective. The current study tests the impact of Frax: a game-based, adaptive learning program that uses research-based instructional methods to support foundational fractions skills. Research Questions: A two-year longitudinal study (Fall 2021 through Spring 2023) with elementary school students was conducted to measure the impact of Frax usage on fractions knowledge and mathematics achievement. The study used a quasi-experimental methodology with case-control matching to create equivalent student groups at baseline. Student product usage and math performance were measured in collaboration with the school district. The study aimed to address the following research questions: (1) Does usage of the Frax program improve students' performance on standardized math assessments? (2) Do students who use the Frax program with fidelity show greater improvement on math assessments over time compared to matched, control students? (3) Do the effects of the Frax program vary for students of different ability levels? Participants: The sample (Table 1) included 2,440 3rd-grade and 2,620 4th-grade students from a large, suburban public school district in the southeastern United States. The district's minority enrollment is over 60% and 35% of students are economically disadvantaged. The sample consisted of 35% Hispanic/Latino and 15% Black/African American students. The majority of students, 79%, scored at least 1 grade level below standards on the baseline math test. Intervention: The Frax Foundations I program, broadly aligned to 3rd-grade fractions standards, contains 27 lessons (Missions) which take 30 minutes each to complete. Lessons are typically completed in class with teachers monitoring student progress to deliver real-time support. Frax is designed as a zero-entry program; students with no previous knowledge of fractions can begin using the program immediately. The Frax approach teaches students that fractions are numbers with magnitude like any other number. Students practice these concepts through explicit, scaffolded use of length models, number lines, and measurements. Students build the conceptual foundation they need to move on to fractions arithmetic. The adaptive algorithms behind Frax are designed to maximize student engagement and motivation, automatically recognizing and delivering the right level of support to students. This creates individualized, efficient instruction that intentionally moves each student toward mastery. Research Design: This study used a quasi-experimental, case-control matching design. All 3rd-5th grade teachers in the district had access to the Frax program and were eligible to receive professional development. Program usage was measured by the number of missions students completed each year. Baseline achievement was quantified by Fall 2021 i-Ready Diagnostic Assessment math scale scores and performance relative to grade-level proficiency (2+ grade levels below, 1-grade level below, on grade level or above). Matching was conducted in Spring 2022, creating matched pairs of Frax users and non-users on current grade level (3rd, 4th) and Fall 2021 i-Ready math scale scores (±5 points). Early growth (Spring 2022 and Fall 2022) was measured by the I-Ready Diagnostics assessment. In Spring 2023, the district moved to a state-specific diagnostic test. Overall math scale scores, fractions subscale scores, and relative achievement categories (below standards, at/near standards, and above standards) were used to determine the impact of Frax usage on student math growth. Analysis: SPSS was used for all analyses. Paired samples t-tests and standardized effect sizes (Hedge's g) were used to determine the magnitude of gains in test scores comparing across matched users and non-users. Categorical 2x2 chi-square tests were used to look at the likelihood of meeting grade level expectations for users and non-users. Findings/Results: Results from Year 1 found that fidelity program usage led to statistically significantly greater improvement in math compared to paired non-users. Compared to previous metanalyses (Lipsey et al., 2012), Frax was 3x more effective at improving math scores than the average educational intervention for 3rd graders and 5x more effective for 4th graders (Table 2). Frax usage was also related to students' achievement of grade level proficiency; 47% of high Frax users met grade level expectations in the spring compared to only 31% of students in the control group, X[superscript 2 ](1, N = 1008) = 4.65, p = 0.031. Importantly, this effect was observed for students within every student baseline achievement category (Figure 1). The results from year 2 found that the achievement gains associated with Frax usage in year 1 were sustained: in Spring 2023 high Frax users had significantly higher overall math scores, t(170) = 4.044, p < 0.001, and were significantly more likely to score above standards on the Fractions subscale, X[superscript 2] (1, N = 342) = 5.78, p = 0.016, compared to their matched non-users (Figure 2). Importantly, control students in Year 1 who went on to use Frax in Year 2 also showed significant achievement gains, fully catching up to or exceeding their Year 1 matched peers (Table 3). Conclusions: EdTech has the potential to support significant learning gains for all learners while alleviating the heavy burden associated with delivering individualized instruction. The current study provides evidence that the Frax program is an efficient and effective way to support fractions knowledge and math achievement. Efforts to control for potential bias were used in the current study, including creating equivalent groups, but future research should be conducted using an experimental methodology with students from multiple districts. Continued efforts to measure program efficacy and support evidence-based implementations must be collaboratively embraced by vendors, researchers, and school administrators.
PT  - Reports - Research

OWN - ERIC
TI  - De-Identifying Student Personally Identifying Information in Discussion Forum Posts with Large Language Models
AU  - Andres Felipe Zambrano
AU  - Shreya Singhal
AU  - Maciej Pankiewicz
AU  - Ryan Shaun Baker
AU  - Chelsea Porter
AU  - Xiner Liu
OT  - Artificial Intelligence
OT  - Identification
OT  - Privacy
OT  - Information Security
OT  - Discussion Groups
OT  - MOOCs
OT  - College Students
JT  - Information and Learning Sciences
SO  - v126 n5-6 p401-424 2025
AID - http://dx.doi.org/10.1108/ILS-11-2024-0156
OID - EJ1473727
VI  - 126
PG  - 401-424
DP  - 2025
LID - http://eric.ed.gov/?id=EJ1473727
AB  - Purpose: This study aims to evaluate the effectiveness of three large language models (LLMs), GPT-4o, Llama 3.3 70B and Llama 3.1 8B, in redacting personally identifying information (PII) from forum data in massive open online courses (MOOCs). Design/methodology/approach: Forum posts from students enrolled in nine MOOCs were redacted by three human reviewers. The GPT and Llama models were then tasked with de-identifying the same data set using standardized prompts. Discrepancies between LLM and human redactions were analyzed to identify patterns in LLM errors. Findings: All models achieved an average recall of over 0.9 in identifying PII and identified PII instances overlooked by humans. However, their precisions were lower -- 0.579 for GPT-4o, 0.506 for Llama 3.3 and 0.262 for Llama 3.1 -- showing a tendency to over-redact non-PII names and locations. Research limitations/implications: Several courses' data were analyzed to increase findings' generalizability but the models' performance may vary in other contexts. GPT and Llama models were selected because of their availability and cost-effectiveness at the time of the study; future newer models may improve performance. Practical implications: The use of downloadable LLMs enables researchers to de-identify data without training specialized models or involving external companies, ensuring that student data remains private. Originality/value: Previous research on LLM text de-identification has largely used proprietary models, which require sharing data containing sensitive PII with third-party companies. This study evaluates the performance of two open weight models that can be deployed locally, eliminating the need to share sensitive data externally.
ISSN - ISSN-2398-5348
ISSN - EISSN-2398-5356
LA  - English
PT  - Journal Articles
PT  - Reports - Research

OWN - ERIC
TI  - Smart Learning Environments in the Post Pandemic Era. Selected Papers from the CELDA 2022 Conference. Cognition and Exploratory Learning in the Digital Age
AU  - Demetrios G. Sampson, Editor
AU  - Dirk Ifenthaler, Editor
AU  - Pedro Isaías, Editor
OT  - Teaching Methods
OT  - Influence of Technology
OT  - Educational Technology
OT  - Professional Development
OT  - COVID-19
OT  - Learning Analytics
OT  - Data
OT  - Computer Simulation
OT  - Behavior Patterns
OT  - Evaluation
OT  - Electronic Learning
OT  - Augmentative and Alternative Communication
OT  - Programming
OT  - Educational Games
OT  - Open Educational Resources
OT  - Ethics
OT  - Blended Learning
OT  - Artificial Intelligence
JT  - Cognition and Exploratory Learning in the Digital Age
AID - https://doi.org/10.1007/978-3-031-54207-7
OID - ED656589
DP  - 2024
LID - http://eric.ed.gov/?id=ED656589
AB  - This edited volume presents the latest research focussing on current challenges on the deployment of smart technologies and pedagogies for supporting teaching and learning in the post-covid19 era. This is at the core of studying the evolution of the learning process, the role of technology-supported pedagogical approaches, and the progress of educational technology innovations in the context of digital transformation in education and professional training. A selection of the best papers from the Cognition and Exploratory Learning in the Digital Age (CELDA) Conference, 2022 are included in this volume, bringing together high-quality research on Smart Pedagogies in the Post-Pandemic Era; Smart Learning Technologies in the Post-Pandemic Era; and Case Studies of Smart Learning Environments. The volume contributes to the discussion of current issues in digital education between researchers, practitioners, and policymakers.
ISBN - 978-3-031-54206-0
ISSN - ISSN-2662-5628
ISSN - EISSN-2662-5636
LA  - English
PT  - Books
PT  - Collected Works - General
PT  - Reports - Research

OWN - ERIC
TI  - Accountability in Higher Education: Navigating Current Issues and Trends
AU  - Topeka Small Singleton
OT  - Accountability
OT  - Higher Education
OT  - Educational Trends
OT  - Educational Benefits
OT  - Equal Education
OT  - Diversity
OT  - Inclusion
OT  - Ethics
OT  - Educational Finance
OT  - Mental Health
OT  - Wellness
OT  - Leadership
OT  - Artificial Intelligence
OT  - Accreditation (Institutions)
OT  - Educational Quality
OT  - Quality Assurance
JT  - IGI Global
AID - https://dx.doi.org/10.4018/979-8-3693-7708-6
OID - ED671807
DP  - 2025
LID - http://eric.ed.gov/?id=ED671807
AB  - Accountability in higher education has become a critical issue as higher education institutions face scrutiny over student outcomes, financial transparency, and the value of a college degree. As the cost of tuition is on the rise and student debt growing, the concerns on equitability and the concerns of student engagement have left many in the public to lose trust in higher education. From government regulations to accreditation standards and data-driven assessment models, accountability measures are evolving to ensure that higher education remains both effective and accessible. As the public become more distrustful of higher education, discussing the problems issues is effective in seeking change. "Accountability in Higher Education: Navigating Current Issues and Trends" explores the current trends and issues with accountability in higher education. It discusses how accountability in higher education is essential and is the most impactful. This book covers topics such as accountability, diversity and inclusion, and educational training, and is a useful resource higher education professionals who seek to know more about navigating the landscape of accountability in higher education.
ISBN - 979-8-3693-7708-6
PT  - Books
PT  - Collected Works - General

OWN - ERIC
TI  - University Undergraduates' Perceptions on the Use of ChatGPT for Academic Purposes: Evidence from a University in Czech Republic
AU  - Blanka Klimova
AU  - Victor Paiva Luz de Campos
OT  - Undergraduate Students
OT  - Undergraduate Study
OT  - Student Attitudes
OT  - Artificial Intelligence
OT  - Technology Uses in Education
OT  - Natural Language Processing
OT  - Foreign Countries
OT  - Opportunities
OT  - Barriers
OT  - Technology Integration
OT  - Graduate Students
OT  - Graduate Study
OT  - Information Science
OT  - Research
OT  - Concept Formation
OT  - Usability
OT  - Accuracy
OT  - Reliability
OT  - Ethics
JT  - Cogent Education
SO  - v11 n1 Article 2373512 2024
AID - http://dx.doi.org/10.1080/2331186X.2024.2373512
OID - EJ1454195
VI  - 11
IP  - 1
DP  - Article 2373512 2024
LID - http://eric.ed.gov/?id=EJ1454195
AB  - At present, ChatGPT is penetrating all spheres of human activities, and especially education is no exception. The purpose of this exploratory study is to examine the potentials and pitfalls of using ChatGPT for academic purposes among university students, as well as provide relevant pedagogical implications for its use in academia. The methodology is based on a mix-method approach, i.e. both quantitative and qualitative by analysing an online questionnaire that was distributed among both Czech and foreign students at a university in the Czech Republic. The findings of this study reveal ChatGPT's burgeoning significance as an academic instrument, alongside concerns regarding its constraints and potential misuse. Most students employ ChatGPT for academic purposes, as demonstrated by the favorable feedback it receives for its effectiveness in facilitating research, stimulating idea generation, promoting comprehension of intricate concepts, and furnishing prompt responses. Hence, ChatGPT embodies promise for forthcoming generations regarding its capacity to augment educational programs, potentially fostering greater efficiency and interactivity in the learning process. Nevertheless, a critical apprehension lies in students excessively relying on ChatGPT, which may impede the cultivation of vital skills, such as critical thinking and problem-solving. Therefore, the authors of this study provide several pedagogical implications for its use in academia, such as using ChatGPT as a supportive tool in classes, as well as using it for collaborative work and group tasks since ChatGPT promotes sharing information, faster collection of data, providing diverse and creative ideas, or speed communication. Another important pedagogical implication is raising awareness of ethical guidelines, given that many students remain oblivious to them, necessitating the training of teachers to impart ethical usage of ChatGPT. Finally, the results of this study align with several educational theories, such as constructivism or self-determination theory.
ISSN - EISSN-2331-186X
LA  - English
PT  - Journal Articles
PT  - Reports - Research
PT  - Tests/Questionnaires

OWN - ERIC
TI  - Proceedings of International Conference on Social and Education Sciences (IConSES) (Chicago, Illinois, October 17-20, 2024). Volume 1
AU  - Valarie Akerson, Editor
AU  - Ozkan Akman, Editor
AU  - M. Lutfi Ciddi, Editor
OT  - Higher Education
OT  - Ethics
OT  - Technology Uses in Education
OT  - Mathematics Education
OT  - College Students
OT  - Social Sciences
OT  - Foreign Countries
OT  - Special Education Teachers
OT  - Teacher Role
OT  - Dictionaries
OT  - Second Language Instruction
OT  - Uncommonly Taught Languages
OT  - Informed Consent
OT  - Social Science Research
OT  - Educational Research
OT  - Artificial Intelligence
OT  - Academic Achievement
OT  - Physics
OT  - Science Instruction
OT  - COVID-19
OT  - Pandemics
OT  - Scientific Concepts
OT  - Student Research
OT  - Engineering Education
OT  - Leadership Training
OT  - Computer Games
OT  - Athletics
OT  - Values
OT  - Black Colleges
OT  - Business Education
OT  - Multilingualism
OT  - Bilingual Teachers
OT  - Online Courses
OT  - Handicrafts
OT  - Cultural Influences
OT  - Distance Education
OT  - Educational Technology
JT  - International Society for Technology, Education, and Science
OID - ED671809
DP  - 2024
LID - http://eric.ed.gov/?id=ED671809
AB  - "Proceedings of International Conference on Social and Education Sciences" includes full papers presented at the International Conference on Social and Education Sciences (IConSES), which took place on October 17-20, 2024, in Chicago, Illinois. The aim of the conference is to offer opportunities to share ideas, discuss theoretical and practical issues, and to connect with the leaders in the fields of education and social sciences. The IConSES invites submissions that address the theory, research, or applications in all disciplines of education and social sciences. The IConSES is organized for: faculty members in all disciplines of education and social sciences, graduate students, K-12 administrators, teachers, principals, and all interested in education and social sciences. [Individual papers are indexed in ERIC.]
ISBN - 978-1-952092-72-5
PT  - Books
PT  - Collected Works - Proceedings

OWN - ERIC
TI  - Proceedings of International Conference on Studies in Education and Social Sciences (ICSES) (Istanbul, Turkey, November 7-10, 2024). Volume 1
AU  - Mahmut Sami Ozturk, Editor
AU  - Abdullatif Kaban, Editor
AU  - Mevlut Unal, Editor
OT  - Metacognition
OT  - Preservice Teachers
OT  - Mathematics Teachers
OT  - Foreign Countries
OT  - Conservation (Environment)
OT  - Racism
OT  - Ethnic Groups
OT  - Social Discrimination
OT  - Team Sports
OT  - Curriculum Implementation
OT  - Cognitive Processes
OT  - English (Second Language)
OT  - Theses
OT  - Writing (Composition)
OT  - College Faculty
OT  - Teacher Effectiveness
OT  - Prevention
OT  - Child Abuse
OT  - Marriage
OT  - High School Students
OT  - Females
OT  - Training
OT  - Elementary Education
OT  - Social Studies
OT  - Student Attitudes
OT  - Teacher Motivation
OT  - Artificial Intelligence
OT  - Expectation
OT  - Value Judgment
OT  - Evaluation Methods
OT  - Cognitive Style
OT  - College Students
OT  - Climate
OT  - Proverbs
OT  - Natural Disasters
OT  - Counselor Role
OT  - Psychological Patterns
OT  - Well Being
OT  - Cultural Maintenance
OT  - World History
OT  - Cultural Influences
JT  - International Society for Technology, Education, and Science
OID - ED672802
DP  - 2024
LID - http://eric.ed.gov/?id=ED672802
AB  - "Proceedings of International Conference on Studies in Education and Social Sciences" includes full papers presented at the International Conference on Studies in Education and Social Sciences (ICSES) which took place on November 7-10, 2024, in Istanbul, Turkey. The aim of the conference is to offer opportunities to share ideas, discuss theoretical and practical issues, and to connect with the leaders in the fields of education and social sciences. The conference is organized annually by the International Society for Technology, Education, and Science (ISTES). The ICSES invites submissions which address the theory, research, or applications in all disciplines of education and social sciences. The ICSES is organized for: faculty members in all disciplines of education and social sciences, graduate students, K-12 administrators, teachers, principals, and all interested in education and social sciences. [Individual papers are indexed in ERIC.]
ISBN - 978-1-952092-14-5
PT  - Books
PT  - Collected Works - Proceedings

