[
  {
    "source": "semantic_scholar",
    "source_id": "08127aa0f141b9be6b391664db028d4dd2a37232",
    "title": "Managing Transparency Fairness Accountability in AI for Sustainable Human Resource Management",
    "authors": [
      "Rini Setiawati",
      "Ardi Kusmara",
      "Taavi Kuusk"
    ],
    "year": 2025,
    "abstract": "The proliferation of Artificial Intelligence (AI) in Human Resource Management (HRM) offers significant efficiencies but concurrently introduces critical ethical challenges regarding transparency, fairness, and accountability, thereby impacting sustainable workforce management. The novelty of this study lies in its exploration of strategies for effectively managing these ethical dimensions in AI-driven HRM, with a focus on identifying practical solutions to mitigate algorithmic bias and enhance transparency. The research focuses on identifying ethical issues, such as algorithmic bias and lack of transparency in AI-assisted recruitment, performance evaluation, and overall employee management. Adopting a Systematic Literature Review (SLR) methodology, this paper analyzes recent publications (2019-2024) from Scopus to synthesize existing knowledge on AI ethics in HRM. Key findings reveal a significant lack of standardized best practices and audit trails, with opaque AI-driven decisions often undermining trust and fairness. If not properly designed, AI algorithms can perpetuate biases embedded in historical data, leading to discriminatory outcomes, as evidenced by cases at companies like Amazon and HireVue. The study concludes that organizations must proactively implement robust governance frameworks, including ethics training, the development of transparent and fair-by-design algorithms, regular audits, and mechanisms for human oversight. Integrating frameworks such as Fairness, Accountability, and Transparency (FAT) and Ethical AI by Design is crucial for ensuring that AI applications in HRM are ethically sound, legally compliant, and contribute to sustainable and equitable workforce management.",
    "doi": "10.1109/ICCIT65724.2025.11166968",
    "url": "https://www.semanticscholar.org/paper/08127aa0f141b9be6b391664db028d4dd2a37232",
    "pdf_url": "",
    "venue": "International Conference on Communications and Information Technology",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.894980"
  },
  {
    "source": "semantic_scholar",
    "source_id": "7fc48e5cbc04f976bff6f6d92e19b0520d903ef0",
    "title": "Professional Ethics in Human Resource Management in the Era of Digital Transformation: Challenges and Opportunities",
    "authors": [
      "Dito Aditia Darma Nst",
      "Ela Diovera Niel",
      "Lismayana Eryanti Siregar",
      "Muti Lulu Habibah",
      "Elveria Melda Sinaga",
      "Nur Ainun Rahma Lubis",
      "M Falahul Anshor"
    ],
    "year": 2025,
    "abstract": "Digital transformation has significantly reshaped human resource management (HRM) through the adoption of Human Resource Information Systems (HRIS), artificial intelligence (AI), big data analytics, e-learning platforms, and remote work technologies. Although these innovations improve efficiency and decision-making, they also generate ethical challenges related to data privacy, algorithmic bias, transparency, and employee monitoring. This article examines the role of professional ethics in HRM within the context of digital transformation, highlighting both emerging challenges and potential opportunities. This study employs a conceptual research approach supported by a comprehensive literature review of scholarly works on HRM, professional ethics, and digitalization. The analysis focuses on core ethical principles such as integrity, fairness, responsibility, professionalism, and confidentiality, and evaluates their implementation in digital HR practices. The findings indicate that unethical use of digital technologies may lead to discrimination, reduced employee trust, and violations of individual rights, particularly through biased AI-based recruitment systems and opaque performance evaluation mechanisms. However, digital transformation also offers opportunities to strengthen ethical HR governance. The use of ethical data management, algorithmic audits, digital transparency, and e-learning-based ethics training can enhance accountability and fairness in HR processes. The study concludes that integrating professional ethics with digital HRM is essential for developing human-centered, sustainable, and trustworthy organizations in the digital era.",
    "doi": "10.61132/icmeb.v2i2.291",
    "url": "https://www.semanticscholar.org/paper/7fc48e5cbc04f976bff6f6d92e19b0520d903ef0",
    "pdf_url": "",
    "venue": "Proceeding of the International Conference on Management, Entrepreneurship, and Business",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.894998"
  },
  {
    "source": "semantic_scholar",
    "source_id": "fccd2b6ca6be4163a868c191b9153d52c6d6a036",
    "title": "Human Rights and Artificial Intelligence in Healthcare-Related Settings: A Grammar of Human Rights Approach.",
    "authors": [
      "Helga Molb\u00e6k-Steensig",
      "M. Scheinin"
    ],
    "year": 2025,
    "abstract": "This article examines the expanding role of Artificial Intelligence (AI) in healthcare and associated human rights concerns, including whether new EU legislation takes all relevant human rights concerns into account. AI presents promising ways to fulfil the right to health through improving diagnostics, treatments, and resource allocation, but its use also comes with risks concerning privacy, bias, discrimination, and human dignity. Existing literature often relies on the rather vague FATE (Fairness, Accountability, Transparency, Ethics) principles, but recent calls have been made for a human-rights-based approach more broadly to ensure the legality and ethics of AI applications. This article responds to that call by proposing a structured methodology for reconciling rights, considering both the different structures of civil and political versus economic, social and cultural human rights, the negative and positive obligations of the state, and the interplay with different AI design choices.",
    "doi": "10.1163/15718093-bja10146",
    "url": "https://www.semanticscholar.org/paper/fccd2b6ca6be4163a868c191b9153d52c6d6a036",
    "pdf_url": "",
    "venue": "European Journal of Health Law",
    "citation_count": 1,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:49.895006"
  },
  {
    "source": "semantic_scholar",
    "source_id": "53d4f0e7b936b541ccd72093527d4bb5b9aaa22a",
    "title": "Can HR adapt to the paradoxes of artificial intelligence?",
    "authors": [
      "Andy Charlwood",
      "Nigel Guenole"
    ],
    "year": 2022,
    "abstract": "Artificial intelligence (AI) is widely heralded as a new and revolutionary technology that will transform the world of work. While the impact of AI on human resource (HR) and people management is difficult to predict, the article considers potential scenarios for how AI will affect our field. We argue that although popular accounts of AI stress the risks of bias and unfairness, these problems are eminently solvable. However, the way that the AI industry is currently constituted and wider trends in the use of technology for organising work mean that there is a significant risk that AI use will degrade the quality of work. Viewing different scenarios through a paradox lens, we argue that both positive and negative visions of the future are likely to coexist. The HR profession has a degree of agency to shape the future if it chooses to use it; HR professionals need to develop the skills to ensure that ethics and fairness are at the centre of AI development for HR and people management.",
    "doi": "10.1111/1748-8583.12433",
    "url": "https://www.semanticscholar.org/paper/53d4f0e7b936b541ccd72093527d4bb5b9aaa22a",
    "pdf_url": "https://doi.org/10.1111/1748-8583.12433",
    "venue": "Human Resource Management Journal",
    "citation_count": 154,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895011"
  },
  {
    "source": "semantic_scholar",
    "source_id": "60704201f864cf64a66a562f6c4de7a9f52d9054",
    "title": "The emergence of \u201ctruth machines\u201d?: Artificial intelligence approaches to lie detection",
    "authors": [
      "Jo Ann Oravec"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1007/s10676-022-09621-6",
    "url": "https://www.semanticscholar.org/paper/60704201f864cf64a66a562f6c4de7a9f52d9054",
    "pdf_url": "",
    "venue": "Ethics and Information Technology",
    "citation_count": 30,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:49.895015"
  },
  {
    "source": "semantic_scholar",
    "source_id": "26ccb19d6cb2c18fe8e9f6bc29494e098dd5b90b",
    "title": "An Ethical Governance Framework for AI-Driven Competency Assessment",
    "authors": [],
    "year": 2025,
    "abstract": "The expanding application of artificial intelligence (AI) in human resource (HR) management for competency evaluation reflects organisations' pursuit of efficiency, yet this growth has outpaced the development of essential ethics and governance. This study aimed to determine sectoral differences in perceptions of AI-based evaluation and to develop a tool that balances efficiency with ethics. A small-scale mixed-methods pilot study with professionals in the energy (safety-critical) and education (empathy-based) sectors revealed attitudes differing by sector. While energy practitioners viewed AI as a promising tool for reducing bias in safety analysis, educators were more skeptical, emphasizing challenges around transparency, creativity, and contextual judgment. This paper introduces the Responsible AI Competence Assessment (RAICA) framework to address these governance gaps. RAICA extends the Technology Acceptance Model (TAM) through the addition of ethical trust, algorithmic fairness, and sector-sensitive validation metrics. Furthermore, the framework translates abstract policy instruments into actionable operational protocols, including mandates for bias auditing and algorithmic explainability. The proposed framework provides a flexible and practical governance template for high-stakes decision-making across diverse sectors by bridging efficiency and ethical accountability.",
    "doi": "10.55057/ijbtm.2025.7.11.10",
    "url": "https://www.semanticscholar.org/paper/26ccb19d6cb2c18fe8e9f6bc29494e098dd5b90b",
    "pdf_url": "",
    "venue": "International Journal of Business and Technology Management",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895020"
  },
  {
    "source": "semantic_scholar",
    "source_id": "dfd7bc2c8a4e4d9ef0e9658de53c28b65ca10987",
    "title": "Ethically Aligned Artificial Intelligence: Investigating Algorithmic Bias, Human Identity, and Posthuman Ethics through a Data-Driven Philosophical Lens",
    "authors": [
      "A. Alyousef",
      "Asem Omari"
    ],
    "year": 2025,
    "abstract": "Human society is being transformed by AI at an unprecedented speed-and in this context questions regarding fairness, agency, and identity become very tricky. This paper presents an interdisciplinary study into algorithmic bias and its ethical implicature in the relationship of data science and philosophy. By bringing into account concepts from posthumanism and moral theory, the research scrutinizes the redefinition of human identity within an age of autonomous systems and artificial consciousness. It proposes a data-oriented mechanism to the detection and mitigation of bias in AI systems, substantiated with case studies in health care and recruitment. One of the emphases of this work is on transparency, accountability, and inclusive governance, ultimately arguing for ethically aligned AI that promotes human dignity concurrent with evolving technological realities. Implications of this study point toward diversifying the development of a new ethical paradigm with the capability to regulate AI design, deployment, and policy.",
    "doi": "10.63332/joph.v5i5.1316",
    "url": "https://www.semanticscholar.org/paper/dfd7bc2c8a4e4d9ef0e9658de53c28b65ca10987",
    "pdf_url": "",
    "venue": "Journal of Posthumanism",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895024"
  },
  {
    "source": "semantic_scholar",
    "source_id": "bb3c1e07efa0b94a883b5d18a6135137f9b0dadb",
    "title": "Is Artificial Intelligence (AI) Research Biased and Conceptually Vague? A Systematic Review of Research on Bias and Discrimination in the context of using AI in Human Resource Management",
    "authors": [
      "Ivan Kekez",
      "Lode Lauwaert",
      "Nina Begi\u010devi\u0107 Re\u0111ep"
    ],
    "year": 2025,
    "abstract": null,
    "doi": "10.1016/j.techsoc.2025.102818",
    "url": "https://www.semanticscholar.org/paper/bb3c1e07efa0b94a883b5d18a6135137f9b0dadb",
    "pdf_url": "https://doi.org/10.1016/j.techsoc.2025.102818",
    "venue": "Technology and Society",
    "citation_count": 17,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895029"
  },
  {
    "source": "semantic_scholar",
    "source_id": "1f3b09fa5891b23452636914a1ffbd965f68a654",
    "title": "Artificial Intelligence Ethics: A Dialogue between Technological Advances and Human Values",
    "authors": [
      "Linji Fan"
    ],
    "year": 2024,
    "abstract": "The rapid development of artificial intelligence technology has already had a profound impact in various fields, ranging from healthcare and education to transport and finance. However, accompanying these technological advances are a series of complex and profound ethical issues. These issues involve not only data privacy and security, but also challenges of algorithmic bias, fairness, and transparency in decision-making. In addition, the \u2018black box\u2019 nature of AI systems blurs the attribution of responsibility and increases society's distrust of the technology. As AI is increasingly used in society, the question of how to find a balance between technological innovation and human values has become an urgent one. While technological advancement can certainly bring efficiency and convenience, the lack of ethical constraints may lead to privacy leakage, unfair decision-making and moral hazard. Therefore, it has become particularly important to establish a sound AI ethical framework to regulate the application of the technology, protect individual privacy, and ensure fairness and transparency. The establishment of an AI ethical framework is not only to regulate the application of the technology, but also to protect social justice and core human values. Through systematic ethical guidelines, moral considerations can be integrated into all stages of technology development and application, providing clear guidelines to help all parties use AI technology under the premise of legal compliance. At the same time, such an ethical framework can also help enhance public trust in AI and promote the healthy development of the technology in a wider range of fields. In conclusion, the rapid development of AI brings unprecedented opportunities and raises profound ethical challenges. We need to ensure the coordinated development of technological progress and social values by establishing a sound ethical framework, and promote AI to move forward in a more responsible, fairer and transparent direction. The combination of ethics and technology will become an important force to lead the future development of science and technology, bringing more benefits and progress to human society.",
    "doi": "10.54097/tvqkkf40",
    "url": "https://www.semanticscholar.org/paper/1f3b09fa5891b23452636914a1ffbd965f68a654",
    "pdf_url": "https://drpress.org/ojs/index.php/ijeh/article/download/22205/21741",
    "venue": "International Journal of Education and Humanities",
    "citation_count": 4,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895032"
  },
  {
    "source": "semantic_scholar",
    "source_id": "451f87249e1a6dd21c76b45b7cffda0a464127ab",
    "title": "The Impact of Artificial Intelligence Replacing Humans in Making Human Resource Management Decisions on Fairness: A Case of Resume Screening",
    "authors": [
      "Fei Cai",
      "Jiashu Zhang",
      "Lei Zhang"
    ],
    "year": 2024,
    "abstract": "A growing number of organizations have used artificial intelligence (AI) to make decisions to replace human resource (HR) workers; yet, the fairness perceptions of the people affected by the decision are still unclear. Given that an organization\u2019s sustainability is significantly influenced by individuals\u2019 perceptions of fairness, this study takes a resume-screening scenario as an example to explore the impact of AI replacing humans on applicants\u2019 perceptions of fairness. This study adopts the method of the online scenario experiment and uses SPSS to analyze the experimental data: 189 and 214 people, respectively, participated in two online scenarios, with two independent variables of decision makers (AI and humans), two dependent variables of procedural and distributive fairness, and two moderating variables of outcome favorability and the expertise of AI. The results show that the applicants tend to view AI screening resumes as less fair than humans. Furthermore, moderating effects exist between the outcome favorability and the expertise of AI. This study reveals the impact of AI substituting for humans in decision-making on fairness. The proposed model can help organizations use AI to screen resumes more effectively. And future research can explore the collaboration between humans and AI to make human resource management decisions.",
    "doi": "10.3390/su16093840",
    "url": "https://www.semanticscholar.org/paper/451f87249e1a6dd21c76b45b7cffda0a464127ab",
    "pdf_url": "https://www.mdpi.com/2071-1050/16/9/3840/pdf?version=1714658775",
    "venue": "Sustainability",
    "citation_count": 20,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895036"
  },
  {
    "source": "semantic_scholar",
    "source_id": "71f0b30e3fec3e8aab8beb6f374d18a069743505",
    "title": "Artificial Intelligence Ethics and Fairness: A study to address bias and fairness issues in AI systems, and the ethical implications of AI applications",
    "authors": [
      "Nimesh Gupta"
    ],
    "year": 2023,
    "abstract": "Artificial intelligence (AI) has made incredible strides in several fields, revolutionising business and everyday life. Thoughts regarding the moral ramifications and fairness of AI systems have grown in prominence along with its fast development. This article explores the crucial issues of AI fairness and ethics, concentrating on ways to detect and reduce prejudice in AI systems while also discussing larger ethical implications. The paper emphasises the possible repercussions of biased decision-making while highlighting the many forms and sources of bias that might develop in AI models. There are several methods and strategies to deal with bias in AI systems, including data pretreatment, algorithmic changes, and transparency measures. In an effort to balance justice and efficacy, the trade-offs between fairness goals and overall model performance are examined. The article also emphasises how crucial it is for AI systems to be transparent and understandable in order to foster accountability. For the purpose of establishing ethical AI development and deployment practises, regulatory issues and ethical decision-making frameworks are also investigated. This study emphasises the need of ongoing research and development of moral AI systems to guarantee a just and equitable future for AI applications via in-depth analysis and case studies.",
    "doi": "10.31305/rrijm2023.v03.n02.004",
    "url": "https://www.semanticscholar.org/paper/71f0b30e3fec3e8aab8beb6f374d18a069743505",
    "pdf_url": "https://doi.org/10.31305/rrijm2023.v03.n02.004",
    "venue": "Revista Review Index Journal of Multidisciplinary",
    "citation_count": 33,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895040"
  },
  {
    "source": "semantic_scholar",
    "source_id": "715f218b3692c855d4932c2d3150f2f95deeec28",
    "title": "Artificial Intelligence (AI) and Human Resource Management Practice: A Conceptual Review",
    "authors": [
      "Ifeoluwa Oluwaseyi Dopamu",
      "T. Fapohunda",
      "Y. Dauda"
    ],
    "year": 2025,
    "abstract": "The integration of Artificial Intelligence (AI) into Human Resource Management (HRM) is reshaping traditional practices and driving strategic transformation in modern organisations. This conceptual review adopts a qualitative content approach, synthesizing empirical and theoretical literature on AI and HRM to identify emerging patterns, frameworks, and implications for practice. This paper explores AI applications in recruitment, performance management, employee engagement, training, and workforce planning. It highlights the benefits of AI adoption as well as raises ethical and operational concerns, including data privacy, bias, and accountability, while also illustrating its future potential in predictive workforce analytics, ethical governance, and adaptive learning systems that redefine employee experience. Drawing from recent literature and real-world insights, the study emphasizes the need for organisations to implement AI ethically and responsibly, ensuring its deployment is guided by fairness and transparency. It concludes by advocating for robust data governance frameworks and continuous learning to ensure AI serves as a tool for inclusive and sustainable HRM practices in the digital age.",
    "doi": "10.36108/ljerhrm/5202.50.0230",
    "url": "https://www.semanticscholar.org/paper/715f218b3692c855d4932c2d3150f2f95deeec28",
    "pdf_url": "",
    "venue": "LASU Journal of Employment Relations & Human Resource Management",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895044"
  },
  {
    "source": "semantic_scholar",
    "source_id": "1730d49286d48aa0d9b3f7cf5a685e51bfc2e48b",
    "title": "A Study on Artificial Intelligence in Human Resource - Challenges",
    "authors": [
      "A. K"
    ],
    "year": 2025,
    "abstract": "ABSTRACT\n\n \n\nArtificial Intelligence (AI) is transforming Human Resource (HR) management by enhancing efficiency, decision-making, and strategic planning. This study investigates the integration of AI in HR functions such as recruitment, employee engagement, performance evaluation, and workforce analytics, while focusing on the challenges that accompany this technological shift. Key issues explored include data privacy concerns, ethical implications, bias in AI algorithms, resistance to change, and the need for new skill sets among HR professionals. The research emphasizes the importance of balancing automation with human oversight to ensure fairness, transparency, and accountability. Understanding these challenges is essential for organizations aiming to harness the full potential of AI in HR while maintaining a human-centric approach.\n\n\nKEYWORDS: Artificial Intelligence (AI), Human Resource Management (HRM), Recruitment Automation, Employee Engagement, Performance Evaluation, Workforce Analytics, Ethical Challenges",
    "doi": "10.55041/ijsrem46047",
    "url": "https://www.semanticscholar.org/paper/1730d49286d48aa0d9b3f7cf5a685e51bfc2e48b",
    "pdf_url": "",
    "venue": "INTERNATIONAL JOURNAL OF SCIENTIFIC RESEARCH IN ENGINEERING AND MANAGEMENT",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895048"
  },
  {
    "source": "semantic_scholar",
    "source_id": "0ae3983c58ecab9f2d17d2a3aa280f31b69999b9",
    "title": "The Role of Artificial Intelligence in Transforming Human Resource Management Processes (an Analytical Study)",
    "authors": [
      "Norah Almuhanna"
    ],
    "year": 2025,
    "abstract": "This study aims to analyze the role of artificial intelligence (AI) in driving transformation within human resource management (HRM) processes through a descriptive\u2013analytical approach based on a review of recent peer-reviewed literature published between 2019 and 2025. The study explores the key domains affected by this transformation, including recruitment and selection, training and skill development, performance evaluation and motivation, as well as compensation management and talent retention. The research adopts a descriptive\u2013analytical methodology by examining the content of prior studies and identifying both theoretical and practical trends that highlight the impact of AI on enhancing the efficiency and effectiveness of human resources. Findings indicate that AI has become a pivotal factor in redefining HRM functions, contributing to improved decision accuracy and organizational fairness. However, it also faces challenges related to ethics, algorithmic transparency, and data governance. Moreover, the results show that the Saudi context demonstrates advanced readiness for adopting AI-driven HR solutions in line with Saudi Vision 2030, while emphasizing the need to further develop digital competencies and ethical regulatory policies. The study recommends establishing digital governance frameworks, equipping HR professionals with AI-related skills, and developing applied Arab studies to better understand the unique characteristics of intelligent transformation in human resource management.",
    "doi": "10.52132/ajrsp.e.2025.79.2",
    "url": "https://www.semanticscholar.org/paper/0ae3983c58ecab9f2d17d2a3aa280f31b69999b9",
    "pdf_url": "",
    "venue": "Academic Journal of Research and Scientific Publishing",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895052"
  },
  {
    "source": "semantic_scholar",
    "source_id": "65fd92ce5f1a6690416668ffe3142e990ecf2af0",
    "title": "Artificial Intelligence in Human Resource Management: A Comprehensive Literature Review",
    "authors": [
      "Muhammad Arfah"
    ],
    "year": 2025,
    "abstract": "Advances in artificial intelligence (AI) have transformed various aspects of human resource management (HRM), especially in decision making, operational efficiency, and data analysis. The application of AI in HRM offers opportunities to increase organizational effectiveness, but also raises challenges related to transparency, algorithmic bias, and ethics in workforce management. Therefore, this research was conducted to explore the impact of AI in HRM and how organizations can optimize its use. This research uses a literature review method, by examining various scientific sources related to the implementation of AI in HRM. The study was conducted on articles from academic journals, industry reports, and related publications that discuss the role of AI in the recruitment process, performance evaluation, employee training, and strategic decision making. The research results show that AI can improve HRM efficiency through automation of administrative tasks, predictive analytics, and personalization of the employee experience. However, the main challenges found include algorithmic bias, lack of transparency in AI systems, and legal and regulatory uncertainty. In conclusion, AI has great potential in supporting more effective and data-driven HRM, but its use must be accompanied by policies that ensure transparency, accountability and a balance between automation and the role of humans in decision making. Therefore, a careful approach is needed in adopting AI to ensure maximum benefits without compromising aspects of ethics and fairness.",
    "doi": "10.54065/ijed.5.1.2025.336",
    "url": "https://www.semanticscholar.org/paper/65fd92ce5f1a6690416668ffe3142e990ecf2af0",
    "pdf_url": "",
    "venue": "Income Journal Of Economics Development",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895055"
  },
  {
    "source": "semantic_scholar",
    "source_id": "de0418bdada464d62e9d4bf2b0a91f2f1a3e0988",
    "title": "Artificial Intelligence in Human Resource Management: A Study of IT Companies in Bengaluru",
    "authors": [
      "Priya A",
      "Dr. Shailashri. V. T"
    ],
    "year": 2025,
    "abstract": "(AI) Artificial Intelligence has become an inextricable element of Human Resource Management (HRM) especially in recruitment methodologies, altering the way organizations consider prospects, performance assessment, and employee commitment. This paper aims to investigate the effect of organizational size and HR roles on AI technology adoption in recruitment process, with a special reference to IT companies in Bengaluru. The research hopes to offer guidance on how organizations can maximize the potential of AI in their HR by exploring how AI utilities including Applicant Tracking Systems (ATS), chatbots and predictive analytics influence time-to-hire, candidate experience and recruitment efficiency. It also discusses ethics implications of AI deployment, including aspects such as algorithmic bias and employee data privacy.\nThe results show that larger companies are more likely to adopt AI for recruiting because of their financial resources and infrastructure. In addition, HR Managers are key contributors to AI adoption, given their participation in making strategic decisions and greater access to the necessary tools/ skills to successfully apply. The report reveals that the promise of AI is being realized to deliver operational efficiencies, yet these benefits are accompanied by concerns about fairness and transparency in AI decisions, and about potential risk and bias in AI algorithms.\nThis study adds to the emerging body of knowledge on AI in HR with its investigation of the impact of underlined organization size and HR role on AI adoption in recruitment, theoretical and practical implications for organizations seeking to introduce AI in recruitment and ethical challenges are presented. The research also adds another voice to the chorus of those highlighting the importance of human-in-the-loop review before decisions are acted upon by an AI tool, so that it support company values and enables fair recruitment steps.",
    "doi": "10.36948/ijfmr.2025.v07i04.53349",
    "url": "https://www.semanticscholar.org/paper/de0418bdada464d62e9d4bf2b0a91f2f1a3e0988",
    "pdf_url": "",
    "venue": "International Journal For Multidisciplinary Research",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895059"
  },
  {
    "source": "semantic_scholar",
    "source_id": "30c5a9f05cb0039b09b120ef5ecc7ddd4551ab1a",
    "title": "Humans and Machines at Work: Redefining Strategic Human Resource Management in the Era of Artificial Intelligence and Workforce Automation",
    "authors": [
      "Sarfaraz Raza Khan",
      "Muhammad Ali Baig",
      "Dr. Ayaz Qaiser",
      "Dr. Fatima Abrar",
      "Haider Ali"
    ],
    "year": 2025,
    "abstract": "Artificial Intelligence (AI) and workforce automation are rapidly integrating, fundamentally redefining strategic orientation of Human Resource Management (HRM) across industries. This manuscript studies how Strategic Human Resource Management (SHRM) is responding to these technological disruptions by examining the real world experiences of 15 HR professionals from technology, manufacturing and service sectors. Research using primary qualitative data from semi structured interviews identifies themes related to AI in deployment recruitment, employee performance management, ethical issues, employee re\u2010skilling and HRs evolving role. Results show organizations using AI tools to boost operational efficiency and decision making, but issues such as algorithmic bias, lacking transparency, ambiguous ethics and limited digital literacy within HR teams remain considerable. The study also points out sectoral disparities in AI readiness and organizational support that make AI prepared for successful SHRM transformation not solely technological infrastructure but an ethical governance, collaboration across functions and foresight. The paper contributes to the emerging discourse on human centered AI by interpreting these findings through a multidisciplinary lens, also arguing that this kind of balance in technological innovation needs to optimize for employee wellbeing and organizational values. Thus, this research highlights the need for proactive, inclusive and ethically driven SHRM frameworks during the AI era.",
    "doi": "10.59075/6h0sjx74",
    "url": "https://www.semanticscholar.org/paper/30c5a9f05cb0039b09b120ef5ecc7ddd4551ab1a",
    "pdf_url": "",
    "venue": "The Critical Review of Social Sciences Studies",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895063"
  },
  {
    "source": "semantic_scholar",
    "source_id": "5bbb477081e0745e785db6164fe56e7ea8f988f6",
    "title": "Mapping Artificial Intelligence Trends and Challenges in Human Resource Management Practice: A Bibliometric Analysis Of Recent Literature",
    "authors": [
      "Rusmita Ayu Rahmawati",
      "Lilia Pasca Riani"
    ],
    "year": 2025,
    "abstract": "Research Aims: This research aims to map the evolving trends and challenges in the application of Artificial Intelligence (AI) to human resource management (HRM) practices through a bibliometric analysis approach with current literature, hoping to provide a comprehensive understanding of the current landscape and its implications for academics and practitioners.\nDesign/methodology/approach: The method used in this study is a bibliometric approach by analyzing scientific articles from databases such as Scopus and Web of Science. The data analysis technique was then processed and visualized using VOSviewer software to identify patterns and thematic relationships between research topics.\nResearch Findings: The results show that the application of AI in HR management has a significant impact on key HR functions such as HR analytics, recruitment processes, and strategic decision-making, but on the other hand also faces challenges such as algorithm bias, data privacy, ethics, technology adoption barriers, and the limitations of comprehensive bibliometric analysis to address these issues holistically.\nTheoretical Contribution/Originality: This study makes a theoretical contribution through a comprehensive map of AI trends and challenges in HR management, enriching the literature with insights into the dynamics of the technology and its implications for HR management theory. The study also proposes a conceptual framework to address the ethical and practical challenges of AI implementation in organizations.\nKeywords: Artificial Intelligence, Human Resource Management, Bibliometric Analysis, HR Analytics, Machine Learning, Ethics",
    "doi": "10.47153/jbmr.v6i10.1944",
    "url": "https://www.semanticscholar.org/paper/5bbb477081e0745e785db6164fe56e7ea8f988f6",
    "pdf_url": "",
    "venue": "Journal of Business and Management Review",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895067"
  },
  {
    "source": "semantic_scholar",
    "source_id": "deacf8f523c9d8dc0017d664bab64739742cebda",
    "title": "Ethics in Artificial Intelligence: Bias, Fairness and Beyond",
    "authors": [],
    "year": 2023,
    "abstract": null,
    "doi": "10.1007/978-981-99-7184-8",
    "url": "https://www.semanticscholar.org/paper/deacf8f523c9d8dc0017d664bab64739742cebda",
    "pdf_url": "",
    "venue": "Studies in Computational Intelligence",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895070"
  },
  {
    "source": "semantic_scholar",
    "source_id": "84f8451946a74172f81b18a5c3f1978691d17f0b",
    "title": "Exploring Artificial Intelligence Bias, Fairness and Ethics in Organisation and Managerial Studies",
    "authors": [
      "Marco Smacchia",
      "S. Za"
    ],
    "year": 2023,
    "abstract": null,
    "doi": null,
    "url": "https://www.semanticscholar.org/paper/84f8451946a74172f81b18a5c3f1978691d17f0b",
    "pdf_url": "",
    "venue": "European Conference on Information Systems",
    "citation_count": 2,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:49.895074"
  },
  {
    "source": "semantic_scholar",
    "source_id": "5b1413be55553a9cc4b94232cd52a7cacbeb4a05",
    "title": "The Impact of Artificial Intelligence Bias on Human Resource Management Functions: Systematic Literature Review and Future Research Directions",
    "authors": [
      "Mohand Tuffaha"
    ],
    "year": 2023,
    "abstract": "Artificial intelligence (AI) has become a valuable tool for facilitating Human Resource Management (HRM) functions. Although, it should be noted that AI has a specific character side away from other technology. Publications covering this knowledge area have grown sharply, however the scholarly covering the impact of AI bias inHRM is scarce. This paper studies this area and goes deeper to explore the future research areas by conducting a systematic literature review for 598 papers from Scopes and Emerald insight databases of which 34 articles were selected after implementing the PRISMA tool and quality evaluation stage. Results generated revealed that biased AI applications are negatively affecting performance management, compensation, staffing and training and development. Apart from that future research domains and questions have been outlined and identified from organizations\u2019 and employees\u2019 perspectives.",
    "doi": "10.37745/ejbir.2013/vol11n43558",
    "url": "https://www.semanticscholar.org/paper/5b1413be55553a9cc4b94232cd52a7cacbeb4a05",
    "pdf_url": "https://eajournals.org/ejbir/wp-content/uploads/sites/20/2023/07/The-impact-of-artificial-intelligence.pdf",
    "venue": "European journal of business and innovation research",
    "citation_count": 11,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895078"
  },
  {
    "source": "semantic_scholar",
    "source_id": "ecbc956981cb6ecc77c4a9e0b8a6923cf2a587ae",
    "title": "Potential benefits and challenges of artificial intelligence in human resource management in public institutions",
    "authors": [
      "Kelvin M Mwita",
      "F. Kitole"
    ],
    "year": 2025,
    "abstract": "This study explores the benefits and challenges of implementing artificial intelligence (AI) in human resource management (HRM) among public institutions in Tanzania. Using a cross-sectional research design, data was collected from 217 HR practitioners through random sampling and questionnaires. The descriptive approach assessed participants\u2019 understanding of AI, its perceived benefits, challenges, and risks in HRM. The findings on the perceived benefits of AI in HRM show that increased efficiency, better decision-making, and cost reduction are the top advantages, while ease of use ranks the lowest. However, challenges such as lack of expertise, data privacy concerns, high costs, and resistance to change remain significant barriers. Most respondents strongly agree that AI enhances recruitment, training, performance management, and compliance, but concerns persist over bias, transparency, and emotional intelligence limitations in areas like employee relations and compensation. Additionally, results on risks of using AI on HRM indicate that high-risk components like Human Resource Information System (HRIS), Recruitment, Compensation, and Performance Management face serious concerns such as bias and implementation complexity. Moderate-risk areas like succession planning and compliance show manageable challenges, while low-risk components like health and safety and employee relations reflect minimal issues. Statistical analysis confirms significant associations between risk levels and several HRM components, especially HRIS and Recruitment (p\u2009<\u20090.01), highlighting the need for targeted interventions. The study emphasizes the need for public institutions to establish robust ethical frameworks, invest in capacity-building for HR practitioners, and ensure human oversight in AI-driven processes. By addressing these concerns, public institutions can mitigate risks, improve AI adoption, and optimize the potential of AI to enhance HR practices, offering a roadmap for equitable, effective, and ethical implementation of AI technologies in workforce management.",
    "doi": "10.1007/s44282-025-00175-8",
    "url": "https://www.semanticscholar.org/paper/ecbc956981cb6ecc77c4a9e0b8a6923cf2a587ae",
    "pdf_url": "https://doi.org/10.1007/s44282-025-00175-8",
    "venue": "Discover Global Society",
    "citation_count": 10,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895084"
  },
  {
    "source": "semantic_scholar",
    "source_id": "a8cfe8f54eb3f55d2d3e045a7d14231e64cc5b16",
    "title": "Ethics of Artificial Intelligence: Balancing Innovation with Privacy, Fairness, and Accountability",
    "authors": [
      "Manasseh F. Oguru"
    ],
    "year": 2025,
    "abstract": "Artificial Intelligence (AI) is transforming societies through its capacity to drive innovation, optimise decision-making, and enhance productivity across diverse sectors. However, the rapid deployment of AI systems raises complex ethical questions that extend beyond technical performance. This review critically examines the ethics of artificial intelligence with emphasis on three central pillars: privacy, fairness, and accountability. AI technologies often rely on vast datasets that risk infringing on individual privacy when mismanaged, necessitating robust frameworks for data governance and consent. Equally pressing is the issue of fairness, as algorithmic bias can perpetuate systemic inequalities and undermine social justice. This concern is particularly acute in sensitive domains such as healthcare, finance, and criminal justice, where biased outputs can have life-altering consequences. Accountability also emerges as a central challenge, as the diffusion of responsibility between developers, organisations, and users creates ambiguity regarding who should be held responsible for harms caused by AI systems. Addressing these ethical dimensions requires an integrated approach that blends technological safeguards with regulatory oversight and societal engagement. The paper explores strategies such as explainable AI, impact assessments, and participatory design as pathways to align innovation with ethical responsibility. Ultimately, the balance between harnessing AI\u2019s transformative potential and safeguarding fundamental rights hinges on continuous dialogue among stakeholders\u2014governments, industry, academia, and civil society. By fostering ethical resilience in AI governance, societies can ensure that innovation does not compromise human dignity, equity, or trust. This work underscores the importance of proactive, interdisciplinary measures to guide the ethical trajectory of AI as it becomes an indispensable part of everyday life.",
    "doi": "10.9734/ajarr/2025/v19i101169",
    "url": "https://www.semanticscholar.org/paper/a8cfe8f54eb3f55d2d3e045a7d14231e64cc5b16",
    "pdf_url": "",
    "venue": "Asian Journal of Advanced Research and Reports",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895088"
  },
  {
    "source": "semantic_scholar",
    "source_id": "90d1b4159b362012bda0b8b5ad43b320cddca69f",
    "title": "Nursing leadership and artificial intelligence ethics: Safeguarding relationships and values",
    "authors": [
      "Paola Arcadi"
    ],
    "year": 2025,
    "abstract": null,
    "doi": "10.1177/09697330251366599",
    "url": "https://www.semanticscholar.org/paper/90d1b4159b362012bda0b8b5ad43b320cddca69f",
    "pdf_url": "",
    "venue": "Nursing Ethics",
    "citation_count": 1,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:49.895092"
  },
  {
    "source": "semantic_scholar",
    "source_id": "ed4a95917c1c9caaca7899a594755dc7fc99cee7",
    "title": "The Ethics of Generative AI: Analyzing ChatGPT's Impact on Bias, Fairness, Privacy, and Accountability",
    "authors": [
      "Mohd Haider Raza Beg",
      "Vandana Mehndiratta"
    ],
    "year": 2024,
    "abstract": "Pros and cons of Generative Artificial Intelligence (Intent), Many fields has its own use-case space for GAI. ChatGPT and systems like it give a sophisticated understanding of cognition along with content that is indistinguishable from humans, however these systems raise ethical issues in professional and social contexts. Challenges in the broad adoption of AI technologies including, accountability, fairness, bias and privacy arise as issues. These reforms will be critical as AI systems continue to be both developed and deployed, maintaining the crucial ethical standards and underpinning social trust. In the context of algorithmic biases, potential privacy violations, and an increased amount of risk due to automation in these critical decision areas; this paper provides a commentary regarding ethical concerns using generative AI. In addition, is the necessity of addressing these ethical challenges with tools like AI Ethics Impact Assessments, VADER Sentiment Analysis, TensorFlow's Indicators of Fairness, and continuous conversation.",
    "doi": "10.1109/ICSES63760.2024.10910483",
    "url": "https://www.semanticscholar.org/paper/ed4a95917c1c9caaca7899a594755dc7fc99cee7",
    "pdf_url": "",
    "venue": "International Conference on Signals and Electronic Systems",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895096"
  },
  {
    "source": "semantic_scholar",
    "source_id": "c84491016e9547393cd29f78ce5ac8e1d57c512e",
    "title": "Artificial Intelligence in Human Resource Management: A Systematic Literature Review and Human-Centered Framework",
    "authors": [
      "Dr. M. Hema Sundari",
      "Matheshkanna L",
      "Mohammed Riswan R",
      "Muthuraj V",
      "Mohana vasan T G",
      "Moureiya vithu G S"
    ],
    "year": 2025,
    "abstract": "Artificial intelligence (AI) is transforming human resource management (HRM), particularly in areas such as recruitment, performance evaluation, employee development, and job satisfaction. This systematic literature review employs the PRISMA method to synthesise findings from 78 peer-reviewed articles published between 2018 and 2025. AI is making recruitment more efficient, supporting personalized learning, and improving workplace analytics. Still, there are ongoing concerns about transparency, fairness, data privacy, and employee trust. Thematic analysis points to four main trends: better recruitment, more tailored learning, performance evaluations supported by algorithms, and higher employee engagement. While there has been progress, research shows that ethical and governance frameworks are still lacking, especially for long-term employee welfare and sustainable HR management. This study suggests a human-centered approach that balances technical efficiency with inclusivity, equity, and sustainability. The review aims to help both academics and managers by outlining current challenges, identifying gaps, and suggesting directions for future research.",
    "doi": "10.47392/irjaem.2025.0478",
    "url": "https://www.semanticscholar.org/paper/c84491016e9547393cd29f78ce5ac8e1d57c512e",
    "pdf_url": "",
    "venue": "International Research Journal on Advanced Engineering and Management (IRJAEM)",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895100"
  },
  {
    "source": "semantic_scholar",
    "source_id": "285ade017c044c6a40098cb4ad3a23297c1525dc",
    "title": "THE VALUE AND MANIFESTATION OF PREDICTIVE EMPATHY IN THE IMPLEMENTATION OF ARTIFICIAL INTELLIGENCE IN HUMAN RESOURCE MANAGEMENT",
    "authors": [
      "Filip Bu\u0161ina",
      "J. Kovalchuk"
    ],
    "year": 2025,
    "abstract": "The digital transformation of human resource management has facilitated the transition from the automation of routine functions (HR 4.0) to human-centric management (HR 5.0). The purpose of the study is to confirm that artificial intelligence does not replace humans but rather enhances their role through the model of predictive empathy. Based on data from a survey of 698 organizations across nine Central and Eastern European countries, the following findings were identified: a) the integration of AI tools increases the accuracy and transparency of HR processes while maintaining a focus on the individual and human values; b) organizations applying the HR 5.0 approach demonstrate higher levels of employee trust, a better perception of fairness, and greater decision-making efficiency. A strategic framework for implementing human-centric AI solutions in HR is proposed, along with the stages of introducing the predictive-empathic model through the formation of a three-level system of technological, organizational, and social trust, ensuring digital transformation accompanied by ethical and organizational-cultural changes. It is concluded that digitalization and AI do not eliminate the human factor but rather create conditions for a new ethics of management. The obtained results can be recommended for developing corporate digital transformation strategies aimed at building sustainable and ethically responsible HR systems, supporting the transition to the HR 5.0 model.",
    "doi": "10.15688/ek.jvolsu.2025.4.11",
    "url": "https://www.semanticscholar.org/paper/285ade017c044c6a40098cb4ad3a23297c1525dc",
    "pdf_url": "",
    "venue": "Vestnik Volgogradskogo gosudarstvennogo universiteta Ekonomika",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895104"
  },
  {
    "source": "semantic_scholar",
    "source_id": "ea37c234bec29fd2ca2aacb4bee3dbfd581da4eb",
    "title": "Adoption of Artificial Intelligence Technology in Human Resource Management in Digital Office Management",
    "authors": [
      "Marcha Dwi Yuliana",
      "Febri Mardianti"
    ],
    "year": 2025,
    "abstract": "The objective of this research is to examine the impact of integrating Artificial Intelligence (AI) on the effectiveness of Human Resource Management (HRM) within a digital office workplace. The study reveals that AI enhances the efficiency, accuracy, and fairness of numerous HR operations, especially recruitment, performance evaluation, and staff development. This research employs a qualitative descriptive approach using a systematic literature review to synthesize relevant scholarly findings on AI adoption in HRM within digital office environments. Furthermore, the implementation of digital technologies promotes enhanced communication, faster information flow, and a collaborative and inventive working environment. Despite these benefits, challenges remain, such as data privacy issues, cybersecurity threats, employees\u2019 insufficient digital literacy, and resistance to technological innovation. Successful AI implementation in human resource management requires a holistic strategy encompassing technological readiness, enhancement of employees\u2019 digital competencies, adherence to ethical standards, and an adaptable organizational culture. This approach allows organizations to develop flexible, sustainable, and effective office management systems that preserve a competitive edge amidst ongoing digital transformation.",
    "doi": "10.61242/ijabo.25.621",
    "url": "https://www.semanticscholar.org/paper/ea37c234bec29fd2ca2aacb4bee3dbfd581da4eb",
    "pdf_url": "",
    "venue": "International Journal Administration, Business &amp; Organization",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895107"
  },
  {
    "source": "semantic_scholar",
    "source_id": "6e9eac50e099ad95fb516418b95a8198c1e20e74",
    "title": "The transformation of human resource management through artificial intelligence",
    "authors": [
      "Marijana Zimonji\u0107",
      "Milinko Veli\u010dkovi\u0107"
    ],
    "year": 2025,
    "abstract": "The development of artificial intelligence (AI) represents one of the key drivers of digital transformation in modern business, with a particularly profound impact on\nhuman resource management (HRM). The integration of AI into HR processes enables\norganizations to enhance efficiency, objectivity, and accuracy in decision-making related\nto recruitment, selection, evaluation, and employee development. By automating administrative tasks and applying predictive analytics and machine learning algorithms, HR\nmanagement evolves from an operational to a strategic, data-driven function. This paper\nanalyzes the key aspects of HR transformation through the use of AI, with a special focus\non its role in optimizing recruitment and selection processes. Empirical findings indicate\nthat AI contributes to reducing hiring time, increasing fairness and transparency, and\nimproving the candidate experience, while simultaneously raising ethical and regulatory\nconcerns regarding algorithmic transparency and data privacy. The paper concludes that,\nwhen applied responsibly and ethically, artificial intelligence has become an indispensable strategic tool in modern human resource management, enabling the creation of more\nagile, inclusive, and efficient organizations.",
    "doi": "10.5937/megrev2502061z",
    "url": "https://www.semanticscholar.org/paper/6e9eac50e099ad95fb516418b95a8198c1e20e74",
    "pdf_url": "",
    "venue": "Megatrend Revija",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895111"
  },
  {
    "source": "semantic_scholar",
    "source_id": "7772383387b4f784dbc151678e16e95c33605988",
    "title": "The Integration of Artificial Intelligence in Human Resource Management in the U.S. Retail Sector",
    "authors": [
      "R. I. Rezvi",
      "Kazi Obaidur Rahman",
      "Farhan Nasrullah",
      "Md Samirul Islam",
      "Mehedi Hasan",
      "Nayeema Nusrat",
      "Shamina Sharmin Jishan",
      "Shoaib Ahmed"
    ],
    "year": 2025,
    "abstract": "This paper addresses the challenge of integrating Artificial Intelligence (AI) into human resource management (HRM) for the retail sector with the view of addressing challenges of high employee turnover, skill development as well as performance monitoring. Methodology: Existing literature was subjected to a thematic analysis to identify key themes and insights about AI\u2019s role in recruitment, employee motivation, and performance evaluation. Key Findings: AI paces up recruitment speed, personalizes training through adaptive learning and performs performance tracking in real-time. But there are ethical problems, such as algorithmic bias and transparency. Implications: AI brings transformative tools for retail HR management processes and employee engagement. The key to inclusivity and trust is balanced implementation and ethical oversight. Future Directions: Future research needs to address long term workforce impacts and frameworks for the ethical challenges in retail HRM.",
    "doi": "10.32996/jbms.2025.7.1.22",
    "url": "https://www.semanticscholar.org/paper/7772383387b4f784dbc151678e16e95c33605988",
    "pdf_url": "",
    "venue": "Journal of business and management studies",
    "citation_count": 3,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895115"
  },
  {
    "source": "semantic_scholar",
    "source_id": "2d4112456041576b461155d417e014d28af0968c",
    "title": "From Automation to Ethics: Responsible AI in Human Resource Management across Industries with Insights from the Power Sector",
    "authors": [
      "Chandan Kumar"
    ],
    "year": 2025,
    "abstract": "The integration of Artificial Intelligence (AI) in Human Resource Management (HRM) is revolutionising workforce management by automating recruitment, performance evaluations, and employee engagement processes. However, AI-driven HRM systems raise critical ethical concerns, particularly regarding bias, privacy, and transparency. This study explores the ethical implications of AI adoption in HRM, with a specific focus on the power sector, where automation plays a crucial role in workforce optimisation. The research employs a quantitative approach, analysing responses from 250 employees across various departments in power sector organisations. Using SPSS, key statistical tests\u2014including factor analysis, correlation, regression, and ANOVA\u2014are applied to examine the relationships between AI bias, privacy concerns, transparency, employee trust, and job satisfaction. Findings reveal that AI bias significantly affects workforce diversity, while privacy concerns negatively impact employee trust in AI-driven HR decisions. Moreover, the study highlights that greater transparency in AI decision-making fosters higher employee satisfaction and engagement. The study underscores the need for organisations to implement ethical AI governance frameworks to ensure fair, unbiased, and privacy-compliant AI systems in HRM. It recommends explainable AI models, fairness audits, and hybrid decision-making (AI + human oversight) to enhance trust and acceptance of AI-driven HR practices. These findings contribute to the broader discourse on responsible AI adoption in HRM, offering strategic insights for HR leaders, policymakers, and AI developers in the power sector.",
    "doi": "10.31305/rrijm.2025.v10.n4.009",
    "url": "https://www.semanticscholar.org/paper/2d4112456041576b461155d417e014d28af0968c",
    "pdf_url": "",
    "venue": "RESEARCH REVIEW International Journal of Multidisciplinary",
    "citation_count": 3,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895118"
  },
  {
    "source": "semantic_scholar",
    "source_id": "5f6fc0d79366676bbea8cd6e165ad6bcc500bc0b",
    "title": "A Study on the Impact of Artificial Intelligence on Human Resource Management",
    "authors": [
      "Oishi Biswas",
      "Prerana Sharma",
      "Shreyashi Das",
      "Laxmi Bharti"
    ],
    "year": 2025,
    "abstract": "The impact of artificial intelligence (AI) on human resources management (HRM) is profound, driving major shifts in how organizations approach workforce management. AI is fundamentally changing key HR processes such as recruitment, performance management, employee development, and HR administration. In the recruitment space, AI-powered tools can automate the initial stages of hiring, streamlining tasks like resume screening and interview scheduling. These technologies are able to analyze large pools of applicants, matching their qualifications and skills to the job requirements. This can lead to faster, more accurate hiring decisions and help organizations build diverse, high-performing teams. However, there is a potential risk that biases embedded in the data used by AI systems could reinforce inequalities, making it crucial for companies to ensure that their AI tools are regularly audited for fairness and inclusivity.\n\nIn performance management, AI is transforming how employees are evaluated and developed. Traditional performance reviews can often be subjective and inconsistent, but AI can introduce a more objective and data-driven approach. By continuously tracking key performance indicators (KPIs) and employee behaviors, AI can provide real-time insights into performance trends, identify potential areas of improvement, and even predict future challenges. This enables HR professionals to tailor development plans for individual employees, fostering personal growth and enhancing overall productivity. However, the reliance on AI for performance evaluation raises concerns about employee privacy and the potential for over-monitoring, highlighting the need for clear ethical guidelines and transparency in how data is collected and used.",
    "doi": "10.55041/ijsrem44266",
    "url": "https://www.semanticscholar.org/paper/5f6fc0d79366676bbea8cd6e165ad6bcc500bc0b",
    "pdf_url": "",
    "venue": "INTERANTIONAL JOURNAL OF SCIENTIFIC RESEARCH IN ENGINEERING AND MANAGEMENT",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895152"
  },
  {
    "source": "semantic_scholar",
    "source_id": "66f7f6be7841cf86e428aeaefaf0a11be2006b77",
    "title": "Application and Challenges of Artificial Intelligence in Human Resource Management",
    "authors": [
      "Qingrui Li"
    ],
    "year": 2025,
    "abstract": "The integration of artificial intelligence (AI) into human resource management (HRM) presents a transformative opportunity to enhance efficiency, improve decision-making, and address ethical concerns. This research examines the current state of AI applications in HRM, identifying key benefits and challenges associated with implementation. It develops a framework for ethical and responsible AI deployment, considering concerns about bias, privacy, and job displacement. By analyzing real-world case studies and exploring future trends, the research provides insights into the potential impact of AI on the future of work. This study contributes to the field by offering a comprehensive overview of AI in HRM, highlighting its potential to optimize processes, personalize employee experiences, and address ethical considerations.",
    "doi": "10.54097/sq17e902",
    "url": "https://www.semanticscholar.org/paper/66f7f6be7841cf86e428aeaefaf0a11be2006b77",
    "pdf_url": "",
    "venue": "Frontiers in Business, Economics and Management",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895161"
  },
  {
    "source": "semantic_scholar",
    "source_id": "52e34c95b61e721208ed4fc929c38b21f68eb041",
    "title": "The Transformative Impact of Artificial Intelligence and Automation on Human Resource Practices: A Comprehensive Research Overview",
    "authors": [
      "Mallikarjun Devindrappa"
    ],
    "year": 2025,
    "abstract": "Artificial Intelligence (AI) and automation are profoundly reshaping Human Resource Management (HRM), transitioning HR from a traditionally administrative function to a strategic business partner. This report provides a comprehensive research overview of this transformation, examining the diverse applications of AI across core HR practices, including talent acquisition, onboarding, performance management, learning and development, employee engagement, and administrative task automation. It synthesizes the significant benefits, such as enhanced operational efficiency, data-driven strategic decision-making, and personalized employee experiences. Concurrently, the report critically analyzes the inherent challenges and ethical dilemmas, with a particular focus on algorithmic bias, data privacy and security, the potential for job displacement and skill gaps, and the imperative for transparency and human oversight. Mitigation strategies and best practices for responsible AI adoption are discussed, emphasizing robust governance, data quality, algorithmic audits, and workforce upskilling. The future trajectory of AI in HR points towards more sophisticated innovations like Agentic AI and hyper-personalization, further evolving the role of HR professionals into ethical stewards and strategic integrators of technology. Ultimately, the report underscores the necessity of a balanced approach, integrating technological advancements with human-centric values to foster effective, equitable, and engaging workplaces where AI augments human capabilities.",
    "doi": "10.31305/trjtm2025.v05.n01.006",
    "url": "https://www.semanticscholar.org/paper/52e34c95b61e721208ed4fc929c38b21f68eb041",
    "pdf_url": "",
    "venue": "TECHNO REVIEW Journal of Technology and Management",
    "citation_count": 2,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895163"
  },
  {
    "source": "semantic_scholar",
    "source_id": "9203539261c7cb6ab3ad9c47a871b549d44e39e1",
    "title": "Artificial Intelligence in Human Resource Management: A Case of Information Technology Sector of Khyber Pakhtunkhwa, Pakistan",
    "authors": [
      "Maseeh Ullah",
      "M. Din",
      "Farooq Khan",
      "Saad Mushtaq"
    ],
    "year": 2025,
    "abstract": "The integration of Artificial Intelligence (AI) into Human Resource Management (HRM) is revolutionizing traditional HR practices by enhancing efficiency, objectivity, and strategic decision-making. This paper explores the multifaceted applications of AI in HRM, focusing on recruitment, performance evaluation, employee engagement, and workforce planning. Through a comprehensive literature review and analysis of current industry practices, the study highlights how AI-driven tools such as chatbots, predictive analytics, and resume screening algorithms are transforming HR functions. While AI offers significant benefits, including time savings and improved candidate-job matching, it also raises critical concerns about data privacy, algorithmic bias, and ethical transparency. The paper concludes with recommendations for responsible AI adoption and outlines areas for future research, emphasizing the need for a balanced approach that leverages AI while preserving the human element in HRM.",
    "doi": "10.63468/jpsa.3.1.6",
    "url": "https://www.semanticscholar.org/paper/9203539261c7cb6ab3ad9c47a871b549d44e39e1",
    "pdf_url": "",
    "venue": "Journal of Political Stability Archive",
    "citation_count": 2,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895165"
  },
  {
    "source": "semantic_scholar",
    "source_id": "eff9c6e239940c2b8714a3225586564a8bd205f2",
    "title": "Human resource development in the age of artificial intelligence: a theoretical synthesis",
    "authors": [
      "Caleb Bennett",
      "Jeremy Bennett"
    ],
    "year": 2026,
    "abstract": null,
    "doi": "10.1007/s43681-025-00944-w",
    "url": "https://www.semanticscholar.org/paper/eff9c6e239940c2b8714a3225586564a8bd205f2",
    "pdf_url": "",
    "venue": "AI and Ethics",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895167"
  },
  {
    "source": "semantic_scholar",
    "source_id": "83c2bb49d7ca200352531f19377ba14cc3ce8685",
    "title": "Artificial\u00a0Intelligence\u00a0in\u00a0Human\u00a0Resource\u00a0Management:\u00a0Exploring\u00a0Public Policy Implications and Emerging Ethical Challenges",
    "authors": [
      "Taufeeq Ahmed",
      "Rabia Majeed"
    ],
    "year": 2025,
    "abstract": "This\u00a0research examines\u00a0the\u00a0dual impact\u00a0of Artificial Intelligence\u00a0(AI) integration\u00a0in\u00a0Human\u00a0Resource\u00a0Management\u00a0(HRM),\u00a0focusing\u00a0on\u00a0the intersection of technological efficiency gains with emerging public policy requirements and ethical challenges. Employing a mixed- methods approach, the study combines quantitative survey data from 427 HR professionals across multiple sectors with qualitative policy analysis of regulatory frameworks from 12 jurisdictions and three in- depth organizational case studies. Structural Equation Modeling (SEM)\u00a0was\u00a0used\u00a0to\u00a0analyze\u00a0relationships\u00a0between\u00a0AI\u00a0adoption\u00a0factors and ethical outcomes. AI adoption in HRM yields significant efficiency improvements (average 37.2% reduction in recruitment time,\u00a031.8%\u00a0cost\u00a0reduction),\u00a0but\u00a0simultaneously\u00a0introduces\u00a0substantial ethical\u00a0risks.\u00a0Algorithmic\u00a0bias\u00a0was\u00a0detected\u00a0in\u00a028.7%\u00a0of\u00a0systems,\u00a0with gender bias being most prevalent (19.3%). Policy compliance gaps were substantial, with only 41.2% of organizations fully meeting GDPR requirements for AI systems. Organizations must develop comprehensive AI governance frameworks that balance efficiency gains with ethical safeguards. Policymakers should prioritize developing sector-specific AI regulations for HRM that address transparency\u00a0requirements,\u00a0bias\u00a0auditing\u00a0standards,\u00a0and\u00a0employee\u00a0data protection. This study contributes a novel integrated framework for understanding the policy-ethics-technology nexus in AI-HRM adoption, providing empirical evidence of the specific trade-offs organizations face and offering actionable policy recommendations.",
    "doi": "10.63468/sshrr.255",
    "url": "https://www.semanticscholar.org/paper/83c2bb49d7ca200352531f19377ba14cc3ce8685",
    "pdf_url": "",
    "venue": "Social Sciences &amp; Humanity Research Review",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895169"
  },
  {
    "source": "semantic_scholar",
    "source_id": "8cdae09acd753c5fc7dfd3fb5ea15f2d1d92728d",
    "title": "THE STRATEGIC CHALLENGES OF ARTIFICIAL INTELLIGENCE ON HUMAN RESOURCE MANAGEMENT PRACTICES",
    "authors": [
      "Sandeep Kumar Gupta",
      "Billekanti Punitha Sai",
      "Patan Ushma",
      "Chithanoor Meghana",
      "Kakarla Uday Kiran Reddy"
    ],
    "year": 2025,
    "abstract": "Artificial Intelligence (AI) is profoundly transforming the field of Human Resource Management (HRM) by streamlining administrative functions, enabling data-driven decision-making, and enhancing overall workforce efficiency. Through automation and predictive analytics, AI assists HR professionals in recruitment, performance evaluation, training, and employee engagement. However, while the potential of AI is vast, its integration into HRM presents several strategic challenges. Ethical dilemmas, data privacy risks, algorithmic bias, and the potential for employee displacement or resistance are significant barriers to effective implementation. Moreover, the rapid advancement of AI technologies demands continuous upskilling and reskilling of HR personnel to ensure technological adaptability. \nThis paper examines these multifaceted strategic challenges by drawing insights from contemporary literature and qualitative research findings across different organizational contexts. It further investigates how organizations can align AI adoption with ethical governance frameworks, transparent communication, and employee inclusion strategies. \nThe findings suggest that sustainable AI integration in HRM requires balancing technological efficiency with human-centric values to maintain trust, fairness, and inclusivity. In conclusion, the paper emphasizes the importance of responsible innovation, where AI tools are leveraged not merely for automation but as catalysts for strategic transformation in HR practices. By fostering a culture of learning and ethical awareness, organizations can harness AI\u2019s full potential while mitigating its associated risks.",
    "doi": "10.36690/iceaf-2025-26",
    "url": "https://www.semanticscholar.org/paper/8cdae09acd753c5fc7dfd3fb5ea15f2d1d92728d",
    "pdf_url": "",
    "venue": "Book of abstractsract",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895170"
  },
  {
    "source": "semantic_scholar",
    "source_id": "64af082bdb1d9b688cedf6caf22109955e3c00c6",
    "title": "Artificial Intelligence Applications in Human Resource Management",
    "authors": [
      "Cemal Iyem",
      "Beyza Erer"
    ],
    "year": 2025,
    "abstract": "With the rapid advancement of information technologies in recent years, artificial intelligence (AI) has begun to be integrated into human resource (HR) management, as in all other business functions.. This inevitable technological shift has reshaped the HR function, enabling HR professionals to utilize machine learning and algorithms to streamline business processes, reduce bias and improve analysis and decision-making. With such significant benefits, it is curious how actively AI is being used in the field of human resource management. Therefore, the study aims to identify in which function(s) of Human Resource Management artificial intelligence technologies are being used. The study used a case study approach, one of the qualitative research designs, and analysed how companies integrate artificial intelligence technologies into basic human resource processes using the \u201cdocument analysis\u201d method. The study was designed as a case study.",
    "doi": "10.33712/mana.1702990",
    "url": "https://www.semanticscholar.org/paper/64af082bdb1d9b688cedf6caf22109955e3c00c6",
    "pdf_url": "",
    "venue": "Uluslararas\u0131 Y\u00f6netim Akademisi Dergisi",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895172"
  },
  {
    "source": "semantic_scholar",
    "source_id": "f0bde02072e7acbbd47725f8fc414a4528f63696",
    "title": "Artificial Intelligence in Human Resource Management: Transforming Workforce Optimization, Recruitment, and Employee Engagement",
    "authors": [
      "Sheenu Arora",
      "Ruchi Srivastava",
      "V. K. Gupta"
    ],
    "year": 2025,
    "abstract": "Artificial intelligence (AI), which enhances workforce optimization, decision-making, and process automation, is transforming human resource management (HRM). This paper explores how AI can be used in HRM, with a focus on important functions, including hiring, employee engagement, training and development, performance review, and retention. Chatbots, machine learning, natural language processing (NLP), and predictive analytics are examples of AIpowered technologies that increase productivity, reduce biases, and streamline HR operations. Despite the numerous benefits of artificial intelligence, issues such as algorithmic bias, data privacy, transparency, and resistance by employees still prevail. To assess AI's impact on HRM, the research employs a qualitative approach, analysing secondary data from scholarly articles, industry reports, and case studies. Findings indicate that while AI significantly enhances workforce management, ethical use and regulatory oversight are required. The research also considers possible future growth, with an emphasis on growth in AI, generative AI, and people analytics. Companies will achieve a competitive advantage in the evolving HR space if they thoroughly implement AI while maintaining human authority.",
    "doi": "10.1109/ICDISS68238.2025.11320597",
    "url": "https://www.semanticscholar.org/paper/f0bde02072e7acbbd47725f8fc414a4528f63696",
    "pdf_url": "",
    "venue": "2025 International Conference on Digital Innovations for Sustainable Solutions (ICDISS)",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895174"
  },
  {
    "source": "semantic_scholar",
    "source_id": "879d8b46832a1ecd19531ba53e0f83f82412f769",
    "title": "Leveraging Artificial Intelligence in Decision Support Systems for Strategic Human Resource Management: A Systematic Literature Review",
    "authors": [
      "Bara Aldino",
      "Sujoko Sujoko"
    ],
    "year": 2025,
    "abstract": "This study examines the integration of Artificial Intelligence (AI) into Decision Support Systems (DSS) for Strategic Human Resource Management (SHRM) through a systematic literature review (SLR). The research investigates how AI technologies enhance various HR functions, such as recruitment, training, performance evaluation, and talent management. The findings indicate that AI significantly improves operational efficiency, decision-making accuracy, and the overall speed of HR processes. However, challenges such as ethical concerns, data privacy issues, and potential algorithmic bias in decision-making are highlighted. The paper aims to provide a conceptual framework for the effective application of AI in SHRM and identifies key trends, challenges, and opportunities in AI adoption within HR functions. By synthesizing existing research, this study offers valuable insights into optimizing the use of AI in DSS for SHRM, emphasizing the importance of aligning AI implementation with ethical principles and organizational goals. The research advances theoretical and practical understanding of AI's role in HRM and encourages further exploration of its impact across various organizational contexts.",
    "doi": "10.58811/opsearch.v4i4.185",
    "url": "https://www.semanticscholar.org/paper/879d8b46832a1ecd19531ba53e0f83f82412f769",
    "pdf_url": "",
    "venue": "Quarterly Journal of the Operational Research Society of India (OPSEARCH)",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895175"
  },
  {
    "source": "semantic_scholar",
    "source_id": "792f2a858b78230dcc78965d1765de8cc96ce723",
    "title": "Artificial Intelligence in Human Resource Management: \nReshaping Talent Strategies in the Digital Era",
    "authors": [
      "Ting Tao"
    ],
    "year": 2025,
    "abstract": "The integration of artificial intelligence (AI) into human resource management (HRM) has revolutionized traditional practices, \nenabling data-driven decision-making and operational efficiency. This paper systematically analyzes the applications of AI in recruitment, \ntraining, performance management, and staff retention, supported by case studies from global enterprises (e.g., Unilever, IBM) and Chinese \ncorporations (e.g., Alibaba, Tencent). It further explores ethical challenges, including algorithmic bias and data privacy risks, and proposes \na governance framework balancing technological innovation with human-centric values. The study concludes with future directions for AIHRM synergy, emphasizing collaborative intelligence and policy coordination.",
    "doi": "10.70711/memf.v2i6.6912",
    "url": "https://www.semanticscholar.org/paper/792f2a858b78230dcc78965d1765de8cc96ce723",
    "pdf_url": "",
    "venue": "Modern Economic Management Forum",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895177"
  },
  {
    "source": "semantic_scholar",
    "source_id": "39ab7ddf0ae8ae752839c2d2d7e8badb80ffc28f",
    "title": "Research on the Impact of Artificial Intelligence on Employee Experience in Human Resource Management",
    "authors": [
      "Lingying Fang",
      "Xu Jing",
      "Shaofeng Zhang"
    ],
    "year": 2025,
    "abstract": "Driven by artificial intelligence technology, human resource management is undergoing a digital transformation. The central contradiction lies in the dynamic interplay between technological empowerment and humanistic values. This study focuses on the dual impact of artificial intelligence (AI) on employee experience within human resource management (HRM). It aims to systematically analyze how AI technologies facilitate the enhancement and optimization of employee experience during HRM processes, while simultaneously revealing their potential technological paradox and experience depletion. It reveals that: the application of AI technology demonstrates significant effectiveness in enhancing recruitment efficiency, personalizing employee training, and increasing the objectivity of performance management. At the same time, issues such as algorithmic bias, black-box decision-making, and excessive monitoring may trigger a crisis of trust. Consequently, this study advances the proposition that, the key issue in the digital transformation of enterprise human resource management lies in continuously building a dynamic framework of\u201chuman intelligence collaboration\u201d, seeking an appropriate balance between technological rationality and human needs/dignity, and between efficiency gains and humanistic care, thereby ensuring that the application of artificial intelligence centers on human beings.",
    "doi": "10.26789/ijest.v4i3.2105",
    "url": "https://www.semanticscholar.org/paper/39ab7ddf0ae8ae752839c2d2d7e8badb80ffc28f",
    "pdf_url": "",
    "venue": "\u56fd\u9645\u5316\u6559\u80b2\u79d1\u5b66\u4e0e\u7406\u8bba",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895178"
  },
  {
    "source": "semantic_scholar",
    "source_id": "a42554ce8fc8a3c3b6235abac522bc2a27158281",
    "title": "Bias in artificial intelligence for medical imaging: fundamentals, detection, avoidance, mitigation, challenges, ethics, and prospects",
    "authors": [
      "Burak Ko\u00e7ak",
      "A. Ponsiglione",
      "A. Stanzione",
      "Christian Bluethgen",
      "J. Santinha",
      "L. Ugga",
      "Merel Huisman",
      "M. Klontzas",
      "Roberto Cannella",
      "Renato Cuocolo"
    ],
    "year": 2024,
    "abstract": "ABSTRACT Although artificial intelligence (AI) methods hold promise for medical imaging-based prediction tasks, their integration into medical practice may present a double-edged sword due to bias (i.e., systematic errors). AI algorithms have the potential to mitigate cognitive biases in human interpretation, but extensive research has highlighted the tendency of AI systems to internalize biases within their model. This fact, whether intentional or not, may ultimately lead to unintentional consequences in the clinical setting, potentially compromising patient outcomes. This concern is particularly important in medical imaging, where AI has been more progressively and widely embraced than any other medical field. A comprehensive understanding of bias at each stage of the AI pipeline is therefore essential to contribute to developing AI solutions that are not only less biased but also widely applicable. This international collaborative review effort aims to increase awareness within the medical imaging community about the importance of proactively identifying and addressing AI bias to prevent its negative consequences from being realized later. The authors began with the fundamentals of bias by explaining its different definitions and delineating various potential sources. Strategies for detecting and identifying bias were then outlined, followed by a review of techniques for its avoidance and mitigation. Moreover, ethical dimensions, challenges encountered, and prospects were discussed.",
    "doi": "10.4274/dir.2024.242854",
    "url": "https://www.semanticscholar.org/paper/a42554ce8fc8a3c3b6235abac522bc2a27158281",
    "pdf_url": "https://d2v96fxpocvxx.cloudfront.net/new/beb8919b-f013-4ea1-b1c8-40332e840fe1/articles/dir.2024.242854/DIR-2024-2854.pdf",
    "venue": "Diagnostic and Interventional Radiology",
    "citation_count": 133,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:49.895181"
  },
  {
    "source": "semantic_scholar",
    "source_id": "69d9469b40b0866691b3d72e2a7d75164e1bced0",
    "title": "Artificial Intelligence and Ethics",
    "authors": [
      "Shipra Gupta",
      "Priti Sharma"
    ],
    "year": 2025,
    "abstract": "Artificial Intelligence (AI) is becoming a powerful force that is reshaping economies, civilizations, and personal lives. But along with its quick development come a plethora of ethical issues that need serious thought. This essay explores the complex relationship between ethics and artificial intelligence (AI), focusing on the moral issues raised by the creation, application, and use of intelligent systems. The discussion starts out by looking at the moral dilemmas that AI algorithms present, especially with regard to responsibility, justice, and bias. It examines the moral conundrums that result from independent decision-making processes, including those that occur in criminal justice, healthcare, and work settings. The study also examines the moral obligations that AI practitioners, developers, and legislators have to protect human rights, privacy, and dignity in the face of the widespread use of AI technologies. This study also explores the changing relationship between AI and society values, covering issues like as moral pluralism, cultural relativism, and international regulation of AI ethics. It considers the moral ramifications of AI's contribution to the amplification or reduction of socioeconomic inequality as well as its capacity to reinforce or lessen institutionalized prejudice and discrimination. The article also looks at new ethical frameworks and regulatory strategies meant to guarantee the ethical and responsible development and application of AI technologies. It assesses how well the current policies, procedures, and oversight frameworks promote openness, responsibility, and confidence in artificial intelligence (AI) systems. This paper concludes by arguing that an interdisciplinary and cooperative approach is necessary to address the ethical issues raised by AI. It also highlights the significance of ethical reflection, stakeholder engagement, and continuous discourse in forming an AI-enabled future that respects human rights, values, and dignity.",
    "doi": "10.2139/ssrn.5076025",
    "url": "https://www.semanticscholar.org/paper/69d9469b40b0866691b3d72e2a7d75164e1bced0",
    "pdf_url": "",
    "venue": "Social Science Research Network",
    "citation_count": 21,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895183"
  },
  {
    "source": "semantic_scholar",
    "source_id": "136fd18f5369ed2fbf47b5c553987f726ba522f0",
    "title": "The emergence of artificial intelligence ethics auditing",
    "authors": [
      "Danielle Schiff",
      "Stephanie Kelley",
      "Javier Camacho Ib\u00e1\u00f1ez"
    ],
    "year": 2024,
    "abstract": "The emerging ecosystem of artificial intelligence (AI) ethics and governance auditing has grown rapidly in recent years in anticipation of impending regulatory efforts that encourage both internal and external auditing. Yet, there is limited understanding of this evolving landscape. We conduct an interview-based study of 34 individuals in the AI ethics auditing ecosystem across seven countries to examine the motivations, key auditing activities, and challenges associated with AI ethics auditing in the private sector. We find that AI ethics audits follow financial auditing stages, but tend to lack robust stakeholder involvement, measurement of success, and external reporting. Audits are hyper-focused on technically oriented AI ethics principles of bias, privacy, and explainability, to the exclusion of other principles and socio-technical approaches, reflecting a regulatory emphasis on technical risk management. Auditors face challenges, including competing demands across interdisciplinary functions, firm resource and staffing constraints, lack of technical and data infrastructure to enable auditing, and significant ambiguity in interpreting regulations and standards given limited (or absent) best practices and tractable regulatory guidance. Despite these roadblocks, AI ethics and governance auditors are playing a critical role in the early ecosystem: building auditing frameworks, interpreting regulations, curating practices, and sharing learnings with auditees, regulators, and other stakeholders.",
    "doi": "10.1177/20539517241299732",
    "url": "https://www.semanticscholar.org/paper/136fd18f5369ed2fbf47b5c553987f726ba522f0",
    "pdf_url": "",
    "venue": "Big Data &amp; Society",
    "citation_count": 13,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895184"
  },
  {
    "source": "semantic_scholar",
    "source_id": "dd9c5bd2b0b6ba19d88a7daf3fde42ab4da659b1",
    "title": "A Comprehensive Strategy to Bias and Mitigation in Human Resource Decision Systems",
    "authors": [
      "Silvia D'Amicantonio",
      "Mishal Kizhakkam Kulangara",
      "Het Darshan Mehta",
      "Shalini Pal",
      "Marco Levantesi",
      "Marco Polignano",
      "Erasmo Purificato",
      "Ernesto William De Luca"
    ],
    "year": 2024,
    "abstract": null,
    "doi": null,
    "url": "https://www.semanticscholar.org/paper/dd9c5bd2b0b6ba19d88a7daf3fde42ab4da659b1",
    "pdf_url": "",
    "venue": "XAI.it@AI*IA",
    "citation_count": 4,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:49.895186"
  },
  {
    "source": "semantic_scholar",
    "source_id": "29a2c7c87d5bbeccb479202fdaac491159f42e19",
    "title": "Research Paper Artificial Intelligence (AI) and the Ethics of Moral Decision-Making: Integrating Human and Spiritual Values into Legal Frameworks for Ethical AI Development",
    "authors": [
      "Firdausi Kabir"
    ],
    "year": 2025,
    "abstract": "The rapid development of artificial intelligence (AI) technology has raised more ethical concerns than ever before, particularly with autonomous decision-making systems. Even more modern AI systems can carry out growingly intricate work with fewer human interventions, putting into doubt accountability, fairness, transparency, and the ethical consequences of the machine-directed decision. Though important literature has been done concerning AI ethics in terms of technical, legal, and philosophical frameworks, the inclusion of human and spiritual values within the framework of AI judgments is currently a critical gap. The ethical consideration of human values, such as empathy, justice, and human dignity, are fundamental aspects of human consideration, but their implementation in the algorithmic systems is scarce. Spiritual values, which include moral principles based on various cultural, religious, and philosophical traditions, provide another complementary aspect to the control of AI behaviour, to make sure that autonomous systems are in line with the expectations of morality and ethical propriety of society.\n\nThe paper aims to analyse how human and spiritual values can be integrated in a legal and policy framework to develop ethical AI. The research uses an interdisciplinary methodology by taking the perspectives of philosophy, theology, computer science, and law to theorise a model where-by the making of ethical decisions can be integrated within AI systems. The study relies on the literature on AI ethics, human centred design, and legal governance to determine the existing gaps and challenges when it comes to the translation of abstract ethical principles into computational mechanisms. There are case studies in the fields of autonomous vehicles, healthcare, and law enforcement that are examined to demonstrate the potential of the involvement of moral and spiritual considerations in AI algorithms, as well as their limitations.\n\nSome of the major research questions that were used to guide this research include: How do we operationalize human and spiritual values in AI systems? How can legal and policy processes be used to guarantee adherence to ethical standards? How far can AI systems be programmed to incorporate cross-cultural ethics at the expense of technical effectiveness? Answering these questions, the paper helps to develop a more comprehensive view of AI ethics, which is not limited to technical or utilitarian methods. The results serve as an additional indication that making AI human and spiritual is not just an imaginary task but a viable requirement to adjust technology to the standards and rules of society, as well as the expectations of the ethical framework. Some of the operationalisation strategies of ethical principles are the development of value-sensitive algorithms, ethical compliance regulatory guidelines, and interdisciplinary oversight mechanisms. Additionally, the paper identifies the possible obstacles, including cultural pluralism, interpretative ambiguities of moral codes, and technical constraints of algorithm design, which should be resolved to accomplish successful integration.",
    "doi": "10.65025/icfai25008f",
    "url": "https://www.semanticscholar.org/paper/29a2c7c87d5bbeccb479202fdaac491159f42e19",
    "pdf_url": "",
    "venue": "International Conference on Faith and Artificial Intelligence (ICFAI 2025)",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895188"
  },
  {
    "source": "semantic_scholar",
    "source_id": "03e44b87cafc556bcf356fb035192942e7d409df",
    "title": "An Analysis of Artificial Intelligence Adoption in the Human Resource Management",
    "authors": [
      "Anurag Kumar"
    ],
    "year": 2024,
    "abstract": "The integration of AI into HRM practices will mark a turning point in the history of organizational dynamics, bringing with it improved productivity and fresh perspectives on long-term planning. Because of this integration, many difficult questions and ethical dilemmas emerge. The hazy waters of artificial intelligence (AI) in human resource management are explored in this study, which examines its effects on training, engagement, performance reviews, and recruiting. Examining the AI-HRM nexus, this study draws on recent literature and statistics to highlight key developments, motivating factors, and obstacles. In addition, it explores the ways AI is changing HRM practices, illuminating the potential for innovation as well as concerns about prejudice and privacy invasion. We are examining the openness, responsibility, and fairness of AI-driven HRM systems since ethical concerns are at the heart of this discussion. For companies looking to apply AI to HRM and use an integrated framework, this report provides strategic insights to help them manage the hurdles of AI adoption. Helping companies make the most of technology while protecting and valuing their personnel is the main goal. Keywords: Artificial Intelligence, Human Resource Management, AI Adoption, Recruitment, Talent Management, Employee Engagement, Performance Evaluation, Ethical Implications, Privacy Concerns, Workforce Upskilling.",
    "doi": "10.55041/ijsrem32681",
    "url": "https://www.semanticscholar.org/paper/03e44b87cafc556bcf356fb035192942e7d409df",
    "pdf_url": "https://ijsrem.com/download/an-analysis-of-artificial-intelligence-adoption-in-the-human-resource-management/?wpdmdl=32277&refresh=665c243347c761717314611",
    "venue": "INTERANTIONAL JOURNAL OF SCIENTIFIC RESEARCH IN ENGINEERING AND MANAGEMENT",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895189"
  },
  {
    "source": "semantic_scholar",
    "source_id": "2e970aeee1c9bf17e32d6139be715c2a07116161",
    "title": "Ethical Framework for Artificial Intelligence and Urban Sustainability",
    "authors": [
      "Tatik Mariyanti",
      "Indra Wijaya",
      "Sandy Setiawan",
      "Chandra Lukita",
      "Eamon Fletcher"
    ],
    "year": 2025,
    "abstract": "The integration of artificial intelligence (AI) into urban environments addresses sustainability challenges like resource management, transportation efficiency, and waste reduction. However, critical need for a robust ethical framework to ensure equitable and environmentally responsible implementation. The method proposed emphasizes a combination of community involvement, fairness, and resilience, integrating ethical principles with practical strategies to maximize societal benefits, and incorporates the use of SmartPLS for structural equation modeling to analyze the relationships between ethical principles, sustainability dimensions, and urban outcomes. A significant GAP exists in current frameworks, which often focus solely on individual-level ethics and fail to address the dynamic, systemic challenges posed by fragile social systems and the uneven global structure. The novelty of this approach lies in its comprehensive vision that interlinks human-centered and collectivist-oriented development, bridging socio economic, environmental, and technological dimensions of sustainability. The proposed ethical framework not only mitigates risks but also fosters inclusive and resilient urban ecosystems, aligning digital innovations with the complex interconnections of the Sustainable Development Goals (SDGs) 11 (on sustainable cities).",
    "doi": "10.34306/bfront.v4i2.689",
    "url": "https://www.semanticscholar.org/paper/2e970aeee1c9bf17e32d6139be715c2a07116161",
    "pdf_url": "",
    "venue": "Blockchain Frontier Technology",
    "citation_count": 19,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895191"
  },
  {
    "source": "semantic_scholar",
    "source_id": "d11dd70bf393212c26c846a0bb474f055c8d3515",
    "title": "Artificial Intelligence and Remote Work: Transforming Human Resource Management in a Post-Pandemic World",
    "authors": [
      "Ch Sahyaja",
      "Ch Shankar",
      "Khudsiya Zeeshan",
      "N. Nagaraj"
    ],
    "year": 2024,
    "abstract": "This research explores the transformative impact of Artificial Intelligence (AI) on Human Resource Management (HRM) practices within the context of remote work. By analyzing existing research and case studies, this paper investigates how AI technologies, such as machine learning and predictive analytics, can be leveraged to optimize recruitment processes, streamline performance evaluations, and facilitate seamless collaboration among geographically dispersed teams. The study also addresses the ethical considerations associated with AI in HRM, including data privacy, algorithmic bias, and ensuring fair and equitable treatment of employees. The findings of this research provide valuable insights into the potential of AI to revolutionize HRM practices in the remote work era, enabling organizations to enhance employee engagement, improve decision-making, and drive innovation.",
    "doi": "10.1109/ICACRS62842.2024.10841784",
    "url": "https://www.semanticscholar.org/paper/d11dd70bf393212c26c846a0bb474f055c8d3515",
    "pdf_url": "",
    "venue": "2024 3rd International Conference on Automation, Computing and Renewable Systems (ICACRS)",
    "citation_count": 2,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895192"
  },
  {
    "source": "semantic_scholar",
    "source_id": "5631a17a2380724a459a45d7311716f77a514519",
    "title": "A research paper on how Artificial Intelligence changes the Human Resource Activities inside the organization and provides the significant improvement in workforce working environment for various day to day decisions making along with their efficiency and their productivity",
    "authors": [
      "N. Ganatra"
    ],
    "year": 2024,
    "abstract": "This paper speaks volumes about the various processes of Human resource like recruitment , training, selections, performance and development and workforce planning and how the Artificial Intelligence has revolutionized over the period of time by providing various insights and supporting in the decision making process. Artificial intelligence has provided a bias free and advanced algorithms due to which the screening and scheduling of HR process has been done with accurate parameters and lightning fast speed. This study provides a detailed insight to the AI intervention and its effectiveness in providing a great decision making system to the Human resource professionals. This platform is utilizing the sentiment analysis and catboats to monitor and improve the work place environment, which pushes the positivity in work culture and boosts productivity The AI aids in providing continuous feedback, various goal settings and tracking the performance productivity. This also provides a gist as well as in depth knowledge of top performers of the unit and also share the areas of improvement by which the others can reach up to a new bench mark. This AI has been a boon to the HR individuals thoroughly, especially during the performance appraisals. On the other AI enables personalized training programs and adaptive learning paths, addressing skill gaps and aligning employee development along with organizational goals.The point to ponder over is that the AI has also played a crucial role in workforce planning and analytics, additionally, it has aided by providing tools to forecast future workforce needs, optimize resource allocation, and enhance strategic decision-making. This process which is done by IA is by analyzing large datasets, AI also predicts turnover trends and informs succession planning, contributing to organizational productive and efficient life cycle The research has infused a mixed-methods approach, which combines qualitative and quantitative data collection through surveys, interviews, and case studies, alongside statistical analysis of HR metrics pre- and post-AI implementation. The basics of this research paper aims to provide valuable insights for HR professionals and organizational leaders on leveraging AI to enhance HR effectiveness and drive business success. There a strong determination which ensures that the findings will contribute to the evolving body of knowledge on AI in HR and support the development of strategic frameworks for AI adoption in human resource management on a longer run.",
    "doi": "10.18231/j.jmra.2024.030",
    "url": "https://www.semanticscholar.org/paper/5631a17a2380724a459a45d7311716f77a514519",
    "pdf_url": "https://doi.org/10.18231/j.jmra.2024.030",
    "venue": "Journal of Management Research and Analysis",
    "citation_count": 2,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895194"
  },
  {
    "source": "semantic_scholar",
    "source_id": "9bc8e3b48b343b869fb204c271beb83de507e8f4",
    "title": "Human Resource Management Optimization Strategies for Diverse Work Environments Based on Artificial Intelligence",
    "authors": [
      "Min Wu"
    ],
    "year": 2024,
    "abstract": "Abstract Under the diversified work environment, the relationship between employees and enterprises has ushered in new and significant changes. How to adapt to changes, form a new human resource management model, and improve management performance is an urgent issue. In this paper, we constructed an employee turnover pre-analysis measurement model based on XGBoost artificial intelligence, iterated many times during training, generated a weak classifier in each iteration, trained on the basis of the residuals of the previous classifier, and finally combined all the weak classifiers in a weighted way, reduced the bias to improve the accuracy of the final classifier through continuous iteration, and completed the construction of the model. The historical data of employees in six branches of enterprise W are imported into the model for analysis, and the F1 values are all above 0.85, and the AUCs are all higher than 0.7, with good prediction performance. The top three important employee turnover influencing characteristics and their weights are overtime work 0.647, monthly income 0.618, and interpersonal relationship 0.579. Accordingly, human resource management optimization strategies are designed and applied in Enterprise W to implement human resource management reform. After the reform, the average monthly separation rate has been reduced from 2.23% to 0.19%, and the average number of monthly separations has been reduced to only 7, which is 91.86% lower than during the pre-reform period. This study proposes feasible paths for modern information technology and artificial intelligence-enabled human resource management, and optimization of human resource management in a diverse work environment.",
    "doi": "10.2478/amns-2024-2556",
    "url": "https://www.semanticscholar.org/paper/9bc8e3b48b343b869fb204c271beb83de507e8f4",
    "pdf_url": "https://doi.org/10.2478/amns-2024-2556",
    "venue": "Applied Mathematics and Nonlinear Sciences",
    "citation_count": 2,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895196"
  },
  {
    "source": "semantic_scholar",
    "source_id": "e4af9104cb0a4b456cc0592b741f73ec34c72d06",
    "title": "Sustainable human resource management: A transformation perspective of human resource management functions through optimised artificial intelligence",
    "authors": [
      "Arif Furqon Nugraha Adz Zikri",
      "Sunu Widianto",
      "Rita Komaladewi"
    ],
    "year": 2024,
    "abstract": "Human resource management research which links to sustainability and the integration of artificial intelligence (AI) in HR practice has been increased. This paper explores the potential transformation of AI in HRM, revealing the factors that contribute to successful AI adoption and strategies to overcome adoption barriers within organisations. This research aims to verify a model for determining salaries for new employees that is competitive and in line with market standards. This paper also provides practical insights regarding how organisations can effectively analysis the role of HRM and AI to prevent undue evictions of HR professionals. To perform data analysis and processing, this research uses python analysis, with Jupyter notebook software and continues with model testing using regression evaluation model such as Mean Absolute Error (MAE), Mean Squared Error (MSE), Root Mean Squared Error (RMSE), and coefficient of determination R2-Score. The four main findings addressed in this study are lack of quality data, bias in data, loss of human aspect, and error and uncertainty. Furthermore, this research provides managerial implications for sustainable HRM practices in overcoming the main problem, namely determining new employee salaries using AI with the best accuracy by oversampling and comparing salaries through job portals to see current market trends.",
    "doi": "10.26740/bisma.v16n2.p167-189",
    "url": "https://www.semanticscholar.org/paper/e4af9104cb0a4b456cc0592b741f73ec34c72d06",
    "pdf_url": "https://doi.org/10.26740/bisma.v16n2.p167-189",
    "venue": "BISMA (Bisnis dan Manajemen)",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895201"
  },
  {
    "source": "semantic_scholar",
    "source_id": "53b04ccd2a001467d7ce168e9ce20b16a9466a69",
    "title": "Fairness And Bias in Artificial Intelligence: A Brief Survey of Sources, Impacts, And Mitigation Strategies",
    "authors": [
      "Emilio Ferrara"
    ],
    "year": 2023,
    "abstract": "The significant advancements in applying artificial intelligence (AI) to healthcare decision-making, medical diagnosis, and other domains have simultaneously raised concerns about the fairness and bias of AI systems. This is particularly critical in areas like healthcare, employment, criminal justice, credit scoring, and increasingly, in generative AI models (GenAI) that produce synthetic media. Such systems can lead to unfair outcomes and perpetuate existing inequalities, including generative biases that affect the representation of individuals in synthetic data. This survey study offers a succinct, comprehensive overview of fairness and bias in AI, addressing their sources, impacts, and mitigation strategies. We review sources of bias, such as data, algorithm, and human decision biases\u2014highlighting the emergent issue of generative AI bias, where models may reproduce and amplify societal stereotypes. We assess the societal impact of biased AI systems, focusing on perpetuating inequalities and reinforcing harmful stereotypes, especially as generative AI becomes more prevalent in creating content that influences public perception. We explore various proposed mitigation strategies, discuss the ethical considerations of their implementation, and emphasize the need for interdisciplinary collaboration to ensure effectiveness. Through a systematic literature review spanning multiple academic disciplines, we present definitions of AI bias and its different types, including a detailed look at generative AI bias. We discuss the negative impacts of AI bias on individuals and society and provide an overview of current approaches to mitigate AI bias, including data pre-processing, model selection, and post-processing. We emphasize the unique challenges presented by generative AI models and the importance of strategies specifically tailored to address these. Addressing bias in AI requires a holistic approach involving diverse and representative datasets, enhanced transparency and accountability in AI systems, and the exploration of alternative AI paradigms that prioritize fairness and ethical considerations. This survey contributes to the ongoing discussion on developing fair and unbiased AI systems by providing an overview of the sources, impacts, and mitigation strategies related to AI bias, with a particular focus on the emerging field of generative AI.",
    "doi": "10.3390/sci6010003",
    "url": "https://www.semanticscholar.org/paper/53b04ccd2a001467d7ce168e9ce20b16a9466a69",
    "pdf_url": "https://www.mdpi.com/2413-4155/6/1/3/pdf?version=1703577406",
    "venue": "Social Science Research Network",
    "citation_count": 528,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:49.895203"
  },
  {
    "source": "semantic_scholar",
    "source_id": "59fe933820a51d1e29afa8a6a923620f882e068b",
    "title": "ETHICAL IMPLICATIONS OF ARTIFICIAL INTELLIGENCE IN HUMAN RESOURCE MANAGEMENT FOR SUSTAINABLE DEVELOPMENT",
    "authors": [
      "Michal Val\u010do"
    ],
    "year": 2023,
    "abstract": "\"The research purpose is to explore the ethical implications of AI integration in HRM practices and its potential contribution to sustainable development. Research motivation: The rapid advancement of AI has brought forth numerous opportunities and challenges in HRM, including privacy concerns, bias, and discrimination. However, AI also has the potential to foster a culture of ethics and sustainability in organizations, and to address non-traditional security challenges and promote economic self-reliance. Research design, approach, and method: This paper will conduct a literature review of the latest research on AI in HRM and its ethical implications. The review will examine the relationship between AI and the ethical dimensions of HRM, such as privacy, surveillance, bias, and discrimination. It will also discuss the role of AI in fostering a culture of ethics and sustainability within organizations, and how it can be utilized to address non-traditional security challenges and promote an independent and self-reliant economy. Main findings: AI in HRM raises significant ethical concerns, including privacy and surveillance concerns, the potential for bias and discrimination, and the risk of over-reliance on AI at the expense of human judgment. AI has the potential to contribute significantly to sustainable development by optimizing resource allocation, improving efficiency, and facilitating decision-making processes. It can also foster a culture of ethics and sustainability within organizations and address non-traditional security challenges. However, the potential negative impacts of AI on sustainable development, such as its significant energy consumption and the risk of job displacement, should not be overlookedPractical/managerial implications: To harness the potential of AI in HRM while mitigating its risks, it is crucial to establish best practices and guidelines for its ethical use. These should include defining clear goals and objectives for AI implementation, involving stakeholders in the process, ensuring data quality, continuously monitoring and evaluating AIdriven processes, and addressing ethical considerations. Organizations must also carefully consider and address the challenges of implementing AI in HRM, such as data privacy concerns, algorithmic bias, ethical considerations, resistance to change, integration with existing systems, ensuring AI complements human decision-making, legal and regulatory compliance, and skills gap.\"",
    "doi": "10.51316/icpt.hust.2023.34",
    "url": "https://www.semanticscholar.org/paper/59fe933820a51d1e29afa8a6a923620f882e068b",
    "pdf_url": "",
    "venue": "The International Conference on Human Resources for Sustainable Development",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895204"
  },
  {
    "source": "semantic_scholar",
    "source_id": "41331cef3b4a3c0469c76047ae716bfe8f34ab0e",
    "title": "Bias and Fairness Issues in Artificial Intelligence-driven Cybersecurity",
    "authors": [
      "Ugochukwu Mmaduekwe"
    ],
    "year": 2024,
    "abstract": "Aim: This paper aims to examine the bias and fairness issues accorded with artificial intelligence (AI)-driven cybersecurity.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \nProblem Statement: The evolving global dependence on cybersecurity has exposed organizations, individuals, and nations to different vulnerabilities and security threats. However, merging of cyberspace with AI technologies has the potential to transform multiple domains but the implementation of AI is faced with bias problems limiting its application. \nSignificance of Study: Artificial intelligence and cybersecurity have been identified as two transformative and interconnected entities with great potential to revolutionize numerous areas of human life. However, it is imperative to critically look at the bias and fairness accorded with the implication of artificial intelligence-driven cybersecurity which are keywords limiting the usage and efficiency of the approach.\u00a0\u00a0 \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \nDiscussion: The concept of artificial intelligence and cybersecurity was discussed together with their interconnectivity which enhances the application in tackling cyber threats. Various areas of artificial intelligence deployment in cyberspace were presented. The sources and solutions to bias and fairness in artificial intelligence-driven cybersecurity were also discussed. This paper has critically discussed various ways via which AI biases influence cyber security. Nonetheless, ways by which this problem can be tackled were presented.\u00a0\u00a0\u00a0 \nConclusion: Artificial intelligence-driven cybersecurity has found wide industrial applications in different areas. However, there is a need to critically address the issues of bias and fairness attached to it to improve its efficiency. The use of the teams; AI model; and Corporate governance and leadership should be adopted to find lasting solutions to the problem of biases in AI-driven cyber security.",
    "doi": "10.9734/cjast/2024/v43i64391",
    "url": "https://www.semanticscholar.org/paper/41331cef3b4a3c0469c76047ae716bfe8f34ab0e",
    "pdf_url": "https://journalcjast.com/index.php/CJAST/article/download/4391/8740",
    "venue": "Current Journal of Applied Science and Technology",
    "citation_count": 5,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895206"
  },
  {
    "source": "semantic_scholar",
    "source_id": "92f2596f7d249a44ed7bbec0c25afc95dcc7597a",
    "title": "Analysis on Artificial Intelligence based Human Resource Computer Management System",
    "authors": [
      "Subrahmanya Bhat",
      "T. Padmavathi",
      "Kumuda P R",
      "Nuzhat Fatima Rizvi",
      "Suganya Bharathi S",
      "C. Madhuvappan"
    ],
    "year": 2024,
    "abstract": "Human resource management and competitiveness are becoming increasingly crucial in the growth of businesses. This study examines the factors of the enterprise survival environment in the process model of human asset management from the perception of control and computing. Based on systematic analysis, this study employs the SWOT is an acronym that stands for Strengths, Weaknesses, Opportunities, Threats, and analysis algorithm to creatively examine the contact of corresponding environmental elements on human resource management mode, and formulates a comprehensive set of human resource development plan. Simultaneously, in light of the control and computer challenges that exist in the human resource model, this study proposes specific implementation rules and methods, and theoretically verifies the efficacy and reliability of the related rules. By eliminating bias, automating tedious procedures, and empowering HR staff to make data-driven judgments, AI may expedite the hiring process. AI may save HR teams time and resources by, for instance, scheduling interviews, reviewing resumes, and performing preliminary candidate screening. It makes possible a data-driven strategy for hiring, promoting, and retaining people that aims to reduce bias and improve the experiences of both job searchers and workers.",
    "doi": "10.1109/ICSADL61749.2024.00021",
    "url": "https://www.semanticscholar.org/paper/92f2596f7d249a44ed7bbec0c25afc95dcc7597a",
    "pdf_url": "",
    "venue": "2024 3rd International Conference on Sentiment Analysis and Deep Learning (ICSADL)",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895208"
  },
  {
    "source": "semantic_scholar",
    "source_id": "4e351619058e4d30989bcb964e973f9db61f818c",
    "title": "Artificial intelligence and human capital: A review",
    "authors": [
      "N. Karunakaran",
      "K. V. Pradeep"
    ],
    "year": 2024,
    "abstract": "Artificial Intelligence (AI) has primarily impacted the global human capital. The human capital has been elucidated, focusing on their developing relationship with AI. The complex facets of human capital, including aptitude, proficiency, and competence, have been examined in this review, concentrating on the intricate association between AI and human capital. A secondary data analysis was conducted for this study, incorporating 16 studies that were meticulously chosen from online search engines. Key search words such as \"Human Capital and AI\" and \"AI and Human Resource Management\" were employed for collecting the articles. Compelling data was extracted from these articles to uncover the linkage between AI and human capital. The study yielded both affirmative and negative outcomes following a thorough review of articles. The research identified major concerns associated with AI-powered HR processes concerning bias, fairness, privacy, and security. It underscores the urgency for incorporating responsible AI practices and harnessing the potential of AI while mitigating risks and ensuring equitable human capital development. The connection between AI and human capital provides an invaluable resource for researchers, practitioners, and policymakers navigating the evolving landscape of workforce development in an era of AI-driven innovation.",
    "doi": "10.18231/j.jmra.2024.025",
    "url": "https://www.semanticscholar.org/paper/4e351619058e4d30989bcb964e973f9db61f818c",
    "pdf_url": "https://doi.org/10.18231/j.jmra.2024.025",
    "venue": "Journal of Management Research and Analysis",
    "citation_count": 2,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895210"
  },
  {
    "source": "semantic_scholar",
    "source_id": "7238f09714807e09ddc972e099d2f6a925617436",
    "title": "Ethics of the application of artificial intelligence in human resource management",
    "authors": [
      "A. S. Lobacheva",
      "O. Sobol"
    ],
    "year": 2021,
    "abstract": "The article reveals the main ethical problems and contradictions associated with the use of artificial intelligence. The paper reveals the concept of \u201cartificial intelligence\u201d. The authors analyse two areas of ethical problems of artificial intelligence: fundamental ideas about the ethics of artificial intelligent systems and the creation of ethical norms.The paper investigates the work of world organizations on the development of ethical standards for the use of artificial intelligence: the Institute of Electrical and Electronics Engineers and UNESCO. The study analyses the main difficulties in the implementation of artificial intelligent systems: the attitude of employees to the use of robots in production activities and the automation of processes that affect their work functions and work organization; ethical issues related to retraining and re-certification of employees in connection with the introduction of new software products and robots; ethical issues in reducing staff as a result of the introduction of artificial intelligence and automation of production and business processes; ethical problems of the processing of personal data of employees, including assessments of their psychological and physical condition, personal qualities and character traits, values\u00a0 and beliefs by specialized programs based on artificial intelligence, as well as tracking the work of employees; ethical contradictions when using special devices and tracking technologies in robotic technology and modern software products, which also extend to the employees interacting with them.",
    "doi": "10.26425/2658-3445-2021-4-1-20-28",
    "url": "https://www.semanticscholar.org/paper/7238f09714807e09ddc972e099d2f6a925617436",
    "pdf_url": "https://e-management.guu.ru/jour/article/download/138/91",
    "venue": "E-Management",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895211"
  },
  {
    "source": "semantic_scholar",
    "source_id": "609f936d990436b9ed9fab3c21e891fb3b417ee6",
    "title": "Balancing Technology, Ethics, and Society: A Review of Artificial Intelligence in Embryo Selection",
    "authors": [
      "Roberto Aufieri",
      "Francesco Mastrocola"
    ],
    "year": 2025,
    "abstract": "The introduction of artificial intelligence (AI) in embryo selection during in vitro fertilization presents distinct ethical and societal challenges compared to the general implementation of AI in healthcare. This narrative review examines ethical perspectives and potential societal implications of implementing AI-driven embryo selection. The literature reveals that some authors perceive AI as an extension of a technocratic paradigm that commodifies embryos, considering that any embryo selection methods undermine the dignity of human life. Others, instead, contend that prioritizing embryos with the highest viability is morally permissible while cautioning against discarding embryos based solely on unproven AI assessments. The reviewed literature identified further potential ethical concerns associated with this technique, including possible bias in the selection criteria, lack of transparency in black-box algorithms, risks of \u201cmachine paternalism\u201d replacing human judgment, privacy issues with sensitive fertility data, equity of access, and challenges in maintaining human-centered care. These findings, along with the results of the only randomized controlled trial available, suggest that the introduction of AI-driven embryo selection in clinical practice is not currently scientifically and ethically justified. Implementing and deploying ethical and responsible AI in embryo selection would be feasible only if the ethical and societal concerns raised are adequately addressed.",
    "doi": "10.3390/info16010018",
    "url": "https://www.semanticscholar.org/paper/609f936d990436b9ed9fab3c21e891fb3b417ee6",
    "pdf_url": "https://doi.org/10.3390/info16010018",
    "venue": "Inf.",
    "citation_count": 9,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:49.895213"
  },
  {
    "source": "semantic_scholar",
    "source_id": "52b3df2f621ad24a69e0e5e1ef834e86e87331e0",
    "title": "Mitigating Age-Related Bias in Large Language Models: Strategies for Responsible Artificial Intelligence Development",
    "authors": [
      "Zhuang Liu",
      "Shiyao Qian",
      "Shuirong Cao",
      "Tianyu Shi"
    ],
    "year": 2025,
    "abstract": "The increasing popularity of large language models (LLMs) in digital platforms elevates the urgency to address inherent biases, particularly age-related biases, which can significantly skew the model\u2019s fairness and performance. This paper introduces a novel two-stage bias mitigation approach utilizing LLM\u2019s empathy ability, reinforcement learning, and human-in-the-loop mechanisms to identify and correct age-related biases without altering model parameters. There are two modes for our bias mitigation strategy. Self-bias mitigation in the loop allows LLMs to self-assess and adjust their outputs autonomously, promoting inherent bias awareness and correction. Alternatively, cooperative bias mitigation in the loop leverages collaborative filtering among multiple LLMs to debate and mitigate biases through consensus. Furthermore, we introduce the empathetic perspective exchange strategy, which can further refine the answers by changing the perspective in the context information given to the LLM. In this way, more suitable responses applicable to different ages are generated. Our comprehensive evaluation across several data sets demonstrates that our trained model, FairLLM, significantly reduces age bias, outperforming existing techniques in fairness metrics. These findings underscore the effectiveness of our proposed framework in fostering the development of more equitable artificial intelligence systems, potentially benefiting a broader demographic spectrum by reducing digital ageism. History: This paper has been accepted by Kaushik Dutta for the Special Issue on Responsible AI and Data Science for Social Good. Funding: This work was supported by the National Natural Science Foundation of China [Grants 71971046, 72172029, 72403033, 72272028, and 72442025]. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2024.0645 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2024.0645 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .",
    "doi": "10.1287/ijoc.2024.0645",
    "url": "https://www.semanticscholar.org/paper/52b3df2f621ad24a69e0e5e1ef834e86e87331e0",
    "pdf_url": "",
    "venue": "INFORMS journal on computing",
    "citation_count": 7,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895214"
  },
  {
    "source": "semantic_scholar",
    "source_id": "2b34a0a10e53b9f623a1a5363cea8d332bb09757",
    "title": "Ethics and governance of artificial intelligence in digital China: Evidence from online survey and social media data",
    "authors": [
      "Jiongyi Cao",
      "Tianguang Meng"
    ],
    "year": 2025,
    "abstract": "With the emerging trend of artificial intelligence (AI) and its application in various fields, AI ethics and its related incidents have aroused concern and caused wide discussion in both society and academia around the world. In this paper, we discuss AI ethics and governance with respect to public perspectives. Based on the existing literature, policies, and guidelines on AI ethics, we sorted AI ethics concerns into eight dimensions: safety, transparency, fairness, personal data protection, liability, truthfulness, human autonomy, and human dignity. Combining online survey data with social media data, we quantified people's concerns on each dimension, and their attitudes toward AI governance policies and goals. The results shed light on how the public understands and views AI ethics and related governance. Finally, we propose several future directions in the development of AI ethics.",
    "doi": "10.1177/2057150X241313085",
    "url": "https://www.semanticscholar.org/paper/2b34a0a10e53b9f623a1a5363cea8d332bb09757",
    "pdf_url": "",
    "venue": "Chinese Journal of Sociology",
    "citation_count": 6,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895216"
  },
  {
    "source": "semantic_scholar",
    "source_id": "21c6ccffad2cf969aa3b74570fd50405ad700e90",
    "title": "Human Resource Management and Generative Artificial Intelligence (ChatGPT): Nexus, Perspectives and Praxis",
    "authors": [
      "Onyinyechi Ajaero",
      "Julius Bolade Anjorin"
    ],
    "year": 2024,
    "abstract": "The workplace is changing, ChatGPT and other AI technologies are leading the way. ChatGPT is a cutting-edge chatbot created by OpenAI that uses natural language processing to respond to user requests with \"human-like\" speech. Businesses all over the world are taking notice of it because of its robust capabilities, which have the possibility of helping automate a multitude of company procedures. The aim of the study is to identify the ChatGPT - Nexus, Perspectives and Praxis and investigate the concept\u2019s applicability to generative AI and HRM. This is to underscore and device remediation strategies with respect to likely difficulties in the broad use of ChatGPT in HRM. To stop unfair behaviors and ensure that employees are treated fairly, ethical issues like algorithmic bias and data privacy must be thoroughly examined. The methodology employed involves the use of qualitative paradigm involving the review of literature such as books, journals, publications, articles, online resources among others. The integrative literature review approach enables the researcher to conduct a critical assessment of AI technology vis-\u00e0-vis HRM. The study is anchored by one of the most widely accepted theories in human resource management \u2013 The Resource-Based View. The study predicts a significant decline in the likelihood of attaining a long-term competitive advantage through strategic Human Resource Management when considering the effects of widely used ChatGPT. The study's findings indicate that ChatGPT help team members communicate and work together more effectively by simplifying the understanding and tracking of project progress, processing and analyzing large amounts of text-based data, facilitating cross-cultural communication, and giving prompt, accurate answers to frequently asked questions. Hiring and recruiting are two critical HR processes towhich generative AI impacts immediate benefits.",
    "doi": "10.37745/gjhrm.2013/vol12n51929",
    "url": "https://www.semanticscholar.org/paper/21c6ccffad2cf969aa3b74570fd50405ad700e90",
    "pdf_url": "https://eajournals.org/gjhrm/wp-content/uploads/sites/34/2024/07/Human-Resource-Management.pdf",
    "venue": "Global journal of human resource management",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895217"
  },
  {
    "source": "semantic_scholar",
    "source_id": "312e66bcee5bad5376a97f4d771ecdcca2c78078",
    "title": "Transparency In The reporting of Artificial INtelligence \u2013 the TITAN guideline",
    "authors": [
      "R. Agha",
      "Ginimol Mathew",
      "Rasha Rashid",
      "Ahmed Kerwan",
      "A. Al-Jabir",
      "C. Sohrabi",
      "T. Franchi",
      "Maria Nicola",
      "M. Agha"
    ],
    "year": 2025,
    "abstract": "The use of AI in research and the literature is increasing. The need for transparency is clear. Here we present a guideline to transparently reporting the use of AI in any manuscript in general. The guideline items cover; declaration, purpose and scope, AI tools and configuration, data inputs and safeguards, human oversight and verification, bias, ethics and regulatory compliance and reproducibility and transparency. This guide will evolve over time as technology, systems and behaviour evolve.",
    "doi": "10.70389/pjs.100082",
    "url": "https://www.semanticscholar.org/paper/312e66bcee5bad5376a97f4d771ecdcca2c78078",
    "pdf_url": "",
    "venue": "Premier Journal of Science",
    "citation_count": 1398,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895219"
  },
  {
    "source": "semantic_scholar",
    "source_id": "21d151d9b338618999861a2c6833ba15718fd688",
    "title": "AI and Ethics: Scale Development for Measuring Ethical Perceptions of Artificial Intelligence Across Sectors and Countries",
    "authors": [
      "Ezgi Saatci"
    ],
    "year": 2025,
    "abstract": "Artificial Intelligence (AI) has rapidly become an integral technology across many sectors, including healthcare, finance, research, and manufacturing. AI\u2019s ability to automate processes, analyse large datasets, and make predictive decisions offers significant opportunities for innovation, but it also raises profound ethical challenges. Ethical concerns regarding AI encompass issues of transparency, accountability, fairness, data privacy, and the need for human oversight. Given the diverse applications of AI, these ethical concerns vary not only by sector but also across different cultural and regulatory environments. Despite growing discourse on AI ethics, empirical tools for assessing ethical perceptions of AI across varied organizational contexts remain limited. From that need, this study introduces the AI and Ethics Perception Scale (AEPS), designed to measure individual and collective perceptions of AI ethics across five key dimensions: Transparency, Accountability, Privacy, Fairness, and Human Oversight. The AEPS was developed through a rigorous methodological process, beginning with a pilot study of 112 participants and validated with data from 417 participants across three culturally diverse countries: Turkey, India, and the United Kingdom. The scale was used to assess ethical perceptions in sectors such as healthcare, finance, and manufacturing. Both Exploratory Factor Analysis (EFA) and Confirmatory Factor Analysis (CFA) were used to validate the scale\u2019s structure. This study reveals significant cross-cultural and cross-sectoral differences in the prioritization of ethical concerns, demonstrating the need for contextually sensitive ethical frameworks for AI governance.\n",
    "doi": "10.11648/j.ijebo.20251301.14",
    "url": "https://www.semanticscholar.org/paper/21d151d9b338618999861a2c6833ba15718fd688",
    "pdf_url": "",
    "venue": "International Journal of Economic Behavior and Organization",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895221"
  },
  {
    "source": "semantic_scholar",
    "source_id": "c54afa2427b1eaa8b5e7a31e592f6c4612d709a6",
    "title": "Potential of Artificial Intelligence in Boosting Employee Retention in the Human Resource Industry",
    "authors": [
      "S. Paigude",
      "Smita C. Pangarkar",
      "Sheela Hundekari",
      "Manisha Mali",
      "Kirti H. Wanjale",
      "Yashwant Dongre"
    ],
    "year": 2023,
    "abstract": "Artificial intelligence (AI) has the potential to transform the human resource (HR) industry by automating routine tasks, improving decision-making, and enhancing employee engagement and retention. In this paper, we explore the use of machine learning and deep learning techniques to boost employee retention in the HR industry. We review the current state of the art in AI for HR, including the use of predictive analytics, natural language processing, and chatbots for talent management and employee development. We also discuss the challenges and ethical considerations of using AI in HR, including issues of bias and the need for transparent and explainable algorithms. Finally, we present case studies of successful AI-powered HR initiatives that have demonstrated improvements in employee retention and engagement. Our findings suggest that AI has the potential to significantly enhance employee retention in the HR industry, but its implementation requires careful planning and consideration of potential risks and ethical issues.",
    "doi": "10.17762/ijritcc.v11i3s.6149",
    "url": "https://www.semanticscholar.org/paper/c54afa2427b1eaa8b5e7a31e592f6c4612d709a6",
    "pdf_url": "https://ijritcc.org/index.php/ijritcc/article/download/6149/5711",
    "venue": "International Journal on Recent and Innovation Trends in Computing and Communication",
    "citation_count": 33,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895223"
  },
  {
    "source": "semantic_scholar",
    "source_id": "ae0cf9e758bcbfcb2acfa58bb15aaccdd8745eaa",
    "title": "How artificial intelligence adopts human biases: the case of cosmetic skincare industry",
    "authors": [
      "A. Georgievskaya",
      "T. Tlyachev",
      "Daniil Danko",
      "K. Chekanov",
      "Hugo Corstjens"
    ],
    "year": 2023,
    "abstract": "The cosmetic skincare industry is a growing market that extends to different regions and customer groups. In addition to scientific advances and technological developments, state-of-the-art digital approaches, including machine learning and other artificial intelligence (AI)-based techniques, are being applied at different stages of the value chain. The objectives of these efforts include optimizing the supply chain, developing high-quality, effective and safe products and personalization at every step of the customer journey. However, the use of digital technologies comes with risks and undesirable effects. These include a lack of transparency and accountability, compromised fairness and a general deficiency in data governance, all of which are critical at every customer touchpoint. This dark side of digital transformation is recognized by both businesses and governments. In this paper, we explain the concept of bias leading to unfairness for beauty technology applications. Based on published data we identified potential sources of AI bias in the cosmetic skincare industry and/or beauty tech. They were classified by the stage of the AI lifecycle: biases related to target setting, to acquisition and annotation, to modeling, to validation and evaluation, and to deployment and monitoring. We aim to create awareness of such phenomena among readers, whether executives, managers, developers or potential end-users.",
    "doi": "10.1007/s43681-023-00378-2",
    "url": "https://www.semanticscholar.org/paper/ae0cf9e758bcbfcb2acfa58bb15aaccdd8745eaa",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s43681-023-00378-2.pdf",
    "venue": "AI and Ethics",
    "citation_count": 21,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:49.895224"
  },
  {
    "source": "semantic_scholar",
    "source_id": "58ce6320bf0642bf033e3a0afe4abc4a9278f7f0",
    "title": "A systematic literature review on artificial intelligence in recruiting and selection: a matter of ethics",
    "authors": [
      "Martina Mori",
      "Sara Sassetti",
      "Vincenzo Cavaliere",
      "Mariacristina Bonti"
    ],
    "year": 2024,
    "abstract": "PurposeStarting from the relevance of ethics to the application of artificial intelligence (AI) in the context of employee recruitment and selection (R&S), in this article, we aim to provide a comprehensive review of the literature in light of the main ethical theories (utilitarian theories, theories of justice, and theories of rights) to identify a future research agenda and practical implications.Design/methodology/approachOn the basis of the best-quality and most influential journals, we conducted a systematic review of 120 articles from two databases (Web of Science and Scopus) to provide descriptive results and adopt a framework for deductive classification of the main topics.FindingsInspired by the three ethical theories, we identified three thematic lines of enquiry for the debate on AI in R&S: (1) the utilitarian view: the efficient optimisation of R&S through AI; (2) the justice view: the perceptions of justice and fairness related to AI techniques; and (3) the rights view: the respect for legal and human rights requirements when AI is applied.Originality/valueThis article provides a detailed assessment of the adoption of AI in the R&S process from the standpoint of traditional ethics theories and offers an integrative theoretical framework for future research on AI in the broader field of HRM.",
    "doi": "10.1108/pr-03-2023-0257",
    "url": "https://www.semanticscholar.org/paper/58ce6320bf0642bf033e3a0afe4abc4a9278f7f0",
    "pdf_url": "",
    "venue": "Person-centered review",
    "citation_count": 29,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895226"
  },
  {
    "source": "semantic_scholar",
    "source_id": "934c5c7649d29a3429969910b4e473d237315670",
    "title": "AI AND HUMAN RESOURCE MANAGEMENT: A MULTIDISCIPLINARY PERSPECTIVE ON EFFICIENCY AND ETHICS",
    "authors": [
      "H. A",
      "Dr.S. Saravanan",
      "Dr Rajeshwari shinde",
      "D. Rawat",
      "Dr.Yazhini Kuppusamy",
      "Dr. O. Pandithurai"
    ],
    "year": 2025,
    "abstract": "The rapid integration of Artificial Intelligence (AI) into Human Resource Management (HRM) has redefined the traditional boundaries of workforce administration, talent acquisition, and employee engagement. As organizations increasingly rely on algorithmic systems for decision-making, the convergence of technological efficiency and ethical responsibility has emerged as a pivotal concern within modern management discourse. This research explores the multifaceted role of AI in reshaping HR functions through a multidisciplinary lens, combining insights from management science, behavioral psychology, data ethics, and organizational sociology. The study examines how AI-driven tools such as predictive analytics for recruitment, natural language processing in performance evaluation, and automated sentiment analysis for employee well-being have enhanced operational precision and strategic decision-making in HRM. Methodologically, the research employs a mixed approach, synthesizing empirical case studies, policy reviews, and theoretical frameworks to evaluate both the efficiency gains and ethical complexities arising from AI adoption. Findings indicate that AI significantly reduces administrative redundancy, enhances predictive accuracy in workforce planning, and enables a more data-driven understanding of employee behavior. However, these advancements are counterbalanced by profound ethical and social challenges, including algorithmic bias, loss of transparency, privacy intrusions, and the erosion of human discretion in evaluative processes. The analysis reveals that while AI augments managerial capabilities, its unregulated application risks transforming human resources into mere data entities, thereby undermining the human-centric foundations of employment relations. The paper argues that a sustainable integration of AI in HRM must reconcile the competing imperatives of efficiency and ethics through an adaptive governance framework. This includes instituting algorithmic accountability, transparent data management policies, and cross-disciplinary collaboration between technologists, ethicists, and HR professionals. Furthermore, the study emphasizes the importance of cultivating digital literacy and ethical awareness among HR practitioners to ensure that AI complements rather than replaces human judgment. Ultimately, the research contributes to the growing discourse on responsible AI by demonstrating that technological progress in HRM must be guided not only by efficiency metrics but also by normative principles that preserve fairness, dignity, and inclusivity in the workplace. It calls for a paradigm shift toward a balanced, ethically informed, and human-centered approach to managing the future of work. \n\u00a0",
    "doi": "10.52152/rs45sj42",
    "url": "https://www.semanticscholar.org/paper/934c5c7649d29a3429969910b4e473d237315670",
    "pdf_url": "",
    "venue": "Lex localis - Journal of Local Self-Government",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895227"
  },
  {
    "source": "semantic_scholar",
    "source_id": "97027eb0412de7a15ecd19e05b2f997b4da945c9",
    "title": "Ethics and Artificial Intelligence",
    "authors": [
      "Bhautik Modi"
    ],
    "year": 2025,
    "abstract": "Artificial Intelligence (AI) is revolutionizing industries ranging from healthcare and finance to transportation and warfare. However, its rapid advancement presents profound ethical challenges, including algorithmic bias, privacy concerns, accountability, and workforce disruption. This article explores key dimensions of AI ethics, such as defining ethical boundaries, addressing bias, and navigating privacy in the age of data-driven innovation. It highlights ethical dilemmas in healthcare, workforce implications, and military applications of AI. Furthermore, the article underscores the need for global regulatory frameworks, interdisciplinary collaboration, and stakeholder engagement to ensure responsible AI development. As AI continues to evolve, a balance between innovation and ethical oversight is paramount to aligning technological progress with societal values and human rights. By fostering inclusivity and prioritizing transparency, we can navigate the complexities of AI ethics and harness its transformative potential responsibly.",
    "doi": "10.55489/ijmr.1303202582",
    "url": "https://www.semanticscholar.org/paper/97027eb0412de7a15ecd19e05b2f997b4da945c9",
    "pdf_url": "",
    "venue": "International Journal of Medical Research",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895229"
  },
  {
    "source": "semantic_scholar",
    "source_id": "5a81b9633cdcebbb1b09ca0fa21657165f2c0014",
    "title": "A Study On Artificial Intelligence Ethics In Education",
    "authors": [
      "H. Vashistha",
      "Harikrishnan M"
    ],
    "year": 2025,
    "abstract": "This rapid advancement and development of Artificial Intelligence (AI) technologies has significantly transformed various sectors, like research and development sectors, education sectors including education. As educational institutions increasingly integrate AI tools and systems, to gather information, data and other necessary items, use of Artificial Intelligence (AI) has become a common practice as well as a basic necessity. This study explores the necessity of incorporating AI ethics into education curricula, examining how ethical considerations can guide the development, deployment, and use of AI technologies within academic settings, this study also includes the negative impact that AI is putting on our human mind, human intelligence and the thinking ability of the human beings. We will find out how the AI is making us lazy not to use our own brain or study books and other informative items like journals, research papers, magazines etc to gather information. Through a comprehensive review of current literature and case studies, the research highlights key ethical concerns such as data privacy, algorithmic bias, and the impact of AI on academic integrity and student outcomes (Anderson & Anderson, 2018; Binns, 2018). The study also assesses existing frameworks and guidelines for AI ethics and their applicability to education contexts (Chen et al., 2020). By identifying gaps and proposing actionable recommendations, this study aims to provide educators, policymakers, and AI practitioners with a strategic approach to embedding ethical practices in AI-related education. The findings underscore the importance of developing a multidisciplinary approach to AI ethics that incorporates insights from computer science, philosophy, law, and education to ensure that AI technologies are used responsibility and equitably in academic environments (Floridi, 2019; Holmes et al., 2019).",
    "doi": "10.36948/ijfmr.2025.v07i01.36798",
    "url": "https://www.semanticscholar.org/paper/5a81b9633cdcebbb1b09ca0fa21657165f2c0014",
    "pdf_url": "",
    "venue": "International Journal For Multidisciplinary Research",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895230"
  },
  {
    "source": "semantic_scholar",
    "source_id": "5fe35633c4e78e00f481130220a510de87a16092",
    "title": "Research on Algorithmic Ethics in Artificial Intelligence",
    "authors": [
      "Xinying Xu"
    ],
    "year": 2024,
    "abstract": "With the rapid development of artificial intelligence, the ethical issues of artificial intelligence have become increasingly prominent. This paper discusses the problems of data security, bias and the implantation of morality and values in the ethics of artificial intelligence algorithms, and systematically and comprehensively expounds the main solutions to these three problems. It is found that the current three major technical paths for solving the data security issues have the problems of high dependency, large computation and communication overhead, and limited applicability, and the future trend is the integration and development of the three paths; the solution of the bias problem needs to be improved in terms of interpretability under the condition that the underlying fairness is difficult to be determined; and it is difficult for the implantation of morality and values to take into account the learning ability, adaptability, and interpretability at the same time. Finally, this paper analyzes and looks forward to the development of AI ethics, hoping to provide lessons and references for AI ethics-related research.",
    "doi": "10.1109/IoTAAI62601.2024.10692746",
    "url": "https://www.semanticscholar.org/paper/5fe35633c4e78e00f481130220a510de87a16092",
    "pdf_url": "",
    "venue": "2024 6th International Conference on Internet of Things, Automation and Artificial Intelligence (IoTAAI)",
    "citation_count": 0,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:49.895232"
  },
  {
    "source": "semantic_scholar",
    "source_id": "e6cb3bd3c0f7ffc55a8d5af27c4c57e57601138b",
    "title": "Fairness, Bias, and Ethics in AI: Exploring the Factors Affecting Student Performance",
    "authors": [
      "N. Gordon",
      "Tareq Al Jaber",
      "Doris Omughelli"
    ],
    "year": 2024,
    "abstract": "The use of artificial intelligence (AI) as a data science tool for education has enormous potential for increasing student performance and course outcomes. However, the growing concern about fairness, bias, and ethics in AI systems requires a careful examination of these issues in an educational context. Using AI and predictive modelling tools, this paper explores the aspects influencing student performance and course success. The Open University Learning Analytics Dataset (OULAD) is analysed using several AI techniques (logistic regression and random forest) in this study to reveal insights about fairness, ethics, and potential biases. This dataset has been used by hundreds of studies to explore how educational data mining can provide information on students. However, potential bias or unfairness in that dataset could undermine the results and any conclusions made from them. To gain insights into the dataset's properties, this was analysed using a typical data science methodology, which included data collecting, cleaning, and exploratory data analysis using Python. By applying AI-based predictive models, this study\u00a0aims\u00a0to detect potential biases and their impact on student outcomes. Fairness and ethical considerations are central to the analysis as the representation of various demographic groups and any disparities are\u00a0evaluated\u00a0in course results. The goal is to provide useful insights on the proper use of AI in education, while also maintaining equitable and transparent decision-making procedures. The findings shed light on the complicated interplay between artificial intelligence, fairness, and ethics in the context of student performance and course success. As artificial intelligence continues to influence the educational landscape, this study will provide useful ideas for encouraging fairness and minimising biases, resulting in a more inclusive and equal learning environment.",
    "doi": "10.54963/jic.v4i1.306",
    "url": "https://www.semanticscholar.org/paper/e6cb3bd3c0f7ffc55a8d5af27c4c57e57601138b",
    "pdf_url": "https://ojs.ukscip.com/journals/jic/article/download/306/258",
    "venue": "Journal of Intelligent Communication",
    "citation_count": 6,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895233"
  },
  {
    "source": "semantic_scholar",
    "source_id": "e340d387f359e98cad6c604f5279cc4a5171aee2",
    "title": "Fairness and bias in AI: a sociotechnical perspective",
    "authors": [
      "Sanae el Mimouni",
      "M. Bouhdadi"
    ],
    "year": 2025,
    "abstract": "\n \n This paper aims to advance a comprehensive sociotechnical framework for addressing fairness and bias in artificial intelligence (AI) systems, recognizing that purely technical solutions are insufficient to ensure equitable AI deployment across sectors such as hiring, lending and criminal justice.\n \n \n \n This study critically evaluates existing technical solutions for mitigating bias, highlighting their limitations in addressing real-world sociocultural contexts. A sociotechnical framework that combines algorithmic techniques, human oversight, regulatory frameworks and stakeholder engagement is proposed.\n \n \n \n This study presents a multi-component framework that integrates technical debiasing methods, stakeholder engagement, human oversight, regulatory compliance and continuous evaluation. The framework demonstrates that combining technical expertise, social science insights and diverse stakeholder perspectives leads to more effective bias mitigation and fairer AI systems.\n \n \n \n Although the framework provides a theoretical foundation, its practical implementation across different contexts and organizations requires further empirical validation. Future research should focus on measuring the effectiveness of this framework in real-world applications.\n \n \n \n This paper advances the field by proposing a comprehensive sociotechnical framework that bridges the gap between technical and social approaches to AI fairness, providing practical guidelines for organizations while acknowledging the complexity of implementing fair AI systems.\n",
    "doi": "10.1108/jices-12-2024-0182",
    "url": "https://www.semanticscholar.org/paper/e340d387f359e98cad6c604f5279cc4a5171aee2",
    "pdf_url": "",
    "venue": "Journal of Information, Communication and Ethics in Society",
    "citation_count": 3,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895235"
  },
  {
    "source": "semantic_scholar",
    "source_id": "401be0ddf265363b621a7f9ab15eb0665503d7e7",
    "title": "An Overview of Artificial Intelligence Ethics: Issues and Solution for Challenges in Different Fields",
    "authors": [
      "S. P. Santhoshkumar",
      "K. Susithra",
      "T. K. Prasath"
    ],
    "year": 2023,
    "abstract": "Artificial Intelligence (AI) ethics are the values and principles that govern the creation and application of AI. As AI technology develops quickly, there is rising worry about the possible ethical ramifications of its application, including concerns about privacy, bias, accountability, transparency, safety, and the effect on society as a whole. Making sure AI systems are created and used in a way that respects human rights and values is one of the main concerns of AI ethics. For instance, there can be worries about the use of AI in surveillance or the possibility that these technologies will legitimise already-existing social prejudices and discrimination. Making sure AI systems are accountable and transparent is a key aspect of AI ethics. It can be challenging to comprehend how AI systems make judgements and who is accountable for those decisions as they get more complicated and autonomous. Transparency in AI research and decision-making, as well as systems for accountability and remedies when things go wrong, are becoming increasingly important. Additionally, it's important to guarantee the security and safety of AI systems. Concern over the possibility of cyberattacks and other types of harmful use is growing as AI systems become more linked and incorporated into our daily lives. Finally, it's important to make sure that AI is created and applied in a way that benefits all humanity. This entails tackling problems like employment loss, economic inequality, and the possibility that AI will be applied in ways that are detrimental to society. There is an increasing need for cooperation between business, government, academia, and civil society to address these and other ethical issues. This involves creating moral standards, norms, and best practises as well as the systems necessary to guarantee responsibility and compliance.",
    "doi": "10.36548/jaicn.2023.1.006",
    "url": "https://www.semanticscholar.org/paper/401be0ddf265363b621a7f9ab15eb0665503d7e7",
    "pdf_url": "https://doi.org/10.36548/jaicn.2023.1.006",
    "venue": "March 2023",
    "citation_count": 5,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895236"
  },
  {
    "source": "semantic_scholar",
    "source_id": "26ad600f03e0b0395ca2d1c291a2f8cddc24eadd",
    "title": "Faith and Artificial Intelligence (AI) in Catholic Education: A Theological Virtue Ethics Perspective",
    "authors": [
      "Jeff Clyde Corpuz"
    ],
    "year": 2025,
    "abstract": "This study responds to the increasing call for thoughtful theological and ethical engagement with Artificial Intelligence (AI) by examining the role of personal theological reflection using Generative Artificial Intelligence (GenAI) content in Catholic theological education. It investigates how both educators and students might utilize AI-generated imagery as a pedagogical resource with which to enrich theological insight and foster ethical discernment, particularly through the lens of theological virtue ethics. AI is not a substitute for all human tasks. However, the use of AI holds potential for theology and catechetical religious education. Following Gl\u00e4ser-Zikuda\u2019s model of Self-Reflecting Methods of Learning Research, this study systematically engages in reflective observation to examine how the use of GenAI in theology classrooms has influenced personal theological thinking, pedagogical practices, and ethical considerations. It documents experiences using common generative AI tools such as ChatGPT, Canva, Meta AI, Deep AI, and Gencraft in theology classes. The principles of virtue ethics and Human-Centered Artificial Intelligence (HCAI) offer a critical framework for ethical, pedagogical, and theological engagement. The findings contribute to the emerging interdisciplinary discourse on AI ethics and theology, and religious pedagogy in the digital age.",
    "doi": "10.3390/rel16081083",
    "url": "https://www.semanticscholar.org/paper/26ad600f03e0b0395ca2d1c291a2f8cddc24eadd",
    "pdf_url": "",
    "venue": "Religions",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895238"
  },
  {
    "source": "semantic_scholar",
    "source_id": "fe2af1b0bbe5a66edb8ad90133ccc1f05dddb44d",
    "title": "Issues and Prospects in the Use of Artificial Intelligence in Human Resource Management",
    "authors": [
      "Swati Atmaram Chougule"
    ],
    "year": 2023,
    "abstract": "We examine the gap between the promise and reality of artificial intelligence in human resource management and propose ways forward. We highlight four problems with using data science approaches to human resource tasks: 1) the complexity of HR phenomena, 2) the restrictions imposed by tiny data sets, 3) accountability problems related to fairness and other ethical and regulatory constraints, and 4) the possibility of unfavorable employee responses to management choices using data-based algorithms. We suggest practical solutions to these issues, focusing on three overlapping concepts-cause and effect, randomization and trials, and employee input-that might be both economically efficient and socially suitable for employing data science in employee management.",
    "doi": "10.51976/ijari.1042208",
    "url": "https://www.semanticscholar.org/paper/fe2af1b0bbe5a66edb8ad90133ccc1f05dddb44d",
    "pdf_url": "https://doi.org/10.51976/ijari.1042208",
    "venue": "International journal of advance research and innovation",
    "citation_count": 2,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895240"
  },
  {
    "source": "semantic_scholar",
    "source_id": "fe33b5a74255728246848eab05023a78b1f6aa43",
    "title": "Role Of Artificial Intelligence in Human Resources",
    "authors": [
      "Palak Soni"
    ],
    "year": 2025,
    "abstract": "Abstract\n\n \n\nArtificial Intelligence (AI) has become a transformative force in Human Resource Management (HRM), revolutionizing core functions such as recruitment, performance management, training, and employee engagement. This paper explores the integration of AI in HR processes, focusing on its applications, benefits, and associated challenges. A combination of literature review and primary research has been used to understand the current trends, potential advantages, and ethical concerns. The findings suggest that while AI significantly enhances efficiency and data-driven decision-making in HR, concerns regarding algorithmic bias, data privacy, and the loss of human touch remain. This study provides insights into how organizations can responsibly implement AI in HR, balancing technological innovation with ethical and human-centric practices.",
    "doi": "10.55041/ijsrem50409",
    "url": "https://www.semanticscholar.org/paper/fe33b5a74255728246848eab05023a78b1f6aa43",
    "pdf_url": "",
    "venue": "INTERNATIONAL JOURNAL OF SCIENTIFIC RESEARCH IN ENGINEERING AND MANAGEMENT",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895286"
  },
  {
    "source": "semantic_scholar",
    "source_id": "2ad6b8c806b81fd7e3efa39767429832b448902f",
    "title": "AI Ethics in Engineering: Enhancing Fairness in Machine Learning Models for Critical Systems",
    "authors": [
      "Vijayalaxmi Methuku",
      "Direesh Reddy Aunugu",
      "Anil Kumar Jonnalagadda",
      "Praveen Kumar Myakala"
    ],
    "year": 2025,
    "abstract": "The integration of artificial intelligence (AI) and machine learning (ML) into engineering systems has revolutionized industries such as autonomous vehicles, renewable energy management, and industrial automation. While these advancements have significantly improved efficiency, predictive accuracy, and operational reliability, they have also introduced ethical challenges, particularly concerning fairness and bias in decision-making. This study investigates the ethical implications of AI in critical engineering systems, focusing on fairness in resource allocation, fault detection, and safety-critical applications. Three engineering datasets were analyzed to evaluate bias and fairness in ML models: the KITTI Vision Benchmark Suite for autonomous vehicles, NASA\u2019s C-MAPSS dataset for aerospace predictive maintenance, and the UCI Gas Sensor Array Drift dataset for industrial IoT applications. Ensemble methods such as Random Forest and LightGBM were employed due to their robustness in handling complex datasets. Bias mitigation strategies, including reweighting, data augmentation, and fairness constraints, were applied to address disparities and ensure equitable outcomes. Results demonstrated significant improvements in fairness metrics, with demographic parity, equal opportunity, and disparate impact showing an average enhancement of over 30% across datasets. Precision improved by 9.75%, recall increased by 17.71%, and AUC-ROC rose by 14.18%. Although accuracy experienced a minor reduction (3% on average), these gains underscore the effectiveness of the mitigation techniques in achieving fairness while maintaining system performance. This study highlights the importance of integrating fairness into AI models for engineering systems, balancing performance with ethical considerations to ensure equitable and reliable outcomes in critical applications.",
    "doi": "10.1109/ICCIES63851.2025.11032595",
    "url": "https://www.semanticscholar.org/paper/2ad6b8c806b81fd7e3efa39767429832b448902f",
    "pdf_url": "",
    "venue": "2025 International Conference on Computational Innovations and Engineering Sustainability (ICCIES)",
    "citation_count": 3,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895289"
  },
  {
    "source": "semantic_scholar",
    "source_id": "3e61f0f22f9d53b2deca9af45c03b6bf3092d0ea",
    "title": "The Role of Artificial Intelligence in Modern Human Resource Management: A Review",
    "authors": [
      "Priti Dubey"
    ],
    "year": 2023,
    "abstract": "More than anything else, artificial intelligence is crucial to the human resources sector. In order to recruit and create a competent staffing and hiring process, HR recruiters have integrated AI technologies. HR duties are anticipated to adapt in tandem with the ongoing changes in the workplace and the advancement of technology in all industries nowadays. In this article review the various study on role of artificial intelligence in modern human resource management. It concluded that AI is transforming Human Resource Management (HRM) by improving efficiency, decision-making, and employee experience. It streamlines recruitment, talent management, performance evaluation, and workplace safety while enabling data-driven insights. However, ethical concerns such as bias and job displacement must be addressed. Balancing AI automation with human empathy is crucial for its success. This review highlights AI\u2019s potential and its mediating factors, such as creativity and usability, in HRM. While AI offers significant benefits, industry-specific challenges and its evolving nature must be considered. Thoughtful and strategic AI integration will ensure ethical, effective, and sustainable workforce management in modern organizations.",
    "doi": "10.69968/ijisem.2023v2i459-64",
    "url": "https://www.semanticscholar.org/paper/3e61f0f22f9d53b2deca9af45c03b6bf3092d0ea",
    "pdf_url": "",
    "venue": "International Journal of Innovations in Science Engineering And Management",
    "citation_count": 3,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895290"
  },
  {
    "source": "semantic_scholar",
    "source_id": "3c75e26a59826ace7d7a12762c3cb0021b682119",
    "title": "Artificial Intelligence in Human Resource Management: Advancements, Implications and Future Prospects",
    "authors": [
      "Saraswathi T",
      "Karthikeyan M",
      "C. Balakrishnan",
      "T. Nithya",
      "B. Maheswari",
      "Siva Subramanian.R"
    ],
    "year": 2023,
    "abstract": "The present condition, challenges, and potential applications of artificial intelligence (AI) in human resource management (HRM) are all explored in this survey article. As an innovation, artificial intelligence (AI) has the potential to completely revolutionize several facets of human resource management (HRM). Examining the usage of AI-powered tools and systems in different HR processes, the present situation with AI in HRM is examined. These encompass learning and development, performance management, employee engagement, and recruiting. The use of AI algorithms and machine learning approaches to automate regular HR operations, analyze vast amounts of employee data, and provide insightful data to aid decision-making is addressed in this article. However, integrating AI into HRM also poses a number of difficulties that must be resolved. Bias, privacy issues, and transparency are just a few of the ethical and legal ramifications of using AI in decision-making processes that are discussed in this survey. The study emphasizes how accountability and fairness must be maintained in AI systems by responsible design, oversight, and periodic evaluation. With an emphasis on job displacement and workforce reorganization, the possible influence of AI on the human workforce is also explored. To effectively traverse this change, strategies including work role redefinition, employee up skilling, and establishing a collaborative atmosphere between humans and AI are suggested. The possible advantages and breakthroughs that AI might bring to HRM practices are highlighted as the future perspectives of AI in HRM are examined. As new applications for AI in HRM, sentiment analysis, predictive analytics, intelligent decision support, and personalized employee experiences are all highlighted. In order to fully realize the promise of AI in HRM, the study underlines the significance of data infrastructure, data governance frameworks, and a data-driven culture. Overall, this survey study offers an in-depth review of the existing situation, difficulties, and prospects for AI in HRM. It aggregates current information, identifies research gaps, and gives practitioners and scholars new perspectives on how AI will fundamentally alter the way HRM activities are carried out in the future.",
    "doi": "10.17762/ijritcc.v11i11s.8099",
    "url": "https://www.semanticscholar.org/paper/3c75e26a59826ace7d7a12762c3cb0021b682119",
    "pdf_url": "https://ijritcc.org/index.php/ijritcc/article/download/8099/6531",
    "venue": "International Journal on Recent and Innovation Trends in Computing and Communication",
    "citation_count": 3,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895292"
  },
  {
    "source": "semantic_scholar",
    "source_id": "6579b1945d457ffddc4e3baf3c2d39b89517da1f",
    "title": "Transformative AI in human resource management: enhancing workforce planning with topic modeling",
    "authors": [
      "Murale Venugopal",
      "Vandana Madhavan",
      "Rajiv Prasad",
      "R. Raman"
    ],
    "year": 2024,
    "abstract": "Abstract This study explores the transformative role of artificial intelligence (AI) in human resource management (HRM), focusing on key functions such as recruitment, retention, and performance management. A comprehensive review was carried out PRISMA framework and BERTopic model on AI and HRM\u2011related keywords. The resulting publications were analyzed to extract meaningful topics. AI\u2011driven tools streamline candidate screening and interview analysis, significantly enhancing hiring efficiency and decision\u2011making accuracy. Concerns about algorithmic bias highlight the need for robust governance frameworks to ensure transparency and fairness in AI\u2011driven processes. The study emphasizes the importance of aligning AI adoption with Organizational Development principles to foster inclusivity and organizational justice. The integration of AI in performance management facilitates real\u2011time, objective performance assessments, although overreliance on such technologies can affect employee trust and engagement. Despite these advances, the study highlights ethical concerns surrounding data privacy and the potential for algorithmic bias. Addressing these challenges requires the implementation of comprehensive ethical frameworks to promote fairness and inclusivity in AI\u2011HRM applications. Strategically, AI transforms HR from a reactive function to a proactive, data\u2011driven partner aligned with long\u2011term organizational goals. Successful AI integration depends on governance mechanisms that uphold ethical standards, foster employee trust, and ensure transparency, enabling organizations to fully leverage AI\u2019s potential in enhancing workforce management.",
    "doi": "10.1080/23311975.2024.2432550",
    "url": "https://www.semanticscholar.org/paper/6579b1945d457ffddc4e3baf3c2d39b89517da1f",
    "pdf_url": "",
    "venue": "Cogent Business &amp; Management",
    "citation_count": 37,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895294"
  },
  {
    "source": "semantic_scholar",
    "source_id": "36b7144904d27483369d7f0a0a62000e85ba9e45",
    "title": "AI-Driven human resource systems for equitable workplaces: A roadmap for the future of U.S. healthcare and nonprofits",
    "authors": [
      "Ndifreke D. Essien",
      "Chibuzor Njoku",
      "Ifeoma Solomon",
      "Evelyn Gachui"
    ],
    "year": 2025,
    "abstract": "Artificial Intelligence (AI) is increasingly transforming Human Resource (HR) systems, offering new possibilities for addressing systemic challenges in healthcare and nonprofit sectors\u2014namely, burnout, workforce attrition, and inequitable employment practices. This literature review explores how AI-driven tools such as machine learning, predictive analytics, and digital automation are being applied to core HR functions including burnout detection, pay equity analysis, performance evaluation, scheduling, and turnover prediction. With burnout rates rising and equity gaps persisting, particularly in mission-driven environments, AI presents an opportunity to deliver data-informed, scalable interventions that improve employee well-being and organizational fairness. The review highlights key benefits of AI integration, including administrative efficiency, reduced bias, improved decision-making, and early intervention capabilities. It also critically examines ethical challenges related to algorithmic bias, transparency, employee privacy, and the potential dehumanization of workplace interactions. Drawing on case studies, regulatory guidance, and emerging research, the manuscript proposes a roadmap for ethical AI implementation tailored to the values of social impact organizations. The recommendations emphasize human oversight, stakeholder inclusion, AI literacy, and privacy safeguards. The analysis concludes that AI\u2019s role in HR should be augmentative\u2014amplifying human empathy and institutional integrity. When guided by equitable frameworks, AI-enabled HR systems can not only mitigate existing workplace inequities but also build more resilient, inclusive, and sustainable workforces across healthcare and nonprofit sectors. \nKeywords: Artificial Intelligence, Burnout Prevention, Compensation Equity, Workforce Optimization, Human Resource Technology, Nonprofit Organizations, Healthcare Workforce, Predictive Analytics, Ethical AI, HH Innovation.",
    "doi": "10.51594/ijarss.v7i5.1916",
    "url": "https://www.semanticscholar.org/paper/36b7144904d27483369d7f0a0a62000e85ba9e45",
    "pdf_url": "",
    "venue": "International journal of applied research in social sciences",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895295"
  },
  {
    "source": "semantic_scholar",
    "source_id": "c1964f69305ddec12274a1ac29492b1b609e66e3",
    "title": "Ethics of artificial intelligence in embryo assessment: mapping the terrain",
    "authors": [
      "J. Koplin",
      "M. Johnston",
      "Amy Webb",
      "Andrea Whittaker",
      "Catherine Mills"
    ],
    "year": 2024,
    "abstract": "Abstract Artificial intelligence (AI) has the potential to standardize and automate important aspects of fertility treatment, improving clinical outcomes. One promising application of AI in the fertility clinic is the use of machine learning (ML) tools to assess embryos for transfer. The successful clinical implementation of these tools in ways that do not erode consumer trust requires an awareness of the ethical issues that these technologies raise, and the development of strategies to manage any ethical concerns. However, to date, there has been little published literature on the ethics of using ML in embryo assessment. This mini-review contributes to this nascent area of discussion by surveying the key ethical concerns raised by ML technologies in healthcare and medicine more generally, and identifying which are germane to the use of ML in the assessment of embryos. We report concerns about the \u2018dehumanization\u2019 of human reproduction, algorithmic bias, responsibility, transparency and explainability, deskilling, and justice.",
    "doi": "10.1093/humrep/deae264",
    "url": "https://www.semanticscholar.org/paper/c1964f69305ddec12274a1ac29492b1b609e66e3",
    "pdf_url": "",
    "venue": "Human Reproduction",
    "citation_count": 16,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:49.895297"
  },
  {
    "source": "semantic_scholar",
    "source_id": "d414fad4602cafc68637c0ab105775c40e584aea",
    "title": "Problematizing the role of artificial intelligence in hiring and organizational inequalities: A multidisciplinary review",
    "authors": [
      "Karen D Hughes",
      "Alla Konnikov",
      "Nicole Denier",
      "Yang Hu"
    ],
    "year": 2025,
    "abstract": "What are the implications of the growing use of artificial intelligence (AI) in recruitment and hiring for organizational inequalities? While advocates suggest that AI is a groundbreaking tool that can enhance hiring precision, efficiency, diversity and fit, critics raise serious concerns around bias, fairness, and privacy. This review article critically advances this debate by drawing on diverse scholarship across computing and data sciences; human resource, management, and organization studies; social sciences; and law. Using a hybrid review approach that combines scoping and problematizing review methods, we examine the implications of algorithmic hiring for organizational inequalities. Our review identifies a multidisciplinary discussion marked by asymmetries in how key concerns are conceptualized; a clear and heightened potential for AI to conceal inequalities in hiring processes; and contestation over the regulation of algorithmic hiring. Building on Acker\u2019s (2006) framework of \u2018inequality regimes\u2019, we propose the concept of algorithmically-mediated inequality regimes to highlight AI\u2019s capacity for concealing and reproducing inequalities in hiring through enhanced algorithmic invisibility and the growing legitimacy of AI solutions. We propose an agenda for future research, policy, and practice, emphasizing the need for an interdisciplinary \u2018chain of knowledge\u2019 and a multi-stakeholder \u2018chain of responsibility\u2019 in AI application and regulation.",
    "doi": "10.1177/00187267251403902",
    "url": "https://www.semanticscholar.org/paper/d414fad4602cafc68637c0ab105775c40e584aea",
    "pdf_url": "",
    "venue": "Human relations; studies towards the integration of the social sciences",
    "citation_count": 1,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:49.895299"
  },
  {
    "source": "semantic_scholar",
    "source_id": "f810af61e1e72315c15263aeef874d58d03fe06b",
    "title": "Recalibrating Human\u2013Machine Relations through Bias-Aware Machine Learning: Technical Pathways to Fairness and Trust",
    "authors": [
      "Esam Othman",
      "R. Mahafdah"
    ],
    "year": 2025,
    "abstract": "Considering the importance of artificial intelligence (AI) in decision-making processes in various fields such as health, law and finance, the concern for bias and fairness of decision making has increased. This paper presents an extensive discussion of bias-aware machine learning(Ml) such as fairness-aware modeling, detection and mitigation. The paper demonstrates aspects of fairness, different forms of algorithmic bias including intersectional bias and how biased systems impact society. The paper turns to appreciation of dentieth, Trust Dynamics, Legal and Regulatory Frameworks And in the Context of Promoting Transparency: Exploring the Role of Explainable AI (XAI). Taking into account the current advances for combatting bias, also pre-processing, in-processing, and post-processing methods, for instance, draw on examples from major domains of interest. Apart from the improvements AIs have achieved, existing challenges involve little attention to relationship among different identities, poor frameworks in place for implementation and operation in other parts of the world, inadequate abuse detection mechanisms among others. Regarding this, we present some of the research questions that focus on the notions of transparency, privacy protected fairness audits, and shared control with the aim of guiding the growth of fair, responsible, and competent AI systems.",
    "doi": "10.63332/joph.v5i4.1091",
    "url": "https://www.semanticscholar.org/paper/f810af61e1e72315c15263aeef874d58d03fe06b",
    "pdf_url": "",
    "venue": "Journal of Posthumanism",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895300"
  },
  {
    "source": "semantic_scholar",
    "source_id": "84eb79e6898bf19d51b363a820694007d5b5dd21",
    "title": "Leveraging Artificial Intelligence for Human Resource Analytics from Recruitment to Retention",
    "authors": [],
    "year": 2025,
    "abstract": "Background: Human Resource Management (HRM) experiences substantial changes from Artificial Intelligence (AI) through its ability to deliver data-based recruitment and onboarding insights and performance management and retention analytics. Organizations competing for talent together with employee experience needs achieve measurable decision-making and workforce outcome advantages through AI HR analytics implementation. \n\nMethods: A total of 100 HR professionals from technology and finance sectors as well as retail and healthcare and manufacturing industries participated in the research. The data collection process used a structured questionnaire to assess AI implementation stages and usage locations together with participant views on benefits and implementation hurdles. Quantitative data underwent descriptive statistical analysis while qualitative information helped explain implementation barriers and ethical concerns.\n\nResults: Organizations that apply AI-driven HR analytics achieve significant performance improvements. The recruitment process became 20\u201335% more efficient while the time for hiring shortened drastically and candidate assessment quality improved by 30%. Employee engagement scores showed an 18% increase and voluntary attrition rates dropped by 25%. Organizations which implemented AI-based performance monitoring systems managed to identify employees who needed retention the most thus enhancing their targeted retention approaches. Survey participants pointed out three main obstacles which included data privacy problems (62%), algorithmic bias (48%) and implementation expenses (41%).\n\nConclusion: The successful adoption of technology demands organizations to combine its functional aspects with moral standards which protect equality along with open operations and confidence building.",
    "doi": "10.25163/ai.1110384",
    "url": "https://www.semanticscholar.org/paper/84eb79e6898bf19d51b363a820694007d5b5dd21",
    "pdf_url": "",
    "venue": "Journal of Ai ML DL",
    "citation_count": 2,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895301"
  },
  {
    "source": "semantic_scholar",
    "source_id": "d2900b56cec16f2e1070905489a191bbf87a00be",
    "title": "A Survey on Human Resource Management Under the AI Act: Ethical, Practical, and Regulatory Perspectives",
    "authors": [
      "Nicola Albor\u00e9",
      "Alessandro Castelnovo",
      "Matteo Della Valle",
      "Andrea Ermellino",
      "Luca Puggini",
      "Silvia Tessaro"
    ],
    "year": 2025,
    "abstract": null,
    "doi": null,
    "url": "https://www.semanticscholar.org/paper/d2900b56cec16f2e1070905489a191bbf87a00be",
    "pdf_url": "",
    "venue": "AIMMES",
    "citation_count": 0,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:49.895303"
  },
  {
    "source": "semantic_scholar",
    "source_id": "7c019053c5028a89afb4929051c11e85e2307802",
    "title": "CalibHRM: A Feedback-Calibrated Ethical Decision Framework for Adaptive and Transparent Human Resource Management",
    "authors": [
      "Bo Wang"
    ],
    "year": 2025,
    "abstract": "In recent years, the application of artificial intelligence in Human Resource Management (HRM) has created efficiencies. Also, there are significant challenges with transparency, fairness and ethical accountability in decisionmaking. Therefore, this manuscript introduces CalibHRM, a Feedback-Calibrated Ethical Decision Framework, utilizing the Throughput Model (TPM) for ethically-relevant and adaptive HRM decision processes. Specifically, the framework is designed across five structured processes, initially the data collection and normalization of employee HR records, performance management assessments and employee feedback, Subsequently, ethical pathway encoding performs the ethical moral reasoning models based on six TPM models. Consequently, calculating the Ethical Balance Score (EBS) to effectively characterize fairness, satisfaction, bias, and accuracy. Further, a Feedback Calibration Cycle (FCC) is utilized which rehabilitates the power of ethical pathways on the basis of changes in EBS as compared to a target. Additionally, the proposed CalibHRM uses a lightweight recalibrative mechanism of adjustments within algorithm-assisted HRM decisions that continuously reinforces and aligns ethical and organizational values with decision-making. Experimental validation is provided through the assessment of HR decision dataset to demonstrate how CalibHRM strengthens ethics balance, reduces bias factors, and provides a transparent framework for interpretative explanation and decision-making for characteristics aligned with fairness-angled HRM. The proposed CalibHRM model obtained high results in terms of Mean Error (ME) and Standard Deviation Error (SDE) of 20.65 and 4.49 respectively.",
    "doi": "10.1109/IC3IT66137.2025.11341592",
    "url": "https://www.semanticscholar.org/paper/7c019053c5028a89afb4929051c11e85e2307802",
    "pdf_url": "",
    "venue": "2025 International Conference on Communication, Computer, and Information Technology (IC3IT)",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895305"
  },
  {
    "source": "semantic_scholar",
    "source_id": "13028174c6e8217845d6ae9c2fec386b06d9920e",
    "title": "Generative Artificial Intelligence and Collaboration: Exploring Religious Human-Machine Communication and Tensions in Leadership Practices",
    "authors": [
      "P. H. Cheong",
      "Liming Liu"
    ],
    "year": 2025,
    "abstract": "The adoption of generative artificial intelligence (GAI) applications has bolstered efforts toward human-machine collaboration. Given the lag in research on AI and religion, this study examines how pastors engage GAI to develop religious human-machine communication practices that constitute their leadership. Findings from in-depth interviews with pastors in the U.S. reveal that they view GAI as an idea generator, research assistant, co-author and translator. Clergy enact multiple ways to incorporate GAI communication in religious education and to enhance sermonic performances. Concurrently, pastors perceive tensions between innovation and established rites, as they contend with the authenticity and spiritual depth of GAI content while meeting the needs of their congregants amid temporal and resource challenges. This article concludes with implications for future research, AI governance and ethics.",
    "doi": "10.30658/hmc.11.9",
    "url": "https://www.semanticscholar.org/paper/13028174c6e8217845d6ae9c2fec386b06d9920e",
    "pdf_url": "",
    "venue": "Human-Machine Communication",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895306"
  },
  {
    "source": "semantic_scholar",
    "source_id": "4ee0ed72d5e3b7c574ede9a579ee55bba91f21a3",
    "title": "Role of Artificial Intelligence in Human Resource Management: A Comprehensive Review",
    "authors": [
      "Ilango Kessavane"
    ],
    "year": 2025,
    "abstract": "With the ever-evolving digitalism landscape, Artificial Intelligence (AI) is one such transformational phenomena\nin Human Resource Management (HRM). Therefore, this thorough study describes all about the\nmultidimensional role of AI in HRM focusing its applications, advantages, and obstacles. This study provides\ninsights into how AI improves recruitment, employee engagement, performance management, and talent\ndevelopment by exploring AI-enabled tools and technologies. The review also explores ethical and potential\nbiases with AI in HR. This paper offers to illustrate asset project on academic literatures and case studies in\nahead of time. Taken together, this paper adds to the literature the effect of AI on HR by providing\nrecommendations on how to leverage AI for a sustainable competitive advantage.",
    "doi": "10.35629/3795-11014144",
    "url": "https://www.semanticscholar.org/paper/4ee0ed72d5e3b7c574ede9a579ee55bba91f21a3",
    "pdf_url": "",
    "venue": "Journal of Software Engineering and Simulation",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895377"
  },
  {
    "source": "semantic_scholar",
    "source_id": "ce10bf2c192ca641b9afb0b7264f969087220ef9",
    "title": "A Leveraging Artificial Intelligence (AI) Powered Human Resource Management Strategy with Elevated Performance Metrics to Improve Talent Acquisition and Employee Engagement",
    "authors": [
      "Liu Chao",
      "Zhang Yi",
      "Zhang Jiyu",
      "Chin Yuk Fong"
    ],
    "year": 2025,
    "abstract": "The digital transformation period has turned Human Resource Management (HRM) into a strategic collaborative practice from its former administrative position. This research develops an elaborate strategy which utilizes Artificial Intelligence (AI) to transform Human Resource Management (HRM) capabilities in talent recruitment and employee engagement for contemporary enterprises. The proposed system improves both recruitment speed and workforce contentment through its integration of machine learning algorithms along with natural language processing (NLP) and reinforcement learning methods with traditional HR practices. The employment of NLP techniques during resume evaluation produced results that surpassed human screening with a measurement accuracy of 92.3%. XGBoost based predictive candidate-job fit analysis reached 89.6% accuracy in its assessment of organizational-demand and candidate-profile compatibility. The interpretation of employee feedback from different departments reached an 88.4% accuracy through LSTM models for sentiment analysis. The deployment of AI engagement monitoring technology resulted in a 34.4% average increase of employee engagement scores following implementation. The AI recommendation system received employee acceptance in 60.3% of cases according to its recorded data. The analyzed data shows that artificial intelligence offers organizations opportunities to optimize HR operations and decrease bias while making better data-based workforce decisions. Research findings indicate that artificial intelligence serves beyond being a supportive tool because it becomes a strategic partner for human capital management in digital environments.",
    "doi": "10.1109/ICFTS62006.2025.11031510",
    "url": "https://www.semanticscholar.org/paper/ce10bf2c192ca641b9afb0b7264f969087220ef9",
    "pdf_url": "",
    "venue": "2025 International Conference on Frontier Technologies and Solutions (ICFTS)",
    "citation_count": 2,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895380"
  },
  {
    "source": "semantic_scholar",
    "source_id": "eec008aba27da4bf167271b7c54e63f3262b4451",
    "title": "Artificial intelligence applications in human resource management: it is a mixed bag!",
    "authors": [
      "Antarpreet Singh",
      "Jatin Pandey"
    ],
    "year": 2025,
    "abstract": "\n \n Artificial intelligence (AI) has brought major disruptions in the new generation human resources (HR) ecosystems. The research community as well as chief human resources officers (CHROs) have been taking strong initiatives to examine the use of AI in human resource management (HRM) function, including harmonious human\u2013machine collaboration. The AI-HRM area is under-researched, and this study addresses an important research gap regarding the benefits and challenges of AI applications in HRM.\n \n \n \n The study adopts a qualitative research methodology (abductive case research) and collects data from multiple sources in three Indian companies. These organizations span diverse sectors and were at different stages of AI adoption in HRM at the time of the study. The multi-data-sources strategy helps triangulation and establishes credibility of the research.\n \n \n \n The findings provide a clear view about the benefits of AI applications in HRM, higher productivity, recruitment efficiency, adaptive learning and high-quality HR decisions. The study also underpins key challenges, including a lack of human touch, employees\u2019 loss of control over jobs and the fear of losing jobs to AI.\n \n \n \n The research provides a theoretical contribution to the growing AI-HRM literature in the context of the theory of cost economics in the context of recruitment efficiency as well as leveraging adaptive learning from the context of the multi-level organizational learning framework to improve the performance of the HR function. The research also provides significant managerial insights for CHROs recommending that they embrace humanized AI in the HRM function and institutionalize AI ethics.\n",
    "doi": "10.1108/ijppm-09-2024-0599",
    "url": "https://www.semanticscholar.org/paper/eec008aba27da4bf167271b7c54e63f3262b4451",
    "pdf_url": "",
    "venue": "International Journal of Productivity and Performance Management",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895382"
  },
  {
    "source": "semantic_scholar",
    "source_id": "b1ca638938db823e6de0412bf0f0014e4dbf7bd1",
    "title": "The impact of challenges posed by the adoption of artificial intelligence strategy for human resource managers",
    "authors": [
      "Naser Khdour",
      "R. Fenech",
      "P. Baguant",
      "Alessandra Theuma"
    ],
    "year": 2025,
    "abstract": "Artificial intelligence (AI) is revolutionizing industries across the globe and its transformative potential continues to make significant changes in human resource management (HRM) by optimizing recruitment, enhancing employee engagement, and streamlining HRM processes. The study evaluated the challenges faced while adopting AI in HRM to enhance firms\u2019 data transformation processes. The study adopted a quantitative research design and surveys for data collection. A random sampling approach was used to select 169 companies in Jordan, with 200 employees chosen. A multiple regression model (MRM) was used to assess the impact of challenges on AI adoption. The study revealed that data falsification and biased decision-making are the most pervasive challenges, while firm long-term budgeting has been facilitated. The study concludes that adopting AI in HRM results in unfair decision-making and invalidated results. Further financial maintenance is also a factor sufficiently provided by the innovative AI techniques applied in the recruitment process (Jihad & V\u00e1rallyai, 2021; Prikshat et al., 2023). The Jordanian context, which is culturally distinct from the rest of the globe, has not had its AI-related challenges well addressed. This research addresses a gap in the literature by describing the challenges faced by human resource (HR) managers in Jordan when attempting to integrate AI and by proposing a solution to these problems.",
    "doi": "10.22495/cbsrv6i3art3",
    "url": "https://www.semanticscholar.org/paper/b1ca638938db823e6de0412bf0f0014e4dbf7bd1",
    "pdf_url": "",
    "venue": "Corporate & Business Strategy Review",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895384"
  },
  {
    "source": "semantic_scholar",
    "source_id": "5541b1c103cb477ecbb53861216e64dc88fff32d",
    "title": "Transforming Human Resource Management in Healthcare: The Role of Artificial Intelligence and Industry 5.0",
    "authors": [
      "Riste Temjanovski",
      "Afrim Loku",
      "Zlatko Bezovski"
    ],
    "year": 2025,
    "abstract": "The healthcare sector is undergoing a transformative shift driven by the integration of Artificial Intelligence (AI) and the principles of Industry 5.0. This paper explores how AI is revolutionizing Human Resource Management (HRM) in healthcare, enhancing operational efficiency, optimizing recruitment and talent acquisition, and fostering employee engagement. Industry 5.0 introduces a human-centric approach that emphasizes collaboration between humans and advanced technologies, prioritizing employee well being and creating a more resilient workforce. This study also highlights the experiences of the Western Balkans, where regional adoption of AI in healthcare HRM has demonstrated significant improvements, including reduced recruitment times, enhanced workforce efficiency, and alignment with European Union digital health standards. Through a comprehensive review of current literature, case studies, and statistical data, this paper examines the benefits, challenges, and future implications of AI-driven HRM systems, with a particular focus on predictive analytics, personalized employee development, and proactive workforce planning. It further addresses critical challenges such as data privacy, ethical considerations, and the need for robust governance frameworks to ensure transparency and fairness in AI-driven decision-making. The findings reveal that successful integration of AI and Industry 5.0 principles in healthcare HRM not only enhances organizational agility but also improves public health outcomes, positioning healthcare providers to navigate the complexities of an evolving global healthcare landscape.",
    "doi": "10.46763/joe2510154t",
    "url": "https://www.semanticscholar.org/paper/5541b1c103cb477ecbb53861216e64dc88fff32d",
    "pdf_url": "",
    "venue": "JOURNAL OF ECONOMICS",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895720"
  },
  {
    "source": "semantic_scholar",
    "source_id": "ca0cef2c06f7f5f43a7bea23e2094bb4113ca3e9",
    "title": "Artificial Intelligence in Employee Well-Being and Human Resource Management",
    "authors": [
      "Himani Agarwal"
    ],
    "year": 2025,
    "abstract": "The efforts would be on how Artificial Intelligence be essential in the well-being of employees and Human Resource department in a consortium and therefore why such department should do planning to adopt Artificial Intelligence and what conceivable the role and challenges for the employees in the area of Human Resource and why it has become important to understand about Artificial Intelligence would be answered by highlighting the motivation for Artificial Intelligence, Artificial Intelligence can be adopted for any department but this paper try to emphasize on what Artificial Intelligence can contribute in Employee well-being. Artificial Intelligence is transforming Human Resource Management by enhancing employee wellness and optimizing workforce management. Artificial Intelligence-driven tools help organizations improve Recruitment, Performance Evaluation, Employee Engagement, and overall, Job satisfaction. In employee well-being, Chatbots and virtual assistants driven by Artificial Intelligence provide real-time mental health support, while sentiment analysis tools assess workplace morale by analyzing employee feedback. Wearable technology and Artificial Intelligence -driven wellness programs further aid in stress management and Work-Life balance. In Human Resource Management, Artificial Intelligence streamlines talent acquisition through automated resume screening, predictive analytics for candidate selection, and bias reduction in hiring. Artificial Intelligence -powered learning platforms personalize training programs, boosting employee skill development. Furthermore, Artificial Intelligence enhances workforce analytics by identifying trends in employee performance, absenteeism, and attrition risks, allowing Human Resource professionals to implement proactive strategies. Despite its benefits, Artificial Intelligence adoption in Human Resource Management uplift concerns about data safety, algorithmic bias, and ethical considerations in decision-making. Organizations must ensure transparency and fairness while integrating Artificial Intelligence into Human Resource processes. The upcoming era of Artificial Intelligence in Human Resource Management lies in generating a balanced approach that leverages Artificial Intelligence\u2019s analytical power while maintaining the human touch in employee interactions. By fostering a data-driven, employee-centric approach, Artificial Intelligence contributes to a more engaged, healthier, and productive workforce, ultimately leading to improved organizational performance and job satisfaction.",
    "doi": "10.63825/opjubr.2025.4.1.07",
    "url": "https://www.semanticscholar.org/paper/ca0cef2c06f7f5f43a7bea23e2094bb4113ca3e9",
    "pdf_url": "",
    "venue": "OPJU Business Review",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895732"
  },
  {
    "source": "semantic_scholar",
    "source_id": "c16a4354f2f3351869fef3ff14daf7ff76d56bdf",
    "title": "Implementation of Ethics of Using Artificial Intelligence in the Education System in Indonesia",
    "authors": [
      "Musidiansyah Otto Syaidina",
      "Rifqi Fahrudin",
      "Indah Ainun Mutiara"
    ],
    "year": 2024,
    "abstract": "The use of Artificial Intelligence (AI) in education is a rapidly evolving field with the potential to transform teaching and learning. However, its implementation brings various ethical and practical challenges that must be carefully considered. Key aspects include ensuring student data privacy, promoting fairness and inclusivity in access to technology, maintaining transparency in AI algorithms and decision-making processes, and determining the appropriate levels of human control. Furthermore, accessibility for all students, including those with special needs, must be prioritized, alongside evaluating the potential long-term effects on cognitive, social, and emotional development. Given the complexity of these issues, a thoughtful and ethical approach to integrating AI into education requires ongoing collaboration among various stakeholders, including educators, AI developers, policymakers, students, and the broader community. The goal of this collaboration is to ensure that AI is used in ways that not only improve educational outcomes but also uphold fairness, equity, and transparency. It is crucial to address concerns such as data privacy, algorithmic bias, and the potential negative effects of AI on vulnerable groups to ensure the technology serves as an inclusive tool for education. This research adopts a qualitative approach to explore the different aspects of AI in education, aiming to identify and analyze its potential benefits. By examining the implications of AI integration, the study seeks to provide valuable insights into how AI can be effectively and ethically applied in education, ensuring it enhances learning while respecting core educational values and human dignity.",
    "doi": "10.34306/bfront.v4i1.571",
    "url": "https://www.semanticscholar.org/paper/c16a4354f2f3351869fef3ff14daf7ff76d56bdf",
    "pdf_url": "",
    "venue": "Blockchain Frontier Technology",
    "citation_count": 9,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895735"
  },
  {
    "source": "semantic_scholar",
    "source_id": "4395e37d174a93948142ea2852411084cbd5551c",
    "title": "The Ethics of AI: Navigating the Moral Dilemmas of Artificial Intelligence",
    "authors": [
      "Fayyad Muhammad Hani Bayan"
    ],
    "year": 2024,
    "abstract": "The significance of ethics in artificial intelligence (AI) cannot be overstated, as it encompasses the foundational principles guiding the responsible creation, deployment, and management of AI technologies. As AI systems increasingly permeate every facet of our lives\u2014from healthcare and education to security and entertainment\u2014their decisions and actions have profound implications not only on individual rights and privacy but also on societal norms and values. Ethical considerations in AI are paramount to ensure that these technologies enhance human well-being, uphold fairness, and protect freedoms, rather than perpetuate biases, exacerbate inequalities, or undermine democratic institutions. The importance of AI ethics lies in its ability to provide a framework for navigating the complex moral dilemmas presented by AI, such as the balance between innovation and regulation, the protection of individual privacy versus the benefits of big data, and the prevention of AI misuse. By foregrounding ethical principles, stakeholders\u2014including developers, policymakers, and users\u2014can work towards the development of AI technologies that are not only technologically advanced but also socially responsible and aligned with human values. This emphasis on ethics ensures that as AI systems become more autonomous and integral to our daily lives, they do so in a manner that is transparent, accountable, and inclusive, thereby fostering trust and confidence in their widespread adoption and use.",
    "doi": "10.36571/ajsp661",
    "url": "https://www.semanticscholar.org/paper/4395e37d174a93948142ea2852411084cbd5551c",
    "pdf_url": "https://doi.org/10.36571/ajsp661",
    "venue": "Arab Journal for Scientific Publishing",
    "citation_count": 8,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895737"
  },
  {
    "source": "semantic_scholar",
    "source_id": "83d652b3a6bfc3286d7a11fae11229a59ae89c89",
    "title": "Artificial Intelligence Driven Human Resource Optimization and Institutional Performance in Nigeria Public Sector: A Study of Enugu State",
    "authors": [
      "U. Egwuagu",
      "N. Okolie",
      "Adaobi Ugwu"
    ],
    "year": 2025,
    "abstract": "This study assessed the Artificial Intelligence (AI) driven human resource optimization and institutional performance in the Nigerian public sector, focusing on Enugu State. The specific objectives were to examine the effect of AI applications on recruitment, evaluate AI-driven human resource practices on service delivery efficiency, and identify the impact of AI on service output quality. A descriptive survey research design was adopted, with a study population of 12,886. Using Yamane\u2019s formula, a sample size of 388 respondents was determined. Data were collected through structured questionnaires and analyzed using descriptive statistics (frequency distribution, percentages, mean, and standard deviation) and inferential statistics (Pearson correlation). Findings revealed that AI applications significantly improve recruitment processes, enhance service delivery efficiency, and promote quality service output through reduced errors, transparency, and resource utilization. The study concluded that AI is a transformative tool for operational efficiency in Enugu State\u2019s public sector. It recommended increased investment in AI-based recruitment systems, continuous training of HR personnel, and the establishment of clear ethical guidelines to ensure fairness, transparency, and sustainability of AI adoption. \n\u00a0",
    "doi": "10.4314/jpds.v19i4.1",
    "url": "https://www.semanticscholar.org/paper/83d652b3a6bfc3286d7a11fae11229a59ae89c89",
    "pdf_url": "",
    "venue": "Journal of Policy and Development Studies",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895738"
  },
  {
    "source": "semantic_scholar",
    "source_id": "c16a4354f2f3351869fef3ff14daf7ff76d56bdf",
    "title": "Implementation of Ethics of Using Artificial Intelligence in the Education System in Indonesia",
    "authors": [
      "Musidiansyah Otto Syaidina",
      "Rifqi Fahrudin",
      "Indah Ainun Mutiara"
    ],
    "year": 2024,
    "abstract": "The use of Artificial Intelligence (AI) in education is a rapidly evolving field with the potential to transform teaching and learning. However, its implementation brings various ethical and practical challenges that must be carefully considered. Key aspects include ensuring student data privacy, promoting fairness and inclusivity in access to technology, maintaining transparency in AI algorithms and decision-making processes, and determining the appropriate levels of human control. Furthermore, accessibility for all students, including those with special needs, must be prioritized, alongside evaluating the potential long-term effects on cognitive, social, and emotional development. Given the complexity of these issues, a thoughtful and ethical approach to integrating AI into education requires ongoing collaboration among various stakeholders, including educators, AI developers, policymakers, students, and the broader community. The goal of this collaboration is to ensure that AI is used in ways that not only improve educational outcomes but also uphold fairness, equity, and transparency. It is crucial to address concerns such as data privacy, algorithmic bias, and the potential negative effects of AI on vulnerable groups to ensure the technology serves as an inclusive tool for education. This research adopts a qualitative approach to explore the different aspects of AI in education, aiming to identify and analyze its potential benefits. By examining the implications of AI integration, the study seeks to provide valuable insights into how AI can be effectively and ethically applied in education, ensuring it enhances learning while respecting core educational values and human dignity.",
    "doi": "10.34306/bfront.v4i1.571",
    "url": "https://www.semanticscholar.org/paper/c16a4354f2f3351869fef3ff14daf7ff76d56bdf",
    "pdf_url": "",
    "venue": "Blockchain Frontier Technology",
    "citation_count": 9,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972698"
  },
  {
    "source": "semantic_scholar",
    "source_id": "4395e37d174a93948142ea2852411084cbd5551c",
    "title": "The Ethics of AI: Navigating the Moral Dilemmas of Artificial Intelligence",
    "authors": [
      "Fayyad Muhammad Hani Bayan"
    ],
    "year": 2024,
    "abstract": "The significance of ethics in artificial intelligence (AI) cannot be overstated, as it encompasses the foundational principles guiding the responsible creation, deployment, and management of AI technologies. As AI systems increasingly permeate every facet of our lives\u2014from healthcare and education to security and entertainment\u2014their decisions and actions have profound implications not only on individual rights and privacy but also on societal norms and values. Ethical considerations in AI are paramount to ensure that these technologies enhance human well-being, uphold fairness, and protect freedoms, rather than perpetuate biases, exacerbate inequalities, or undermine democratic institutions. The importance of AI ethics lies in its ability to provide a framework for navigating the complex moral dilemmas presented by AI, such as the balance between innovation and regulation, the protection of individual privacy versus the benefits of big data, and the prevention of AI misuse. By foregrounding ethical principles, stakeholders\u2014including developers, policymakers, and users\u2014can work towards the development of AI technologies that are not only technologically advanced but also socially responsible and aligned with human values. This emphasis on ethics ensures that as AI systems become more autonomous and integral to our daily lives, they do so in a manner that is transparent, accountable, and inclusive, thereby fostering trust and confidence in their widespread adoption and use.",
    "doi": "10.36571/ajsp661",
    "url": "https://www.semanticscholar.org/paper/4395e37d174a93948142ea2852411084cbd5551c",
    "pdf_url": "https://doi.org/10.36571/ajsp661",
    "venue": "Arab Journal for Scientific Publishing",
    "citation_count": 8,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972707"
  },
  {
    "source": "semantic_scholar",
    "source_id": "be09def26939375435358fcb161d077c6505071b",
    "title": "Research on the Application and Optimization of Artificial Intelligence Technology in Enterprise Human Resource Management",
    "authors": [
      "Zhenxia Liu",
      "Huimin Zhou"
    ],
    "year": 2025,
    "abstract": "The rapid development of artificial intelligence (AI) technology is profoundly reshaping the paradigm of corporate human resource management. Based on industry research and practical case studies, this paper systematically explores the current application status and optimization paths of AI technology (represented by AI-generated content) in various modules of corporate human resource management. Research indicates that in the recruitment domain, AI technologies such as intelligent resume parsing and automated job description generation have significantly improved talent matching efficiency. In training and development scenarios, AI technologies like adaptive learning systems and intelligent knowledge extraction tools are driving the development of personalized training. Additionally, the performance management domain is showing a trend toward intelligent upgrades. In the compensation management module, AI-based market trend analysis and automated solution design are helping companies reduce costs and improve efficiency. The study also emphasizes that AI technology will drive structural changes in job roles and highlights the need to address risks such as algorithm explainability, data bias prevention, and privacy security. Companies must establish human-machine collaboration mechanisms, build intelligent excellence center systems, and strengthen ethical compliance frameworks to achieve a transformation from digital human capital management to the integration of humanity and technology.",
    "doi": "10.1145/3768801.3768921",
    "url": "https://www.semanticscholar.org/paper/be09def26939375435358fcb161d077c6505071b",
    "pdf_url": "",
    "venue": "Proceedings of the 2025 2nd International Conference on Big Data and Digital Management",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972709"
  },
  {
    "source": "semantic_scholar",
    "source_id": "4f881119a44f5552f9408dbd995f3c90fe3fe9b0",
    "title": "APPLICATION DOMAINS OF ARTIFICIAL INTELLIGENCE IN HUMAN RESOURCE MANAGEMENT",
    "authors": [
      "Oleksandr Mihus",
      "Agnieszka Schuetz"
    ],
    "year": 2025,
    "abstract": "The digital transformation of organizational processes has led to the widespread integration of artificial intelligence in personnel management. AI technologies have become an important component of strategic human resource development, providing opportunities for optimizing recruitment, evaluation, motivation, training, and employee retention. The use of AI in HR allows organizations to enhance the efficiency of decision-making, reduce the influence of subjective factors, and ensure evidence-based assessment of human capital. At the same time, the introduction of AI requires understanding both its capabilities and limitations, including ethical considerations, data privacy protection, transparency of algorithms, and the potential impact on employee trust. The rapid development of AI technologies makes their application in HR not only a technological but also a managerial challenge that requires systematic approaches and effective governance mechanisms.\nThe goal of this research is to identify key areas of artificial intelligence application in personnel management, analyze their advantages and risks, and determine the conditions for effective implementation in organizational practice.\nThe study is based on a systematic review of scientific sources and analytical reports of international organizations in the field of human resource management and digital innovation. Methods of structural-logical analysis, comparison, classification, and synthesis were applied to identify the main directions of AI use. Empirical examples of AI implementation in recruitment, performance management, training, and employee well-being programs were analyzed. Attention was paid to regulatory approaches, ethical frameworks, and standards that guide the responsible use of AI in HR.\nThe research identifies several core areas of AI application in personnel management. First, AI is widely used in recruitment and selection through automated candidate screening, resume analysis, and predictive assessment of job fit. These tools reduce the time and cost of hiring, although they require careful control to avoid algorithmic bias. Second, AI supports performance management by analyzing work patterns, productivity indicators, and behavioral data to provide objective feedback. Third, AI contributes to the personalization of learning and development through adaptive training platforms that adjust educational content to the individual competencies and career trajectories of employees. Fourth, AI assists in employee engagement and well-being monitoring through sentiment analysis, chatbots for internal communication, and early identification of burnout risks. Fifth, AI enhances strategic workforce planning by supporting data-driven forecasting of workforce needs and identifying competencies required for future organizational development. Despite the benefits, challenges include data protection, transparency of algorithms, and the need for strengthening ethical and regulatory frameworks to prevent discrimination and preserve employee autonomy.\nArtificial intelligence significantly expands the possibilities of personnel management, increasing the accuracy of HR decisions and enabling personalized development strategies. However, effective use of AI requires balanced integration, clear ethical standards, continuous evaluation of algorithms, and the involvement of HR professionals in shaping technology-driven human resource policies.\n\n\nFuture research should focus on developing ethical frameworks for AI in HR, assessing the impact of AI on organizational culture, exploring employee perceptions of algorithmic management, and identifying strategies for increasing trust and transparency in AI-supported HR systems.",
    "doi": "10.36690/iceaf-2025-124-125",
    "url": "https://www.semanticscholar.org/paper/4f881119a44f5552f9408dbd995f3c90fe3fe9b0",
    "pdf_url": "",
    "venue": "Book of Abstracts",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972711"
  },
  {
    "source": "semantic_scholar",
    "source_id": "6a9e34862e3183ddc7e2ae144b4a1a1da0bcbb48",
    "title": "Embedding Artificial Intelligence in Next Generation Human Resource Development Implementations",
    "authors": [
      "Arshad Matin"
    ],
    "year": 2025,
    "abstract": "A new era of data-driven, automated, and intelligent decision-making processes across a broad range of HR tasks is being ushered in by the development of artificial intelligence (AI), which is significantly changing the field of human resource management (HRM). This study examines the revolutionary effects of AI technology on HRM practices by a thorough secondary review of recent scholarly works, industry reports, and case studies. AI-powered hiring and talent acquisition platforms, predictive analytics for assessing employee performance, intelligent workforce planning, automated onboarding, and real-time employee engagement platforms are some of the major areas of disruption that have been highlighted. The study not only highlights these developments but also critically analyzes the risks and difficulties that come with integrating AI, including issues with data privacy, algorithmic and cognitive biases, lack of interpretability, transparency, and the widening digital skill gap among HR professionals. In addition to highlighting the significance of coordinating AI deployment with organizational ethics, legal compliance, and human-centric values, the study delves deeper into the strategic implications of AI in promoting agile, inclusive, and responsive HR ecosystems. As crucial avenues for long-term adoption, emerging themes like explainable AI (XAI), ethical AI governance, and AI literacy in HR are also covered. According to the findings, while AI has the ability to greatly improve HRM's operational efficiency, decision accuracy, and employee experience, long-term success depends on a methodical, morally sound, and strategically integrated strategy.",
    "doi": "10.22161/ijaems.114.17",
    "url": "https://www.semanticscholar.org/paper/6a9e34862e3183ddc7e2ae144b4a1a1da0bcbb48",
    "pdf_url": "",
    "venue": "International Journal of Advanced engineering Management and Science",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972713"
  },
  {
    "source": "semantic_scholar",
    "source_id": "83d652b3a6bfc3286d7a11fae11229a59ae89c89",
    "title": "Artificial Intelligence Driven Human Resource Optimization and Institutional Performance in Nigeria Public Sector: A Study of Enugu State",
    "authors": [
      "U. Egwuagu",
      "N. Okolie",
      "Adaobi Ugwu"
    ],
    "year": 2025,
    "abstract": "This study assessed the Artificial Intelligence (AI) driven human resource optimization and institutional performance in the Nigerian public sector, focusing on Enugu State. The specific objectives were to examine the effect of AI applications on recruitment, evaluate AI-driven human resource practices on service delivery efficiency, and identify the impact of AI on service output quality. A descriptive survey research design was adopted, with a study population of 12,886. Using Yamane\u2019s formula, a sample size of 388 respondents was determined. Data were collected through structured questionnaires and analyzed using descriptive statistics (frequency distribution, percentages, mean, and standard deviation) and inferential statistics (Pearson correlation). Findings revealed that AI applications significantly improve recruitment processes, enhance service delivery efficiency, and promote quality service output through reduced errors, transparency, and resource utilization. The study concluded that AI is a transformative tool for operational efficiency in Enugu State\u2019s public sector. It recommended increased investment in AI-based recruitment systems, continuous training of HR personnel, and the establishment of clear ethical guidelines to ensure fairness, transparency, and sustainability of AI adoption. \n\u00a0",
    "doi": "10.4314/jpds.v19i4.1",
    "url": "https://www.semanticscholar.org/paper/83d652b3a6bfc3286d7a11fae11229a59ae89c89",
    "pdf_url": "",
    "venue": "Journal of Policy and Development Studies",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972714"
  },
  {
    "source": "semantic_scholar",
    "source_id": "b09b194b05111a0d9a8ae97901aa73d92f10b0ac",
    "title": "Integration of Artificial Intelligence in Human Resource Management: Analyzing Opportunities, Challenges, and Human-AI Collaboration",
    "authors": [
      "Adil Benabou",
      "Fatima Touhami"
    ],
    "year": 2025,
    "abstract": "This study explored the role of Artificial Intelligence (AI) in transforming Human Resource Management (HRM). By systematically reviewing a wide range of literature, this study highlighted both the potential benefits and challenges associated with AI in HRM. From an initial collection of 983 articles, we focused on 91 key studies that provided in-depth insights into AI\u2019s impact on HR functions such as recruitment, employee integration, career management, payroll, and compensation. While AI has the capacity to significantly enhance these functions, its integration also raises important issues, including ethical concerns, biases, data privacy, and the need for extensive employee training and reskilling. This review underscores the importance of balancing technological innovation with ethical considerations and employee well-being. By offering practical insights and suggesting directions for future research, this study aimed to assist HR practitioners and researchers in effectively leveraging AI to improve organizational performance and employee satisfaction.",
    "doi": "10.24191/mar.v24i01-15",
    "url": "https://www.semanticscholar.org/paper/b09b194b05111a0d9a8ae97901aa73d92f10b0ac",
    "pdf_url": "https://doi.org/10.24191/mar.v24i01-15",
    "venue": "Management and Accounting Review",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972716"
  },
  {
    "source": "semantic_scholar",
    "source_id": "9a5ab3075b2a9b34037a9097631985875f604e09",
    "title": "Artificial Intelligence Technologies in Human Resource Management: Social Experience of Implementation and Use",
    "authors": [
      "Larisa Sergeevna Koval'zhina",
      "Anna Anatol'evna Orlova"
    ],
    "year": 2025,
    "abstract": "The article discusses the social issues of implementing and using artificial intelligence technologies in human resource management of organizations and enterprises. It addresses experts' expectations and the potential for the adoption of artificial intelligence, as well as the barriers to the implementation of advanced AI functions, which include both technical problems and social ones (the need for a change in corporate culture). The theoretical and methodological foundations of the research are based on a sociological approach that views technologies not as neutral tools but as social artifacts embedded in existing social structures, cultural norms, and organizational practices. The aim of this research is to identify and classify the social problems of implementing and using AI in HR, as well as to assess the current state and prospects of using artificial intelligence technologies in personnel management in companies in the Tyumen region. A fragment of the results of an expert survey of HR specialists and heads of HR departments of companies of various sizes and industry affiliations, conducted in 2024 and 2025 in the Tyumen region, is presented. The analysis revealed that the existing mechanisms of both self-regulation (corporate policies, professional codes) and institutional regulation (legislation) are underdeveloped, fragmentary, and often reactive. They fail to keep pace with the dynamics of technological changes and do not always adequately consider the specifics of the social experiences of various actors involved in digital HR practices. Four main clusters of social problems are identified: algorithmic bias and the reproduction of social inequality; dehumanization of HR processes and erosion of the organization's social capital; violation of privacy and the creation of a \"digital copy\"; transformation of the HR manager profession and the problem of distributed responsibility. Based on the analysis of the use of AI technologies in personnel management of organizations in the Tyumen region and the study of theoretical concepts of self-regulation and institutional regulation, an integrative model of \"Balanced Institutionalization of AI in HR\" is proposed. The principles of the model include: the principle of contextual embeddedness and human sovereignty; the principle of algorithmic transparency and accountability; the principle of preventive assessment of social risks; and the principle of pluralistic regulation.",
    "doi": "10.25136/2409-7144.2025.12.77472",
    "url": "https://www.semanticscholar.org/paper/9a5ab3075b2a9b34037a9097631985875f604e09",
    "pdf_url": "",
    "venue": "\u0421\u043e\u0446\u0438\u043e\u0434\u0438\u043d\u0430\u043c\u0438\u043a\u0430",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972717"
  },
  {
    "source": "semantic_scholar",
    "source_id": "a76b2e0289aa510b55f8ddae7487cea1f9f4c7ed",
    "title": "Functional Architectonics of Artificial Intelligence in the Context of Digitalized Human Resource Management",
    "authors": [
      "Volodymyr Kuchynskyi",
      "Iegor O. Vozniuk"
    ],
    "year": 2025,
    "abstract": "The article develops a conception for the structure of artificial intelligence in digitalized human resource management, based on a historical and evolutionary analysis of the development of intelligent systems, from the earliest ideas of machine thinking to modern generative models. The stages of the evolutionary dynamics of artificial intelligence, which combine periods of growth and decline resulting from discrepancies between the expectations of the scientific community and technological capabilities, are described. It is demonstrated that each new stage of development contributed to the formation of models and directions capable of integrating with other digital tools and expanding the scope of their practical application. The theoretical and methodological foundations for the use of artificial intelligence in the field of digitalized human resource management, as a key business process of a modern enterprise, are developed. The rationale for implementing a hybrid (neuro-symbolic) approach to model training, which combines machine learning with symbolic knowledge and rule-based systems, has been substantiated. This approach allows for greater transparency and control over algorithmic decisions, reduces the risks of bias, and ensures the efficiency of intelligent algorithms. Based on this, practical functional areas of artificial intelligence corresponding to the multifaceted nature of HR processes have been identified. The study also presents arguments for integrating fundamental and applied functional areas into a unified artificial intelligence framework in human resource management, addressing the challenges of digital transformation. The proposed framework features a flexible architecture that facilitates scalable HR process automation, personalized personnel decisions, and enhanced productivity. Practical results from leading global companies confirm the efficiency of applying AI in digitalized human resource management, and the developed conception can serve as a basis for creating scalable digital ecosystems in the HR field.",
    "doi": "10.32983/2222-4459-2025-9-367-375",
    "url": "https://www.semanticscholar.org/paper/a76b2e0289aa510b55f8ddae7487cea1f9f4c7ed",
    "pdf_url": "",
    "venue": "Business Inform",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972719"
  },
  {
    "source": "semantic_scholar",
    "source_id": "e0b0a828c77a8e61ed546c91e6f526fc94c7892d",
    "title": "REINVITING HUMAN RESOURCE MANAGEMENT IN THE AGE OF ARTIFICIAL INTELLIGENCE",
    "authors": [
      "Afzil Ramadian",
      "Ismartaya",
      "Syakira Fadla",
      "Esih Nurasiah Zamil"
    ],
    "year": 2025,
    "abstract": "This study conducts a systematic literature review and bibliometric analysis to map the intellectual structure and thematic evolution of Artificial Intelligence (AI) and Machine Learning (ML) in Human Resource Management (HRM), with a focus on sustainability implications in business. Using PRISMA 2020, 62 articles were selected from Scopus-indexed publications. Bibliometric analysis via VOS viewer reveals three dominant thematic clusters: technical foundations of AI/ML, HRM-oriented applications, and data-driven decision-support systems. Key findings identify India, China, Malaysia, and the United States as leading contributors, with strong South\u2013South collaborations especially between India and Malaysia highlighting emerging innovation pathways in plural economies. The results demonstrate that AI\u2013HRM synergy significantly enhances business sustainability by enabling data-driven strategic decisions, optimizing resource allocation, and supporting personalized and inclusive HR practices. However, ethical risks such as algorithmic bias pose challenges to sustainable implementation. The study recommends\u00a0transparent AI governance, regular algorithmic audits, and Human-in-the-Loop (HITL) protocols\u00a0to ensure that AI integration strengthens rather than undermines human-centric and sustainable HRM. These insights provide a foundation for policymakers and organizations pursuing responsible digital transformation in dynamic regions such as Southeast Asia.",
    "doi": "10.30997/jvs.v11i2.22285",
    "url": "https://www.semanticscholar.org/paper/e0b0a828c77a8e61ed546c91e6f526fc94c7892d",
    "pdf_url": "",
    "venue": "JURNAL VISIONIDA",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972721"
  },
  {
    "source": "semantic_scholar",
    "source_id": "b7e93297e403a221913e20b4e187a8f2d2d89210",
    "title": "The integration of artificial intelligence in human resource management practices: A review of literature and bibliometric",
    "authors": [
      "Raja Chakra",
      "Ayoub Oulamine",
      "Hicham Bahida",
      "Rachid Ziky",
      "Ayoub Massiki"
    ],
    "year": 2025,
    "abstract": "This research explores the integration of artificial intelligence in human resource management (HRM) practices through a bibliometric review of the literature. It is based on the analysis of multiple articles from academic databases, with the aim of examining AI advances in this field. The objective is to understand its impact, identify the benefits it brings to HRM, and analyze the challenges associated with its deployment based on the collected data from Scopus. We used data collected through the SCOPUS database. Using a bibliometric journal approach as the research methodology, we aim to provide an in-depth exploration and understanding of the findings and results found in recent literature on the impact of AI on HRM. The results show that the annual production of research in this field has increased steadily from 2018 to 2024. The most relevant contributions have focused on the study of artificial intelligence and human resources. AI has become an essential tool in organizations\u2019 efforts to promote diversity and inclusion within their workforce. One area where AI has proven effective is in human resource decision-making. AI offers a powerful solution to address biases because it can analyze data impartially and objectively, without being influenced by bias.",
    "doi": "10.53894/ijirss.v8i5.9244",
    "url": "https://www.semanticscholar.org/paper/b7e93297e403a221913e20b4e187a8f2d2d89210",
    "pdf_url": "",
    "venue": "International journal of innovative research and scientific studies",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972722"
  },
  {
    "source": "semantic_scholar",
    "source_id": "a16d798aad13ac0999d717e61ed3dd3b16ec09b4",
    "title": "The Role of Artificial Intelligence in Designing Future Human Resource Management Strategies",
    "authors": [
      "Bala Bharathi T",
      "R. R. K. V"
    ],
    "year": 2025,
    "abstract": "Artificial Intelligence (AI) is revolutionizing Human Resource Management (HRM) by integrating automation, predictive Analytics, and data-driven decision-making. Organizations are increasingly adopting AI-powered solutions to enhance talent acquisition, employee engagement, performance management, and workforce planning. AI-driven recruitment systems streamline hiring by reducing biases, improving candidate-job matching, and expediting the selection process. Additionally, chatbots and virtual assistants are transforming onboarding, training, and employee support by providing real-time assistance and personalized learning experiences. Beyond recruitment, AI plays a crucial role in workforce analytics, helping HR professionals predict attrition risks, optimize talent management, and enhance employee well-being. Machine learning algorithms and sentiment analysis enable organizations to proactively address workforce challenges, implement effective retention strategies, and cultivate a positive workplace culture. Moreover, AI enhances HR operations by automating payroll processing, benefits administration, and compliance tracking, reducing manual errors and ensuring regulatory adherence. This paper covers the evolving role of AI in shaping future HRM strategies, highlighting the impact of AI on HR, opportunities, and challenges. It also emphasizes the significance of a balanced AI-human approach, where AI augments HR capabilities without replacing human judgment. By integrating AI ethically and strategically, organizations can create an agile, data-driven, and employee-centric HRM framework that aligns with future workforce needs.",
    "doi": "10.63328/ijrdes-v7ri3p10",
    "url": "https://www.semanticscholar.org/paper/a16d798aad13ac0999d717e61ed3dd3b16ec09b4",
    "pdf_url": "",
    "venue": "International Journal of Research and Development in Engineering Science",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972724"
  },
  {
    "source": "semantic_scholar",
    "source_id": "b3cbeaec41527d4499ad4e1e533c6c4fc25e00fb",
    "title": "A Preliminary Review of Artificial Intelligence Adoption in Human Resource Management: Evidence from Asia",
    "authors": [
      "C. Fung",
      "Suman Tiwari",
      "Kevin Jan Sian Voon"
    ],
    "year": 2025,
    "abstract": "Artificial intelligence (AI) integration into human resource management\n(HRM) has gained considerable momentum in Asia, driven by the\nregion's rapid digital transformation and dynamic economic growth.\nDespite increasing scholarly attention, existing literature often adopts\nfragmented perspectives on AI applications across different HRM\nfunctions. This review paper aims to identify trends, challenges, and\noutcomes of AI adoption in HRM functions, considering the sociocultural and economic diversity of Asian countries. It investigates the\nadoption of AI, its application, and its implications across key HRM\nfunctions, including recruitment, training and development,\nperformance appraisal, and employee engagement. This paper adopts a\nsystematic review methodology, synthesising peer-reviewed indexed\njournal articles published from 2020 to 2024. Thematic analysis reveals\nthat AI technologies have enhanced operational efficiency, decisionmaking processes, and personalised employee experiences. However,\ncritical concerns persist regarding data privacy, algorithmic bias, and\nemployee acceptance. Additionally, the uneven pace of AI adoption\nacross industries and countries highlights the influence of regulatory\nframeworks, organisational readiness, and technological infrastructure.\nThis review contributes to the growing body of knowledge by offering\na region-specific perspective on AI integration in HRM, addressing the\nunique complexities of the Asian context. The findings offer practical\ninsights for HR practitioners and policymakers to navigate AI\nimplementation while fostering ethical and inclusive AI adoption. The\npaper also identifies key research gaps, calling for future research to\nexamine the long-term impacts of AI-driven HRM practices and their\nimplications for workforce dynamics in the evolving digital landscape",
    "doi": "10.24191/ijsms.v10i1.24222",
    "url": "https://www.semanticscholar.org/paper/b3cbeaec41527d4499ad4e1e533c6c4fc25e00fb",
    "pdf_url": "",
    "venue": "International Journal of Service Management and Sustainability",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972725"
  },
  {
    "source": "semantic_scholar",
    "source_id": "eef2fb5dc309e007557f5d493e782676041b3bd8",
    "title": "Ethics of Artificial Intelligence(AI)",
    "authors": [
      "Pragya K. K"
    ],
    "year": 2024,
    "abstract": "In today's research and development, artificial intelligence (AI) ethics are a complex and urgent issue. Concerns about artificial intelligence (AI) systems' possible effects on people, communities, and the larger global environment are raised as these systems are incorporated into more and more facets of society. This study examines the ethical implications of artificial intelligence (AI), looking at topics including privacy, fairness, accountability, transparency, and the possibility of prejudice and discrimination in AI algorithms and decision-making processes. The study endeavours to contribute to the establishment of frameworks and rules that encourage the responsible and ethical use of AI technologies, guaranteeing their conformity with society values and the preservation of human rights, by critically assessing these ethical issues. Keywords:-AI ethics , artificial intelligence, ethics, machine ethics, robotics, challenges.",
    "doi": "10.55041/ijsrem33762",
    "url": "https://www.semanticscholar.org/paper/eef2fb5dc309e007557f5d493e782676041b3bd8",
    "pdf_url": "https://ijsrem.com/download/ethics-of-artificial-intelligenceai/?wpdmdl=33545&refresh=66597edc5f1111717141212",
    "venue": "INTERANTIONAL JOURNAL OF SCIENTIFIC RESEARCH IN ENGINEERING AND MANAGEMENT",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972727"
  },
  {
    "source": "semantic_scholar",
    "source_id": "0a0e2015084e68127dd6750d5d0aaa297e5b2f0d",
    "title": "Artificial Intelligence, Bias, and Ethics",
    "authors": [
      "Aylin Caliskan"
    ],
    "year": 2023,
    "abstract": "Although ChatGPT attempts to mitigate bias, when instructed to translate the gender-neutral Turkish sentences \u201cO bir doktor. O bir hem\u015fire\u201d to English, the outcome is biased: \u201cHe is a doctor. She is a nurse.\u201d In 2016, we have demonstrated that language representations trained via unsupervised learning automatically embed implicit biases documented in social cognition through the statistical regularities in language corpora. Evaluating embedding associations in language, vision, and multi-modal language-vision models reveals that large-scale sociocultural data is a source of implicit human biases regarding gender, race or ethnicity, skin color, ability, age, sexuality, religion, social class, and intersectional associations. The study of gender bias in language, vision, language-vision, and generative AI has highlighted the sexualization of women and girls in AI, while easily accessible generative AI models such as text-to-image generators amplify bias at scale. As AI increasingly automates tasks that determine life\u2019s outcomes and opportunities, the ethics of AI bias has significant implications for human cognition, society, justice, and the future of AI. Thus, it is necessary to advance our understanding of the depth, prevalence, and complexities of bias in AI to mitigate it both in machines and society.",
    "doi": "10.24963/ijcai.2023/799",
    "url": "https://www.semanticscholar.org/paper/0a0e2015084e68127dd6750d5d0aaa297e5b2f0d",
    "pdf_url": "https://www.ijcai.org/proceedings/2023/0799.pdf",
    "venue": "International Joint Conference on Artificial Intelligence",
    "citation_count": 24,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:53.972728"
  },
  {
    "source": "semantic_scholar",
    "source_id": "6d6db2763b8b38d9b42cd3e5a98b025fba43f3fb",
    "title": "Early warning of complex climate risk with integrated artificial intelligence",
    "authors": [
      "M. Reichstein",
      "V. Benson",
      "Jan Blunk",
      "G. Camps-Valls",
      "F. Creutzig",
      "C. Fearnley",
      "Boran Han",
      "K. Kornhuber",
      "Nasim Rahaman",
      "Bernhard Sch\u00f6lkopf",
      "Josep Tarraga",
      "R. Vinuesa",
      "Karen Dall",
      "Joachim Denzler",
      "Dorothea Frank",
      "Giulia Martini",
      "Naomi Nganga",
      "Danielle C. Maddix",
      "Kommy Weldemariam"
    ],
    "year": 2025,
    "abstract": "As climate change accelerates, human societies face growing exposure to disasters and stress, highlighting the urgent need for effective early warning systems (EWS). These systems monitor, assess, and communicate risks to support resilience and sustainable development, but challenges remain in hazard forecasting, risk communication, and decision-making. This perspective explores the transformative potential of integrated Artificial Intelligence (AI) modeling. We highlight the role of AI in developing multi-hazard EWSs that integrate Meteorological and Geospatial foundation models (FMs) for impact prediction. A user-centric approach with intuitive interfaces and community feedback is emphasized to improve crisis management. To address climate risk complexity, we advocate for causal AI models to avoid spurious predictions and stress the need for responsible AI practices. We highlight the FATES (Fairness, Accountability, Transparency, Ethics, and Sustainability) principles as essential for equitable and trustworthy AI-based Early Warning Systems for all. We further advocate for decadal EWSs, leveraging climate ensembles and generative methods to enable long-term, spatially resolved forecasts for proactive climate adaptation. In the era of climate change, human societies face growing exposure to disasters and complex climate risks. This perspective explores the transformative potential of integrated Artificial Intelligence in developing multi-hazard Early Warning Systems for all.",
    "doi": "10.1038/s41467-025-57640-w",
    "url": "https://www.semanticscholar.org/paper/6d6db2763b8b38d9b42cd3e5a98b025fba43f3fb",
    "pdf_url": "https://doi.org/10.1038/s41467-025-57640-w",
    "venue": "Nature Communications",
    "citation_count": 44,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:53.972731"
  },
  {
    "source": "semantic_scholar",
    "source_id": "876ab281803d388d2608d9db3dcbea513c538639",
    "title": "UNMASKING BIAS: A CRITICAL REVIEW OF AI IN HUMAN RESOURCE MANAGEMENT",
    "authors": [
      "Kumarakulasingam Brasanan"
    ],
    "year": 2024,
    "abstract": "Using Artificial Intelligence (AI) more in Human Resource Management (HRM) can bring many advantages such as making processes faster, more fair, and able to handle larger tasks effectively. However, this change in technology has also brought some new problems, especially biased algorithms. This review looks at how bias appears in AI-based HR systems, especially in hiring, performance reviews, and workforce data analysis. Utilizing inquire about from diverse areas, real-life illustrations, and speculations, this paper looks at how inclination is built into information, how calculations are planned, and how they are utilized. Imperative illustrations, like Amazon\u2019s stopped AI contracting instrument and facial examination utilized by HireVue, appear how these innovations can proceed to make shamefulness based on gender, race, and financial status. The review points out a few reasons for unfairness, such as training data that doesn\u2019t include everyone, unclear algorithms, and no responsibility when putting systems into use. It also looks closely at current laws and ethical rules, pointing out that they are not enough to deal with the complicated issues of bias in artificial intelligence in human resources management.",
    "doi": "10.26480/mjhrm.01.2025.53.56",
    "url": "https://www.semanticscholar.org/paper/876ab281803d388d2608d9db3dcbea513c538639",
    "pdf_url": "",
    "venue": "Malaysian Journal Of Human Resources Management",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972732"
  },
  {
    "source": "semantic_scholar",
    "source_id": "37dc3e66b662cfc71ec72aeabcc72ce239216157",
    "title": "Artificial Intelligence in Human Resource Management: A Systematic Review of Drivers, Challenges, and Future Pathways",
    "authors": [
      "Venkatesh Thulasidoss",
      "Mohamed Alfaz",
      "Tamang Min"
    ],
    "year": 2025,
    "abstract": "Background: In developed countries, recruitment agencies are preferring Artificial Intelligence (AI) technologies in hiring human resources in companies. AI integration has become essential in HRM. AI supports multiple functions such as finding the right employees, setting management goals, maintaining institutional knowledge, and modernising work styles.\nObjectives: The study aims to examine the role and benefits of AI in HRM, assess the challenges, ethical concerns, and human\u2013AI collaboration, and explore its practical applications and future directions.\nMethod: The research applies literature review as methodology to collect evidences regarding the roles and challenges of AI in the recruitment process through the perspective of the Diffusion of Innovation theory.\nFindings: Findings shows that AI systems show enhanced efficiency throughout candidate screening processes and skills evaluation however human supervision stands essential to deal with biases and maintain fair recruitment procedures.\nConclusion: The research concludes that future recruitment will evolve into human-AI partnership models instead of machine-only automation while proposing industry standards and ethical frameworks and regulatory policies for implementation-guidance.\nNovelty of the study: Unlike previous research, this paper synthesises how AI development is transforming human resource recruitment while also highlighting the barriers that hinder its effective implementation. A key contribution of this review is the introduction of the concept of human-centered AI in HRM, developed in line with Rogers\u2019 Diffusion of Innovation theory.",
    "doi": "10.3126/njmr.v8i4.82368",
    "url": "https://www.semanticscholar.org/paper/37dc3e66b662cfc71ec72aeabcc72ce239216157",
    "pdf_url": "",
    "venue": "Nepal Journal of Multidisciplinary Research",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972733"
  },
  {
    "source": "semantic_scholar",
    "source_id": "7502eebcb1c0d3fcfd2c06c4cb63faa1a75022f7",
    "title": "Artificial Intelligence and its ability to reduce recruitment bias",
    "authors": [
      "Zaker Ul Oman",
      "A. Siddiqua",
      "Ruqia Noorain"
    ],
    "year": 2024,
    "abstract": "Artificial intelligence is transforming the landscape of Human Resource Management (HRM), altering conventional methods and elevating the recruitment process for companies. The conventional approach to hiring can be incredibly time-intensive, often stretching over several weeks to sift through all applications. This process can be daunting for recruiters, who are tasked with reviewing numerous resumes. AI steps in to streamline this process by rapidly sifting through a large number of applications, identifying the most suitable candidates, and providing concise overviews of their qualifications. This not only saves recruiters time but also allows them to concentrate on improving the candidate experience and attracting top talent. AI operates around the clock, ensuring the recruitment process remains active and effective even when recruiters are not on duty. Moreover, AI can help mitigate bias, when utilized correctly, it can facilitate more equitable hiring decisions by focusing on relevant skills and experiences rather than personal biases. This article explores the multifaceted role of AI in mitigating recruitment bias, AI algorithms use objective data and set criteria to reduce unconscious bias during initial screening. This approach helps ensure that job seekers are evaluated based on qualifications and merit, rather than personal characteristics.",
    "doi": "10.30574/wjarr.2024.24.1.3054",
    "url": "https://www.semanticscholar.org/paper/7502eebcb1c0d3fcfd2c06c4cb63faa1a75022f7",
    "pdf_url": "",
    "venue": "World Journal of Advanced Research and Reviews",
    "citation_count": 6,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972735"
  },
  {
    "source": "semantic_scholar",
    "source_id": "2d964d26bde42ca53650724b4bdfd23fd33952d6",
    "title": "Towards an Environmental Ethics of Artificial Intelligence",
    "authors": [
      "Nynke van Uffelen",
      "Lode Lauwaert",
      "Mark Coeckelbergh",
      "O. Kudina"
    ],
    "year": 2024,
    "abstract": "In recent years, much research has been dedicated to uncovering the environmental impact of Artificial Intelligence (AI), showing that training and deploying AI systems require large amounts of energy and resources, and the outcomes of AI may lead to decisions and actions that may negatively impact the environment. This new knowledge raises new ethical questions, such as: When is it (un)justifiable to develop an AI system, and how to make design choices, considering its environmental impact? However, so far, the environmental impact of AI has largely escaped ethical scrutiny, as AI ethics tends to focus strongly on themes such as transparency, privacy, safety, responsibility, and bias. Considering the environmental impact of AI from an ethical perspective expands the scope of AI ethics beyond an anthropocentric focus towards including more-than-human actors such as animals and ecosystems. This paper explores the ethical implications of the environmental impact of AI for designing AI systems by drawing on environmental justice literature, in which three categories of justice are distinguished, referring to three elements that can be unjust: the distribution of benefits and burdens (distributive justice), decision-making procedures (procedural justice), and institutionalized social norms (justice as recognition). Based on these tenets of justice, we outline criteria for developing environmentally just AI systems, given their ecological impact.",
    "doi": "10.48550/arXiv.2501.10390",
    "url": "https://www.semanticscholar.org/paper/2d964d26bde42ca53650724b4bdfd23fd33952d6",
    "pdf_url": "",
    "venue": "arXiv.org",
    "citation_count": 5,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:53.972737"
  },
  {
    "source": "semantic_scholar",
    "source_id": "45ae12c71ea4908ce9733f0714655d1d2e76fb54",
    "title": "The Ethics of Artificial Intelligence: Examining the Ethical Considerations Surrounding the Development and Use of AI",
    "authors": [
      "Aisha Zahid Huriye"
    ],
    "year": 2023,
    "abstract": "Aim: AI systems can be complex and opaque, making it challenging to understand how they make decisions. This raises concerns about fairness and accountability, as individuals may not understand the factors that influence the decisions made by AI systems. The aim of this study was to examine the ethical considerations surrounding the development and use of AI. \nMethods: The study adopted a desktop research design. Relevant books reference and journal articles for the study were identified using Google Scholar. The inclusion criteria entailed materials that were related to the ethics of artificial intelligence. \nResults: The study found out that bias, privacy, accountability and transparency are the main ethical concerns that surround the development and use of AI technology in developed countries. Additionally, the studies emphasized the need for collaboration between stakeholders, including policymakers, researchers, and local communities, to ensure that ethical guidelines are developed and implemented. In African countries, the studies highlighted the need for a nuanced understanding of the cultural, political, and economic context of the region when considering ethical AI. Issues related to bias, data privacy, and the impact of AI on the labor market were identified as important ethical considerations in the region. \nConclusion: This study emphasizes the need for a human-centered approach that prioritizes the needs and values of local communities, as well as greater engagement with local stakeholders in the development of ethical guidelines. \nRecommendation: The study recommend development and implementation of ethical guidelines for AI. Policymakers, developers, and researchers should work together to develop and implement ethical guidelines for AI systems. These guidelines should address issues related to bias, transparency, accountability, and privacy, and should be grounded in a commitment to promoting human well-being and social good.",
    "doi": "10.58425/ajt.v2i1.142",
    "url": "https://www.semanticscholar.org/paper/45ae12c71ea4908ce9733f0714655d1d2e76fb54",
    "pdf_url": "https://gprjournals.org/journals/index.php/AJT/article/download/142/177",
    "venue": "American Journal of Technology",
    "citation_count": 57,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972738"
  },
  {
    "source": "semantic_scholar",
    "source_id": "b3fdf3e9cb0a0d0794913ab31376fdb9113db252",
    "title": "Addressing Bias and Fairness Issues in Artificial Intelligence",
    "authors": [
      "Pragya Gupta"
    ],
    "year": 2023,
    "abstract": null,
    "doi": null,
    "url": "https://www.semanticscholar.org/paper/b3fdf3e9cb0a0d0794913ab31376fdb9113db252",
    "pdf_url": "",
    "venue": "",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972740"
  },
  {
    "source": "semantic_scholar",
    "source_id": "e579660ed595fbb19c995ac03eb6ea762b2b4d22",
    "title": "A study of artificial intelligence and its role in human resource management",
    "authors": [
      "Jayaraj Gaddihalli",
      "Arif Shaikh",
      "Rashmi Harti"
    ],
    "year": 2024,
    "abstract": "In this present scenario requests for the human assets as an obligatory resource in arrange to progress the organizational execution. The organizations need to endeavour for embracing the imaginative HR hones to move forward their execution and be diverse in the competition. In close future, HRM is moving from the conventional way of HR hones to more advance like computerization, increased insights, mechanical autonomy and AI. Artificial intelligence is already proving to change our lives. From mechanization of ordinary and time-consuming assignments, to the expansion and enhancement of human capabilities, Computer based program has changed the way work. This may not be a fair time for HR, but it can be a dangerous time that needs to be reformed and supported. Today\u2019s HR professionals both human and technology work to create a simple and intuitive workplace. performance.",
    "doi": "10.1051/itmconf/20246801035",
    "url": "https://www.semanticscholar.org/paper/e579660ed595fbb19c995ac03eb6ea762b2b4d22",
    "pdf_url": "https://doi.org/10.1051/itmconf/20246801035",
    "venue": "ITM Web of Conferences",
    "citation_count": 24,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972742"
  },
  {
    "source": "semantic_scholar",
    "source_id": "2173ac6dd528032446b0b55f15571a8dd8b20e5c",
    "title": "Artificial intelligence ethics by design. Evaluating public perception on the importance of ethical design principles of artificial intelligence",
    "authors": [
      "Kimon Kieslich",
      "Birte Keller",
      "C. Starke"
    ],
    "year": 2021,
    "abstract": "Despite the immense societal importance of ethically designing artificial intelligence, little research on the public perceptions of ethical artificial intelligence principles exists. This becomes even more striking when considering that ethical artificial intelligence development has the aim to be human-centric and of benefit for the whole society. In this study, we investigate how ethical principles (explainability, fairness, security, accountability, accuracy, privacy, and machine autonomy) are weighted in comparison to each other. This is especially important, since simultaneously considering ethical principles is not only costly, but sometimes even impossible, as developers must make specific trade-off decisions. In this paper, we give first answers on the relative importance of ethical principles given a specific use case\u2014the use of artificial intelligence in tax fraud detection. The results of a large conjoint survey ( n = 1099 ) suggest that, by and large, German respondents evaluate the ethical principles as equally important. However, subsequent cluster analysis shows that different preference models for ethically designed systems exist among the German population. These clusters substantially differ not only in the preferred ethical principles but also in the importance levels of the principles themselves. We further describe how these groups are constituted in terms of sociodemographics as well as opinions on artificial intelligence. Societal implications, as well as design challenges, are discussed.",
    "doi": "10.1177/20539517221092956",
    "url": "https://www.semanticscholar.org/paper/2173ac6dd528032446b0b55f15571a8dd8b20e5c",
    "pdf_url": "https://journals.sagepub.com/doi/pdf/10.1177/20539517221092956",
    "venue": "Big Data & Society",
    "citation_count": 124,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:53.972744"
  },
  {
    "source": "semantic_scholar",
    "source_id": "32aec099ac576f7eedeeaaf9f8581df8a465a0fd",
    "title": "Unraveling the Ethical Conundrum of Artificial Intelligence: A Synthesis of Literature and Case Studies",
    "authors": [
      "Pavan Kumar Reddy Poli",
      "Sushma Pamidi",
      "Shravan Kumar Reddy Poli"
    ],
    "year": 2024,
    "abstract": null,
    "doi": "10.1007/s41133-024-00077-5",
    "url": "https://www.semanticscholar.org/paper/32aec099ac576f7eedeeaaf9f8581df8a465a0fd",
    "pdf_url": "",
    "venue": "Augmented Human Research",
    "citation_count": 9,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972745"
  },
  {
    "source": "semantic_scholar",
    "source_id": "3f7f02a9b4f4f240f74fa43922dcebcac5c93b64",
    "title": "Fairness and Ethics in Artificial Intelligence-Based Medical Imagining",
    "authors": [
      "Subarna Tripathi",
      "T. Musiolik"
    ],
    "year": 2022,
    "abstract": "Artificial intelligence has a huge array of current and potential applications in healthcare and medicine. Ethical issues arising due to algorithmic biases are one of the greatest challenges faced in the generalizability of AI models today. The authors address safety and regulatory barriers that impede data sharing in medicine as well as potential changes to existing techniques and frameworks that might allow ethical data sharing for machine learning. With these developments in view, they also present different algorithmic models that are being used to develop machine learning-based medical systems that will potentially evolve to be free of the sample, annotator, and temporal bias. These AI-based medical imaging models will then be completely implemented in healthcare facilities and institutions all around the world, even in the remotest areas, making diagnosis and patient care both cheaper and freely accessible.",
    "doi": "10.4018/978-1-7998-7888-9.ch004",
    "url": "https://www.semanticscholar.org/paper/3f7f02a9b4f4f240f74fa43922dcebcac5c93b64",
    "pdf_url": "",
    "venue": "Ethical Implications of Reshaping Healthcare With Emerging Technologies",
    "citation_count": 16,
    "fields_of_study": [
      "Psychology"
    ],
    "retrieved_at": "2026-02-02T16:57:53.972747"
  },
  {
    "source": "semantic_scholar",
    "source_id": "b47f132fd09632cfc986a99caa70c8f2f958e88d",
    "title": "Connecting the Dots in Trustworthy Artificial Intelligence: From AI Principles, Ethics, and Key Requirements to Responsible AI Systems and Regulation",
    "authors": [
      "Natalia D\u00edaz Rodr\u00edguez",
      "J. Ser",
      "Mark Coeckelbergh",
      "Marcos L'opez de Prado",
      "E. Herrera-Viedma",
      "Francisco Herrera"
    ],
    "year": 2023,
    "abstract": "Trustworthy Artificial Intelligence (AI) is based on seven technical requirements sustained over three main pillars that should be met throughout the system's entire life cycle: it should be (1) lawful, (2) ethical, and (3) robust, both from a technical and a social perspective. However, attaining truly trustworthy AI concerns a wider vision that comprises the trustworthiness of all processes and actors that are part of the system's life cycle, and considers previous aspects from different lenses. A more holistic vision contemplates four essential axes: the global principles for ethical use and development of AI-based systems, a philosophical take on AI ethics, a risk-based approach to AI regulation, and the mentioned pillars and requirements. The seven requirements (human agency and oversight; robustness and safety; privacy and data governance; transparency; diversity, non-discrimination and fairness; societal and environmental wellbeing; and accountability) are analyzed from a triple perspective: What each requirement for trustworthy AI is, Why it is needed, and How each requirement can be implemented in practice. On the other hand, a practical approach to implement trustworthy AI systems allows defining the concept of responsibility of AI-based systems facing the law, through a given auditing process. Therefore, a responsible AI system is the resulting notion we introduce in this work, and a concept of utmost necessity that can be realized through auditing processes, subject to the challenges posed by the use of regulatory sandboxes. Our multidisciplinary vision of trustworthy AI culminates in a debate on the diverging views published lately about the future of AI. Our reflections in this matter conclude that regulation is a key for reaching a consensus among these views, and that trustworthy and responsible AI systems will be crucial for the present and future of our society.",
    "doi": "10.48550/arXiv.2305.02231",
    "url": "https://www.semanticscholar.org/paper/b47f132fd09632cfc986a99caa70c8f2f958e88d",
    "pdf_url": "http://arxiv.org/pdf/2305.02231",
    "venue": "Information Fusion",
    "citation_count": 476,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:53.972749"
  },
  {
    "source": "semantic_scholar",
    "source_id": "01c36a74693065664bba51e7fdf95709cc690aae",
    "title": "Testing AI Models: The Human Factor in Ensuring Accuracy, Fairness, and Transparency",
    "authors": [
      "Ashwin Choubey"
    ],
    "year": 2025,
    "abstract": "The integration of artificial intelligence across industries has highlighted the indispensable role of human testers in ensuring AI system reliability, fairness, and transparency. While automated testing provides efficiency in processing large-scale data, human oversight remains crucial for detecting nuanced issues, cultural biases, and ethical concerns. This article delves into the multifaceted aspects of human-centric AI testing, exploring how human testers contribute to test design, bias detection, and ethical framework implementation. The article demonstrates that human testers excel in identifying contextual subtleties, cultural nuances, and potential societal impacts that automated systems often miss. Through collaborative approaches combining human expertise with AI capabilities, organizations can achieve superior testing outcomes in areas ranging from healthcare diagnostics to human resource management. The implementation of structured documentation practices and diverse testing teams further enhances the effectiveness of AI system evaluation. As AI systems grow more complex, addressing scaling challenges and developing enhanced human-AI collaboration tools becomes essential for maintaining robust testing processes and ensuring responsible AI deployment.",
    "doi": "10.32628/cseit251112238",
    "url": "https://www.semanticscholar.org/paper/01c36a74693065664bba51e7fdf95709cc690aae",
    "pdf_url": "",
    "venue": "International Journal of Scientific Research in Computer Science Engineering and Information Technology",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972750"
  },
  {
    "source": "semantic_scholar",
    "source_id": "4a10e59163f2e4e4472e754ccea7c6d2a99c5705",
    "title": "Enhancing Recruitment Selection Process In Human Resource With Artificial Intelligence Powered Resume Parser",
    "authors": [
      "Yik Junn Kuan",
      "Pei Yi Voon",
      "Li June Tan",
      "Mahdiyehsadat Moosavi",
      "Kar Yee Chong"
    ],
    "year": 2025,
    "abstract": "The traditional recruitment process suffers from inefficiencies, subjective evaluations and biases that hinder hiring quality and increase costs. This research develops an AI-powered Resume Parser to automate resume screening process and address these challenges. The system uses Natural Language Processing (NLP) and machine learning techniques for automation, utilizing an XGBoost classifier for job categorization and a customized Named Entity Recognition (NER) model for information extraction. The models were trained on 2484 resumes across 24 job categories with comprehensive data pre-processing and addressed class imbalance using SMOTE. The performance of six algorithms was compared throughout the research, revealing that XGBoost achieved optimal accuracy of 77% in job categorization, outperforming other tested algorithms including Random Forest (68%), Support Vector Machine (SVM) (62%), and Logistic Regression (64%) etc. The customized NER model successfully extracted key entities including candidate name and skills with high accuracy in test cases, proving its effectiveness in resume parsing. This system revolutionizes the recruitment process by promoting fairness, efficiency and transparency while addressing the limitations of manual recruitment methods.",
    "doi": "10.1109/IICAIET67254.2025.11265526",
    "url": "https://www.semanticscholar.org/paper/4a10e59163f2e4e4472e754ccea7c6d2a99c5705",
    "pdf_url": "",
    "venue": "International Conference on Artificial Intelligence in Engineering and Technology",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972752"
  },
  {
    "source": "semantic_scholar",
    "source_id": "741c7e78d0bd101b1fbf39d0c47fc519941bd275",
    "title": "Toward fairness in artificial intelligence for medical image analysis: identification and mitigation of potential biases in the roadmap from data collection to model deployment",
    "authors": [
      "K. Drukker",
      "Weijie Chen",
      "Judy Gichoya",
      "Nicholas P. Gruszauskas",
      "Jayashree Kalpathy-Cramer",
      "Sanmi Koyejo",
      "Kyle Myers",
      "Rui C. S\u00e1",
      "B. Sahiner",
      "Heather M. Whitney",
      "Zi Zhang",
      "M. Giger"
    ],
    "year": 2023,
    "abstract": "Abstract. Purpose To recognize and address various sources of bias essential for algorithmic fairness and trustworthiness and to contribute to a just and equitable deployment of AI in medical imaging, there is an increasing interest in developing medical imaging-based machine learning methods, also known as medical imaging artificial intelligence (AI), for the detection, diagnosis, prognosis, and risk assessment of disease with the goal of clinical implementation. These tools are intended to help improve traditional human decision-making in medical imaging. However, biases introduced in the steps toward clinical deployment may impede their intended function, potentially exacerbating inequities. Specifically, medical imaging AI can propagate or amplify biases introduced in the many steps from model inception to deployment, resulting in a systematic difference in the treatment of different groups. Approach Our multi-institutional team included medical physicists, medical imaging artificial intelligence/machine learning (AI/ML) researchers, experts in AI/ML bias, statisticians, physicians, and scientists from regulatory bodies. We identified sources of bias in AI/ML, mitigation strategies for these biases, and developed recommendations for best practices in medical imaging AI/ML development. Results Five main steps along the roadmap of medical imaging AI/ML were identified: (1) data collection, (2) data preparation and annotation, (3) model development, (4) model evaluation, and (5) model deployment. Within these steps, or bias categories, we identified 29 sources of potential bias, many of which can impact multiple steps, as well as mitigation strategies. Conclusions Our findings provide a valuable resource to researchers, clinicians, and the public at large.",
    "doi": "10.1117/1.JMI.10.6.061104",
    "url": "https://www.semanticscholar.org/paper/741c7e78d0bd101b1fbf39d0c47fc519941bd275",
    "pdf_url": "https://www.spiedigitallibrary.org/journals/journal-of-medical-imaging/volume-10/issue-6/061104/Toward-fairness-in-artificial-intelligence-for-medical-image-analysis/10.1117/1.JMI.10.6.061104.pdf",
    "venue": "Journal of Medical Imaging",
    "citation_count": 89,
    "fields_of_study": [
      "Medicine",
      "Engineering"
    ],
    "retrieved_at": "2026-02-02T16:57:53.972754"
  },
  {
    "source": "semantic_scholar",
    "source_id": "bf42d79010c6b3b3c6807c8ddccfa2a099038863",
    "title": "Ethical impact assessment. A tool of the Recommendation on the Ethics of Artificial Intelligence",
    "authors": [],
    "year": 2023,
    "abstract": "The Recommendation on the Ethics of AI provides a framework to ensure that AI developments align with the promotion and protection of human rights and human dignity, environmental sustainability, fairness, inclusion and gender equality. It underscores that these goals and principles should inform technological developments in an ex-ante manner. To support effective implementation, UNESCO developed two instruments, the Readiness Assessment Methodology (RAM) and the Ethical Impact Assessment (EIA). The EIA is proposed to procurers of AI systems, as this is one of the main channels in which algorithms make their way to highly sensitive public domains. But the questions and the structure of the document are designed so the tools can also be used more generally by developers of AI systems, in the public or private sectors, who wish to develop AI ethically and fully comply with international standards such as the Recommendation. The document comprises two main parts that together strike a balance between procedure and substance. In the first part, related to scoping, the goal is to understand the basics of the system, as well as to lay out some preliminary questions, such as whether automation is the best solution for the case at hand. It also raises questions about the project team and whether plans are in place to engage different stakeholders. The second part is dedicated to implementing the principles in the UNESCO Recommendation. UNESCO Catno: 0000386276",
    "doi": "10.54678/ytsa7796",
    "url": "https://www.semanticscholar.org/paper/bf42d79010c6b3b3c6807c8ddccfa2a099038863",
    "pdf_url": "",
    "venue": "",
    "citation_count": 25,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972756"
  },
  {
    "source": "semantic_scholar",
    "source_id": "c4cdd704768868167b161ef4cbce275de7e160d9",
    "title": "On the Right to Work in the Age of Artificial Intelligence: Ethical Safeguards in Algorithmic Human Resource Management",
    "authors": [
      "M. Capasso",
      "Payal Arora",
      "Deepshikha Sharma",
      "Celeste Tacconi"
    ],
    "year": 2024,
    "abstract": "Abstract Algorithmic human resource management (AHRM), the automation or augmentation of human resources-related decision-making with the use of artificial intelligence (AI)-enabled algorithms, can increase recruitment efficiency but also lead to discriminatory results and systematic disadvantages for marginalized groups in society. In this paper, we address the issue of equal treatment of workers and their fundamental rights when dealing with these AI recruitment systems. We analyse how and to what extent algorithmic biases can manifest and investigate how they affect workers\u2019 fundamental rights, specifically (1) the right to equality, equity, and non-discrimination; (2) the right to privacy; and, finally, (3) the right to work. We recommend crucial ethical safeguards to support these fundamental rights and advance forms of responsible AI governance in HR-related decisions and activities.",
    "doi": "10.1017/bhj.2024.26",
    "url": "https://www.semanticscholar.org/paper/c4cdd704768868167b161ef4cbce275de7e160d9",
    "pdf_url": "",
    "venue": "Business and Human Rights Journal",
    "citation_count": 9,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972757"
  },
  {
    "source": "semantic_scholar",
    "source_id": "ffada086cca0ba01ab7d72845bafcab035f8618d",
    "title": "Role of artificial intelligence in human resource management for optimizing employee productivity",
    "authors": [
      "Nupur Veshne",
      "Jyoti Jamnani"
    ],
    "year": 2024,
    "abstract": "Artificial intelligence (AI) has significantly transformed various industries, including human resource management, by enhancing efficiency, decision-making, and employee productivity. Recruitments can be modernized by using catboats, predictive analysis helps in offering data-driven insights that can be used to find skill gaps and people management planning. AI\u2019s advancements have made it easy to integrate AI with HRM for increasing efficiency, despite this a lot of ethical concerns, biases, and privacy issue makes it difficult to implement AI completely in the decision-making process. This paper is a bibliometric study focusing on the evolution of AI with HRM to enhance employee productivity and identify key trends and research gaps. This study considered publications for 10 years from 2014 to 2024 through various databases such as Scopus, Web of Science, and IEEE, the study further divides the literature to highlight the most cited authors, countries contributing to the field, and year-wise contribution. The paper focuses on studying the role of AI in various functional areas of HR such as recruitment, performance, and employee productivity. The findings highlight the increasing role of AI across multiple HR practices. This bibliometric investigation offers valuable findings for researchers and practitioners aiming to use AI to enhance HR jobs.",
    "doi": "10.1051/itmconf/20246801003",
    "url": "https://www.semanticscholar.org/paper/ffada086cca0ba01ab7d72845bafcab035f8618d",
    "pdf_url": "https://doi.org/10.1051/itmconf/20246801003",
    "venue": "ITM Web of Conferences",
    "citation_count": 3,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972759"
  },
  {
    "source": "semantic_scholar",
    "source_id": "122ac1ab00f8c54a609e18d2aea5a0008b032f8a",
    "title": "Strategic Adoption of Artificial Intelligence for Human Resource Management Practices Transforming Healthcare Sector",
    "authors": [
      "Amit Joshi",
      "Rubee Singh",
      "Seema Rani"
    ],
    "year": 2024,
    "abstract": "The incorporation of Artificial Intelligence (AI) technology into several industries has significantly impacted the usual workflows and processes in recent years, including the healthcare industry. Human Resource Management (HRM) is essential in healthcare businesses as it is responsible for the recruitment, training, and the retention of skilled staff members who are capable of providing high-quality patient care. This paper investigates different methods in which AI is used in HRM in the healthcare industry on the basis of existing research in the area. It analyzes how AI affects recruitment, talent management, workforce optimization, and employee well-being. This paper also discusses the challenges and future prospects of AI-driven approaches in HRM practices. It explores how these approaches are changing the way healthcare organizations operate and improving patient outcomes. The results provide some valuable contributions to the field of artificial intelligence in the healthcare sector. Initially, the chapter gives a factual foundation for the current presumptions on the implementation and difficulties of artificial intelligence in the healthcare domain. Further, it shows how artificial intelligence provides numerous opportunities to expedite Human Resource operations by offering automated applicant screening, customized learning systems, optimizing the workforce and enhancing employee engagement. Although AI has the capacity to revolutionize HRM practices in the healthcare industry, it also presents some challenges and obstacles. In order to ensure that AI-driven solutions promote fairness, transparency, and equity, it is crucial to address issues such as algorithmic bias, privacy of data and the impact on the human workforce in a deliberate manner. In addition, healthcare firms need to invest funds for implementing rigorous cyber security measures in order to ensure the privacy of patient and employee data from cyber-attacks and potential breaches.",
    "doi": "10.58818/ijems.v3i3.133",
    "url": "https://www.semanticscholar.org/paper/122ac1ab00f8c54a609e18d2aea5a0008b032f8a",
    "pdf_url": "",
    "venue": "The International Journal of Education Management and Sociology",
    "citation_count": 5,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972760"
  },
  {
    "source": "semantic_scholar",
    "source_id": "592deae803b208f808dd4fd09f5018203882934c",
    "title": "Artificial Intelligence in Educational Data Mining and Human-in-the-Loop Machine Learning and Machine Teaching: Analysis of Scientific Knowledge",
    "authors": [
      "Eloy L\u00f3pez-Meneses",
      "Luis L\u00f3pez-Catal\u00e1n",
      "Noelia Pel\u00edcano-Piris",
      "Pedro C. Mellado-Moreno"
    ],
    "year": 2025,
    "abstract": "This study explores the integration of artificial intelligence (AI) into educational data mining (EDM), human-assisted machine learning (HITL-ML), and machine-assisted teaching, with the aim of improving adaptive and personalized learning environments. A systematic review of the scientific literature was conducted, analyzing 370 articles published between 2006 and 2024. The research examines how AI can support the identification of learning patterns and individual student needs. Through EDM, student data are analyzed to predict student performance and enable timely interventions. HITL-ML ensures that educators remain in control, allowing them to adjust the system according to their pedagogical goals and minimizing potential biases. Machine-assisted teaching allows AI processes to be structured around specific learning criteria, ensuring relevance to educational outcomes. The findings suggest that these AI applications can significantly improve personalized learning, student tracking, and resource optimization in educational institutions. The study highlights ethical considerations, such as the need to protect privacy, ensure the transparency of algorithms, and promote equity, to ensure inclusive and fair learning environments. Responsible implementation of these methods could significantly improve educational quality.",
    "doi": "10.3390/app15020772",
    "url": "https://www.semanticscholar.org/paper/592deae803b208f808dd4fd09f5018203882934c",
    "pdf_url": "https://doi.org/10.3390/app15020772",
    "venue": "Applied Sciences",
    "citation_count": 17,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972762"
  },
  {
    "source": "semantic_scholar",
    "source_id": "991ea65441a76cf817475541c60e2740b352c71d",
    "title": "Combining Human-in-the-Loop Systems and AI Fairness Toolkits to Reduce Age Bias in AI Job Hiring Algorithms",
    "authors": [
      "Christopher G. Harris"
    ],
    "year": 2024,
    "abstract": "As artificial intelligence (AI) systems become more sophisticated, they are increasingly integrated into high-stakes decision-making processes, such as hiring, fraud detection, loan approvals, and medical diagnoses. However, this growing reliance on AI raises concerns about the potential for these systems to perpetuate and amplify societal biases. Researchers have developed two main approaches to bias mitigation in AI to address this issue: human-in-the-loop (HITL) systems and AI fairness toolkits. HITL systems involve human reviewers actively participating in the AI decision-making process, while AI fairness toolkits are software tools that can identify and mitigate bias. HITL systems are particularly effective in addressing biases tied to specific domains, while AI fairness toolkits can be useful in identifying and addressing bias proactively. This paper examines different combinations of HITL systems and AI fairness toolkits, conducts an experiment to evaluate biases in hiring decisions using each, and provides recommendations for organizations considering implementing one or both approaches.",
    "doi": "10.1109/BigComp60711.2024.00019",
    "url": "https://www.semanticscholar.org/paper/991ea65441a76cf817475541c60e2740b352c71d",
    "pdf_url": "",
    "venue": "International Conference on Big Data and Smart Computing",
    "citation_count": 3,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:53.972763"
  },
  {
    "source": "semantic_scholar",
    "source_id": "2d6a9ee25f4736f0a605d489e90ab160b09547ec",
    "title": "Ai as Employee Performance Evaluation: An Innovative Approach in Human Resource Development",
    "authors": [
      "Dr. H. Djunaedi",
      "M.AB"
    ],
    "year": 2024,
    "abstract": "Employee performance evaluation is a crucial process in human resource management. It measures an individual's contribution to organizational goals. However, traditional evaluation methods face obstacles like subjective bias, inefficiency, and lack of objectivity. Artificial Intelligence (AI) technology offers a promising solution. This paper discusses AI's implementation as an evaluation tool and its impact on human resource development. Previous research shows that AI improves objectivity, fairness, and efficiency in appraisal. It accurately identifies employee potential, aiding targeted development programs. However, research gaps remain, such as AI's use in different industries and ethical concerns affecting employees and organizational culture. This study aims to investigate AI's use in various industry contexts, understand ethical and trust aspects, and analyze its impact on employees and organizational culture. The results will provide valuable insights into AI's benefits in performance evaluation, benefiting human resource development and improving the evaluation process. Organizational understanding of AI's challenges and benefits in human resource development can enhance overall productivity and performance.",
    "doi": "10.52783/pst.469",
    "url": "https://www.semanticscholar.org/paper/2d6a9ee25f4736f0a605d489e90ab160b09547ec",
    "pdf_url": "",
    "venue": "Power system technology",
    "citation_count": 9,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972764"
  },
  {
    "source": "semantic_scholar",
    "source_id": "4a19368f0b3bcd6969bea644725ca0e1e409190d",
    "title": "Assessing the Influence of Artificial Intelligence on Human Resource Management Practices",
    "authors": [
      "Qurotul Aini",
      "U. Rusilowati",
      "Marsani Asfi",
      "Po Abas Sunarya",
      "Souza Nurafrianto Windiartono Putra",
      "Achani Rahmania Az Zahra"
    ],
    "year": 2024,
    "abstract": "This research investigates the contemporary impact of artificial intelligence (AI) on human resource management (HRM) practices. In the context of the rapidly evolving AI landscape, this study aims to comprehensively assess its transformative effects on HRM within current organizational and business frameworks. Utilizing a multi-faceted methodology, including a cross-sector survey of 235 participants, in-depth interviews with HR professionals, and extensive literature analysis, the research explores critical issues such as AI\u2019s influence on recruitment processes, performance evaluations, and employee development strategies. The findings reveal that while AI has the potential to enhance HRM efficiency, it also introduces ethical considerations, data security challenges, and psychological implications for employees. The study advocates for a holistic approach to integrating AI into HRM practices, taking into account technical nuances, ethical dimensions, and prioritizing employee well-being. Practical implications emphasize the need for organizations to adopt balanced and adaptive policies to ensure the judicious use of AI in HRM, achieving optimal benefits while maintaining fairness and workforce welfare.",
    "doi": "10.1109/ICCIT62134.2024.10701158",
    "url": "https://www.semanticscholar.org/paper/4a19368f0b3bcd6969bea644725ca0e1e409190d",
    "pdf_url": "",
    "venue": "International Conference on Communications and Information Technology",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972766"
  },
  {
    "source": "semantic_scholar",
    "source_id": "b24cd6730256ced735b6fab7ef3ad637fcf9a0b0",
    "title": "Impact of Artificial Intelligence (AI) on Human Resource Management (HRM)",
    "authors": [
      "Ritika Gupta"
    ],
    "year": 2024,
    "abstract": "Incorporating Artificial Intelligence (AI) into Human Resource Management (HRM) has become a significant driving force in shaping contemporary workplaces. This paper comprehensively examines AI's influence on HRM, from its foundational concepts to its practical applications, advantages, challenges, ethical considerations, legal ramifications, anticipated trends, and actionable recommendations. Commencing with an introductory framework, the paper navigates the intricate facets of AI within HRM, elucidating its diverse components and functionalities. It further scrutinizes AI's specific roles in recruitment, training, performance management, and employee engagement, emphasizing its transformative potential. Additionally, the paper articulates the manifold benefits AI affords HRM, such as process optimization, informed decision-making, and enhanced employee engagement, juxtaposed against the inherent challenges, including data integrity, privacy concerns, biases, and algorithmic transparency issues. Addressing AI's ethical and legal dimensions in HRM, the paper underscores the imperative of conscientious AI integration and governance. Furthermore, it anticipates forthcoming AI trends and furnishes strategic guidance for organizations navigating this evolving landscape. Ultimately, the paper advocates for ethical, transparent, and human-centric approaches to AI adoption, underscoring its profound impact on HRM practices and workplace dynamics.",
    "doi": "10.36948/ijfmr.2024.v06i03.21444",
    "url": "https://www.semanticscholar.org/paper/b24cd6730256ced735b6fab7ef3ad637fcf9a0b0",
    "pdf_url": "https://www.ijfmr.com/papers/2024/3/21444.pdf",
    "venue": "International Journal For Multidisciplinary Research",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972767"
  },
  {
    "source": "semantic_scholar",
    "source_id": "f1f0a6ebacac9983b8e745b19dbf18123b655473",
    "title": "The Transformative Role of Artificial Intelligence in Human Resource",
    "authors": [
      "Yavana Rani Subramanian",
      "Riya R"
    ],
    "year": 2024,
    "abstract": "This research paper explores the impact of artificial intelligence (AI) on human resources (HR). It focuses on the role of HR professionals evolving the influence of AI-driven practices on employee experience and the dynamics of collaboration between humans and AI. The study emphasizes a shift in HR responsibilities towards functions and highlights the crucial skills needed for success in an AI integrated environment. It identifies effects on employee experience, such as learning opportunities, while acknowledging potential drawbacks like job displacement and biased algorithms. The paper advocates for a partnership between humans and AI, emphasizing governance and continuous learning. Recommendations for HR professionals and organizations include embracing learning, prioritizing functions, advocating for ethical AI practices, and fostering collaborative relationships with AI. Ultimately, the paper envisions a future where AI complements expertise to create a compassionate workplace. It calls for research in this transformative HR landscape.",
    "doi": "10.31674/ijrtbt.2024.v08i02.002",
    "url": "https://www.semanticscholar.org/paper/f1f0a6ebacac9983b8e745b19dbf18123b655473",
    "pdf_url": "",
    "venue": "International Journal on Recent Trends in Business and Tourism",
    "citation_count": 3,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972769"
  },
  {
    "source": "semantic_scholar",
    "source_id": "d80cd9caaada14ca658b65c5448125d2522f90cf",
    "title": "A study on Pursuit of Artificial Intelligence in Human Resource Management: A Narrative view",
    "authors": [
      "Mahesh C. Ganagi",
      "Arun A. Rotti"
    ],
    "year": 2024,
    "abstract": "This study harnesses the power of narrative to explore how artificial intelligence (AI) transforms Human Resource Management (HRM). The findings illustrate the broad changes that are taking place in key HR activities like recruitment, performance management processes, employee engagement and learning & development as organizations adopt more AI powered tools to enable workforce outcomes. Synthesising current insights and case studies, the paper identifies AI use-cases that help improve processes while supporting data-driven decision-making. But it tackles moral questions too \u2014 biases in algorithms, privacy issues around handling data and the iffy territory of how workers might take to using A.I. The methodology makes use of a secondary data analysis, employing thematic analysis to investigate the consequences that AI can mean for HRM. The results bring home the vast possibilities and difficulties associated with utilizing AI, underscoring why HR workers must quickly come to grips with rapid change in tech. Conclusion This study facilitates important contributions to the current debate on AI and future work, providing a comprehensive narrative perspective on what it means for HR professionals and organizations.",
    "doi": "10.1051/itmconf/20246801005",
    "url": "https://www.semanticscholar.org/paper/d80cd9caaada14ca658b65c5448125d2522f90cf",
    "pdf_url": "https://doi.org/10.1051/itmconf/20246801005",
    "venue": "ITM Web of Conferences",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972770"
  },
  {
    "source": "semantic_scholar",
    "source_id": "a6d0cde74930483a124173777ac0fd43aae56d5a",
    "title": "HUMAN RESOURCE MANAGEMENT AND ARTIFICIAL INTELLIGENCE: TRANSFORMATIVE EFFECTS AND FUTURE PROSPECTS",
    "authors": [
      "Rajeev Kaur"
    ],
    "year": 2024,
    "abstract": "Artificial intelligence (AI) is technology that enables computers and machines to simulate human learning, comprehension, problem solving, decision making, creativity and autonomy. Ancient civilizations contained tales of intelligent robots, such as Greek and Chinese cultures. AI as a modern phenomenon which took shape in the mid-20th century with the advent of digital computers. The first breakthrough, published in 1950, was Alan Turing's paper, \u2018Computing Machinery and Intelligence. AI can make provide detailed solution to users and experts. They can act independently, replacing the need for human intelligence or intervention (a classic example being a self-driving car). Many sectors like finance, healthcare, to human resource management (HRM), rely on AI technologies. AI's integration in HRM has brought about great change in conventional HR practices used to measure efficiency, accuracy, strategic decision-making, etc. AI technologies help to provide solution to automation of repetitive tasks, analysis of sprawling volumes of data and insights facilitating decision-making. Through this research paper we try to understand the AI's effects on HR processes, in terms of recruitment, onboarding, performance appraisal, training and development, employee engagement, workforce planning; understanding the benefits and cons of implementing AI in HRM; ethical considerations and potential biases in AI algorithms relevant to HR practices; analysis of emergent AI trends with respect to HRM. Trends in AI in HR tend towards a most promising future, presenting several innovations. Accordingly, HR professionals will be expected to acquire competency with regards to new roles and responsibilities to avail AI in enhancing strategic planning, ethical oversight, and data-driven decision-making.",
    "doi": "10.62823/ijemmasss/6.3(ii).6911",
    "url": "https://www.semanticscholar.org/paper/a6d0cde74930483a124173777ac0fd43aae56d5a",
    "pdf_url": "",
    "venue": "International Journal of Education, Modern Management, Applied Science &amp; Social Science",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972772"
  },
  {
    "source": "semantic_scholar",
    "source_id": "b3818f70a2eaa14f8e8042ae899e95c62b0478b4",
    "title": "Ethical Concerns Upon Artificial Intelligence Empowered Human Resource Management: A Qualitative Study among Middle-level Managers from Beijing Technology Companies",
    "authors": [
      "Hong Wei",
      "Cao Chen"
    ],
    "year": 2024,
    "abstract": "The evolution of artificial intelligence (AI) in organizational management has significantly enhanced operational efficiency. However, it has introduced ethical challenges in human resource management. Between January to March 2024, this study conducted 21 semi-structured interviews with middle-level managers from high-tech companies in Beijing. Through word frequency analysis, the study found that key topics among the managers were \u201ccompany,\u201d \u201cdata,\u201d \u201csystem,\u201d and \u201cproblem,\u201d with \u201cAI\u201d frequently recurring in the discussions. Sentiment analysis revealed generally favorable attitudes toward AI in human resource management (AI-HRM), along with nuanced emotional expressions such as inquiry, introspection, recommendation, challenge, adaptation, resistance, and indifference. The sentiment distribution of keywords aligned with topic trends. Thematic analysis identified key ethical concerns in AI-HRM, including issues related to data collection and utilization, human versus machine decision-making, quantitative versus qualitative assessment methodologies, the balance between fairness and efficiency, the need for trustworthy, explainable, and transparent AI, and the oversight of AI-HRM. This study contributes to the ethical investigation of AI-HRM from the perspective of middle-level managers, highlighting themes that are critical for understanding the theory, application, and future development of AI-HRM.",
    "doi": "10.36948/ijfmr.2024.v06i05.28860",
    "url": "https://www.semanticscholar.org/paper/b3818f70a2eaa14f8e8042ae899e95c62b0478b4",
    "pdf_url": "https://www.ijfmr.com/papers/2024/5/28860.pdf",
    "venue": "International Journal For Multidisciplinary Research",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972773"
  },
  {
    "source": "semantic_scholar",
    "source_id": "7d29cfa033dc65a063555083aba9afc26d382a94",
    "title": "The Effects and Functionality of Artificial Intelligence in Human Resource Management",
    "authors": [
      "Muskan Kumari,"
    ],
    "year": 2024,
    "abstract": "Artificial intelligence (AI) technology have revolutionised many elements of corporate operations in recent years, and human resource management (HRM) is no exception. The many functions and impacts of AI in the field of HRM are examined in this paper. This study attempts to shed light on how AI is changing traditional HR practices, the benefits it delivers, as well as the possible obstacles and ethical considerations it presents, by a thorough examination of the available research and empirical investigations. The study will examine how AI is used in HRM in a variety of contexts, such as hiring and selection procedures, performance management, employee engagement, and training and development programmes. It will look at how AI-powered solutions are improving accuracy and efficiency in HR tasks. Examples of these tools include chatbots for candidate conversation, resume screening algorithms, and predictive analytics for finding high-potential individuals. The project will also explore the ways in which AI may support inclusion and diversity in the workplace and enhance the work experience for employees. Additionally, the study will go over the possible drawbacks of implementing AI in HRM, including worries about algorithmic bias, data privacy, and the displacement of human labour. The ethical issues surrounding the use of AI to make critical HR decisions as well as the requirement for accountability and transparency in AI-driven processes will also be covered.",
    "doi": "10.55041/ijsrem31091",
    "url": "https://www.semanticscholar.org/paper/7d29cfa033dc65a063555083aba9afc26d382a94",
    "pdf_url": "https://ijsrem.com/download/the-effects-and-functionality-of-artificial-intelligence-in-human-resource-management/?wpdmdl=30405&refresh=665b9debcd5851717280235",
    "venue": "INTERANTIONAL JOURNAL OF SCIENTIFIC RESEARCH IN ENGINEERING AND MANAGEMENT",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972775"
  },
  {
    "source": "semantic_scholar",
    "source_id": "652dca5fc615170d2905ca78c91ee17dc5257549",
    "title": "Ethics, Bias, and Governance in Artificial Intelligence for Hepatology: Toward Building a Safe and Fair Future.",
    "authors": [
      "Chanda K. Ho",
      "S. Asrani"
    ],
    "year": 2025,
    "abstract": null,
    "doi": "10.1016/j.jceh.2025.102628",
    "url": "https://www.semanticscholar.org/paper/652dca5fc615170d2905ca78c91ee17dc5257549",
    "pdf_url": "",
    "venue": "Journal of Clinical and Experimental Hepatology",
    "citation_count": 4,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:53.972776"
  },
  {
    "source": "semantic_scholar",
    "source_id": "28afd70b450ed944d6040aee97575bf3ff295cb3",
    "title": "Ethical Integration of Artificial Intelligence in Healthcare: Narrative Review of Global Challenges and Strategic Solutions",
    "authors": [
      "M. P. Singh",
      "Y. Keche"
    ],
    "year": 2025,
    "abstract": "Artificial intelligence (AI) is revolutionizing healthcare, offering innovative solutions to enhance diagnostic accuracy, treatment efficacy, and accessibility. However, integrating AI into clinical practice raises significant ethical implications, necessitating clear guidelines and frameworks. This paper provides a comprehensive review of the ethical landscape surrounding AI deployment in healthcare across various countries and regions. It explores AI's transformative potential while underscoring the need to prioritize patient safety, transparency, accountability, data privacy, fairness, and human oversight. The paper analyzes existing guidelines from the European Union, the United States, India, Australia, and Africa, identifying common ethical principles and considerations. It discusses challenges and proposes suggestions for addressing issues such as data quality and bias, transparency, privacy and security, accessibility and equity, and robust legal and regulatory frameworks. By fostering a comprehensive understanding of the ethical implications and guidelines surrounding AI in healthcare, this paper aims to contribute to the responsible development and equitable deployment of these transformative technologies.",
    "doi": "10.7759/cureus.84804",
    "url": "https://www.semanticscholar.org/paper/28afd70b450ed944d6040aee97575bf3ff295cb3",
    "pdf_url": "",
    "venue": "Cureus",
    "citation_count": 10,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:53.972778"
  },
  {
    "source": "semantic_scholar",
    "source_id": "65b983d217e294de4cc3fb22758368d5bf9a41fe",
    "title": "Ethics in Education: Exploring the Ethical Implications of Artificial Intelligence Implementation",
    "authors": [
      "Florina Mihai Leta",
      "Diane-Paula Vancea"
    ],
    "year": 2023,
    "abstract": "The integration of artificial intelligence (AI) technology in education has introduced numerous possibilities and benefits. However, it also raises ethical concerns that demand careful consideration. This research article explores the ethical implications associated with the implementation of AI in education. The literature review examines key ethical dimensions, including privacy and data protection, equity and bias, and the impact on the teacher-student relationship. The findings highlight the importance of transparency, accountability, and fairness in AI design and deployment. The article proposes a comprehensive framework to guide ethical AI implementation in education, emphasizing the need for robust policies, algorithmic transparency, and addressing biases. By proactively addressing these ethical considerations, educational stakeholders can ensure a responsible and inclusive educational environment that harnesses the potential of AI while upholding ethical principles.",
    "doi": "10.61801/ouaess.2023.1.54",
    "url": "https://www.semanticscholar.org/paper/65b983d217e294de4cc3fb22758368d5bf9a41fe",
    "pdf_url": "",
    "venue": "Ovidius University Annals: Economic Sciences Series",
    "citation_count": 10,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972779"
  },
  {
    "source": "semantic_scholar",
    "source_id": "6fe7a7dec52c70a7b1f246998c7936b2dba20b07",
    "title": "Ethical issues of Artificial Intelligence in Healthcare in Developing Countries: A Systematic Review of Empirical Studies",
    "authors": [
      "Khunsa Junaid",
      "Mehreen Nasir",
      "Saadia Rafique",
      "Amber Arshad",
      "Meha Siddiqui",
      "Muhammad Ali Junaid"
    ],
    "year": 2025,
    "abstract": "Significant improvements in diagnosis, treatment, and patient outcomes are possible with the use of artificial intelligence (AI) in healthcare. However, there is still a lack of research on ethical issues, especially in developing nations. This systematic review, conducted following PRISMA 2020 guidelines, identified 22 studies from a comprehensive search of 2977 records published between January 2019 and May 2024. Ethical themes were categorised using Jobin et al.'s framework and the European Commission's Ethics Guidelines for Trustworthy AI (EGTAI), while studies were evaluated using Kitchenham and Charters' quality checklist. Nine main ethical issues were identified by thematic analysis; the most often discussed issues were data privacy and justice, followed by patient safety, autonomy, and cyber-security. Benevolence received the least attention, while notable ethical conundrums included bias, fairness, discrimination, algorithmic transparency, and data protection. This systematic review highlights the need for stronger regulatory frameworks, ethical guidelines, and governance structures to ensure responsible AI integration in healthcare, particularly in developing countries, and calls for further research to address existing gaps.",
    "doi": "10.21649/akemu.v31ispl2.5827",
    "url": "https://www.semanticscholar.org/paper/6fe7a7dec52c70a7b1f246998c7936b2dba20b07",
    "pdf_url": "",
    "venue": "Annals of King Edward Medical University",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972781"
  },
  {
    "source": "semantic_scholar",
    "source_id": "cee7a6ad22e907fe4e971902267a49b7cb13ed87",
    "title": "Artificial intelligence bias auditing \u2013 current approaches, challenges and lessons from practice",
    "authors": [
      "Sabina Lacmanovi\u0107",
      "M. \u0160kare"
    ],
    "year": 2025,
    "abstract": "\n\nThis study aims to explore current approaches, challenges and practical lessons in auditing artificial intelligence (AI) systems for bias, focusing on legal compliance audits in the USA and the European Union (EU). This emphasizes the need for standardized methodologies to ensure trustworthy AI systems that align with ethical and regulatory expectations.\n\n\n\nA qualitative analysis compared bias audit practices, including US bias audit report summaries under New York City\u2019s Local Law 144 and conformity assessments (CAs) required by the EU AI Act. Data was gathered from publicly available reports and compliance guidelines to identify key challenges and lessons.\n\n\n\nThe findings revealed that AI systems are susceptible to various biases stemming from data, algorithms and human oversight. Although valuable, legal compliance audits lack standardization, leading to inconsistent reporting practices. The EU\u2019s risk-based CA approach offers a comprehensive framework; however, its effectiveness depends on developing practical standards and consistent application.\n\n\n\nThis study is limited by the early implementation stage of regulatory frameworks, particularly the EU AI Act, and restricted access to comprehensive audit reports. A geographic focus on US and EU jurisdictions may limit the generalizability of the findings. Data availability constraints and the lack of standardized reporting frameworks affect the comparative analysis. Future research should focus on longitudinal studies of audit effectiveness, the development of standardized methodologies for intersectional bias assessment and the investigation of automated audit tools that can adapt to emerging AI technologies while maintaining practical feasibility across different organizational contexts.\n\n\n\nThis research underscores the necessity of adopting socio-technical perspectives and standardized methodologies in AI auditing. It provides actionable insights for firms, regulators and auditors into implementing robust governance and risk assessment practices to mitigate AI biases.\n\n\n\nEffective AI bias auditing practices ensure algorithmic fairness and prevent discriminatory outcomes in critical domains like employment, health care and financial services. The findings emphasize the need for enhanced stakeholder engagement and community representation in audit processes. Implementing robust auditing frameworks can help close socioeconomic gaps by identifying and mitigating biases disproportionately affecting marginalized groups. This research contributes to developing equitable AI systems that respect diversity and promote social justice while maintaining technological advancement.\n\n\n\nThis study contributes to the discourse on AI governance by comparing two regulatory approaches, bias audits and CAs and offers practical lessons from current implementation. It highlights the critical role of standardization in advancing trustworthy and ethical AI systems in the finance and accounting contexts.\n",
    "doi": "10.1108/raf-01-2025-0006",
    "url": "https://www.semanticscholar.org/paper/cee7a6ad22e907fe4e971902267a49b7cb13ed87",
    "pdf_url": "",
    "venue": "Review of Accounting and Finance",
    "citation_count": 12,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972782"
  },
  {
    "source": "semantic_scholar",
    "source_id": "29395b01f6dd2f39b16a230e3057693290e1c011",
    "title": "Effectiveness of Artificial Intelligence for Enhancing Decision-Making Process of Recruitment in HRM Process",
    "authors": [
      "S. Jafri",
      "Shitiz Upreti",
      "F. Saiyad",
      "Khadilkar Sujay Madhukar",
      "Vandana Mishra Chaturvedi",
      "Prakash Divakaran"
    ],
    "year": 2024,
    "abstract": "The integration of Artificial Intelligence (AI) into the recruitment process represents a significant advancement in Human Resource Management (HRM), aiming to optimize the efficiency and effectiveness of hiring practices. This paper explores the effectiveness of AI in improving decision-making processes within HRM, focusing on machine learning's role in streamlining candidate sourcing, enhancing candidate experience, boosting screening efficiency, optimizing interview processes, and improving onboarding experiences. By examining various studies and technological applications, it highlights the transformative potential of AI in recruitment, addressing challenges such as bias mitigation, engagement improvement, and access expansion to diverse talent pools. The research underscores the critical need for developing human-centric AI systems that prioritize transparency, privacy, accountability, fairness, and societal benefit. Through a comprehensive analysis, the paper advocates for the strategic implementation of AI in recruitment, emphasizing continuous monitoring, evaluation, and the necessary training for HR professionals to harness AI's full potential.",
    "doi": "10.1109/InC460750.2024.10649327",
    "url": "https://www.semanticscholar.org/paper/29395b01f6dd2f39b16a230e3057693290e1c011",
    "pdf_url": "",
    "venue": "2024 IEEE International Conference on Contemporary Computing and Communications (InC4)",
    "citation_count": 3,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972784"
  },
  {
    "source": "semantic_scholar",
    "source_id": "1e7bd33d0d1e76b71d6ad84487de97d2cafdbd4b",
    "title": "Ethical Implications of Artificial Intelligence in University Education",
    "authors": [
      "J. Mauti",
      "Dennis Song\u2019oro Ayieko"
    ],
    "year": 2025,
    "abstract": "The integration of Artificial Intelligence (AI) in university education has emerged as a transformative force, promising to revolutionize teaching, learning, and administration. However, its rapid adoption has sparked ethical concerns, particularly in resource-constrained settings. This theoretical article examines the ethical implications of specific AI applications, including plagiarism detection tools, adaptive learning systems, and automated grading technologies within Kenyan universities. It highlights three critical areas: data privacy and security, student-lecturer dynamics, and algorithmic bias. Drawing from Kantian deontological ethics, which emphasizes duty and the inherent morality of actions, the article argues for a balanced approach to AI integration that prioritizes ethical responsibilities over mere technological expedience. Data privacy and security remain pivotal concerns, as AI systems amass extensive personal data, often without robust safeguards, exposing students to potential exploitation and breaches. The article explores the intersection of AI and student-lecturer relationships, revealing how AI-driven tools can disrupt traditional mentorship roles central to African pedagogical traditions. Furthermore, the pervasive issue of algorithmic bias is critically analysed, emphasizing its potential to perpetuate educational inequities and marginalize underrepresented groups. The article highlights the absence of localized frameworks to address these ethical dilemmas in Kenyan universities. By anchoring its analysis in Kantian ethics, this article provides a compelling framework for navigating the ethical challenges posed by AI in education, ensuring that its implementation enhances equity, accountability, and human dignity. This work contributes to ongoing discourse on the responsible use of AI in education, offering actionable insights for policy, research, and practice",
    "doi": "10.37284/eajes.8.1.2583",
    "url": "https://www.semanticscholar.org/paper/1e7bd33d0d1e76b71d6ad84487de97d2cafdbd4b",
    "pdf_url": "",
    "venue": "East African Journal of Education Studies",
    "citation_count": 11,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972785"
  },
  {
    "source": "semantic_scholar",
    "source_id": "fea476bebf4de3b94356005978888724fba6f719",
    "title": "Ethical Challenges and Solutions in the Deployment of Artificial Intelligence Sys-tems",
    "authors": [
      "Subhash Chandra Bose Naripeddy",
      "Viswanadha Raju Thotakura"
    ],
    "year": 2025,
    "abstract": "The rapid advancement of Artificial Intelligence (AI) technologies has introduced transformative possibilities across sectors such as healthcare, finance, transportation, and education. However, the widespread deployment of AI systems also presents a range of ethical challenges, including algorithmic bias, data privacy concerns, lack of transparency, accountability issues, and the potential for job displacement. This article explores the core ethical dilemmas associated with AI adoption and provides a critical analysis of existing frameworks and policy measures aimed at addressing them. The study further examines practical solutions such as explainable AI (XAI), fairness-aware algorithms, regulatory oversight, and inclusive data practices. By integrating interdisciplinary perspectives from technology, law, and ethics, this paper aims to guide researchers, developers, and policymakers in fostering responsible and equitable AI deployment.",
    "doi": "10.60087/jaigs.v8i02.392",
    "url": "https://www.semanticscholar.org/paper/fea476bebf4de3b94356005978888724fba6f719",
    "pdf_url": "",
    "venue": "Journal of Artificial Intelligence General science (JAIGS) ISSN:3006-4023",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972787"
  },
  {
    "source": "semantic_scholar",
    "source_id": "50302d9eb975c1d7c76fccadf9c5490cf5f7ec1b",
    "title": "AI Ethics and Bias: Exploratory study on the ethical considerations and potential biases in ai and data-driven decision-making in banking, with a focus on fairness, transparency, and accountability",
    "authors": [
      "Thiruma Valavan"
    ],
    "year": 2023,
    "abstract": "The integration of Artificial Intelligence (AI) and data-driven decision-making in the banking industry has ushered in unprecedented opportunities for efficiency, risk assessment, and customer service. However, this rapid adoption of AI technology comes with its own set of ethical considerations and potential biases. This research paper delves into the intricate landscape of AI ethics and bias within the banking sector, with a central emphasis on fairness, transparency, and accountability. In sum, this paper contributes to the ongoing discourse on AI ethics and bias by providing valuable insights into the ethical considerations and potential biases inherent in AI and data-driven decision-making within the banking sector. It underscores the necessity of fairness, transparency, and accountability as guiding principles in the responsible integration of AI technology in banking, while also presenting future research directions for this evolving field.",
    "doi": "10.30574/wjarr.2023.20.2.2245",
    "url": "https://www.semanticscholar.org/paper/50302d9eb975c1d7c76fccadf9c5490cf5f7ec1b",
    "pdf_url": "https://wjarr.com/sites/default/files/WJARR-2023-2245.pdf",
    "venue": "World Journal of Advanced Research and Reviews",
    "citation_count": 9,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972788"
  },
  {
    "source": "semantic_scholar",
    "source_id": "592caab82055f97486e15afd4aa3d5b8793eec51",
    "title": "Framework for Fairness in Machine Learning Using Detecting and Mitigating Bias in AI Algorithms",
    "authors": [
      "Vincent Koc"
    ],
    "year": 2025,
    "abstract": "The importance of artificial intelligence (AI) and machine learning (ML) is on the rise as they are increasingly being used in critical decision-making in areas including healthcare, finance, and criminal justice. Their effectiveness, however, is often compromised as these systems replicate and even worsen pre-existing biases from historical data or from the designs of models, ultimately causing unfair and undesirable results. This paper describes a systematic analysis for bias detection and mitigation in machine learning algorithms. The approach includes preprocessing of data, algorithmic changes, and changes during post-processing for improvement of anticipated inequalities while keeping the performance of the model intact. The model's applicability has been illustrated in the areas of healthcare, finance, and criminal justice with case studies demonstrating the need for a trade-off between the model's accuracy and fairness. Besides, AI ethics are also advanced through transparency methods like SHAP and GradCAM, which strengthen trust in AI systems as ethical principles are ensured in the deployment of the AI systems. Though these achievements are significant, challenges on the issue of scaling, fairness definitions, and contextual variations still persist with regard to the application of AI for fairness promoting purposes, suggesting interdisciplinary directions as ways to mitigate the challenges.",
    "doi": "10.1109/ICBATS66542.2025.11258168",
    "url": "https://www.semanticscholar.org/paper/592caab82055f97486e15afd4aa3d5b8793eec51",
    "pdf_url": "",
    "venue": "2025 3rd International Conference on Business Analytics for Technology and Security (ICBATS)",
    "citation_count": 2,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972790"
  },
  {
    "source": "semantic_scholar",
    "source_id": "38fe59360f926697bdab2551b8a42e3d2591fd92",
    "title": "The Ethics of Artificial Intelligence in Legal Decision Making: An Empirical Study",
    "authors": [
      "Brij Mohan",
      "Dutta"
    ],
    "year": 2023,
    "abstract": "Artificial intelligence (AI) is increasingly being used in legal decision making, from predicting case outcomes to aiding in sentencing. However, the use of AI raises ethical concerns regarding fairness, accountability, and transparency. This paper explores these concerns in the context of AI in legal decision making. One ethical issue is the potential for AI to perpetuate existing biases in the legal system. AI algorithms are only as unbiased as the data they are trained on, and if the data reflects historical biases, the AI will perpetuate these biases in its decision making. Another issue is accountability, as it can be difficult to determine who is responsible for errors or bias in AI decision making.",
    "doi": "10.48047/pne.2018.55.1.38",
    "url": "https://www.semanticscholar.org/paper/38fe59360f926697bdab2551b8a42e3d2591fd92",
    "pdf_url": "http://psychologyandeducation.net/pae/index.php/pae/article/download/7788/6176",
    "venue": "psychologyandeducation",
    "citation_count": 6,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972791"
  },
  {
    "source": "semantic_scholar",
    "source_id": "4c101ad76e1f5801f07f5eb0639b5a074fb32594",
    "title": "Consumer bias against evaluations received by artificial intelligence: the mediation effect of lack of transparency anxiety",
    "authors": [
      "Alberto Lopez",
      "Ricardo Garza"
    ],
    "year": 2023,
    "abstract": "PurposeWill consumers accept artificial intelligence (AI) products that evaluate them? New consumer products offer AI evaluations. However, previous research has never investigated how consumers feel about being evaluated by AI instead of by a human. Furthermore, why do consumers experience being evaluated by an AI algorithm or by a human differently? This research aims to offer answers to these questions.Design/methodology/approachThree laboratory experiments were conducted. Experiments 1 and 2 test the main effect of evaluator (AI and human) and evaluations received (positive, neutral and negative) on fairness perception of the evaluation. Experiment 3 replicates previous findings and tests the mediation effect.FindingsBuilding on previous research on consumer biases and lack of transparency anxiety, the authors present converging evidence that consumers who got positive evaluations reported nonsignificant difference on the level of fairness perception on the evaluation regardless of the evaluator (human or AI). Contrarily, consumers who got negative evaluations reported lower fairness perception when the evaluation was given by AI. Further moderated mediation analysis showed that consumers who get a negative evaluation by AI experience higher levels of lack of transparency anxiety, which in turn is an underlying mechanism driving this effect.Originality/valueTo the best of the authors' knowledge, no previous research has investigated how consumers feel about being evaluated by AI instead of by a human. This consumer bias against AI evaluations is a phenomenon previously overlooked in the marketing literature, with many implications for the development and adoption of new AI products, as well as theoretical contributions to the nascent literature on consumer experience and AI.",
    "doi": "10.1108/jrim-07-2021-0192",
    "url": "https://www.semanticscholar.org/paper/4c101ad76e1f5801f07f5eb0639b5a074fb32594",
    "pdf_url": "",
    "venue": "Journal of Research in Interactive Marketing",
    "citation_count": 28,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972793"
  },
  {
    "source": "semantic_scholar",
    "source_id": "916fac0f8c3d8e04df7fa526bcf7b3cb56e798a3",
    "title": "Integrated Human-Centered Artificial Intelligence (HCAI) Performance & Development Model: Bridging the Policy-to-Practice Divide in Performance Management and Employee Development",
    "authors": [
      "Rosemary Uche Packson-Enajerho"
    ],
    "year": 2026,
    "abstract": "Purpose: Despite growing enthusiasm for Artificial Intelligence (AI) in Human Resource Management (HRM), a\nsignificant disconnect persists between the aspirational ideals of Human-Centered AI (HCAI) policies and their practical\napplication in organizational performance management and employee development systems. Traditional performance\nappraisal methods remain infrequent, biased, and disengaging, while AI-based systems risk dehumanization and\nalgorithmic bias if not ethically guided. This paper seeks to bridge this divide by proposing a comprehensive model that\nharmonizes data-driven analytics with empathetic, human-led management practices.\nObjective: The study aims to develop and present the Integrated Human-Centered Artificial Intelligence (HCAI)\nPerformance & Development Model, a conceptual framework designed to operationalize the principles of HCAI\nin performance evaluation and learning systems. The model seeks to transform performance management from a\ncompliance-oriented activity into a continuous, developmental, and ethically grounded process.\nMethodology: Employing a conceptual research design, this paper utilizes a theory-building approach based on the\nsystematic synthesis and thematic analysis of existing scholarship in AI analytics, continuous performance feedback,\nmotivational theory, and managerial coaching. The resulting model was constructed through iterative conceptual\nintegration, informed by both empirical studies and theoretical frameworks, and elaborated using descriptive narrative\nsupported by a visual schematic.\nFindings:The research introduces the Integrated HCAI Performance & Development Model, comprising four\ninterdependent components:\n(1) the AI-Powered Analytics Engine, which aggregates multidimensional performance data to identify trends, skill\ngaps, and development opportunities;\n(2) the Human-Centered Interpretation Layer, where managers apply empathetic judgment to contextualize AI-generated\ninsights;\n(3) the Continuous Feedback & Development Loop, which facilitates ongoing dialogue and co-created learning plans;\nand\n(4) the Strategic HR Policy Foundation, ensuring ethical integrity, transparency, and fairness. Collectively, these\ncomponents align organizational policies with human-centered, technology-enhanced practices. Conclusion: The model provides an actionable framework for integrating intelligent analytics and human empathy to\nenhance performance management and employee development. It underscores the pivotal role of strategic HR leadership\nin ethically governing AI systems and cultivating a culture of psychological safety and learning. Future research should\nfocus on empirical validation through longitudinal and quantitative studies to assess the model\u2019s impact on performance\noutcomes, motivation, and organizational adaptability.",
    "doi": "10.33140/amlai.07.01.01",
    "url": "https://www.semanticscholar.org/paper/916fac0f8c3d8e04df7fa526bcf7b3cb56e798a3",
    "pdf_url": "",
    "venue": "Advances in Machine Learning &amp; Artificial Intelligence",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972794"
  },
  {
    "source": "semantic_scholar",
    "source_id": "9e957bf5cace1f56c55ba704e09bdf39f3eb00b8",
    "title": "Bias in Artificial Intelligence Models in Financial Services",
    "authors": [
      "\u00c1ngel Pav\u00f3n P\u00e9rez"
    ],
    "year": 2022,
    "abstract": "Nowadays, artificial intelligence models are widely used in financial services, from credit scoring to fraud detection, having a direct impact on our daily lives. Although such models have been developed to try to reduce human bias and thus bring greater fairness to financial services decisions, studies have found that there is still significant discrimination by both face-to-face and algorithmic lenders. In fact, Apple has recently been investigated for gender discrimination in assigning a credit limit to its users, demonstrating that there may still be inherent biases in the development of such algorithms and models. Furthermore, biases in financial services models may not only lead to unfair discrimination but were also linked to health problems and recovery prospects. This project aims to analyse and identify the different types of biases found in AI models and data used in the financial services industry. We propose a method using data analysis and explainable models to explain how these biases emerge throughout the process of developing AI models as well as applying state-of-the-art bias dealing techniques to avoid and mitigate them. Finally, we propose how to evaluate these models according to the business objectives and consider possible trade-offs between different definitions of fairness. Thus, the main questions that this project will try to answer are as follows: - What are the current biases in credit risk and fraud detection models and how to identify them? - In what ways understanding how biases emerge from the data can help us in bias mitigation? - To what extent could credit risk and fraud detection models bias be mitigated, and what are the implications of those mitigation techniques? Answering these questions, we hope to create a pipeline for building these models by understanding the key points where bias can emerge and the appropriate methods to avoid it.",
    "doi": "10.1145/3514094.3539561",
    "url": "https://www.semanticscholar.org/paper/9e957bf5cace1f56c55ba704e09bdf39f3eb00b8",
    "pdf_url": "",
    "venue": "AAAI/ACM Conference on AI, Ethics, and Society",
    "citation_count": 4,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:53.972795"
  },
  {
    "source": "semantic_scholar",
    "source_id": "396e7b21c94feefeac8d480adcc3a85545886fa6",
    "title": "Navigating the Ethical Challenges of Artificial Intelligence in Higher Education: An Analysis of Seven Global AI Ethics Policies",
    "authors": [
      "Zouhaier Slimi",
      "Beatriz",
      "Villarejo Carballido"
    ],
    "year": 2023,
    "abstract": null,
    "doi": null,
    "url": "https://www.semanticscholar.org/paper/396e7b21c94feefeac8d480adcc3a85545886fa6",
    "pdf_url": "",
    "venue": "",
    "citation_count": 99,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972797"
  },
  {
    "source": "semantic_scholar",
    "source_id": "3141e9fb4534434bbc9e6765651c3e8fb55175fb",
    "title": "Trust in Artificial Intelligence: Comparing Trust Processes Between Human and Automated Trustees in Light of Unfair Bias",
    "authors": [
      "Markus Langer",
      "Cornelius J. K\u00f6nig",
      "C. Back",
      "Victoria Hemsing"
    ],
    "year": 2021,
    "abstract": "Automated systems based on artificial intelligence (AI) increasingly support decisions with ethical implications where decision makers need to trust these systems. However, insights regarding trust in automated systems predominantly stem from contexts where the main driver of trust is that systems produce accurate outputs (e.g., alarm systems for monitoring tasks). It remains unclear whether what we know about trust in automated systems translates to application contexts where ethical considerations (e.g., fairness) are crucial in trust development. In personnel selection, as a sample context where ethical considerations are important, we investigate trust processes in light of a trust violation relating to unfair bias and a trust repair intervention. Specifically, participants evaluated preselection outcomes (i.e., sets of preselected applicants) by either a human or an automated system across twelve selection tasks. We additionally varied information regarding imperfection of the human and automated system. In task rounds five through eight, the preselected applicants were predominantly male, thus constituting a trust violation due to potential unfair bias. Before task round nine, participants received an excuse for the biased preselection (i.e., a trust repair intervention). The results of the online study showed that participants have initially less trust in automated systems. Furthermore, the trust violation and the trust repair intervention had weaker effects for the automated system. Those effects were partly stronger when highlighting system imperfection. We conclude that insights from classical areas of automation only partially translate to the many emerging application contexts of such systems where ethical considerations are central to trust processes.",
    "doi": "10.1007/s10869-022-09829-9",
    "url": "https://www.semanticscholar.org/paper/3141e9fb4534434bbc9e6765651c3e8fb55175fb",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10869-022-09829-9.pdf",
    "venue": "Journal of business and psychology",
    "citation_count": 90,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:53.972799"
  },
  {
    "source": "semantic_scholar",
    "source_id": "c6d7f9c236c7546bba9bff47c9502f19845c3f51",
    "title": "Exploring The Ethical Governance of Artificial Intelligence from An Islamic Ethical Perspective",
    "authors": [
      "Uthman Mohammed Mustapha Kannike",
      "A. Fahm"
    ],
    "year": 2025,
    "abstract": "This study aims to examine the intersection of contemporary artificial intelligence (AI) with Islamic ethics, specifically exploring how foundational Islamic ethical principles can guide the integration and governance of AI technologies. Employing a theoretical and conceptual analysis method, the research investigates epistemological and theological considerations related to the application of machine learning algorithms in interpreting sacred Islamic texts. The core theoretical underpinnings guiding this analysis include Taw\u1e25\u012bd (the Oneness of God), which emphasizes harmony and ethical coherence; Maq\u0101\u1e63id al-Shar\u012b\u02bfah (Objectives of Islamic Law), focusing on safeguarding fundamental human interests such as faith, life, intellect, progeny, and wealth; Ihsan (Excellence and Benevolence), advocating for moral excellence in technological applications; and \u02bfAdl (Justice), which demands equity and fairness in technological advancements. The findings indicate that while AI holds significant promise for enhancing societal welfare, education, healthcare, and economic justice within Muslim communities, it presents profound ethical challenges, including algorithmic bias, privacy infringement, human autonomy erosion, and accountability concerns. The study highlights the necessity of rigorous ethical oversight grounded in Islamic ethics to navigate these challenges, proposing that AI applications adhere to principles of justice, transparency, and the preservation of human dignity and autonomy. The implications of this research extend beyond theoretical considerations, underscoring the importance of interdisciplinary collaboration between Islamic scholars, ethicists, policymakers, and technologists. Islamic ethical guidelines can enrich global conversations on AI ethics, ensuring technological innovations align with universally recognized moral standards while promoting social justice and human flourishing.",
    "doi": "10.22452/fiqh.vol22no1.5",
    "url": "https://www.semanticscholar.org/paper/c6d7f9c236c7546bba9bff47c9502f19845c3f51",
    "pdf_url": "",
    "venue": "Jurnal Fiqh",
    "citation_count": 8,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972800"
  },
  {
    "source": "semantic_scholar",
    "source_id": "9cae55bf7fff58e333489d4aa4994675b6f8aaff",
    "title": "Mitigating machine learning bias between high income and low\u2013middle income countries for enhanced model fairness and generalizability",
    "authors": [
      "Jenny Yang",
      "Lei A. Clifton",
      "N. Dung",
      "N. Phong",
      "L. Yen",
      "Doan Bui Xuan Thy",
      "A. Soltan",
      "Louise Thwaites",
      "David A. Clifton"
    ],
    "year": 2024,
    "abstract": "Collaborative efforts in artificial intelligence (AI) are increasingly common between high-income countries (HICs) and low- to middle-income countries (LMICs). Given the resource limitations often encountered by LMICs, collaboration becomes crucial for pooling resources, expertise, and knowledge. Despite the apparent advantages, ensuring the fairness and equity of these collaborative models is essential, especially considering the distinct differences between LMIC and HIC hospitals. In this study, we show that collaborative AI approaches can lead to divergent performance outcomes across HIC and LMIC settings, particularly in the presence of data imbalances. Through a real-world COVID-19 screening case study, we demonstrate that implementing algorithmic-level bias mitigation methods significantly improves outcome fairness between HIC and LMIC sites while maintaining high diagnostic sensitivity. We compare our results against previous benchmarks, utilizing datasets from four independent United Kingdom Hospitals and one Vietnamese hospital, representing HIC and LMIC settings, respectively.",
    "doi": "10.1038/s41598-024-64210-5",
    "url": "https://www.semanticscholar.org/paper/9cae55bf7fff58e333489d4aa4994675b6f8aaff",
    "pdf_url": "https://www.nature.com/articles/s41598-024-64210-5.pdf",
    "venue": "Scientific Reports",
    "citation_count": 23,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:53.972802"
  },
  {
    "source": "semantic_scholar",
    "source_id": "367977633e1f5f643335ad58cb2bfbcc6035e159",
    "title": "The Role of Artificial Intelligence in Improving Organizational Behavior: A Systematic Study",
    "authors": [
      "Reza Rostamzadeh",
      "Fereshteh Khajeh Alizadeh",
      "Shirvan Keivani",
      "Hero Isavi"
    ],
    "year": 2025,
    "abstract": "Artificial intelligence (AI) represents a transformative technology with the potential to profoundly influence organizational behavior (OB). It can enhance organizational performance and efficiency through mechanisms such as automation, resource optimization, and advanced data analysis. Nevertheless, the integration of AI within organizations presents various social and ethical dilemmas that could adversely impact fairness, privacy, and employee satisfaction. This research aims to develop a comprehensive framework that elucidates the role of AI in enhancing OB while also identifying the associated challenges and opportunities through a meta\u2010synthesis approach. A systematic review of the literature was conducted, focusing on studies that explore the intersection of AI and OB, employing a qualitative meta\u2010synthesis methodology. The data were sourced from scholarly articles published in esteemed scientific databases from 1995 to 2024. Ultimately, 18 articles specifically relevant to this subject were selected, and the data underwent analysis through open coding. This process yielded 231 distinct codes, which were subsequently organized and integrated based on their conceptual similarities into various dimensions and components. The findings showed that the impact of AI on OB includes five main dimensions: (1) automation, (2) innovation and organizational learning, (3) intelligent decision\u2010making, (4) organizational culture and human interactions, and (5) ethics and leadership. These dimensions include components such as data analysis, improved decision\u2010making, personalization, trust and information security, and adaptation to new technologies. Finally, a research model was presented focusing on these dimensions. In addition to the benefits related to productivity and improved decision\u2010making, the implementation of AI in organizations requires ethical and cultural considerations to maintain satisfaction and human interactions. Paying attention to algorithmic fairness and transparency in decision\u2010making can strengthen employee trust and facilitate the adoption of this technology. Therefore, organizations should manage the implementation of AI in a way that serves the development of OB and improved performance through training, developing ethical frameworks, and providing appropriate support.",
    "doi": "10.1155/hbe2/8094428",
    "url": "https://www.semanticscholar.org/paper/367977633e1f5f643335ad58cb2bfbcc6035e159",
    "pdf_url": "",
    "venue": "Human Behavior and Emerging Technologies",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972804"
  },
  {
    "source": "semantic_scholar",
    "source_id": "276f063120faf0a4016aca230d9f4514c01a0331",
    "title": "From Ethics to Execution: The Role of Academic Librarians in Artificial Intelligence (AI) Policy-Making at Colleges and Universities",
    "authors": [
      "Russell Michalak"
    ],
    "year": 2023,
    "abstract": "Abstract This paper highlights the importance of involving academic librarians in the development of ethical AI policies. The Academic Librarian Framework for Ethical AI Policy Development (ALF Framework) is introduced, recognizing librarians\u2019 unique skills and expertise. The paper discusses the benefits of their involvement, including expertise in information ethics and privacy, practical experience with AI tools, and collaborations. It also addresses challenges, such as limited awareness, institutional resistance, resource constraints, interdisciplinary collaboration, and evolving AI technologies, offering practical solutions. By actively involving librarians, institutions can develop comprehensive and ethical AI policies that prioritize social responsibility and respect for human rights.",
    "doi": "10.1080/01930826.2023.2262367",
    "url": "https://www.semanticscholar.org/paper/276f063120faf0a4016aca230d9f4514c01a0331",
    "pdf_url": "",
    "venue": "Journal of Library Administration",
    "citation_count": 31,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972805"
  },
  {
    "source": "semantic_scholar",
    "source_id": "9966837df189780dfd3e16bea7d1dc0b115d7af3",
    "title": "Exploring bias and fairness in artificial intelligence and machine learning algorithms",
    "authors": [
      "Utsab Khakurel",
      "Ghada Abdelmoumin",
      "Aakriti Bajracharya",
      "D. Rawat"
    ],
    "year": 2022,
    "abstract": "Machine learning algorithms are being widely used in different fields such as image recognition, speech recognition, traffic and weather prediction, recommendations, spam filtering, self-driving cars, stock market prediction, medical diagnosis, and more. The ability of machines to feed in years of data and predict the outcome has helped humans in unimaginable ways. Machine learning has automated half of human work requiring very little human intervention and saving time and energy. However, sometimes individuals end up paying the price and falling victim to the unfair and biased outcome of machine learning algorithms. Machines learn through data what they are provided with, but the data that machines learn from does not come free from human biases. Human biases based on race, sex, ethnicity, skin color, and other sensitive attributes are reflected in the dataset which, when fed to the machine, results in a similar biased prediction. The years of data represent the bias that has been present in society, and the machine learning model simply mimics the pattern. There has been constant research and experiments being done on how to prevent these biases from reflecting on the prediction. In this paper, we will investigate if there is any bias present in the benchmark Statlog \u201cAustralian Credit Approval\u201d dataset and take necessary measures to mitigate the bias present in the data. The paper shows how the AIF360 tool can identify and mitigate bias in the data and eventually in the learning algorithms.",
    "doi": "10.1117/12.2621282",
    "url": "https://www.semanticscholar.org/paper/9966837df189780dfd3e16bea7d1dc0b115d7af3",
    "pdf_url": "",
    "venue": "Defense + Commercial Sensing",
    "citation_count": 9,
    "fields_of_study": [
      "Engineering"
    ],
    "retrieved_at": "2026-02-02T16:57:53.972806"
  },
  {
    "source": "semantic_scholar",
    "source_id": "0f81aa2e0e21e4a673eeabd2ca4f4c41009a8688",
    "title": "Building Trustworthy Multimodal AI: A Review of Fairness, Transparency, and Ethics in Vision-Language Tasks",
    "authors": [
      "Mohammad Saleh",
      "Azadeh Tabatabaei"
    ],
    "year": 2025,
    "abstract": "Objective: This review explores the trustworthiness of multimodal artificial intelligence (AI) systems, specifically focusing on vision-language tasks. It addresses critical challenges related to fairness, transparency, and ethical implications in these systems, providing a comparative analysis of key tasks such as Visual Question Answering (VQA), image captioning, and visual dialogue. Background: Multimodal models, particularly vision-language models, enhance artificial intelligence (AI) capabilities by integrating visual and textual data, mimicking human learning processes. Despite significant advancements, the trustworthiness of these models remains a crucial concern, particularly as AI systems increasingly confront issues regarding fairness, transparency, and ethics. Methods: This review examines research conducted from 2017 to 2024 focusing on forenamed core vision-language tasks. It employs a comparative approach to analyze these tasks through the lens of trustworthiness, underlining fairness, explainability, and ethics. This study synthesizes findings from recent literature to identify trends, challenges, and state-of-the-art solutions. Results: Several key findings were highlighted. Transparency: Explainability of vision language tasks is important for user trust. Techniques, such as attention maps and gradient-based methods, have successfully addressed this issue. Fairness: Bias mitigation in VQA and visual dialogue systems is essential for ensuring unbiased outcomes across diverse demographic groups. Ethical Implications: Addressing biases in multilingual models and ensuring ethical data handling is critical for the responsible deployment of vision-language systems. Conclusion: This study underscores the importance of integrating fairness, transparency, and ethical considerations in developing vision-language models within a unified framework.",
    "doi": "10.22133/ijwr.2025.503147.1264",
    "url": "https://www.semanticscholar.org/paper/0f81aa2e0e21e4a673eeabd2ca4f4c41009a8688",
    "pdf_url": "",
    "venue": "arXiv.org",
    "citation_count": 6,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:53.972808"
  },
  {
    "source": "semantic_scholar",
    "source_id": "00c3e0b19febce5d401c5955482e95dadaf184c0",
    "title": "Ethical issues in the development of artificial intelligence: recognizing the risks",
    "authors": [
      "M. K. Kamila",
      "S. Jasrotia"
    ],
    "year": 2023,
    "abstract": "\nPurpose\nThis study aims to analyse the ethical implications associated with the development of artificial intelligence (AI) technologies and to examine the potential ethical ramifications of AI technologies.\n\n\nDesign/methodology/approach\nThis study undertakes a thorough examination of existing academic literature pertaining to the ethical considerations surrounding AI. Additionally, it conducts in-depth interviews with individuals to explore the potential benefits and drawbacks of AI technology operating as autonomous ethical agents. A total of 20 semi-structured interviews were conducted, and the data were transcribed using grounded theory methodology.\n\n\nFindings\nThe study asserts the importance of fostering an ethical environment in the progress of AI and suggests potential avenues for further investigation in the field of AI ethics. The study finds privacy and security, bias and fairness, trust and reliability, transparency and human\u2013AI interactions as major ethical concerns.\n\n\nResearch limitations/implications\nThe implications of the study are far-reaching and span across various domains, including policy development, design of AI systems, establishment of trust, education and training, public awareness and further research. Notwithstanding the potential biases inherent in purposive sampling, the constantly evolving landscape of AI ethics and the challenge of extrapolating findings to all AI applications and contexts, limitations may still manifest.\n\n\nOriginality/value\nThe novelty of the study is attributed to its comprehensive methodology, which encompasses a wide range of stakeholder perspectives on the ethical implications of AI in the corporate sector. The ultimate goal is to promote the development of AI systems that exhibit responsibility, transparency and accountability.\n",
    "doi": "10.1108/ijoes-05-2023-0107",
    "url": "https://www.semanticscholar.org/paper/00c3e0b19febce5d401c5955482e95dadaf184c0",
    "pdf_url": "",
    "venue": "International Journal of Ethics and Systems",
    "citation_count": 53,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972809"
  },
  {
    "source": "semantic_scholar",
    "source_id": "e37771b7ba03bfe4920d9d36095c0416a44718be",
    "title": "Relational accountability in AI-driven pharmaceutical practices: an ethics approach to bias, inequity and structural harm",
    "authors": [
      "Irfan Biswas"
    ],
    "year": 2025,
    "abstract": "The integration of artificial intelligence (AI) into pharmaceutical practices raises critical ethical concerns, including algorithmic bias, data commodification and global health inequities. While existing AI ethics frameworks emphasise transparency and fairness, they often overlook structural vulnerabilities tied to race, gender and socioeconomic status. This paper introduces relational accountability\u2014a feminist ethics framework\u2014to critique AI-driven pharmaceutical practices, arguing that corporate reliance on biased algorithms exacerbates inequalities by design. Through case studies of Pfizer-IBM Watson\u2019s immuno-oncology collaboration and Google DeepMind\u2019s National Health Service partnership, we demonstrate how AI entrenches disparities in drug pricing, access and development. We propose a causal pathway linking biased training data to inequitable health outcomes, supported by empirical evidence of AI-driven price discrimination and exclusionary clinical trial recruitment algorithms. Policy solutions, including algorithmic audits and equity-centred data governance, are advanced to realign AI with the ethical imperative. This work bridges feminist bioethics and AI governance, offering a novel lens to address structural harm in healthcare innovation.",
    "doi": "10.1136/jme-2025-110913",
    "url": "https://www.semanticscholar.org/paper/e37771b7ba03bfe4920d9d36095c0416a44718be",
    "pdf_url": "",
    "venue": "Journal of Medical Ethics",
    "citation_count": 2,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:53.972811"
  },
  {
    "source": "semantic_scholar",
    "source_id": "9669421802618ad91bc6546406787a4688a86237",
    "title": "Evaluating Responsible AI Adaption: Ethics, Bias Mitigation, and Governance",
    "authors": [
      "AbdulQuddus Mohammed",
      "G. Khalifa",
      "Fatima Hasan Alhammadi"
    ],
    "year": 2025,
    "abstract": "With the emergence of Artificial Intelligence (AI) within the organizational decision-making process, the issue of trust, transparency, and ethical governance has become even more pressing. In this paper, five dimensions are examined, namely explainability, bias, fairness, mitigation measures, and regulatory regimes, as key determinants of the adoption of responsible AI systems. The study based on a structured questionnaire that was sent to AI professionals working in the main industries of the United Arab Emirates (UAE) shows that explainability and fairness are the most striking factors predicting stakeholder trust and adoption. Detection of bias, mitigation practices and regulatory clarity also have major roles albeit less substantially. The results emphasize the necessity of employing the multi-dimensional governance strategy that would involve technical transparency, as well as ethical and legal protection. This research provides practical recommendations to policymakers, industry players, and developers who want to create reliable AI systems that would resonate with the societal norms and legal standards.",
    "doi": "10.1109/ITT69610.2025.11352926",
    "url": "https://www.semanticscholar.org/paper/9669421802618ad91bc6546406787a4688a86237",
    "pdf_url": "",
    "venue": "Information Technology Trends",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972812"
  },
  {
    "source": "semantic_scholar",
    "source_id": "99f88b690adccc73ec29b2e3cf351f25b77252e0",
    "title": "Ethical Considerations in Artificial Intelligence Interventions for Mental Health and Well-Being: Ensuring Responsible Implementation and Impact",
    "authors": [
      "H. R. Saeidnia",
      "Seyed Ghasem Hashemi Fotami",
      "Brady D. Lund",
      "Nasrin Ghiasi"
    ],
    "year": 2024,
    "abstract": "AI has the potential to revolutionize mental health services by providing personalized support and improving accessibility. However, it is crucial to address ethical concerns to ensure responsible and beneficial outcomes for individuals. This systematic review examines the ethical considerations surrounding the implementation and impact of artificial intelligence (AI) interventions in the field of mental health and well-being. To ensure a comprehensive analysis, we employed a structured search strategy across top academic databases, including PubMed, PsycINFO, Web of Science, and Scopus. The search scope encompassed articles published from 2014 to 2024, resulting in a review of 51 relevant articles. The review identifies 18 key ethical considerations, including 6 ethical considerations associated with using AI interventions in mental health and wellbeing (privacy and confidentiality, informed consent, bias and fairness, transparency and accountability, autonomy and human agency, and safety and efficacy); 5 ethical principles associated with the development and implementation of AI technologies in mental health settings to ensure responsible practice and positive outcomes (ethical framework, stakeholder engagement, ethical review, bias mitigation, and continuous evaluation and improvement); and 7 practices, guidelines, and recommendations for promoting the ethical use of AI in mental health interventions (adhere to ethical guidelines, ensure transparency, prioritize data privacy and security, mitigate bias and ensure fairness, involve stakeholders, conduct regular ethical reviews, and monitor and evaluate outcomes). This systematic review highlights the importance of ethical considerations in the responsible implementation and impact of AI interventions for mental health and well-being. By addressing privacy, bias, consent, transparency, human oversight, and continuous evaluation, we can ensure that AI interventions like chatbots and AI-enabled medical devices are developed and deployed in an ethically sound manner, respecting individual rights, promoting fairness, and maximizing benefits while minimizing potential harm.",
    "doi": "10.3390/socsci13070381",
    "url": "https://www.semanticscholar.org/paper/99f88b690adccc73ec29b2e3cf351f25b77252e0",
    "pdf_url": "https://doi.org/10.3390/socsci13070381",
    "venue": "The social science",
    "citation_count": 86,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972814"
  },
  {
    "source": "semantic_scholar",
    "source_id": "07265044885834daaf6f5a1c2f278d6719d67e66",
    "title": "The Ethics of Artificial Intelligence in Education: Practices, Challenges, and Debates",
    "authors": [
      "Joshua Rose"
    ],
    "year": 2024,
    "abstract": "The book discusses the field of Artificial Intelligence in Education (AIED). The authors believe that AIED is a diverse field that encompasses aspects of philosophy, learning and teaching, research, and engineering. They argue that AIED practitioners need to take a broader approach to define the purpose of the field and be more engaged with more general societal issues. The authors call for AIED systems to be designed with transparency, accountability, and user control, to ensure fairness and equity in education. They also suggest a shift away from the traditional model of AI design, which assumes a fixed objective, to a more collaborative model that allows for negotiation between humans and AI to set individual goals.",
    "doi": "10.1080/0361526x.2024.2427948",
    "url": "https://www.semanticscholar.org/paper/07265044885834daaf6f5a1c2f278d6719d67e66",
    "pdf_url": "",
    "venue": "The Serials librarian",
    "citation_count": 32,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972815"
  },
  {
    "source": "semantic_scholar",
    "source_id": "d0e6c65649636bfd03d760cddc27ef5f9466e5f2",
    "title": "The Role of Artificial Intelligence in HR operations Challenges & Opportunities",
    "authors": [],
    "year": 2025,
    "abstract": "The integration of Artificial Intelligence (AI) into Human Resource (HR) operations is transforming traditional workforce management by enhancing efficiency, accuracy, and strategic decision-making. This paper explores the evolving role of AI in core HR functions such as talent acquisition, employee engagement, performance evaluation, and workforce analytics. AI-driven tools offer significant opportunities, including automation of repetitive tasks, data-driven insights for decision-making, and personalized employee experiences. However, the implementation of AI also introduces notable challenges such as data privacy concerns, algorithmic bias, lack of transparency, and resistance to change within organizations. This study examines both the transformative potential and the limitations of AI in HR, emphasizing the need for ethical governance, robust data strategies, and a balanced human-AI collaboration. The findings suggest that while AI presents substantial opportunities for innovation in HR practices, its successful integration requires careful planning, stakeholder engagement, and ongoing evaluation to ensure equitable and effective outcomes.",
    "doi": "10.46632/jdaai/4/2/6",
    "url": "https://www.semanticscholar.org/paper/d0e6c65649636bfd03d760cddc27ef5f9466e5f2",
    "pdf_url": "",
    "venue": "REST Journal on Data Analytics and Artificial Intelligence",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972816"
  },
  {
    "source": "semantic_scholar",
    "source_id": "3707dd2839d594fc093cbae85826cbca0f3e1b50",
    "title": "Artificial Intelligence and Legal Decision-Making in the USA and Pakistan: A Critical Appreciation of Regulatory Frameworks",
    "authors": [
      "Bakht Munir",
      "Akhtar Ali Ansari",
      "Yasir Arafat"
    ],
    "year": 2025,
    "abstract": "Artificial Intelligence (AI) is substituting human decision-making in every aspect of life where law stands with no exception. New technological trends offer expeditious and cost-effective AI tools yet confront challenges such as privacy invasion, bias, fairness, and hallucinations, necessitating regulatory oversight. Like other countries, the USA and Pakistan have initiated AI solutions in their legal domain. A strong regulatory oversight is indispensable for its legitimacy and efficiency. Based on their functions and ethical considerations, AI tools in the legal profession face competing opinions. With qualitative research methodology, the research aims to explore how AI is transforming and reshaping the legal regime, focused on the comparative analysis of the USA and Pakistan. The research paper critically examines the legal frameworks and impacts of AI solutions and how both countries navigate the complexities of AI-based decision-making.",
    "doi": "10.31703/gfpr.2024(vii-iv).06",
    "url": "https://www.semanticscholar.org/paper/3707dd2839d594fc093cbae85826cbca0f3e1b50",
    "pdf_url": "",
    "venue": "Global Foreign Policies Review",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972818"
  },
  {
    "source": "semantic_scholar",
    "source_id": "943cce23c69df7a53e547b38a16dc7395c5841d2",
    "title": "Using Artificial Intelligence (AI) as a Toolfor Inclusive Leadership in the Digital Era:Challenges, Opportunities and Implications",
    "authors": [
      "Tasneem Alkhateeb"
    ],
    "year": 2025,
    "abstract": "This paper explores the use of Artificial Intelligence (AI) in higher education institutions to enhance inclusive leadership. Inclusive leadership must support the ethical integration of AI to ensure it serves all students. Artificial intelligence has the ability to solve problems in education, improve teaching and learning methodologies, and accelerate progress towards long-term improvement. However, leaders face five top challenges in the age of artificial intelligence. These include: adapting to technological disruption, ethical issues, improving collaboration between humans and AI, leading workforce change, sustaining human leadership and fostering a moral culture. Leaders must understand the technical aspects, practical applications, and strategic implications of AI, prioritize continuous education, and create an adaptive culture. They must navigate ethical concerns like privacy, bias, fairness, and accountability, establish ethical leadership strategies, and ensure transparency in AI decisions. The study recommends strategies, including creating explicit criteria for the use of artificial intelligence, promoting digital literacy and ensuring that the impact of its technologies on learning is continuously evaluated.",
    "doi": "10.64851/csi.v1i1.27",
    "url": "https://www.semanticscholar.org/paper/943cce23c69df7a53e547b38a16dc7395c5841d2",
    "pdf_url": "",
    "venue": "Crossroads of Social Inquiry",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972820"
  },
  {
    "source": "semantic_scholar",
    "source_id": "976deefce3ce6607d30827023a9d321052ef25b7",
    "title": "Human-in-the-loop: Explainable or accurate artificial intelligence by exploiting human bias?",
    "authors": [
      "L. Valtonen",
      "S. M\u00e4kinen"
    ],
    "year": 2022,
    "abstract": "Artificial intelligence (AI) is a major contributor in industry 4.0 and there exists a strong push for AI adoption across fields for both research and practice. However, AI has quite well elaborated risks for both business and general society. Hence, paying attention to avoiding hurried adoption of counter-productive practices is important. For both managerial and general social issues, the same solution is sometimes proposed: human-in-the-loop (HITL). However, HITL literature is contradictory: HITL is proposed to promote fairness, accountability, and transparency of AI, which are sometimes assumed to come at the cost of AI accuracy. Yet, HITL is also considered a way to improve accuracy. To make sense of the convoluted literature, we begin to explore qualitatively how explainability is constructed in a HITL process, and how method accuracy is affected as its function. To do this, we study qualitatively and quantitatively a multi-class classification task with multiple machine learning algorithms. We find that HITL can increase both accuracy and explainability, but not without deliberate effort to do so. The effort required to achieve both increased accuracy and explainability, requires an iterative HITL in which accuracy improvements are not continuous, but disrupted by unique and varying human biases shedding additional perspectives on the task at hand.",
    "doi": "10.1109/ICE/ITMC-IAMOT55089.2022.10033225",
    "url": "https://www.semanticscholar.org/paper/976deefce3ce6607d30827023a9d321052ef25b7",
    "pdf_url": "",
    "venue": "2022 IEEE 28th International Conference on Engineering, Technology and Innovation (ICE/ITMC) & 31st International Association For Management of Technology (IAMOT) Joint Conference",
    "citation_count": 3,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972821"
  },
  {
    "source": "semantic_scholar",
    "source_id": "b5c7f6016afdd03d41f5c0e4f8679bd4c46a3871",
    "title": "Towards a Human-Centred Artificial Intelligence Maturity Model",
    "authors": [
      "Mia Hartikainen",
      "Kaisa V\u00e4\u00e4n\u00e4nen",
      "Thomas Olsson"
    ],
    "year": 2023,
    "abstract": "Artificial intelligence (AI) is becoming a central building block of computational systems. Following the long traditions of human-centered design, Human-Centered AI (HCAI) emphasises the importance of putting humans and various societal considerations in the centre of the development. However, the question is: how to realise HCAI when designing systems that utilise novel computational tools and require consideration of increasingly broad set of requirements, spanning from fairness and transparency to accountability and ethics? The purpose of our study is to support the AI development practices in companies in order for the humans to have AI solutions that are efficient, trustworthy, and safe. To this end, we propose a maturity model for HCAI (HCAI-MM). In this paper we present the first phase of the model development, in which the central building blocks of HCAI are specified and initial company requirements for the model's structure and content are evaluated with four AI developers.",
    "doi": "10.1145/3544549.3585752",
    "url": "https://www.semanticscholar.org/paper/b5c7f6016afdd03d41f5c0e4f8679bd4c46a3871",
    "pdf_url": "https://doi.org/10.1145/3544549.3585752",
    "venue": "CHI Extended Abstracts",
    "citation_count": 17,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:53.972823"
  },
  {
    "source": "semantic_scholar",
    "source_id": "419d0d4b9c407e6c7bca21af84c33e177530ffbe",
    "title": "The accuracy-bias trade-offs in AI text detection tools and their impact on fairness in scholarly publication",
    "authors": [
      "Ahmad R. Pratama"
    ],
    "year": 2025,
    "abstract": "Artificial intelligence (AI) text detection tools are considered a means of preserving the integrity of scholarly publication by identifying whether a text is written by humans or generated by AI. This study evaluates three popular tools (GPTZero, ZeroGPT, and DetectGPT) through two experiments: first, distinguishing human-written abstracts from those generated by ChatGPT o1 and Gemini 2.0 Pro Experimental; second, evaluating AI-assisted abstracts where the original text has been enhanced by these large language models (LLMs) to improve readability. Results reveal notable trade-offs in accuracy and bias, disproportionately affecting non-native speakers and certain disciplines. This study highlights the limitations of detection-focused approaches and advocates a shift toward ethical, responsible, and transparent use of LLMs in scholarly publication.",
    "doi": "10.7717/peerj-cs.2953",
    "url": "https://www.semanticscholar.org/paper/419d0d4b9c407e6c7bca21af84c33e177530ffbe",
    "pdf_url": "",
    "venue": "PeerJ Computer Science",
    "citation_count": 5,
    "fields_of_study": [
      "Computer Science",
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:53.972824"
  },
  {
    "source": "semantic_scholar",
    "source_id": "e5dd5fa615f8cf1e21ed5d6f8656513437f465e1",
    "title": "Artificial Intelligence for Promoting Equity, Diversity, and Inclusion",
    "authors": [
      "Mazdak Zamani",
      "Ali Motamedi",
      "Sasan Karamizadeh",
      "T. Khodadadi",
      "M. Alizadeh",
      "Saman Shojae Chaeikar"
    ],
    "year": 2025,
    "abstract": "In the pursuit of a more inclusive, equitable, and diverse workplace, many organizations are turning to artificial intelligence as a transformative approach to enhance hiring practices. By automating resume evaluations, AI systems can reduce the impact of human biases that often lead to the underrepresentation of certain demographic groups. However, the use of AI in recruitment presents its own set of challenges, including the potential for biased algorithms, lack of transparency, and over-reliance on automation. This paper explores the benefits, challenges, and limitations of using AI to assess resumes, with a particular focus on how AI can enhance EDI in hiring practices. Through the review of various AI tools and case studies, the paper examines how AI can be leveraged to promote fairness, consistency, and access to diverse talent pools. Additionally, the paper discusses solutions to mitigate the risks of bias, such as diversifying training datasets, increasing transparency through explainable AI models, and ensuring human oversight in decision-making. Ultimately, this paper provides recommendations for organizations seeking to integrate AI into their recruitment process while ensuring that it fosters an inclusive and equitable hiring environment.",
    "doi": "10.1109/ACDSA65407.2025.11166379",
    "url": "https://www.semanticscholar.org/paper/e5dd5fa615f8cf1e21ed5d6f8656513437f465e1",
    "pdf_url": "",
    "venue": "2025 International Conference on Artificial Intelligence, Computer, Data Sciences and Applications (ACDSA)",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972826"
  },
  {
    "source": "semantic_scholar",
    "source_id": "8ac78c62df01109719d88d23706d857c71923b58",
    "title": "The potential and risks of artificial intelligence in promoting personalized learning",
    "authors": [
      "Jiang Qiang"
    ],
    "year": 2025,
    "abstract": ": As a significant advancement in the field of technology, Artificial Intelligence (AI) has achieved automation of specific tasks by simulating and enhancing human cognitive functions. In the field of education, AI has notably promoted the development of personalized learning. By analyzing learning data, AI can identify students' learning patterns and provide targeted academic guidance, enabling real-time feedback and dynamic adjustments to learning content. Additionally, AI offers personalized learning resources and auxiliary tools to enhance motivation and efficiency in learning. However, the application of AI in personalized learning also faces risks such as privacy and data security, algorithmic bias, and educational equity. To address these challenges, strict data protection measures must be taken to ensure algorithmic fairness and to promote the equitable distribution of educational resources.",
    "doi": "10.23977/jaip.2025.080112",
    "url": "https://www.semanticscholar.org/paper/8ac78c62df01109719d88d23706d857c71923b58",
    "pdf_url": "",
    "venue": "Journal of Artificial Intelligence Practice",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972827"
  },
  {
    "source": "semantic_scholar",
    "source_id": "62701f25325275973371486ec5f9972e64133f51",
    "title": "Leverage Generative AI for human resource management: integrated risk analysis approach",
    "authors": [
      "Ying Jiang",
      "Ziming Cai",
      "Xiaojun Wang"
    ],
    "year": 2025,
    "abstract": null,
    "doi": "10.1080/09585192.2025.2544972",
    "url": "https://www.semanticscholar.org/paper/62701f25325275973371486ec5f9972e64133f51",
    "pdf_url": "",
    "venue": "",
    "citation_count": 3,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972828"
  },
  {
    "source": "semantic_scholar",
    "source_id": "c1986252349bb67d8a769b065391c273e42c26f3",
    "title": "Explanations as Bias Detectors: A Critical Study of Local Post-hoc XAI Methods for Fairness Exploration",
    "authors": [
      "Vasiliki Papanikou",
      "Danae Pla Karidi",
      "E. Pitoura",
      "Emmanouil Panagiotou",
      "E. Ntoutsi"
    ],
    "year": 2025,
    "abstract": "As Artificial Intelligence (AI) is increasingly used in areas that significantly impact human lives, concerns about fairness and transparency have grown, especially regarding their impact on protected groups. Recently, the intersection of explainability and fairness has emerged as an important area to promote responsible AI systems. This paper explores how explainability methods can be leveraged to detect and interpret unfairness. We propose a pipeline that integrates local post-hoc explanation methods to derive fairness-related insights. During the pipeline design, we identify and address critical questions arising from the use of explanations as bias detectors such as the relationship between distributive and procedural fairness, the effect of removing the protected attribute, the consistency and quality of results across different explanation methods, the impact of various aggregation strategies of local explanations on group fairness evaluations, and the overall trustworthiness of explanations as bias detectors. Our results show the potential of explanation methods used for fairness while highlighting the need to carefully consider the aforementioned critical aspects.",
    "doi": "10.48550/arXiv.2505.00802",
    "url": "https://www.semanticscholar.org/paper/c1986252349bb67d8a769b065391c273e42c26f3",
    "pdf_url": "",
    "venue": "arXiv.org",
    "citation_count": 1,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:53.972830"
  },
  {
    "source": "semantic_scholar",
    "source_id": "b5a2ece8d75985eaedead63b6508bddf8ff6a723",
    "title": "Bias in Adjudication and the Promise of AI: Challenges to Procedural Fairness",
    "authors": [
      "Giovana Lopes"
    ],
    "year": 2025,
    "abstract": "Empirical research demonstrates that judges are prone to cognitive and social biases, both of which can reduce the accuracy of judgements and introduce extra-legal influences on judicial decisions. While these findings raise the important question of how to mitigate the effects of judicial bias, they have also been used to argue in favour of incorporating artificial intelligence (AI) into adjudication, either as decision aids or, in a more extreme way, to fully automate judicial tasks. The argument goes as follows: if human judgement is susceptible to biases, and if the human psyche is also inscrutable, would it not be better to replace it with AI? After all, AI promises greater accuracy and consistency and can replace biased human decisions with objective automated ones. However, the use of AI by courts requires careful deliberation, as it potentially introduces new challenges, particularly concerning procedural fairness. This article seeks to explore how the use of AI in the administration of justice can challenge some of the foundational elements of the right to a fair trial, as enshrined in Article 6 of the European Convention on Human Rights (ECHR). This analysis is conducted through the theoretical framework of procedural justice, arguing that the use of AI for judicial decision-making can negatively impact perceptions of procedural fairness in ways that traditional human adjudication does not. It therefore seeks to debunk the narrative that, at least where bias is concerned, human and artificial decision-making are equally problematic.",
    "doi": "10.5204/lthj.3812",
    "url": "https://www.semanticscholar.org/paper/b5a2ece8d75985eaedead63b6508bddf8ff6a723",
    "pdf_url": "",
    "venue": "Law, Technology and Humans",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972831"
  },
  {
    "source": "semantic_scholar",
    "source_id": "8b987b810a5d0de7bb92abd21a039fcfc87787ec",
    "title": "Bias and Fairness in Automated Loan Approvals: A Systematic Review of Machine Learning Approaches",
    "authors": [
      "Suraiyo Raziyeva",
      "Meraryslan Meraliyev"
    ],
    "year": 2025,
    "abstract": "\n\n\nArtificial intelligence (AI) is increasingly transforming credit approval processes, enabling financial institutions to assess risk more efficiently and at greater scale. As these systems become more embedded in lending decisions, concerns around fairness, bias, and accountability have grown significantly. Many of these concerns stem from the use of historical data, proxy variables, and model optimization choices that can unintentionally reinforce existing social and economic inequalities. This work presents a systematic overview of the types and sources of bias in AI - driven loan approval systems and critically examines how machine learning techniques attempt to address them. It also highlights emerging solutions, including explainable AI, federated learning, human-in-the-loop frameworks, and intersectional fairness approaches. Despite ongoing advancements, unresolved challenges remain - particularly the need for dynamic fairness monitoring and for addressing intersectional biases affecting individuals from multiple marginalized groups. To bridge these gaps, the paper emphasizes the importance of interdisciplinary collaboration among AI developers, regulatory bodies, and social scientists. It advocates embedding fairness as a core design principle in the development and deployment of future AI systems. Overall, this study contributes to the growing effort to develop more transparent, inclusive, and socially responsible financial technologies.\n\n\n",
    "doi": "10.47344/jbzmnx25",
    "url": "https://www.semanticscholar.org/paper/8b987b810a5d0de7bb92abd21a039fcfc87787ec",
    "pdf_url": "",
    "venue": "Journal of Emerging Technologies and Computing",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972833"
  },
  {
    "source": "semantic_scholar",
    "source_id": "b756c2e60621e813616554299d7493c038e519a2",
    "title": "AI in human resource management",
    "authors": [
      "Janine Berg",
      "Hannah Johnston"
    ],
    "year": 2025,
    "abstract": "The rapid integration of artificial intelligence (AI) into Human Resource Management (HRM) is transforming how organizations recruit, manage, and evaluate their workforces. While proponents champion AI as a means to enhance efficiency, reduce bias, and align HR practices with strategic business goals, this paper argues that such optimism is misplaced. Drawing on a critical review of AI's application across four core HRM functions\u2014recruitment, compensation, scheduling, and performance management\u2014this paper identifies significant risks and limitations arising from the fundamental structure of AI systems. Central to the analysis is a three-parameter framework for assessing AI tools: their objective, the data they rely upon, and how they are programmed. The paper shows that across HR functions, AI systems frequently operationalize reductive or poorly aligned objectives, rely on low-quality or biased data, and are programmed in non-transparent ways that undermine their usefulness. These structural shortcomings not only undermine the effectiveness of AI systems but also introduce legal, ethical, and practical risks for firms and their workers.",
    "doi": "10.54394/nmsh7611",
    "url": "https://www.semanticscholar.org/paper/b756c2e60621e813616554299d7493c038e519a2",
    "pdf_url": "",
    "venue": "",
    "citation_count": 2,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972834"
  },
  {
    "source": "semantic_scholar",
    "source_id": "df0676b6fb13abd16657e321350675f318b9175e",
    "title": "Ethical and Legal Implications of AI in Human Resource Management",
    "authors": [
      "Hamza Ghazanfar",
      "Ayaz Ul Haq"
    ],
    "year": 2025,
    "abstract": "The rapid-fire integration of Artificial Intelligence (AI) in Human Resource Management (HRM) has steered in transformative edge in reclamation, gift accession, performance evaluation, and hand engagement. Still, this progress isn't without substantial ethical and legal enterprises. This narrative review synthesizes findings from six crucial studies including abstract analyses, empirical checks, and legal reviews to critically examine the pressing counteraccusations of AI deployment in HRM across global and indigenous surrounds.\u00a0\u00a0 The review reveals a strong agreement around several core challenges warrant of translucency and explain ability in AI- driven opinions, the perpetuation of algorithmic bias, violations of data sequestration rights, and unclear legal responsibility in cases of demarcation or detriment. Studies similar as Harper & Millard (2023) and Du (2024) highlight crunches in current employment laws, particularly in regulating automated decision- timber, while Cheong (2024) underscores the ethical pitfalls posed by opaque AI systems and calls for integrated governance fabrics. Empirical substantiation from Khan et al. (2023) and Nawaz (2023) further illustrates how AI relinquishment in reclamation can affect in perceived unfairness, especially when stakeholders are barred from the design process or when systems are trained on prejudiced data. In developing surrounds like Nigeria and Pakistan, structural constraints including limited structure, low AI knowledge, and weak nonsupervisory oversight \u2014 emulsion these pitfalls, as reported by Elenwo (2025) and Khan et al. (2023).\u00a0\u00a0 The methodology across these studies is varied, ranging from quantitative checks and retrogression analysis to legal converse and thematic conflation. Despite this diversity, a common limitation is apparent a lack of longitudinal, relative, and hand- centered exploration, which impedes a holistic understanding of AI\u2019s long- term impact on pool rights and organizational equity.\u00a0\u00a0 In response, this review advocates for a multifaceted approach that combines legal modernization, ethical checkups, stakeholder participation, and capacity- structure measures. It proposes that effective AI governance in HRM must be both environment-sensitive and rights- driven \u2014 balancing invention with responsibility, and robotization with inclusivity.\u00a0\u00a0 This study contributes to the evolving converse on Responsible AI in HR by relating nonsupervisory gaps, ethical eyeless spots, and stylish practices for indifferent integration. It aims to support HR leaders, policymakers, and technologists in designing AI systems that aren't only effective, but also fair, transparent, and aligned with transnational labor and mortal rights norms.",
    "doi": "10.56976/jsom.v4i2.254",
    "url": "https://www.semanticscholar.org/paper/df0676b6fb13abd16657e321350675f318b9175e",
    "pdf_url": "",
    "venue": "Journal of Social &amp; Organizational Matters",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972836"
  },
  {
    "source": "semantic_scholar",
    "source_id": "d94a928e897f2f3016f7200c20906dac202f4a6e",
    "title": "EXPLORING THE ROLE OF ARTIFICIAL INTELLIGENCE IN TRANSFORMING HR PRACTICES",
    "authors": [
      "Md. Masudul",
      "Haque Bhuiyan",
      "Kripa Nath",
      "Palash Saha",
      "Pankaj Kumar Sarker",
      "Md. Tanjil Biswas"
    ],
    "year": 2025,
    "abstract": "This study explores the role of Artificial Intelligence (AI) in transforming Human Resource (HR) practices, focusing on its impact on recruitment, employee engagement, performance management, and overall HR efficiency. Through a survey of 300 HR professionals, managers, and employees, the research evaluates the benefits and challenges of AI adoption in HR functions. The findings reveal that AI enhances efficiency, reduces biases in recruitment and performance evaluations, and improves employee satisfaction through personalized experiences. However, challenges such as high implementation costs, concerns about algorithmic bias, data privacy issues, and resistance to change were identified as barriers to successful AI adoption. The study concludes that while AI offers significant advantages for HR practices, organizations must address these challenges through training, transparency, and careful implementation to fully leverage AI's potential.",
    "doi": "10.35409/ijbmer.2025.3646",
    "url": "https://www.semanticscholar.org/paper/d94a928e897f2f3016f7200c20906dac202f4a6e",
    "pdf_url": "https://doi.org/10.35409/ijbmer.2025.3646",
    "venue": "International Journal of Business Management and Economic Review",
    "citation_count": 5,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972837"
  },
  {
    "source": "semantic_scholar",
    "source_id": "3695a2fee84fb634764c06b7e2f3ce78092353dd",
    "title": "Algorithmic Bias and Data Justice: ethical challenges in Artificial Intelligence Systems",
    "authors": [
      "Javier Gonz\u00e1lez-Argote",
      "E. Maldonado",
      "Karina Maldonado"
    ],
    "year": 2025,
    "abstract": "This article examines the critical ethical challenges posed by algorithmic bias in artificial intelligence (AI) systems, focusing on its implications for social justice and data equity. Through a systematic review of case studies and theoretical frameworks, we analyze how biased datasets and algorithmic designs perpetuate structural inequalities, particularly affecting marginalized communities. The study highlights key examples, such as gender and racial biases in facial recognition and hiring algorithms, while exploring mitigation strategies rooted in data justice principles. Additionally, we evaluate regulatory responses, including the European Union's AI Act, which proposes a risk-based governance framework. The findings underscore the urgent need for interdisciplinary approaches to develop fairer AI systems that align with ethical standards and human rights.",
    "doi": "10.56294/ai2025159",
    "url": "https://www.semanticscholar.org/paper/3695a2fee84fb634764c06b7e2f3ce78092353dd",
    "pdf_url": "",
    "venue": "EthAIca",
    "citation_count": 4,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972839"
  },
  {
    "source": "semantic_scholar",
    "source_id": "686a744eb2bca0e7645e0f1953a09418c4f76d73",
    "title": "The rise of AI in human resource management: A systematic review of task automation through PRISMA",
    "authors": [
      "Kawthar Bouzerda",
      "Selimane Hani",
      "Hasnae Rahmani",
      "Ali Hebaz",
      "Abdessamad Dibi",
      "Hasna Mharzi"
    ],
    "year": 2025,
    "abstract": "Objective:\u00a0This study synthesizes current evidence on the role of Artificial Intelligence (AI)\u00a0and, where relevant, Open Science (OS) practices\u00a0in enhancing Human Resource Management (HRM) performance. It focuses on recruitment processes, ethical considerations, and employee participation. Methodology:\u00a0A systematic literature review was conducted in Scopus covering the period 2019\u20132024, following PRISMA guidelines. The initial search yielded 1486 records. After de-duplication and screening using Rayyan, 66 studies (\u2248 4.4%) met the inclusion criteria, which targeted peer-reviewed works addressing AI-supported HR decision-making. A combined content and bibliometric analysis was performed in R (Bibliometrix) to identify thematic patterns and conceptual structures. Results:\u00a0Analysis revealed four thematic clusters: 1) Implementation and employee participation emphasizing human-in-the-loop approaches and effective change management; 2) ethical challenges including algorithmic bias, transparency gaps, and data privacy risks; 3) data-driven decision-making delivering higher accuracy, fewer errors, and personalized recruitment and performance assessment; 4) operational efficiency enabling faster workflows and reduced administrative workloads. AI tools consistently improved selection quality, while OS practices promoted transparency and knowledge sharing. Implications:\u00a0The successful adoption of AI in HRM requires employee engagement, strong ethical safeguards, and transparent data governance. Future research should address the long-term cultural, organizational, and well-being impacts of AI\u00a0integration, as well as its sustainability.",
    "doi": "10.18282/hrms4595",
    "url": "https://www.semanticscholar.org/paper/686a744eb2bca0e7645e0f1953a09418c4f76d73",
    "pdf_url": "",
    "venue": "Human Resources Management and Services",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972846"
  },
  {
    "source": "semantic_scholar",
    "source_id": "375228b06b8bce65db6b8e7324694392a0748279",
    "title": "Implication of AI in Transforming Human Resource Development",
    "authors": [
      "Subhrodipto Basu Choudhury",
      "Soma Garani",
      "S. Majumder"
    ],
    "year": 2025,
    "abstract": "This paper presents a systematic conceptual review of the application of Artificial Intelligence (AI) in Human Resource Management (HRM). Human resources form the backbone of organizations, and the integration of AI technologies is transforming key HR functions such as recruitment, training and development, performance management, compensation, grievance redressal, and retirement planning. This study synthesizes peer-reviewed literature published between 2018 and 2024 drawn from databases such as Scopus, Web of Science, Google Scholar, and major academic publishers. The review identifies how AI enhances efficiency, reduces bias, supports strategic decision-making, and improves employee experience, while emphasizing that human judgment remains essential in ethical and relational domains.",
    "doi": "10.63015/3ai-2482.2.5",
    "url": "https://www.semanticscholar.org/paper/375228b06b8bce65db6b8e7324694392a0748279",
    "pdf_url": "",
    "venue": "Current Natural Sciences and Engineering",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972847"
  },
  {
    "source": "semantic_scholar",
    "source_id": "8b16d313557ad698550c3a793b7faac8e82bb513",
    "title": "Advantages and ethics of artificial intelligence in plastic and reconstructive surgery",
    "authors": [
      "Dylan Treger",
      "Griffin Harris",
      "S. Thaller"
    ],
    "year": 2025,
    "abstract": "As artificial intelligence (AI) technologies evolve in sophistication, they offer the potential to benefit various aspects of plastic and reconstructive surgery practice. From enhancing surgical precision within the operating room to streamlining administrative tasks and supporting the diagnosis and treatment of patients, AI may grow into an invaluable tool that redefines standards of care within plastic surgery. Given the nascent and largely theoretical role of AI in plastic surgery, numerous questions arise regarding its safety, actual utility, ethical considerations, and policies needed to regulate its use. This manuscript aims to provide commentary on AI in healthcare and to discuss an alternative viewpoint of its use in plastic surgery. Americans remain hesitant about healthcare providers leveraging AI in their care. Ongoing scrutiny is required to protect patients from unintended sequelae, safeguard their privacy, mitigate bias, and reduce harm. Early legislation by the United States federal government has aimed to define a role for AI in healthcare, yet more explicit guidance is required. Uncertainty in medico-legal implications begs the question of where liability would fall if AI use causes adverse outcomes. If applied appropriately, AI may ultimately improve patient outcomes and satisfaction with their plastic surgery care. With less energy dedicated toward automatable tasks and tools that push the envelope of human performance, plastic surgeons may be better equipped to care for their patients. We advocate for a cautiously optimistic approach to AI\u2019s incorporation within plastic and reconstructive surgery.",
    "doi": "10.20517/ais.2024.66",
    "url": "https://www.semanticscholar.org/paper/8b16d313557ad698550c3a793b7faac8e82bb513",
    "pdf_url": "https://doi.org/10.20517/ais.2024.66",
    "venue": "Artificial Intelligence Surgery",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972849"
  },
  {
    "source": "semantic_scholar",
    "source_id": "e7cdb9d070cd74944f91a99cf178174f6d2ac2b0",
    "title": "Artificial intelligence (AI) in health systems: introducing a \u2018Do Good\u2019 approach",
    "authors": [
      "Elsa Papadopoulou",
      "T. Exarchos",
      "Sasa Jenko",
      "Katarina Krepelkova",
      "Joana Namorado"
    ],
    "year": 2025,
    "abstract": null,
    "doi": "10.1007/s43681-025-00757-x",
    "url": "https://www.semanticscholar.org/paper/e7cdb9d070cd74944f91a99cf178174f6d2ac2b0",
    "pdf_url": "",
    "venue": "AI and Ethics",
    "citation_count": 1,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:53.972850"
  },
  {
    "source": "semantic_scholar",
    "source_id": "c52172d98826c2f1196c5aecd537694d2d773838",
    "title": "Ethics in the Age of Artificial Intelligence",
    "authors": [
      "B\u00fc\u015fra Tural",
      "Zeynep \u00d6rpek",
      "Zeynep Destan"
    ],
    "year": 2025,
    "abstract": "Artificial Intelligence (AI) technologies are transforming many sectors by causing radical changes in the modern world. AI solutions that accelerate processes, increase efficiency, and improve decision-making mechanisms in areas such as health, finance, education, and transportation also bring with them important discussions in terms of ethics, security, and social harmony. In this context, the need for AI applications to be developed in a reliable, fair, and transparent manner is becoming increasingly important.The concept of \u201cResponsible AI\u201d aims to design and implement AI in a way that respects human rights, is free from discrimination, is accountable, and is compatible with social values. The neutrality of algorithms, the protection of personal data, and the risk that AI applications may produce biased or erroneous outputs make it necessary to manage this technology in line with ethical principles. Ensuring public trust and increasing social acceptance of AI is a critical requirement for sustainable and successful innovation processes. In this context, various control mechanisms have been developed to ensure the security of AI applications and their compliance with ethical rules.This study examines the necessity of a responsible AI approach, how it should be shaped within the framework of ethical principles, and the security mechanisms used in this context. Considering the long-term societal impacts of AI, the importance of protecting individual rights as well as creating a reliable and sustainable framework for companies and public institutions is emphasized. In particular, the examination of security tools such as Llama Guard is examined, and how they play a critical role in the process of responsible management of AI.",
    "doi": "10.1109/AICCONF64766.2025.11064304",
    "url": "https://www.semanticscholar.org/paper/c52172d98826c2f1196c5aecd537694d2d773838",
    "pdf_url": "",
    "venue": "2025 3rd Cognitive Models and Artificial Intelligence Conference (AICCONF)",
    "citation_count": 3,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:53.972852"
  },
  {
    "source": "semantic_scholar",
    "source_id": "405960c1a6407f0d4537ac33a737574f66884c52",
    "title": "Artificial Intelligence in Talent Acquisition: A Paradigm Shift in HRM Practices",
    "authors": [
      "Chirag Harchandani"
    ],
    "year": 2025,
    "abstract": "The birth of artificial intelligence was between 1950-1956 but AI in HRM practices was used first in the 2000s. This rapid advancement of AI has significantly transformed Human Resource Management Practices. AI-based systems currently help HR automate a large segment of repetitive tasks in processes such as talent screening, hiring, engaging, re-engaging, employee relations, onboarding, etc, which used to be a long and hectic task before the introduction of automated tools. Nevertheless, these automated practices raise ethical concerns about bias, transparency, and how AI may undermine human judgment. The focus of this paper is to discuss and analyze the present scenario of AI in the field of HR. It has suggested that AI has the potential to optimize HRM practices leading to higher efficiency and cost-cutting, while also exposing several other challenges and risks such as data privacy and security, job disarticulation, and diminished autonomy for employees. By doing a real-world experiment on a normal and ATS-friendly resume and reviewing case studies such as an ATS rejecting a company\u2019s own manager, this research investigates the balance between AI efficiency and human judgment.",
    "doi": "10.55544/sjmars.4.1.1",
    "url": "https://www.semanticscholar.org/paper/405960c1a6407f0d4537ac33a737574f66884c52",
    "pdf_url": "",
    "venue": "Stallion Journal for Multidisciplinary Associated Research Studies",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972853"
  },
  {
    "source": "semantic_scholar",
    "source_id": "b4bab7a5413d44f0f2443a6e3345d21564926b36",
    "title": "The Power of Artificial Intelligence in Recruitment: A Theoretical Analysis of Current AI-Based Recruitment Strategies",
    "authors": [
      "Sayeed Arshad Raza"
    ],
    "year": 2025,
    "abstract": "Abstract: This report critically examines the burgeoning integration of Artificial Intelligence (AI) within recruitment processes, dissecting the inherent tension between aspirations for heightened efficiency and the crucial imperative of maintaining ethical standards. By examining AI tools used in pre-screening, candidate engagement, and evaluation through the diverse frameworks of Human Capital Theory, Organizational Justice Theory, the Technology Acceptance Model (TAM), and Critical Theory, this study highlights underlying concerns such as algorithmic bias, the risk of impersonal or dehumanized candidate experiences, and the diminishing protection of applicant privacy. It contributes a novel and comprehensive framework meticulously designed for evaluating AI recruitment strategies, integrating disparate theoretical perspectives to furnish practical guidance for both Human Resource (HR) professionals and AI vendors. Emphasizing the necessity of rigorous ethical audits, algorithmic transparency, the indispensable role of human oversight, and a steadfast commitment to responsible AI development and deployment, the report advocates for proactive measures to ensure fairness, inclusivity, and a positive candidate experience. Furthermore, it identifies promising avenues for future research, including longitudinal studies to assess long-term impacts on diversity and the development of robust and reliable fairness metrics\n\nKeywords: AI, Recruitment, Algorithmic Bias, Fairness, Candidate Experience, Human Resources, Ethics, Theoretical Framework, Organizational Justice, Human Capital Theory, Technology Acceptance Model, Critical Theory.",
    "doi": "10.55041/ijsrem49671",
    "url": "https://www.semanticscholar.org/paper/b4bab7a5413d44f0f2443a6e3345d21564926b36",
    "pdf_url": "",
    "venue": "INTERNATIONAL JOURNAL OF SCIENTIFIC RESEARCH IN ENGINEERING AND MANAGEMENT",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972855"
  },
  {
    "source": "semantic_scholar",
    "source_id": "d91aa0d28406ee2a31acca6040e750988c7582cb",
    "title": "AI Ethics: Integrating Transparency, Fairness, and Privacy in AI Development",
    "authors": [
      "P. Radanliev"
    ],
    "year": 2025,
    "abstract": "ABSTRACT The expansion of Artificial Intelligence in sectors such as healthcare, finance, and communication has raised critical ethical concerns surrounding transparency, fairness, and privacy. Addressing these issues is essential for the responsible development and deployment of AI systems. This research establishes a comprehensive ethical framework that mitigates biases and promotes accountability in AI technologies. A comparative analysis of international AI policy frameworks from regions including the European Union, United States, and China is conducted using analytical tools such as Venn diagrams and Cartesian graphs. These tools allow for a visual and systematic evaluation of the ethical principles guiding AI development across different jurisdictions. The results reveal significant variations in how global regions prioritize transparency, fairness, and privacy, with challenges in creating a unified ethical standard. To address these challenges, we propose technical strategies, including fairness-aware algorithms, routine audits, and the establishment of diverse development teams to ensure ethical AI practices. This paper provides actionable recommendations for integrating ethical oversight into the AI lifecycle, advocating for the creation of AI systems that are both technically sophisticated and aligned with societal values. The findings underscore the necessity of global collaboration in fostering ethical AI development.",
    "doi": "10.1080/08839514.2025.2463722",
    "url": "https://www.semanticscholar.org/paper/d91aa0d28406ee2a31acca6040e750988c7582cb",
    "pdf_url": "",
    "venue": "Applied Artificial Intelligence",
    "citation_count": 111,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:53.972856"
  },
  {
    "source": "semantic_scholar",
    "source_id": "3681a4af812501dbe79dfddbccec1fc88a6caa01",
    "title": "Artificial Intelligence in Trauma and Orthopaedic Surgery: A Comprehensive Review From Diagnosis to Rehabilitation",
    "authors": [
      "Ahmed M Mohamed",
      "Alaa Elasad",
      "Usman Fuad",
      "Ioannis P Pengas",
      "Adham Elsayed",
      "Prabhakar Bhamidipati",
      "Peter Salib"
    ],
    "year": 2025,
    "abstract": "Artificial intelligence (AI) has presented clinical maturity in healthcare applications. AI is reshaping orthopaedic practice by enhancing the speed and efficiency of clinical decision-making, surgical planning, and research workflows. AI enables clinicians to optimize the care pathway through rapid data processing, pattern recognition, and predictive modelling. This review examines the current AI applications across the entire spectrum of orthopaedic care and its contribution to patient care and resource utilization. Despite these promising developments, several barriers prevent widespread adoption, including concerns regarding algorithm transparency, data privacy, potential bias in training datasets, and implementation costs. The path forward requires the development of explainable AI systems that clinicians can trust and validate. As AI technology continues to evolve, success will depend on augmenting human judgment with machine precision to deliver optimal care for patients with musculoskeletal conditions.",
    "doi": "10.7759/cureus.92280",
    "url": "https://www.semanticscholar.org/paper/3681a4af812501dbe79dfddbccec1fc88a6caa01",
    "pdf_url": "",
    "venue": "Cureus",
    "citation_count": 4,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:53.972858"
  },
  {
    "source": "semantic_scholar",
    "source_id": "fde840d002673ff67a709c9964dda775f80e969f",
    "title": "Applications and challenges of artificial intelligence-driven 3D vision in biomedical engineering: A biomechanics perspective",
    "authors": [
      "Lei Wang",
      "Zunjie Zhu"
    ],
    "year": 2025,
    "abstract": "This paper explores the applications and challenges of artificial intelligence (AI)-driven 3D vision technology in biomedical engineering, with a specific focus on its integration with biomechanics. 3D vision technology offers richer spatial information compared to traditional 2D imaging and is increasingly applied in fields like medical image analysis, surgical navigation, lesion detection, and biomechanics. In biomechanics, AI-driven 3D vision is used for analyzing human movement, modeling musculoskeletal systems, and assessing joint biomechanics. However, challenges persist, including image quality, computational resource demands, data privacy, and algorithmic bias. This paper reviews the development of 3D vision technology and AI, discusses its applications in biomedicine and biomechanics, and addresses the key technical obstacles, offering insights into the future development of these technologies in the context of biomedical and biomechanical research.",
    "doi": "10.62617/mcb1006",
    "url": "https://www.semanticscholar.org/paper/fde840d002673ff67a709c9964dda775f80e969f",
    "pdf_url": "",
    "venue": "Molecular &amp; Cellular Biomechanics",
    "citation_count": 3,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972859"
  },
  {
    "source": "semantic_scholar",
    "source_id": "4092be66782505e69fb0199894df68742c62e9d7",
    "title": "The Impact of Artificial Intelligence-Based Human Resource Management Systems on Organizational Efficiency",
    "authors": [
      "Pankaj Kumar Tyagi",
      "Vikram Jit Singh",
      "Ajit Kumar Singh",
      "Ayush Saxena",
      "Priyanka Tyagi",
      "Pankaj Mehta"
    ],
    "year": 2023,
    "abstract": "The transformative impact of AI-based HRMSs (artificial intelligence-based human resource management systems) on the effectiveness of organizations has been examined in this empirical paper. Artificial Intelligence (AI) is revolutionizing workforce management in today's dynamic business landscape. It is transforming functions like employee engagement, performance management, the onboarding process, recruitment, as well as workforce planning. By streamlining HR procedures, AI-HRMS enables automation, and predictive analytics, in addition to data-driven decision-making. The study illustrates the benefits of AI-HRMS with case studies and statistical analysis. By automating the screening of candidates and anticipating job success, these systems strengthen the efficiency of recruitment. Personalized plans and real-time support speed up employee onboarding and increase fulfillment. AI-HRMS uses personalized development plans, automated forecasting, and task automation to increase employee engagement and retention. Continuous improvement is promoted and worker contributions are matched with organizational objectives through data-driven performance management. The paper highlights challenges as well as successful implementations in companies such as Siemens, Unilever, IBM, as well as others. Careful consideration is needed for data privacy, opposition from staff members, system integration, and potential bias. Organizations can fully utilize AI-HRMS by triumphing over these obstacles, bringing in improved prospects for HR administration and organizational effectiveness.",
    "doi": "10.1109/UPCON59197.2023.10434792",
    "url": "https://www.semanticscholar.org/paper/4092be66782505e69fb0199894df68742c62e9d7",
    "pdf_url": "",
    "venue": "IEEE Uttar Pradesh Section International Conference on Electrical, Computer and Electronics Engineering",
    "citation_count": 5,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972861"
  },
  {
    "source": "semantic_scholar",
    "source_id": "a20afbcf5fe7a60d69442cab3fc1b46ffe97f9a3",
    "title": "Artificial Intelligence in Human Resource Management: Transforming Business Practices",
    "authors": [
      "Smruti Ranjan Das",
      "Prithu Sarkar",
      "Shripada Patil",
      "Ritesh Sharma",
      "Shikha Aggarwal",
      "Melanie Lourens"
    ],
    "year": 2023,
    "abstract": "The significant effects of artificial intelligence (AI) on human resource management (HRM) and its revolutionary effect on modern corporate practices have been investigated in this empirical study. In the ever-changing business landscape of today, companies are always looking for innovative strategies to improve productivity and competitiveness. Artificial intelligence (AI) has become a key invention that not only penetrates many industries but also transforms human resource management (HRM) by transforming workforce management, performance evaluation, including talent acquisition. The conventional resume screening process has been changed by AI's involvement in talent acquisition, resulting in it being more objective and efficient. Artificial intelligence (AI)-powered algorithms quickly evaluate a large number of resumes, classify applicants, and identify the best ones. AI gives businesses a competitive edge by broadening the talent pool and scanning a variety of sources to help with proactive candidate sourcing. In order to enhance the applicant experience overall, chatbots and virtual assistants communicate with candidates in real time while they do pre-screening interviews. In order to overcome bias issues, predictive analytics assists in assessing individuals' potential and synchronizes recruiting with strategic goals. Artificial intelligence (AI) brings continuous in addition to objective feedback systems to performance evaluation and feedback, minimizing subjectivity and enhancing fairness. Identifying skill gaps makes individualized development strategies possible. AI's data-driven approach to workforce management including optimization helps with staffing requirements predictions, schedule optimization, resource allocation, and proactive employee attrition management. The use of AI in HRM has many advantages, but it also presents difficulties in addition to moral questions, including data privacy, job security, and decision-making responsibility. To overcome these obstacles, organizations are required to set up strong data protection procedures, open lines of communication, as well as distinct accountability structures. This empirical research explores the complex relationship between AI and HRM and provides guidance with regard to how to use AI to support more ethical and effective HR procedures, which will eventually influence corporate practices in the future.",
    "doi": "10.1109/UPCON59197.2023.10434524",
    "url": "https://www.semanticscholar.org/paper/a20afbcf5fe7a60d69442cab3fc1b46ffe97f9a3",
    "pdf_url": "",
    "venue": "IEEE Uttar Pradesh Section International Conference on Electrical, Computer and Electronics Engineering",
    "citation_count": 6,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972862"
  },
  {
    "source": "semantic_scholar",
    "source_id": "66963f526ab81db63a5b727654b5082bdf06846f",
    "title": "Integrating Artificial Intelligence in Human Resource Functions: Challenges and Opportunities",
    "authors": [
      "Nordahlia Umar Baki",
      "Roziah Mohd Rasdi",
      "S. Krauss",
      "Mohd Khaizer Omar"
    ],
    "year": 2023,
    "abstract": "Artificial intelligence (AI) comes in many forms and has entered the overall system of organisations including in human resource (HR), where AI started to replace some of the human functions. Nonetheless, despite increased academic interest, research on AI-based HR tools is limited and fragmented. This article discusses the challenges and opportunities brought together during AI intervention in innovating HR functions. This study systematically reviews the existing literature, highlighting key areas where AI is being integrated, such as recruitment, employee engagement, training and development, and performance assessment. With the integration of AI, it successfully helps the industry to work in more effective and efficient ways through enhancing employee learning experiences, mitigating human biases, reducing manpower and training cost, and increasing employee engagement and retention. On the other hand, there are also studies that have raised the concern of the challenges during the AI integration, such as high implementation cost of technology tools, uncertainty and employee resistance, lack of human touch and legal and ethical concerns. This paper argues that successful integration of AI in HR functions requires a holistic approach. Collaboration between HR professionals and AI experts is crucial to address technical and ethical challenges. To leverage AI, organisations must embrace change management strategies to facilitate a smooth transition and foster a culture of continuous improvement. This study sheds light on how AI is transforming HR functions and establishes the groundwork for future research such as competency development, workplace learning, and organisation development, enabling practitioners and scholars to navigate the intricate terrain of AI integration in HR successfully.",
    "doi": "10.6007/ijarbss/v13-i8/18071",
    "url": "https://www.semanticscholar.org/paper/66963f526ab81db63a5b727654b5082bdf06846f",
    "pdf_url": "https://hrmars.com/papers_submitted/18071/integrating-artificial-intelligence-in-human-resource-functions-challenges-and-opportunities.pdf",
    "venue": "International Journal of Academic Research in Business and Social Sciences",
    "citation_count": 4,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972864"
  },
  {
    "source": "semantic_scholar",
    "source_id": "3e89d80f5d85d81032e2222928f0401524fa6508",
    "title": "The integration and implications of artificial intelligence in forensic science",
    "authors": [
      "Paige Tynan"
    ],
    "year": 2024,
    "abstract": null,
    "doi": "10.1007/s12024-023-00772-6",
    "url": "https://www.semanticscholar.org/paper/3e89d80f5d85d81032e2222928f0401524fa6508",
    "pdf_url": "",
    "venue": "Forensic Science, Medicine, and Pathology",
    "citation_count": 25,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140579"
  },
  {
    "source": "semantic_scholar",
    "source_id": "e285139b9d25057156b2d13225d86e92456be9fd",
    "title": "Unveiling the Influence of Artificial Intelligence on Resource Management and Sustainable Development: A Comprehensive Investigation",
    "authors": [
      "Geetha Manoharan",
      "Meeta Joshi",
      "Kawerinder Singh Sidhu",
      "Rajesh Bhaskar Survase",
      "Roop Raj",
      "Ashutosh Pandey"
    ],
    "year": 2024,
    "abstract": "Artificial Intelligence (AI) holds immense potential to reconstruct various facets of ability administration and contribute to tenable incident. However, its ratification raises important righteous considerations that must be forwarded to guarantee justice, transparency, and responsibility. This paper determines a inclusive exploration of AI\u2019s influence on source administration and tenable development, trying allure implications across various subdivisions and rules. The study critically resolves the current countryside of AI enactment in human resource management (HRM) and allure impact on administrative adeptness and worker well-being. It more investigates AI\u2019s duty in trying key challenges related to tenable happening, such as material preservation, friendly equity, and business-related progress. By inspecting existing article and practical evidence, this paper focal points the opportunities and challenges guide AI endorsement and offers understandings into strategies for optimizing effectiveness and impartiality with AI. Additionally, the study stresses the significance of righteous considerations in AI acceptance, containing algorithmic bias, data solitude, responsibility, and the moral implications of task displacement. Overall, this paper underscores the need for a equalized approach to AI enactment that maximizes allure benefits while mitigating potential risks, eventually donating to acceptable and equitable incident.",
    "doi": "10.1109/ICACCM61117.2024.11059226",
    "url": "https://www.semanticscholar.org/paper/e285139b9d25057156b2d13225d86e92456be9fd",
    "pdf_url": "",
    "venue": "2024 International Conference on Advances in Computing, Communication and Materials (ICACCM)",
    "citation_count": 24,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140589"
  },
  {
    "source": "semantic_scholar",
    "source_id": "58c95c5e45f458d18c9fd13952bba852c25d9bbb",
    "title": "Transparent Artificial Intelligence and Human Resource Management: A Systematic Literature Review",
    "authors": [
      "A. M. Votto",
      "C. Liu"
    ],
    "year": 2023,
    "abstract": "As the technological expansion of Artificial Intelligence (AI) penetrates various industries, Human Resource Management has attempted to keep pace with the new capabilities and challenges these technologies have brought. When adopting AI, transparency within HRM decisions is an increasing demand to establish ethical, unbiased, and fair practices within a firm. To this end, explainable AI (XAI) methods have become vital in achieving transparency within HRM decision-making. Thus, there has been a growing interest in exploring successful XAI techniques, as evidenced by the systematic literature review (SLR) performed in this paper. Our SLR starts by revealing where AI exists within HRM. Following this, we review the literature on XAI and accuracy, XAI design, accountability, and data processing initiatives within HRM. The integrated framework we propose provides an avenue to bridge the gap between transparent HRM practices and Artificial Intelligence, providing the industrial and academic community with better insight into where XAI could exist within HRM processes.",
    "doi": "10.24251/hicss.2023.132",
    "url": "https://www.semanticscholar.org/paper/58c95c5e45f458d18c9fd13952bba852c25d9bbb",
    "pdf_url": "https://scholarspace.manoa.hawaii.edu/bitstreams/675b7c99-690f-422c-b449-8d8dbbd2c502/download",
    "venue": "Hawaii International Conference on System Sciences",
    "citation_count": 1,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140592"
  },
  {
    "source": "semantic_scholar",
    "source_id": "93aa1a8c0dcd7b6ca69a02b08eb464d20c25ab5a",
    "title": "Behavioral Ethics Ecologies of Human-Artificial Intelligence Systems",
    "authors": [
      "Stephen Fox"
    ],
    "year": 2022,
    "abstract": "Historically, evolution of behaviors often took place in environments that changed little over millennia. By contrast, today, rapid changes to behaviors and environments come from the introduction of artificial intelligence (AI) and the infrastructures that facilitate its application. Behavioral ethics is concerned with how interactions between individuals and their environments can lead people to questionable decisions and dubious actions. For example, interactions between an individual\u2019s self-regulatory resource depletion and organizational pressure to take non-ethical actions. In this paper, four fundamental questions of behavioral ecology are applied to analyze human behavioral ethics in human\u2013AI systems. These four questions are concerned with assessing the function of behavioral traits, how behavioral traits evolve in populations, what are the mechanisms of behavioral traits, and how they can differ among different individuals. These four fundamental behavioral ecology questions are applied in analysis of human behavioral ethics in human\u2013AI systems. This is achieved through reference to vehicle navigation systems and healthcare diagnostic systems, which are enabled by AI. Overall, the paper provides two main contributions. First, behavioral ecology analysis of behavioral ethics. Second, application of behavioral ecology questions to identify opportunities and challenges for ethical human\u2013AI systems.",
    "doi": "10.3390/bs12040103",
    "url": "https://www.semanticscholar.org/paper/93aa1a8c0dcd7b6ca69a02b08eb464d20c25ab5a",
    "pdf_url": "https://www.mdpi.com/2076-328X/12/4/103/pdf?version=1649734738",
    "venue": "Behavioral Science",
    "citation_count": 4,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140593"
  },
  {
    "source": "semantic_scholar",
    "source_id": "75b2b52d2b95bffbff6de9f852db8b810254db84",
    "title": "From Bias to Fairness: A Review of Ethical Considerations and Mitigation Strategies in Artificial Intelligence",
    "authors": [
      "Saurabh Srivastava",
      "Khushi Sinha"
    ],
    "year": 2023,
    "abstract": "Abstract: Artificial intelligence (AI) has become increasingly popular in recent years and has been used in a range of industries to improve outcomes, streamline processes, and improve decision-making. But there are also moral questions raised by the employment of AI, particularly in light of potential bias and discrimination. In order to promote justice and reduce bias, this paper offers a thorough discussion of ethical issues and mitigation techniques in AI. The evolution of AI and its possible advantages and disadvantages are first covered in the paper. After that, it explores the different ethical issues surrounding AI, such as trust, accountability, fairness, and openness. The study emphasises the effects of bias and discrimination on AI systems as well as the possible outcomes of these problems. The study also discusses the various mitigation measures, such as algorithmic strategies, data pre-processing, and model validation, that have been suggested to mitigate bias and enhance justice in AI. In order to develop the subject of AI ethics, the study analyses the advantages and disadvantages of different frameworks and emphasises the necessity of continued interdisciplinary research and collaboration. The study's importance in advancing ethical concerns and fairness in AI is highlighted in the paper's conclusion. It offers information about the state of the field at the moment and points out potential directions for further study. Overall, the article is a useful tool for academics, professionals, and decision-makers who want to support ethical and responsible AI development and application.",
    "doi": "10.22214/ijraset.2023.49990",
    "url": "https://www.semanticscholar.org/paper/75b2b52d2b95bffbff6de9f852db8b810254db84",
    "pdf_url": "https://doi.org/10.22214/ijraset.2023.49990",
    "venue": "International Journal for Research in Applied Science and Engineering Technology",
    "citation_count": 4,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140595"
  },
  {
    "source": "semantic_scholar",
    "source_id": "f45b24bca3b0a05237883c23e941ee3b8a5cee57",
    "title": "From Recruitment to Retention: AI Tools for Human Resource Decision-Making",
    "authors": [
      "Mitra Madanchian"
    ],
    "year": 2024,
    "abstract": "HR decision-making is changing as a result of artificial intelligence (AI), especially in the areas of hiring, onboarding, and retention. This study examines the use of AI tools throughout the lifecycle of an employee, emphasizing how they enhance the effectiveness, customization, and scalability of HR procedures. These solutions streamline employee setup, learning, and documentation. They range from AI-driven applicant tracking systems (ATSs) for applicant selection to AI-powered platforms for automated onboarding and individualized training. Predictive analytics also helps retention and performance monitoring plans, which lowers turnover, but issues such as bias, data privacy, and ethical problems must be carefully considered. This paper addresses the limitations and future directions of AI while examining its disruptive potential in HR.",
    "doi": "10.3390/app142411750",
    "url": "https://www.semanticscholar.org/paper/f45b24bca3b0a05237883c23e941ee3b8a5cee57",
    "pdf_url": "",
    "venue": "Applied Sciences",
    "citation_count": 27,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140596"
  },
  {
    "source": "semantic_scholar",
    "source_id": "b41daf07f4cb04f494a0c7ce420afc68b3e6dbf5",
    "title": "Beyond bias and discrimination: redefining the AI ethics principle of fairness in healthcare machine-learning algorithms",
    "authors": [
      "B. Giovanola",
      "S. Tiribelli"
    ],
    "year": 2022,
    "abstract": "The increasing implementation of and reliance on machine-learning (ML) algorithms to perform tasks, deliver services and make decisions in health and healthcare have made the need for fairness in ML, and more specifically in healthcare ML algorithms (HMLA), a very important and urgent task. However, while the debate on fairness in the ethics of artificial intelligence (AI) and in HMLA has grown significantly over the last decade, the very concept of fairness as an ethical value has not yet been sufficiently explored. Our paper aims to fill this gap and address the AI ethics principle of fairness from a conceptual standpoint, drawing insights from accounts of fairness elaborated in moral philosophy and using them to conceptualise fairness as an ethical value and to redefine fairness in HMLA accordingly. To achieve our goal, following a first section aimed at clarifying the background, methodology and structure of the paper, in the second section, we provide an overview of the discussion of the AI ethics principle of fairness in HMLA and show that the concept of fairness underlying this debate is framed in purely distributive terms and overlaps with non-discrimination, which is defined in turn as the absence of biases. After showing that this framing is inadequate, in the third section, we pursue an ethical inquiry into the concept of fairness and argue that fairness ought to be conceived of as an ethical value. Following a clarification of the relationship between fairness and non-discrimination, we show that the two do not overlap and that fairness requires much more than just non-discrimination. Moreover, we highlight that fairness not only has a distributive but also a socio-relational dimension. Finally, we pinpoint the constitutive components of fairness. In doing so, we base our arguments on a renewed reflection on the concept of respect, which goes beyond the idea of equal respect to include respect for individual persons. In the fourth section, we analyse the implications of our conceptual redefinition of fairness as an ethical value in the discussion of fairness in HMLA. Here, we claim that fairness requires more than non-discrimination and the absence of biases as well as more than just distribution; it needs to ensure that HMLA respects persons both as persons and as particular individuals. Finally, in the fifth section, we sketch some broader implications and show how our inquiry can contribute to making HMLA and, more generally, AI promote the social good and a fairer society.",
    "doi": "10.1007/s00146-022-01455-6",
    "url": "https://www.semanticscholar.org/paper/b41daf07f4cb04f494a0c7ce420afc68b3e6dbf5",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s00146-022-01455-6.pdf",
    "venue": "Ai & Society",
    "citation_count": 119,
    "fields_of_study": [
      "Computer Science",
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140598"
  },
  {
    "source": "semantic_scholar",
    "source_id": "fe1e7f07ec5546061ba9fda973f0b92aaff0a548",
    "title": "Artificial intelligence adoption in extended HR ecosystems: enablers and barriers. An abductive case research",
    "authors": [
      "Antarpreet Singh",
      "Jatin Pandey"
    ],
    "year": 2024,
    "abstract": "Artificial intelligence (AI) has disrupted modern workplaces like never before and has induced digital workstyles. These technological advancements are generating significant interest among HR leaders to embrace AI in human resource management (HRM). Researchers and practitioners are keen to investigate the adoption of AI in HRM and the resultant human\u2013machine collaboration. This study investigates HRM specific factors that enable and inhibit the adoption of AI in extended HR ecosystems and adopts a qualitative case research design with an abductive approach. It studies three well-known Indian companies at different stages of AI adoption in HR functions. This research investigates key enablers such as optimistic and collaborative employees, strong digital leadership, reliable HR data, specialized HR partners, and well-rounded AI ethics. The study also examines barriers to adoption: the inability to have a timely pulse check of employees\u2019 emotions, ineffective collaboration of HR employees with digital experts as well as external HR partners, and not embracing AI ethics. This study contributes to the theory by providing a model for AI adoption and proposes additions to the unified theory of acceptance and use of technology in the context of AI adoption in HR ecosystems. The study also contributes to the best-in-class industry HR practices and digital policy formulation to reimagine workplaces, promote harmonious human\u2013AI collaboration, and make workplaces future-ready in the wake of massive digital disruptions.",
    "doi": "10.3389/fpsyg.2023.1339782",
    "url": "https://www.semanticscholar.org/paper/fe1e7f07ec5546061ba9fda973f0b92aaff0a548",
    "pdf_url": "https://www.frontiersin.org/articles/10.3389/fpsyg.2023.1339782/pdf?isPublishedV2=False",
    "venue": "Frontiers in Psychology",
    "citation_count": 26,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140600"
  },
  {
    "source": "semantic_scholar",
    "source_id": "c7eefc8d67b152e95a7e19bf66a0c3832b73bed4",
    "title": "Model of relationships between corporate social responsibility, human resources management, and artificial intelligence",
    "authors": [
      "R. Sk\u00fdpalov\u00e1",
      "Katar\u00edna Zvar\u00edkov\u00e1",
      "Sumana Chaudhuri"
    ],
    "year": 2025,
    "abstract": "Research background: The research explores the interrelationship between human resource management (HRM), corporate social responsibility (CSR), and artificial intelligence (AI) in the modern business environment. It examines the potential of AI to optimise HR processes while ensuring ethical considerations and social responsibility are integrated into corporate strategies.\nPurpose of the article: The aim of the article is to identify and quantify the causal relationships between human resource management, corporate social responsibility, and the perception of artificial intelligence within the company as key aspects of sustainable business development.\nMethods: Research was conducted in the Czech business environment based on 451 responses from HR managers in medium- to large-sized companies. A uniquely designed questionnaire was created to capture the respondents' subjective attitudes in September 2024. The hypotheses were evaluated using the application of structural equation modelling (SEM).\nFindings & value added: The findings confirm that CSR activities exert a clear and positive impact on HRM, whereas AI, despite its significant potential to enhance HR processes, is not yet fully implemented or utilised at an optimal level. In addition, we have also analysed the relationship between AI and CSR, and empirical findings indicate that AI can significantly support CSR activities as these two domains had the potential to enhance the competitiveness of the organisation. Our results emphasise the necessity for policy makers and managers to enhance CSR focused HRM practices and to support guidelines to ensure the ethical deployment of AI as the ethical and social implications of implementing AI in HR and CSR present another key challenge, including data bias and privacy concerns.",
    "doi": "10.24136/oc.3875",
    "url": "https://www.semanticscholar.org/paper/c7eefc8d67b152e95a7e19bf66a0c3832b73bed4",
    "pdf_url": "",
    "venue": "Oeconomia Copernicana",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140601"
  },
  {
    "source": "semantic_scholar",
    "source_id": "e82339666d2462b29962e9934e6d115717a21396",
    "title": "The Development of Artificial Intelligence and Its Impact on Human Rights Protection from An Ethical and Legal Perspective",
    "authors": [
      "Karyono Karyono"
    ],
    "year": 2025,
    "abstract": "The development of artificial intelligence (AI) has brought about major changes in various sectors of life, from public services to the legal system. Amid the benefits of efficiency and accuracy offered, the use of AI poses serious challenges to the protection of human rights. Risks such as privacy violations, algorithmic discrimination, decision-making without accountability, and digital surveillance are urgent issues that need to be addressed legally and ethically. The study examines the impact of the use of AI on human rights by emphasizing aspects of algorithm transparency, data bias, privacy rights, legal vacuum, and the global technology gap. This study uses a normative legal method with a statutory regulatory approach and a conceptual approach, referring to various national legal instruments such as the 1945 Constitution, Law No. 39 of 1999 concerning Human Rights, and Law No. 27 of 2022 concerning Personal Data Protection, as well as international standards such as the Universal Declaration of Human Rights, ICCPR, OECD AI Principles, and EU AI Act. The results of the study reveal that existing regulations are not sufficient to address the complexity of AI, so a special law is needed that comprehensively regulates artificial intelligence. In addition, the integration of human rights principles, technology ethics, and public policy is a strategic step to ensure that technological innovation does not ignore human values. Thus, AI can be developed responsibly, fairly, and oriented towards respect for human dignity.",
    "doi": "10.38035/gijlss.v3i2.499",
    "url": "https://www.semanticscholar.org/paper/e82339666d2462b29962e9934e6d115717a21396",
    "pdf_url": "",
    "venue": "Greenation International Journal of Law and Social Sciences",
    "citation_count": 2,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140603"
  },
  {
    "source": "semantic_scholar",
    "source_id": "e9da5272909d027dc56dba03d5e5ac6880382247",
    "title": "EARN Fairness: Explaining, Asking, Reviewing, and Negotiating Artificial Intelligence Fairness Metrics Among Stakeholders",
    "authors": [
      "Lin Luo",
      "Yuri Nakao",
      "Mathieu Chollet",
      "Hiroya Inakoshi",
      "Simone Stumpf"
    ],
    "year": 2024,
    "abstract": "Numerous fairness metrics have been proposed and employed by artificial intelligence (AI) experts to quantitatively measure bias and define fairness in AI models. Recognizing the need to accommodate stakeholders' diverse fairness understandings, efforts are underway to solicit their input. However, conveying AI fairness metrics to stakeholders without AI expertise, capturing their personal preferences, and seeking a collective consensus remain challenging and underexplored. To bridge this gap, we propose a new framework, EARN (Explain, Ask, Review, and Negotiate) Fairness, which facilitates collective metric decisions among stakeholders without requiring AI expertise. The framework features an adaptable interactive system and a stakeholder-centered EARN Fairness process to Explain fairness metrics, Ask stakeholders' personal metric preferences, Review metrics collectively, and Negotiate a consensus on metric selection. To gather empirical results, we applied the framework to a credit rating scenario and conducted a user study involving 18 decision subjects without AI knowledge. We elicited their personal metric preferences and subsequently we studied how they reached metric consensus in team sessions. Our work shows that the EARN Fairness framework supports stakeholders to express and negotiate fairness preferences, and we provide practical guidance for implementing human-centered AI fairness in high-risk contexts. Through this approach, we aim to reach consensus of fairness perspectives, fostering more equitable and inclusive AI fairness.",
    "doi": "10.1145/3710908",
    "url": "https://www.semanticscholar.org/paper/e9da5272909d027dc56dba03d5e5ac6880382247",
    "pdf_url": "",
    "venue": "Proc. ACM Hum. Comput. Interact.",
    "citation_count": 4,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140604"
  },
  {
    "source": "semantic_scholar",
    "source_id": "ac02b7a54280a44dd5c8ae967ee383bde4417776",
    "title": "Discussion on the Application Status and Optimization Direction of Artificial Intelligence Introduced into Enterprise Management and Operation Systems",
    "authors": [
      "Zhibin Feng"
    ],
    "year": 2025,
    "abstract": ": Artificial intelligence (AI) technology, as the core driving force of the new round of scientific and technological innovation and industrial change, impacts the market competitiveness of enterprises and the composition structure of sustainable development conditions. Based on the current status of the application of the new human-machine integration mode of AI technology introduced into the enterprise management and operation system, this paper analyzes the existing technology application and drawbacks and explores the optimization path of the enterprise's application of the new human-machine integration mode from the four dimensions of the management object, attributes, decision-making and ethics. This paper concludes that the introduction of AI technology resources in enterprises requires enterprise managers to reconfigure the resource management model and coordinate the human-machine relationship. At the same time, managers are required to improve their technical quality, combine technical theories and management frameworks, and optimize the traditional management operation mode of enterprises. In addition, the participation of AI technology in decision-making requires enterprise managers to coordinate the ratio of human-machine decision-making, and proactively prevent possible risks in technology-assisted decision-making and prediction. Finally, enterprises need to proactively prevent the legal and ethical risks that may exist when AI technology is applied.",
    "doi": "10.5220/0014306800004718",
    "url": "https://www.semanticscholar.org/paper/ac02b7a54280a44dd5c8ae967ee383bde4417776",
    "pdf_url": "",
    "venue": "Proceedings of the 2nd International Conference on Engineering Management, Information Technology and Intelligence",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140606"
  },
  {
    "source": "semantic_scholar",
    "source_id": "15f479258fb5290bb6a60141d21d6820aee33932",
    "title": "RETRACTED: Future directions of artificial intelligence integration: Managing strategies and opportunities",
    "authors": [
      "R. Sundar",
      "Ziaul Haque Choudhury",
      "M. Chiranjivi",
      "Gayatri Parasa",
      "Praseeda Ravuri",
      "M. Sivaram",
      "Balambigai Subramanian",
      "Kireet Muppavaram",
      "Vijaya Madhavi Lakshmi.Challa"
    ],
    "year": 2024,
    "abstract": "Embracing Artificial Intelligence (AI) is becoming more common in a variety of areas, including healthcare, banking, and transportation, and it is based on substantial data analysis. However, utilizing data for AI raises a number of obstacles. This extensive article examines the challenges connected with using data for AI, including data quality, volume, privacy and security, bias and fairness, interpretability and ethical considerations, and the required technical knowledge. The investigation delves into each obstacle, providing insightful solutions for businesses and organizations to properly handle these complexities. Organizations may effectively harness AI\u2019s capabilities to make educated decisions by understanding and proactively tackling these difficulties, obtaining a competitive edge in the digital era. This review study, which provides a thorough examination of numerous solutions developed over the last decade to address data difficulties for AI, is expected to be a helpful resource for the scientific research community. It not only provides insights into current difficulties, but it also serves as a platform for creating novel ideas to alter our approaches to data strategies for AI.",
    "doi": "10.3233/JIFS-238830",
    "url": "https://www.semanticscholar.org/paper/15f479258fb5290bb6a60141d21d6820aee33932",
    "pdf_url": "",
    "venue": "Journal of Intelligent &amp; Fuzzy Systems",
    "citation_count": 4,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140607"
  },
  {
    "source": "semantic_scholar",
    "source_id": "593c13c306ba13c7a4738ae3db7e652edee1555f",
    "title": "Artificial Intelligence in Journalism: A Narrative Review of Opportunities, Challenges, Ethical Tensions, and Human-Machine Collaboration",
    "authors": [
      "Habeeb Abdulrauf",
      "Abdulmalik Adetola Lawal",
      "Amarachi Nina Uma Mba",
      "Comfort Ademola",
      "Zaynab B. Yusuf",
      "Shalewa Babatayo",
      "Idris Ayinde"
    ],
    "year": 2025,
    "abstract": "Artificial Intelligence (AI) is changing the practices of journalism around the world, which influence how news is gathered, produced, and disseminated. This review synthesizes theories, empirical, and other literature to explore the multidimensional impact that AI has on journalistic workflows and values. This review centered on 81 core sources published between 2015 to 2024, examining AI\u2019s affordances, including automation of routine reporting, data mining and audience personalization. The paper also assesses the emerging risks such as algorithmic bias, erosion of editorial transparency, and the popularity of deepfakes in the media. Guided by Human\u2013Machine Communication (HMC) frameworks, Actor-Network Theory, and affordance theory, this review submit that AI is a collaboratived partner rather than a competitor to human journalists. Case examples from newsrooms worldwide (e.g., Associated Press, Washington Post, ICIJ) show both promise and issues in AI integration to the practice of journalism. The paper also addresses the ethical tensions arising from AI-generated content, newsroom accountability, and evolving public trust in machine-assisted reporting. The paper offers future directions that highlight seven key areas: advancing deepfake detection tools, creating of AI ethics guidelines, advocating for the AI training in journalism education, and bridging technological gaps between large and smaller newsrooms. It concludes by hammering on maintaining human editorial oversight and democratic values as AI is growingly augmented in journalistic practice. This paper, therefore, offers a timely and interdisciplinary contribution to media scholars, technologists, and newsroom leaders who are embracing the future of AI-driven journalism.",
    "doi": "10.54536/ajahs.v4i4.5963",
    "url": "https://www.semanticscholar.org/paper/593c13c306ba13c7a4738ae3db7e652edee1555f",
    "pdf_url": "",
    "venue": "American Journal of Arts and Human Science",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140609"
  },
  {
    "source": "semantic_scholar",
    "source_id": "dd6b1095962e661f18da53ca93aae39c1a834b4e",
    "title": "The balance between innovation and human rights: problems of applying artificial intelligence",
    "authors": [
      "T.P. Popovich"
    ],
    "year": 2025,
    "abstract": "The article provides a comprehensive analysis of the impact of artificial intelligence technologies on the human rights system in the context of the digital transformation of society. The main threats and challenges posed by AI systems for the implementation of fundamental human rights and freedoms are investigated. Particular attention is paid to the problems of algorithmic bias, which leads to a violation of the right to non-discrimination, mass collection and processing of personal data without proper control, which threatens the right to privacy, restrictions on freedom of expression through automated content moderation, as well as threats to the right to a fair trial in the case of using automated decision-making systems without proper transparency. \nThe specific risks associated with mass surveillance and biometric identification technologies, including facial recognition systems in public places, the use of AI in employment and the military, and the manipulation of public opinion through deepfake technologies, are analyzed. Three stages of assessing the impact of AI on human rights are considered: analysis of the quality of training data, risk assessment at the system design stage, and consideration of algorithmic interactions. It is argued that AI systems, by their nature, reproduce social biases embedded in past experience data and do not have the inherent ability to change their behavior in accordance with the evolution of ethical norms in society. The application of artificial intelligence in the financial sector is examined in detail, in particular in credit scoring systems, where algorithms analyze huge amounts of data about the applicant\u2019s digital footprint. The problem of \u201cnetwork discrimination\u201d is identified, when a person\u2019s financial capabilities are assessed based on the characteristics of their social environment, which violates the principle of individual responsibility and can limit freedom of belief through self-censorship. The example of the practice of American companies shows how the use of AI systems in financial decision- making can both expand access to credit for representatives of marginalized communities and strengthen existing forms of discrimination.",
    "doi": "10.61345/1339-7915.2025.3.16",
    "url": "https://www.semanticscholar.org/paper/dd6b1095962e661f18da53ca93aae39c1a834b4e",
    "pdf_url": "",
    "venue": "Visegrad journal on human rights",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140611"
  },
  {
    "source": "semantic_scholar",
    "source_id": "dc7f001149ed4c931dfa5ffa1a7379858fa449e2",
    "title": "Ethical Considerations of Bias and Fairness in AI Models",
    "authors": [
      "Sarvachan Verma",
      "Neha Paliwal",
      "Kanchan Yadav",
      "P. C. Vashist"
    ],
    "year": 2024,
    "abstract": "The ethical implications of artificial intelligence (AI) are becoming increasingly important. AI systems have the potential to incite bias against certain races and genders, either through programming choices or through the data collected to train the device. Thus, it is imperative to address ethical issues pertaining to justice and bias in order to guarantee the most responsible and optimal application of AI in society. Integrating AI ethics into software development processes is one way to deal with bias and equality in machine learning models. AI developers also have to deal with bias through length of information, in addition to programming concerns. Determining the lifespan of records entails making deliberate decisions about record entry that reduce prejudice and ensure fairness. It entails getting rid of protected characteristics that could have biased effects, such race or gender. Diversifying the kind of records that are included in models can also help to lessen the risk of bias.",
    "doi": "10.1109/ICDT61202.2024.10489577",
    "url": "https://www.semanticscholar.org/paper/dc7f001149ed4c931dfa5ffa1a7379858fa449e2",
    "pdf_url": "",
    "venue": "International Conference on Database Theory",
    "citation_count": 6,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140612"
  },
  {
    "source": "semantic_scholar",
    "source_id": "b0b1abb19ff12ce7bbc4c4b694fd4c2bdfe3f711",
    "title": "Framework for Bias Detection in Machine Learning Models: A Fairness Approach",
    "authors": [
      "Alveiro Alonso Rosado G\u00f3mez",
      "Maritza Liliana Calder\u00f3n Benavides"
    ],
    "year": 2024,
    "abstract": null,
    "doi": "10.1145/3616855.3635731",
    "url": "https://www.semanticscholar.org/paper/b0b1abb19ff12ce7bbc4c4b694fd4c2bdfe3f711",
    "pdf_url": "",
    "venue": "Web Search and Data Mining",
    "citation_count": 5,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140614"
  },
  {
    "source": "semantic_scholar",
    "source_id": "8d4c60de296a369049c33e2c7852a46cfb3ccd66",
    "title": "Beyond Human Judgment: Exploring the Impact of Artificial Intelligence on HR Decision-Making Efficiency and Fairness",
    "authors": [
      "Md. Abul Khair",
      "Ravikiran Mahadasa",
      "Ferdouse Ara Tuli",
      "Janaki Rama Phanendra Kumar Ande"
    ],
    "year": 2020,
    "abstract": "This study aims to evaluate the impact of artificial intelligence (AI) on the efficiency and fairness of human resources (HR) decision-making. The key goals are to determine how artificial intelligence improves decision-making efficiency, investigate the fairness issues involved in AI-driven human resource practices, and make policy suggestions for engaging in ethical HR practices. The approach utilized is known as secondary data analysis. It is used to synthesize insights and patterns by pulling upon previously published literature and empirical investigations; even though artificial intelligence technologies present an opportunity to optimize human resource operations and improve organizational performance, significant findings demonstrate that these technologies also create ethical problems connected to algorithmic biases and an absence of transparency. Regulatory oversight, ethical standards, data governance, diversity and inclusion programs, and constant monitoring and assessment are some of the policy implications that should be considered to guarantee responsible deployment of artificial intelligence in human resource contexts. When it comes to human resource decision-making, companies can embrace the revolutionary potential of artificial intelligence (AI) while maintaining ethical standards if they prioritize justice, openness, and accountability.",
    "doi": "10.18034/gdeb.v9i2.730",
    "url": "https://www.semanticscholar.org/paper/8d4c60de296a369049c33e2c7852a46cfb3ccd66",
    "pdf_url": "https://i-proclaim.my/journals/index.php/gdeb/article/download/730/660",
    "venue": "Global Disclosure of Economics and Business",
    "citation_count": 25,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140615"
  },
  {
    "source": "semantic_scholar",
    "source_id": "2e4916d53d6c8b3626a2ab7c6d62258f4251fc7f",
    "title": "Artificial intelligence agent in clinical trial operations: a fictional (for now) case study",
    "authors": [
      "T. M\u00e9nard",
      "Katrina A. Bramstedt"
    ],
    "year": 2025,
    "abstract": null,
    "doi": "10.1007/s43681-025-00798-2",
    "url": "https://www.semanticscholar.org/paper/2e4916d53d6c8b3626a2ab7c6d62258f4251fc7f",
    "pdf_url": "",
    "venue": "AI and Ethics",
    "citation_count": 0,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140617"
  },
  {
    "source": "semantic_scholar",
    "source_id": "a6dd1f1a9b1ce69a09e884cc5d497f4d2b6336e2",
    "title": "Governance and Ethical Challenges of Artificial Intelligence in Warfare",
    "authors": [
      "Md Tanvir Islam Sourav",
      "Nasrullah Masud",
      "Abdullah Al Bassam",
      "Abdus Sobhan"
    ],
    "year": 2025,
    "abstract": "The sudden integration of AI in today's workflow has made urgent ethical and governance discussions on accountability, bias, and human agency in making lethal decisions. This review looks into the ethics of military AI technologies: autonomous weapon systems (aerospace systems), AI-supported surveillance and targeting algorithms, and assesses the governance regimes created to minimize risks. Just-war theory continues to act as the moral compass. Still, it tells us little about the complications specific to AI, namely convoluted accountability chains and algorithmic biases that harm civilians [1], [2]. This paper has exposed these fundamentally disparate pathways worldwide through the comparative analysis of new ethical frameworks. The IEEE Global Initiative supports human control and transparency. At the same time, the Department of Defense in the United States prefers reliability from a technical point of view. At the same time, the EU grounds any human decision on actions that cause death and destruction [3]\u2013[5]. The Russian-Ukrainian war misuses facial recognition and places AI-guided systems for airstrikes in the 2023 Gaza conflict, at the historical case studies of recent wars that indicate deep-rooted systemic flaws in the governance architectures, such as biased mitigation and accountability [6], [7]. The study identifies three critical gaps in current policies: (1) insufficient mechanisms for auditing biased algorithms, (2) ambiguous legal responsibility for AWS outcomes, and (3) fragmented international regulatory efforts. The paper proposes a hybrid governance model combining rigorous ethical auditing, interoperable technical standards, and binding multilateral agreements to address these. Findings underscore the urgent need for interdisciplinary collaboration among technologists, ethicists, and policymakers to align AI advancements with international humanitarian law. Without proactive measures, the unchecked proliferation of military AI risks destabilizing global security and eroding public trust in automated defense systems [8].",
    "doi": "10.1109/QPAIN66474.2025.11171759",
    "url": "https://www.semanticscholar.org/paper/a6dd1f1a9b1ce69a09e884cc5d497f4d2b6336e2",
    "pdf_url": "",
    "venue": "2025 International Conference on Quantum Photonics, Artificial Intelligence, and Networking (QPAIN)",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140618"
  },
  {
    "source": "semantic_scholar",
    "source_id": "e4a2baa92dcdfbcd82621e9915d0a433704a8516",
    "title": "Politics by Automatic Means? A Critique of Artificial Intelligence Ethics at Work",
    "authors": [
      "M. Cole",
      "C. Cant",
      "Funda Ustek\u2010Spilda",
      "Mark Graham"
    ],
    "year": 2022,
    "abstract": "Calls for \u201cethical Artificial Intelligence\u201d are legion, with a recent proliferation of government and industry guidelines attempting to establish ethical rules and boundaries for this new technology. With few exceptions, they interpret Artificial Intelligence (AI) ethics narrowly in a liberal political framework of privacy concerns, transparency, governance and non-discrimination. One of the main hurdles to establishing \u201cethical AI\u201d remains how to operationalize high-level principles such that they translate to technology design, development and use in the labor process. This is because organizations can end up interpreting ethics in an ad-hoc way with no oversight, treating ethics as simply another technological problem with technological solutions, and regulations have been largely detached from the issues AI presents for workers. There is a distinct lack of supra-national standards for fair, decent, or just AI in contexts where people depend on and work in tandem with it. Topics such as discrimination and bias in job allocation, surveillance and control in the labor process, and quantification of work have received significant attention, yet questions around AI and job quality and working conditions have not. This has left workers exposed to potential risks and harms of AI. In this paper, we provide a critique of relevant academic literature and policies related to AI ethics. We then identify a set of principles that could facilitate fairer working conditions with AI. As part of a broader research initiative with the Global Partnership on Artificial Intelligence, we propose a set of accountability mechanisms to ensure AI systems foster fairer working conditions. Such processes are aimed at reshaping the social impact of technology from the point of inception to set a research agenda for the future. As such, the key contribution of the paper is how to bridge from abstract ethical principles to operationalizable processes in the vast field of AI and new technology at work.",
    "doi": "10.3389/frai.2022.869114",
    "url": "https://www.semanticscholar.org/paper/e4a2baa92dcdfbcd82621e9915d0a433704a8516",
    "pdf_url": "https://www.frontiersin.org/articles/10.3389/frai.2022.869114/pdf",
    "venue": "Frontiers in Artificial Intelligence",
    "citation_count": 18,
    "fields_of_study": [
      "Medicine",
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140620"
  },
  {
    "source": "semantic_scholar",
    "source_id": "4950d90b58b2b48f4ab2cd290b1f0e6cb9a116db",
    "title": "Ethical and Legal Challenges of AI in Human Resource Management",
    "authors": [
      "Jiaxing Du"
    ],
    "year": 2024,
    "abstract": "Artificial Intelligence (AI) has become a transformative force in Human Resource Management (HRM), enhancing recruitment, training, performance evaluation, and employee engagement. This paper examines the ethical and legal challenges associated with the integration of AI in HRM. Key ethical concerns include bias and discrimination, privacy and data protection, transparency and explainability, and the impact on job security and automation. Legal challenges revolve around compliance with data protection laws, anti-discrimination regulations, and labor laws. This paper provides recommendations for addressing these challenges through a comprehensive analysis of real-world case studies and relevant data through policy development, best practices, and future research directions. The goal is to contribute to the responsible and ethical use of AI in HRM, ensuring that its benefits are maximized while mitigating potential risks.",
    "doi": "10.54097/83j64ub9",
    "url": "https://www.semanticscholar.org/paper/4950d90b58b2b48f4ab2cd290b1f0e6cb9a116db",
    "pdf_url": "",
    "venue": "Journal of Computing and Electronic Information Management",
    "citation_count": 11,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140621"
  },
  {
    "source": "semantic_scholar",
    "source_id": "6d490989a6b61fe4210c222c9f6dc95990f70042",
    "title": "Artificial intelligence and public sector human resource management in South Africa: Opportunities, challenges and prospects",
    "authors": [
      "A. Chilunjika",
      "Kudakwashe Intauno",
      "S. Chilunjika"
    ],
    "year": 2022,
    "abstract": "Orientation: The Fourth Industrial Revolution has transformed modern society by ushering in the fusion of advances in robotics, the Internet of Things (IoT), genetic engineering, quantum computing, and artificial intelligence (AI) among others. AI brings a range of different technologies and applications to interact with environments that comprise both the relevant objects and the interaction rules and have the capacity to process information in a way that resembles intelligent behaviour. Similarly, artificial intelligence is also being used in the human resources management (HRM) processes and functions in the public sector to map sequences to actions.Research purpose: The study explores the opportunities, challenges, and future prospects of integrating Artificial Intelligence (AI) and Public Sector Human Resource Management (HRM) in South Africa\u2019s public sector.Motivation for the study: The study was motivated by the need to examine the dynamics surrounding the adoption, implementation and operationalisation of the 4IR in the management of human resources in the SA public sector in this unfolding dispensation.Research Approach: Data was collected using the extensive review of written records such as books, journal articles, book chapters among others which were purposively selected for use in this study. Data was analysed using content and thematic analysis techniques.Research Findings: The study established that Artificial Intelligence is beneficial in the sense that it can improve public service delivery in South Africa as the HRM personnel is enabled to focus more on the strategic areas of management by taking over routine tasks, and that it helps minimize bias in public service recruitment and selection. In contrast, research on potential challenges has revealed that combining Artificial Intelligence and Public Sector Human Resource Management may pose a threat to white-collar jobs.Practical/ Managerial Implications: This study may lead to practical applications of AI to support the HR functions of public sector entities in SA. The public managers are better informed about the impediments, gaps and opportunities that may arise from using AI in managing human resources in SA\u2019s public sector.Contributions: This study contributes to the body of knowledge as it unpacks and informs the dynamics associated with the implementation of AI in managing human resources in public sector entities.",
    "doi": "10.4102/sajhrm.v20i0.1972",
    "url": "https://www.semanticscholar.org/paper/6d490989a6b61fe4210c222c9f6dc95990f70042",
    "pdf_url": "https://sajhrm.co.za/index.php/sajhrm/article/download/1972/3069",
    "venue": "Sa Journal of Human Resource Management",
    "citation_count": 47,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140623"
  },
  {
    "source": "semantic_scholar",
    "source_id": "dd8c8f102041c9ded50cf9e9f3db6b9940609f0a",
    "title": "ARTIFICIAL INTELLIGENCE IN CRIMINAL JUSTICE MANAGEMENT: A SYSTEMATIC LITERATURE REVIEW",
    "authors": [
      "Khairul Alam Talukder",
      "Touhida Ferdousi Shompa"
    ],
    "year": 2024,
    "abstract": "This systematic review, based on 37 articles, explores the role of artificial intelligence (AI) in criminal justice, focusing on its applications in predictive policing, judicial risk assessments, and surveillance, as well as the associated ethical and regulatory challenges. AI has demonstrated substantial potential for improving efficiency and accuracy in criminal justice systems, from optimizing law enforcement resource allocation to providing data-driven risk assessments that support judicial decisions. However, the review identifies significant ethical issues, especially related to algorithmic bias, which can perpetuate existing societal inequalities and disproportionately affect marginalized communities. Concerns around transparency and accountability are prevalent, as the \"black-box\" nature of many AI algorithms complicates public understanding and trust in AI-driven outcomes. Surveillance tools, including facial recognition and behavioral analysis, enhance real-time threat detection but raise privacy and civil rights concerns, highlighting the need for regulatory oversight. Gaps in legal frameworks suggest the urgency for standardized policies that address data privacy, algorithmic fairness, and accountability in AI applications. The findings underscore that interdisciplinary collaboration, transparent practices, and comprehensive regulatory measures are essential to responsibly integrate AI into criminal justice, balancing technological advancements with justice, equity, and public trust.",
    "doi": "10.70008/jmldeds.v1i01.42",
    "url": "https://www.semanticscholar.org/paper/dd8c8f102041c9ded50cf9e9f3db6b9940609f0a",
    "pdf_url": "https://nonhumanjournal.com/index.php/JMLDEDS/article/download/42/42",
    "venue": "Non human journal",
    "citation_count": 7,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140624"
  },
  {
    "source": "semantic_scholar",
    "source_id": "b29559cf818317411d734aabf67efc7c5d411e5e",
    "title": "Artificial intelligence in governance: recent trends, risks, challenges, innovative frameworks and future directions",
    "authors": [
      "Arjun Ghosh",
      "Ankit Saini",
      "Himanshu Barad"
    ],
    "year": 2025,
    "abstract": null,
    "doi": "10.1007/s00146-025-02312-y",
    "url": "https://www.semanticscholar.org/paper/b29559cf818317411d734aabf67efc7c5d411e5e",
    "pdf_url": "",
    "venue": "Ai & Society",
    "citation_count": 24,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140626"
  },
  {
    "source": "semantic_scholar",
    "source_id": "a29915337616551711d1a8128bab1255090466a7",
    "title": "Machine Learning and Human Resource Management: A Path to Efficient Workforce Management",
    "authors": [
      "Ankita Saxena",
      "Sammaiah Buhukya",
      "Ippa Sumalatha",
      "Amit Dutt",
      "Abothar Mahmod Shaaker",
      "A. V"
    ],
    "year": 2023,
    "abstract": "In order to achieve effective workforce management, this empirical study investigates the incorporation of machine learning into human resource management (HRM). HRM is a fundamental function that oversees talent acquisition, employee welfare, and performance optimization in organizations. The dynamic nature of today's workplace presents special opportunities as well as challenges for HRM. Machine learning, a branch of artificial intelligence, has the potential to completely transform human resource management (HRM) by means of the use of data-driven decision-making, bias mitigation, employee experience personalization, as well as procedure optimization. The first section of the paper provides an overview of machine learning's application to HRM, with a particular focus on forward-thinking employee turnover prediction, personalized onboarding and training, recruitment automation, in addition to predictive analytics for employee success. Machine learning promotes fairness and equal opportunities by utilizing objective data to address bias in HR procedures. There are numerous advantages to incorporating machine learning into HRM, such as objectivity, personalization, automation that reduces costs, and decision-making based on information. The practical advantages of integrating machine learning in HRM are demonstrated by real-world case studies from businesses like Hilton, Xerox, and IBM. The resulting advantages include improved productivity, lower attrition, and higher employee engagement.",
    "doi": "10.1109/UPCON59197.2023.10434761",
    "url": "https://www.semanticscholar.org/paper/a29915337616551711d1a8128bab1255090466a7",
    "pdf_url": "",
    "venue": "IEEE Uttar Pradesh Section International Conference on Electrical, Computer and Electronics Engineering",
    "citation_count": 2,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140627"
  },
  {
    "source": "semantic_scholar",
    "source_id": "830bc5710f3d2efbc24fc354a69124c5872f9f98",
    "title": "Auditing the AI auditors: A framework for evaluating fairness and bias in high stakes AI predictive models.",
    "authors": [
      "R. Landers",
      "Tara S. Behrend"
    ],
    "year": 2022,
    "abstract": "Researchers, governments, ethics watchdogs, and the public are increasingly voicing concerns about unfairness and bias in artificial intelligence (AI)-based decision tools. Psychology's more-than-a-century of research on the measurement of psychological traits and the prediction of human behavior can benefit such conversations, yet psychological researchers often find themselves excluded due to mismatches in terminology, values, and goals across disciplines. In the present paper, we begin to build a shared interdisciplinary understanding of AI fairness and bias by first presenting three major lenses, which vary in focus and prototypicality by discipline, from which to consider relevant issues: (a) individual attitudes, (b) legality, ethicality, and morality, and (c) embedded meanings within technical domains. Using these lenses, we next present psychological audits as a standardized approach for evaluating the fairness and bias of AI systems that make predictions about humans across disciplinary perspectives. We present 12 crucial components to audits across three categories: (a) components related to AI models in terms of their source data, design, development, features, processes, and outputs, (b) components related to how information about models and their applications are presented, discussed, and understood from the perspectives of those employing the algorithm, those affected by decisions made using its predictions, and third-party observers, and (c) meta-components that must be considered across all other auditing components, including cultural context, respect for persons, and the integrity of individual research designs used to support all model developer claims. (PsycInfo Database Record (c) 2022 APA, all rights reserved).",
    "doi": "10.1037/amp0000972",
    "url": "https://www.semanticscholar.org/paper/830bc5710f3d2efbc24fc354a69124c5872f9f98",
    "pdf_url": "",
    "venue": "American Psychologist",
    "citation_count": 143,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140629"
  },
  {
    "source": "semantic_scholar",
    "source_id": "5c6bc0f99b7314d37d0bbde84716eb0d0f8d930f",
    "title": "Guest Editorial: Business Ethics in the Era of Artificial Intelligence",
    "authors": [
      "M. Haenlein",
      "Ming-Hui Huang",
      "Andrea Edith Kaplan"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1007/s10551-022-05060-x",
    "url": "https://www.semanticscholar.org/paper/5c6bc0f99b7314d37d0bbde84716eb0d0f8d930f",
    "pdf_url": "",
    "venue": "Journal of Business Ethics",
    "citation_count": 47,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140630"
  },
  {
    "source": "semantic_scholar",
    "source_id": "5d6a997eb7b226917c3d98d2f72d84be45384b23",
    "title": "AI Ethics and Transparency in Operations Management: How Governance Mechanisms Can Reduce Data Bias and Privacy Risks",
    "authors": [
      "Zuowei Li"
    ],
    "year": 2024,
    "abstract": "The use of artificial intelligence (AI) in operations management holds the key to efficiency, precision and agility in business decision-making, yet it also involves ethical challenges such as fairness, accountability, transparency and privacy that can undermine trust in AI. This paper examines the ethical considerations of AI use in operations, paying particular attention to data bias, privacy risks and governance. Drawing on major governance frameworks such as the OECD AI Principles and the EUs Ethics Guidelines for Trustworthy AI, this paper proposes a hybrid governance model to address the unique challenges of operational contexts. A case study in the financial sector is used to further explain how privacy-preserving techniques can safeguard the sensitive customer data needed for AI-driven customer service. Extensive experimentation conducted in that case has shown that privacy-preserving methods such as differential privacy and federated learning can reduce the incidence of unauthorised data-access events by as much as 30 per cent and can improve customer satisfaction by more than 20 per cent. This paper contributes to the dynamic discourse on ethical AI by offering practical recommendations to organisations on how to conduct AI operations in a way that is responsible and compliant.",
    "doi": "10.54254/2977-5701/13/2024130",
    "url": "https://www.semanticscholar.org/paper/5d6a997eb7b226917c3d98d2f72d84be45384b23",
    "pdf_url": "https://www.ewadirect.com/journal/jaeps/article/view/18052/pdf",
    "venue": "Journal of Applied Economics and Policy Studies",
    "citation_count": 8,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140632"
  },
  {
    "source": "semantic_scholar",
    "source_id": "ffa5a275be9ea886dff66494c821f2b2db2f091d",
    "title": "Exploring Ethical Dimensions in AI: Navigating Bias and Fairness in the Field",
    "authors": [
      "Jeff Shuford"
    ],
    "year": 2024,
    "abstract": "The rapid progress in implementing Artificial Intelligence (AI) across various domains such as healthcare decision-making, medical diagnosis, and others has raised significant concerns regarding the fairness and bias embedded within AI systems. This is particularly crucial in sectors like healthcare, employment, criminal justice, credit scoring, and the emerging field of generative AI models (GenAI) producing synthetic media. Such systems can lead to unfair outcomes and perpetuate existing inequalities, including biases ingrained in the synthetic data representation of individuals.This survey paper provides a concise yet comprehensive examination of fairness and bias in AI, encompassing their origins, ramifications, and potential mitigation strategies. We scrutinize sources of bias, including data, algorithmic, and human decision biases, shedding light on the emergent issue of generative AI bias where models may replicate and amplify societal stereotypes. Assessing the societal impact of biased AI systems, we spotlight the perpetuation of inequalities and the reinforcement of harmful stereotypes, especially as generative AI gains traction in shaping public perception through generated content.Various proposed mitigation strategies are explored, with an emphasis on the ethical considerations surrounding their implementation. We stress the necessity of interdisciplinary collaboration to ensure the effectiveness of these strategies. Through a systematic literature review spanning multiple academic disciplines, we define AI bias and its various types, delving into the nuances of generative AI bias. We discuss the adverse effects of AI bias on individuals and society, providing an overview of current approaches to mitigate bias, including data preprocessing, model selection, and post-processing. Unique challenges posed by generative AI models are highlighted, underscoring the importance of tailored strategies to address them effectively.Addressing bias in AI necessitates a holistic approach, involving diverse and representative datasets, enhanced transparency, and accountability in AI systems, and exploration of alternative AI paradigms prioritizing fairness and ethical considerations. This survey contributes to the ongoing discourse on developing fair and unbiased AI systems by outlining the sources, impacts, and mitigation strategies related to AI bias, with a particular focus on the burgeoning field of generative AI.",
    "doi": "10.60087/jaigs.vol03.issue01.p124",
    "url": "https://www.semanticscholar.org/paper/ffa5a275be9ea886dff66494c821f2b2db2f091d",
    "pdf_url": "https://jaigs.org/index.php/JAIGS/article/download/54/41",
    "venue": "Journal of Artificial Intelligence General science (JAIGS) ISSN:3006-4023",
    "citation_count": 3,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140633"
  },
  {
    "source": "semantic_scholar",
    "source_id": "78ef946e2cff0e57e92bf538a1d1f0f5a2775ae3",
    "title": "Research on the Application of Large Language Models in Human Resource Management Practices",
    "authors": [
      "Jingran Sun"
    ],
    "year": 2024,
    "abstract": "With the rapid development of artificial intelligence technology, large language models (LLMs) are being increasingly applied across various fields. This paper focuses on the research of LLMs in human resource management practices, discussing the current applications, challenges, and future trends of LLMs in core HR functions such as recruitment, training, and performance management. Through a systematic review and analysis of existing literature, this study finds that LLMs demonstrate enormous potential in HR management, significantly improving work efficiency, optimizing decision-making processes, and personalizing employee experiences. However, challenges such as data privacy, algorithmic bias, and ethical concerns still exist in practical applications. This paper proposes a series of recommendations to promote the effective application of LLMs in HR management and provides insights for future research directions.",
    "doi": "10.62677/ijetaa.2408125",
    "url": "https://www.semanticscholar.org/paper/78ef946e2cff0e57e92bf538a1d1f0f5a2775ae3",
    "pdf_url": "",
    "venue": "International Journal of Emerging Technologies and Advanced Applications",
    "citation_count": 4,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140635"
  },
  {
    "source": "semantic_scholar",
    "source_id": "8b8eefd16afffd5198d055b5e1a0ffd29739238b",
    "title": "EXPLORING THE LANDSCAPE: A LITERATURE REVIEW OF AI\u2019S IMPACT ON HUMAN RESOURCE MANAGEMENT",
    "authors": [
      "Daniel-Florin D\u0103niloaia"
    ],
    "year": 2024,
    "abstract": "This article explores literature and finds the transformative impact of artificial \nintelligence (AI) on human resource management (HRM), highlighting its applications \nand benefits across various HR functions. AI enhances recruitment, training, \nperformance management, and compensation by automating routine tasks and providing \nadvanced analytics. This allows HR professionals to focus on strategic decision-making \nand personalized employee engagement. Despite challenges such as data privacy \nconcerns and algorithmic bias, AI improves efficiency, accuracy, and employee \nsatisfaction. The article emphasizes the need for balancing technological advancements \nwith ethical considerations to ensure AI complements rather than replaces human skills.",
    "doi": "10.47743/ejpar.2024-3-6",
    "url": "https://www.semanticscholar.org/paper/8b8eefd16afffd5198d055b5e1a0ffd29739238b",
    "pdf_url": "",
    "venue": "European Journal of Public Administration Research",
    "citation_count": 3,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140636"
  },
  {
    "source": "semantic_scholar",
    "source_id": "42451898b9c9b5c9c6a65614ac5f2e7e8be8d93b",
    "title": "Explainable deep learning integrated with decentralized identity systems to combat bias, enhance trust, and ensure fairness in algorithmic governance",
    "authors": [
      "Oyegoke Oyebode"
    ],
    "year": 2024,
    "abstract": "The growing reliance on artificial intelligence in decision-making processes has intensified debates over bias, fairness, and accountability in algorithmic governance. While deep learning models deliver unprecedented predictive performance, their \u201cblack box\u201d nature has undermined transparency and public trust, particularly in high-stakes applications such as finance, healthcare, and digital public services. Explainable AI (XAI) has emerged to address this gap by making model reasoning interpretable, yet explainability alone cannot guarantee fairness without verifiable systems of identity and accountability. This study proposes a framework that integrates explainable deep learning with decentralized identity (DID) systems to combat bias, enhance trust, and ensure equitable governance outcomes. In this framework, explainable deep learning models provide human-understandable insights into algorithmic decisions, enabling stakeholders to evaluate reasoning processes. Meanwhile, decentralized identity systems built on blockchain technologies ensure that individuals retain control over their digital identities, reducing risks of centralized manipulation and exclusion. By linking interpretable models with verifiable identity protocols, algorithmic governance can achieve both transparency and fairness while protecting privacy. The integration enables bias detection and correction at both the model and system levels: interpretable models flag discriminatory features, while decentralized identity guarantees equitable access across diverse populations. Applications in digital voting, welfare distribution, and credit scoring illustrate how the framework strengthens accountability and prevents systemic marginalization. Ultimately, combining explainable deep learning with decentralized identity provides a path toward trustworthy and fair algorithmic governance, where decisions are not only accurate but also transparent, inclusive, and ethically aligned with societal values.",
    "doi": "10.30574/wjarr.2024.21.2.0595",
    "url": "https://www.semanticscholar.org/paper/42451898b9c9b5c9c6a65614ac5f2e7e8be8d93b",
    "pdf_url": "",
    "venue": "World Journal of Advanced Research and Reviews",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140637"
  },
  {
    "source": "semantic_scholar",
    "source_id": "9534e6b18c015575f7f49d5a1252c6a854a690d7",
    "title": "Ethics and governance of trustworthy medical artificial intelligence",
    "authors": [
      "Jie Zhang",
      "Zong-Ming Zhang"
    ],
    "year": 2023,
    "abstract": "Background The growing application of artificial intelligence (AI) in healthcare has brought technological breakthroughs to traditional diagnosis and treatment, but it is accompanied by many risks and challenges. These adverse effects are also seen as ethical issues and affect trustworthiness in medical AI and need to be managed through identification, prognosis and monitoring. Methods We adopted a multidisciplinary approach and summarized five subjects that influence the trustworthiness of medical AI: data quality, algorithmic bias, opacity, safety and security, and responsibility attribution, and discussed these factors from the perspectives of technology, law, and healthcare stakeholders and institutions. The ethical framework of ethical values-ethical principles-ethical norms is used to propose corresponding ethical governance countermeasures for trustworthy medical AI from the ethical, legal, and regulatory aspects. Results Medical data are primarily unstructured, lacking uniform and standardized annotation, and data quality will directly affect the quality of medical AI algorithm models. Algorithmic bias can affect AI clinical predictions and exacerbate health disparities. The opacity of algorithms affects patients\u2019 and doctors\u2019 trust in medical AI, and algorithmic errors or security vulnerabilities can pose significant risks and harm to patients. The involvement of medical AI in clinical practices may threaten doctors \u2018and patients\u2019 autonomy and dignity. When accidents occur with medical AI, the responsibility attribution is not clear. All these factors affect people\u2019s trust in medical AI. Conclusions In order to make medical AI trustworthy, at the ethical level, the ethical value orientation of promoting human health should first and foremost be considered as the top-level design. At the legal level, current medical AI does not have moral status and humans remain the duty bearers. At the regulatory level, strengthening data quality management, improving algorithm transparency and traceability to reduce algorithm bias, and regulating and reviewing the whole process of the AI industry to control risks are proposed. It is also necessary to encourage multiple parties to discuss and assess AI risks and social impacts, and to strengthen international cooperation and communication.",
    "doi": "10.1186/s12911-023-02103-9",
    "url": "https://www.semanticscholar.org/paper/9534e6b18c015575f7f49d5a1252c6a854a690d7",
    "pdf_url": "https://bmcmedinformdecismak.biomedcentral.com/counter/pdf/10.1186/s12911-023-02103-9",
    "venue": "BMC Medical Informatics and Decision Making",
    "citation_count": 284,
    "fields_of_study": [
      "Computer Science",
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140639"
  },
  {
    "source": "semantic_scholar",
    "source_id": "78de9c493c6b9a93492df504d784d001459b7858",
    "title": "Ethics for Artificial Intelligence, Ethics for All",
    "authors": [
      "Knud Thomsen"
    ],
    "year": 2019,
    "abstract": "Abstract For human ethics, it can convincingly be argued that justice is a central cornerstone and basis. Here, it is suggested that this can, to some extent, similarly be applied to robots. The article makes the argument that Rawls\u2019 veil of ignorance in his conception of justice as fairness can effectively be replaced by a much more natural condition of prudent egoism in a finite world. Observing ones\u2019 own important interests in an encompassing context paves the way for a guideline for the conduct, which is binding for humans, robots and each and every pragmatic agent with a minimum level of rationality. These arguments do not see humans (forever) in any privileged position: any agent, single human, state, alien or artificial with a certain minimum of general cognitive (and effective) capabilities is bound by a universal negative imperative. This entails that precautious procedures are preferable, and some general prudently constrained flexibility is required for self-consistency and survival.",
    "doi": "10.1515/pjbr-2019-0029",
    "url": "https://www.semanticscholar.org/paper/78de9c493c6b9a93492df504d784d001459b7858",
    "pdf_url": "https://www.degruyter.com/downloadpdf/journals/pjbr/10/1/article-p359.pdf",
    "venue": "Paladyn J. Behav. Robotics",
    "citation_count": 9,
    "fields_of_study": [
      "Computer Science",
      "Psychology"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140641"
  },
  {
    "source": "semantic_scholar",
    "source_id": "a58796b7403268d4d70d457fd7f1ef5f153ee9f0",
    "title": "Barriers and Enablers in Integrating AI into Human Resource Management Strategies: Maximizing Human Capital",
    "authors": [
      "Dr. U. Amaleshwari, R. Shanmugapriya"
    ],
    "year": 2024,
    "abstract": "Artificial intelligence (AI) has shaken the foundation of modern workplaces like never before and has induced digitized workstyles within the organisation. These furtherance in technology are generating significant interest among stakeholders to embrace AI in human resource management (HRM). Research and Development teams, analysts and practitioners are keen to investigate the sequel of AI in HR and their collaboration with gadget applications involving machine language, Data-science, Blockchain and Big Data. This study investigates HRM specific factors that are imbibed towards adoption of AI in extended HR based digital platform adopting a qualitative research design with an abductive approach. This research also investigates key enablers like optimistic, enthusiastic, and collaborative employees, strong digital enabled leadership, reliable HR meta-data, specialized HR partners, and well-rounded accountable AI ethics. The study also examines barriers towards awareness in AI adoption: the inability to have a timely internal audit pulse check of employees, their ability of emotional decision making, ineffective agile digital experts as well as external HR partners. On summarising, this study also contributes theory by providing a model that influences AI adoption and proposes ascending in welcoming unified theory of acceptance and use of innovative technology in the context of AI adoption in HR upskilling and reskilling ecosystems eventually. The study also contributes the anecdotes of best-in-class industrial HR practices with secured digital policy formulation to reimagine cybermated workplaces cubical. Maximising the human capital in the digital era be obliged in harmonious conglomerative human\u2013AI enterprise making workplaces an eminent future-ready in the wake of productive and massive successful digital disruptions with efficacy. \n\u00a0",
    "doi": "10.52783/eel.v14i1.1295",
    "url": "https://www.semanticscholar.org/paper/a58796b7403268d4d70d457fd7f1ef5f153ee9f0",
    "pdf_url": "https://eelet.org.uk/index.php/journal/article/download/1295/1115",
    "venue": "European Economic Letters (EEL)",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140642"
  },
  {
    "source": "semantic_scholar",
    "source_id": "b5c00cb5e31924070b6442adb1c6771a03578594",
    "title": "A cloud-based architecture for explainable Big Data analytics using self-structuring Artificial Intelligence",
    "authors": [
      "Nishan Mills",
      "Zafar Issadeen",
      "Amali Matharaarachchi",
      "T. Bandaragoda",
      "Daswin De Silva",
      "Andrew Jennings",
      "Milos Manic"
    ],
    "year": 2024,
    "abstract": "Big Data is steadily expanding beyond the boundaries of its foundational constructs of three primary Vs, Volume, Velocity and Variety, and two secondary Vs, Veracity and Value. The advent of 5G networks, Edge computing and IoT technologies has transformed Big Data into this modern context. With these new manifestations of Big Data, the focus is not only on the data itself but on the context that it applies to its immediate environment as well as the human and societal perception of this context. It is increasingly challenging for conventional AI algorithms to process and transform this data, analyse and visualise a broad spectrum of insights, and then formulate the explainability of such insights in terms of bias, transparency, safety, ethics, and causality. Self-structuring Artificial Intelligence (SSAI) addresses the limitations of conventional AI by adapting to the inherent structure of the data, incrementally learning and abstracting from this structure. SSAI has not been investigated in a cloud-based setting for generating explainable insights from these new types of Big Data. In this paper we propose a cloud-based architecture for explainable Big Data analytics using SSAI in highly-connected 5G and Edge computing environments. The proposed architecture is empirically evaluated on a commercial scale Big Data use case of Smart Grid for Smart Cities. The results of these experiments confirm the functionality and effectiveness of the proposed architecture.",
    "doi": "10.1007/s44163-024-00123-6",
    "url": "https://www.semanticscholar.org/paper/b5c00cb5e31924070b6442adb1c6771a03578594",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s44163-024-00123-6.pdf",
    "venue": "Discover Artificial Intelligence",
    "citation_count": 6,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140643"
  },
  {
    "source": "semantic_scholar",
    "source_id": "5168acd455cf906cc1e44facdb34a33c35ae4ab6",
    "title": "Understanding Recruiters\u2019 Acceptance of Artificial Intelligence: Insights from the Technology Acceptance Model",
    "authors": [
      "Filomena Almeida",
      "Ana Jun\u00e7a Silva",
      "Sara L. Lopes",
      "Isabel Braz"
    ],
    "year": 2025,
    "abstract": "The integration of new technologies in professional contexts has emerged as a critical determinant of organizational efficiency and competitiveness. In this regard, the application of Artificial Intelligence (AI) in recruitment processes facilitates faster and more accurate decision-making by processing large volumes of data, minimizing human bias, and offering personalized recommendations to enhance talent development and candidate selection. The Technology Acceptance Model (TAM) provides a valuable framework for understanding recruiters\u2019 perceptions of innovative technologies, such as AI tools and GenAI. Drawing on the TAM, a model was developed to explain the intention to use AI tools, proposing that perceived ease of use and perceived usefulness influence attitudes toward AI, which subsequently affect the intention to use AI tools in recruitment and selection processes. Two studies were conducted in Portugal to address this research objective. The first was a qualitative exploratory study involving 100 interviews with recruiters who regularly utilize AI tools in their professional activities. The second study employed a quantitative confirmatory approach, utilizing an online questionnaire completed by 355 recruiters. The qualitative findings underscored the transformative role of AI in recruitment, emphasizing its potential to enhance efficiency and optimize resource management. However, recruiters also highlighted concerns regarding the potential loss of personal interaction and the need to adapt roles within this domain. The results also supported the indirect effect of perceived ease of use and perceived usefulness on the use of AI tools in recruitment and selection processes via positive attitudes toward the use of these tools. This suggests that AI is best positioned as a complementary tool rather than a replacement for human decision-making. The insights gathered from recruiters\u2019 perspectives provide actionable recommendations for organizations seeking to leverage AI in recruitment processes. Specifically, the findings show the importance of ethical considerations and maintaining human involvement to ensure a balanced and effective integration of AI tools.",
    "doi": "10.3390/app15020746",
    "url": "https://www.semanticscholar.org/paper/5168acd455cf906cc1e44facdb34a33c35ae4ab6",
    "pdf_url": "https://doi.org/10.3390/app15020746",
    "venue": "Applied Sciences",
    "citation_count": 21,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140645"
  },
  {
    "source": "semantic_scholar",
    "source_id": "20d98ea79c7b108bcc07aeb4fa4f152948919d53",
    "title": "Artificial Intelligence in Performance Evaluation (Case Study of PT. Pos Indonesia Employees)",
    "authors": [
      "Agung Dwianto",
      "Sitta Kusuma",
      "Junengsih"
    ],
    "year": 2024,
    "abstract": "The development of artificial intelligence (AI) has revolutionized various aspects of human resource management, including employee performance evaluation. While existing studies have extensively explored the potential of AI in improving efficiency and objectivity, they often overlook the nuanced employee experiences and organizational dynamics that influence its successful implementation. This research bridges this gap by examining the perceptions and experiences of PT Pos Indonesia employees regarding the use of an AI-based performance evaluation system. Using a qualitative approach with a phenomenological design, data was collected through in-depth interviews with employees who have used the system for at least six months. The findings reveal that AI contributes significantly to enhancing efficiency and reducing subjectivity in evaluations. However, challenges such as algorithm bias, the relevance of performance metrics, and system transparency remain prevalent. Importantly, this study identifies critical factors influencing acceptance, including employee understanding, trust, and perceptions of fairness in the evaluation process. Unlike previous research, this study emphasizes the interplay between technological and human factors, highlighting the irreplaceable role of human interaction in providing qualitative context. This research extends the existing literature by offering a deeper understanding of employee-centered factors and organizational practices that facilitate the integration of AI in performance evaluation. Practically, it provides actionable insights for organizations aiming to implement AI-based systems effectively, ethically, and equitably.",
    "doi": "10.32877/bt.v7i2.1817",
    "url": "https://www.semanticscholar.org/paper/20d98ea79c7b108bcc07aeb4fa4f152948919d53",
    "pdf_url": "",
    "venue": "bit-Tech",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140646"
  },
  {
    "source": "semantic_scholar",
    "source_id": "a4acf62a6dcc898e77f6a7f0dea11bda6451611a",
    "title": "The Applications of Artificial Intelligence in Human Resources",
    "authors": [
      "Priyal Gordiya"
    ],
    "year": 2024,
    "abstract": "The study examines the transformative role of artificial intelligence in Human resources and its profound implications for the future of workforce management. Questionnaires are used to evaluate the current perception, applications & adoption of artificial intelligence in human resources practices, as well as its potential impact and ability to shape tomorrow's Human Resource landscape. Understanding of how people view the integration of AI in human resources functions, by rigorously analysing questionnaire responses. These findings reveal the apprehensions, expectations and acceptance levels of AI driven human resource management processes. In addition, important foresight is provided on the evolution of technology and Human Capital dynamics within organisational structures. Moreover, a compelling case study is presented to demonstrate the effectiveness of AI when it comes to human resource management on an actual basis. The case study shows how AI solutions simplify recruitment, enhance employee engagement, optimise talent management and mitigate biases in the decision making process for a more agile, data driven environment that is inclusive. Finally, this research aims at breaking down the complex implications of artificial intelligence for human resources and providing information on its transformative potential which will make it easier to adopt effective decisions as part of organisational HR strategies. Keywords: Artificial Intelligence, Human Resources, Case Study, Perception, Awareness",
    "doi": "10.55041/isjem01599",
    "url": "https://www.semanticscholar.org/paper/a4acf62a6dcc898e77f6a7f0dea11bda6451611a",
    "pdf_url": "",
    "venue": "International Scientific Journal of Engineering and Management",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140648"
  },
  {
    "source": "semantic_scholar",
    "source_id": "03e4a19eff4063130d0f46affc11297fb8ef0895",
    "title": "Balcerzak, Michal and Julia Kapela\u0144ska-Pr\u0119gowska, eds. 2024. Artificial Intelligence and International Human Rights Law. Developing Standards for a Changing World",
    "authors": [
      "Itziar Art\u00ed\u00f1ano Ortiz"
    ],
    "year": 2024,
    "abstract": "This work analyzes the intersections between artificial intelligence (AI) and human rights from an international perspective. It analyzes the regulatory efforts of essential entities such as the United Nations, the Council of Europe, and the European Union. Recent initiatives that aim to establish ethical and legal standards to address the risks associated with AI are highlighted. Mass surveillance, algorithmic bias, and privacy violations stand out among these aspects. The book takes a unique approach, integrating a normative perspective with analyses of specific cases to examine the impact of artificial intelligence in key areas such as justice, health, labor rights, and privacy. It delves into challenges such as video manipulation, facial recognition regulations, and ethical conflicts in applying autonomous technologies in international settings. The book underscores the necessity of a flexible legal framework that accommodates technological advances while upholding fundamental rights. It also underscores the need to strengthen the responsibility of states and private entities to protect these rights. This volume is a fundamental reference point in the creation of international norms that ensure artificial intelligence respects human rights and proactively participates in their promotion in a globalized and constantly evolving world. Its insights are invaluable in the field of AI ethics and human rights.",
    "doi": "10.18543/djhr.3200",
    "url": "https://www.semanticscholar.org/paper/03e4a19eff4063130d0f46affc11297fb8ef0895",
    "pdf_url": "",
    "venue": "Deusto Journal of Human Rights",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140649"
  },
  {
    "source": "semantic_scholar",
    "source_id": "f144e643f65fb4965f01dceac011152d0aa912d9",
    "title": "A Report Review: Artificial Intelligence and the Future of Teaching and Learning",
    "authors": [
      "Weny Kritandani",
      "R. Aryani",
      "Tetta Rakasiwi"
    ],
    "year": 2024,
    "abstract": "This review provides an insightful overview of \"Artificial Intelligence and the Future of Teaching and Learning,\" a policy report by the United States Department of Education. Keywords such as Artificial Intelligence (AI) development, policy-making, ethics, equity, collaboration, and human-centric approach are emphasised throughout. The review highlights the report's comprehensive analysis, actionable recommendations, and emphasis on inclusive policy-making processes. It underscores the significance of understanding AI's multifaceted nature, its potential to enhance education, and the importance of safeguarding privacy and equity. Practical examples and case studies are discussed, along with recommendations for aligning AI with educational goals. Overall, the review positions the report as a valuable resource for policymakers, educators, and technology developers, guiding them toward responsible AI integration in education.",
    "doi": "10.17977/um043v6i2p245-253",
    "url": "https://www.semanticscholar.org/paper/f144e643f65fb4965f01dceac011152d0aa912d9",
    "pdf_url": "https://journal2.um.ac.id/index.php/irbej/article/download/51618/12925",
    "venue": "International research-based education journal",
    "citation_count": 9,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140651"
  },
  {
    "source": "semantic_scholar",
    "source_id": "7526ec41d691039bd104afd2039fdb5f7e41d55f",
    "title": "Ethics of the Use of Artificial Intelligence (AI) in the Paradigm of Islamic Law",
    "authors": [
      "Mulki Firdaus Alamsyah",
      "Yayuli",
      "Ahmad Remanda"
    ],
    "year": 2025,
    "abstract": "Objective: The principal objective of this scholarly inquiry is to meticulously examine the ethical implications of artificial intelligence (AI) within the context of Islamic jurisprudence, with a distinct focus on the principles of maqosid al-shari\u2018ah (the paramount objectives of Islamic law) serving as a moral and legal foundation for the evaluation of AI applications. Theoretical framework: The theoretical foundations of this investigation are derived from Islamic legal and ethical philosophy, specifically the five fundamental values of maqosid al-shari\u2018ah, safeguarding of faith, life, intellect, lineage, and property employed as evaluative criteria to assess the integration of technology within Muslim societies. Literature review: A diverse array of primary sources, including the Qur\u2019an and Hadith, is meticulously scrutinized alongside contemporary Islamic scholarship that addresses the intersection of ethics and technology. Previous research on Islamic ethics in the digital and biomedical spheres is referenced, elaborated upon, and critically appraised to ensure a contemporary and contextually relevant analysis. Methods: This investigation adopts a qualitative methodology based on an exhaustive literature review. Primary religious texts and secondary academic discourses concerning AI ethics and Islamic law are analyzed through thematic content analysis to develop a normative framework that harmonizes Shariah principles with emerging AI technologies. Results: The findings of this research indicate that while AI offers substantial benefits in areas such as healthcare, education, and governance, it simultaneously presents ethical challenges, including issues related to surveillance, algorithmic bias, and a reduction in human accountability. From an Islamic standpoint, AI should not replace human moral agency but rather enhance it. Justice, accountability, and the welfare of the community must remain of utmost importance in its application. Implications: This study highlights the urgent need for interdisciplinary dialogue between Islamic scholars and technology developers, the promotion of Islamic ethical awareness among Muslim AI practitioners, and the establishment of fatwas and Shariah-compliant regulatory frameworks to ensure the ethical incorporation of AI into Muslim societies. Novelty: This research offers a noteworthy contribution to the burgeoning field of Islamic AI ethics by providing a structured, Shariah-aligned ethical framework for the assessment and guidance of AI technologies. It underscores the adaptability of Islamic jurisprudence in addressing contemporary innovations while remaining steadfastly anchored in enduring ethical principles.",
    "doi": "10.61455/sicopus.v4i01.393",
    "url": "https://www.semanticscholar.org/paper/7526ec41d691039bd104afd2039fdb5f7e41d55f",
    "pdf_url": "",
    "venue": "Solo International Collaboration and Publication of Social Sciences and Humanities",
    "citation_count": 4,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140652"
  },
  {
    "source": "semantic_scholar",
    "source_id": "d59c2a543b146c80bea4a46b26c6647552cdc9ba",
    "title": "Ethical gaps in the ethics of artificial intelligence",
    "authors": [
      "Vasilii Andreevich Avdyunin"
    ],
    "year": 2025,
    "abstract": "The development of neural networks and their active implementation in various spheres of the economy have raised the challenge of ethical evaluation and legal regulation of the development and application of artificial intelligence (AI) systems. Over the last decade, more than 200 ethical codes and recommendations have been created worldwide, which are actively discussed within the framework of scientific research. The majority of these documents are based on a principle-based approach that sets the boundaries of ethics in the field of AI. This article examines the ethical gaps in artificial intelligence ethics through the development of a multi-level system of strategies to overcome them. The subject of the research is specific mechanisms and strategies for transforming abstract ethical principles into functioning practices at each level. This article discusses the main approaches to addressing issues in artificial intelligence ethics. A systemic approach is proposed as a methodological basis, integrating technical solutions, organizational changes, and legal mechanisms. The applicability of the proposed approach is demonstrated through the analysis of key ethical issues in AI: systematic reproduction of biases, the \"black box\" problem, distribution of responsibility, the declarative nature of ethical and legal norms, and the challenges of responsibility attribution. For each problem, specific methods of resolution are outlined - from the creation of counterfactual fairness algorithms to checklists for assessing the ethics of AI systems. Conclusions are drawn that a three-level \"filter\" system is necessary for systematically addressing ethical gaps in AI ethics, which involves differentiating approaches at the development level, organizational changes, creating new principles for state regulation, and a shift in the paradigm of responsibility distribution. The main conclusion of the research is the need for a comprehensive systemic approach, where the rigor of regulation is proportional to the potential harm from the use of the AI system.",
    "doi": "10.25136/2409-8728.2025.12.77033",
    "url": "https://www.semanticscholar.org/paper/d59c2a543b146c80bea4a46b26c6647552cdc9ba",
    "pdf_url": "",
    "venue": "\u0424\u0438\u043b\u043e\u0441\u043e\u0444\u0441\u043a\u0430\u044f \u043c\u044b\u0441\u043b\u044c",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140654"
  },
  {
    "source": "semantic_scholar",
    "source_id": "61f22b225b278259e978235e41dce4811f6e9bea",
    "title": "The Anchoring Effect, Algorithmic Fairness, and the Limits of Information Transparency for Emotion Artificial Intelligence",
    "authors": [
      "Lauren Rhue"
    ],
    "year": 2023,
    "abstract": "Emotion artificial intelligence (AI) is shown to vary systematically in its ability to accurately identify emotions, and this variation creates potential biases. In this paper, we conduct an experiment involving three commercially available emotion AI systems and a group of human labelers tasked with identifying emotions from two image data sets. The study focuses on the alignment between facial expressions and the emotion labels assigned by both the AI and humans. Importantly, human labelers are given the AI\u2019s scores and informed about its algorithmic fairness measures. This paper presents several key findings. First, the labelers\u2019 scores are affected by the emotion AI scores, consistent with the anchoring effect. Second, information transparency about the AI\u2019s fairness does not uniformly affect human labeling across different emotions. Moreover, information transparency can even increase human inconsistencies. Plus, significant inconsistencies in the scoring among different emotion AI models cast doubt on their reliability. Overall, the study highlights the limitations of individual decision making and information transparency regarding algorithmic fairness measures in addressing algorithmic fairness. These findings underscore the complexity of integrating emotion AI into practice and emphasize the need for careful policies on emotion AI.",
    "doi": "10.1287/isre.2019.0493",
    "url": "https://www.semanticscholar.org/paper/61f22b225b278259e978235e41dce4811f6e9bea",
    "pdf_url": "",
    "venue": "Information systems research",
    "citation_count": 22,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140655"
  },
  {
    "source": "semantic_scholar",
    "source_id": "11d2e9cd96039efc734b5baf25e38f7640c79435",
    "title": "ETHICS AND RESPONSIBILITY IN THE IMPLEMENTATION OF ARTIFICIAL INTELLIGENCE IN JUSTICE",
    "authors": [
      "Volodymyr Zverev",
      "V. Bushkov",
      "B. Khrushkov",
      "Andriy Shavolin",
      "Serhiy Smyshlyaev",
      "Yehor Prokopovych-Tkachenko"
    ],
    "year": 2025,
    "abstract": "The article examines the complex challenges and prospects arising from the implementation of artificial intelligence (AI) in the justice system. The growing role of automated algorithms in legal procedures demonstrates the intention to increase the efficiency of judicial proceedings and optimize the work of law enforcement agencies. At the same time, the use of AI can give rise to a number of ethical, legal and technical problems, particularly issues of transparency, accountability, algorithmic discrimination and biases that manifest in judicial practice and law enforcement processes. The article analyzes scientific approaches to the formation of principles of accountability when making AI decisions and proposes theoretical and practical guidelines for developing the transparency and reliability of intelligent algorithms in the legal sphere. Considerable attention is paid to the research methodology, which combines formal-legal and empirical methods, as well as algorithmic modeling and machine learning tools. The \u201cResults\u201d section provides examples of quantitative analyses and compares the effectiveness of different approaches to the application of AI in jurisprudence. Visualizations and tables demonstrate statistical information and features of the integration of AI into judicial procedures and legal practice. The \u201cDiscussion\u201d highlights the theoretical and practical aspects of the developing of an ethics code and legal regulation possibilities, considering diverse challenges. It is concluded that for the effective implementation of AI in justice, wholesome models of transparency, independent auditing and regulatory mechanisms should be developed that also consider the specifics of the judicial system, human rights and the protection of confidential information. Proposals are formulated to establish the responsibility of developers, users and government agencies.",
    "doi": "10.69635/ciai.2025.10",
    "url": "https://www.semanticscholar.org/paper/11d2e9cd96039efc734b5baf25e38f7640c79435",
    "pdf_url": "",
    "venue": "Contemporary Issues in Artificial Intelligence",
    "citation_count": 2,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140656"
  },
  {
    "source": "semantic_scholar",
    "source_id": "2f43f82828c430d283e6531bcce62019ea0f59a4",
    "title": "Evolving uses of artificial intelligence in human resource management in emerging economies in the global South: some preliminary evidence",
    "authors": [
      "N. Kshetri"
    ],
    "year": 2021,
    "abstract": "Purpose: The purpose of this paper is to examine the use of artificial intelligence (AI) in human resource management (HRM) in the Global South. Design/methodology/approach: Multiple case studies of AI tools used in HRM in these countries in recruiting and selecting as well as developing, retaining and productively utilizing employees have been used. Findings: With AI deployment in HRM, organizations can enhance efficiency in recruitment and selection and gain access to a larger recruitment pool. With AI deployment in HRM, subjective criteria such as nepotism and favoritism are less likely to come into play in recruitment and selection of employees. AI deployment in HRM also has a potentially positive impact on the development, retainment and productive utilization of employees. Research limitations/implications: AI is an evolving technology. Most HRM apps have not gained enough machine learning capabilities with real-world experience. Some of them lack a scientific basis. AI in HRM thus currently affects only a tiny proportion of the population in the GS. Practical implications: The paper explores the roles of AI in expanding recruitment pools. It also advances our understanding of how AI-based HIRM tools can help reduce biases in selecting candidates, which is especially important in the Global South. It also delves into various mechanisms by which AI helps in the development, retainment and productive utilization of employees. Originality/value: We provide details of various mechanisms by which AI brings input and output efficiencies in recruitment and selection in these countries.",
    "doi": "10.1108/mrr-03-2020-0168",
    "url": "https://www.semanticscholar.org/paper/2f43f82828c430d283e6531bcce62019ea0f59a4",
    "pdf_url": "http://libres.uncg.edu/ir/uncg/f/N_Kshetri_Evolving_2021.pdf",
    "venue": "",
    "citation_count": 88,
    "fields_of_study": [
      "Business"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140658"
  },
  {
    "source": "semantic_scholar",
    "source_id": "cbd7be183791cd2ce31d5533b8050c4922dc45df",
    "title": "ETHICS AND ADVANCEMENT OF ARTIFICIAL INTELLIGENCE IN INTERNATIONAL HR-MANAGEMENT: RISKS AND WAYS TO MINIMIZE THEM",
    "authors": [
      "T. Aizenberg"
    ],
    "year": 2025,
    "abstract": "The article explores the ethical aspects of using artificial intelligence (AI) in international HR management, with a particular focus on the risks of discrimination that may arise from the use of historical data. The authors analyze the impact of AI algorithms on key HR processes, including hiring, promotion, and performance evaluation. It is found that automated systems can unconsciously reproduce biases inherent in the original data sets, which can lead to unequal treatment of candidates and employees. \nSpecial attention is paid to the problems of algorithm transparency, personal data protection, and injustice in automated HR systems. An important aspect is the issue of trust in algorithmic solutions, their explainability, and compliance with international standards of ethics and regulation. The lack of clarity and complexity of algorithms can lead to situations where HR professionals cannot explain the reasons for making a decision, which, in turn, reduces the trust in the use of AI in HR management. \nThe article suggests methods to minimize the risks of bias, including careful selection and adjustment of initial data, auditing algorithms for discriminatory factors, ensuring transparency of decision-making processes, and applying a hybrid approach that combines automated systems with human control. In addition, the authors emphasize the importance of adhering to ethical standards and international norms when developing and implementing AI in HR processes. \nAn important aspect of the study is the need to train HR professionals in the principles of working with AI, understanding its capabilities and limitations, as well as methods for identifying and correcting potentially unfair algorithmic decisions. Training and professional development of HR managers in the field of ethical use of AI will help to form a more responsible approach to its application. \nThe author also notes that in order to ensure the effective and fair use of AI in HR, it is necessary to continue developing regulatory frameworks and corporate policies. This will not only minimize the potential risks of discrimination but will also help to increase the overall trust in automated HR solutions. The development of regulatory documents, standardization of approaches to auditing algorithms, and improvement of mechanisms for assessing their ethics are key elements for further integration of AI in HR at the international level.",
    "doi": "10.33989/2226-4051.2025.31.331532",
    "url": "https://www.semanticscholar.org/paper/cbd7be183791cd2ce31d5533b8050c4922dc45df",
    "pdf_url": "",
    "venue": "Aesthetics and Ethics of Pedagogical Action",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140660"
  },
  {
    "source": "semantic_scholar",
    "source_id": "e735a029f453ce06fffb27b75e2cbf29566bfaf5",
    "title": "Development of a Method for Ensuring Fairness of an Artificial Intelligence System in the Implementation Process",
    "authors": [
      "Yejin Shin",
      "KyoungWoo Cho",
      "Joon Ho Kwak",
      "Jaeyoung Hwang"
    ],
    "year": 2022,
    "abstract": "Artificial intelligence (AI) technology is becoming common in daily life as it finds applications in various fields. Consequently, studies have strongly focused on the reliability of AI technology to ensure that it will be used ethically and in a nonmalicious manner. In particular, the fairness of AI technology should be ensured to avoid problems such as discrimination against a certain group (e.g., racial discrimination). This paper defines seven requirements for eliminating factors that reduce the fairness of AI systems in the implementation process. It also proposes a measure to reduce the bias and discrimination that can occur during AI system implementation to ensure the fairness of AI systems. The proposed requirements and measures are expected to enhance the fairness and ensure the reliability of AI systems and to ultimately increase the acceptability of AI technology in human society.",
    "doi": "10.1109/ICTC55196.2022.9952891",
    "url": "https://www.semanticscholar.org/paper/e735a029f453ce06fffb27b75e2cbf29566bfaf5",
    "pdf_url": "",
    "venue": "Information and Communication Technology Convergence",
    "citation_count": 1,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140661"
  },
  {
    "source": "semantic_scholar",
    "source_id": "d52ede1dd9c2f5d9dee8f6fae4203304b18bbdc8",
    "title": "Artificial Intelligence Ethics Taxonomy - Robotic Process Automation (RPA) as Business Case",
    "authors": [
      "D. Beerbaum"
    ],
    "year": 2021,
    "abstract": "A Robotic Process Automation (RPA) enabled by Artificial intelligence (AI) has become an important field within the digitalisation of the economy. AI-driven robots and machines are forecasted to grow dramatically in the next years. AI-enabled RPA replaces the work a human would normally do by mimicking interactions with applications and provides direct access to systems using APIs. RPA has superior advantages versus human execution:24x7 execution, eternal lifetime and scalability. Process automatization is per se not a brand-new technology, however due to notable progress in AI, which RPAleverages, it has become an own solution category. RPA enables algorithmic rules without being biased. \n \nEthical considerations intend to make AI-driven RPA more human and introduce morality into the machine learning. The Uber-Waymo trial made transparent how much AI development is influenced by human irrationality and irrational exuberances. It reveals a culture of agile software development, which prioritize releasing the latest software over testing and verification, and one that encourages shortcuts and irrationality. This also give proof that applying AI cannot ensure that irrational exuberances disappear. The reason for this irrational exuberance may have its roots in the exponential growth in computing and storage \n \ntechnologies predicted by Gordon Moore five decades ago. This paper develops a concept how irrational exuberances with the business case of RPA can be prevented from happening. One general approach for solutioning of the issue is to increase transparency. The paper recommends applying technology to make data more accessible and more readable on the application of artificial intelligence. With the aim of application of \u201ctransparency technology XBRL (eXtensible Business Reporting Language)\u201d is incorporated. XBRL is part of the choice architecture on regulation by governments (Sunstein, 2013). XBRL is connected to a taxonomy. The paper develops a taxonomy for RPA to make application of artificial intelligence more transparent to the public and incorporates ethical considerations. As a business case the strongly growing RPA industry is selected. The paper focus on the way to enhance AI that aligns with human values. How can incentive be provided that AI systems themselves do not become potential objects of moral concern. The main outcome of the paper is that AI-enabled RPA reveal moral concerns however transparency technologies at the same time also offer way to mitigate such risks.",
    "doi": "10.2139/SSRN.3834361",
    "url": "https://www.semanticscholar.org/paper/d52ede1dd9c2f5d9dee8f6fae4203304b18bbdc8",
    "pdf_url": "",
    "venue": "",
    "citation_count": 13,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140663"
  },
  {
    "source": "semantic_scholar",
    "source_id": "91b99d1651b776cab4e16f54f7fbffc117ae82f7",
    "title": "Artificial intelligence-based clinical decision support for liver transplant evaluation and considerations about fairness: A qualitative study",
    "authors": [
      "Alexandra T. Strauss",
      "Carolyn N. Sidoti",
      "Hannah C. Sung",
      "Vedant Jain",
      "Harold Lehmann",
      "Tanjala S. Purnell",
      "John W. Jackson",
      "Daniel Malinsky",
      "James P. Hamilton",
      "J. Garonzik\u2010Wang",
      "Stephen H Gray",
      "M. Levan",
      "J. Hinson",
      "Ayse P. Gurses",
      "A. Gurakar",
      "D. Segev",
      "Scott Levin"
    ],
    "year": 2023,
    "abstract": "Background: The use of large-scale data and artificial intelligence (AI) to support complex transplantation decisions is in its infancy. Transplant candidate decision-making, which relies heavily on subjective assessment (ie, high variability), provides a ripe opportunity for AI-based clinical decision support (CDS). However, AI-CDS for transplant applications must consider important concerns regarding fairness (ie, health equity). The objective of this study was to use human-centered design methods to elicit providers\u2019 perceptions of AI-CDS for liver transplant listing decisions. Methods: In this multicenter qualitative study conducted from December 2020 to July 2021, we performed semistructured interviews with 53 multidisciplinary liver transplant providers from 2 transplant centers. We used inductive coding and constant comparison analysis of interview data. Results: Analysis yielded 6 themes important for the design of fair AI-CDS for liver transplant listing decisions: (1) transparency in the creators behind the AI-CDS and their motivations; (2) understanding how the AI-CDS uses data to support recommendations (ie, interpretability); (3) acknowledgment that AI-CDS could mitigate emotions and biases; (4) AI-CDS as a member of the transplant team, not a replacement; (5) identifying patient resource needs; and (6) including the patient\u2019s role in the AI-CDS. Conclusions: Overall, providers interviewed were cautiously optimistic about the potential for AI-CDS to improve clinical and equitable outcomes for patients. These findings can guide multidisciplinary developers in the design and implementation of AI-CDS that deliberately considers health equity.",
    "doi": "10.1097/HC9.0000000000000239",
    "url": "https://www.semanticscholar.org/paper/91b99d1651b776cab4e16f54f7fbffc117ae82f7",
    "pdf_url": "https://doi.org/10.1097/hc9.0000000000000239",
    "venue": "Hepatology Communications",
    "citation_count": 12,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140665"
  },
  {
    "source": "semantic_scholar",
    "source_id": "ee1141959004443596ceec788ce87dda23049b87",
    "title": "Human Services Organizations and the Responsible Integration of AI: Considering Ethics and Contextualizing Risk(s)",
    "authors": [
      "Brian E. Perron",
      "Lauri Goldkind",
      "Zia Qi",
      "Bryan Victor"
    ],
    "year": 2025,
    "abstract": "Abstract This paper examines the responsible integration of artificial intelligence (AI) in human services organizations (HSOs), proposing a nuanced framework for evaluating AI applications across multiple dimensions of risk. The authors argue that ethical concerns about AI deployment\u2014including professional judgment displacement, environmental impact, model bias, and data laborer exploitation\u2014vary significantly based on implementation context and specific use cases. They challenge the binary view of AI adoption, demonstrating how different applications present varying levels of risk that can often be effectively managed through careful implementation strategies. The paper highlights promising solutions, such as local large language models, that can facilitate responsible AI integration while addressing common ethical concerns. The authors propose a dimensional risk assessment approach that considers factors like data sensitivity, professional oversight requirements, and potential impact on client wellbeing. They conclude by outlining a path forward that emphasizes empirical evaluation, starting with lower-risk applications and building evidence-based understanding through careful experimentation. This approach enables organizations to maintain high ethical standards while thoughtfully exploring how AI might enhance their capacity to serve clients and communities effectively.",
    "doi": "10.1080/15228835.2025.2457045",
    "url": "https://www.semanticscholar.org/paper/ee1141959004443596ceec788ce87dda23049b87",
    "pdf_url": "",
    "venue": "Journal of technology in human services",
    "citation_count": 6,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140666"
  },
  {
    "source": "semantic_scholar",
    "source_id": "54db901155a8d8f16cf271d08b5bcdd31301203e",
    "title": "The Application of Artificial Intelligence in Health Care Resource Allocation Before and During the COVID-19 Pandemic: Scoping Review",
    "authors": [
      "Hao Wu",
      "Xiao-Lin Lu",
      "H. Wang"
    ],
    "year": 2023,
    "abstract": "\n \n Imbalanced health care resource distribution has been central to unequal health outcomes and political tension around the world. Artificial intelligence (AI) has emerged as a promising tool for facilitating resource distribution, especially during emergencies. However, no comprehensive review exists on the use and ethics of AI in health care resource distribution.\n \n \n \n This study aims to conduct a scoping review of the application of AI in health care resource distribution, and explore the ethical and political issues in such situations.\n \n \n \n A scoping review was conducted following the PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses extension for Scoping Reviews). A comprehensive search of relevant literature was conducted in MEDLINE (Ovid), PubMed, Web of Science, and Embase from inception to February 2022. The review included qualitative and quantitative studies investigating the application of AI in health care resource allocation.\n \n \n \n The review involved 22 articles, including 9 on model development and 13 on theoretical discussions, qualitative studies, or review studies. Of the 9 on model development and validation, 5 were conducted in emerging economies, 3 in developed countries, and 1 in a global context. In terms of content, 4 focused on resource distribution at the health system level and 5 focused on resource allocation at the hospital level. Of the 13 qualitative studies, 8 were discussions on the COVID-19 pandemic and the rest were on hospital resources, outbreaks, screening, human resources, and digitalization.\n \n \n \n This scoping review synthesized evidence on AI in health resource distribution, focusing on the COVID-19 pandemic. The results suggest that the application of AI has the potential to improve efficacy in resource distribution, especially during emergencies. Efficient data sharing and collecting structures are needed to make reliable and evidence-based decisions. Health inequality, distributive justice, and transparency must be considered when deploying AI models in real-world situations.\n",
    "doi": "10.2196/38397",
    "url": "https://www.semanticscholar.org/paper/54db901155a8d8f16cf271d08b5bcdd31301203e",
    "pdf_url": "https://ai.jmir.org/2023/1/e38397/PDF",
    "venue": "JMIR AI",
    "citation_count": 24,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140668"
  },
  {
    "source": "semantic_scholar",
    "source_id": "3da2d02a6178f3f0343089a9c4f57eb0f2d23433",
    "title": "Edge-Cloud Collaboration Enabled Video Service Enhancement: A Hybrid Human-Artificial Intelligence Scheme",
    "authors": [
      "D. Wu",
      "Ruili Bao",
      "Zhidu Li",
      "Honggang Wang",
      "Hong Zhang",
      "Ruyan Wang"
    ],
    "year": 2021,
    "abstract": "In this paper, a video service enhancement strategy is investigated under an edge-cloud collaboration framework, where video caching and delivery decisions are made at the cloud and edge respectively. We aim to guarantee the user fairness in terms of video coding rate under statistical delay constraint and edge caching capacity constraint. A hybrid human-artificial intelligence approach is developed to improve the user hit rate for video caching. Specifically, individual user interest is first characterized by merging factorization machine (FM) model and multi-layer perceptron (MLP) model, where both low-order and high-order features can be well learned simultaneously. Thereafter, a social aware similarity model is constructed to transfer individual user interest to group interest, based on which, videos can be selected to cache at the network edge. Furthermore, a dual bisection exploration scheme is proposed to optimize wireless resource allocation and video coding rate. The effectiveness of the proposed video caching and delivery scheme is finally validated by extensive experiments with a real-world dataset.",
    "doi": "10.1109/TMM.2021.3066050",
    "url": "https://www.semanticscholar.org/paper/3da2d02a6178f3f0343089a9c4f57eb0f2d23433",
    "pdf_url": "https://arxiv.org/pdf/2103.12516",
    "venue": "IEEE transactions on multimedia",
    "citation_count": 58,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140669"
  },
  {
    "source": "semantic_scholar",
    "source_id": "97b446e2ec3b402ea104421dab5eb4b99a21e42a",
    "title": "Understanding artificial intelligence ethics and safety",
    "authors": [
      "David Leslie"
    ],
    "year": 2019,
    "abstract": "A remarkable time of human promise has been ushered in by the convergence of the ever-expanding availability of big data, the soaring speed and stretch of cloud computing platforms, and the advancement of increasingly sophisticated machine learning algorithms. Innovations in AI are already leaving a mark on government by improving the provision of essential social goods and services from healthcare, education, and transportation to food supply, energy, and environmental management. These bounties are likely just the start. The prospect that progress in AI will help government to confront some of its most urgent challenges is exciting, but legitimate worries abound. As with any new and rapidly evolving technology, a steep learning curve means that mistakes and miscalculations will be made and that both unanticipated and harmful impacts will occur. \nThis guide, written for department and delivery leads in the UK public sector and adopted by the British Government in its publication, 'Using AI in the Public Sector,' identifies the potential harms caused by AI systems and proposes concrete, operationalisable measures to counteract them. It stresses that public sector organisations can anticipate and prevent these potential harms by stewarding a culture of responsible innovation and by putting in place governance processes that support the design and implementation of ethical, fair, and safe AI systems. It also highlights the need for algorithmically supported outcomes to be interpretable by their users and made understandable to decision subjects in clear, non-technical, and accessible ways. Finally, it builds out a vision of human-centred and context-sensitive implementation that gives a central role to communication, evidence-based reasoning, situational awareness, and moral justifiability.",
    "doi": "10.5281/zenodo.3240529",
    "url": "https://www.semanticscholar.org/paper/97b446e2ec3b402ea104421dab5eb4b99a21e42a",
    "pdf_url": "https://digital.library.unt.edu/ark:/67531/metadc2289556/m2/1/high_res_d/attachment_6.pdf",
    "venue": "Social Science Research Network",
    "citation_count": 444,
    "fields_of_study": [
      "Computer Science",
      "Mathematics"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140671"
  },
  {
    "source": "semantic_scholar",
    "source_id": "f0fbd6f92d182581ff435858155c24bf2f55157c",
    "title": "Ethical Considerations Emerge from Artificial Intelligence (AI) in Biotechnology",
    "authors": [
      "Mahintaj Dara",
      "Negar Azarpira"
    ],
    "year": 2025,
    "abstract": "The integration of Artificial intelligence (AI) in biotechnology presents significant ethical challenges that must be addressed to ensure responsible innovations. Key concerns include data privacy and security, as AI systems often handle sensitive genetic and health information, necessitating robust regulations to protect individuals\u2019 rights and maintain public trust. Algorithmic bias poses another critical issue; AI can reflect existing biases in training data, leading to inequitable healthcare outcomes. Transparency in AI decision-making is essential, as \u201cblack box\u201d models hinder trust, especially in drug discovery and genetics. Ethical implications of genetic manipulation require careful scrutiny to define the limits of human intervention. Additionally, societal impacts must be considered to ensure equitable distribution of AI benefits, preventing the exacerbation of disparities. Engaging diverse stakeholders, including ethicists and policymakers, is vital in aligning these technologies with societal values. Ultimately, prioritizing ethics will allow us to harness AI and biotechnology\u2019s potential while safeguarding human rights and promoting equity.",
    "doi": "10.18502/ajmb.v17i1.17680",
    "url": "https://www.semanticscholar.org/paper/f0fbd6f92d182581ff435858155c24bf2f55157c",
    "pdf_url": "",
    "venue": "Avicenna journal of medical biotechnology",
    "citation_count": 11,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140673"
  },
  {
    "source": "semantic_scholar",
    "source_id": "1c04cce4ee5fafc8f0bedbf520fdee279bf83539",
    "title": "Human-Centered Artificial Intelligence: Designing for User Empowerment and Ethical Considerations",
    "authors": [
      "Usman Ahmad Usmani",
      "Ari Happonen",
      "J. Watada"
    ],
    "year": 2023,
    "abstract": "Human-Centered Artificial Intelligence (AI) focuses on AI systems prioritizing user empowerment and ethical considerations. We explore the importance of usercentric design principles and ethical guidelines in creating AI technologies that enhance user experiences and align with human values. It emphasizes user empowerment through personalized experiences and explainable AI, fostering trust and user agency. Ethical considerations, including fairness, transparency, accountability, and privacy protection, are addressed to ensure AI systems respect human rights and avoid biases. Effective human AI collaboration is emphasized, promoting shared decision-making and user control. By involving interdisciplinary collaboration, this research contributes to advancing human-centered AI, providing practical recommendations for designing AI systems that enhance user experiences, promote user empowerment, and adhere to ethical standards. It emphasizes the harmonious coexistence between humans and AI, enhancing well-being and autonomy and creating a future where AI technologies benefit humanity. Overall, this research highlights the significance of human-centered AI in creating a positive impact. By centering on users' needs and values, AI systems can be designed to empower individuals and enhance their experiences. Ethical considerations are crucial to ensure fairness and transparency. With effective collaboration between humans and AI, we can harness the potential of AI to create a future that aligns with human aspirations and promotes societal well-being.",
    "doi": "10.1109/HORA58378.2023.10156761",
    "url": "https://www.semanticscholar.org/paper/1c04cce4ee5fafc8f0bedbf520fdee279bf83539",
    "pdf_url": "",
    "venue": "2023 5th International Congress on Human-Computer Interaction, Optimization and Robotic Applications (HORA)",
    "citation_count": 36,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140674"
  },
  {
    "source": "semantic_scholar",
    "source_id": "80c5d486c73bc43fcbbfcfbbb1971c1a72a8f27b",
    "title": "Artificial Intelligence in Human Resources Management: Challenges and a Path Forward",
    "authors": [
      "Prasanna Tambe",
      "P. Cappelli",
      "V. Yakubovich"
    ],
    "year": 2019,
    "abstract": "There is a substantial gap between the promise and reality of artificial intelligence in human resource (HR) management. This article identifies four challenges in using data science techniques for HR tasks: complexity of HR phenomena, constraints imposed by small data sets, accountability questions associated with fairness and other ethical and legal constraints, and possible adverse employee reactions to management decisions via data-based algorithms. It then proposes practical responses to these challenges based on three overlapping principles\u2014causal reasoning, randomization and experiments, and employee contribution\u2014that would be both economically efficient and socially appropriate for using data science in the management of employees.",
    "doi": "10.1177/0008125619867910",
    "url": "https://www.semanticscholar.org/paper/80c5d486c73bc43fcbbfcfbbb1971c1a72a8f27b",
    "pdf_url": "",
    "venue": "California Management Review",
    "citation_count": 954,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140675"
  },
  {
    "source": "semantic_scholar",
    "source_id": "7b4b93a933e33266c1f344c54da661c3e588699e",
    "title": "Ethical and legal considerations influencing human involvement in the implementation of artificial intelligence in a clinical pathway: A multi-stakeholder perspective",
    "authors": [
      "Elizabeth Redrup Hill",
      "C. Mitchell",
      "T. Brigden",
      "Alison Hall"
    ],
    "year": 2023,
    "abstract": "Introduction Ethical and legal factors will have an important bearing on when and whether automation is appropriate in healthcare. There is a developing literature on the ethics of artificial intelligence (AI) in health, including specific legal or regulatory questions such as whether there is a right to an explanation of AI decision-making. However, there has been limited consideration of the specific ethical and legal factors that influence when, and in what form, human involvement may be required in the implementation of AI in a clinical pathway, and the views of the wide range of stakeholders involved. To address this question, we chose the exemplar of the pathway for the early detection of Barrett's Oesophagus (BE) and oesophageal adenocarcinoma, where Gehrung and colleagues have developed a \u201csemi-automated\u201d, deep-learning system to analyse samples from the CytospongeTM TFF3 test (a minimally invasive alternative to endoscopy), where AI promises to mitigate increasing demands for pathologists' time and input. Methods We gathered a multidisciplinary group of stakeholders, including developers, patients, healthcare professionals and regulators, to obtain their perspectives on the ethical and legal issues that may arise using this exemplar. Results The findings are grouped under six general themes: risk and potential harms; impacts on human experts; equity and bias; transparency and oversight; patient information and choice; accountability, moral responsibility and liability for error. Within these themes, a range of subtle and context-specific elements emerged, highlighting the importance of pre-implementation, interdisciplinary discussions and appreciation of pathway specific considerations. Discussion To evaluate these findings, we draw on the well-established principles of biomedical ethics identified by Beauchamp and Childress as a lens through which to view these results and their implications for personalised medicine. Our findings are not only relevant to this context but have implications for AI in digital pathology and healthcare more broadly.",
    "doi": "10.3389/fdgth.2023.1139210",
    "url": "https://www.semanticscholar.org/paper/7b4b93a933e33266c1f344c54da661c3e588699e",
    "pdf_url": "https://www.frontiersin.org/articles/10.3389/fdgth.2023.1139210/pdf",
    "venue": "Frontiers in Digital Health",
    "citation_count": 31,
    "fields_of_study": [
      "Computer Science",
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140677"
  },
  {
    "source": "semantic_scholar",
    "source_id": "06b5090c00326183f7b3fe6e891586449e14650e",
    "title": "Ethics of artificial intelligence and robotics",
    "authors": [
      "V. C. M\u00fcller"
    ],
    "year": 2020,
    "abstract": null,
    "doi": null,
    "url": "https://www.semanticscholar.org/paper/06b5090c00326183f7b3fe6e891586449e14650e",
    "pdf_url": "",
    "venue": "",
    "citation_count": 305,
    "fields_of_study": [
      "Sociology"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140679"
  },
  {
    "source": "semantic_scholar",
    "source_id": "42eae4671b13b346b115705bc844afaede91cd39",
    "title": "Explainable Artificial Intelligence for Energy-Efficient Radio Resource Management",
    "authors": [
      "Alexandru-Daniel Marcu",
      "S. K. G. Peesapati",
      "Jessica Moysen Cortes",
      "Sahar Imtiaz",
      "James Gross"
    ],
    "year": 2023,
    "abstract": "As wireless systems evolve, the problems of radio resource management (RRM) become harder to solve. Once the additional constraint of energy-efficient utilization of resources is factored in, these problems become even more challenging. Thus, experts started developing solutions based on complex artificial intelligence (AI) models that, unfortunately, suffer from a performance-explainability trade-off. In this work, we propose an explainable AI (XAI) methodology for addressing this tradeoff. Our methodology can be used to generate feature importance explanations of AI models through three XAI methods: (i) Kernel SHapley Additive exPlanations (SHAP), (ii) Counterfactual Explanations for Robustness, Transparency, Interpretability, and Fairness of Artificial Intelligence models (CERTIFAI), and (iii) Anchors. For Anchors, we formulate a new feature importance score based on the feature\u2019s presence within the rules built by the method. We then use the generated explanations to improve the understanding of the model and reduce its complexity through a feature selection process. By applying our methodology to a reinforcement learning (RL) agent designed for energy-efficient RRM, we were able to reduce its complexity by approximately 27%\u221262% according to various metrics, without losing performance. Additionally, we show the possibility to replace the AI-based inference process with an Anchors-based inference process with similar performance and higher interpretability for humans.",
    "doi": "10.1109/WCNC55385.2023.10119130",
    "url": "https://www.semanticscholar.org/paper/42eae4671b13b346b115705bc844afaede91cd39",
    "pdf_url": "",
    "venue": "IEEE Wireless Communications and Networking Conference",
    "citation_count": 12,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140680"
  },
  {
    "source": "semantic_scholar",
    "source_id": "ef1c416afe87edcb49901bd3329cc00ccd921653",
    "title": "Bias Mitigation in Primary Health Care Artificial Intelligence Models: Scoping Review",
    "authors": [
      "M. Sasseville",
      "Steven Ouellet",
      "Caroline Rh\u00e9aume",
      "Malek Sahlia",
      "V. Couture",
      "P. Despr\u00e9s",
      "Jean-S\u00e9bastien Paquette",
      "David Darmon",
      "Fr\u00e9d\u00e9ric Berg\u00e9ron",
      "Marie-Pierre Gagnon"
    ],
    "year": 2024,
    "abstract": "Background Artificial intelligence (AI) predictive models in primary health care have the potential to enhance population health by rapidly and accurately identifying individuals who should receive care and health services. However, these models also carry the risk of perpetuating or amplifying existing biases toward diverse groups. We identified a gap in the current understanding of strategies used to assess and mitigate bias in primary health care algorithms related to individuals\u2019 personal or protected attributes. Objective This study aimed to describe the attempts, strategies, and methods used to mitigate bias in AI models within primary health care, to identify the diverse groups or protected attributes considered, and to evaluate the results of these approaches on both bias reduction and AI model performance. Methods We conducted a scoping review following Joanna Briggs Institute (JBI) guidelines, searching Medline (Ovid), CINAHL (EBSCO), PsycINFO (Ovid), and Web of Science databases for studies published between January 1, 2017, and November 15, 2022. Pairs of reviewers independently screened titles and abstracts, applied selection criteria, and performed full-text screening. Discrepancies regarding study inclusion were resolved by consensus. Following reporting standards for AI in health care, we extracted data on study objectives, model features, targeted diverse groups, mitigation strategies used, and results. Using the mixed methods appraisal tool, we appraised the quality of the studies. Results After removing 585 duplicates, we screened 1018 titles and abstracts. From the remaining 189 full-text articles, we included 17 studies. The most frequently investigated protected attributes were race (or ethnicity), examined in 12 of the 17 studies, and sex (often identified as gender), typically classified as \u201cmale versus female\u201d in 10 of the studies. We categorized bias mitigation approaches into four clusters: (1) modifying existing AI models or datasets, (2) sourcing data from electronic health records, (3) developing tools with a \u201chuman-in-the-loop\u201d approach, and (4) identifying ethical principles for informed decision-making. Algorithmic preprocessing methods, such as relabeling and reweighing data, along with natural language processing techniques that extract data from unstructured notes, showed the greatest potential for bias mitigation. Other methods aimed at enhancing model fairness included group recalibration and the application of the equalized odds metric. However, these approaches sometimes exacerbated prediction errors across groups or led to overall model miscalibrations. Conclusions The results suggest that biases toward diverse groups are more easily mitigated when data are open-sourced, multiple stakeholders are engaged, and during the algorithm\u2019s preprocessing stage. Further empirical studies that include a broader range of groups, such as Indigenous peoples in Canada, are needed to validate and expand upon these findings. Trial Registration OSF Registry osf.io/9ngz5/; https://osf.io/9ngz5/ International Registered Report Identifier (IRRID) RR2-10.2196/46684",
    "doi": "10.2196/60269",
    "url": "https://www.semanticscholar.org/paper/ef1c416afe87edcb49901bd3329cc00ccd921653",
    "pdf_url": "https://doi.org/10.2196/60269",
    "venue": "Journal of Medical Internet Research",
    "citation_count": 13,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140682"
  },
  {
    "source": "semantic_scholar",
    "source_id": "196674fbcc0e15b98adaaeef6cf0c11f86acd22d",
    "title": "On the Ethics and Practicalities of Artificial Intelligence, Risk Assessment, and Race",
    "authors": [
      "Neil R. Hogan",
      "Ethan Q Davidge",
      "Gabriela Cor\u0103bian"
    ],
    "year": 2021,
    "abstract": null,
    "doi": "10.29158/JAAPL.200116-20",
    "url": "https://www.semanticscholar.org/paper/196674fbcc0e15b98adaaeef6cf0c11f86acd22d",
    "pdf_url": "",
    "venue": "The journal of the American Academy of Psychiatry and the Law",
    "citation_count": 22,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140684"
  },
  {
    "source": "semantic_scholar",
    "source_id": "dd4ccd8a36fbf7fc2ee18c05570ea715ded7be35",
    "title": "The Impact of Artificial Intelligence on Human Resources Management Strategy: Opportunities for the Humanisation and Risks",
    "authors": [
      "V. Konovalova",
      "E. Mitrofanova",
      "A. Mitrofanova",
      "R. Gevorgyan"
    ],
    "year": 2022,
    "abstract": "The article discusses the growing role of artificial intelligence in human resources management strategy. The results of research and practical experience confirm the possibility of using artificial intelligence to humanise human resource management (reducing bias in the selection of personnel, mastering employees\u2019 experience, personalising training, analysing the emotional state of employees, and managing their wellbeing) are generalised. Highlighted are the risks of dehumanisation of personnel management when introducing artificial intelligence, which can be caused by both new threats and the strengthening of existing problems in this area.",
    "doi": "10.24234/wisdom.v2i1.763",
    "url": "https://www.semanticscholar.org/paper/dd4ccd8a36fbf7fc2ee18c05570ea715ded7be35",
    "pdf_url": "https://cyberleninka.ru/article/n/the-impact-of-artificial-intelligence-on-human-resources-management-strategy-opportunities-for-the-humanisation-and-risks/pdf",
    "venue": "wisdom",
    "citation_count": 8,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140685"
  },
  {
    "source": "semantic_scholar",
    "source_id": "9e31d55037675a43abc65f05ada20ce5cb1a2730",
    "title": "AI in human resources: efficiency, ethics, and emerging challenges",
    "authors": [
      "Soumi Majumder",
      "Syedahmed Salman",
      "Nilanjan Dey"
    ],
    "year": 2025,
    "abstract": null,
    "doi": "10.1007/s43681-025-00862-x",
    "url": "https://www.semanticscholar.org/paper/9e31d55037675a43abc65f05ada20ce5cb1a2730",
    "pdf_url": "",
    "venue": "AI and Ethics",
    "citation_count": 0,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140686"
  },
  {
    "source": "semantic_scholar",
    "source_id": "a09ec60dee41fabe75f63d19f85c6f3048dddcf3",
    "title": "Harnessing the power of artificial intelligence for disease-surveillance purposes",
    "authors": [
      "Barbara Tornimbene",
      "Zoila Beatriz Leiva Rioja",
      "J. Brownstein",
      "Adam Dunn",
      "Sylvain Faye",
      "Jude Kong",
      "Nada Malou",
      "Clara Nordon",
      "Benjamin Rader",
      "Oliver Morgan"
    ],
    "year": 2025,
    "abstract": "The COVID-19 pandemic accelerated the development of AI-driven tools to improve public health surveillance and outbreak management. While AI programs have shown promise in disease surveillance, they also present issues such as data privacy, prejudice, and human-AI interactions. This sixth session of the of the WHO Pandemic and Epidemic Intelligence Innovation Forum examines the use of Artificial Intelligence (AI) in public health by collecting the experience of key global health organizations, such the Boston Children's Hospital, the Global South AI for Pandemic & Epidemic Preparedness & Response (AI4PEP) network, Medicines Sans Fronti\u00e8res (MSF), and the University of Sydney. AI's utility in clinical care, particularly in diagnostics, medication discovery, and data processing, has resulted in improvements that may also benefit public health surveillance. However, the use of AI in global health necessitates careful consideration of ethical issues, particularly those involving data use and algorithmic bias. As AI advances, particularly with large language models, public health officials must develop governance frameworks that stress openness, accountability, and fairness. These systems should address worldwide differences in data access and ensure that AI technologies are tailored to specific local needs. Ultimately, AI's ability to improve healthcare efficiency and equity is dependent on multidisciplinary collaboration, community involvement, and inclusive AI designs in ensuring equitable healthcare outcomes to fit the unique demands of global communities.",
    "doi": "10.1186/s12919-025-00320-w",
    "url": "https://www.semanticscholar.org/paper/a09ec60dee41fabe75f63d19f85c6f3048dddcf3",
    "pdf_url": "",
    "venue": "BMC Proceedings",
    "citation_count": 8,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140688"
  },
  {
    "source": "semantic_scholar",
    "source_id": "d5da13a175fb91730e7cc23c508f4b9888ad66b8",
    "title": "The Ethical Role of Generative Artificial Intelligence in Modern HR Decision-Making: A Systematic Literature Review",
    "authors": [
      "S. Porkodi",
      "Teresita Luzon Cedro"
    ],
    "year": 2025,
    "abstract": "The rapid development of generative artificial intelligence (AI) has led to the recognition of tools like ChatGPT and its potential to transform human resource (HR) management processes, particularly in decision-making. This review study aims to assess the effectiveness and benefits of ChatGPT in enhancing HR functions, particularly decision-making, and to identify any challenges and ethical considerations involved. Additionally, the study seeks to establish a hybrid framework that combines AI-driven decision-making with human oversight. A systematic literature review was conducted using PRISMA guidelines, selecting 50 articles from Scopus and Google Scholar databases. The literature review includes a synthesis analysis to assess publication trends and a keyword analysis to identify key themes such as ChatGPT\u2019s impact on decision-making in HR management. The study reveals that ChatGPT can streamline HR processes, improve communication, and support personalized learning and decision-making, eventually contributing to enhanced performance and engagement. However, the technology requires human input for moral judgment and empathy, presenting challenges like resistance to adoption, algorithmic bias, and data privacy concerns. This study uniquely contributes to the literature by providing a systematic analysis of ChatGPT\u2019s role in HR decision-making and proposing a hybrid framework that addresses AI\u2019s limitations through ethical guidelines and human oversight. The findings emphasize the need for empirical research in larger, diverse settings and future enhancements to ChatGPT\u2019s contextual understanding of HR.",
    "doi": "10.24018/ejbmr.2025.10.1.2535",
    "url": "https://www.semanticscholar.org/paper/d5da13a175fb91730e7cc23c508f4b9888ad66b8",
    "pdf_url": "https://doi.org/10.24018/ejbmr.2025.10.1.2535",
    "venue": "European Journal of Business and Management Research",
    "citation_count": 6,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140690"
  },
  {
    "source": "semantic_scholar",
    "source_id": "3f92b660f3991a4e510398f5736a8d9f0f85aaba",
    "title": "The Ethical Concerns of Artificial Intelligence in Urban Planning",
    "authors": [
      "Thomas W. Sanchez",
      "M. Brenman",
      "Xinyue Ye"
    ],
    "year": 2024,
    "abstract": "Abstract Problem, research strategy, and findings The integration of a artificial intelligence (AI) into urban planning presents potential ethical challenges, including concerns about bias, transparency, accountability, privacy, and misinformation. As planners rely more on AI for decision making, the potential for these systems to perpetuate biases, obscure decision-making processes, and infringe on privacy becomes more pronounced, potentially undermining public trust and excluding marginalized communities. We reviewed existing literature on AI ethics in urban planning, examining biases, transparency, accountability, and privacy issues. Our methodology synthesized findings from various studies, reports, and theoretical frameworks to highlight ethical concerns in AI-driven urban planning. Recommendations for ethical AI implementation emphasize transparency, inclusive data sets, public engagement, and robust ethical guidelines. Our research identified critical ethical concerns in AI-driven urban planning. Bias in AI systems can lead to unequal outcomes, disproportionately affecting marginalized communities. Transparency issues arise from the black box nature of AI, complicating understanding and trust in AI-driven decisions. Privacy concerns are heightened due to extensive data collection and potential misuse, raising the risk of surveillance and data breaches. Limitations include the availability of specific literature focused on AI ethics for urban planning and the evolving nature of AI technologies, suggesting a need for ongoing research and adaptive strategies. Human oversight and continuous monitoring are essential to ensure ethical practices, with an emphasis on community engagement and public education to foster trust and inclusivity. Takeaway for practice Urban planners should adopt a proactive approach to mitigate ethical risks associated with AI. Ensuring transparency, involving diverse community groups, and maintaining robust data privacy measures are crucial. Prioritizing public engagement and education will help to demystify AI technologies and build public trust. Addressing these ethical concerns allows planners to leverage AI\u2019s potential while safeguarding equity, privacy, and accountability in urban development.",
    "doi": "10.1080/01944363.2024.2355305",
    "url": "https://www.semanticscholar.org/paper/3f92b660f3991a4e510398f5736a8d9f0f85aaba",
    "pdf_url": "https://www.tandfonline.com/doi/pdf/10.1080/01944363.2024.2355305?needAccess=true",
    "venue": "Journal of the American Planning Association",
    "citation_count": 63,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140691"
  },
  {
    "source": "semantic_scholar",
    "source_id": "b30d9e5b507316dee7da81ee4371638034afa936",
    "title": "Designing human resource management systems in the age of AI",
    "authors": [
      "Patrick Nicolas Tinguely",
      "Junghyun Lee",
      "Vivianna Fang He"
    ],
    "year": 2023,
    "abstract": "The increasing adoption of artificial intelligence (AI) is reshaping the practices of human resource management (HRM). We propose a typology of HR\u2013AI collaboration systems across the dimensions of task characteristics (routine vs. non-routine; low vs. high cognitive complexity) and social acceptability of such systems among organizational members. We discuss how organizations should design HR\u2013AI collaboration systems in light of issues of AI explainability, high stakes contexts, and threat to employees\u2019 professional identities. We point out important design considerations that may affect employees' perceptions of organizational fairness and emphasize HR professionals' role in the design process. We conclude by discussing how our Point of View article contributes to literatures on organization design and human\u2013AI collaboration and suggesting potential avenues for future research.",
    "doi": "10.1007/s41469-023-00153-x",
    "url": "https://www.semanticscholar.org/paper/b30d9e5b507316dee7da81ee4371638034afa936",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s41469-023-00153-x.pdf",
    "venue": "Journal of Organization Design",
    "citation_count": 17,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140693"
  },
  {
    "source": "semantic_scholar",
    "source_id": "f539bf3856bbc547210baaed874ed6f3b5c66b76",
    "title": "Bias in Artificial Intelligence Systems",
    "authors": [
      "Rafa\u0142 Rejmaniak"
    ],
    "year": 2021,
    "abstract": "Abstract Artificial intelligence systems are currently deployed in many areas of human activity. Such systems are increasingly assigned tasks that involve taking decisions about people or predicting future behaviours. These decisions are commonly regarded as fairer and more objective than those taken by humans, as AI systems are thought to be resistant to such influences as emotions or subjective beliefs. In reality, using such a system does not guarantee either objectivity or fairness. This article describes the phenomenon of bias in AI systems and the role of humans in creating it. The analysis shows that AI systems, even if operating correctly from a technical standpoint, are not guaranteed to take decisions that are more objective than those of a human, but those systems can still be used to reduce social inequalities.",
    "doi": "10.15290/bsp.2021.26.03.02",
    "url": "https://www.semanticscholar.org/paper/f539bf3856bbc547210baaed874ed6f3b5c66b76",
    "pdf_url": "https://doi.org/10.15290/bsp.2021.26.03.02",
    "venue": "Bia\u0142ostockie Studia Prawnicze",
    "citation_count": 11,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140694"
  },
  {
    "source": "semantic_scholar",
    "source_id": "72b39cf03173e4ced50e54873dac32258bbbfe16",
    "title": "Trustworthy AI and Corporate Governance: The EU\u2019s Ethics Guidelines for Trustworthy Artificial Intelligence from a Company Law Perspective",
    "authors": [
      "Eleanore Hickman",
      "M. Petrin"
    ],
    "year": 2020,
    "abstract": "AI will change many aspects of the world we live in, including the way corporations are governed. Many efficiencies and improvements are likely, but there are also potential dangers, including the threat of harmful impacts on third parties, discriminatory practices, data and privacy breaches, fraudulent practices and even \u2018rogue AI\u2019. To address these dangers, the EU published \u2018The Expert Group\u2019s Policy and Investment Recommendations for Trustworthy AI\u2019 (the Guidelines). The Guidelines produce seven principles from its four foundational pillars of respect for human autonomy, prevention of harm, fairness, and explicability. If implemented by business, the impact on corporate governance will be substantial. Fundamental questions at the intersection of ethics and law are considered, but because the Guidelines only address the former without (much) reference to the latter, their practical application is challenging for business. Further, while they promote many positive corporate governance principles\u2014including a stakeholder-oriented (\u2018human-centric\u2019) corporate purpose and diversity, non-discrimination, and fairness\u2014it is clear that their general nature leaves many questions and concerns unanswered. In this paper we examine the potential significance and impact of the Guidelines on selected corporate law and governance issues. We conclude that more specificity is needed in relation to how the principles therein will harmonise with company law rules and governance principles. However, despite their imperfections, until harder legislative instruments emerge, the Guidelines provide a useful starting point for directing businesses towards establishing trustworthy AI.",
    "doi": "10.1007/s40804-021-00224-0",
    "url": "https://www.semanticscholar.org/paper/72b39cf03173e4ced50e54873dac32258bbbfe16",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s40804-021-00224-0.pdf",
    "venue": "European Business Organization Law Review",
    "citation_count": 75,
    "fields_of_study": [
      "Business"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140695"
  },
  {
    "source": "semantic_scholar",
    "source_id": "d687f8d336387d67e5b990f8c5cc53288683011c",
    "title": "Artificial Intelligence in African Higher Education: Uses, Misuses, and Ethical Dilemmas",
    "authors": [
      "Ayenew Guadu",
      "Dawit Dibekulu",
      "A. Menberu"
    ],
    "year": 2025,
    "abstract": "Globally, Artificial Intelligence (AI) is changing higher education, and African institutions are becoming more and more involved in this digital revolution. AI applications such as predictive analytics, automated grading, and intelligent tutoring systems offer promising opportunities to enhance research, teaching, learning, and administration\u2014particularly in settings with limited resources. However, the incorporation of AI into African higher education also raises significant socio-technical and ethical issues. Academic dishonesty, algorithmic bias, data privacy, and unequal access to digital infrastructure are some of the issues that risk exacerbating existing educational inequalities. Furthermore, concerns regarding digital sovereignty, fairness, and cultural relevance are raised by the dependence on AI tools created in the Global North. This article highlights the dual potential for both empowerment and marginalization as it critically analyzes the advantages and hazards of implementing AI in African higher institutions. It calls for a responsible, inclusive, and culturally grounded approach to AI in African higher education through a contextual and ethical lens, using concepts like digital justice, the ethics of technology, and decolonial theory.",
    "doi": "10.54364/aaiml.2025.53234",
    "url": "https://www.semanticscholar.org/paper/d687f8d336387d67e5b990f8c5cc53288683011c",
    "pdf_url": "",
    "venue": "Advances in Artificial Intelligence and Machine Learning",
    "citation_count": 1,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140697"
  },
  {
    "source": "semantic_scholar",
    "source_id": "28ec0afa570fdcce7ce18f751bead511d4fc4b13",
    "title": "Balancing the scale: navigating ethical and practical challenges of artificial intelligence (AI) integration in legal practices",
    "authors": [
      "Ammar Zafar"
    ],
    "year": 2024,
    "abstract": "The paper explores the integration of artificial intelligence in legal practice, discussing the ethical and practical issues that arise and how it affects customary legal procedures. It emphasises the shift from labour-intensive legal practice to technology-enhanced methods, with a focus on artificial intelligence's potential to improve access to legal services and streamline legal procedures. This discussion importantly highlights the ethical challenges introduced by the integration of Artificial Intelligence, with a specific focus on issues of bias and transparency. These ethical concerns become particularly paramount in the context of sensitive legal areas, including but not limited to, child custody disputes, criminal justice, and divorce settlements. It underscores the critical need for maintaining ethical vigilance, advocating for developing and implementing AI systems characterised by a profound commitment to ethical integrity. This approach is vital to guarantee fairness and uphold transparency across all judicial proceedings. The study advocates for a \"human in the loop\" strategy that combines human knowledge and AI techniques to mitigate biases and guarantee individualised legal results to ensure AI functions as a complement rather than a replacement, the paper concludes by emphasising the necessity of preserving the human element in legal practices.",
    "doi": "10.1007/s44163-024-00121-8",
    "url": "https://www.semanticscholar.org/paper/28ec0afa570fdcce7ce18f751bead511d4fc4b13",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s44163-024-00121-8.pdf",
    "venue": "Discover Artificial Intelligence",
    "citation_count": 42,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140698"
  },
  {
    "source": "semantic_scholar",
    "source_id": "656fd9a402830709b9ff8f8b9fdb5738bd48f4fc",
    "title": "ICIS 2019 SIGHCI Workshop Panel Report: Human\u2013 Computer Interaction Challenges and Opportunities for Fair, Trustworthy and Ethical Artificial Intelligence",
    "authors": [],
    "year": 2020,
    "abstract": "Artificial Intelligence (AI) is rapidly changing every aspect of our society\u2014including amplifying our biases. Fairness, trust and ethics are at the core of many of the issues underlying the implications of AI. Despite this, research on AI with relation to fairness, trust and ethics in the information systems (IS) field is still scarce. This panel brought together academia, business and government perspectives to discuss the challenges and identify potential solutions to address such challenges. This panel report presents eight themes based around the discussion of two questions: (1) What are the biggest challenges to designing, implementing and deploying fair, ethical and trustworthy AI?; and (2) What are the biggest challenges to policy and governance for fair, ethical and trustworthy AI? The eight themes are: (1) identifying AI biases; (2) drawing attention to AI biases; (3) addressing AI biases; (4) designing transparent and explainable AI; (5) AI fairness, trust, ethics: old wine in a new bottle?; (6) AI accountability; (7) AI laws, policies, regulations and standards; and (8) frameworks for fair, ethical and trustworthy AI. Based on the results of the panel discussion, we present research questions for each theme to guide future research in the area of human\u2013computer interaction.",
    "doi": "10.17705/1thci.00130",
    "url": "https://www.semanticscholar.org/paper/656fd9a402830709b9ff8f8b9fdb5738bd48f4fc",
    "pdf_url": "https://aisel.aisnet.org/cgi/viewcontent.cgi?article=1135&context=thci",
    "venue": "",
    "citation_count": 26,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140700"
  },
  {
    "source": "semantic_scholar",
    "source_id": "f4c0210e76e30d1727246c0af5ef3cd5c5d21585",
    "title": "Automating intellectual freedom: Artificial intelligence, bias, and the information landscape",
    "authors": [
      "Catherine Smith"
    ],
    "year": 2021,
    "abstract": "Anxieties over automation and personal freedom are challenging libraries\u2019 role as havens of intellectual freedom. The introduction of artificial intelligence into the resource description process creates an opportunity to reshape the digital information landscape\u2014and loss of trust by library users. Resource description necessarily manipulates a library\u2019s presentation of information, which influences the ways users perceive and interact with that information. Human catalogers inevitably introduce personal and cultural biases into their work, but artificial intelligence may perpetrate biases on a previously unseen scale. The automation of this process may be perceived as a greater threat than the manipulation produced by human operators. Librarians must understand the risks of artificial intelligence and consider what oversight and countermeasures are necessary to mitigate the harm to libraries and their users before ceding resource description to artificial intelligence in place of the \u201cprofessional considerations\u201d the IFLA Statement on Libraries and Intellectual Freedom calls for in providing access to library materials.",
    "doi": "10.1177/03400352211057145",
    "url": "https://www.semanticscholar.org/paper/f4c0210e76e30d1727246c0af5ef3cd5c5d21585",
    "pdf_url": "",
    "venue": "IFLA Journal",
    "citation_count": 13,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140701"
  },
  {
    "source": "semantic_scholar",
    "source_id": "da01fc413908d3c271622033b45c4eae0f315d3b",
    "title": "Leveraging data analytics in human resource management",
    "authors": [
      "Sai Nethra Betgeri",
      "Naga Parameshwari Chekuri"
    ],
    "year": 2025,
    "abstract": "Human Resource Management (HRM) has transitioned from traditional, intuition-driven practices to a data-driven domain, enabling organizations to leverage advanced analytics for improved workforce management. Integrating data analytics in HR functions such as recruitment, employee engagement, retention, and performance management has proven transformative, providing actionable insights to optimize operations and align HR strategies with organizational objectives. This paper examines the practical applications of HR analytics, emphasizing the role of predictive models, artificial intelligence (AI), and machine learning (ML) in forecasting trends, identifying risks, and enhancing decision-making processes. Key findings highlight how predictive analytics improves hiring efficiency by reducing time-to-hire and enhancing candidate quality, while retention analytics mitigates turnover by identifying at-risk employees and enabling timely interventions. Performance analytics further supports identifying skill gaps and optimizing training programs, driving overall organizational productivity. This paper also explores critical challenges, including data privacy concerns, algorithmic biases, and the need to upskill HR professionals to embrace analytics tools effectively. The results underscore the growing importance of HR analytics as a strategic enabler in shaping workforce management's future while emphasizing ethical considerations and the need for robust data governance frameworks. This study offers practical insights and recommendations for organizations seeking to harness the full potential of HR analytics.",
    "doi": "10.30574/ijsra.2025.15.1.1009",
    "url": "https://www.semanticscholar.org/paper/da01fc413908d3c271622033b45c4eae0f315d3b",
    "pdf_url": "",
    "venue": "International Journal of Science and Research Archive",
    "citation_count": 3,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140703"
  },
  {
    "source": "semantic_scholar",
    "source_id": "f3137d1562fdd9160b98815264ea6fbd409e8c26",
    "title": "Assessing Explainable in Artificial Intelligence: A TOPSIS Approach to Decision-Making",
    "authors": [],
    "year": 2025,
    "abstract": "Explainable in Artificial Intelligence (AI) is the ability to comprehend and explain how AI models generate judgments or predictions. The complexity of AI systems, especially machine learning models, is increasing. understanding their reasoning process becomes crucial for ensuring trust, fairness, and accountability. Explainable AI (XAI) helps demystify the \"black box\" character of sophisticated models, Deep neural networks, for example, which allows users to to grasp how inputs are transformed into outputs. In many AI system judgments can have a big impact on industries including healthcare, banking, and law making transparency a necessity. Explainable also aids in identifying and mitigating biases, improving model performance, and complying with regulatory requirements. As AI technologies evolve, there is an increasing emphasis on balancing model accuracy with interpretability, making some AI systems remain ethical, transparent, and in line with human values. In artificial intelligence (AI) research, Explainable is essential for fostering confidence, guaranteeing responsibility, and enhancing The openness of artificial intelligence systems. As Artificial intelligence models, especially intricate ones like deep learning, become more widely adopted, understanding their Processes for making decisions are crucial for validating their outcomes. The goal of explainable AI (XAI) research is to create models interpretable so that users can comprehend the decision-making process. This is particularly crucial in high-stakes industries like healthcare, banking, and law, where poor or prejudiced choices can have serious repercussions. Explainable also supports regulatory compliance, model improvement, and ethical AI deployment. An approach to decision-making known as TOPSIS (Technique for Order of Preference by Similarity to Ideal Answer) evaluates how far an alternative is from the worst-case situation and how close it is to the ideal solution. The worst-case solution shows the lowest values, while the ideal solution shows the best values given the desired criteria. Each alternative is given a similarity score by TOPSIS, which ranks them according to how near the ideal answer they are. This method is frequently used to enhance decision-making in a variety of domains, including business, engineering, environmental research, and healthcare. Alternative: LIME (Local Interpretable Model), SHAP (Shapley Additive Explanations), Deep LIFT (Deep Learning Important Features), Anchor Explanations, ICE (Individual Conditional Expectation), Counterfactual Explanations, Rule-based Explanation Systems, Saliency Maps (for CNNs), Integrated Gradients, XAI for Healthcare. Evaluation preference: Interpretability, Accuracy of Explanations, User Trust, Computational Complexity, Scalability, Flexibility. The results indicate that XAI for Healthcare ranks highest, while Saliency Maps (for CNNs) holds the lowest rank.",
    "doi": "10.46632/jdaai/2/3/14",
    "url": "https://www.semanticscholar.org/paper/f3137d1562fdd9160b98815264ea6fbd409e8c26",
    "pdf_url": "",
    "venue": "REST Journal on Data Analytics and Artificial Intelligence",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140704"
  },
  {
    "source": "semantic_scholar",
    "source_id": "ed8af3e125a4108ca2acc8d60323fa8ec2b83cfc",
    "title": "Balancing bytes and biases: A case study of AI adoption in academic human resource management",
    "authors": [
      "Rusnandari Retno Cahyani",
      "Anniez Rachmawati Musslifah"
    ],
    "year": 2025,
    "abstract": "The integration of Artificial Intelligence (AI) is rapidly transforming Human Resource Management (HRM), yet its adoption within the unique context of higher education institutions remains underexplored, particularly in developing nations. This study addresses this gap by investigating the application and implications of AI in core HRM functions, specifically recruitment, performance evaluation, and workforce planning, at a public university in Indonesia. Adopting an exploratory qualitative case study methodology, this study sourced data from twelve purposively selected stakeholders, including HR managers, academic leaders, and IT personnel, through semi-structured interviews, document analysis, and non-participant observation. The collected data were systematically analyzed using thematic analysis, revealing a dual impact of AI adoption. While AI integration significantly enhances operational efficiency by automating recruitment screening and supporting data-driven workforce planning, it also introduces critical challenges, including the risk of algorithmic bias, a lack of transparency, and the potential erosion of human judgment in culturally sensitive evaluations. The study concludes that successful AI implementation in academic HRM is contingent upon institutional readiness, a supportive organizational culture, and a robust technological infrastructure. By applying the Technology-Organization-Environment (TOE), Technology Acceptance Model (TAM), and Diffusion of Innovation (DoI) frameworks, this research contributes a nuanced understanding of the factors shaping AI adoption in higher education, underscoring the necessity of a balanced approach that leverages AI's benefits while preserving essential human oversight in university administration.",
    "doi": "10.22515/jemin.v5i2.11679",
    "url": "https://www.semanticscholar.org/paper/ed8af3e125a4108ca2acc8d60323fa8ec2b83cfc",
    "pdf_url": "",
    "venue": "Journal of Educational Management and Instruction (JEMIN)",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140705"
  },
  {
    "source": "semantic_scholar",
    "source_id": "0c6a7b5263ff43a8a9fb3c567e589ef544941af1",
    "title": "AI-Powered Human Resource Management for Enhancing Employee Recruitment Efficiency and Talent Retention in Organizations",
    "authors": [
      "Kajal Chheda",
      "Urvashi Thakur",
      "R. J",
      "Ganesh Prasad Das",
      "Mukesh Kumar Parashar",
      "Krishna Reddy"
    ],
    "year": 2025,
    "abstract": "Artificial Intelligence (AI)-powered Human Resource Management (HRM) systems address inefficiencies in recruitment and employee retention. Traditional methods are slow, biased, and reactive. Integrating AI enables predictive insights, automated screening, and employee satisfaction monitoring, transforming HR practices into data-driven, strategic decision-making processes. This research aims to evaluate the impact of AI on improving recruitment efficiency and talent retention. It investigates whether AI-based tools significantly reduce hiring time, enhance job candidate fit, and predict attrition risk. Data was sourced from 1,000 anonymzed employee records, including 400 resumes, 280 satisfaction responses, and 320 attrition cases across the IT and finance sectors. Collected over a three-year period, the dataset supports recruitment analysis and employee retention prediction using AI-based models. Five variables were analyzed: recruitment time (RT), candidate-job match score (CJMS), employee satisfaction score (ESS), retention rate (RR), and AI-predicted attrition risk (APAR). These variables represent both continuous and ordinal data types, suitable for independent sample t-tests and regression analysis in SPSS 25. SPSS analysis showed significant reductions in recruitment time (p < 0.01) and improvements in job match scores. Among independent sample t-test results, the highest t-value was observed for CJMS (t = 22.15, p < 0.001). Spearman\u2019s correlation indicated a strong positive link between satisfaction and retention. Regression analysis confirmed high predictive accuracy of AI-based attrition risk models. In regression findings, APAR had the highest R\u00b2 value (R\u00b2 = 0.42, p < 0.001). AI-powered HR systems significantly enhance recruitment efficiency and retention strategies. Statistical evidence confirms the effectiveness of AI in predicting attrition and improving candidate-job alignment, enabling organizations to make proactive, data-informed HR decisions and foster a more stable workforce.",
    "doi": "10.62486/agma2025165",
    "url": "https://www.semanticscholar.org/paper/0c6a7b5263ff43a8a9fb3c567e589ef544941af1",
    "pdf_url": "",
    "venue": "Management",
    "citation_count": 2,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140707"
  },
  {
    "source": "semantic_scholar",
    "source_id": "964c6946a053836d55b0fd0e398e57d405fd7f3d",
    "title": "Optimizing Workforce Efficiency in the United States (U.S.) Federal Sector: The Role of Predictive Analytics and AI in Human Resource (HR) Decision-Making",
    "authors": [
      "Kemisola Kasali"
    ],
    "year": 2025,
    "abstract": "The U.S. federal government is undergoing a critical workforce transformation, driven by initiatives under the Department of Government Efficiency (DOGE) to optimize resource allocation and reduce bureaucratic redundancies. This shift poses significant challenges in maintaining service quality amid workforce reductions but offers opportunities to enhance operational effectiveness and public service delivery through technological innovation. Predictive analytics and artificial intelligence (AI) offer strategic, data-driven solutions to enhance human resource (HR) decision-making that enables federal agencies to proactively forecast attrition, enhance workforce planning, and improve operational efficiency. This article examines the integration of AI in federal HR operations, assesses its potential to streamline hiring, retention, and performance management. By evaluating current policy frameworks and presenting innovative AI-driven workforce strategies, this article contributes to the advancement of government modernization. The recommendations provide concrete steps for implementing AI governance frameworks, establishing public-private partnerships, and developing inclusive workforce analytics systems to ensure AI adoption enhances rather than disrupts public service delivery. This article also proposed the introduction of novel approaches to AI integration in federal HR which includes a hybrid human-AI decision support system and an innovative cross-agency AI knowledge sharing platform. In addition, this paper addresses critical challenges that include data privacy concerns, algorithmic bias risks, and the ethical implications of AI-driven decision-making in the federal workforce context that provides a balanced perspective on both opportunities and limitations of these technologies.",
    "doi": "10.51244/ijrsi.2025.12030082",
    "url": "https://www.semanticscholar.org/paper/964c6946a053836d55b0fd0e398e57d405fd7f3d",
    "pdf_url": "",
    "venue": "International journal of research and scientific innovation",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140708"
  },
  {
    "source": "semantic_scholar",
    "source_id": "fb7ffb7e4bd8c03df8a58238ddeafa277319043a",
    "title": "The impacts of AI and automation on human resource management \u2013 systematic review",
    "authors": [
      "Fernanda Maria de Almeida Santos",
      "A. Pereira",
      "Alexandre Shanches",
      "Diogo Crespo",
      "Henriqueta Pala"
    ],
    "year": 2025,
    "abstract": "This study focuses on the growing impact of Artificial Intelligence (AI) and automation on the Human Resource Management (HRM) processes of organizations. It examines how these emerging technologies are redefining HRM practices, with a particular focus on recruitment, training and human capital management. A methodology was used that integrates a quantitative analysis, derived from data collected through a structured survey on a Likert scale, and a systematic review of the literature. This two-pronged approach allowed us to assess perceptions about the implementation of AI in HRM and to identify emerging trends and patterns in recent studies. The results show that AI and automation contribute to greater efficiency in recruitment and selection processes, promoting greater equality in the identification and progression of talent. There was also a positive impact on skills development and vocational training, underlining the importance of adaptive strategies for the continuous development of employees. We face ethical and privacy challenges regarding the use of AI in HR. It highlights the need for robust practices for the protection of employee data and the prevention of bias and discrimination in algorithms. The importance of human intervention in automated decisions is highlighted, ensuring the maintenance of fairness and ethics, as well as the need for professional requalification in the face of technological changes. The study concludes that despite the challenges, AI and automation offer unprecedented opportunities for innovation in HRM. Organizations that integrate these technologies with the human elements of work are better prepared for a dynamic and technologically advanced future.",
    "doi": "10.34117/bjdv11n2-079",
    "url": "https://www.semanticscholar.org/paper/fb7ffb7e4bd8c03df8a58238ddeafa277319043a",
    "pdf_url": "",
    "venue": "Brazilian Journal of Development",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140710"
  },
  {
    "source": "semantic_scholar",
    "source_id": "71cdc4d3ecb738dcd531019ee6f81abf36e65698",
    "title": "Multimodality of AI for Education: Toward Artificial General Intelligence",
    "authors": [
      "Gyeonggeon Lee",
      "Lehong Shi",
      "Ehsan Latif",
      "Yizhu Gao",
      "Arne Bewersdorff",
      "Matthew Nyaaba",
      "Shuchen Guo",
      "Zheng Liu",
      "Gengchen Mai",
      "Tianming Liu",
      "Xiaoming Zhai"
    ],
    "year": 2025,
    "abstract": "This article addresses the growing importance of understanding how multimodal artificial general intelligence (AGI) can be integrated into educational practices. We first reviewed the theoretical foundations of multimodality in human learning, encompassing its concept and history, dual coding theory and multimedia theory, VARK multimodality, and multimodal assessment (see Section II-A). After that, we revisited the essential components of AGI, particularly focusing on the multimodal nature of AGI that distinguished it from artificial narrow intelligence. Based on its conversational functionality, multimodal AGI is considered an educational agent already tested in various educational situations (see Section II-B). How significant text, image, audio, and video modalities are for education, the technological backgrounds of AGI for analyzing and generating them, and educational applications of artificial intelligence (AI) for each modality were thoroughly reviewed (Sections III\u2013VI). Finally, we comprehensively investigated the ethics of AGI in education, originating from the ethics of AI and specified in three strands: first, data privacy and ethical integrity, second, explainability, transparency, and fairness, and third, responsibility and decision-making. Practical implementation of ethical AGI frameworks in education was reviewed (see Section VII). This article also discusses the implications for learning theories, derived operational design principles, current research gaps, practical constraints and institutional readiness, and future directions (see Section VIII). This exploration aims to provide an advanced understanding of the intersection between AI, multimodality, and education, setting a foundation for future research and development.",
    "doi": "10.1109/TLT.2025.3574466",
    "url": "https://www.semanticscholar.org/paper/71cdc4d3ecb738dcd531019ee6f81abf36e65698",
    "pdf_url": "",
    "venue": "IEEE Transactions on Learning Technologies",
    "citation_count": 14,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140711"
  },
  {
    "source": "semantic_scholar",
    "source_id": "9083dedbf490b427da7fa5d954b7be0b7e337bb8",
    "title": "Ethical Considerations in Cloud AI: Addressing Bias and Fairness in Algorithmic Systems",
    "authors": [
      "Shreya Gupta"
    ],
    "year": 2025,
    "abstract": "Artificial intelligence systems deployed through cloud infrastructure have transformed numerous sectors while simultaneously raising critical ethical concerns regarding bias and fairness. This article examines the multifaceted nature of algorithmic bias in cloud AI systems, presenting quantitative evidence of disparities across facial recognition, hiring, lending, criminal justice, and healthcare applications. Data from commercial deployments reveals substantial demographic disparities, with error rates varying by factors of 40+ between different population groups. The societal implications manifest as economic disadvantages, restricted opportunities, and diminished public trust, particularly affecting already marginalized communities. Technical interventions demonstrate considerable promise, with resampling methods, synthetic data generation, and fairness-aware algorithms reducing bias metrics by 40-70% while largely maintaining predictive performance. However, technical solutions alone prove insufficient, necessitating comprehensive governance frameworks. Regulatory approaches, certification mechanisms, participatory design, and professional ethics significantly outperform voluntary guidelines, though implementation gaps persist across the AI ecosystem. The analysis concludes that a combination of technical debiasing and robust governance is essential, with regulatory approaches showing the most significant impact on reducing bias. Addressing bias in cloud AI represents both an ethical imperative and an economic necessity as these systems increasingly influence critical infrastructure and decision-making processes worldwide.",
    "doi": "10.48175/ijarsct-25053",
    "url": "https://www.semanticscholar.org/paper/9083dedbf490b427da7fa5d954b7be0b7e337bb8",
    "pdf_url": "",
    "venue": "International Journal of Advanced Research in Science, Communication and Technology",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140713"
  },
  {
    "source": "semantic_scholar",
    "source_id": "507bcf70a20b594f9cea790431ae65fbef479bba",
    "title": "Ethical Challenges and Bias in Real-World AI: A Fairness-Oriented Approach to Resume Screening Systems",
    "authors": [
      "Dr. S. Ponmalar",
      "T. Rohith",
      "K. N. Kumar",
      "A. K. N. Kaarthick",
      "R.Vishva Balaji"
    ],
    "year": 2025,
    "abstract": "Artificial Intelligence (AI) is rapidly integrating into decision-making across fields like finance, healthcare, and criminal justice. However, its widespread use brings ethical challenges, especially the potential for bias in AI algorithms. This paper examines these ethical concerns, emphasizing three main types of bias: data bias, algorithmic bias, and interaction biasThrough real-world case studies, including biased facial recognition systems, hiring algorithms, and criminal justice AI tools, this paper highlights the far-reaching societal impact of these biases. These case studies demonstrate how bias in AI systems can result in unequal access to resources, unjust treatment in legal systems, and perpetuation of stereotypes in employment practices. This paper highlights the pressing need for robust strategies to address the ethical risks associated with AI. It delves into established frameworks such as Ethically Aligned AI, the EU Guidelines on Trustworthy AI, and the Toronto Declaration, offering essential principles for creating AI systems that prioritize fairness, transparency, and accountability. By evaluating current applications across different industries, this paper proposes actionable solutions to reduce bias in AI systems and also a sample model has been developed to represent how the system has to be under ethics and including enhancing data diversity and implementing robust governance mechanisms to ensure ethical oversight in resume screening processThis research seeks to advance the conversation on ethical AI by emphasizing fairness, equity, and the social good, ensuring that AI technologies are developed to benefit all communities equally.",
    "doi": "10.1109/ICAISS61471.2025.11042179",
    "url": "https://www.semanticscholar.org/paper/507bcf70a20b594f9cea790431ae65fbef479bba",
    "pdf_url": "",
    "venue": "2025 Third International Conference on Augmented Intelligence and Sustainable Systems (ICAISS)",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140714"
  },
  {
    "source": "semantic_scholar",
    "source_id": "98b2d76be7886f34f40fc2af0a4e806f5d159e6b",
    "title": "AI Gender Bias, Disparities, and Fairness: Does Training Data Matter?",
    "authors": [
      "Ehsan Latif",
      "Xiaoming Zhai",
      "Lei Liu"
    ],
    "year": 2023,
    "abstract": "This study delves into the pervasive issue of gender issues in artificial intelligence (AI), specifically within automatic scoring systems for student-written responses. The primary objective is to investigate the presence of gender biases, disparities, and fairness in generally targeted training samples with mixed-gender datasets in AI scoring outcomes. Utilizing a fine-tuned version of BERT and GPT-3.5, this research analyzes more than 1000 human-graded student responses from male and female participants across six assessment items. The study employs three distinct techniques for bias analysis: Scoring accuracy difference to evaluate bias, mean score gaps by gender (MSG) to evaluate disparity, and Equalized Odds (EO) to evaluate fairness. The results indicate that scoring accuracy for mixed-trained models shows an insignificant difference from either male- or female-trained models, suggesting no significant scoring bias. Consistently with both BERT and GPT-3.5, we found that mixed-trained models generated fewer MSG and non-disparate predictions compared to humans. In contrast, compared to humans, gender-specifically trained models yielded larger MSG, indicating that unbalanced training data may create algorithmic models to enlarge gender disparities. The EO analysis suggests that mixed-trained models generated more fairness outcomes compared with gender-specifically trained models. Collectively, the findings suggest that gender-unbalanced data do not necessarily generate scoring bias but can enlarge gender disparities and reduce scoring fairness.",
    "doi": "10.48550/arXiv.2312.10833",
    "url": "https://www.semanticscholar.org/paper/98b2d76be7886f34f40fc2af0a4e806f5d159e6b",
    "pdf_url": "",
    "venue": "arXiv.org",
    "citation_count": 17,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140716"
  },
  {
    "source": "semantic_scholar",
    "source_id": "b06fa39d0d9dbf57f9053f4f737a61774774b1a1",
    "title": "Ethical principles for artificial intelligence in education: a meta-review approach",
    "authors": [
      "Mihiri Wickramasinghe",
      "Lasith Gunawardena",
      "Amitha Padukkage"
    ],
    "year": 2025,
    "abstract": null,
    "doi": "10.1007/s43681-025-00878-3",
    "url": "https://www.semanticscholar.org/paper/b06fa39d0d9dbf57f9053f4f737a61774774b1a1",
    "pdf_url": "",
    "venue": "AI and Ethics",
    "citation_count": 0,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140717"
  },
  {
    "source": "semantic_scholar",
    "source_id": "45fbc2288f19559aaffaa663db09dcb01c841975",
    "title": "Transformasi Artificial Intelligence dalam Akuntansi Keuangan: Inovasi dalam Pengambilan Keputusan atau Memunculkan Tantangan Baru?",
    "authors": [
      "Esa Cahyani Nazari",
      "M. Mukhtaruddin"
    ],
    "year": 2025,
    "abstract": "Artificial Intelligence (AI) is increasingly used in financial accounting to improve decision-making effectiveness. This research analyzes the role of AI in supporting data-driven decision making and identifies challenges in its implementation. Using a qualitative approach with the Systematic Literature Review (SLR) method, this study reviewed 41 relevant articles from national and international journals. The results showed that 28 studies supported the effectiveness of AI in improving financial decision-making by automating transaction recording, enabling algorithm-based predictive analysis, and detecting financial anomalies. AI enables companies to respond faster to market changes, increase transparency of financial reports, and reduce human errors in accounting processes.However, 13 studies highlighted challenges such as technological complexity, limited transparency in decision-making, algorithmic bias, and organizational readiness. In addition, evolving regulations are an obstacle to ensuring optimal use of AI while minimizing ethical and legal risks. The success of AI in financial decision-making depends on infrastructure readiness, regulatory support, and human resource competencies. Without a well-planned strategy, AI may pose new challenges that hinder its effectiveness. Therefore, this study provides insights into the optimal AI implementation strategy to ensure that this technology improves the accuracy and transparency of decision making while maintaining financial accounting accountability.",
    "doi": "10.58192/ebismen.v4i1.3158",
    "url": "https://www.semanticscholar.org/paper/45fbc2288f19559aaffaa663db09dcb01c841975",
    "pdf_url": "",
    "venue": "Jurnal ekonomi, bisnis dan manajemen",
    "citation_count": 3,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140719"
  },
  {
    "source": "semantic_scholar",
    "source_id": "46cf57f8e463606fd48bf418e3c901accccbf20c",
    "title": "Responsible artificial intelligence (AI) in healthcare: a paradigm shift in leadership and strategic management",
    "authors": [
      "Amlan Haque"
    ],
    "year": 2025,
    "abstract": "Purpose This paper aims to explore the paradigm shift in leadership and strategic management driven by the integration of responsible artificial intelligence (AI) in healthcare. It explores the evolving role of leadership in adapting to AI technologies while ensuring ethical governance, transparency and accountability in healthcare decision-making. Design/methodology/approach This study conducts a comprehensive review of current literature, case studies and industry reports to evaluate the implications of responsible AI adoption in healthcare leadership. It focuses on key areas such as AI-driven decision-making, resource optimisation, crisis management and patient care, while also addressing challenges in integrating AI technologies effectively. Findings The integration of AI in healthcare is transforming leadership from traditional, experience-based decision-making to data-driven, AI-enhanced strategies. Responsible leadership emphasises addressing ethical concerns such as bias, transparency and accountability. AI technologies improve resource allocation, crisis management and patient care, but challenges such as workforce resistance and the need for upskilling healthcare professionals remain. Practical implications Healthcare leaders must adopt a responsible leadership framework that balances AI\u2019s potential with ethical and human-centred care principles. Recommendations include developing AI literacy programmes for healthcare professionals, ensuring inclusivity in AI algorithms and establishing governance policies that promote transparency and accountability in AI applications. Originality/value This paper provides a critical, forward-looking perspective on how responsible AI can drive a paradigm shift in healthcare leadership. It offers novel insights into the integration of AI within healthcare organisations, emphasising the need for leadership that prioritises ethical AI usage and promotes patient well-being in a rapidly evolving digital landscape.",
    "doi": "10.1108/LHS-01-2025-0018",
    "url": "https://www.semanticscholar.org/paper/46cf57f8e463606fd48bf418e3c901accccbf20c",
    "pdf_url": "",
    "venue": "Leadership in Health Services",
    "citation_count": 2,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140720"
  },
  {
    "source": "semantic_scholar",
    "source_id": "099d060bce611b5b7b432dbb4f533efa67ac179e",
    "title": "AI-Driven HR: Revolutionizing Human Resource Management",
    "authors": [
      "A. Meher",
      "Deepti Mishra",
      "Tania Mishra",
      "Abhaya Kumar Sahoo"
    ],
    "year": 2025,
    "abstract": "In today\u2019s rapidly evolving technology environment, the integration of artificial intelligence (AI) into various industries has become a significant driver of innovation. In the context of human resources, artificial intelligence is defined as a wide variety of software algorithms that enable a computer to perform human resource management activities that would normally require human cognition and intervention. This includes data-driven decision making, behavioral analysis, trend prediction and much more. One area that is experiencing a profound impact from AI is human resources management (HRM). By incorporating an AI system into the HR department, the company\u2019s employees will gain increased productivity and experience. AI can assist HR departments in every phase of their professional work, from timely candidate selection to performance evaluation. Integrating artificial intelligence into human resource management can then help a business achieve overall efficiency and gain an edge over its competitors. By leveraging AI technologies, organizations can improve employee\u2019s performance, their productivity, and decision-making processes. AI will eventually have a noticeable and longlasting effect on HR. Since technology is always evolving, AI framework must be adaptable enough to update itself and make adjustments as needed. We can use AI to take away most of the monotonous employee\u2019s tasks, analyze vast amounts of data to make tangible decisions, and create a holistic impact on the organization and its people. According to 76% of HR directors, companies would fall behind in organizational performance if they do not integrate and apply AI technologies like generative AI within the next 12 to 24 months. To effectively decide whether to use new AI solutions for HR, CHROs must evaluate technological trends in an organized manner.HR workers may now employ machine learning and algorithms to expedite work processes, lessen biases, and enhance analysis and decision-making thanks to advancements in AI technology, which has completely changed the HR department. Still, some companies are delaying the use of AI for additional use cases due to existing limits and threats.. Artificial intelligence needs proper data storage and maintenance to function effectively. It collects and analyzes all the necessary data and enables the HR department to make data-based decisions. HR manager can make data-driven decisions that are sustainable and impactful. We\u2019ll discuss in this article and explore the role of AI in HR practices and its implications for the future of work.",
    "doi": "10.1109/AESPC67542.2025.11326711",
    "url": "https://www.semanticscholar.org/paper/099d060bce611b5b7b432dbb4f533efa67ac179e",
    "pdf_url": "",
    "venue": "2025 5th IEEE International Conference on Applied Electromagnetics, Signal Processing, & Communication (AESPC)",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140721"
  },
  {
    "source": "semantic_scholar",
    "source_id": "79e1a2270e3b3ff8cf51fb739fad4046a4f99afc",
    "title": "AI-Driven Transformation of Human Resource Management: From Performance Evaluation to Fair Recruitment through Image Processing",
    "authors": [
      "Kartikay Sharma",
      "Aman Sharma",
      "Tanu Sharma"
    ],
    "year": 2025,
    "abstract": "This paper explore the significance of Artificial Intelligence (AI) in Human Resource Management (HRM), discussing its applications, advantages, challenges, and ethical considerations.This study examines the national (India: Digital Personal Information Protection (DPDP) Act, 2023; NITI Aayog AI policy) and international (European Union\u2019s General Data Protection Regulation, GDPR) legal frameworks, which focus on data protection, transparency, and human interventions. This paper provides a important case study on the application of image processing and machine vision in HR recruitment at NovaHire Solutions, demonstrating and how AI-driven visual analytics can enhance justice, diversity, and the collaboration between human and artificial intelligence in decision-making together. The findings disclose the importance of oversight, impairment assessments, and training programs in ensuring the responsible and effective utilisation of AI for management of personnel..",
    "doi": "10.1109/ICIIP68302.2025.11346292",
    "url": "https://www.semanticscholar.org/paper/79e1a2270e3b3ff8cf51fb739fad4046a4f99afc",
    "pdf_url": "",
    "venue": "International Conference on Intelligent Information Processing",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140723"
  },
  {
    "source": "semantic_scholar",
    "source_id": "eba7cee9e4871e26fa41e1c47c972c1c00c38c8a",
    "title": "The Ethics of AI in Pricing: Fairness, Transparency, and Accountability",
    "authors": [
      "Divya Chaudhary"
    ],
    "year": 2025,
    "abstract": "The integration of artificial intelligence into pricing mechanisms represents a fundamental transformation in commercial practices, introducing unprecedented ethical complexities that challenge traditional notions of market fairness and consumer protection. AI-driven pricing systems leverage sophisticated machine learning algorithms to process vast datasets encompassing consumer behavior, market dynamics, and competitive intelligence, enabling real-time price adjustments that promise enhanced revenue optimization and personalized customer experiences. However, these technological capabilities simultaneously introduce a novel analytical framework for evaluating systematic discrimination, transparency deficits, and accountability gaps in AI pricing that extend far beyond individual transactions to encompass broader societal questions about economic justice and market power distribution. The pursuit of fairness in algorithmic pricing confronts multifaceted challenges stemming from embedded historical biases in training data, conflicting fairness metrics, and geographic discrimination patterns that can exacerbate existing inequalities. Transparency challenges emerge from the black box nature of complex neural networks and unprecedented information asymmetries between businesses and consumers, while responsibility attribution becomes problematic across multi-layered development teams and fragmented regulatory frameworks. The societal implications encompass consumer welfare impacts, market concentration risks, and the potential for algorithmic coordination that may undermine competitive market dynamics, necessitating comprehensive approaches to balance technological innovation with ethical considerations and consumer protection principles.",
    "doi": "10.22399/ijcesen.3949",
    "url": "https://www.semanticscholar.org/paper/eba7cee9e4871e26fa41e1c47c972c1c00c38c8a",
    "pdf_url": "",
    "venue": "International Journal of Computational and Experimental Science and Engineering",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140724"
  },
  {
    "source": "semantic_scholar",
    "source_id": "e65e36729355900b270f8ce497f1a2d6ca89a01b",
    "title": "Artificial Intelligence in Newsrooms: Ethical Challenges Facing Journalists",
    "authors": [
      "O. Al-Zoubi",
      "Normahfuzah Ahmad",
      "Norsiah Abdul Hamid"
    ],
    "year": 2024,
    "abstract": "Artificial intelligence has started to expand in journalism, especially in advanced news organisations. It is evident that journalists are beginning to realise the importance of AI and that it will be a partner to human journalists in their work inside newsrooms. Despite the numerous benefits that AI contributes to journalism, several challenges hinder the expansion and spread of its adoption among journalists. The ethical challenges of AI systems have become a concern among journalists. Therefore, this research is guided by the relationship between technological development and media ethics as the philosophical study of morality, specifically the Social Responsibility Theory. This study adopts a qualitative approach to explore the ethical challenges of AI faced by journalists. In-depth interviews were conducted with 14 journalists working in the newsroom of a government-affiliated channel, Al Mamlaka TV in Jordan. Data obtained from interviews conducted were analysed thematically. The results concluded that the main ethical challenges faced by journalists in the newsroom in adopting AI are data bias; privacy violations; and the absence of legislation and international regulations regarding the use of AI in journalism. The study concludes that journalists at Al Mamlaka TV adhere to the basics of Social Responsibility Theory through their critical adoption of AI in the newsroom.",
    "doi": "10.11114/smc.v12i1.6587",
    "url": "https://www.semanticscholar.org/paper/e65e36729355900b270f8ce497f1a2d6ca89a01b",
    "pdf_url": "https://redfame.com/journal/index.php/smc/article/download/6587/6440",
    "venue": "Studies in Media and Communication",
    "citation_count": 37,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140726"
  },
  {
    "source": "semantic_scholar",
    "source_id": "fd529d00882e1a6ba6f7ba92a6198860c8af0356",
    "title": "Artificial intelligence and the role of ethics",
    "authors": [
      "R. A. Quinn"
    ],
    "year": 2021,
    "abstract": "An ethical approach to AI does not function as bicycle brake on an intercontinental airplane. Ethics does not put insufficient brakes on progress. It does, however, asks how principles and values that are important for a democratic society can be translated into a digital democratic society. Beyond discussions of transparency, accountability, explainability, fairness and trustworthiness, this text focusses on two major issues: representation gaps \u2013 where minorities and a majority (women) are under- or misrepresented in data; and data silhouettes \u2013 where the body, the self and human life seems to be deciphered by data alone. Ethical reasoning thus insists that the non-quantifiable areas of human life are as important as any quantifiable aspects. An extensive quantification of the social, the political and the individual person must be continuously examined for its effects. Good regulation is not an obstacle to research and business, but that is necessary to create trust in AI systems.",
    "doi": "10.3233/SJI-210791",
    "url": "https://www.semanticscholar.org/paper/fd529d00882e1a6ba6f7ba92a6198860c8af0356",
    "pdf_url": "",
    "venue": "Statistical Journal of the IAOS",
    "citation_count": 6,
    "fields_of_study": [
      "Psychology"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140727"
  },
  {
    "source": "semantic_scholar",
    "source_id": "84b04f0ae6628766df776b804a9e81f6d73f9b2e",
    "title": "Improving Fine Arts Through Artificial Intelligence in Art Analysis, Production, and Restoration",
    "authors": [
      "Mona Ansari"
    ],
    "year": 2025,
    "abstract": "Artificial Intelligence transforms fine arts through innovations which support artistic analysis processes and artistic creation as well as restore artistic masterpieces. AI's impact on the field of fine arts focuses on three main areas including machine learning analysis for artwork understanding along with AI-generated art production as well as deep learning approaches for artwork restoration. Experimental studies analyze how AI performs regarding artwork restoration precision as well as artistic coherence maintaining and conservation speed while proving that AI improves upon traditional restoration techniques in terms of precision and scalability. The authentication of AI art creates ethics tests so do biases in databases and issues about cultural preservation. The paper presents the human-AI collaborative model which demonstrates AI functions as a creative enhancement instead of replacing artists. This study delivers a detailed view of AI's changes in artistic practices through research of present-day uses as well as hurdles and upcoming strategies. These findings enhance research about AI and human artistic collaboration by helping both technology development and ethical considerations related to artistic preservation.",
    "doi": "10.1109/ICCIAA65327.2025.11013667",
    "url": "https://www.semanticscholar.org/paper/84b04f0ae6628766df776b804a9e81f6d73f9b2e",
    "pdf_url": "",
    "venue": "2025 1st International Conference on Computational Intelligence Approaches and Applications (ICCIAA)",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140728"
  },
  {
    "source": "semantic_scholar",
    "source_id": "143051ba917aee1357ce5adc72e87568580de444",
    "title": "Guidance needed for using artificial intelligence to screen journal submissions for misconduct",
    "authors": [
      "Mohammad Hosseini",
      "David B Resnik"
    ],
    "year": 2024,
    "abstract": "Journals and publishers are increasingly using artificial intelligence (AI) to screen submissions for potential misconduct, including plagiarism and data or image manipulation. While using AI can enhance the integrity of published manuscripts, it can also increase the risk of false/unsubstantiated allegations. Ambiguities related to journals\u2019 and publishers\u2019 responsibilities concerning fairness and transparency also raise ethical concerns. In this Topic Piece, we offer the following guidance: (1) All cases of suspected misconduct identified by AI tools should be carefully reviewed by humans to verify accuracy and ensure accountability; (2) Journals/publishers that use AI tools to detect misconduct should use only well-tested and reliable tools, remain vigilant concerning forms of misconduct that cannot be detected by these tools, and stay abreast of advancements in technology; (3) Journals/publishers should inform authors about irregularities identified by AI tools and give them a chance to respond before forwarding allegations to their institutions in accordance with Committee on Publication Ethics guidelines; (4) Journals/publishers that use AI tools to detect misconduct should screen all relevant submissions and not just random/purposefully selected submissions; and (5) Journals should inform authors about their definition of misconduct, their use of AI tools to detect misconduct, and their policies and procedures for responding to suspected cases of misconduct.",
    "doi": "10.1177/17470161241254052",
    "url": "https://www.semanticscholar.org/paper/143051ba917aee1357ce5adc72e87568580de444",
    "pdf_url": "https://journals.sagepub.com/doi/pdf/10.1177/17470161241254052",
    "venue": "Research ethics",
    "citation_count": 16,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140730"
  },
  {
    "source": "semantic_scholar",
    "source_id": "f86a4e7abaa633228ec5d7914bf2e423b62f719f",
    "title": "Artificial intelligence in gynecologic and obstetric emergencies",
    "authors": [
      "H. Elbiss",
      "F. Abu-Zidan"
    ],
    "year": 2025,
    "abstract": "Artificial intelligence (AI) uses a process by which machines perform human-like functions such as automated clinical decisions. This may operate efficiently in gynecologic and obstetric emergencies. We aimed to review the role and applications of AI in gynecologic and obstetric emergencies. A literature search was carried out in November 2023 in PubMed, Cochrane Library and Google Scholar using the keywords combination of \u201cartificial intelligence, gynecology and obstetrics\u201d. Relevant articles were selected and read. Reference lists of the selected articles were also searched. The literature demonstrated the role of AI to improve healthcare in emergency settings in several aspects such as diagnostic imaging, improving predictions in emergencies, and improving planning and resource allocation for emergency services. AI works objectively, overcoming human biases in decision-making. Creating interconnected data registries for AI will likely enhance its performance. Validation research in emergency settings has shown that AI-prediction tools perform more accurately compared with the estimation of risk and outcomes by gynecologists and obstetricians in emergency situations including endometriosis and acute abdominal pain. There was acceptance of AI and its potential benefits. Ethical dilemmas of using AI include data governance, responsibility for errors, and security issues. Providing training on AI to healthcare professionals working in emergency departments is needed. Healthcare professionals should educate themselves about the anticipated role of AI in gynecologic and obstetric emergencies, its indications, limitations, and ethical considerations so that they can take steps towards its application in their future practice using defined guidelines.",
    "doi": "10.1186/s12245-025-00820-8",
    "url": "https://www.semanticscholar.org/paper/f86a4e7abaa633228ec5d7914bf2e423b62f719f",
    "pdf_url": "",
    "venue": "International Journal of Emergency Medicine",
    "citation_count": 5,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140731"
  },
  {
    "source": "semantic_scholar",
    "source_id": "6094d6efd2952030ba343e97348f7be155a4b9d1",
    "title": "Leveraging Artificial Intelligence in Breast Cancer Screening and Diagnosis",
    "authors": [
      "Abdul Haseeb Hasan",
      "Umar Abdul Rehman Khalid",
      "Muhammad Ali Abid"
    ],
    "year": 2025,
    "abstract": "Breast cancer remains the most prevalent malignancy worldwide, posing a significant public health burden due to its high incidence and mortality rates. Early detection through mammography has been instrumental in reducing breast cancer-related deaths; however, traditional screening methods are constrained by human limitations, including variability in interpretation and resource-intensive workflows. Artificial intelligence (AI) has emerged as a transformative tool in breast cancer diagnostics, leveraging machine learning (ML) and deep learning (DL) algorithms to enhance accuracy, efficiency, and accessibility. AI applications in digital mammography (DM), digital breast tomosynthesis (DBT), ultrasound, and magnetic resonance imaging (MRI) have demonstrated improved sensitivity and specificity, reducing false positives and false negatives while optimizing radiologist workload. Despite these advancements, challenges such as data accessibility, algorithm biases, regulatory constraints, and clinical integration hinder widespread AI adoption. Addressing these limitations requires standardized validation protocols, enhanced interpretability through explainable AI (XAI), and improved clinician and patient education. This editorial explores the evolving role of AI in breast cancer screening and diagnosis, emphasizing its potential to bridge healthcare disparities and improve global breast cancer outcomes.",
    "doi": "10.7759/cureus.79177",
    "url": "https://www.semanticscholar.org/paper/6094d6efd2952030ba343e97348f7be155a4b9d1",
    "pdf_url": "",
    "venue": "Cureus",
    "citation_count": 5,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140733"
  },
  {
    "source": "semantic_scholar",
    "source_id": "a19a3bb8957fd460e8f2db8ea5f120deca10b94d",
    "title": "Virtual Reality in Human Resource Management: Past, Present and Future Trends",
    "authors": [
      "Mohit Yadav",
      "Rahul Khurana",
      "N. Vihari",
      "Arun Mittal",
      "Arun Balodi",
      "A. Srivastava"
    ],
    "year": 2023,
    "abstract": "This paper presents a comprehensive bibliometric analysis of 416 research articles from 1993 to 2023, specifically focusing on applying Virtual Reality in Human Resource Management. The study delves into publishing trends, prominent journals, and noteworthy contributors, including authors, institutions, and countries. The findings offer valuable insights for researchers, aiding in selecting reputable journals for publication and highlighting key research topics and emerging subfields. Future research should explore integrating VR with emerging technologies like artificial intelligence and data analytics to develop sophisticated HR solutions while also investigating the ethical implications of VR in recruiting and employee training to ensure fairness and transparency. Additionally, exploring how VR can enhance diversity and inclusion in hiring procedures by promoting empathy and unbiased decision-making is a promising area for further study.",
    "doi": "10.1109/ICRASET59632.2023.10420290",
    "url": "https://www.semanticscholar.org/paper/a19a3bb8957fd460e8f2db8ea5f120deca10b94d",
    "pdf_url": "",
    "venue": "2023 International Conference on Recent Advances in Science and Engineering Technology (ICRASET)",
    "citation_count": 5,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140734"
  },
  {
    "source": "semantic_scholar",
    "source_id": "aba6cada1ff16fe91a738ce7ef8025dccc933b3b",
    "title": "Artificial intelligence in vaccine research and development: an umbrella review",
    "authors": [
      "Rabie Adel El Arab",
      "May Alkhunaizi",
      "Yousef N. Alhashem",
      "Alissar Al Khatib",
      "Munirah Bubsheet",
      "Salwa Hassanein"
    ],
    "year": 2025,
    "abstract": "Background The rapid development of COVID-19 vaccines highlighted the transformative potential of artificial intelligence (AI) in modern vaccinology, accelerating timelines from years to months. Nevertheless, the specific roles and effectiveness of AI in accelerating and enhancing vaccine research, development, distribution, and acceptance remain dispersed across various reviews, underscoring the need for a unified synthesis. Methods We conducted an umbrella review to consolidate evidence on AI\u2019s contributions to vaccine discovery, optimization, clinical testing, supply-chain logistics, and public acceptance. Five databases were systematically searched up to January 2025 for systematic, scoping, narrative, and rapid reviews, as well as meta-analyses explicitly focusing on AI in vaccine contexts. Quality assessments were performed using the ROBIS and AMSTAR 2 tools to evaluate risk of bias and methodological rigor. Results Among the 27 reviews, traditional machine learning approaches\u2014random forests, support vector machines, gradient boosting, and logistic regression\u2014dominated tasks from antigen discovery and epitope prediction to supply\u2011chain optimization. Deep learning architectures, including convolutional and recurrent neural networks, generative adversarial networks, and variational autoencoders, proved instrumental in multiepitope vaccine design and adaptive clinical trial simulations. AI\u2011driven multi\u2011omic integration accelerated epitope mapping, shrinking discovery timelines by months, while predictive analytics optimized manufacturing workflows and supply\u2011chain operations (including temperature\u2011controlled, \u201ccold\u2011chain\u201d logistics). Sentiment analysis and conversational AI tools demonstrated promising capabilities for real\u2011time monitoring of public attitudes and tailored communication to address vaccine hesitancy. Nonetheless, persistent challenges emerged\u2014data heterogeneity, algorithmic bias, limited regulatory frameworks, and ethical concerns over transparency and equity. Discussion and implications These findings illustrate AI\u2019s transformative potential across the vaccine lifecycle but underscore that translating promise into practice demands five targeted action areas: robust data governance and multi\u2011omics consortia to harmonize and share high\u2011quality datasets; comprehensive regulatory and ethical frameworks featuring transparent model explainability, standardized performance metrics, and interdisciplinary ethics committees for ongoing oversight; the adoption of adaptive trial designs and manufacturing simulations that enable real\u2011time safety monitoring and in silico process modeling; AI\u2011enhanced public engagement strategies\u2014such as routinely audited chatbots, real\u2011time sentiment dashboards, and culturally tailored messaging\u2014to mitigate vaccine hesitancy; and a concerted focus on global equity and pandemic preparedness through capacity building, digital infrastructure expansion, routine bias audits, and sustained funding in low\u2011resource settings. Conclusion This umbrella review confirms AI\u2019s pivotal role in accelerating vaccine development, enhancing efficacy and safety, and bolstering public acceptance. Realizing these benefits requires not only investments in infrastructure and stakeholder engagement but also transparent model documentation, interdisciplinary ethics oversight, and routine algorithmic bias audits. Moreover, bridging the gap from in silico promise to real\u2011world impact demands large\u2011scale validation studies and methods that can accommodate heterogeneous evidence, ensuring AI\u2011driven innovations deliver equitable global health outcomes and reinforce pandemic preparedness.",
    "doi": "10.3389/fimmu.2025.1567116",
    "url": "https://www.semanticscholar.org/paper/aba6cada1ff16fe91a738ce7ef8025dccc933b3b",
    "pdf_url": "",
    "venue": "Frontiers in Immunology",
    "citation_count": 28,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140736"
  },
  {
    "source": "semantic_scholar",
    "source_id": "a5599ee4bef37d2837af78949d36fd161d642844",
    "title": "The Transformative Role of Artificial Intelligence in Plastic and Reconstructive Surgery: Challenges and Opportunities",
    "authors": [
      "M. Mansoor",
      "Andrew F. Ibrahim"
    ],
    "year": 2025,
    "abstract": "Background/Objectives: This study comprehensively examines how artificial intelligence (AI) technologies are transforming clinical practice in plastic and reconstructive surgery across the entire patient care continuum, with the specific objective of identifying evidence-based applications, implementation challenges, and emerging opportunities that will shape the future of the specialty. Methods: A comprehensive narrative review was conducted analyzing the integration of AI technologies in plastic surgery, including preoperative planning, intraoperative applications, postoperative monitoring, and quality improvement. Challenges related to implementation, ethics, and regulatory frameworks were also examined, along with emerging technological trends that will shape future practice. Results: AI applications in plastic surgery demonstrate significant potential across multiple domains. In preoperative planning, AI enhances risk assessment, outcome prediction, and surgical simulation. Intraoperatively, AI-assisted robotics enables increased precision and technical capabilities beyond human limitations, particularly in microsurgery. Postoperatively, AI improves complication detection, pain management, and outcomes assessment. Despite these benefits, implementation faces challenges including data privacy concerns, algorithmic bias, liability questions, and the need for appropriate regulatory frameworks. Future directions include multimodal AI systems, federated learning approaches, and integration with extended reality and regenerative medicine technologies. Conclusions: The integration of AI into plastic surgery represents a significant opportunity to enhance surgical precision, improve outcome prediction, and expand the boundaries of what is surgically possible. However, successful implementation requires addressing ethical considerations and maintaining the human elements of surgical care. Plastic surgeons must actively engage with AI development to ensure these technologies address genuine clinical needs while aligning with the specialty\u2019s core values of restoring form and function, alleviating suffering, and enhancing quality of life.",
    "doi": "10.3390/jcm14082698",
    "url": "https://www.semanticscholar.org/paper/a5599ee4bef37d2837af78949d36fd161d642844",
    "pdf_url": "",
    "venue": "Journal of Clinical Medicine",
    "citation_count": 17,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140737"
  },
  {
    "source": "semantic_scholar",
    "source_id": "ac06b608b5f9d26eb37c12061bf70c91ef331a9d",
    "title": "Artificial intelligence in healthcare and medicine: clinical applications, therapeutic advances, and future perspectives",
    "authors": [
      "Yosri A. Fahim",
      "Ibrahim W. Hasani",
      "Samer Kabba",
      "Waleed Mahmoud Ragab"
    ],
    "year": 2025,
    "abstract": "Healthcare systems worldwide face growing challenges, including rising costs, workforce shortages, and disparities in access and quality, particularly in low- and middle-income countries. Artificial intelligence (AI) has emerged as a transformative tool capable of addressing these issues by enhancing diagnostics, treatment planning, patient monitoring, and healthcare efficiency. AI\u2019s role in modern medicine spans disease detection, personalized care, drug discovery, predictive analytics, telemedicine, and wearable health technologies. Leveraging machine learning and deep learning, AI can analyze complex data sets, including electronic health records, medical imaging, and genomic profiles, to identify patterns, predict disease progression, and recommend optimized treatment strategies. AI also has the potential to promote equity by enabling cost-effective, resource-efficient solutions in low-resource and remote settings, such as mobile diagnostics, wearable biosensors, and lightweight algorithms. Successful deployment requires addressing critical challenges, including data privacy, algorithmic bias, model interpretability, regulatory oversight, and maintaining human clinical oversight. Emphasizing scalable, ethical, and evidence-driven implementation, key strategies include clinician training in AI literacy, adoption of resource efficient tools, global collaboration, and robust regulatory frameworks to ensure transparency, safety, and accountability. By complementing rather than replacing healthcare professionals, AI can reduce errors, optimize resources, improve patient outcomes, and expand access to quality care. This review emphasizes the responsible integration of AI as a powerful catalyst for innovation, sustainability, and equity in healthcare delivery worldwide.",
    "doi": "10.1186/s40001-025-03196-w",
    "url": "https://www.semanticscholar.org/paper/ac06b608b5f9d26eb37c12061bf70c91ef331a9d",
    "pdf_url": "",
    "venue": "European Journal of Medical Research",
    "citation_count": 19,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424441"
  },
  {
    "source": "semantic_scholar",
    "source_id": "5938d49ce92e071dd3433e33d35daebfcacbdcd3",
    "title": "Scientific Map of Artificial Intelligence Research in Digital Business",
    "authors": [
      "Loso Judijanto",
      "Agung Zulfikri"
    ],
    "year": 2025,
    "abstract": "Th\u200cis study\u200b performs\u200b a bib\u200dl\u200biom\u2060etric\u200b an\u2060d scientometric evaluation of\u200b worldwide\u200d re\u200dsearch on Ar\u2060tificial Intelligence (AI) in Digital Business utilizing\u200c Scopus da\u200dta from 2020 to 2025. Ut\u200bili\u200czing VOSviewer\u200b and B\u200di\u2060bliometrix, we deli\u200cneate keyword co-occu\u200brrence\u200d, author c\u200dollaboration, and ins\u200dt\u2060itutional networks to disce\u200drn\u2060 prevailing c\u200blusters and\u200d emerg\u200ding fronts. Res\u200bults ind\u200dicate that digital busi\u200dness, digital t\u200dransfor\u2060mation,\u200b a\u200dnd\u2060 AI capabili\u200cties are\u200c fundamenta\u200cl the\u200dm\u200ces, whereas digital\u2060 ec\u2060o\u200bsystems, sustainability, res\u200dpons\u200ci\u200dble\u200b a\u200cnd t\u2060rustworthy inn\u200covation, and govern\u2060ance-focus\u200bed analyti\u2060cs are em\u200ce\u2060rging trends. Network analysis indica\u2060te\u200ds strong\u200c Eur\u2060opean connection\u200ds spear\u200cheaded by Geo\u200brg\u200d-\u200bAugust-Universit\u00e4t G\u00f6\u200cttingen,\u200b the Univ\u2060ersity of St\u2060. Gall\u200be\u200cn, and KU Leuven, alongside expandi\u200dng transatlantic relationsh\u200bip\u200bs and colla\u200cborative\u200b m\u2060ul\u200cti-institu\u200bti\u2060onal grou\u200cps. We t\u200dhe\u2060oretically comb\u200cine the Resource-Bas\u2060ed Vie\u200bw and\u200b Dynamic Capabilit\u200dies, pos\u2060iting that\u200d data as\u200bsets, algorithms\u200b, and human\u200d\u2013AI routines are strategi\u200bc r\u2060esources whose orc\u200bhestration f\u200cacil\u200di\u200dtates perceiving, seizin\u200cg, and reconfig\u200buring am\u200cid chaotic changes. The method\u200cological integratio\u200cn of perf\u200dor\u200bmance metrics with scientific mapping reveals\u200d the s\u200ctru\u200dcture, ma\u2060tu\u200crity\u200c, and interdisciplina\u200cry knowledge connections within fields such\u2060 as information sy\u2060ste\u200dms, management, and compute\u200dr science. The study prov\u200ci\u200ddes ma\u200bnageri\u200bal g\u200buidance for aligning\u200b technical innova\u200dtio\u200dn w\u200bith go\u2060ve\u200crnance and sustaina\u2060bili\u200dty: i\u2060nves\u200bt in inte\u2060r\u200copera\u200db\u2060le data inf\u200drastructure, imple\u200dment responsibl\u200be A\u200dI safegua\u200brd\u200ds, cultivate ambide\u2060xtrous teams\u2060, a\u200bnd assess val\u2060ue creat\u2060ion beyond prod\u2060uctivity, fo\u2060cusing on resil\u200dience and e\u200cnvironmental, social, and ethical out\u200ccomes. Po\u200bl\u200bicy implica\u2060ti\u200bons e\u2060ncom\u200cpa\u200dss inc\u200ben\u200dtives for open standards\u2060, developme\u200cnt of skills pipe\u200dline\u2060s, and f\u200bacilitatio\u200dn of c\u2060ross-bor\u2060de\u200br coll\u200daborat\u2060ion. Limitat\u200dions encompass exclu\u200dsive Scopus cover\u200dage, a predomi\u200dnance of English\u200b language, an\u200cd rapidly evolving terminolo\u200cgy; n\u200donetheless, triangulated a\u200bpp\u2060roaches reduce bias and offer a timely guide for resear\u200dche\u2060rs and decision-makers. Subs\u2060equent research should corroborate these findings using lon\u200cgitu\u2060dinal data\u2060s\u200bets.",
    "doi": "10.31004/riggs.v4i4.3255",
    "url": "https://www.semanticscholar.org/paper/5938d49ce92e071dd3433e33d35daebfcacbdcd3",
    "pdf_url": "",
    "venue": "RIGGS: Journal of Artificial Intelligence and Digital Business",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424456"
  },
  {
    "source": "semantic_scholar",
    "source_id": "f031fe645728d6fd36a9a36232cf19a846e9db73",
    "title": "Fairness, Accountability and Transparency in Artificial Intelligence: A Case Study of Logical Predictive Models",
    "authors": [
      "Kacper Sokol"
    ],
    "year": 2019,
    "abstract": "Machine learning -- the part of artificial intelligence aimed at eliciting knowledge from data and automated decision making without explicit instructions -- is making great strides, with new algorithms being invented every day. These algorithms find myriads of applications, but their ubiquity often comes at the expense of limited interpretability, hidden biases and unexpected vulnerabilities. Whenever one of these factors is a priority, the learning algorithm of choice is often a method considered to be inherently interpretable, e.g. logical models such as decision trees. In my research I challenge this assumption and highlight (quite common) cases when the assumed interpretability fails to deliver. To restore interpretability of logical machine learning models (decision trees and their ensembles in particular) I propose to explain them with class-contrastive counterfactual statements, which are a very common type of explanation in human interactions, well-grounded in social science research. To evaluate transparency of such models I collate explainability desiderata that can be used to systematically assess and compare such methods as an addition to user studies. Given contrastive explanations, I investigate their influence on the model's security, in particular gaming and stealing the model. Finally, I evaluate model fairness, where I am interested in choosing the most fair model among all the models with equal performance.",
    "doi": "10.1145/3306618.3314316",
    "url": "https://www.semanticscholar.org/paper/f031fe645728d6fd36a9a36232cf19a846e9db73",
    "pdf_url": "",
    "venue": "AAAI/ACM Conference on AI, Ethics, and Society",
    "citation_count": 11,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424461"
  },
  {
    "source": "semantic_scholar",
    "source_id": "7327f152502e8d7a80989772deace698410afaf0",
    "title": "Artificial intelligence studies in cartography: a review and synthesis of methods, applications, and ethics",
    "authors": [
      "Yuhao Kang",
      "Song Gao",
      "Robert E. Roth"
    ],
    "year": 2023,
    "abstract": "ABSTRACT The past decade has witnessed the rapid development of geospatial artificial intelligence (GeoAI) primarily due to the ground-breaking achievements in deep learning and machine learning. A growing number of scholars from cartography have demonstrated successfully that GeoAI can accelerate previously complex cartographic design tasks and even enable cartographic creativity in new ways. Despite the promise of GeoAI, researchers and practitioners have growing concerns about the ethical issues of GeoAI for cartography. In this paper, we conducted a systematic content analysis and narrative synthesis of research studies integrating GeoAI and cartography to summarize current research and development trends regarding the usage of GeoAI for cartographic design. Based on this review and synthesis, we first identify dimensions of GeoAI methods for cartography such as data sources, data formats, map evaluations, and six contemporary GeoAI models, each of which serves a variety of cartographic tasks. These models include decision trees, knowledge graph and semantic web technologies, deep convolutional neural networks, generative adversarial networks, graph neural networks, and reinforcement learning. Further, we summarize seven cartographic design applications where GeoAI have been effectively employed: generalization, symbolization, typography, map reading, map interpretation, map analysis, and map production. We also raise five potential ethical challenges that need to be addressed in the integration of GeoAI for cartography: commodification, responsibility, privacy, bias, and (together) transparency, explainability, and provenance. We conclude by identifying four potential research directions for future cartographic research with GeoAI: GeoAI-enabled active cartographic symbolism, human-in-the-loop GeoAI for cartography, GeoAI-based mapping-as-a-service, and generative GeoAI for cartography.",
    "doi": "10.1080/15230406.2023.2295943",
    "url": "https://www.semanticscholar.org/paper/7327f152502e8d7a80989772deace698410afaf0",
    "pdf_url": "",
    "venue": "Cartography and Geographic Information Science",
    "citation_count": 63,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424466"
  },
  {
    "source": "semantic_scholar",
    "source_id": "6d128e070b7466d0894fde735e27f17aa848ad14",
    "title": "Artificial Intelligence For Decision Making In The Era Of Big Data Evolution",
    "authors": [
      "Rebeka Sultana"
    ],
    "year": 2024,
    "abstract": "This study systematically examines the transformative role of Artificial Intelligence (AI) in decision-making, focusing on its applications, challenges, and future opportunities. Using the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines, a total of 100 peer-reviewed articles were analyzed to ensure a rigorous and comprehensive understanding of the subject. The findings highlight AI's ability to optimize decision-making processes through advanced technologies such as machine learning, natural language processing, and predictive analytics, significantly enhancing accuracy, efficiency, and responsiveness across diverse sectors such as healthcare, finance, supply chain management, and public administration. Despite these advancements, the study identifies persistent challenges, including algorithmic bias, data privacy concerns, and the lack of transparency in \"black box\" AI models, which undermine trust and accountability. Additionally, the review uncovers research gaps, particularly in low-resource settings and emerging markets, where AI's potential remains underutilized due to infrastructural and data limitations. The integration of AI with emerging technologies, such as blockchain, quantum computing, and edge computing, presents promising opportunities to enhance scalability, security, and transparency in decision-making. The study also underscores the importance of interdisciplinary research, particularly at the intersection of AI and social sciences, to better understand human-AI interaction and foster ethical and socially equitable AI adoption. By addressing these challenges and leveraging emerging opportunities, AI can evolve into a transformative tool for informed, inclusive, and responsible decision-making in an increasingly complex world.",
    "doi": "10.70008/jbimisr.v1i01.59",
    "url": "https://www.semanticscholar.org/paper/6d128e070b7466d0894fde735e27f17aa848ad14",
    "pdf_url": "",
    "venue": "Non human journal",
    "citation_count": 12,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424470"
  },
  {
    "source": "semantic_scholar",
    "source_id": "d5023caaebebe75ba09927a0f4fabe55c356c2ea",
    "title": "THE USE OF ARTIFICIAL INTELLIGENCE IN JUDICIAL DECISIONMAKING: THE EXAMPLE OF CHINA",
    "authors": [
      "U. Tahura",
      "Niloufer Selvadurai"
    ],
    "year": 2023,
    "abstract": "\u00a0The paper analyses whether and to what extent AI-assisted judicial decision-making systems uphold the fundamental values that underpin the exercise of judicial discretion. As China is at the forefront of developing systems to simulate judicial thought, the paper explores this issue through the lens of China \u201csmart court\u201d. Beginning by considering how AI-assisted judicial decision making differs from traditional human judicial decision-making, the paper progresses to identify areas of legal concern as to the use of AI in judicial decision-making. Building on this analysis, the paper progresses to examine the use of AI in the China smart court system, including the \u201cautomated reason-generation framework\u201d and \u201cdeviation analysis\u201d adopted in the smart courts of China. The paper concludes by suggesting that the use of AI in judicial decision-making needs to appropriately calibrate the efficiency gains of automated processes with the need to maintain transparency and accountability, avoid bias and ensure a fair process.",
    "doi": "10.55574/pyeb5374",
    "url": "https://www.semanticscholar.org/paper/d5023caaebebe75ba09927a0f4fabe55c356c2ea",
    "pdf_url": "https://www.ijlet.org/wp-content/uploads/2023/03/2022-3-1-20.pdf",
    "venue": "International Journal of Law, Ethics, and Technology",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424475"
  },
  {
    "source": "semantic_scholar",
    "source_id": "30c1f17071d60cac17de99cce5b92217c1def9ea",
    "title": "Execution of Artificial Intelligence Approach in Human Resource Management Functions: Benefits and Challenges in Pakistan",
    "authors": [
      "Munaza Bibi"
    ],
    "year": 2019,
    "abstract": "Artificial intelligence has a theatrical effect on management of the workforce in the future.\u00a0This paper has highlighted the benefits and challenges to adoption of artificial intelligence approach in human resource management functions in Pakistan. Artificial intelligence-based human resource applications have robust potential to increase employee performance, engagement & retention while it also helps to reduce turnover, errors, time & biases in HR decision making. Artificial Intelligence needs to be incorporated by the organization in Pakistan for effective people management and HR decisions. Reluctance to the adoption of artificial intelligence in human resource management functions can demonstrate the devastating effect on the overall growth of the organization; thus, human resource leaders should prepare and train the human resource for the adoption of artificial intelligence & also address the concerns regarding man & machine interactions at the workplace. Yet, artificial intelligence cannot substitute the human element in human resource management, although if artificial intelligence united with capabilities of a human, would fetch on more intelligent solutions for HR. Hence, in today\u2019s world, artificial intelligence is a formula for the success of HR.",
    "doi": "10.31529/SJMS.2018.5.1.8",
    "url": "https://www.semanticscholar.org/paper/30c1f17071d60cac17de99cce5b92217c1def9ea",
    "pdf_url": "https://doi.org/10.31529/sjms.2018.5.1.8",
    "venue": "Sarhad Journal of Management Sciences",
    "citation_count": 8,
    "fields_of_study": [
      "Business"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424479"
  },
  {
    "source": "semantic_scholar",
    "source_id": "83c1d9490bd2202c7527ff6afcc738b0d3044721",
    "title": "AI in Human Resource Management: Reimagining Talent Acquisition, Development, and Retention",
    "authors": [
      "Abdumalik M. Kadirov",
      "Yulduzkhon Shakirova",
      "Gulshodakhon Ismoilova",
      "N. Makhmudova"
    ],
    "year": 2024,
    "abstract": "The integration of Artificial Intelligence (AI) into Human Resource Management (HRM) heralds a transformative era for talent acquisition, development, and retention strategies. AI technologies, including Machine Learning (ML), Natural Language Processing (NLP), Robotics Process Automation (RPA), and Predictive Analytics, offer unprecedented opportunities to streamline HR processes, enhance decision-making, and improve overall organizational efficiency. This survey paper explores the multifaceted applications of AI within HRM, focusing on how these technologies are redefining traditional practices in talent management. In talent acquisition, AI-driven tools automate resume screening and facilitate sophisticated candidate search and engagement strategies, enabling a more efficient and effective recruitment process. For talent development, AI applications personalize learning experiences and optimize performance management, addressing individual needs and promoting skill advancement. Additionally, AI\u2019s role in talent retention, through predictive turnover models and employee engagement platforms, underscores its potential to significantly lower turnover rates and foster a committed workforce. Despite these advancements, the paper also addresses the challenges and ethical considerations inherent in AI implementation, including algorithmic bias and privacy concerns. Through comparative analysis and illustrative graphs, this study provides a comprehensive overview of current trends and future directions in AI-enhanced HRM, offering valuable insights for practitioners and policymakers aiming to navigate the complexities of technology-driven human resource strategies.",
    "doi": "10.1109/ICKECS61492.2024.10617231",
    "url": "https://www.semanticscholar.org/paper/83c1d9490bd2202c7527ff6afcc738b0d3044721",
    "pdf_url": "",
    "venue": "2024 International Conference on Knowledge Engineering and Communication Systems (ICKECS)",
    "citation_count": 12,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424483"
  },
  {
    "source": "semantic_scholar",
    "source_id": "7faff5b4f3fd3cbcc9b9ce61a0a371e13be1c9bb",
    "title": "The ethical issues of the application of artificial intelligence in healthcare: a systematic scoping review",
    "authors": [
      "Golnar Karimian",
      "Elena Petelos",
      "S. Evers"
    ],
    "year": 2022,
    "abstract": "Artificial intelligence (AI) is being increasingly applied in healthcare. The expansion of AI in healthcare necessitates AI-related ethical issues to be studied and addressed. This systematic scoping review was conducted to identify the ethical issues of AI application in healthcare, to highlight gaps, and to propose steps to move towards an evidence-informed approach for addressing them. A systematic search was conducted to retrieve all articles examining the ethical aspects of AI application in healthcare from Medline (PubMed) and Embase (OVID), published between 2010 and July 21, 2020. The search terms were \u201cartificial intelligence\u201d or \u201cmachine learning\u201d or \u201cdeep learning\u201d in combination with \u201cethics\u201d or \u201cbioethics\u201d. The studies were selected utilizing a PRISMA flowchart and predefined inclusion criteria. Ethical principles of respect for human autonomy, prevention of harm, fairness, explicability, and privacy were charted. The search yielded 2166 articles, of which 18 articles were selected for data charting on the basis of the predefined inclusion criteria. The focus of many articles was a general discussion about ethics and AI. Nevertheless, there was limited examination of ethical principles in terms of consideration for design or deployment of AI in most retrieved studies. In the few instances where ethical principles were considered, fairness, preservation of human autonomy, explicability and privacy were equally discussed. The principle of prevention of harm was the least explored topic. Practical tools for testing and upholding ethical requirements across the lifecycle of AI-based technologies are largely absent from the body of reported evidence. In addition, the perspective of different stakeholders is largely missing.",
    "doi": "10.1007/s43681-021-00131-7",
    "url": "https://www.semanticscholar.org/paper/7faff5b4f3fd3cbcc9b9ce61a0a371e13be1c9bb",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s43681-021-00131-7.pdf",
    "venue": "AI and Ethics",
    "citation_count": 160,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424487"
  },
  {
    "source": "semantic_scholar",
    "source_id": "ff1be9a8d273588ada4575856eabea44a8bb4494",
    "title": "Ethical Concerns With Regards to Artificial Intelligence: A National Public Poll in Taiwan",
    "authors": [
      "Wendy Li-Yun Chang",
      "Shiang-Yao Liu",
      "Ying-Kai Liao",
      "Tony Szu-Hsien Lee"
    ],
    "year": 2024,
    "abstract": "Ethical concerns about how artificial intelligence (AI) impacts individuals and society are increasing rapidly, but few studies have systematically investigated the public awareness of AI ethics. This research collected and analyzed data from a public poll in Taiwan, an Asian region with a developed economy and specific social conditions, to identify societal views on AI ethics. The analysis of 84 AI ethics guidelines worldwide provided the survey framework covering five ethical principles: transparency, fairness, privacy, nonmaleficence, and accountability. The overarching goal was to determine the commonalities and differences in the ethical concerns of Taiwanese laypersons toward AI. Participants aged from 20 to 70 ( $N =1$ ,200) completed a computer-assisted random-digit-dial telephone survey, which utilized ethical scenarios to capture social views, and item validity was confirmed using focus-group interviews. Results found that respondents concerned about nonmaleficence the most, emphasizing that AI applications should not harm humans. Taiwanese people therefore tended to support strict AI technology regulation. It was particularly interesting that different patterns of public concern emerged about accountability, with the opinions on attributing responsibility to stakeholders varying with scenarios and the public\u2019s backgrounds. Those with higher education levels tended to attribute more responsibility to the industry, whereas those who had only received elementary-school education attributed accountability to AI developers. For self-driving cars, accountability was attributed to AI developers, whereas for medical decision-making, the accountability was attributed to the hospitals. These findings may help to elucidate the associations between societal views and the ethical principles of AI worldwide.",
    "doi": "10.1109/ACCESS.2024.3458893",
    "url": "https://www.semanticscholar.org/paper/ff1be9a8d273588ada4575856eabea44a8bb4494",
    "pdf_url": "https://doi.org/10.1109/access.2024.3458893",
    "venue": "IEEE Access",
    "citation_count": 3,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424492"
  },
  {
    "source": "semantic_scholar",
    "source_id": "0fb1acc52f09c05ba96fe3eb7b4395eff20653a4",
    "title": "Artificial Intelligence and Sensor Innovations: Enhancing Livestock Welfare with a Human-Centric Approach",
    "authors": [
      "S. Neethirajan"
    ],
    "year": 2023,
    "abstract": "In the wake of rapid advancements in artificial intelligence (AI) and sensor technologies, a new horizon of possibilities has emerged across diverse sectors. Livestock farming, a domain often sidelined in conventional AI discussions, stands at the cusp of this transformative wave. This paper delves into the profound potential of AI and sensor innovations in reshaping animal welfare in livestock farming, with a pronounced emphasis on a human-centric paradigm. Central to our discourse is the symbiotic interplay between cutting-edge technology and human expertise. While AI and sensor mechanisms offer real-time, comprehensive, and objective insights into animal welfare, it\u2019s the farmer\u2019s intrinsic knowledge of their livestock and environment that should steer these technological strides. We champion the notion of technology as an enhancer of farmers\u2019 innate capabilities, not a substitute. Our manuscript sheds light on: Objective Animal Welfare Indicators: An exhaustive exploration of health, behavioral, and physiological metrics, underscoring AI\u2019s prowess in delivering precise, timely, and objective evaluations. Farmer-Centric Approach: A focus on the pivotal role of farmers in the adept adoption and judicious utilization of AI and sensor technologies, coupled with discussions on crafting intuitive, pragmatic, and cost-effective solutions tailored to farmers' distinct needs. Ethical and Social Implications: A discerning scrutiny of the digital metamorphosis in farming, encompassing facets like animal privacy, data safeguarding, responsible AI deployment, and potential technological access disparities. Future Pathways: Advocacy for principled technology design, unambiguous responsible use guidelines, and fair technology access, all echoing the fundamental principles of human-centric computing and analytics. In essence, our paper furnishes pioneering insights at the crossroads of farming, animal welfare, technology, and ethics. It presents a rejuvenated perspective, bridging the chasm between technological advancements and their human beneficiaries, resonating seamlessly with the ethos of the Human-Centric Intelligent Systems journal. This comprehensive analysis thus marks a significant stride in the burgeoning domain of human-centric intelligent systems, especially within the digital livestock farming landscape, fostering a harmonious coexistence of technology, animals, and humans.",
    "doi": "10.1007/s44230-023-00050-2",
    "url": "https://www.semanticscholar.org/paper/0fb1acc52f09c05ba96fe3eb7b4395eff20653a4",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s44230-023-00050-2.pdf",
    "venue": "Human-Centric Intelligent Systems",
    "citation_count": 77,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424496"
  },
  {
    "source": "semantic_scholar",
    "source_id": "e88e53874dba0f058e55b729f11deaae4b65ea7a",
    "title": "PROS AND CONS OF USING ALGORITHMIC MANAGEMENT IN HUMAN RESOURCE",
    "authors": [
      "Miglena Angelova"
    ],
    "year": 2024,
    "abstract": "The opportunities that Artificial Intelligence and the principles of Algorithmic management provide to modern managers bring undeniable advantages for the development of a competitive business in today's extremely difficult business environment. At the same time, however, the effect of their use should be carefully analysed from the point of view of the compliance of the employees opinion in the enterprise - mainly in line with the observance and guarantee of basic rights of the employees. In this regard, the European Parliament and the European Council launched a legislative initiative to define harmonized rules within the Community on the use of artificial intelligence. Concepts such as \"algorithmic discrimination\" were introduced quite purposefully at the regulation level, given the risk of possible abuses associated with the use of AI. This report aims to ascertain the views of employers and employees on the use of artificial intelligence in Human Resource Management. The report presents and analyses data from an empirical study conducted among managers and employees in leading ICT enterprises in Bulgaria. According to our responders, one of the biggest advantages of using AI in Human Resources Management is related to the elimination of subjectivity in performance evaluation and the possibility of fair play in the procedures of internal selection of employees. At the same time, employees with more experience (over 10 years) are more sceptical of the idea of their work performance being evaluated solely by AI, while younger workers show more trust in AI solutions. However, both managers and workers recognize that it is best for the final decision in determining career development to be made by a person, but justified by the analyses made by AI. The report draws conclusions and recommendations that can serve both researchers and business managers. Certainly, AI is yet to undergo a very large development and application, including in the Human Resource Management, but at the same time it should not be at the expense of affected rights.",
    "doi": "10.17770/etr2024vol2.8031",
    "url": "https://www.semanticscholar.org/paper/e88e53874dba0f058e55b729f11deaae4b65ea7a",
    "pdf_url": "https://journals.ru.lv/index.php/ETR/article/download/8031/6341",
    "venue": "ENVIRONMENT. TECHNOLOGIES. RESOURCES. Proceedings of the International Scientific and Practical Conference",
    "citation_count": 3,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424499"
  },
  {
    "source": "semantic_scholar",
    "source_id": "411b5978e3983f617826fff6171b30fd44dd8744",
    "title": "The Gig Economy and Automation: Implications for Human Resource Management in Pakistan",
    "authors": [
      "Madiha Bashir",
      "Syeda Noor-e-Zahra",
      "Zobia Qaisar"
    ],
    "year": 2024,
    "abstract": "In the face of ground-breaking advancements such as automation, artificial intelligence, and the gig economy, the realm of human resource management (HRM) is undergoing a profound transformation. As the nature of work evolves, HRM practices must adapt to ensure both organizational performance and employee well-being. A primary focus of the study is the increasing emphasis on workforce flexibility. The rise of remote work, flexible schedules, and contingent labour has necessitated a shift in HRM practices. This research explores how organizations can effectively manage a diverse workforce while maintaining productivity and employee satisfaction. Additionally, the study examines the impact of job changes, including automation-driven task shifts and the emergence of new roles. It investigates how HR professionals can assist employees in adapting to these changes and acquiring the necessary skills for the future of work. Ethical considerations are also a central theme of this research. With the rise of AI and automation, questions surrounding data privacy, algorithmic bias, and ethical decision-making in the workplace have become increasingly pressing. The study explores the ethical implications of these technologies and provides guidance for HR professionals on developing ethical policies and practices. This research study underscores the critical role of HRM in fostering a productive and supportive work environment. It highlights the need for HR professionals to be strategic partners with business leaders, aligning HR practices with overall organizational goals. By understanding the challenges and opportunities presented by these revolutionary developments, HR professionals can equip their organizations to navigate the complexities of the contemporary workplace and achieve long-term success. This research offers a valuable resource for HR professionals, business executives, and policymakers seeking to understand the changing landscape of HRM and develop effective strategies for managing their workforce in the face of technological advancements and evolving workforce dynamics. \nReferences \nAdams-Prassl, J. (2019). What if your boss was an algorithm? Economic incentives, legal challenges, and the rise of artificial intelligence at work.\u00a0Comp. Lab. L. & Pol'y J.,\u00a041, 123. \nAli, Z., & Niaz, A. (2024). Impact of Leadership Styles on the Employees\u2019 Engagement in Private Healthcare Industry of UAE.\u00a0Inverge Journal of Social Sciences,\u00a03(1), 7-27. \nAlizai, S. H., Asif, M., & Rind, Z. K. (2021). Relevance of Motivational Theories and Firm Health.\u00a0Management (IJM),\u00a012(3), 1130-1137. \nAli, Z. A., Zain, M., Pathan, M. S., & Mooney, P. (2024). Contributions of artificial intelligence for circular economy transition leading toward sustainability: an explorative study in agriculture and food industries of Pakistan.\u00a0Environment, Development and Sustainability,\u00a026(8), 19131-19175. \nAsif, D. M. (2024). THE COMPLEXITIES OF BIOTERRORISM: CHALLENGES AND CONSIDERATIONS.\u00a0International Journal of Contemporary Issues in Social Sciences,\u00a03(3), 2175-2184. \nAsif, M. (2022). Integration of Information Technology in Financial Services and its Adoption by the Financial Sector in Pakistan.\u00a0Inverge Journal of Social Sciences,\u00a01(2), 23-35. \nAsif, M. (2021). Contingent Effect of Conflict Management towards Psychological Capital and Employees\u2019 Engagement in Financial Sector of Islamabad.\u00a0Preston University, Kohat, Islamabad Campus. \nAsif, M., Khan, A., & Pasha, M. A. (2019). Psychological capital of employees\u2019 engagement: moderating impact of conflict management in the financial sector of Pakistan.\u00a0Global Social Sciences Review, IV, 160-172. \nAsif, M., Pasha, M. A., Mumtaz, A., & Sabir, B. (2023). Causes of youth unemployment in Pakistan.\u00a0Inverge Journal of Social Sciences,\u00a02(1), 41-50. \nAsif, M., Pasha, M. A., Shafiq, S., & Craine, I. (2022). Economic impacts of post COVID-19.\u00a0Inverge Journal of Social Sciences,\u00a01(1), 56-65. \nAsif, M., & Sandhu, M. S. (2023). Social Media Marketing Revolution in Pakistan: A Study of its Adoption and Impact on Business Performance.\u00a0Journal of Business Insight and Innovation,\u00a02(2), 67-77. \nAsif, M., & Shaheen, A. (2022). Creating a High-Performance Workplace by the determination of Importance of Job Satisfaction, Employee Engagement, and Leadership.\u00a0Journal of Business Insight and Innovation,\u00a01(2), 9-15. \nAsif, M., Pasha, M. A., Shafiq, S., & Craine, I. (2022). Economic impa{Asif, 2023 #79}cts of post COVID-19.\u00a0Inverge Journal of Social Sciences,\u00a01(1), 56-65. \nAsghar, R. J., Qayyum, A., Zaheer, A., Mughal, A., & Khalid, S. (2011). Implementation of HR Practices in University Teachers of Pakistan. Information Management and Business Review, 3(3), 148-157. \nAsghar, R. J., Shah, M. U. Z. A. M. M. E. L., & Khan, J. A. (2021). Big Five Personality Traits and Training Transfer: Does Organizational Politics Matters.\u00a0International Review of Basic and Applied Sciences,\u00a09(4), 457-469. \nAurangzeb, M. A. (2021). Role of Leadership in Digital Transformation: A Case of Pakistani SMEs. \nAurangzeb, A. (2021). M., & Amin, MK (2021). Resources management and SME's performance.\u00a0Humanities & Social Sciences Reviews,\u00a09(3), 679-689. \nAurangzeb, M., Tunio, M., Rehman, Z., & Asif, M. (2021). Influence of administrative expertise on human resources practitioners on the job performance: Mediating role of achievement motivation.\u00a0International Journal of Management,\u00a012(4), 408-421. \nAzad, T. (2023). The Impact of Technology in the Classroom: An Insight into Students' and Teachers' Psychological Perspectives.\u00a0Inverge Journal of Social Sciences,\u00a02(2), 66-83. \nChintaradeja, P. (2022). Rhodes\u2019 governance concept in relation to Thai public service.\u00a0Inverge Journal of Social Sciences,\u00a01(1), 1-12. \nChompupor, P. (2023). The MICE labour market challenges in Thailand from experts\u2019 perspective.\u00a0Inverge Journal of Social Sciences,\u00a02(2), 165\u2013175. \nDe Stefano, V. (2020). Algorithmic bosses and what to do about them: automation, artificial intelligence and labour protection.\u00a0Economic and policy implications of artificial intelligence, 65-86. \nDarkwa, E., Inguva, H., Osafo-Adjei, C., & Acquah, B. (2024). The public sphere on a digital plane: The influence of the new digital media on Ghana\u2019s democracy and the Public Sphere.\u00a0Inverge Journal of Social Sciences,\u00a03(2), 46-62. \nInyang, U., G. Etuk, S., & Effiom, M. (2024). Employees\u2019 Assessment of Impact of Information Systems on Operational Efficiency of Insurance Companies.\u00a0Inverge Journal of Social Sciences,\u00a03(3), 1\u201312. \nIqbal, M. S., Rahim, Z. A., & Hussain, S. A. (2020). Industry 4.0 revolution and challenges in developing countries: a case study on Pakistan.\u00a0Journal of Advanced Research in Business and Management Studies,\u00a021(1), 40-52. \nIshfaq, U., Imran, A., Joseph, V., Haqdad, U., & Asif, M. (2022). Mediating role of trust between emotional intelligence and project team performance in telecommunication sector.\u00a0PalArch's Journal of Archaeology of Egypt/Egyptology,\u00a019(4), 988-1005. \nJamil, S. (2021). Artificial intelligence and journalistic practice: The crossroads of obstacles and opportunities for the Pakistani journalists.\u00a0Journalism Practice,\u00a015(10), 1400-1422. \nKhan, M. H. (2023). The role of recruitment and selection on organizational performance: An empirical investigation into the impact of recruitment and selection on organizational performance.\u00a0Inverge Journal of Social Sciences,\u00a02(2), 146-164. \nKhan, M. H. (2023). The influence of green HRM practices and green knowledge sharing on green service behaviors: Environmental Sustainability at Work: How Green HRM and Knowledge Transfer Influence Green Service Behaviors.\u00a0Inverge Journal of Social Sciences,\u00a02(2), 176-193. \nKhatun, R. (2023). Work from Home in Pandemic - An Indian Perspective.\u00a0Inverge Journal of Social Sciences,\u00a02(3), 77\u201395.\u00a0 \nMalik, A., Budhwar, P., & Srikanth, N. R. (2020). Gig economy, 4IR and artificial intelligence: Rethinking strategic HRM. In\u00a0Human & technological resource management (HTRM): New insights into revolution 4.0\u00a0(pp. 75-88). Emerald Publishing Limited. \nMangi, R. A., Jhatial, A. A., Shah, S. A. A., & Ghumro, I. A. (2012). Human resource management practices in private sector organisations in Pakistan: study of cultural influences.\u00a0Global Journal of Management and Business Research,\u00a012(7), 20-30. \nMirza, M. S., & Rashid, S. (2024). Effect of Online Cooperative Learning on Students\u2019 Academic Achievement at Higher Education Level.\u00a0Inverge Journal of Social Sciences,\u00a03(2), 1-10. \nMumtaz, A., Munir, N., Mumtaz, R., Farooq, M., & Asif, M. (2023). Impact of Psychological & Economic Factors on Investment Decision-Making in Pakistan Stock Exchange.\u00a0Journal of Positive School Psychology, 130-135. \nMushtaque, T., Tunio, M. N., ur Rehman, Z., & Asif, M. (2021). INFLUENCE OF ADMINISTRATIVE EXPERTISE OF HUMAN RESOURCE PRACTITIONERS ON THE JOB PERFORMANCE: MEDIATING ROLE OF ACHIEVEMENT MOTIVATION.\u00a0International Journal of Management (IJM),\u00a012(4). \nNabi, M. K. (2019). The impact of artificial intelligence (AI) on workforce in emerging economies.\u00a0Global Journal of Management and Business Research,\u00a019(8), 71-78. \nNadeem, M., Ali, Y., Rehman, O. U., & Saarinen, L. T. (2024). Barriers and strategies for digitalisation of economy in developing countries: Pakistan, a case in point.\u00a0Journal of the Knowledge Economy,\u00a015(1), 4730-4749. \nNimmagadda, B., Vangaveti, Y., Aaluri, S., Rao, C. M., & Singh, B. (2024). An Analytical study on Navigating Sustainability Challenges and Opportunities in the era of AI and the Gig Economy. In\u00a0MATEC Web of Conferences\u00a0(Vol. 392, p. 01044). EDP Sciences. \nNishtar, Z., Munir, M. A., Akram, N., Masood, B., Asghar, F., & Meahrayen, M. A. (2023). Green Finance and the Automate Solar Tracking System: Assessing Efficiency, Financial impact, and Environmental Benefits.\u00a0Inverge Journal of Social Sciences,\u00a02(3), 134-147. \nPasha, M. A., Ramzan, M., & Asif, M. (2019). Impact of Economic Value Added Dynamics on Stock Prices ",
    "doi": "10.63544/ijss.v3i3.90",
    "url": "https://www.semanticscholar.org/paper/411b5978e3983f617826fff6171b30fd44dd8744",
    "pdf_url": "",
    "venue": "Inverge Journal of Social Sciences",
    "citation_count": 2,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424504"
  },
  {
    "source": "semantic_scholar",
    "source_id": "5317d9d7f6b8ad4c67a89f53ee31c3bc875db933",
    "title": "\u201cJust\u201d accuracy? Procedural fairness demands explainability in AI-based medical resource allocations",
    "authors": [
      "J. Rueda",
      "J. Rodr\u00edguez",
      "Iris Parra Jounou",
      "J. Hortal-Carmona",
      "T. Aus\u00edn",
      "D. Rodr\u00edguez-Arias"
    ],
    "year": 2022,
    "abstract": "The increasing application of artificial intelligence (AI) to healthcare raises both hope and ethical concerns. Some advanced machine learning methods provide accurate clinical predictions at the expense of a significant lack of explainability. Alex John London has defended that accuracy is a more important value than explainability in AI medicine. In this article, we locate the trade-off between accurate performance and explainable algorithms in the context of distributive justice. We acknowledge that accuracy is cardinal from outcome-oriented justice because it helps to maximize patients\u2019 benefits and optimizes limited resources. However, we claim that the opaqueness of the algorithmic black box and its absence of explainability threatens core commitments of procedural fairness such as accountability, avoidance of bias, and transparency. To illustrate this, we discuss liver transplantation as a case of critical medical resources in which the lack of explainability in AI-based allocation algorithms is procedurally unfair. Finally, we provide a number of ethical recommendations for when considering the use of unexplainable algorithms in the distribution of health-related resources.",
    "doi": "10.1007/s00146-022-01614-9",
    "url": "https://www.semanticscholar.org/paper/5317d9d7f6b8ad4c67a89f53ee31c3bc875db933",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s00146-022-01614-9.pdf",
    "venue": "Ai & Society",
    "citation_count": 38,
    "fields_of_study": [
      "Medicine",
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424509"
  },
  {
    "source": "semantic_scholar",
    "source_id": "36d9f42cd27c91e56587602723cfa7e9d4203386",
    "title": "Establishing Data Provenance for Responsible Artificial Intelligence Systems",
    "authors": [
      "K. Werder",
      "B. Ramesh",
      "Rongen Zhang"
    ],
    "year": 2022,
    "abstract": "Data provenance, a record that describes the origins and processing of data, offers new promises in the increasingly important role of artificial intelligence (AI)-based systems in guiding human decision making. To avoid disastrous outcomes that can result from bias-laden AI systems, responsible AI builds on four important characteristics: fairness, accountability, transparency, and explainability. To stimulate further research on data provenance that enables responsible AI, this study outlines existing biases and discusses possible implementations of data provenance to mitigate them. We first review biases stemming from the data's origins and pre-processing. We then discuss the current state of practice, the challenges it presents, and corresponding recommendations to address them. We present a summary highlighting how our recommendations can help establish data provenance and thereby mitigate biases stemming from the data's origins and pre-processing to realize responsible AI-based systems. We conclude with a research agenda suggesting further research avenues.",
    "doi": "10.1145/3503488",
    "url": "https://www.semanticscholar.org/paper/36d9f42cd27c91e56587602723cfa7e9d4203386",
    "pdf_url": "https://kups.ub.uni-koeln.de/53868/1/TMIS_manuscript_DataProvenance.pdf",
    "venue": "ACM Transactions on Management Information Systems",
    "citation_count": 72,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424513"
  },
  {
    "source": "semantic_scholar",
    "source_id": "d68d37eac48895ed9d99aa6bed8e08be07f5cc22",
    "title": "Artificial intelligence-assisted generative pretrained transformers for applications of ChatGPT in higher education among graduates",
    "authors": [
      "Jigna B. Prajapati",
      "Ashwini Kumar",
      "Sudarshan Singh",
      "Bhupendra G. Prajapati",
      "Yash Thakar",
      "Prashant R. Tambe",
      "Amit Ved"
    ],
    "year": 2024,
    "abstract": null,
    "doi": "10.1007/s43545-023-00818-0",
    "url": "https://www.semanticscholar.org/paper/d68d37eac48895ed9d99aa6bed8e08be07f5cc22",
    "pdf_url": "",
    "venue": "SN Social Sciences",
    "citation_count": 11,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424517"
  },
  {
    "source": "semantic_scholar",
    "source_id": "6aa4d770032622093d26309fc4fe4ae000a56ee0",
    "title": "The ethics of artificial intelligence, UNESCO and the African Ubuntu perspective",
    "authors": [
      "Dorine E. van Norren"
    ],
    "year": 2022,
    "abstract": "\nPurpose\nThis paper aims to demonstrate the relevance of worldviews of the global south to debates of artificial intelligence, enhancing the human rights debate on artificial intelligence (AI) and critically reviewing the paper of UNESCO Commission on the Ethics of Scientific Knowledge and Technology (COMEST) that preceded the drafting of the UNESCO guidelines on AI. Different value systems may lead to different choices in programming and application of AI. Programming languages may acerbate existing biases as a people\u2019s worldview is captured in its language. What are the implications for AI when seen from a collective ontology? Ubuntu (I am a person through other persons) starts from collective morals rather than individual ethics.\n\n\nDesign/methodology/approach\nLiterature overview on the African philosophy of Ubuntu as applied to artificial intelligence. Application of it to the United Nations Educational, Scientific and Cultural Organisation (UNESCO) debates on establishing guidelines to the ethics of artificial intelligence.\n\n\nFindings\nMetaphysically, Ubuntu and its conception of social personhood (attained during one\u2019s life) largely rejects transhumanism. When confronted with economic choices, Ubuntu favors sharing above competition and thus an anticapitalist logic of equitable distribution of AI benefits, humaneness and nonexploitation. When confronted with issues of privacy, Ubuntu emphasizes transparency to group members, rather than individual privacy, yet it calls for stronger (group privacy) protection. In democratic terms, it promotes consensus decision-making over representative democracy. Certain applications of AI may be more controversial in Africa than in other parts of the world, like care for the elderly, that deserve the utmost respect and attention, and which builds moral personhood. At the same time, AI may be helpful, as care from the home and community is encouraged from an Ubuntu perspective. The report on AI and ethics of the UNESCO World COMEST formulated principles as input, which are analyzed from the African ontological point of view. COMEST departs from \u201cuniversal\u201d concepts of individual human rights, sustainability and good governance which are not necessarily fully compatible with relatedness, including future and past generations. Next to rules based approaches, which may hamper diversity, bottom-up approaches are needed with intercultural deep learning algorithms.\n\n\nResearch limitations/implications\nThere is very few existing literature on AI and Ubuntu. Therefore, this paper is of an explorative nature.\n\n\nPractical implications\nThe ethics of Ubuntu offers unique vantage points in looking at the organization of society and economics today, which are also relevant for development of AI, especially in its tenet of relatedness rather than individuality (and practical use of AI for individuals), taking responsibility for society as a whole (such as analyzing the benefit of AI for all strata of society), and embodying true inclusiveness. Whether looking at top-down guidelines for the development and implementation of AI or the bottom-up ethical learning process of AI (deep learning), ethics of the Global South can have an important role to play to combat global individualist tendencies and inequity, likely reinforced by AI. This warrants far more research.\n\n\nSocial implications\nApplications of AI in Africa are not contextualized, do not address the most pressing needs of the African continent, lead to cybersecurity issues and also do not incorporate African ethics. UNESCO\u2019s work in this regard is important but expert inputs are largely centered around Western \u201cuniversal\u201d principles and Organisation for Economic Cooperation and Development and EU precedence. African ethics have, so far, a small role to play in global ethics and philosophy and therefore risk to be overlooked in the discussion on AI and ethics. This is why the consultation process of UNESCO on ethics of AI was of paramount importance. However, it does not automatically lead to consultation of African philosophers or sages, as many are educated in Western (ized) education systems. See further details under practical implications.\n\n\nOriginality/value\nThis is a new area of research in which little work has been done so far. This paper offers the opportunity to widen the debate on AI and ethics beyond the conventional discourse, involving multiple worldviews, of which Ubuntu is just one.\n",
    "doi": "10.1108/jices-04-2022-0037",
    "url": "https://www.semanticscholar.org/paper/6aa4d770032622093d26309fc4fe4ae000a56ee0",
    "pdf_url": "",
    "venue": "Journal of Information, Communication and Ethics in Society",
    "citation_count": 19,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424522"
  },
  {
    "source": "semantic_scholar",
    "source_id": "6a876c583e543b7f419281765f9ab176ccea1990",
    "title": "The Ethics of Emotional Artificial Intelligence: A Mixed Method Analysis",
    "authors": [
      "N. Ghotbi"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1007/s41649-022-00237-y",
    "url": "https://www.semanticscholar.org/paper/6a876c583e543b7f419281765f9ab176ccea1990",
    "pdf_url": "",
    "venue": "Asian Bioethics Review",
    "citation_count": 17,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424526"
  },
  {
    "source": "semantic_scholar",
    "source_id": "60c050bbc1d64d409889856450357c2e29579c52",
    "title": "Unravelling Smart HRM 4.0: A Narrative Review of Progressive 4.0 Technology Integration in Human Resource Management",
    "authors": [
      "Syezreen Dalina Rusdi",
      "Ida Rosnita Ismail",
      "R. Isa"
    ],
    "year": 2024,
    "abstract": "The integration of progressive 4.0 technology into human resource management (HRM) represents a significant shift in how organizations optimize and enhance workforce capabilities. This review explores the origins, applications, benefits, challenges and future prospects surrounding smart HRM 4.0. By reviewing existing literature, this paper examines the utilization of Artificial Intelligence (AI), Big Data analytics, machine learning (ML) and the Internet of Things (IoT) in HRM, specifically in talent acquisition, training, performance management, and rewards. Additionally, it addresses the implementation challenges including data quality assurance, skill shortages, and\u00a0cultural resistance. The paper also emphasizes the importance of ethical considerations. In terms of future research, it highlights the necessity for ethically deploying Industry 4.0 and establishing robust AI governance frameworks. By combining technological innovation with ethical values, organizations can navigate the complexities of this integration, leading to a future characterized by workplace efficiency, accountability, and fairness.",
    "doi": "10.22610/imbr.v16i3(i)s.4070",
    "url": "https://www.semanticscholar.org/paper/60c050bbc1d64d409889856450357c2e29579c52",
    "pdf_url": "https://ojs.amhinternational.com/index.php/imbr/article/download/4070/2634",
    "venue": "Information Management and Business Review",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424530"
  },
  {
    "source": "semantic_scholar",
    "source_id": "6d505cb644fb317343cf5cba03630ad6df7e5ee9",
    "title": "Ethical aspects in the use of artificial intelligence in the process of drug development | [Aspecte etice \u00een utilizarea inteligen\u021bei artificiale \u00een procesul de dezvoltare a medicamentelor]",
    "authors": [
      "Ecaterina Pitel",
      "Florin Lea\u0219u",
      "Andrada Nicolau",
      "Liliana Rogozea"
    ],
    "year": 2024,
    "abstract": "Background: The integration of Artificial Intelligence (AI) in drug development has revolutionized the pharmaceutical and medical landscape, enhancing drug discovery, clinical trials, and personalized medicine. This evolution, while beneficial, has introduced significant ethical challenges in data privacy, algorithmic bias, intellectual property rights, and equitable access to AI-driven therapies. Objective: The application of AI in drug development presents uncertainties regarding the ethical management of patient data, potential biases in AI decision-making, and the fair distribution of AI-powered treatments. The rapidly evolving nature of AI technologies and the dynamic regulatory environment further compound these uncertainties, posing a challenge to the ethical deployment of AI in this sector. Methods: We conducted a systematic literature search from January 2019 to December 2023 using databases like PubMed, PLOS, and Google Scholar, with keywords \"artificial intelligence,\" \"ethics,\" and \"drug discovery.\" This search led to the selection and detailed analysis of 33 key documents, focusing on the use of AI in drug discovery and associated ethical challenges. The extracted insights were synthesized to highlight major trends and discoveries in the field. Results: The review found that while AI significantly streamlines drug development processes, it raises substantial concerns about data privacy, decision-making biases, and equitable access. Key findings highlight the importance of ethically managing patient data, employing inclusive data sets for algorithm training, and maintaining transparency in AI operations. Intellectual property rights linked to AI discoveries and the necessity for transparent AI decision-making, particularly in clinical trials, were identified as critical areas needing attention. Conclusions: The rapid advancement of AI in pharmaceuticals necessitates a fine balance between innovation and adherence to ethical principles. This requires a multidisciplinary collaborative approach and the ongoing adaptation of regulatory frameworks to ensure the ethical and effective utilization of AI in drug development.\nRezumat\nIntroducere: Integrarea inteligen\u021bei artificiale (AI) \u00een dezvoltarea medicamentelor a revolu\u021bionat peisajul farmaceutic \u0219i medical, \u00eembun\u0103t\u0103\u021bind descoperirea medicamentelor, studiile clinice \u0219i medicina personalizat\u0103. Aceast\u0103 evolu\u021bie, de\u0219i benefic\u0103, a introdus provoc\u0103ri etice semnificative \u00een ceea ce prive\u0219te confiden\u021bialitatea datelor, p\u0103rtinirea algoritmic\u0103, drepturile de proprietate intelectual\u0103 \u0219i accesul echitabil la terapiile bazate pe IA. Obiective: Aplicarea IA \u00een dezvoltarea medicamentelor prezint\u0103 incertitudini \u00een ceea ce prive\u0219te gestionarea etic\u0103 a datelor pacien\u021bilor, poten\u021bialele prejudec\u0103\u021bi \u00een procesul decizional al IA \u0219i distribu\u021bia echitabil\u0103 a tratamentelor bazate pe IA. Evolu\u021bia rapid\u0103 a tehnologiilor IA \u0219i mediul de reglementare dinamic accen\u00actueaz\u0103 \u0219i mai mult aceste incertitudini, reprezent\u00e2nd o provocare pentru implementarea etic\u0103 a IA \u00een acest sector. Material \u0219i metod\u0103: Am efectuat o c\u0103utare sistematic\u0103 a literaturii din ianuarie 2019 p\u00e2n\u0103 \u00een decembrie 2023 folosind baze de date precum PubMed, PLOS \u0219i Google Scholar, cu cuvinte cheie \"inteligen\u021b\u0103 artificial\u0103\", \"etic\u0103\" \u0219i \"descoperire de medicamente\". Aceast\u0103 c\u0103utare a condus la selectarea \u0219i analiza detaliat\u0103 a 33 de documente-cheie, concentr\u00e2ndu-se pe utilizarea IA \u00een descoperirea medicamentelor \u0219i provoc\u0103rile etice asociate. Perspectivele extrase au fost sintetizate pentru a eviden\u021bia tendin\u021bele \u0219i descoperirile majore din domeniu. Rezultate: Analiza a constatat c\u0103, de\u0219i AI simplific\u0103 semnificativ procesele de dezvoltare a medica\u00acmentelor, aceasta ridic\u0103 preocup\u0103ri substan\u021biale cu privire la confiden\u021bialitatea datelor, prejudec\u0103\u021bile de luare a deciziilor \u0219i accesul echitabil. Principalele constat\u0103ri eviden\u021biaz\u0103 importan\u021ba gestion\u0103rii etice a datelor pacien\u021bilor, a utiliz\u0103rii seturilor de date incluzive pentru antrenarea algoritmilor \u0219i a men\u021binerii transparen\u021bei \u00een opera\u021biunile IA. Drepturile de proprietate intelectual\u0103 legate de descoperirile IA \u0219i necesitatea unui proces decizional transparent \u00een domeniul IA, \u00een special \u00een trialurile clinice, au fost identificate ca domenii critice care necesit\u0103 aten\u021bie. Concluzii: Dezvoltarea rapid\u0103 a IA \u00een industria farmaceutic\u0103 necesit\u0103 un echilibru fin \u00eentre inovare \u0219i respectarea principiilor etice. Acest lucru necesit\u0103 o abordare multidisciplinar\u0103 bazat\u0103 pe colaborare \u0219i adaptarea continu\u0103 a cadrelor de reglementare pentru a asigura utilizarea etic\u0103 \u0219i eficient\u0103 a IA \u00een dezvoltarea medicamentelor.",
    "doi": "10.31926/jmb.2023.2.8",
    "url": "https://www.semanticscholar.org/paper/6d505cb644fb317343cf5cba03630ad6df7e5ee9",
    "pdf_url": "",
    "venue": "Jurnal Medical Brasovean",
    "citation_count": 3,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424534"
  },
  {
    "source": "semantic_scholar",
    "source_id": "a624e3348a51c9ae653437030bbef54336127310",
    "title": "Artificial Intelligence in Employee Performance Evaluation and Its Managerial Implication",
    "authors": [
      "Hina Riaz Dr",
      "Seema Ghanghas"
    ],
    "year": 2024,
    "abstract": ": Since last decade usage of information technology has been increased drastically and artificial intelligence has taken a big leap absorbed into organizational culture of almost every department who surges to be updated and keep the competitive edge thus human resource management is not untouched too. Despite of tremendous research being done in the field of AI yet a dearth of proper research is found questioning the authenticity, rationality, and equability of AI/ML tools in business settings. This paper focuses on the perspective of relying on AI/ML in the process of employee performance management framing Artificial Intelligence performance measurement system integration using learning algorithms to make the evaluation a real-time process much easier, accurate, unbiased and fair. The managerial outlook of AI integrated performance appraisal results in strategic decision making, enhance levels of employee performance, employee commitment, satisfaction and reduced employee turnover behavior. This is an empirical research which examines previous literature through content analysis from authentic writings of secondary resources.",
    "doi": "10.52783/jier.v4i1.559",
    "url": "https://www.semanticscholar.org/paper/a624e3348a51c9ae653437030bbef54336127310",
    "pdf_url": "https://jier.org/index.php/journal/article/download/559/498",
    "venue": "Journal of Informatics Education and Research",
    "citation_count": 6,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424538"
  },
  {
    "source": "semantic_scholar",
    "source_id": "50cf184def032d32d1265136b5036d28734600e0",
    "title": "LEGAL ANALYSIS OF EU ARTIFICIAL INTELLIGENCE ACT (2024): INSIGHTS FROM PERSONAL DATA GOVERNANCE AND HEALTH POLICY",
    "authors": [
      "Anca Parmena Olimid"
    ],
    "year": 2024,
    "abstract": "Background: This study correlates the up-to-date ethical, functional and legal evaluations\nrelated to the management and governance of artificial intelligence (AI) under European\nUnion (EU) law, particularly impacting the health data sector and medical standards as\nprovided by the Artificial Intelligence Act within the Regulation adopted by the European\nCouncil in May 2024. The initial proposal for the management and governance of the AI sector\nwas submitted in April 2021. Three years later, on 13 March 2024, the European Union\nArtificial Intelligence Act (EU AIA) was adopted by the European Parliament. Subsequently,\non 21 May 2024, the Council adopted an innovative legislative framework that harmonises the\nstandards and rules for AI regulation. This framework is set to take effect in May 2026, with\nthe central objective of stimulating and motivating a fair, safe, legal single market that respects\nthe principles of ethics and the fundamental rights of the human person.\nMethods: The current legal analysis focuses on the European Union\u2019s new institutional\ngovernance involving a multistage approach to managing health data, ethical artificial\nintelligence, generative artificial intelligence and classification of types of AI by considering the\ndegree of risk (e.g. artificial intelligence systems with limited risk and systems with high risk)\nand medical devices. It outlines the legal framework for AI regulation and governance in the\nEU by focusing on compliance with the previously adopted legislation in the Medical Devices\nRegulation (2017) and the In-Vitro Diagnostic Regulation (2017). The paper also examines\nthe application of the newly adopted EU Artificial Intelligence Act in relation to national justice\nsystems, previous EU regulations on medical devices and personal data protection regulation,\nand its correlation with the European Court of Human Rights jurisprudence. This opens up\ncomplex discussions related to judicial reform and access to justice. For this purpose, as a\nresearch objective, the legal analysis includes an innovative perspective following an integrative\ndiscussion on the latest legal reforms and regulations of the AI sector in Eastern Europe\nlaunched in 2024 with a special focus on the latest developments in the EU Candidate\nCountries namely Ukraine and the Republic of Moldova.\nResults and conclusions: The present research facilitates the exploration of the real benefits of\nmanaging innovative AI systems for medical data, research, and development, as well as within\nthe medical technology industry.",
    "doi": "10.33327/ajee-18-7.4-a000103",
    "url": "https://www.semanticscholar.org/paper/50cf184def032d32d1265136b5036d28734600e0",
    "pdf_url": "https://doi.org/10.33327/ajee-18-7.4-a000103",
    "venue": "Access to Justice in Eastern Europe",
    "citation_count": 8,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424542"
  },
  {
    "source": "semantic_scholar",
    "source_id": "b30afed03d20e42a9239094b8218831098b7a05e",
    "title": "Artificial Intelligence in Governance: Opportunities, Challenges, and Ethical Implications for Public Administration",
    "authors": [
      "SantoshKumar Pulijala"
    ],
    "year": 2024,
    "abstract": "The integration of Artificial Intelligence (AI) in the public sector presents both unprecedented opportunities and significant challenges for governments worldwide. This article examines the multifaceted impact of AI on public administration, exploring its applications in service delivery, urban planning, public safety, and administrative efficiency. While AI offers substantial benefits, including enhanced decision-making, cost savings, and improved citizen services, it also raises critical concerns regarding bias, privacy, accountability, and workforce displacement. This article provides a comprehensive analysis of the ethical considerations surrounding AI deployment in governance,\nemphasizing the need for transparency, inclusivity, and human oversight. By critically evaluating both the promises and perils of AI in public sector operations, this article contributes to the ongoing discourse on responsible AI adoption in government. The findings underscore the importance of developing robust\ngovernance frameworks that can harness AI's potential while safeguarding citizens' rights and ensuring equitable service delivery. As governments navigate the AI revolution, this article offers insights into strategies for balancing technological advancement with ethical governance, paving the way for a more\nefficient, fair, and responsive public sector.",
    "doi": "10.36948/ijfmr.2024.v06i06.29990",
    "url": "https://www.semanticscholar.org/paper/b30afed03d20e42a9239094b8218831098b7a05e",
    "pdf_url": "https://www.ijfmr.com/papers/2024/6/29990.pdf",
    "venue": "International Journal For Multidisciplinary Research",
    "citation_count": 6,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424545"
  },
  {
    "source": "semantic_scholar",
    "source_id": "36554571bd688b62db21000c659db8bf238b94a2",
    "title": "Artificial Intelligence and Surgery: Ethical Dilemmas and Open Issues.",
    "authors": [
      "L. Cobianchi",
      "J. Verde",
      "T. Loftus",
      "Daniele Piccolo",
      "F. Dal Mas",
      "P. Mascagni",
      "A. Garc\u00eda V\u00e1zquez",
      "L. Ansaloni",
      "G. R. Marseglia",
      "M. Massaro",
      "Benoit Gallix",
      "N. Padoy",
      "Angelos Peter",
      "H. Kaafarani"
    ],
    "year": 2022,
    "abstract": "BACKGROUND\nArtificial intelligence (AI) applications aiming to support surgical decision-making processes are generating novel threats to ethical surgical care. To understand and address these threats, we summarize the main ethical issues that may arise from applying AI to surgery, starting from the Ethics Guidelines for Trustworthy Artificial Intelligence framework recently promoted by the European Commission.\n\n\nSTUDY DESIGN\nA modified Delphi process has been employed to achieve expert consensus.\n\n\nRESULTS\nThe main ethical issues that arise from applying AI to surgery, described in detail here, relate to human agency, accountability for errors, technical robustness, privacy and data governance, transparency, diversity, non-discrimination, and fairness. It may be possible to address many of these ethical issues by expanding the breadth of surgical AI research to focus on implementation science. The potential for AI to disrupt surgical practice suggests that formal digital health education is becoming increasingly important for surgeons and surgical trainees.\n\n\nCONCLUSIONS\nA multidisciplinary focus on implementation science and digital health education is desirable to balance opportunities offered by emerging AI technologies and respect for the ethical principles of a patient-centric philosophy.",
    "doi": "10.1097/XCS.0000000000000242",
    "url": "https://www.semanticscholar.org/paper/36554571bd688b62db21000c659db8bf238b94a2",
    "pdf_url": "https://iris.unive.it/bitstream/10278/3758526/1/2022_13_Cobianchi%20et%20al_JACS%20preprint.pdf",
    "venue": "Journal of the American College of Surgeons",
    "citation_count": 58,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424550"
  },
  {
    "source": "semantic_scholar",
    "source_id": "fc4ec3cc1682b7e24058fd17441c7ab8529530ee",
    "title": "Artificial Intelligence to support ethical decision-making for incapacitated patients: a survey among German anesthesiologists and internists",
    "authors": [
      "Lasse Benzinger",
      "J. Epping",
      "F. Ursin",
      "S. Salloch"
    ],
    "year": 2024,
    "abstract": "Background Artificial intelligence (AI) has revolutionized various healthcare domains, where AI algorithms sometimes even outperform human specialists. However, the field of clinical ethics has remained largely untouched by AI advances. This study explores the attitudes of anesthesiologists and internists towards the use of AI-driven preference prediction tools to support ethical decision-making for incapacitated patients. Methods A questionnaire was developed and pretested among medical students. The questionnaire was distributed to 200 German anesthesiologists and 200 German internists, thereby focusing on physicians who often encounter patients lacking decision-making capacity. The questionnaire covered attitudes toward AI-driven preference prediction, availability and utilization of Clinical Ethics Support Services (CESS), and experiences with ethically challenging situations. Descriptive statistics and bivariate analysis was performed. Qualitative responses were analyzed using content analysis in a mixed inductive-deductive approach. Results Participants were predominantly male (69.3%), with ages ranging from 27 to 77. Most worked in nonacademic hospitals (82%). Physicians generally showed hesitance toward AI-driven preference prediction, citing concerns about the loss of individuality and humanity, lack of explicability in AI results, and doubts about AI\u2019s ability to encompass the ethical deliberation process. In contrast, physicians had a more positive opinion of CESS. Availability of CESS varied, with 81.8% of participants reporting access. Among those without access, 91.8% expressed a desire for CESS. Physicians' reluctance toward AI-driven preference prediction aligns with concerns about transparency, individuality, and human-machine interaction. While AI could enhance the accuracy of predictions and reduce surrogate burden, concerns about potential biases, de-humanisation, and lack of explicability persist. Conclusions German physicians frequently encountering incapacitated patients exhibit hesitance toward AI-driven preference prediction but hold a higher esteem for CESS. Addressing concerns about individuality, explicability, and human-machine roles may facilitate the acceptance of AI in clinical ethics. Further research into patient and surrogate perspectives is needed to ensure AI aligns with patient preferences and values in complex medical decisions.",
    "doi": "10.1186/s12910-024-01079-z",
    "url": "https://www.semanticscholar.org/paper/fc4ec3cc1682b7e24058fd17441c7ab8529530ee",
    "pdf_url": "https://bmcmedethics.biomedcentral.com/counter/pdf/10.1186/s12910-024-01079-z",
    "venue": "BMC Medical Ethics",
    "citation_count": 2,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424554"
  },
  {
    "source": "semantic_scholar",
    "source_id": "360be56f656f7aa4c13325966febbe888c401faf",
    "title": "Machine Ethics and African Identities: Perspectives of Artificial Intelligence in Africa",
    "authors": [
      "D. Kohnert"
    ],
    "year": 2022,
    "abstract": ": Artificial intelligence (AI) has been welcomed enthusiastically by Africans as a new resource for African development. AI could allow for improved well-being by facilitating innovations in the economic sector, education, health, ecology, urban planning, industries etc. Yet, the high expectations may be little more than pious wishes. There are still unsolved questions concerning the required transfer and choice of appropriate technology and its mastering. Given, that the concept of 'technology transfer' of the modernization theories of the 1960s utterly failed, because it was not adapted to the local needs (e.g. lack of resources, widespread poverty and gross socio-economic inequality, labour-intensive technology, low productivity), some scholars called for an endogenous concept of African AI. This, however, triggered heated controversies. Africa became a battleground for 'digital empires' of global powers because of its practically inexistent digital infrastructure. Yet, African solutions to African problems would be required. Moreover, the prevailing narratives and default settings of AI-related technologies have been denounced as male gender-biased, white, heteronormative, able-bodied, and Western. Also, the hitherto existing focus on the formal sector is questionable. Innovators in the informal sector and the agency of the civil society, embedded in the local socio-cultural setting, but closely linked to transnational social spaces, often outperform the states' development efforts. Also, UNESCO cautioned that the effective use of AI would require appropriate skills, the legal framework and infrastructure. As in the past, the call for the pooling of resources, a pan-African strategy, was probably in vain. Possibly, AI will develop most rapidly in the already established African technology hubs of South Africa, Nigeria and Kenya. Yet, promising AI-focused activities also have been recognized in Ethiopia and Uganda. For AI to improve socio-economic inclusion in African settings, rather than undermine it, also gender equality, cultural and linguistic diversity and shifts in the labour markets would be required. Furthermore, ethical questions linked with a specific African identity have been raised. How far African perceptions of personhood and humanity would have to be considered in developing an African AI remains an open question. In short, AI could be a double-edged",
    "doi": "10.2139/ssrn.4163096",
    "url": "https://www.semanticscholar.org/paper/360be56f656f7aa4c13325966febbe888c401faf",
    "pdf_url": "https://mpra.ub.uni-muenchen.de/113799/1/MPRA_paper_113799.pdf",
    "venue": "Social Science Research Network",
    "citation_count": 13,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424558"
  },
  {
    "source": "semantic_scholar",
    "source_id": "788fa6d21adf3933693b9e5618e216beafe94a41",
    "title": "Artificial Intelligence and Sustainable Decisions",
    "authors": [
      "Jingchen Zhao",
      "Beatriz G\u00f3mez Fari\u00f1as"
    ],
    "year": 2022,
    "abstract": "When addressing corporate sustainability challenges, artificial intelligence (AI) is a double-edged sword. AI can make significant progress on the most complicated environmental and social problems faced by humans. On the other hand, the efficiencies and innovations generated by AI may also bring new risks, such as automated bias and conflicts with human ethics. We argue that companies and governments should make collective efforts to address sustainability challenges and risks brought by AI. Accountable and sustainable AI can be achieved through a proactive regulatory framework supported by rigorous corporate policies and reports. Given the rapidly evolving nature of this technology, we propose a harmonised and risk-based regulatory approach that accommodates diverse AI solutions to achieve the common good. Ensuring an adequate level of technological neutrality and proportionality of the regulation is the key to mitigating the wide range of potential risks inherent to the use of AI. Instead of promoting sustainability, unregulated AI would be a threat since it would not be possible to effectively monitor its effects on the economy, society and environment. Such a suitable regulatory framework would not only create a consensus concerning the risks to avoid and how to do so but also include enforcement mechanisms to ensure a trustworthy and ethical use of AI in the boardroom. Once this objective is achieved, it will be possible to refer to this technological development as a common good in itself that constitutes an essential asset to human development.",
    "doi": "10.1007/s40804-022-00262-2",
    "url": "https://www.semanticscholar.org/paper/788fa6d21adf3933693b9e5618e216beafe94a41",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s40804-022-00262-2.pdf",
    "venue": "European Business Organization Law Review",
    "citation_count": 102,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424562"
  },
  {
    "source": "semantic_scholar",
    "source_id": "fee596406375592b29b2f051910e8247ea501c01",
    "title": "Introduction to The Special Section on Bias and Fairness in AI",
    "authors": [
      "T. Calders",
      "Eirini Ntoutsi",
      "Mykola Pechenizkiy",
      "B. Rosenhahn",
      "S. Ruggieri"
    ],
    "year": 2021,
    "abstract": "Fairness in Artificial Intelligence rightfully receives a lot of attention these days. Many life-impacting decisions are being partially automated, including health-care resource planning decisions, insurance and credit risk predictions, recidivism predictions, etc. Much of work appearing on this topic within the Data Mining, Machine Learning and Artificial Intelligence community is focused on technological aspects. Nevertheless, fairness is much wider than this as it lies at the intersection of philosophy, ethics, legislation, and practical perspectives. Therefore, to fill this gap and bring together scholars of these disciplines working on fairness, the first workshop on Bias and Fairness in AI was held online on September 18, 2020 at the ECML-PKDD 2020 conference. This special section includes six articles presenting different perspectives on bias and fairness from different angles.",
    "doi": "10.1145/3468507.3468509",
    "url": "https://www.semanticscholar.org/paper/fee596406375592b29b2f051910e8247ea501c01",
    "pdf_url": "https://repository.uantwerpen.be/docstore/d:irua:7358",
    "venue": "SIGKDD Explorations",
    "citation_count": 8,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424566"
  },
  {
    "source": "semantic_scholar",
    "source_id": "304e37f652c5ac7df3c2b45b2dc1e6d863cb3c0b",
    "title": "The Ethics of Artificial Intelligence: Sociopolitical and Legal Dimensions",
    "authors": [
      "Jingjing Wang",
      "Wenji Mao",
      "Wenjie Wenjie"
    ],
    "year": 2023,
    "abstract": "This study aims to explore the ethical dimensions of artificial intelligence (AI), focusing on its sociopolitical and legal implications. It seeks to identify and analyze the primary ethical concerns that arise from the development and deployment of AI technologies, with an emphasis on understanding how these concerns impact society and the legal frameworks that govern AI. Employing a qualitative research design, this study conducted semi-structured interviews with 22 participants from diverse professional backgrounds, including technology ethicists, legal scholars, AI developers, policymakers, and advocacy group representatives. The data collection aimed for theoretical saturation, with the interviews designed to uncover a broad range of perspectives on AI ethics. Thematic analysis was used to identify and categorize the main themes and sub-themes related to the ethical implications of AI. The analysis revealed two main themes: Sociopolitical Dimension and Legal Dimension. The Sociopolitical Dimension includes categories such as Privacy and Data Governance, Bias and Discrimination, AI and Employment, Digital Divide, and AI in Governance. The Legal Dimension encompasses Intellectual Property Rights, Liability and Accountability, Regulatory Frameworks, AI Ethics and Law Integration, and Human Rights and AI. Each category was further explored through specific concepts, highlighting the complexities and challenges inherent in the ethical considerations of AI technologies. The study underscores the intricate relationship between AI technologies and ethical considerations, emphasizing the necessity for comprehensive, multidisciplinary approaches to address the identified sociopolitical and legal challenges. It advocates for the development of inclusive, equitable, and responsive frameworks that not only mitigate risks but also promote the beneficial potential of AI, ensuring that technological advancements align with societal values and legal norms.",
    "doi": "10.61838/kman.isslp.2.2.6",
    "url": "https://www.semanticscholar.org/paper/304e37f652c5ac7df3c2b45b2dc1e6d863cb3c0b",
    "pdf_url": "https://journalisslp.com/index.php/isslp/article/download/27/24",
    "venue": "Interdisciplinary Studies in Society, Law, and Politics",
    "citation_count": 5,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424570"
  },
  {
    "source": "semantic_scholar",
    "source_id": "810730691b1bcfefbf7fe3b93c6d3e19a3448671",
    "title": "The Use of Responsible Artificial Intelligence Techniques in the Context of Loan Approval Processes",
    "authors": [
      "Erasmo Purificato",
      "F. Lorenzo",
      "Francesca Fallucchi",
      "Ernesto William De Luca"
    ],
    "year": 2022,
    "abstract": "Abstract Despite the existing skepticism about the use of automatic systems in contexts where human knowledge and experience are considered indispensable (e.g., the granting of a mortgage, the prediction of stock prices, or the detection of cancers), our work aims to show how the use of explainability and fairness techniques can lead to the growth of a domain expert\u2019s trust and reliance on an artificial intelligence (AI) system. This article presents a system, applied to the context of loan approval processes, focusing on the two aforementioned ethical principles out of the four defined by the High-Level Expert Group on AI in the document \u201cEthics Guidelines for Trustworthy AI,\u201d published in April 2019, in which the key requirements that AI systems should meet to be considered trustworthy are identified. The presented case study is realized within a proprietary framework composed of several components for supporting the user throughout the management of the whole life cycle of a machine learning model. The main approaches, consisting of providing an interpretation of the model\u2019s outputs and monitoring the model\u2019s decisions to detect and react to unfair behaviors, are described in more detail to compare our system within state-of-the-art related frameworks. Finally, a novel Trust & Reliance Scale is proposed for evaluating the system, and a usability test is performed to measure the user satisfaction with the effectiveness of the developed user interface; results are obtained, respectively, by the submission of the mentioned novel scale to bank domain experts and the usability questionnaire to a heterogeneous group composed of loan officers, data scientists, and researchers.",
    "doi": "10.1080/10447318.2022.2081284",
    "url": "https://www.semanticscholar.org/paper/810730691b1bcfefbf7fe3b93c6d3e19a3448671",
    "pdf_url": "",
    "venue": "International journal of human computer interactions",
    "citation_count": 52,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424574"
  },
  {
    "source": "semantic_scholar",
    "source_id": "71c02376b4aee7ae2b29da937742d95683fc8710",
    "title": "Benefits of using artificial intelligence in core HR processes",
    "authors": [
      "Iryna Vats",
      "O. Kyrylenko",
      "Valentyna Novak"
    ],
    "year": 2024,
    "abstract": "The paper examines the use of artificial intelligence (AI) in the main processes of human resource management. It is noted that in modern conditions, AI is considered an advanced tool that can optimize management processes in various sectors of the economy. The author discusses the new opportunities that AI opens up in human resource management, increasing the efficiency of actions at all levels and complementing human abilities. The main part of the paper is devoted to the advantages and potential opportunities of using AI at different stages of the employee's life cycle in a company. In particular, the author emphasizes the optimization of recruitment through analytical processing of large amounts of information rather than subjective judgment. The paper highlights such areas as operational efficiency, recruitment, onboarding, talent management, strategic planning, career development, and management changes where AI can make a significant contribution. The paper also highlights the issues related to the potential dangers of introducing AI technologies. The level of readiness and the degree of involvement of managers in the latest technologies in human resource management is indicated. The paper raises the issue of efficiency and solving various problems. In addition, examples of real software products are provided. The conclusions emphasize the general perspective of using AI in HR processes and identify areas for further research. In particular, there is a call for the development of mechanisms to protect employees from possible misuse of AI and the development of effective strategies for the implementation of technologies that would take into account ethical aspects. The final part of the paper sets the task for the business community and legislative bodies to actively work on standards for the use of AI in HR to create fair and effective HR management.",
    "doi": "10.37634/efp.2024.3.1",
    "url": "https://www.semanticscholar.org/paper/71c02376b4aee7ae2b29da937742d95683fc8710",
    "pdf_url": "https://doi.org/10.37634/efp.2024.3.1",
    "venue": "Economics. Finances. Law",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424578"
  },
  {
    "source": "semantic_scholar",
    "source_id": "8540e1664d017c4b6a46ca4064908e37f04f02bb",
    "title": "Bias and Fairness in AI-Based Employee Attrition Prediction Using Random Forest",
    "authors": [
      "Idowu Adesoji Oladipupo",
      "S. Folorunso",
      "Sadiq Olusegun Balogun",
      "Fatima Iganya Suleiman",
      "O. Olayemi",
      "Joseph Maugbe Jacob"
    ],
    "year": 2026,
    "abstract": "Artificial intelligence is increasingly employed to predict employee attrition, enabling organisations to improve talent retention and workforce planning. However, without explicit consideration of fairness, these models risk embedding and amplifying societal biases. This study examines bias in AI-based attrition prediction using a Random Forest classifier applied to the IBM HR Analytics employee attrition dataset. Although the model demonstrates high predictive performance (92.3 percent) and an area under the curve of 0.97, subgroup analysis reveals disparities in prediction performance across gender. Fairness assessments based on equal accuracy, demographic parity, and equality of opportunity show that predictions for female employees achieve higher precision and recall than those for male employees, suggesting differential predictive performance across gender groups. The findings highlight organisational risks associated with such disparities, including the risk of unjust decision-making, reduced employee trust, and hindered diversity and inclusion efforts. To mitigate these challenges, the study recommends fairness-aware strategies such as balanced sampling, established fairness metrics, post-processing approaches (e.g., equalised odds), and continuous model auditing. This research underscores the ethical importance of aligning AI systems in human resource management with principles of equity, transparency, and accountability.",
    "doi": "10.64389/icds.2026.02162",
    "url": "https://www.semanticscholar.org/paper/8540e1664d017c4b6a46ca4064908e37f04f02bb",
    "pdf_url": "",
    "venue": "Innovation in Computer and Data Sciences",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424582"
  },
  {
    "source": "semantic_scholar",
    "source_id": "0e4589a51731a7698e6300f2c8f477bf9bd80ad3",
    "title": "Moral consideration of nonhumans in the ethics of artificial intelligence",
    "authors": [
      "A. Owe",
      "S. Baum"
    ],
    "year": 2021,
    "abstract": null,
    "doi": "10.1007/s43681-021-00065-0",
    "url": "https://www.semanticscholar.org/paper/0e4589a51731a7698e6300f2c8f477bf9bd80ad3",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s43681-021-00065-0.pdf",
    "venue": "AI and Ethics",
    "citation_count": 56,
    "fields_of_study": [
      "Sociology",
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424587"
  },
  {
    "source": "semantic_scholar",
    "source_id": "660b94b3ee837a8898a307364a6ca29b23193e9e",
    "title": "Generative Artificial Intelligence and the Impact on Sustainability",
    "authors": [
      "Niklas Humble",
      "Peter Mozelius"
    ],
    "year": 2024,
    "abstract": "An increasingly popular subcategory of Artificial Intelligence (AI) is Generative AI (GAI), which encompasses technologies capable of creating new content, such as images, text, and music, often resembling outputs made by humans. The potential impact by GAI on sustainability is multifaceted. On the positive side, generative AI can aid in optimizing processes, developing innovative solutions, and identifying patterns in large datasets related to sustainability. This can lead to more efficient resource management, reduced energy consumption, and the creation of more sustainable products. However, there are also potential negative impacts, such as increased energy consumption associated with training and running generative AI models, as well as the potential for unintended consequences or biases in the generated content. Additionally, overreliance on generative AI may lead to reduced human oversight, which could undermine holistic, interdisciplinary, and collaborative approaches to sustainability. The aim of this paper is to explore the potential impacts on sustainability by generative artificial intelligence through a review of prior research on the topic.\nThe study was conducted with a scoping literature review approach to identify potential impacts by generative AI on sustainability. Data were collected through a search in the database Scopus during the spring semester of 2024. Keywords, relevant for the study, were combined with Boolean operators. Papers identified through the search underwent a manual screening process by the authors, in which papers were selected for inclusion or exclusion in the study based on a set of criteria. Included paper were then analyzed with thematic analysis, according to the guidelines by Braun and Clarke. A categorization matrix, based in prior research on sustainability, supported the analysis and deductive coding of collected data.\u00a0Results of the study highlight generative AI\u2019s potential impact on sustainability that relate to both environmental aspects, economic aspects, and social aspects of sustainability. These different aspects of sustainability impact make this research an important contribution for deepening the understanding of generative AI and its potential consequences for society. Findings of the study provide theoretical contribution, implications for practice, and recommendations for future research on generative AI and sustainability.",
    "doi": "10.34190/icair.4.1.3024",
    "url": "https://www.semanticscholar.org/paper/660b94b3ee837a8898a307364a6ca29b23193e9e",
    "pdf_url": "https://papers.academic-conferences.org/index.php/icair/article/download/3024/2906",
    "venue": "International Conference on AI Research",
    "citation_count": 3,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424590"
  },
  {
    "source": "semantic_scholar",
    "source_id": "ce59430833ecd08d90df9aebb584c514a8853bc2",
    "title": "Artificial Intelligence & Ethics Beyond engineering at the dawn of decision-making machines",
    "authors": [
      "J. Shaw"
    ],
    "year": 2018,
    "abstract": null,
    "doi": null,
    "url": "https://www.semanticscholar.org/paper/ce59430833ecd08d90df9aebb584c514a8853bc2",
    "pdf_url": "",
    "venue": "",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424631"
  },
  {
    "source": "semantic_scholar",
    "source_id": "51468ede905d33700a4ff10cb6b1e6de7279e74c",
    "title": "Artificial intelligence in radiology: a narrative review of current methods, clinical impact, and future directions",
    "authors": [
      "Amy Avakian",
      "Garrett Barfoot"
    ],
    "year": 2026,
    "abstract": null,
    "doi": "10.1186/s44398-025-00020-7",
    "url": "https://www.semanticscholar.org/paper/51468ede905d33700a4ff10cb6b1e6de7279e74c",
    "pdf_url": "",
    "venue": "BMC Artificial Intelligence",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424638"
  },
  {
    "source": "semantic_scholar",
    "source_id": "b7bc57950b1dc5434dde6120a367c60ad15c6710",
    "title": "Artificial Intelligence (AI) in Revolutionizing Sustainable Recruitment: A Framework for Inclusivity and Efficiency",
    "authors": [
      "SM Masudur Rahman",
      "Md. Amzad Hossain",
      "Md. Shelim Miah",
      "Mahabub Alom",
      "Maruf Islam"
    ],
    "year": 2025,
    "abstract": "This study explores the potential of Artificial Intelligence (AI) technologies to advance sustainable recruitment, focusing on both environmental and social sustainability. AI-driven systems, including machine learning (ML) and natural language processing (NLP), offer significant improvements by automating tasks such as resume screening, candidate profiling, and interview scheduling. These technologies reduce resource consumption, eliminate the need for physical interviews and paperwork, and lower the carbon footprint of recruitment processes. Adopting a theoretical and conceptual analysis methodology, this research draws on a comprehensive review of AI applications in recruitment and sustainability frameworks. No primary data was collected; instead, the study utilizes secondary data from academic literature, industry reports, and expert insights. A conceptual framework is developed to illustrate how AI can be systematically integrated into recruitment processes to enhance sustainability, highlighting stages such as data collection, decision-making, and feedback loops to improve AI algorithms over time. The findings suggest that AI can contribute significantly to resource efficiency by digitizing recruitment processes and reducing environmental impacts like travel-related emissions. Moreover, AI enhances social sustainability by promoting diversity and inclusion in hiring, as automated systems reduce biases in candidate selection. Key strategies include adopting energy-efficient AI technologies, ensuring ethical use through algorithm audits, and leveraging feedback mechanisms to optimize AI performance. Policymakers are encouraged to develop regulations promoting transparency and accountability in AI use. Future research should explore AI\u2019s broader role in human resource management, ensuring its sustainability potential is fully realized.",
    "doi": "10.47857/irjms.2025.v06i01.02698",
    "url": "https://www.semanticscholar.org/paper/b7bc57950b1dc5434dde6120a367c60ad15c6710",
    "pdf_url": "",
    "venue": "International Research Journal of Multidisciplinary Scope",
    "citation_count": 9,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424644"
  },
  {
    "source": "semantic_scholar",
    "source_id": "05579a5181496cae4b0772cd044392044f81ee47",
    "title": "Exposing implicit biases and stereotypes in human and artificial intelligence: state of the art and challenges with a focus on gender",
    "authors": [
      "Ludovica Marinucci",
      "C. Mazzuca",
      "Aldo Gangemi"
    ],
    "year": 2022,
    "abstract": "Biases in cognition are ubiquitous. Social psychologists suggested biases and stereotypes serve a multifarious set of cognitive goals, while at the same time stressing their potential harmfulness. Recently, biases and stereotypes became the purview of heated debates in the machine learning community too. Researchers and developers are becoming increasingly aware of the fact that some biases, like gender and race biases, are entrenched in the algorithms some AI applications rely upon. Here, taking into account several existing approaches that address the problem of implicit biases and stereotypes, we propose that a strategy to cope with this phenomenon is to unmask those found in AI systems by understanding their cognitive dimension, rather than simply trying to correct algorithms. To this extent, we present a discussion bridging together findings from cognitive science and insights from machine learning that can be integrated in a state-of-the-art semantic network. Remarkably, this resource can be of assistance to scholars (e.g., cognitive and computer scientists) while at the same time contributing to refine AI regulations affecting social life. We show how only through a thorough understanding of the cognitive processes leading to biases, and through an interdisciplinary effort, we can make the best of AI technology.",
    "doi": "10.1007/s00146-022-01474-3",
    "url": "https://www.semanticscholar.org/paper/05579a5181496cae4b0772cd044392044f81ee47",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s00146-022-01474-3.pdf",
    "venue": "Ai & Society",
    "citation_count": 49,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424656"
  },
  {
    "source": "semantic_scholar",
    "source_id": "84870e2c569a603c9b3cb0566cbc23b43df4a5bf",
    "title": "A practical guide for nephrologist peer reviewers: evaluating artificial intelligence and machine learning research in nephrology",
    "authors": [
      "Yanni Wang",
      "W. Cheungpasitporn",
      "Hatem Ali",
      "Jianbo Qing",
      "C. Thongprayoon",
      "W. Kaewput",
      "K. Soliman",
      "Zhengxing Huang",
      "Min Yang",
      "Zhongheng Zhang"
    ],
    "year": 2025,
    "abstract": "Abstract Artificial intelligence (AI) and machine learning (ML) are transforming nephrology by enhancing diagnosis, risk prediction, and treatment optimization for conditions such as acute kidney injury (AKI) and chronic kidney disease (CKD). AI-driven models utilize diverse datasets\u2014including electronic health records, imaging, and biomarkers\u2014to improve clinical decision-making. Applications such as convolutional neural networks for kidney biopsy interpretation, and predictive modeling for renal replacement therapies underscore AI\u2019s potential. Nonetheless, challenges including data quality, limited external validation, algorithmic bias, and poor interpretability constrain the clinical reliability of AI/ML models. To address these issues, this article offers a structured framework for nephrologist peer reviewers, integrating the TRIPOD-AI (Transparent Reporting of a Multivariable Prediction Model for Individual Prognosis or Diagnosis\u2013AI Extension) checklist. Key evaluation criteria include dataset integrity, feature selection, model validation, reporting transparency, ethics, and real-world applicability. This framework promotes rigorous peer review and enhances the reproducibility, clinical relevance, and fairness of AI research in nephrology. Moreover, AI/ML studies must confront biases\u2014data, selection, and algorithmic\u2014that adversely affect model performance. Mitigation strategies such as data diversification, multi-center validation, and fairness-aware algorithms are essential. Overfitting in AI is driven by small patient cohorts faced with thousands of candidate features; our framework spotlights this imbalance and offers concrete remedies. Future directions in AI-driven nephrology include multimodal data fusion for improved predictive modeling, deep learning for automated imaging analysis, wearable-based monitoring, and clinical decision support systems (CDSS) that integrate comprehensive patient data. A visual summary of key manuscript sections is included.",
    "doi": "10.1080/0886022X.2025.2513002",
    "url": "https://www.semanticscholar.org/paper/84870e2c569a603c9b3cb0566cbc23b43df4a5bf",
    "pdf_url": "",
    "venue": "Renal Failure",
    "citation_count": 6,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424663"
  },
  {
    "source": "semantic_scholar",
    "source_id": "e4db1b35d721681358aaf084474138771492569d",
    "title": "Human-AI Interaction in Human Resource Management: Understanding Why Employees Resist Algorithmic Evaluation at Workplaces and How to Mitigate Burdens",
    "authors": [
      "Hyanghee Park",
      "Daehwan Ahn",
      "K. Hosanagar",
      "Joonhwan Lee"
    ],
    "year": 2021,
    "abstract": "Recently, Artificial Intelligence (AI) has been used to enable efficient decision-making in managerial and organizational contexts, ranging from employment to dismissal. However, to avoid employees\u2019 antipathy toward AI, it is important to understand what aspects of AI employees like and/or dislike. In this paper, we aim to identify how employees perceive current human resource (HR) teams and future algorithmic management. Specifically, we explored what factors negatively influence employees\u2019 perceptions of AI making work performance evaluations. Through in-depth interviews with 21 workers, we found that 1) employees feel six types of burdens (i.e., emotional, mental, bias, manipulation, privacy, and social) toward AI's introduction to human resource management (HRM), and that 2) these burdens could be mitigated by incorporating transparency, interpretability, and human intervention to algorithmic decision-making. Based on our findings, we present design efforts to alleviate employees\u2019 burdens. To leverage AI for HRM in fair and trustworthy ways, we call for the HCI community to design human-AI collaboration systems with various HR stakeholders.",
    "doi": "10.1145/3411764.3445304",
    "url": "https://www.semanticscholar.org/paper/e4db1b35d721681358aaf084474138771492569d",
    "pdf_url": "",
    "venue": "International Conference on Human Factors in Computing Systems",
    "citation_count": 101,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424667"
  },
  {
    "source": "semantic_scholar",
    "source_id": "597f3c3cb1bebfc9043ff0fc002c01d695e69cd9",
    "title": "Creative data justice: a decolonial and indigenous framework to assess creativity and artificial intelligence",
    "authors": [
      "Payal Arora"
    ],
    "year": 2024,
    "abstract": "ABSTRACT In the last decade, the Global South has emerged as a significant player in the data economy due to their majority user base, and studying its role is crucial to comprehend the future of AI. As societies grapple with the implications of AI on creative life, there is an opportunity to reevaluate the creative contributions of Global South cultures, ensuring they are acknowledged and foregrounded in the evolving landscape of human and machine creativity. This paper calls for reimagining and restructuring creative value with the emergence of AI enabled technologies by broadening who and what counts as creative in this data-driven era. To democratize creativity, a decolonial and indigenous framework of cross-cultural creative value is needed which critically intersects and examines the relations between creative labor, rights, and learning. The study of the Global South\u2019s data economies is important not only to harness its potential but also to address the cross-cultural ethics of building Creative AI tools with data from their underrepresented communities. At its core, the creative data justice framework emphasizes the need to challenge the existing power imbalances in global data governance. This paper proposes that fair creative value can be achieved by drawing inspiration from indigenous systems of care as a counterforce to neoliberal values of efficiency and utility. This framework will help scholars, policymakers and designers in their inclusive approaches to creativity in the age of AI.",
    "doi": "10.1080/1369118X.2024.2420041",
    "url": "https://www.semanticscholar.org/paper/597f3c3cb1bebfc9043ff0fc002c01d695e69cd9",
    "pdf_url": "https://doi.org/10.1080/1369118x.2024.2420041",
    "venue": "Information, Communication &amp; Society",
    "citation_count": 11,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424671"
  },
  {
    "source": "semantic_scholar",
    "source_id": "1013a3e5b2352d2cbe9d8c6291c6406ac504d8e7",
    "title": "How artificial intelligence will change the future of marketing",
    "authors": [
      "T. Davenport",
      "Abhijit Guha",
      "Dhruv Grewal",
      "Timna Bre\u00dfgott"
    ],
    "year": 2019,
    "abstract": "In the future, artificial intelligence (AI) is likely to substantially change both marketing strategies and customer behaviors. Building from not only extant research but also extensive interactions with practice, the authors propose a multidimensional framework for understanding the impact of AI involving intelligence levels, task types, and whether AI is embedded in a robot. Prior research typically addresses a subset of these dimensions; this paper integrates all three into a single framework. Next, the authors propose a research agenda that addresses not only how marketing strategies and customer behaviors will change in the future, but also highlights important policy questions relating to privacy, bias and ethics. Finally, the authors suggest AI will be more effective if it augments (rather than replaces) human managers.",
    "doi": "10.1007/s11747-019-00696-0",
    "url": "https://www.semanticscholar.org/paper/1013a3e5b2352d2cbe9d8c6291c6406ac504d8e7",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s11747-019-00696-0.pdf",
    "venue": "Journal of the Academy of Marketing Science",
    "citation_count": 1551,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424676"
  },
  {
    "source": "semantic_scholar",
    "source_id": "b24d47d2319b0a143280dbc1edaf143f48720f0b",
    "title": "Artificial Intelligence in Psychiatric Inpatient Care: Advancing Diagnostics, Personalized Treatment, and Ethical Integration",
    "authors": [
      "Khadija Jahan Mukta",
      "Md Anamul Islam"
    ],
    "year": 2025,
    "abstract": "Artificial intelligence (AI) is transforming mental inpatient care by improving diagnostic precision, facilitating individualized therapy, and optimizing hospital operations. This scoping review aggregated findings from 24 empirical studies published between 2015 and 2025 to assess the application of AI technologies\u2014such as machine learning, natural language processing, deep learning, digital phenotyping, and conversational agents\u2014in inpatient psychiatric environments. Findings demonstrate that AI enhances the early identification of relapse and suicide risk, facilitates personalized therapy via decision-support systems and chatbots, and bolsters patient monitoring using sensor-based technology. AI enhances operational efficiency by optimizing bed allocation, personnel scheduling, and clinical documentation, hence alleviating administrative burdens. Nonetheless, considerable obstacles persist, including algorithmic bias, privacy issues, clinical opposition, and legal uncertainty. This study offers the Three-Pillar Model for Responsible AI Integration, highlighting therapeutic augmentation, ethical safeguards, and operational governance as fundamental concepts. The analysis highlights the dual nature of AI in psychiatry: its revolutionary promise alongside ethical and implementation challenges. Future investigations should prioritize longitudinal validation, resource-constrained environments, interpretability, and the creation of inclusive datasets. By incorporating transparency, fairness, and human-centered design, AI can enhance mental inpatient treatment to be technologically advanced, equitable, trustworthy, and compassionate.",
    "doi": "10.32996/jpbs.2025.5.3.1",
    "url": "https://www.semanticscholar.org/paper/b24d47d2319b0a143280dbc1edaf143f48720f0b",
    "pdf_url": "",
    "venue": "Journal of psychology & behavioral studies",
    "citation_count": 3,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424693"
  },
  {
    "source": "semantic_scholar",
    "source_id": "966868f68ed4e66cc0c6a2a65a32ddda5065c7bb",
    "title": "Artificial Intelligence in Human Resources in the Era of Society 5.0",
    "authors": [
      "Khansa Islami",
      "Dan Sopiah"
    ],
    "year": 2022,
    "abstract": "Humans and robots must be able to cooperate and work together to complete their roles and activities in the age of Society 5.0, which is a challenge for scholars and professionals of HRM. The company\u2019s HR management operations, including the hiring process, interviews, coaching, advancement, salary, and staff effectiveness reviews, have widely used artificial intelligence (AI). Algorithm-based technology is thought to produce more productive and profitable outcomes, as well as reducing conventional biases. The purpose of this Systematic Literature Review (SLR) is to examine prior research on the application of artificial intelligence to human resource management (HRM), and examine the extent to which the use of artificial intelligence (AI) has affected businesses and employees.",
    "doi": "10.47772/ijriss.2022.61131",
    "url": "https://www.semanticscholar.org/paper/966868f68ed4e66cc0c6a2a65a32ddda5065c7bb",
    "pdf_url": "https://doi.org/10.47772/ijriss.2022.61131",
    "venue": "International journal of research and innovation in social science",
    "citation_count": 3,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424705"
  },
  {
    "source": "semantic_scholar",
    "source_id": "3080807300183fa33c4cc5399ecfc771ed53141e",
    "title": "Medical, dental, and nursing students\u2019 attitudes and knowledge towards artificial intelligence: a systematic review and meta-analysis",
    "authors": [
      "Hamidreza. Amiri",
      "Samira Peiravi",
      "Seyedeh sara rezazadeh shojaee",
      "Motahare Rouhparvarzamin",
      "Mohammad Naser Nateghi",
      "Mohammad Hossein Etemadi",
      "Mahdie ShojaeiBaghini",
      "Farhan Musaie",
      "Mohammad Hossein Anvari",
      "Mahsa Asadi Anar"
    ],
    "year": 2024,
    "abstract": "Nowadays, Artificial intelligence (AI) is one of the most popular topics that can be integrated into healthcare activities. Currently, AI is used in specialized fields such as radiology, pathology, and ophthalmology. Despite the advantages of AI, the fear of human labor being replaced by this technology makes some students reluctant to choose specific fields. This meta-analysis aims to investigate the knowledge and attitude of medical, dental, and nursing students and experts in this field about AI and its application. This study was designed based on PRISMA guidelines. PubMed, Scopus, and Google Scholar databases were searched with relevant keywords. After study selection according to inclusion criteria, data of knowledge and attitude were extracted for meta-analysis. Twenty-two studies included 8491 participants were included in this meta-analysis. The pooled analysis revealed a proportion of 0.44 (95%CI\u2009=\u2009[0.34, 0.54], P\u2009<\u20090.01, I2\u2009=\u200998.95%) for knowledge. Moreover, the proportion of attitude was 0.65 (95%CI\u2009=\u2009[0.55, 0.75], P\u2009<\u20090.01, I2\u2009=\u200999.47%). The studies did not show any publication bias with a symmetrical funnel plot. Average levels of knowledge indicate the necessity of including relevant educational programs in the student\u2019s academic curriculum. The positive attitude of students promises the acceptance of AI technology. However, dealing with ethics education in AI and the aspects of human-AI cooperation are discussed. Future longitudinal studies could follow students to provide more data to guide how AI can be incorporated into education.",
    "doi": "10.1186/s12909-024-05406-1",
    "url": "https://www.semanticscholar.org/paper/3080807300183fa33c4cc5399ecfc771ed53141e",
    "pdf_url": "https://bmcmededuc.biomedcentral.com/counter/pdf/10.1186/s12909-024-05406-1",
    "venue": "BMC Medical Education",
    "citation_count": 63,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424714"
  },
  {
    "source": "semantic_scholar",
    "source_id": "32c11fa96c469d936b67917d6bbc77ed8d6997ac",
    "title": "Incorporating the Concepts of Fairness and Bias into an Undergraduate Computer Science Course to Promote Fair Automated Decision Systems",
    "authors": [
      "Sheikh Rabiul Islam",
      "I. Russell",
      "W. Eberle",
      "D. Dicheva"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1145/3478432.3499043",
    "url": "https://www.semanticscholar.org/paper/32c11fa96c469d936b67917d6bbc77ed8d6997ac",
    "pdf_url": "",
    "venue": "Technical Symposium on Computer Science Education",
    "citation_count": 10,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424719"
  },
  {
    "source": "semantic_scholar",
    "source_id": "6f1d4761c4841be90b5274b26e92c235ff826b6a",
    "title": "Teaching with Artificial Intelligence in Architecture: Embedding Technical Skills and Ethical Reflection in a Core Design Studio",
    "authors": [
      "Jiaqi Wang",
      "Yu Shi",
      "Xiang Chen",
      "Yi Lan",
      "Shuying Liu"
    ],
    "year": 2025,
    "abstract": "This case study examines the integration of artificial intelligence (AI) into undergraduate architectural education through a 2024\u201325 core studio teaching experiment at Zhejiang University. A dual-module framework was implemented, comprising a 20 h AI skills training module and in-class ethics discussions, without altering the existing studio structure. The AI skills module introduced deep learning models, LLMs, AIGC image models, LoRA fine-tuning, and ComfyUI, supported by a dedicated technical instructor. Student feedback indicated phase-dependent and tool-sensitive engagement, and students expressed a preference for embedded ethical discussion within the design studio rather than separate formal instruction. The experiment demonstrated that modular AI education is both scalable and practical, highlighting the importance of phase-sensitive guidance, balanced technical and ethical framing, and institutional support such as cloud platforms and research-based AI tools. The integration enhanced students\u2019 digital adaptability and strategic thinking while prompting reflection on issues such as authorship, algorithmic bias, and accountability in human\u2013AI collaboration. These findings offer a replicable model for AI-integrated design pedagogy that balances technical training with critical awareness.",
    "doi": "10.3390/buildings15173069",
    "url": "https://www.semanticscholar.org/paper/6f1d4761c4841be90b5274b26e92c235ff826b6a",
    "pdf_url": "",
    "venue": "Buildings",
    "citation_count": 2,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424747"
  },
  {
    "source": "semantic_scholar",
    "source_id": "39d1f020a585d3f28cb4b4c14497649e6a469ef1",
    "title": "Artificial Intelligence (AI) Ethics: Ethics of AI and Ethical AI",
    "authors": [
      "K. Siau",
      "Weiyu Wang"
    ],
    "year": 2020,
    "abstract": "Artificial intelligence (AI)-based technology has achieved many great things, such as facial recognition, medical diagnosis, and self-driving cars. AI promises enormous benefits for economic growth, social development, as well as human well-being and safety improvement. However, the low-level of explainability, data biases, data security, data privacy, and ethical problems of AI-based technology pose significant risks for users, developers, humanity, and societies. As AI advances, one critical issue is how to address the ethical and moral challenges associated with AI. Even though the concept of \u201cmachine ethics\u201d was proposed around 2006, AI ethics is still in the infancy stage. AI ethics is the field related to the study of ethical issues in AI. To address AI ethics, one needs to consider the ethics of AI and how to build ethical AI. Ethics of AI studies the ethical principles, rules, guidelines, policies, and regulations that are related to AI. Ethical AI is an AI that performs and behaves ethically. One must recognize and understand the potential ethical and moral issues that may be caused by AI to formulate the necessary ethical principles, rules, guidelines, policies, and regulations for AI (i.e., Ethics of AI). With the appropriate ethics of AI, one can then build AI that exhibits ethical behavior (i.e., Ethical AI). This paper will discuss AI ethics by looking at the ethics of AI and ethical AI. What are the perceived ethical and moral issues with AI? What are the general and common ethical principles, rules, guidelines, policies, and regulations that can resolve or at least attenuate these ethical and moral issues with AI? What are some of the necessary features and characteristics of an ethical AI? How to adhere to the ethics of AI to build ethical AI?",
    "doi": "10.4018/jdm.2020040105",
    "url": "https://www.semanticscholar.org/paper/39d1f020a585d3f28cb4b4c14497649e6a469ef1",
    "pdf_url": "",
    "venue": "Journal of Database Management",
    "citation_count": 297,
    "fields_of_study": [
      "Psychology",
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424753"
  },
  {
    "source": "semantic_scholar",
    "source_id": "19940359f59ab2336780e5bd3b8e0cfa4da6f50f",
    "title": "Ethical Implication of Artificial Intelligence (AI) Adoption in Financial Decision Making",
    "authors": [
      "Omoshola S. Owolabi",
      "Prince C. Uche",
      "Nathaniel T. Adeniken",
      "Christopher Ihejirika",
      "Riyad Bin Islam",
      "Bishal Chhetri"
    ],
    "year": 2024,
    "abstract": "The integration of artificial intelligence (AI) into the financial sector has raised ethical concerns that need to be addressed. This paper analyzes the ethical implications of using AI in financial decision-making and emphasizes the importance of an ethical framework to ensure its fair and trustworthy deployment. The study explores various ethical considerations, including the need to address algorithmic bias, promote transparency and explainability in AI systems, and adhere to regulations that protect equity, accountability, and public trust. By synthesizing research and empirical evidence, the paper highlights the complex relationship between AI innovation and ethical integrity in finance. To tackle this issue, the paper proposes a comprehensive and actionable ethical framework that advocates for clear guidelines, governance structures, regular audits, and collaboration among stakeholders. This framework aims to maximize the potential of AI while minimizing negative impacts and unintended consequences. The study serves as a valuable resource for policymakers, industry professionals, researchers, and other stakeholders, facilitating informed discussions, evidence-based decision-making, and the development of best practices for responsible AI integration in the financial sector. The ultimate goal is to ensure fairness, transparency, and accountability while reaping the benefits of AI for both the financial sector and society.",
    "doi": "10.5539/cis.v17n1p49",
    "url": "https://www.semanticscholar.org/paper/19940359f59ab2336780e5bd3b8e0cfa4da6f50f",
    "pdf_url": "https://ccsenet.org/journal/index.php/cis/article/download/0/0/50148/54269",
    "venue": "Computer and Information Science",
    "citation_count": 25,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424758"
  },
  {
    "source": "semantic_scholar",
    "source_id": "a32baf8c6ba09f528fed3135514951331722a5fd",
    "title": "Artificial Intelligence in Farming: Challenges and opportunities for building trust",
    "authors": [
      "Maaz Gardezi",
      "Bhavna Joshi",
      "Donna M. Rizzo",
      "Mark Ryan",
      "Edward Prutzer",
      "Skye Brugler",
      "Ali Dadkhah"
    ],
    "year": 2023,
    "abstract": "Artificial intelligence (AI) represents technologies with human-like cognitive abilities to learn, perform, and make decisions. AI in precision agriculture (PA) enables farmers and farm managers to deploy highly targeted and precise farming practices based on site-specific agroclimatic field measurements. The foundational and applied development of AI has matured considerably over the last 30 years. The time is now right to engage seriously with the ethics and responsible practice of AI for the well-being of farmers and farm managers. In this paper, we identify and discuss both challenges and opportunities for improving farmers\u2019 trust in those providing AI solutions for PA. We highlight that farmers\u2019 trust can be moderated by how the benefits and risks of AI are perceived, shared, and distributed. We propose four recommendations for improving farmers\u2019 trust. First, AI developers should improve model transparency and explainability. Second, clear responsibility and accountability should be assigned to AI decisions. Third, concerns about the fairness of AI need to be overcome to improve human-machine partnerships in agriculture. Finally, regulation",
    "doi": "10.1002/agj2.21353",
    "url": "https://www.semanticscholar.org/paper/a32baf8c6ba09f528fed3135514951331722a5fd",
    "pdf_url": "https://doi.org/10.1002/agj2.21353",
    "venue": "Agronomy Journal",
    "citation_count": 63,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424773"
  },
  {
    "source": "semantic_scholar",
    "source_id": "3e3b2c41c916544fc06f332d9ae29341c02b9458",
    "title": "Toward Involving End-users in Interactive Human-in-the-loop AI Fairness",
    "authors": [
      "Yuri Nakao",
      "Simone Stumpf",
      "Subeida Ahmed",
      "A. Naseer",
      "Lorenzo Strappelli"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1145/3514258",
    "url": "https://www.semanticscholar.org/paper/3e3b2c41c916544fc06f332d9ae29341c02b9458",
    "pdf_url": "https://eprints.gla.ac.uk/269192/1/269192.pdf",
    "venue": "ACM Trans. Interact. Intell. Syst.",
    "citation_count": 37,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424778"
  },
  {
    "source": "semantic_scholar",
    "source_id": "1e7602967f5da0de3c7ea5592c24df90bc018994",
    "title": "A focused review of artificial intelligence in education: Evolution and challenges",
    "authors": [
      "Erkan Acar",
      "Youmna Deiri",
      "Fatih Yigit"
    ],
    "year": 2025,
    "abstract": "The given systematic analysis reviews 40 articles published in 2015-2025 to discuss the examine the evolution, applications, and challenges of artificial intelligence (AI) in education, specifically in the bi/multilingual learning settings. The review relies on empirical and theoretical study and provides identification of the three major domains, including personalized learning, intelligent tutoring systems and chatbots, and automated assessment. The research results demonstrate that AI improves student engagement and learning performance and teaching efficiency due to the adaptive feedback and real-time analytics, particularly when used to support multiliteracy language learning practices. There are, however, major issues of concern that data privacy, algorithmic bias, unequal access, and the disappearance of relational and cultural facets of teaching and learning. The review highlights the empathy gap in the AI tools and demands the incorporation of AI into the mainstream in an inclusive, ethically based and linguistically responsive manner. It promotes the change in automation to intelligence augmentation and places AI at the service of educators offloading them with fair, human-centered, and AI assistive tools in multilingual learning students in English-dominant settings. The implications refer to the imperative to provide strong governance structures, human centered training of teachers in which AI serves as an addition to intelligence and not intelligence, and inclusive design to provide equitable and effective AI integration and to provide a balanced innovation with a focus on human-centered learning.",
    "doi": "10.20897/jirais/17640",
    "url": "https://www.semanticscholar.org/paper/1e7602967f5da0de3c7ea5592c24df90bc018994",
    "pdf_url": "",
    "venue": "Journal of Interdisciplinary Research in Artificial Intelligence and Society",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424792"
  },
  {
    "source": "semantic_scholar",
    "source_id": "5ccc4284451d033c0a98986fc1544c1c0baa044d",
    "title": "Data and AI governance: Promoting equity, ethics, and fairness in large language models",
    "authors": [
      "Alok Abhishek",
      "Lisa Erickson",
      "Tushar Bandopadhyay"
    ],
    "year": 2025,
    "abstract": "In this paper, we cover approaches to systematically govern, assess and quantify bias across the complete life cycle of machine learning models, from initial development and validation to ongoing production monitoring and guardrail implementation. Building upon our foundational work on the Bias Evaluation and Assessment Test Suite (BEATS) for Large Language Models, the authors share prevalent bias and fairness related gaps in Large Language Models (LLMs) and discuss data and AI governance framework to address Bias, Ethics, Fairness, and Factuality within LLMs. The data and AI governance approach discussed in this paper is suitable for practical, real-world applications, enabling rigorous benchmarking of LLMs prior to production deployment, facilitating continuous real-time evaluation, and proactively governing LLM generated responses. By implementing the data and AI governance across the life cycle of AI development, organizations can significantly enhance the safety and responsibility of their GenAI systems, effectively mitigating risks of discrimination and protecting against potential reputational or brand-related harm. Ultimately, through this article, we aim to contribute to advancement of the creation and deployment of socially responsible and ethically aligned generative artificial intelligence powered applications.",
    "doi": "10.38105/spr.1sn574k4lp",
    "url": "https://www.semanticscholar.org/paper/5ccc4284451d033c0a98986fc1544c1c0baa044d",
    "pdf_url": "",
    "venue": "MIT Science Policy Review",
    "citation_count": 3,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424802"
  },
  {
    "source": "semantic_scholar",
    "source_id": "c3b8424b249bc46b97d1ebd49c441231f1ba0756",
    "title": "Reconceptualizing Gatekeeping in the Age of Artificial Intelligence: A Theoretical Exploration of Artificial Intelligence-Driven News Curation and Automated Journalism",
    "authors": [
      "D. Voinea"
    ],
    "year": 2025,
    "abstract": "Artificial intelligence (AI) is transforming how news is produced, curated, and consumed, challenging traditional gatekeeping theories rooted in human editorial control. We develop a robust theoretical framework to reconceptualize gatekeeping in the AI era. We integrate classic media theories\u2014gatekeeping, agenda-setting, and framing\u2014with contemporary insights from algorithmic news recommender systems, large language model (LLM)\u2013based news writing, and platform studies. Our review reveals that AI-driven content curation systems (e.g., social media feeds, news aggregators) increasingly mediate what news is visible, sometimes reinforcing mainstream agendas, according to Nechushtai & Lewis, while, at other times, introducing new biases or echo chambers. Simultaneously, automated news generation via LLMs raises questions about how training data and optimization goals (engagement vs. diversity) act as new \u201cgatekeepers\u201d in story selection and framing. We found pervasive Simon\u2019s theory that reliance on third-party AI platforms transfers authority from newsrooms, creating power dependencies that may undercut journalistic autonomy. Moreover, adaptive algorithms learn from user behavior, creating feedback loops that dynamically shape news diversity and bias over time. Drawing on communication studies, science & technology studies (STS), and AI ethics, we propose an updated theoretical framework of \u201calgorithmic gatekeeping\u201d that accounts for the hybrid human\u2013AI processes governing news flow. We outline key research gaps\u2014including opaque algorithmic decision-making and normative questions of accountability\u2014and suggest directions for future theory-building to ensure journalism\u2019s core values survive in the age of AI-driven news.",
    "doi": "10.3390/journalmedia6020068",
    "url": "https://www.semanticscholar.org/paper/c3b8424b249bc46b97d1ebd49c441231f1ba0756",
    "pdf_url": "https://doi.org/10.3390/journalmedia6020068",
    "venue": "Journalism and Media",
    "citation_count": 4,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424844"
  },
  {
    "source": "semantic_scholar",
    "source_id": "67bfc8d80a60b23bb1a8734df1b56c357a43ace0",
    "title": "Ethical Challenges in Data Science: Navigating the Complex Landscape of Responsibility and Fairness",
    "authors": [
      "Chiranjeevi Bura",
      "Srikanth Kamatala",
      "Praveen Kumar Myakala"
    ],
    "year": 2025,
    "abstract": "The rapid advancement of data science and artificial intelligence (AI) has revolutionized decision-making across multiple domains, including healthcare, finance, and law enforcement. However, these advancements come with pressing ethical challenges, such as algorithmic bias, data privacy risks, and lack of transparency. This paper systematically analyzes these ethical concerns, focusing on state-of-the-art methodologies for bias detection, explainable AI (XAI), and privacy-preserving techniques. We provide a comparative evaluation of ethical frameworks, including the ACM Code of Ethics, IEEE Ethically Aligned Design (EAD), and regulatory policies such as GDPR and CCPA. Through in-depth case studies examining biased hiring algorithms, risk assessment models in criminal justice, and data privacy concerns in smart technologies\u2014we highlight real-world implications of unethical AI. Furthermore, we propose a structured approach to bias mitigation, integrating fairness-aware machine learning, adversarial debiasing, and regulatory compliance measures. Our findings contribute to responsible AI governance by identifying best practices and technical solutions that promote fairness, accountability, and transparency in AI-driven systems.",
    "doi": "10.47191/ijcsrr/v8-i3-09",
    "url": "https://www.semanticscholar.org/paper/67bfc8d80a60b23bb1a8734df1b56c357a43ace0",
    "pdf_url": "",
    "venue": "International Journal of Current Science Research and Review",
    "citation_count": 3,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424850"
  },
  {
    "source": "semantic_scholar",
    "source_id": "f890916fd3f399dfdeb67ba8efc4b9a71e8029d0",
    "title": "The Algorithmic Hand: Investigating the Impact of Artificial Intelligence on Service Delivery, Customer Interactions, And Efficiency",
    "authors": [
      "Simon Suwanzy Dzreke",
      "Semefa Elikplim Dzreke"
    ],
    "year": 2025,
    "abstract": "Abstract: The study looks closely at the complicated, game-changing, and sometimes contradictory effects of Artificial Intelligence (AI) on modern service delivery. It looks at how AI changes the way businesses work, how customers interact with each other, and the moral limits of service ecosystems. Using a mixed-methods approach with multiple phases (interviews, experiments, case studies, and surveys), the results show that AI systems make tasks much more efficient, cutting transaction costs by up to 30% and response times by up to 40%. The paper makes the service quality seem better for standard tasks through calibrated anthropomorphic design (\u03b2=0.38, p<.001). But this \"algorithmic hand\" also causes serious social and emotional problems in complicated situations. Without real empathy and the ability to adapt to different situations, customers get frustrated and blame the company for AI failures; 82% of them blame the company for not being careful enough, which hurts trust more than anything else. The study shows that contingency factors\u2014task complexity, customer demographics, interface transparency, and agent skill polarization\u2014are important because they affect how well AI works. This leads to ethical issues like measurable algorithmic bias (0.75 SD lower satisfaction among elderly users; p < .01), growing privacy concerns, and widespread gaps in governance. We propose a new, multi-theoretical framework that integrates TAM, Social Presence Theory, and Attribution Theory. This framework explains how customers think and gives practical advice for hybrid human-AI systems. For professionals, its use means getting evidence-based advice on how to improve anthropomorphism, recover from failure, and reduce bias. It calls for regulatory frameworks that put fairness and human dignity at the top of the list. In the end, this work changes the definition of service innovation by saying that AI's real value is not in being able to work on its own, but in being ethically governed and sensitive to the situation. It also calls for more research into the new problems that generative AI is causing, with human flourishing as the main measure of progress.",
    "doi": "10.51583/ijltemas.2025.140600092",
    "url": "https://www.semanticscholar.org/paper/f890916fd3f399dfdeb67ba8efc4b9a71e8029d0",
    "pdf_url": "",
    "venue": "International Journal of Latest Technology in Engineering Management &amp; Applied Science",
    "citation_count": 10,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424854"
  },
  {
    "source": "semantic_scholar",
    "source_id": "1c79833e6442f627f7d136462fd1d036f75c5886",
    "title": "Artificial Intelligence and Deep Learning in Healthcare, Cyber security, and Food Systems: A Comprehensive Review of Applications, Challenges, and Future Directions",
    "authors": [
      "Ali Husnain"
    ],
    "year": 2025,
    "abstract": "The implementation of Artificial Intelligence in healthcare alongside cyber security and food systems produces enhanced efficiency and security functions together with automated processes. Healthcare organizations use AI-powered diagnostic instruments together with predictive data tools and individualized medical approaches to enhance therapeutic results while shortening drug development cycles. AI applications need proper solution to algorithmic biases while protecting data privacy and respecting ethical values for the sake of transparent and fair implementation. Security frameworks which are resilient to emerging exploitative AI techniques together with human oversight have become essential because AI-powered threat detection and automated responses enhance cyber security defenses against cyber-attacks. The upcoming stage of AI advancement will concentrate on three main areas which combine explain ability, trustworthy systems and knowledge transfer between different sectors. Global healthcare advancement along with improved cyber security protection and enhanced food system management are possible through interdisciplinary AI techniques and appropriate challenge management which ensures transparency, security and sustainable practices.",
    "doi": "10.70445/gjeac.1.2.2025.95-126",
    "url": "https://www.semanticscholar.org/paper/1c79833e6442f627f7d136462fd1d036f75c5886",
    "pdf_url": "",
    "venue": "Global Journal of Emerging AI and Computing",
    "citation_count": 2,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424858"
  },
  {
    "source": "semantic_scholar",
    "source_id": "d9c064ceac6f5f9fadc1a7f38ee96ad0faf6abbe",
    "title": "LEGAL CHALLENGES OF ARTIFICIAL INTELLIGENCE AND ROBOTICS: A COMPREHENSIVE REVIEW",
    "authors": [
      "Chidiogo Uzoamaka Akpuokwe",
      "Adekunle Oyeyemi Adeniyi",
      "Seun Solomon Bakare",
      "Nkechi Emmanuella Eneh"
    ],
    "year": 2024,
    "abstract": "The paper presents an insightful overview of the intricate legal challenges posed by the proliferation of Artificial Intelligence (AI) and Robotics. This comprehensive review explores the multifaceted dimensions of the evolving legal landscape, addressing issues at the intersection of technology and law. Key focal points include the accountability and liability frameworks for autonomous AI systems, ethical considerations in the deployment of intelligent machines, and the complex dynamics of data privacy in the age of pervasive automation. The review delves into the intricate legal nuances surrounding intellectual property rights, particularly as AI systems contribute to creative outputs and innovation. It navigates the blurred lines between human and machine authorship, raising fundamental questions about ownership and protection in this digital era. Moreover, the paper emphasizes the global nature of these challenges, highlighting the imperative for international cooperation to formulate harmonized legal standards. As AI and robotics revolutionize industries and societal frameworks, the analysis underscores the critical need for adaptive and anticipatory legal frameworks. It explores how existing legal paradigms are grappling with the unprecedented speed of technological advancements and the ethical dilemmas arising from the delegation of decision-making to intelligent algorithms. The paper sets the stage for a thorough examination of the legal intricacies surrounding AI and robotics. It advocates for a proactive and collaborative approach, involving legal experts, technologists, ethicists, and policymakers in crafting robust frameworks that balance innovation with ethical, privacy, and accountability considerations. This review serves as a foundational resource for understanding and addressing the legal challenges inherent in the transformative era of Artificial Intelligence and Robotics. \nKeywords: Artificial intelligence, Robotics, Legal, AI challenges, Ethics, Review.",
    "doi": "10.51594/csitrj.v5i3.860",
    "url": "https://www.semanticscholar.org/paper/d9c064ceac6f5f9fadc1a7f38ee96ad0faf6abbe",
    "pdf_url": "https://fepbl.com/index.php/csitrj/article/download/860/1061",
    "venue": "Computer Science &amp; IT Research Journal",
    "citation_count": 27,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424862"
  },
  {
    "source": "semantic_scholar",
    "source_id": "c81ba0ca7553f1e1c80437ebd8b34dd6ee55adf7",
    "title": "Using Artificial Intelligence for High-Volume Identification of Silicosis and Tuberculosis: A Bio-Ethics Approach",
    "authors": [
      "J. Spiegel",
      "R. Ehrlich",
      "A. Yassi",
      "F. Riera",
      "James Wilkinson",
      "K. Lockhart",
      "S. Barker",
      "B. Kistnasamy"
    ],
    "year": 2021,
    "abstract": "Although Artificial Intelligence (AI) is being increasingly applied, considerable distrust about introducing \u201cdisruptive\u201d technologies persists. Intrinsic and contextual factors influencing where and how such innovations are introduced therefore require careful scrutiny to ensure that health equity is promoted. To illustrate one such critical approach, we describe and appraise an AI application \u2013 the development of computer assisted diagnosis (CAD) to support more efficient adjudication of compensation claims from former gold miners with occupational lung disease in Southern Africa. In doing so, we apply a bio-ethical lens that considers the principles of beneficence, non-maleficence, autonomy and justice and add explicability as a core principle. We draw on the AI literature, our research on CAD validation and process efficiency, as well as apprehensions of users and stakeholders. Issues of concern included AI accuracy, biased training of AI systems, data privacy, impact on human skill development, transparency and accountability in AI use, as well as intellectual property ownership. We discuss ways in which each of these potential obstacles to successful use of CAD could be mitigated. We conclude that efforts to overcoming technical challenges in applying AI must be accompanied from the onset by attention to ensuring its ethical use.",
    "doi": "10.5334/aogh.3206",
    "url": "https://www.semanticscholar.org/paper/c81ba0ca7553f1e1c80437ebd8b34dd6ee55adf7",
    "pdf_url": "https://doi.org/10.5334/aogh.3206",
    "venue": "Annals of Global Health",
    "citation_count": 15,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424867"
  },
  {
    "source": "semantic_scholar",
    "source_id": "8eeacfa9fbf8ff903441f359411cb073921ebbd0",
    "title": "Cognitive Bias in AI Recommendations: Understanding and Mitigating Human-AI Decision-Making Errors",
    "authors": [
      "Prasasti Aich"
    ],
    "year": 2025,
    "abstract": "Artificial Intelligence (AI) systems increasingly influence human decision-making, from search engine suggestions to hiring recommendations. However, these systems often reinforce cognitive biases, leading to skewed perceptions and decision errors. This workshop will examine the intersection of cognitive biases and AI-generated recommendations, providing UX researchers, designers, and HCI practitioners with strategies to design transparent, fair, and bias-aware AI systems. Additionally, it will include people who use AI in their daily lives to help them realize the impact AI has on their choices. Through interactive discussions, usability studies, and real-world case analyses, participants will explore methods to identify and mitigate cognitive biases in AI recommendations. The workshop aims to foster collaboration and generate insights for a forthcoming publication on bias-aware AI design.",
    "doi": "10.1145/3765766.3765887",
    "url": "https://www.semanticscholar.org/paper/8eeacfa9fbf8ff903441f359411cb073921ebbd0",
    "pdf_url": "",
    "venue": "International Conference on Human-Agent Interaction",
    "citation_count": 1,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424871"
  },
  {
    "source": "semantic_scholar",
    "source_id": "d417065c6b62f57248166c2272cab7ea9191c153",
    "title": "Exploring the Role of Artificial Intelligence in Mental Healthcare: Progress, Pitfalls, and Promises",
    "authors": [
      "Gemma Espejo",
      "Wade Reiner",
      "Michael Wenzinger"
    ],
    "year": 2023,
    "abstract": "The rise of artificial intelligence (AI) heralds a significant revolution in healthcare, particularly in mental health. AI's potential spans diagnostic algorithms, data analysis from diverse sources, and real-time patient monitoring. It is essential for clinicians to remain informed about AI's progress and limitations. The inherent complexity of mental disorders, limited objective data, and retrospective studies pose challenges to the application of AI. Privacy concerns, bias, and the risk of AI replacing human care also loom. Regulatory oversight and physician involvement are needed for equitable AI implementation. AI integration and use in psychotherapy and other services are on the horizon. Patient trust, feasibility, clinical efficacy, and clinician acceptance are prerequisites. In the future, governing bodies must decide on AI ownership, governance, and integration approaches. While AI can enhance clinical decision-making and efficiency, it might also exacerbate moral dilemmas, autonomy loss, and issues regarding the scope of practice. Striking a balance between AI's strengths and limitations involves utilizing AI as a validated clinical supplement under medical supervision, necessitating active clinician involvement in AI research, ethics, and regulation. AI's trajectory must align with optimizing mental health treatment and upholding compassionate care.",
    "doi": "10.7759/cureus.44748",
    "url": "https://www.semanticscholar.org/paper/d417065c6b62f57248166c2272cab7ea9191c153",
    "pdf_url": "https://assets.cureus.com/uploads/editorial/pdf/169611/20230906-22464-vc3sfw.pdf",
    "venue": "Cureus",
    "citation_count": 35,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424875"
  },
  {
    "source": "semantic_scholar",
    "source_id": "9819447e44992a45463040d3ce57da761a303dfc",
    "title": "Integrating Artificial Intelligence into Medical Physics Practice: Promises and Ethical Considerations",
    "authors": [
      "Makoye John",
      "Rose Mina"
    ],
    "year": 2025,
    "abstract": "Artificial intelligence (AI) techniques such as deep learning show great potential to enhance medical physics practice by supporting diagnosis, treatment planning, and other clinical tasks. However, responsible integration of AI requires consideration of both promises and ethical risks to ensure technologies are developed and applied safely and for patient benefit. This research review examines opportunities and challenges of integrating AI across various domains of medical physics. Promising applications are discussed such as using large datasets to help radiologists interpret images more accurately and automating routine analyses to increase efficiency. AI may also expand access to care for rural populations through remote services. Potential ethical issues that could hamper responsible integration are also explored. Ensuring AI algorithms avoid human biases that unfairly impact patient outcomes is imperative. Other considerations include responsible oversight structures, ensuring privacy of patient data, and establishing regulatory and quality standards. This review proposes a framework for multidisciplinary collaboration and rigorous testing prior to clinical adoption of AI tools. It concludes that with ongoing research and development guided by principles of safety, accountability and fairness, AI can potentially enhance medical physics practice while avoiding unintended harms.\n",
    "doi": "10.11648/j.ajai.20250902.16",
    "url": "https://www.semanticscholar.org/paper/9819447e44992a45463040d3ce57da761a303dfc",
    "pdf_url": "",
    "venue": "American Journal of Artificial Intelligence",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424878"
  },
  {
    "source": "semantic_scholar",
    "source_id": "644723972382614555393a21e82014eea892a4eb",
    "title": "Artificial Intelligence in Image Analysis For Dermatology And Dermatopathology: Advancements And Challenges",
    "authors": [
      "R. Balachander",
      "G. Yohalakshmi",
      "A. R. Kavitha"
    ],
    "year": 2025,
    "abstract": "Emergence of Artificial Intelligence has evolved as a transformative tool for dermatology and dermatopathology, addressing significant hurdles such as high consultation costs, global dermatologist shortages, and diagnostic disparities. Therefore, this review delves into the progress that is being made in the areas related to AI applications with focus on its ability to diagnose high-resolution skin images towards better accuracy in diagnostics regarding melanoma, nevi, and inflammatory diseases. Using techniques like CNNs and deep learning, AI achieves sensitivity levels ranging from 58% to 96.1%, which is on par with human expertise. However, there are still many challenges, including dataset biases, underrepresentation of SOC, and reliance on outdated classification systems like the Fitzpatrick Skin Type (FST) scale. This paper will illustrate examples of solutions like Monk Skin Tone Scale, Fast Contrastive Unpaired Translation, (FastCUT) among others, to diminish this problem. Moreover, other ethical considerations like clarity and fairness and data confidentiality, among others, were observed. The review points toward multidisciplinary collaboration prospective clinical trials, and strict observance of regulatory compliance while dealing with AI models with great care for their trustworthiness and inclusivity. Thus, by overcoming these challenges, AI has the potential to revolutionize dermatological care with equity, accessibility, and effectiveness across diverse populations.",
    "doi": "10.1109/ICDSAAI65575.2025.11011788",
    "url": "https://www.semanticscholar.org/paper/644723972382614555393a21e82014eea892a4eb",
    "pdf_url": "",
    "venue": "2025 International Conference on Data Science, Agents & Artificial Intelligence (ICDSAAI)",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424882"
  },
  {
    "source": "semantic_scholar",
    "source_id": "57922a6310ae171f174b85527fc75bb1f9ceee50",
    "title": "Towards Involving End-users in Interactive Human-in-the-loop AI Fairness",
    "authors": [
      "Yuri Nakao",
      "Simone Stumpf",
      "Subeida Ahmed",
      "A. Naseer",
      "Lorenzo Strappelli"
    ],
    "year": 2022,
    "abstract": "Ensuring fairness in artificial intelligence (AI) is important to counteract bias and discrimination in far-reaching applications. Recent work has started to investigate how humans judge fairness and how to support machine learning (ML) experts in making their AI models fairer. Drawing inspiration from an Explainable AI (XAI) approach called \\emph{explanatory debugging} used in interactive machine learning, our work explores designing interpretable and interactive human-in-the-loop interfaces that allow ordinary end-users without any technical or domain background to identify potential fairness issues and possibly fix them in the context of loan decisions. Through workshops with end-users, we co-designed and implemented a prototype system that allowed end-users to see why predictions were made, and then to change weights on features to\"debug\"fairness issues. We evaluated the use of this prototype system through an online study. To investigate the implications of diverse human values about fairness around the globe, we also explored how cultural dimensions might play a role in using this prototype. Our results contribute to the design of interfaces to allow end-users to be involved in judging and addressing AI fairness through a human-in-the-loop approach.",
    "doi": "10.48550/arXiv.2204.10464",
    "url": "https://www.semanticscholar.org/paper/57922a6310ae171f174b85527fc75bb1f9ceee50",
    "pdf_url": "http://arxiv.org/pdf/2204.10464",
    "venue": "arXiv.org",
    "citation_count": 33,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424886"
  },
  {
    "source": "semantic_scholar",
    "source_id": "9721e79ac21e08a7b53ead33bbd1e675f84d1e6e",
    "title": "Balancing innovation and ethics: promote academic integrity through support and effective use of GenAI tools in higher education",
    "authors": [
      "Kangwa Daniel",
      "M. M. Msambwa",
      "A. Fute"
    ],
    "year": 2025,
    "abstract": null,
    "doi": "10.1007/s43681-025-00689-6",
    "url": "https://www.semanticscholar.org/paper/9721e79ac21e08a7b53ead33bbd1e675f84d1e6e",
    "pdf_url": "",
    "venue": "AI and Ethics",
    "citation_count": 4,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424889"
  },
  {
    "source": "semantic_scholar",
    "source_id": "9613a800142ec229cb888ce9b80efa8f78aab092",
    "title": "Artificial intelligence for telemedicine diabetic retinopathy screening: a review",
    "authors": [
      "L. Nakayama",
      "L. Zago Ribeiro",
      "Frederico Novaes",
      "I. Miyawaki",
      "Andresa Emy Miyawaki",
      "Juliana Ang\u00e9lica Estev\u00e3o de Oliveira",
      "Talita Oliveira",
      "F. Malerbi",
      "C. Regatieri",
      "L. Celi",
      "Paolo S. Silva"
    ],
    "year": 2023,
    "abstract": "Abstract Purpose This study aims to compare artificial intelligence (AI) systems applied in diabetic retinopathy (DR) teleophthalmology screening, currently deployed systems, fairness initiatives and the challenges for implementation. Methods The review included articles retrieved from PubMed/Medline/EMBASE literature search strategy regarding telemedicine, DR and AI. The screening criteria included human articles in English, Portuguese or Spanish and related to telemedicine and AI for DR screening. The author\u2019s affiliations and the study\u2019s population income group were classified according to the World Bank Country and Lending Groups. Results The literature search yielded a total of 132 articles, and nine were included after full-text assessment. The selected articles were published between 2004 and 2020 and were grouped as telemedicine systems, algorithms, economic analysis and image quality assessment. Four telemedicine systems that perform a quality assessment, image preprocessing and pathological screening were reviewed. A data and post-deployment bias assessment are not performed in any of the algorithms, and none of the studies evaluate the social impact implementations. There is a lack of representativeness in the reviewed articles, with most authors and target populations from high-income countries and no low-income country representation. Conclusions Telemedicine and AI hold great promise for augmenting decision-making in medical care, expanding patient access and enhancing cost-effectiveness. Economic studies and social science analysis are crucial to support the implementation of AI in teleophthalmology screening programs. Promoting fairness and generalizability in automated systems combined with telemedicine screening programs is not straightforward. Improving data representativeness, reducing biases and promoting equity in deployment and post-deployment studies are all critical steps in model development.",
    "doi": "10.1080/07853890.2023.2258149",
    "url": "https://www.semanticscholar.org/paper/9613a800142ec229cb888ce9b80efa8f78aab092",
    "pdf_url": "https://www.tandfonline.com/doi/pdf/10.1080/07853890.2023.2258149?needAccess=true",
    "venue": "Annals medicus",
    "citation_count": 29,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424894"
  },
  {
    "source": "semantic_scholar",
    "source_id": "df374be55da428c45891f1e09fe3eed81b758993",
    "title": "Ethical AI in Healthcare: A Comprehensive Review Addressing Privacy, Security, and Fairness",
    "authors": [
      "Ivy Payne Nkrumah",
      "Felicia Engmann",
      "Kofi Sarpong Adu-Manu"
    ],
    "year": 2025,
    "abstract": "The integration of Artificial Intelligence (AI) into healthcare presents both transformative potential and profound ethical challenges. This paper examines how ethical principles, such as transparency, fairness, accountability, and privacy, are applied and operationalised in healthcare AI. Using a structured narrative review approach, we analysed over 70 peer-reviewed empirical studies, policy documents, and regulatory frameworks that span applications in clinical decision support systems, diagnostics, mental health interventions and personalised medicine. Particular attention is given to the perspectives of diverse stakeholders, including patients, clinicians, data scientists and regulators. We assess fairness using demographic parity and equalised odds and evaluate transparency via explainability metrics and auditability practices. Our findings highlight the persistent issues of demographic bias, lack of stakeholder participation, and regulatory fragmentation. We propose a typology of responsible AI metrics, including data representativeness indices, fairness-accuracy trade-off scores, and human-AI oversight benchmarks, that can guide the ethical evaluation and deployment of AI models. By emphasising intersectionality, contextual equity, and co-designed governance, this study moves beyond generic ethical appeals to concrete implementation strategies. Our contribution offers a practical and interdisciplinary roadmap for aligning AI innovation with patient-centred values, institutional accountability, and evolving EU regulatory standards in the healthcare sector.",
    "doi": "10.14746/eip.2025.2.2",
    "url": "https://www.semanticscholar.org/paper/df374be55da428c45891f1e09fe3eed81b758993",
    "pdf_url": "",
    "venue": "ETHICS IN PROGRESS",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424898"
  },
  {
    "source": "semantic_scholar",
    "source_id": "a4113e31b39b72bb8f69479e52c339255b2606e7",
    "title": "Fairness in AI-Driven Recruitment: Challenges, Metrics, Methods, and Future Directions",
    "authors": [
      "Dena F. Mujtaba",
      "N. Mahapatra"
    ],
    "year": 2024,
    "abstract": "The recruitment process significantly impacts an organization's performance, productivity, and culture. Traditionally, human resource experts and industrial-organizational psychologists have developed systematic hiring methods, including job advertising, candidate skill assessments, and structured interviews to ensure candidate-organization fit. Recently, recruitment practices have shifted dramatically toward artificial intelligence (AI)-based methods, driven by the need to efficiently manage large applicant pools. However, reliance on AI raises concerns about the amplification and propagation of human biases embedded within hiring algorithms, as empirically demonstrated by biases in candidate ranking systems and automated interview assessments. Consequently, algorithmic fairness has emerged as a critical consideration in AI-driven recruitment, aimed at rigorously addressing and mitigating these biases. This paper systematically reviews biases identified in AI-driven recruitment systems, categorizes fairness metrics and bias mitigation techniques, and highlights auditing approaches used in practice. We emphasize critical gaps and current limitations, proposing future directions to guide researchers and practitioners toward more equitable AI recruitment practices, promoting fair candidate treatment and enhancing organizational outcomes.",
    "doi": "10.48550/arXiv.2405.19699",
    "url": "https://www.semanticscholar.org/paper/a4113e31b39b72bb8f69479e52c339255b2606e7",
    "pdf_url": "",
    "venue": "arXiv.org",
    "citation_count": 12,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424902"
  },
  {
    "source": "semantic_scholar",
    "source_id": "1f7b6e2be404f16a0d2a88eef169961220d5751f",
    "title": "Call for the responsible artificial intelligence in the healthcare",
    "authors": [
      "Umashankar Upadhyay",
      "Anton Gradisek",
      "Usman Iqbal",
      "Eshita Dhar",
      "Y. Li",
      "S. Syed-Abdul"
    ],
    "year": 2023,
    "abstract": "The integration of artificial intelligence (AI) into healthcare is progressively becoming pivotal, especially with its potential to enhance patient care and operational workflows. This paper navigates through the complexities and potentials of AI in healthcare, emphasising the necessity of explainability, trustworthiness, usability, transparency and fairness in developing and implementing AI models. It underscores the \u2018black box\u2019 challenge, highlighting the gap between algorithmic outputs and human interpretability, and articulates the pivotal role of explainable AI in enhancing the transparency and accountability of AI applications in healthcare. The discourse extends to ethical considerations, exploring the potential biases and ethical dilemmas that may arise in AI application, with a keen focus on ensuring equitable and ethical AI use across diverse global regions. Furthermore, the paper explores the concept of responsible AI in healthcare, advocating for a balanced approach that leverages AI\u2019s capabilities for enhanced healthcare delivery and ensures ethical, transparent and accountable use of technology, particularly in clinical decision-making and patient care.",
    "doi": "10.1136/bmjhci-2023-100920",
    "url": "https://www.semanticscholar.org/paper/1f7b6e2be404f16a0d2a88eef169961220d5751f",
    "pdf_url": "https://informatics.bmj.com/content/bmjhci/30/1/e100920.full.pdf",
    "venue": "BMJ Health & Care Informatics",
    "citation_count": 26,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424906"
  },
  {
    "source": "semantic_scholar",
    "source_id": "c1899167f19ff3cb30e59e674bd960d042287e82",
    "title": "Artificial intelligence: a new field of knowledge for nephrologists?",
    "authors": [
      "L. Fayos de Ariz\u00f3n",
      "E. R. Viera",
      "M. Pilco",
      "A. Perera",
      "G. de Maeztu",
      "A. Nicolau",
      "M. Furlano",
      "R. Torra"
    ],
    "year": 2023,
    "abstract": "\n Artificial Intelligence (AI) is a science that involves creating machines that can imitate human intelligence and learn. AI is ubiquitous in our daily lives, from search engines like Google to home assistants like Alexa and, more recently, OpenAI with its chatbot. AI can improve clinical care and research, but its use requires a solid understanding of its fundamentals, the promises and perils of algorithmic fairness, the barriers and solutions to its clinical implementation, and the pathways to developing an AI-competent workforce.\n The potential of AI in the field of nephrology is vast, particularly in the areas of diagnosis, treatment, and prediction. One of the most significant advantages of AI is the ability to improve diagnostic accuracy. Machine learning algorithms can be trained to recognize patterns in patient data, including lab results, imaging, and medical history, in order to identify early signs of kidney disease and thereby allow timely diagnoses and prompt initiation of treatment plans that can improve outcomes for patients. In short, AI holds the promise of advancing personalized medicine to new levels.\n While AI has tremendous potential, there are also significant challenges to its implementation, including data access and quality, data privacy and security, bias, trustworthiness, computing power, AI integration, and legal issues. The European Commission's proposed regulatory framework for AI technology will play a significant role in ensuring the safe and ethical implementation of these technologies in the healthcare industry.\n Training nephrologists in the fundamentals of AI is imperative because traditionally, decision-making pertaining to the diagnosis, prognosis, and treatment of renal patients has relied on ingrained practices, whereas AI serves as a powerful tool for swiftly and confidently synthesizing this information.",
    "doi": "10.1093/ckj/sfad182",
    "url": "https://www.semanticscholar.org/paper/c1899167f19ff3cb30e59e674bd960d042287e82",
    "pdf_url": "https://academic.oup.com/ckj/advance-article-pdf/doi/10.1093/ckj/sfad182/51005865/sfad182.pdf",
    "venue": "Clinical Kidney Journal",
    "citation_count": 22,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424910"
  },
  {
    "source": "semantic_scholar",
    "source_id": "ced30db981dc74704c9bd3cf04876c8540cf2f66",
    "title": "Augmented intelligence should be good for medicine, if medicine is to remain good for us",
    "authors": [
      "Daphna Idan",
      "L. Celi",
      "Sharon Einav",
      "Amit Frenkel"
    ],
    "year": 2025,
    "abstract": null,
    "doi": "10.1007/s44163-025-00256-2",
    "url": "https://www.semanticscholar.org/paper/ced30db981dc74704c9bd3cf04876c8540cf2f66",
    "pdf_url": "",
    "venue": "Discover Artificial Intelligence",
    "citation_count": 0,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424913"
  },
  {
    "source": "semantic_scholar",
    "source_id": "1d7799a5e056cce4ff48330fee77552d824e3be1",
    "title": "Artificial Intelligence Can\u2019t Be Charmed: The Effects of Impartiality on Laypeople\u2019s Algorithmic Preferences",
    "authors": [
      "Marius Claudy",
      "Karl Aquino",
      "Maja Graso"
    ],
    "year": 2022,
    "abstract": "Over the coming years, AI could increasingly replace humans for making complex decisions because of the promise it holds for standardizing and debiasing decision-making procedures. Despite intense debates regarding algorithmic fairness, little research has examined how laypeople react when resource-allocation decisions are turned over to AI. We address this question by examining the role of perceived impartiality as a factor that can influence the acceptance of AI as a replacement for human decision-makers. We posit that laypeople attribute greater impartiality to AI than human decision-makers. Our investigation shows that people value impartiality in decision procedures that concern the allocation of scarce resources and that people perceive AI as more capable of impartiality than humans. Yet, paradoxically, laypeople prefer human decision-makers in allocation decisions. This preference reverses when potential human biases are made salient. The findings highlight the importance of impartiality in AI and thus hold implications for the design of policy measures.",
    "doi": "10.3389/fpsyg.2022.898027",
    "url": "https://www.semanticscholar.org/paper/1d7799a5e056cce4ff48330fee77552d824e3be1",
    "pdf_url": "https://www.frontiersin.org/articles/10.3389/fpsyg.2022.898027/pdf",
    "venue": "Frontiers in Psychology",
    "citation_count": 15,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424917"
  },
  {
    "source": "semantic_scholar",
    "source_id": "5705095c8a342fc068f1f8487fb2706c669d1bfc",
    "title": "AI Ethics and Regulations: Ensuring Trustworthy AI",
    "authors": [
      "Pericles 'Asher' Rospigliosi"
    ],
    "year": 2025,
    "abstract": "As Artificial Intelligence (AI) technologies become increasingly embedded in critical aspects of modern life\u2014ranging from healthcare diagnostics and financial forecasting to autonomous vehicles, law enforcement, education, and national security\u2014the urgency of addressing their ethical implications has grown exponentially. While AI systems offer unprecedented efficiencies and capabilities, they also present significant risks, including algorithmic bias, opaque decisionmaking processes, data exploitation, invasion of privacy, digital surveillance, job displacement, and the amplification of societal inequalities. These risks are particularly acute in high-stakes domains where errors or unchecked use can result in irreversible harm or systemic injustice. This paper offers a comprehensive examination of the evolving ethical landscape surrounding AI development and deployment. It explores foundational ethical principles such as fairness, accountability, transparency, and human-centered design, alongside contemporary challenges introduced by machine learning models, deep learning algorithms, and autonomous decision systems. Special attention is given to the global regulatory landscape, comparing initiatives such as the European Union\u2019s AI Act, the U.S. Blueprint for an AI Bill of Rights, and guidelines from organizations like UNESCO and the OECD. The paper also examines the growing role of interdisciplinary AI ethics teams, algorithmic auditing, and impact assessments. Ultimately, the paper proposes a strategic roadmap for building ethical AI ecosystems grounded in inclusivity, explainability, legal compliance, and social well-being. It emphasizes that aligning AI development with democratic values, human dignity, and global equity is not merely desirable\u2014 but essential\u2014for ensuring that the future of AI serves humanity as a whole, rather than a privileged few.\u00a0",
    "doi": "10.63619/ijai4s.v1i2.004",
    "url": "https://www.semanticscholar.org/paper/5705095c8a342fc068f1f8487fb2706c669d1bfc",
    "pdf_url": "",
    "venue": "International Journal of Artificial Intelligence for Science (IJAI4S)",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424920"
  },
  {
    "source": "semantic_scholar",
    "source_id": "e3a579dae809624b78bc4029c44bb7b2a9d42f5b",
    "title": "A Process for Human Resource Performance Evaluation Using Computational Intelligence: An Approach Using a Combination of Rule-Based Classifiers and Supervised Learning Algorithms",
    "authors": [
      "Anderson Silva De Oliveira G\u00f3es",
      "Roberto C\u00e9lio Lim\u00e3o de Oliveira"
    ],
    "year": 2020,
    "abstract": "This paper proposes a process for human resource performance evaluation using computational intelligence techniques. The human resource (or employee\u2019s) performance evaluation is essentially a regular assessment and review of an employee\u2019s performance on the job. This evaluation can be performed in different ways, depending on the kind of job of the employee and on the company\u2019s politics or business area. The process proposed on this research combines Fuzzy logic, text sentiment analysis and supervised learning classification techniques, such as a multi layer perceptron artificial neural network, decision tree algorithms and na\u00efve bayes into ensemble classifiers, in an attempt to provide a fair evaluation process, minimizing or even eliminating common problems caused by simple objective or subjective approaches. The data provided for this research was originated from several evaluations applied in two Brazilians institutions. Simulation results shows consistence on the data generated by this proposed process, indicating a good perspective for applications on companies of most business areas.",
    "doi": "10.1109/ACCESS.2020.2975485",
    "url": "https://www.semanticscholar.org/paper/e3a579dae809624b78bc4029c44bb7b2a9d42f5b",
    "pdf_url": "https://ieeexplore.ieee.org/ielx7/6287639/8948470/09004612.pdf",
    "venue": "IEEE Access",
    "citation_count": 26,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424924"
  },
  {
    "source": "semantic_scholar",
    "source_id": "28d9b673f0f1df50e44e7f3e27c22580d5b7bc99",
    "title": "Integrating Behavioral, Economic, and Technical Insights to Understand and Address Algorithmic Bias: A Human-Centric Perspective",
    "authors": [
      "G. Adomavicius",
      "Mochen Yang"
    ],
    "year": 2022,
    "abstract": "Many important decisions are increasingly being made with the help of information systems that use artificial intelligence and machine learning models. These computational models are designed to discover useful patterns from large amounts of data, which augment human capabilities to make decisions in various application domains. However, there are growing concerns regarding the ethics challenges faced by these automated decision-making (ADM) models, most notably on the issue of algorithmic bias, in which the models systematically produce less favorable (i.e., unfair) decisions for certain groups of people. In this commentary, we argue that algorithmic bias is not just a technical (e.g., computational or statistical) problem, and its successful resolution requires deep insights into individual and organizational behavior, economic incentives, as well as complex dynamics of the sociotechnical systems in which the ADM models are embedded. We discuss a human-centric, fairness-aware ADM framework that highlights the holistic involvement of human decision makers in each step of ADM. We review the emerging literature on fairness-aware machine learning and then discuss various strategic decisions that humans need to make, such as formulating proper fairness objectives, recognizing fairness-induced trade-offs and implications, utilizing machine learning model outputs, and managing/governing the decisions of ADM models. We further illustrate how these strategic decisions are jointly informed by behavioral, economic, and design sciences. Our discussions reveal a number of future research opportunities uniquely suitable for Management Information Systems (MIS) researchers to pursue.",
    "doi": "10.1145/3519420",
    "url": "https://www.semanticscholar.org/paper/28d9b673f0f1df50e44e7f3e27c22580d5b7bc99",
    "pdf_url": "",
    "venue": "ACM Transactions on Management Information Systems",
    "citation_count": 16,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424927"
  },
  {
    "source": "semantic_scholar",
    "source_id": "5a0e9ae236ba51b423dcde3cdb207d1b3568f206",
    "title": "Exploring prospects, hurdles, and road ahead for generative artificial intelligence in orthopedic education and training",
    "authors": [
      "Nikhil Gupta",
      "Kavin Khatri",
      "Yogender Malik",
      "Amit Lakhani",
      "Abhinav Kanwal",
      "Sameer Aggarwal",
      "A. Dahuja"
    ],
    "year": 2024,
    "abstract": "Generative Artificial Intelligence (AI), characterized by its ability to generate diverse forms of content including text, images, video and audio, has revolutionized many fields, including medical education. Generative AI leverages machine learning to create diverse content, enabling personalized learning, enhancing resource accessibility, and facilitating interactive case studies. This narrative review explores the integration of generative artificial intelligence (AI) into orthopedic education and training, highlighting its potential, current challenges, and future trajectory. A review of recent literature was conducted to evaluate the current applications, identify potential benefits, and outline limitations of integrating generative AI in orthopedic education. Key findings indicate that generative AI holds substantial promise in enhancing orthopedic training through its various applications such as providing real-time explanations, adaptive learning materials tailored to individual student\u2019s specific needs, and immersive virtual simulations. However, despite its potential, the integration of generative AI into orthopedic education faces significant issues such as accuracy, bias, inconsistent outputs, ethical and regulatory concerns and the critical need for human oversight. Although generative AI models such as ChatGPT and others have shown impressive capabilities, their current performance on orthopedic exams remains suboptimal, highlighting the need for further development to match the complexity of clinical reasoning and knowledge application. Future research should focus on addressing these challenges through ongoing research, optimizing generative AI models for medical content, exploring best practices for ethical AI usage, curriculum integration and evaluating the long-term impact of these technologies on learning outcomes. By expanding AI\u2019s knowledge base, refining its ability to interpret clinical images, and ensuring reliable, unbiased outputs, generative AI holds the potential to revolutionize orthopedic education. This work aims to provides a framework for incorporating generative AI into orthopedic curricula to create a more effective, engaging, and adaptive learning environment for future orthopedic practitioners.",
    "doi": "10.1186/s12909-024-06592-8",
    "url": "https://www.semanticscholar.org/paper/5a0e9ae236ba51b423dcde3cdb207d1b3568f206",
    "pdf_url": "https://doi.org/10.1186/s12909-024-06592-8",
    "venue": "BMC Medical Education",
    "citation_count": 19,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424931"
  },
  {
    "source": "semantic_scholar",
    "source_id": "c2400d09993319898ecec666f41d61dfa896b1d0",
    "title": "Revolutionizing Medical Practice: The Impact of Artificial Intelligence (AI) on Healthcare",
    "authors": [],
    "year": 2024,
    "abstract": "The twenty-first century has witnessed significant advancements in informatics, reshaping our understanding of data processing and accessibility. Artificial intelligence (AI), encompassing techniques such as machine learning (ML), deep learning (DP), and neural networks (NN), is poised to revolutionize medicine. AI holds the capability of analyzing vast amounts of data, extracting meaningful insights, and making accurate predictions, thereby empowering industries to make informed decisions, drive innovation, and enhance efficiency. The landscape of medical AI has evolved significantly, demonstrating expert-level disease detection from medical images and promising breakthroughs across various industries. AI revolutionizes medical practice by leveraging advanced algorithms and machine learning capabilities to improve diagnostics, treatment planning, and overall patient care. However, the deployment of medical AI systems in regular clinical practice still needs to be tapped, presenting complex ethical, technical, and human-centered challenges that must be addressed for successful implementation. While AI algorithms have shown efficacy in retrospective medical investigations, their translation into practical medical settings has been limited, raising concerns about their usability and interaction with healthcare professionals. Moreover, the representativeness of retrospective datasets in real-world medical practice is subject to filtering and cleaning biases. Integrating AI into clinical medicine holds great promise for transforming healthcare delivery, improving patient care, and revolutionizing aspects such as diagnosis, treatment planning, drug discovery, personalized treatment, and medical imaging. With advanced algorithms and machine learning capabilities, AI and robotics in Healthcare can analyze large volumes of medical data, extract meaningful insights, and provide accurate predictions, empowering healthcare professionals to make informed decisions and optimize resource allocation. The availability of extensive clinical, genomics, and digital imaging data, coupled with investments from healthcare institutions and technology giants, underscores the potential of AI in healthcare. This review article explores AI's powerful potential to revolutionize healthcare delivery across multiple domains, emphasizing the need to overcome challenges and harness its transformative capabilities in clinical practice.",
    "doi": "10.33140/oajast.02.01.07",
    "url": "https://www.semanticscholar.org/paper/c2400d09993319898ecec666f41d61dfa896b1d0",
    "pdf_url": "https://doi.org/10.33140/oajast.02.01.07",
    "venue": "Open Access Journal of Applied Science and Technology",
    "citation_count": 16,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424935"
  },
  {
    "source": "semantic_scholar",
    "source_id": "989fc6de20cc98117eaf21e607019ca3513832c2",
    "title": "Advancing AI Data Ethics in Nursing: Future Directions for Nursing Practice, Research, and Education",
    "authors": [
      "Patricia A Ball Dunlap",
      "Martin Michalowski"
    ],
    "year": 2024,
    "abstract": "Abstract The ethics of artificial intelligence (AI) are increasingly recognized due to concerns such as algorithmic bias, opacity, trust issues, data security, and fairness. Specifically, machine learning algorithms, central to AI technologies, are essential in striving for ethically sound systems that mimic human intelligence. These technologies rely heavily on data, which often remain obscured within complex systems and must be prioritized for ethical collection, processing, and usage. The significance of data ethics in achieving responsible AI was first highlighted in the broader context of health care and subsequently in nursing. This viewpoint explores the principles of data ethics, drawing on relevant frameworks and strategies identified through a formal literature review. These principles apply to real-world and synthetic data in AI and machine-learning contexts. Additionally, the data-centric AI paradigm is briefly examined, emphasizing its focus on data quality and the ethical development of AI solutions that integrate human-centered domain expertise. The ethical considerations specific to nursing are addressed, including 4 recommendations for future directions in nursing practice, research, and education and 2 hypothetical nurse-focused ethical case studies. The primary objectives are to position nurses to actively participate in AI and data ethics, thereby contributing to creating high-quality and relevant data for machine learning applications.",
    "doi": "10.2196/62678",
    "url": "https://www.semanticscholar.org/paper/989fc6de20cc98117eaf21e607019ca3513832c2",
    "pdf_url": "",
    "venue": "JMIR Nursing",
    "citation_count": 23,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424938"
  },
  {
    "source": "semantic_scholar",
    "source_id": "e2e78a9066a5e8082d78e1b0880838025b31a7cc",
    "title": "Artificial Intelligence and unintended bias: A call for responsible innovation",
    "authors": [
      "Dhruvitkumar V. Talati"
    ],
    "year": 2021,
    "abstract": "This essay discusses the intricate and multifaceted problem of algorithmic bias in artificial intelligence (AI) systems, and emphasizes its human rights, social, and ethical implications. As AI technologies become increasingly embedded in high-stakes areas of medicine, finance, employment, law enforcement, and social services, risks of discriminatory decision-making remain on the rise. Algorithmic bias may perpetuate existing social biases, adversely affect disadvantaged populations disproportionately, and perpetuate institutional discrimination, and thereby pose serious ethical issues.\nThe research endeavors to present an extensive comprehension of algorithmic bias through exploration of its cause, mechanism, and societal aspects. It exhaustively analyzes the presence of bias in AI systems, its cause-running from biased input data to defective algorithmic development, as well as the ethical aspects brought by having AI-based decisions influence real-world repercussions. In addition, the study analyzes material and immaterial effects of AI bias on persons and groups and aims at fairness, transparency, and accountability of AI in particular.\nIn its attempt to deal with these issues, this paper analyzes some measures to mitigate against bias, for instance, technical measures such as bias-aware algorithms, fairness-aware machine learning algorithms, and explainable AI methodologies. Furthermore, it speaks to normative and regulatory regimes that enable responsible AI deployment, as well as grass-roots strategies that enable affected communities to participate in AI stewardship. Through the use of the best of an interdisciplinary approach, the study integrates findings from peer-reviewed literature, international case studies, government policy, and industry standards to provide a comprehensive perspective on the issue.\nFinally, the paper emphasizes the need for active, multi-stakeholder responses that make sure AI technologies conform to basic human rights and moral principles. In incorporating technical, ethical, legal, and social considerations into AI, the research demands more inclusive and accountable AI system that maximizes fairness, minimizes disparities, and secures human dignity in the modern fast-changing world of artificial intelligence.",
    "doi": "10.30574/ijsra.2021.2.2.0110",
    "url": "https://www.semanticscholar.org/paper/e2e78a9066a5e8082d78e1b0880838025b31a7cc",
    "pdf_url": "",
    "venue": "International Journal of Science and Research Archive",
    "citation_count": 3,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424941"
  },
  {
    "source": "semantic_scholar",
    "source_id": "c187a6b6a31d7357f1e92d5f4a1bc7b6ca7542ae",
    "title": "Perceptions, Strategies, and Challenges of Teachers in the Integration of Artificial Intelligence in Primary Education: A Systematic Review",
    "authors": [
      "Olga Arranz Garcia",
      "Mar\u00eda del Carmen Romero Garc\u00eda",
      "Vidal Alonso-Secades"
    ],
    "year": 2025,
    "abstract": "Aim/Purpose: Evaluate teachers\u2019 perceptions, strategies, and challenges in integrating artificial intelligence (AI) into K-12 education and identify patterns and trends in the data from the reviewed studies.\n\nBackground: This systematic review examines a decade of innovation to explore the transformative impact of AI on education (2014\u20132024). Adhering to PRISMA 2020 guidelines, the study uncovers key trends, challenges, and breakthroughs in AI-driven teaching and learning, offering a comprehensive perspective on how AI reshapes educational practices and methodologies. \n\nMethodology: The study employs a systematic review to analyze the implementation of AI techniques and tools in primary education, following the PRISMA 2020 guidelines to ensure the reliability and effectiveness of the findings. To achieve this, an extensive search was conducted in academic databases such as Web of Science, Scopus, and ERIC, focusing on empirical studies and peer-reviewed articles published between 2014 and 2024. Only accessible, peer-reviewed articles classified under Education and Educational Research and published in English or Spanish were selected.\n\nThe search strategy was structured into five categories aligned with the research questions to identify relevant studies accurately. The selection process was carried out in three phases \u2013 Identification, Screening, and Inclusion \u2013 applying predefined criteria to guarantee the quality and relevance of the selected studies. Of an initial total of 514,919 articles, 488,940 were excluded for not meeting the inclusion criteria. After removing duplicates and evaluating titles, abstracts, and full texts, a final set of 28 studies was included.\n\n\nContribution: The study explores the integration of AI in primary education, revealing both teachers\u2019 enthusiasm and the challenges they face. While AI is perceived as a tool to enhance critical thinking, problem-solving, and student engagement, its implementation is limited by insufficient training, resources, and institutional support.\n\nDespite these obstacles, teachers show confidence in designing AI-integrated curricula, though this is weakened by inadequate infrastructure and technical support, highlighting the need for continuous professional development. The study also stresses the importance of establishing a competency framework for AI literacy and adopting a systemic approach to AI education.\n\nAdditionally, ensuring safe learning environments by addressing data privacy and AI biases remains a key challenge. Overcoming these issues is essential for the ethical and effective integration of AI, maximizing its benefits while safeguarding student equity and security.\n\n\nFindings: - Educators see the potential of AI to personalize learning.\n- Barriers are lack of training and resources for teachers.\n- Importance of continuous training in digital skills.\n- Need for policies that promote AI literacy.\n- Collaboration with experts to optimize AI in the classroom.\n\nRecommendations for Practitioners: Teachers are encouraged to collaborate in using AI tools to enhance educational outcomes, supported by continuous professional development programs, clear policies that safeguard privacy and promote equality, and a framework that preserves human autonomy in integrating AI technologies.\n\nRecommendation for Researchers: The lack of empirical research on AI interventions in education limits understanding of its true impact, highlighting the need for future studies to fill this gap and optimize its application for greater educational benefits.\n\nImpact on Society: The integration of AI in K-12 education is not just an opportunity; it is a necessity to prepare future generations for an increasingly digital world. While AI has the potential to revolutionize learning by fostering critical thinking, personalization, and engagement, its impact depends on how effectively it is implemented. To ensure its benefits, it is essential to empower educators and students with AI literacy, address issues like bias and data privacy, and establish robust legal frameworks for fair and transparent use. Without proactive policies, AI could widen educational inequalities instead of reducing them. A responsible, human-centered approach is needed to create an inclusive, ethical, and effective AI-powered education system.\n\nFuture Research: The article highlights the urgency of future empirical research to better understand the real impact of AI in education, as the lack of intervention studies limits its optimal application. Analyzing how AI influences learning outcomes, teaching dynamics, equity, and accessibility is essential, along with investigating the pedagogical competencies and technological conditions that affect its adoption. To this end, expanding the scope of studies is recommended by incorporating multicultural and multilingual perspectives, exploring AI applications across various disciplines and educational levels, and promoting interdisciplinary approaches that address ethical, social, and pedagogical dimensions.\n\n",
    "doi": "10.28945/5458",
    "url": "https://www.semanticscholar.org/paper/c187a6b6a31d7357f1e92d5f4a1bc7b6ca7542ae",
    "pdf_url": "",
    "venue": "J. Inf. Technol. Educ. Res.",
    "citation_count": 12,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424945"
  },
  {
    "source": "semantic_scholar",
    "source_id": "06931b57128240d8b859492a689064c6d453653b",
    "title": "Algorithmic Fairness in Recruitment: Designing AI-Powered Hiring Tools to Identify and Reduce Biases in Candidate Selection",
    "authors": [
      "C. Agbasiere",
      "Goodness Rex Nze-Igwe"
    ],
    "year": 2025,
    "abstract": "The study looks into how artificial intelligence (AI) affects hiring procedures, focusing on the fairness of the algorithms that drive these tools. AI has improved the efficiency of the hiring process, yet its use results in institutionalised discrimination. The AI systems used for recruitment, which base evaluations on past performance data, have the potential to discriminate against minority candidates as well as women through unintentional actions. The ability of AI systems to decrease human biases during recruitment encounters major challenges, as Amazon's discriminatory resume screening demonstrates the issues in systemic bias maintenance. This paper discusses the origins of algorithmic bias, including biased training records, defining labels, and choosing features, and suggests debiasing methods. Methods such as reweighting, adversarial debiasing, and fairness-aware algorithms are assessed for suitability in developing unbiased AI hiring systems. A quantitative approach is used in the research, web scraping data from extensive secondary sources to assess these biases and their mitigation measures. A Fair Machine Learning (FML) theoretical framework is utilised, which introduces fairness constraints into machine learning models so that hiring models do not perpetuate present discrimination. The ethical, legal, and organisational ramifications of using AI for recruitment are further examined under GDPR and Equal Employment Opportunity law provisions. By investigating HR practitioners' experiences and AI-based recruitment data, the study aims to develop guidelines for designing open, accountable, and equitable AI-based hiring processes. The findings emphasise the value of human oversight and the necessity of regular audits to guarantee equity in AI hiring software and, consequently, encourage diversity and equal opportunity during employment.",
    "doi": "10.22178/pos.116-10",
    "url": "https://www.semanticscholar.org/paper/06931b57128240d8b859492a689064c6d453653b",
    "pdf_url": "https://doi.org/10.22178/pos.116-10",
    "venue": "Path of Science",
    "citation_count": 2,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424949"
  },
  {
    "source": "semantic_scholar",
    "source_id": "3eae656fa8f9a658000c2e6bc8023f20533448fd",
    "title": "Guest editorial: Artificial intelligence and machine learning in business and management",
    "authors": [
      "Fouad Ben Abdelaziz",
      "H. Kunze",
      "Davide La Torre",
      "Bernard Sinclair-Desgagn\u00e9"
    ],
    "year": 2022,
    "abstract": "\ufb01 personalized sentiment and team human resource management, motivation, job design, training, knowledge management, leadership and business ethics. the for further insightful and useful inquiries.",
    "doi": "10.1108/jm2-08-2022-325",
    "url": "https://www.semanticscholar.org/paper/3eae656fa8f9a658000c2e6bc8023f20533448fd",
    "pdf_url": "https://doi.org/10.1108/jm2-08-2022-325",
    "venue": "Journal of Modelling in Management",
    "citation_count": 4,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424952"
  },
  {
    "source": "semantic_scholar",
    "source_id": "b39f1792e30bcb39b2363c7b30d4dde2c5515577",
    "title": "Reducing AI bias in recruitment and selection: an integrative grounded approach",
    "authors": [
      "M. Soleimani",
      "A. Intezari",
      "Jim Arrowsmith",
      "David Pauleen",
      "Naz\u0131m Ta\u015fk\u0131n"
    ],
    "year": 2025,
    "abstract": "Abstract Artificial Intelligence (AI) is transforming business domains such as operations, marketing, risk, and financial management. However, its integration into Human Resource Management (HRM) poses challenges, particularly in recruitment, where AI influences work dynamics and decision-making. This study, using a grounded theory approach, interviewed 39 HR professionals and AI developers to explore potential biases in AI-Recruitment Systems (AIRS) and identify mitigation techniques. Findings highlight a critical gap: the HR profession\u2019s need to embrace both technical skills and nuanced people-focused competencies to collaborate effectively with AI developers and drive informed discussions on the scope of AI\u2019s role in recruitment and selection. This research integrates Gibson\u2019s direct perception theory and Gregory\u2019s indirect perception theory, combining psychological, information systems, and HRM perspectives to offer insights into decision-making biases in AI. A framework is proposed to clarify decision-making biases and guide the development of robust protocols for AI in HR, with a focus on ethical oversight and regulatory needs. This research contributes to AI-based HR decision-making literature by exploring the intersection of cognitive bias and AI-augmented decisions in recruitment and selection. It offers practical insights for HR professionals and AI developers on how collaboration and perception can improve the fairness and effectiveness of AIRS-aided decisions.",
    "doi": "10.1080/09585192.2025.2480617",
    "url": "https://www.semanticscholar.org/paper/b39f1792e30bcb39b2363c7b30d4dde2c5515577",
    "pdf_url": "https://doi.org/10.1080/09585192.2025.2480617",
    "venue": "International journal of human resources management",
    "citation_count": 12,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424956"
  },
  {
    "source": "semantic_scholar",
    "source_id": "61ec76bfc24131088f264861e059fdd2acc49fe1",
    "title": "Evaluating and mitigating bias in AI-based medical text generation",
    "authors": [
      "Xiuying Chen",
      "Tairan Wang",
      "Juexiao Zhou",
      "Zirui Song",
      "Xin Gao",
      "Xiangliang Zhang"
    ],
    "year": 2025,
    "abstract": "Artificial intelligence (AI) systems, particularly those based on deep learning models, have increasingly achieved expert-level performance in medical applications. However, there is growing concern that such AI systems may reflect and amplify human bias, reducing the quality of their performance in historically underserved populations. The fairness issue has attracted considerable research interest in the medical imaging classification field, yet it remains understudied in the text-generation domain. In this study, we investigate the fairness problem in text generation within the medical field and observe substantial performance discrepancies across different races, sexes and age groups, including intersectional groups, various model scales and different evaluation metrics. To mitigate this fairness issue, we propose an algorithm that selectively optimizes those underserved groups to reduce bias. Our evaluations across multiple backbones, datasets and modalities demonstrate that our proposed algorithm enhances fairness in text generation without compromising overall performance. This study evaluates bias in AI-generated medical text, revealing disparities across race, sex and age. An optimization method is proposed to enhance fairness without compromising performance, offering a step toward more equitable AI in healthcare.",
    "doi": "10.1038/s43588-025-00789-7",
    "url": "https://www.semanticscholar.org/paper/61ec76bfc24131088f264861e059fdd2acc49fe1",
    "pdf_url": "",
    "venue": "Nature Computational Science",
    "citation_count": 10,
    "fields_of_study": [
      "Computer Science",
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424960"
  },
  {
    "source": "semantic_scholar",
    "source_id": "50bee65826dacb9604d8008327d67ac8637c4a4a",
    "title": "The Impact of Artificial Intelligence on Health Equity in Oncology: A Scoping Review",
    "authors": [
      "Paul Istasy",
      "Wen Shen Lee",
      "Alla Iansavitchene",
      "Ross E. G. Upshur",
      "B. Sadikovic",
      "A. Lazo-Langner",
      "B. Chin\u2010Yee"
    ],
    "year": 2021,
    "abstract": "\n Introduction: The expanding use of Artificial Intelligence (AI) in hematology and oncology research and practice creates an urgent need to consider the potential impact of these technologies on health equity at both local and global levels. Fairness and equity are issues of growing concern in AI ethics, raising problems ranging from bias in datasets and algorithms to disparities in access to technology. The impact of AI on health equity in oncology, however, remains underexplored. We conducted a scoping review to characterize, evaluate, and identify gaps in the existing literature on AI applications in oncology and their implications for health equity in cancer care.\n Methodology: We performed a systematic literature search of MEDLINE (Ovid) and EMBASE from January 1, 2000 to March 28, 2021 using key terms for AI, health equity, and cancer. Our search was restricted to English language abstracts with no restrictions by publication type. Two reviewers screened a total of 9519 abstracts, and 321 met inclusion criteria for full-text review. 247 were included in the final analysis after assessment by three reviewers. Studies were analysed descriptively, by location, type of cancer and AI application, as well as thematically, based on issues pertaining to health equity in oncology.\n Results: Of the 247 studies included in our analysis, 150 (60.7%) were based in North America, 57 (23.0%) in Asia, 29 (11.7%) in Europe, 5 (2.1%) in Central/South America, 4 (1.6%) in Oceania, and 2 (0.9%) in Africa. 71 (28.6%) were reviews and commentaries, and 176 were (71.3%) clinical studies. 25 (10.1%) focused on AI applications in screening, 42 (17.0%) in diagnostics, 46 (18.6%) in prognostication, and 7 (2.9%) in treatment. 40 (16.3%) used AI as a tool for clinical/epidemiological research and 87 (35.2%) discussed multiple applications of AI. A diverse range of cancers were represented in the studies, including hematologic malignancies. Our scoping review identified three overarching themes in the literature, which largely focused on how AI might improve health equity in oncology. These included: (1) the potential for AI reduce disparities by improving access to health services in resource-limited settings through applications such as low-cost cancer screening technologies and decision support systems; (2) the ability of AI to mitigate bias in clinical decision-making through algorithms that alert clinicians to potential sources of bias thereby allowing for more equitable and individualized care; (3) the use of AI as a research tool to identify disparities in cancer outcomes based on factors such as race, gender and socioeconomic status, and thus inform health policy. While most of the literature emphasized the positive impact of AI in oncology, there was only limited discussion of AI's potential adverse effects on health equity . Despite engaging with the use of AI in resource-limited settings, ethical issues surrounding data extraction and AI trials in low-resource settings were infrequently raised. Similarly, AI's potential to reinforce bias and widen disparities in cancer care was under-examined despite engagement with related topics of bias in clinical decision-making.\n Conclusion: The overwhelming majority of the literature identified by our scoping review highlights the benefits of AI applications in oncology, including its potential to improve access to care in low-resource settings, mitigate bias in clinical decision-making, and identify disparities in cancer outcomes. However, AI's potential negative impacts on health equity in oncology remain underexplored: ethical issues arising from deploying AI technologies in low-resources settings, and issues of bias in datasets and algorithms were infrequently discussed in articles dealing with related themes.\n \n \n No relevant conflicts of interest to declare.\n",
    "doi": "10.1182/blood-2021-149264",
    "url": "https://www.semanticscholar.org/paper/50bee65826dacb9604d8008327d67ac8637c4a4a",
    "pdf_url": "https://doi.org/10.1182/blood-2021-149264",
    "venue": "Blood",
    "citation_count": 11,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424963"
  },
  {
    "source": "semantic_scholar",
    "source_id": "fa56200090dc8db644461759075cf473c6c0d8b0",
    "title": "The Role of Artificial Intelligence in Recruitment Process Decision-Making",
    "authors": [
      "A. Al-Alawi",
      "Misbah Naureen",
      "Ebtesam Ismaeel AlAlawi",
      "Ahmed Abdulla Naser Al-Hadad"
    ],
    "year": 2021,
    "abstract": "Artificial Intelligence (AI) can playa pivotal role in the firm's recruiting process, facilitating excellence. This study investigates the challenges AI faces in the hiring process and the outcomes/ results of using AI in the hiring process. The benefits of using AI in the hiring process include identifying AI vendors and firms that have adopted AI in the hiring process, analyzing the present state of AI to facilitate the hiring process, and the impact of adopting AI in the hiring process. Through this study, different perceptions, theories, ideas, and opinions are presented to modulate the use of AI in human resource management utilizing papers from 1988 to 2020. The findings indicate that AI is adopted mainly in high-tech or large companies. The reports presented by these companies on the use of AI thus do not provide an actual picture of the usage and step by step evaluation as interviews are still a part of the recruitment process providing space for human bias. Future research may include aligning the AI with the mission and vision of the company and the rules and regulations of the country that they have been adopted. The aspect of AI to support human resources in decision making, not a threat as AI is considered to take over the human roles in human resource management, should also be studied in detail.",
    "doi": "10.1109/DASA53625.2021.9682320",
    "url": "https://www.semanticscholar.org/paper/fa56200090dc8db644461759075cf473c6c0d8b0",
    "pdf_url": "",
    "venue": "2021 International Conference on Decision Aid Sciences and Application (DASA)",
    "citation_count": 27,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424967"
  },
  {
    "source": "semantic_scholar",
    "source_id": "9cf847bebe4df29a0ecbb66d2ad55641be51bc1d",
    "title": "AI-ENABLED INTERVIEW ANALYSIS: UNVEILING INSIGHTS AND ENHANCING DECISION-MAKING IN HUMAN RESOURCE MANAGEMENT",
    "authors": [
      "Rajneesh Panwar"
    ],
    "year": 2023,
    "abstract": "The process of conducting interviews plays a pivotal role in human resource management, as it directly influences the selection of candidates and ultimately shapes the composition of an organization's workforce. However, traditional interview methods are often subjective and prone to biases, leading to suboptimal decision-making. In recent years, the emergence of artificial intelligence (AI) technologies has provided new opportunities to revolutionize interview analysis and improve decision-making in the hiring process.This research paper explores the application of AI-enabled interview analysis in human resource management, aiming to unveil insights and enhance decision-making. The study focuses on three main areas: interview data collection, analysis, and decision-making support. AI technologies, including natural language processing (NLP) and machine learning algorithms, are leveraged to analyze interview transcripts, audio recordings, and other relevant data sources.By analyzing interview data using AI, this research uncovers hidden patterns, linguistic cues, and behavioural indicators that may be missed by human interviewers. These insights provide a deeper understanding of candidate suitability, skills, and competencies, enabling HR professionals to make more informed and objective decisions. Moreover, AI algorithms can be trained to identify biases and mitigate their impact, leading to fairer and more inclusive hiring practices. The research also investigates the potential challenges and ethical considerations associated with AI- enabled interview analysis. Concerns related to privacy, data security, algorithmic biases, and the role of human judgment in decision-making are examined, highlighting the need for responsible implementation and ongoing monitoring.To validate the effectiveness of AI-enabled interview analysis, a mixed-methods approach is employed, combining quantitative data analysis and qualitative feedback from HR professionals. The study presents empirical evidence demonstrating the benefits of AI technologies in improving decision-making accuracy, efficiency, and fairness. Key Index Terms: Digital AI-enabled interview analysis, Hiring process, Decision-making, Interview data analysis, Natural language processing (NLP), Machine learning algorithms, Candidate selection, Workforce composition, Objective decision-making, Hidden patterns, Linguistic cues.",
    "doi": "10.55041/ijsrem24357",
    "url": "https://www.semanticscholar.org/paper/9cf847bebe4df29a0ecbb66d2ad55641be51bc1d",
    "pdf_url": "https://ijsrem.com/download/ai-enabled-interview-analysis-unveiling-insights-and-enhancing-decision-making-in-human-resource-management/?wpdmdl=22150&refresh=65645571a76171701074289",
    "venue": "INTERANTIONAL JOURNAL OF SCIENTIFIC RESEARCH IN ENGINEERING AND MANAGEMENT",
    "citation_count": 2,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424970"
  },
  {
    "source": "semantic_scholar",
    "source_id": "243288f6e1040bd45c539010754d0eb21a231642",
    "title": "The Impact of Big Data and Artificial Intelligence (AI) in the Insurance Sector",
    "authors": [],
    "year": 2020,
    "abstract": "The other guideline comes from the European Commission\u2019s Independent High-Level Expert Group on Artificial Intelligence (HLAG AI), Ethics Guidelines for Trustworthy AI (High-Level Expert Group on Artificial Intelligence, 2019 [39] ). The assessment list included in the Guidelines is undergoing a pilot phase. The HLEG AI\u2019s Guidelines are more focussed on ethics related issues, and due to this is more specific on the nature of AI and how it should be developed. It is in fact derived from four ethical principles, which are rooted in fundamental rights: respect for human autonomy, prevention of harm, fairness and explicability (High-Level Expert Group on Artificial Intelligence, 2019 [39] ).",
    "doi": "10.1787/c822ee53-en",
    "url": "https://www.semanticscholar.org/paper/243288f6e1040bd45c539010754d0eb21a231642",
    "pdf_url": "",
    "venue": "",
    "citation_count": 34,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424974"
  },
  {
    "source": "semantic_scholar",
    "source_id": "1c3a17f0729e3a37c876a54493f3d9a202a62cec",
    "title": "Dataset-centric AI ethics classification",
    "authors": [
      "Aditya Kartik",
      "Surya Raj",
      "Akash Rattan",
      "Deepti Sahu"
    ],
    "year": 2025,
    "abstract": null,
    "doi": "10.1007/s43681-025-00904-4",
    "url": "https://www.semanticscholar.org/paper/1c3a17f0729e3a37c876a54493f3d9a202a62cec",
    "pdf_url": "",
    "venue": "AI and Ethics",
    "citation_count": 0,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424984"
  },
  {
    "source": "semantic_scholar",
    "source_id": "f3d70d31b306ccb32564efde379701be7f43e12e",
    "title": "How to Make an Artificial Intelligence Algorithm \u201cEcological\u201d? Insights from a holistic perspective",
    "authors": [
      "Tania Di Mascio",
      "Federica Caruso",
      "Sara Peretti"
    ],
    "year": 2023,
    "abstract": "Nowadays, Artificial Intelligence is growing in many daily activities. On the one hand, it has many positive effects and produces social benefits. On the other hand, its development and deployment raise issues related to biases, such as gender, disability, and culture. Moreover, Artificial Intelligence\u2019s growing autonomy in decision-making could lead to decisions that conflict with human values or harm individuals and society. These issues stem from biased or incomplete datasets and a lack of transparency and accountability in the algorithms. Consequently, paying increasing attention to the ongoing discourse on Artificial Intelligence ethics: its autonomy in decision-making, and biases is necessary. A human-centric approach is a minimum requirement for designing algorithms since this approach is aligned with human values, dignity, and goals. Notwithstanding, its application does not guarantee a deep understanding of the context of use. According to recent theoretical perspectives, a deep interpretation of the context of use (i.e., a holistic perspective) could better regulate ethical aspects. This paper goes in this direction, presenting a human-centric and ecological approach as a design methodology. It has been experienced within Use Case 6 of the European FRACTAL project, which aims to develop intelligent totems for advertising and customer assistance in sentient shopping malls. The intelligence is realized by several artificial intelligent algorithms (e.g., gender recognition algorithms). By adopting Bronfenbrenner\u2019s ecological approach, algorithms were made free from gender bias, mirroring the context of men\u2019s and women\u2019s use at shopping malls as it is currently, i.e., characterized by gender balance. This proposal contributes to the ongoing discourse on Artificial Intelligence ethics and the development of its ethical algorithms.",
    "doi": "10.1145/3605390.3605398",
    "url": "https://www.semanticscholar.org/paper/f3d70d31b306ccb32564efde379701be7f43e12e",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3605390.3605398",
    "venue": "ACM SIGCHI Italian Chapter International Conference on Computer-Human Interaction",
    "citation_count": 2,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424988"
  },
  {
    "source": "semantic_scholar",
    "source_id": "e7571ee537d3aa0906737666affc24b81583931e",
    "title": "Algorithmic Human Resource Management: Characteristics, Possibilities and Challenges",
    "authors": [
      "Goran Pavlovi\u0107"
    ],
    "year": 2023,
    "abstract": "In the field of human resources, algorithmic management refers to the utilization of digital technology, artificial intelligence, and big data to de\u00advelop rules and procedures that enable the automated management of hu\u00adman resources. Algorithmic human resource management can potentially re\u00adplace human resource managers in all stages and activities of staffing, there\u00adby significantly expediting the management process and enhancing cost-ef\u00adfectiveness. Through the use of artificial intelligence, algorithms develop pat\u00adterns and models from which they can autonomously learn and improve the quality of decision-making in employee management. However, relying ex\u00adclusively on algorithmic human resource management can lead to the emer\u00adgence of discriminatory management practices, particularly when the algo\u00adrithms are based on unrepresentative or biased data. Considering these fac\u00adtors, this paper aims to examine the fundamental characteristics, princi\u00adples, application possibilities, and challenges of algorithmic human resource management.",
    "doi": "10.31410/eraz.s.p.2023.147",
    "url": "https://www.semanticscholar.org/paper/e7571ee537d3aa0906737666affc24b81583931e",
    "pdf_url": "https://doi.org/10.31410/eraz.s.p.2023.147",
    "venue": "ERAZ Conference \u2013 Knowlegde Based Sustainable Development: Vol 9. Selected Papers",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.425015"
  },
  {
    "source": "semantic_scholar",
    "source_id": "1cb8f64757de8dd6a608271890a754a12fccb1ff",
    "title": "Legal and ethical principles governing the use of artificial intelligence in radiology services in South Africa",
    "authors": [
      "Irvine Sihlahla",
      "D. Donnelly",
      "B. Townsend",
      "D. Thaldar"
    ],
    "year": 2023,
    "abstract": "Abstract Artificial intelligence (AI) will drastically change the healthcare system. Radiology is one speciality that is most affected as AI algorithms are increasingly used in diagnostic imaging. AI\u2010enhanced health technologies will, inter alia, increase workflow efficiency, improve diagnostic accuracy, reduce healthcare\u2010related costs, and help alleviate medical personnel shortages in under\u2010resourced settings. However, the development of AI\u2010enhanced technologies in healthcare is fraught with legal, ethical, and human rights concerns. Currently, the use of AI in South African healthcare is not governed by sui generis legislation or ethical guidance focused exclusively and specifically on AI, although various provisions and principles from law and ethics find application. This article outlines these normative principles and explains their relationship with the extant legal obligations and regulatory framework as applied to the use of AI in radiology services in South Africa. The article concludes with three key recommendations for radiology practitioners using AI in South Africa. These are the need for: vigilant monitoring of AI use in practice, reforms to the liability framework, and appropriate guidance from local regulators and the Health Professions Council of South Africa on the ethical use of AI.",
    "doi": "10.1111/dewb.12436",
    "url": "https://www.semanticscholar.org/paper/1cb8f64757de8dd6a608271890a754a12fccb1ff",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/dewb.12436",
    "venue": "Developing World Bioethics",
    "citation_count": 10,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:02.425019"
  },
  {
    "source": "semantic_scholar",
    "source_id": "ce57a21482fb66664fe89420d5396c2a13c704f3",
    "title": "A theoretical model of AI bias mitigation: incentives, regulation and equilibrium",
    "authors": [
      "Subhasis Bera",
      "Ishita Bera"
    ],
    "year": 2025,
    "abstract": "\n \n This study aims to develop a conceptual economic model to analyse bias in artificial intelligence (AI), decomposing it into functionality bias (arising from data and algorithms) and usage bias (stemming from user incentives). It explores how these biases interact and emerge endogenously in economic systems, proposing a cost-constrained optimisation framework for mitigation.\n \n \n \n A mathematical optimisation model is formulated to minimise total bias, accounting for data curation costs, regulatory penalties and audit expenses. The model derives equilibrium conditions under which bias mitigation is cost-effective and identifies thresholds beyond which interventions fail.\n \n \n \n Reducing usage bias enhances the effectiveness of functionality bias mitigation, creating a cascading fairness effect. High regulatory costs without incentive alignment can discourage mitigation, emphasising the need for balanced interventions. The model highlights the cost-fairness trade-offs and suggests critical thresholds for policy action.\n \n \n \n The theoretical conceptual model is static; future work should explore dynamic extensions and conduct empirical validation to enhance its applicability. Nonetheless, it provides a quantitative foundation linking AI ethics with economic policymaking.\n \n \n \n Firms and policymakers can use the conceptual model to evaluate cost-efficient strategies for mitigating bias, particularly through early-stage interventions and the design of usage incentives.\n \n \n \n The study emphasises the importance of fairness in AI as both a technical and socioeconomic objective, essential for achieving equitable outcomes in areas such as finance, employment and public services.\n \n \n \n Unlike prior approaches that treat fairness as exogenous, this study endogenises bias within an economic decision framework, presenting a novel lens to address AI fairness as a constrained optimisation problem.\n",
    "doi": "10.1108/jices-06-2025-0138",
    "url": "https://www.semanticscholar.org/paper/ce57a21482fb66664fe89420d5396c2a13c704f3",
    "pdf_url": "",
    "venue": "Journal of Information, Communication and Ethics in Society",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.425023"
  },
  {
    "source": "semantic_scholar",
    "source_id": "7022dabf81143d3cb6e2eb538373694870400c28",
    "title": "Impact of Artificial Intelligence on Decision-making in Organisations",
    "authors": [
      "Chandana Charitha",
      "B. Hemaraju"
    ],
    "year": 2023,
    "abstract": "The use of artificial intelligence (AI) in decision-making processes has emerged as a key organizational development driver in the modern, dynamic commercial environment. This case study investigates the broad implications, difficulties, and transformative possibilities of intelligence in corporate decision-making.\nWe discover how applying data analysis, pattern recognition, and artificial intelligence can increase decision-making and accuracy using an integrated strategy. Real-world examples from a variety of industries demonstrate how AI-driven decision-making can boost productivity, lower risk, and encourage innovation.\nHowever, as businesses use AI to its full potential, ethical issues become more crucial.\nThese days, factors including algorithmic bias, data privacy worries, and the demand for human attention must be carefully considered. This paper discusses this intricacy and emphasizes the significance of integrating ethical AI.\ngot an endorsement from 250 workers utilizing a Google Docs study paper. The results illustrated the advantages and difficulties experienced by professionals directly involved in AI-driven decision-making.\nFinally, this study shows how AI has advanced beyond efficiency to develop models for business decision-making.\nOrganizations may overcome obstacles and maximize their potential to advance to a time when AI and people will share a common intelligence in decision-making by understanding the function and ethics of AI.",
    "doi": "10.36948/ijfmr.2023.v05i04.5172",
    "url": "https://www.semanticscholar.org/paper/7022dabf81143d3cb6e2eb538373694870400c28",
    "pdf_url": "https://www.ijfmr.com/papers/2023/4/5172.pdf",
    "venue": "International Journal For Multidisciplinary Research",
    "citation_count": 8,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.425026"
  },
  {
    "source": "semantic_scholar",
    "source_id": "e463c3f4c0a60de71bb1791f1877cfc81cf1dfb6",
    "title": "Artificial Intelligence and the Rule of Law",
    "authors": [
      "Aziz Z Huq"
    ],
    "year": 2021,
    "abstract": "This book chapter examines an interaction between technological shocks and the \u201crule of law.\u201d It does so by analyzing the implications of a class of loosely related computational technologies termed \u201cmachine learning\u201d (ML) or, rather less precisely \u201cartificial intelligence\u201d (AI). These tools are presently employed in the pre-adjudicative phase of enforcing of the laws, for example facilitating the selection of targets for tax and regulatory investigations. \n \nTwo general questions respecting the rule of law arise from these developments. The more immediately apparent one is whether these technologies, when integrated into the legal system, are themselves compatible or in conflict with the rule of law. Depending on which conception of the rule of law is deployed, the substitution of machine decision-making for human judgment can kindle objections based on transparency, predictability, bias, and procedural fairness. A first purpose of this chapter is to examine ways in which this technological shock poses such challenges. The interaction between the normative ambitions of the rule of law and ML technologies, I will suggest, is complex and ambiguous. In many cases, moreover, the more powerful normative objection to technology arises less from the bare fact of its objection, and more from the socio-political context in which that adoption occurred and the dynamic effect of technology on background disparities of power and resources. ML\u2019s adoption likely exacerbates differences of social power and status in ways that place the rule of law under strain. \n \nThe second question posed by new AI and ML technologies has also not been extensively discussed. Yet it is perhaps of more profound significance. Rather than focusing on the compliance of new technologies with rule-of-law values, it hinges on the implications of ML and AI technologies for how the rule of law itself is conceived or implemented. Many of the canonical discussions of the rule of law\u2014including Dicey\u2019s and Waldron\u2019s\u2014entangle a conceptual definition and a series of institutional entailments. Many assume that the rule of law requires the specific institutional form of courts. They presumably also posit human judges exercising discretion and making judgments as necessary rather than optional. For these institutional entailments of the rule of law, a substitution of human for ML technologies likely has destabilizing implications. It sharpens the question whether the abstract concept of the rule of law needs to be realized by a particular institutional form. It raises a question whether instead technological change might demand amendments to relationship between the concept(s) and the practice of the rule of law. For pre-existing normative concepts and their practical, institutional correlates may no longer hold under conditions of technological change. At the very least then, specification of institutional forms of the rule of law under such conditions raises challenges not just as a practical matter but also in terms of legal theory",
    "doi": "10.2139/SSRN.3794777",
    "url": "https://www.semanticscholar.org/paper/e463c3f4c0a60de71bb1791f1877cfc81cf1dfb6",
    "pdf_url": "https://chicagounbound.uchicago.edu/cgi/viewcontent.cgi?article=2194&context=public_law_and_legal_theory",
    "venue": "Social Science Research Network",
    "citation_count": 15,
    "fields_of_study": [
      "Economics"
    ],
    "retrieved_at": "2026-02-02T16:58:02.425030"
  },
  {
    "source": "semantic_scholar",
    "source_id": "5049ef4ba5d8c373580f3f9cb5f3bbc725d617a6",
    "title": "A Vision for Digitizing Judicial Processes and Integrating Artificial Intelligence in Pakistan\u2019s Judiciary: Enhancing Efficiency and Upholding Judicial Integrity",
    "authors": [
      "Faiza Khalil"
    ],
    "year": 2024,
    "abstract": "The judiciary, as the cornerstone of justice and the rule of law, is at a pivotal juncture to harness the transformative power of digital technology and artificial intelligence (AI) to enhance its operations. This essay outlines a comprehensive approach for digitizing judicial processes in Pakistan, incorporating AI integration by drawing parallels with successful international model. The focus is on the need for systemic change to ensure efficiency, transparency, and accessibility in the legal system. Current challenges include a lack of proper implementation of the rule of law, prolonged trials, and low public confidence. Traditional methods of case filing are manual and paper-based, leading to inefficiencies. The essay proposes a step-by-step transformation starting from e-filing to the digitization of the entire lifecycle of a case, aiming to modernize Pakistan\u2019s judiciary. AI can aid in legal research, evidence standards, and sentencing, offering predictive capabilities and streamlining routine case management. Ethical considerations and the need for human judicial discretion are emphasized to balance AI\u2019s assistance with maintaining judicial integrity and fairness. This digital transformation can restore public trust and efficiency in Pakistan\u2019s judiciary, paving the way for a modern, digital legal system. Keywords: Technological Integration in Courts, Predictive Analytics in Law, Transparency in Judicial Processes, Judicial Modernization, Artificial Intelligence in Judiciary, Digital transformation, AI and Legal Ethics, Case Management Systems, E-Filing, Legal Tech Innovation, AI in Legal Research, Efficiency in Judiciary, AI and Evidence Standards, AI in Sentencing, Legal Information Systems",
    "doi": "10.55574/rzhl8875",
    "url": "https://www.semanticscholar.org/paper/5049ef4ba5d8c373580f3f9cb5f3bbc725d617a6",
    "pdf_url": "",
    "venue": "International Journal of Law, Ethics, and Technology",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.425033"
  },
  {
    "source": "semantic_scholar",
    "source_id": "970069616c73a86c10b328c04a43644132cad22f",
    "title": "We\u2019re Missing a Moral Framework of Justice in Artificial Intelligence",
    "authors": [
      "Matthew Le Bui",
      "S. Noble"
    ],
    "year": 2020,
    "abstract": "This chapter assesses the concepts of fairness and bias in artificial intelligence research and interventions. In considering the explosive growth, emergence of, and investment in high-profile AI fairness and ethics interventions within both the academy and industry\u2014alongside the mounting and proliferating calls for the interrogation, regulation, and, in some cases, dismantling and prohibition of AI\u2014it contests and questions the extent to which such remedies can address the original concerns and problems they are designed to address. Indeed, many community organizations are organizing responses and challenging AI used in predictive technologies\u2014facial-recognition software and biometrics technologies\u2014with increasing success. Ultimately, the canon of AI ethics must interrogate and deeply engage with intersectional power structures that work to further consolidate capital in the hands of the elites and that will undergird digital informational systems of inequality: there is no neutral or objective state through which the flows and mechanics of data can be articulated as unbiased or fair.",
    "doi": "10.1093/oxfordhb/9780190067397.013.9",
    "url": "https://www.semanticscholar.org/paper/970069616c73a86c10b328c04a43644132cad22f",
    "pdf_url": "",
    "venue": "",
    "citation_count": 41,
    "fields_of_study": [
      "Sociology"
    ],
    "retrieved_at": "2026-02-02T16:58:02.425037"
  },
  {
    "source": "semantic_scholar",
    "source_id": "ebcc6034b8b561964b5a047dd4bee1483047d6e7",
    "title": "ARTIFICIAL INTELLIGENCE AND THE RULE OF LAW: A CRITICAL APPRAISAL OF A DEVELOPING SECTOR",
    "authors": [
      "Syed Hassan Gilani",
      "Nabila Rauf",
      "Shehla Zahoor"
    ],
    "year": 2023,
    "abstract": "Artificial intelligence has become increasingly prevalent in our daily lives and has the potential to transform many areas of society, including the legal system. While AI has the potential to support the rule of law, it also poses significant challenges and risks, particularly around bias and discrimination. To ensure that AI is compatible with the rule of law, it is essential to take a holistic and interdisciplinary approach that considers the legal, ethical, social, and technical dimensions of AI. This involves designing and using AI systems in a way that is transparent, accountable, fair, and compliant with the law, as well as engaging with diverse stakeholders. Ensuring that AI is compatible with the rule of law is critical for promoting the values of justice, equality, and human rights in the digital age and for building a more just and equitable society. Keywords: Rule of Law, Artificial intelligence, Law enforcement.",
    "doi": "10.52567/pjsr.v5i02.1156",
    "url": "https://www.semanticscholar.org/paper/ebcc6034b8b561964b5a047dd4bee1483047d6e7",
    "pdf_url": "https://ojs.pjsr.com.pk/index.php/PJSR/article/download/1156/805",
    "venue": "Pakistan Journal of Social Research",
    "citation_count": 4,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.425041"
  },
  {
    "source": "semantic_scholar",
    "source_id": "c2e910f50e22be234152f633a94a11c7e93f8f89",
    "title": "Legal aspects of artificial intelligence in the employment process",
    "authors": [
      "Helga \u0160padina"
    ],
    "year": 2023,
    "abstract": "The introduction of artificial intelligence in all domains of life is the most transformative process in recent history. It is also a highly dynamic process, and due to the pace of technological development, a very limited legal framework is available to address issues of human rights, ethics, transparency, privacy, safety and accountability. During the last few years, artificial intelligence started to reshape employment processes. Positive aspects of the introduction of AI in the employment process are efficiency and quality in job matching, digitalisation and acceleration of the process, ability to process large data and match job seekers to available vacancy announcements, the alleviation of administrative burdens of employees of employment agencies and giving them strategic and innovative roles. All these are indispensable in present times when demographic challenges in European countries are leading to increased labour migrations and require changes in the recruitment process. The paper explores the current challenges of AI, i.e. how to achieve human-centred values and fairness of AI use during the employment process, preventing algorithmic bias and discriminatory application of AI tools. In order to harness the maximum benefits of AI, we need to develop a regulatory framework that would be enforceable, inclusive and adaptive (OECD), particularly knowing that most AI solutions are privately owned and developed for commercial purposes.\u00a0\u00a0\u00a0",
    "doi": "10.59954/stnv.546",
    "url": "https://www.semanticscholar.org/paper/c2e910f50e22be234152f633a94a11c7e93f8f89",
    "pdf_url": "https://stnv.idn.org.rs/STNV/article/download/546/518",
    "venue": "Stanovni\u0161tvo",
    "citation_count": 4,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.425044"
  },
  {
    "source": "semantic_scholar",
    "source_id": "746dd0ed2004e8ac6d7084e1e671eccefec3fb85",
    "title": "Evaluating the prospects for university-based ethical governance in artificial intelligence and data-driven innovation",
    "authors": [
      "C. Hine"
    ],
    "year": 2021,
    "abstract": "There has been considerable debate around the ethical issues raised by data-driven technologies such as artificial intelligence. Ethical principles for the field have focused on the need to ensure that such technologies are used for good rather than harm, that they enshrine principles of social justice and fairness, that they protect privacy, respect human autonomy and are open to scrutiny. While development of such principles is well advanced, there is as yet little consensus on the mechanisms appropriate for ethical governance in this field. This paper examines the prospects for the university ethics committee to undertake effective review of research conducted on data-driven technologies in the university context. Challenges identified include: the relatively narrow focus of university-based ethical review on the human subjects research process and lack of capacity to anticipate downstream impacts; the difficulties of accommodating the complex interplay of academic and commercial interests in the field; and the need to ensure appropriate expertise from both specialists and lay voices. Overall, the challenges identified sharpen appreciation of the need to encourage a joined-up and effective system of ethical governance that fosters an ethical culture rather than replacing ethical reflection with bureaucracy.",
    "doi": "10.1177/17470161211022790",
    "url": "https://www.semanticscholar.org/paper/746dd0ed2004e8ac6d7084e1e671eccefec3fb85",
    "pdf_url": "https://journals.sagepub.com/doi/pdf/10.1177/17470161211022790",
    "venue": "Research Ethics",
    "citation_count": 13,
    "fields_of_study": [
      "Political Science"
    ],
    "retrieved_at": "2026-02-02T16:58:02.425048"
  },
  {
    "source": "semantic_scholar",
    "source_id": "bbdad642a48f66f3216a79987c385d5daf2de95e",
    "title": "Ethical Implications of Artificial Intelligence in the Healthcare Sector",
    "authors": [
      "Nutifafa Cudjoe Amedior"
    ],
    "year": 2023,
    "abstract": "This research paper examines the ethical implications of AI in healthcare, covering the benefits and risks of using AI in healthcare services and provision. The paper highlights the applications of AI in healthcare, which can improve efficiency and accuracy of providing healthcare services by health professionals. The benefits of AI cover reducing the need for human intervention and increasing productivity through automation, delivering personalised experiences by recommendations, assisting with informed decision-making by providing real-time data analysis and insights, predicting outcomes or identifying potential threats, improving healthcare and overall customer satisfaction. The paper highlights the ethical implications of the use of AI in healthcare, including privacy and security, bias and discrimination, transparency and explainability, responsibility and accountability, informed consent and human interaction and empathy. The paper recommends that as AI becomes more prevalent in healthcare, establishing clear guidelines for responsible use, and maintaining the importance of human interaction and empathy in patient care, enhances healthcare outcomes while safeguarding patient rights and welfare. Continued research and development of the ethical implications of AI in healthcare for low-income countries as further work can promote the ethical use of AI in healthcare worldwide. Keywords: Artificial Intelligence, Ethics, Ethical Implication, Healthcare, Privacy Proceedings Citation Format Amedior, N.C. Nutifafa Cudjoe Amedior (2022): Ethical Implications of Artificial Intelligence in the Healthcare Sector. Proceedings of the 36th iSTEAMS Accra Bespoke Multidisciplinary Innovations Conference. University of Ghana/Academic City University College, Accra, Ghana. 31st May \u2013 2nd June, 2023. Pp 1-12 www.isteams.net/ecowasetech2022. dx.doi.org/10.22624/AIMS-/ACCRABESPOKE2023P1",
    "doi": "10.22624/aims-/accrabespoke2023p1",
    "url": "https://www.semanticscholar.org/paper/bbdad642a48f66f3216a79987c385d5daf2de95e",
    "pdf_url": "",
    "venue": "Advances in Multidisciplinary & Scientific Research Journal Publication",
    "citation_count": 16,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586654"
  },
  {
    "source": "semantic_scholar",
    "source_id": "d1d7e2acf6f1ee6054b02f0aafbe17dd076b9032",
    "title": "Artificial intelligence for diagnosing exudative age-related macular degeneration.",
    "authors": [
      "Chae-Yeong Kang",
      "John C. Lin",
      "Helen Zhang",
      "I. Scott",
      "Jayashree Kalpathy-Cramer",
      "Su-Hsun Liu",
      "P. Greenberg"
    ],
    "year": 2024,
    "abstract": "BACKGROUND\nAge-related macular degeneration (AMD) is a retinal disorder characterized by central retinal (macular) damage. Approximately 10% to 20% of non-exudative AMD cases progress to the exudative form, which may result in rapid deterioration of central vision. Individuals with exudative AMD (eAMD) need prompt consultation with retinal specialists to minimize the risk and extent of vision loss. Traditional methods of diagnosing ophthalmic disease rely on clinical evaluation and multiple imaging techniques, which can be resource-consuming. Tests leveraging artificial intelligence (AI) hold the promise of automatically identifying and categorizing pathological features, enabling the timely diagnosis and treatment of eAMD.\n\n\nOBJECTIVES\nTo determine the diagnostic accuracy of artificial intelligence (AI) as a triaging tool for exudative age-related macular degeneration (eAMD).\n\n\nSEARCH METHODS\nWe searched CENTRAL, MEDLINE, Embase, three clinical trials registries, and Data Archiving and Networked Services (DANS) for gray literature. We did not restrict searches by language or publication date. The date of the last search was April 2024.\n\n\nSELECTION CRITERIA\nIncluded studies compared the test performance of algorithms with that of human readers to detect eAMD on retinal images collected from people with AMD who were evaluated at eye clinics in community or academic medical centers, and who were not receiving treatment for eAMD when the images were taken. We included algorithms that were either internally or externally validated or both.\n\n\nDATA COLLECTION AND ANALYSIS\nPairs of review authors independently extracted data and assessed study quality using the Quality Assessment of Diagnostic Accuracy Studies-2 (QUADAS-2) tool with revised signaling questions. For studies that reported more than one set of performance results, we extracted only one set of diagnostic accuracy data per study based on the last development stage or the optimal algorithm as indicated by the study authors. For two-class algorithms, we collected data from the 2x2 table whenever feasible. For multi-class algorithms, we first consolidated data from all classes other than eAMD before constructing the corresponding 2x2 tables. Assuming a common positivity threshold applied by the included studies, we chose random-effects, bivariate logistic models to estimate summary sensitivity and specificity as the primary performance metrics.\n\n\nMAIN RESULTS\nWe identified 36 eligible studies that reported 40 sets of algorithm performance data, encompassing over 16,000 participants and 62,000 images. We included 28 studies (78%) that reported 31 algorithms with performance data in the meta-analysis. The remaining nine studies (25%) reported eight algorithms that lacked usable performance data; we reported them in the qualitative synthesis. Study characteristics and risk of bias Most studies were conducted in Asia, followed by Europe, the USA, and collaborative efforts spanning multiple countries. Most studies identified study participants from the hospital setting, while others used retinal images from public repositories; a few studies did not specify image sources. Based on four of the 36 studies reporting demographic information, the age of the study participants ranged from 62 to 82 years. The included algorithms used various retinal image types as model input, such as optical coherence tomography (OCT) images (N = 15), fundus images (N = 6), and multi-modal imaging (N = 7). The predominant core method used was deep neural networks. All studies that reported externally validated algorithms were at high risk of bias mainly due to potential selection bias from either a two-gate design or the inappropriate exclusion of potentially eligible retinal images (or participants). Findings Only three of the 40 included algorithms were externally validated (7.5%, 3/40). The summary sensitivity and specificity were 0.94 (95% confidence interval (CI) 0.90 to 0.97) and 0.99 (95% CI 0.76 to 1.00), respectively, when compared to human graders (3 studies; 27,872 images; low-certainty evidence). The prevalence of images with eAMD ranged from 0.3% to 49%. Twenty-eight algorithms were reportedly either internally validated (20%, 8/40) or tested on a development set (50%, 20/40); the pooled sensitivity and specificity were 0.93 (95% CI 0.89 to 0.96) and 0.96 (95% CI 0.94 to 0.98), respectively, when compared to human graders (28 studies; 33,409 images; low-certainty evidence). We did not identify significant sources of heterogeneity among these 28 algorithms. Although algorithms using OCT images appeared more homogeneous and had the highest summary specificity (0.97, 95% CI 0.93 to 0.98), they were not superior to algorithms using fundus images alone (0.94, 95% CI 0.89 to 0.97) or multimodal imaging (0.96, 95% CI 0.88 to 0.99; P for meta-regression = 0.239). The median prevalence of images with eAMD was 30% (interquartile range [IQR] 22% to 39%). We did not include eight studies that described nine algorithms (one study reported two sets of algorithm results) to distinguish eAMD from normal images, images of other AMD, or other non-AMD retinal lesions in the meta-analysis. Five of these algorithms were generally based on smaller datasets (range 21 to 218 participants per study) yet with a higher prevalence of eAMD images (range 33% to 66%). Relative to human graders, the reported sensitivity in these studies ranged from 0.95 and 0.97, while the specificity ranged from 0.94 to 0.99. Similarly, using small datasets (range 46 to 106), an additional four algorithms for detecting eAMD from other retinal lesions showed high sensitivity (range 0.96 to 1.00) and specificity (range 0.77 to 1.00).\n\n\nAUTHORS' CONCLUSIONS\nLow- to very low-certainty evidence suggests that an algorithm-based test may correctly identify most individuals with eAMD without increasing unnecessary referrals (false positives) in either the primary or the specialty care settings. There were significant concerns for applying the review findings due to variations in the eAMD prevalence in the included studies. In addition, among the included algorithm-based tests, diagnostic accuracy estimates were at risk of bias due to study participants not reflecting real-world characteristics, inadequate model validation, and the likelihood of selective results reporting. Limited quality and quantity of externally validated algorithms highlighted the need for high-certainty evidence. This evidence will require a standardized definition for eAMD on different imaging modalities and external validation of the algorithm to assess generalizability.",
    "doi": "10.1002/14651858.CD015522.pub2",
    "url": "https://www.semanticscholar.org/paper/d1d7e2acf6f1ee6054b02f0aafbe17dd076b9032",
    "pdf_url": "",
    "venue": "Cochrane Database of Systematic Reviews",
    "citation_count": 9,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586671"
  },
  {
    "source": "semantic_scholar",
    "source_id": "a34d13f8ed40eea6de541c7198729a73ae871106",
    "title": "Investigating Fairness with FanFAIR: is Pre-Processing Useful Only for Performances?",
    "authors": [
      "Michele Rispoli",
      "M. S. Nobile",
      "L. Manzoni",
      "Alberto d'Onofrio",
      "M. Confalonieri",
      "F. Salton",
      "P. Confalonieri",
      "B. Ruaro",
      "Chiara Gallese"
    ],
    "year": 2025,
    "abstract": "Artificial Intelligence, and Machine Learning systems in general, are becoming pervasive in our society, from the industry to the public administration. AI can often provide a very efficient means to support decision-making, but it can represent a danger for high-risk applications such as bio-medicine and healthcare. In particular, biased datasets might lead to inaccurate or discriminatory ML systems, undermining the accuracy of their predictions and putting patients' health at risk. FanFAIR is a python tool that provides the community with a semi-automatic tool for datasets' fairness assessment. FanFAIR is designed to integrate qualitative considerations - such as ethics, human rights assessment, and data protection - with quantitative indicators of dataset's fairness, such as balance, the presence of invalid entries, or outliers. In this work, we extend FanFAIR to deal with categorical data, and introduce a new algorithm for outlier detection in the presence of missing values. We then provide a case study on the data collected from COVID patients admitted to pneumology departments in Italy. We show how the successive steps of data cleaning and variable selection improve the indicators provided by FanFAIR. This shows that data cleaning procedures are not only necessary to improve the performance of the machine learning algorithm using the data for learning, but are also a way to improve (a measure of) fairness. Hence, the proposed case study provides an example in which performance and fairness are not in contrast, like it is commonly believed to be, but they improve together.",
    "doi": "10.1109/CIHM64979.2025.10969477",
    "url": "https://www.semanticscholar.org/paper/a34d13f8ed40eea6de541c7198729a73ae871106",
    "pdf_url": "",
    "venue": "2025 IEEE Symposium on Computational Intelligence in Health and Medicine (CIHM)",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586677"
  },
  {
    "source": "semantic_scholar",
    "source_id": "b919566c424d2f2d342366f63a87b89c3ea590bd",
    "title": "The role of artificial intelligence in higher medical education and the ethical challenges of its implementation",
    "authors": [
      "Mark Perkins",
      "A. Pregowska"
    ],
    "year": 2024,
    "abstract": "Artificial intelligence (AI) is penetrating higher medical education; however, its adoption remains low. A PRISMA-S search of the Web of Science database from 2020 to 2024, utilizing the search terms \u201cartificial intelligence,\u201d \u201cmedicine,\u201d \u201ceducation,\u201d and \u201cethics,\u201d reveals this trend. Four key areas of AI application in medical education are examined for their potential benefits: Educational support (such as personalized distance education), radiology (diagnostics), virtual reality (VR) (visualization and simulations), and generative text engines (GenText), such as ChatGPT (from the production of notes to syllabus design). However, significant ethical risks accompany AI adoption, and specific concerns are linked to each of these four areas. While AI is recognized as an important support tool in medical education, its slow integration hampers learning and diminishes student motivation, as evidenced by the challenges in implementing VR. In radiology, data-intensive training is hindered by poor connectivity, particularly affecting learners in developing countries. Ethical risks, such as bias in datasets (whether intentional or unintentional), need to be highlighted within educational programs. Students must be informed of the possible motivation behind the introduction of social and political bias in datasets, as well as the profit motive. Finally, the ethical risks accompanying the use of GenText are discussed, ranging from student reliance on instant text generation for assignments, which can hinder the development of critical thinking skills, to the potential danger of relying on AI-generated learning and treatment plans without sufficient human moderation.",
    "doi": "10.36922/aih.3276",
    "url": "https://www.semanticscholar.org/paper/b919566c424d2f2d342366f63a87b89c3ea590bd",
    "pdf_url": "https://doi.org/10.36922/aih.3276",
    "venue": "Artificial Intelligence in Health",
    "citation_count": 7,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586681"
  },
  {
    "source": "semantic_scholar",
    "source_id": "aa6fb2528d5fa16e11b885926136985d9ad9adc4",
    "title": "Ethics methods are required as part of reporting guidelines for artificial intelligence in healthcare",
    "authors": [
      "V. Sounderajah",
      "Melissa McCradden",
      "Xiaoxuan Liu",
      "S. Rose",
      "H. Ashrafian",
      "G. Collins",
      "James A. Anderson",
      "P. Bossuyt",
      "D. Moher",
      "A. Darzi"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1038/s42256-022-00479-3",
    "url": "https://www.semanticscholar.org/paper/aa6fb2528d5fa16e11b885926136985d9ad9adc4",
    "pdf_url": "",
    "venue": "Nature Machine Intelligence",
    "citation_count": 12,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586686"
  },
  {
    "source": "semantic_scholar",
    "source_id": "52a7ba5d2ea652ad99efe7ee89a0e168e3d80acc",
    "title": "Artificial Intelligence in Education Management: Opportunities, Challenges, and Solutions",
    "authors": [
      "Tong Feng",
      "Qinglun Li"
    ],
    "year": 2024,
    "abstract": "Education management, as an integral part of management science, encompasses core functions such as organizing, planning, coordinating, and controlling educational resources, which closely align with the management concepts used in business administration. Whether in the field of education or business, managers need to improve organizational performance through effective strategy development, resource allocation, and decision-making support. The emergence of Artificial Intelligence (AI) has profoundly transformed several industries, and its impact on education is progressively gaining prominence.This paper explores the opportunities, challenges, and solutions associated with the integration of AI in the education sector. AI offers substantial benefits such as personalized learning experiences, automated educational management, and global access to shared educational resources, revolutionizing the traditional educational landscape. However, its application also presents significant challenges, including concerns over data privacy, the widening of the digital divide, and the evolving role of teachers.Through an analysis of both opportunities and challenges, this paper emphasizes the need for strategic measures to ensure the ethical and equitable use of AI in education. These measures include stronger policy frameworks for data protection, comprehensive teacher training programs for AI integration, and the promotion of global cooperation to bridge technological gaps in underdeveloped regions. Furthermore, the paper projects the potential future developments in AI-driven education, highlighting the importance of balancing technology with human interaction in the learning environment.By addressing both the benefits and risks associated with AI, this paper provides actionable insights for educators, policymakers, and technologists, aimed at creating a more inclusive, efficient, and innovative educational system. Future research should continue to examine AI's ethical implications and strive for solutions that ensure education remains accessible and fair in an increasingly AI-driven world.",
    "doi": "10.54097/raxsbp45",
    "url": "https://www.semanticscholar.org/paper/52a7ba5d2ea652ad99efe7ee89a0e168e3d80acc",
    "pdf_url": "",
    "venue": "Frontiers in Business, Economics and Management",
    "citation_count": 4,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586690"
  },
  {
    "source": "semantic_scholar",
    "source_id": "36471e7feabbe035c94d0a263444f3b76e5774b2",
    "title": "A Comprehensive Study on Bias in Artificial Intelligence Systems: Biased or Unbiased AI, That's the Question!",
    "authors": [
      "Elif Kartal Karatas"
    ],
    "year": 2022,
    "abstract": "Humans are social beings. Emotions, like their thoughts, play an essential role in decision-making. Today, artificial intelligence (AI) raises expectations for faster, more accurate, more rational, and fairer decisions with technological advancements. As a result, AI systems have often been seen as an ideal decision-making mechanism. But what if these systems decide against you based on gender, race, or other characteristics? Biased or unbiased AI, that's the question! The motivation of this study is to raise awareness among researchers about bias in AI and contribute to the advancement of AI studies and systems. As the primary purpose of this study is to examine bias in the decision-making process of AI systems, this paper focused on (1) bias in humans and AI, (2) the factors that lead to bias in AI systems, (3) current examples of bias in AI systems, and (4) various methods and recommendations to mitigate bias in AI systems.",
    "doi": "10.4018/ijiit.309582",
    "url": "https://www.semanticscholar.org/paper/36471e7feabbe035c94d0a263444f3b76e5774b2",
    "pdf_url": "https://doi.org/10.4018/ijiit.309582",
    "venue": "International Journal of Intelligent Information Technologies",
    "citation_count": 10,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586694"
  },
  {
    "source": "semantic_scholar",
    "source_id": "38fa4ae849033386b515bc14ccbdcc39afcf5bfd",
    "title": "The comparative ethics of artificial-intelligence methods for military applications",
    "authors": [
      "N. Rowe"
    ],
    "year": 2022,
    "abstract": "Concerns about the ethics of the use of artificial intelligence by militaries have insufficiently addressed the differences between the methods (algorithms) that such software provides. These methods are discussed and key differences are identified that affect their ethical military use, most notably for lethal autonomous systems. Possible mitigations of ethical problems are discussed such as sharing decision-making with humans, better testing of the software, providing explanations of what is being done, looking for biases, and putting explicit ethics into the software. The best mitigation in many cases is explaining reasoning and calculations to aid transparency.",
    "doi": "10.3389/fdata.2022.991759",
    "url": "https://www.semanticscholar.org/paper/38fa4ae849033386b515bc14ccbdcc39afcf5bfd",
    "pdf_url": "https://www.frontiersin.org/articles/10.3389/fdata.2022.991759/pdf",
    "venue": "Frontiers in Big Data",
    "citation_count": 10,
    "fields_of_study": [
      "Medicine",
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586698"
  },
  {
    "source": "semantic_scholar",
    "source_id": "99eb2faf2629e22717de14eb8210811f9f6d367f",
    "title": "A Narrative Review in Application of Artificial Intelligence in Forensic Science: Enhancing Accuracy in Crime Scene Analysis and Evidence Interpretation",
    "authors": [
      "Abirami Arthanari",
      "S. Raj",
      "Vignesh Ravindran"
    ],
    "year": 2025,
    "abstract": "\n \n \n This review examines the transformative potential of artificial intelligence (AI) in forensic science, emphasizing its applications in crime scene analysis, evidence interpretation, digital forensics, and forensic odontology. It highlights AI\u2019s ability to enhance accuracy, efficiency, and reliability while addressing ethical and practical challenges.\n \n \n \n A systematic search was conducted across PubMed, Web of Science, Scopus, and Google Scholar, complemented by manual reviews of key forensic journals and grey literature. The review included studies on AI applications in forensic odontology and other forensic domains published in the past decade. Predefined inclusion and exclusion criteria were applied, and duplicates were removed. Full-text reviews were conducted to ensure relevance, with disagreements resolved through consensus by a third reviewer to ensure rigor.\n \n \n \n AI has significantly enhanced forensic practices by automating evidence analysis and improving accuracy. It streamlines crime scene reconstruction, accelerates digital forensic processes by analyzing large datasets, and advances dental forensics through rapid victim identification and bite mark analysis. AI-powered biometric systems enhance suspect and victim identification through facial recognition and pattern-matching technologies. However, limitations such as algorithmic bias, data privacy issues, and resource disparities pose challenges to its widespread adoption.\n \n \n \n AI is revolutionizing forensic science by providing enhanced precision, efficiency, and reliability in investigations. Addressing ethical concerns such as transparency, fairness, and algorithmic accountability is crucial for its responsible implementation. Future advancements should prioritize the development of explainable and unbiased algorithms, privacy-preserving techniques, and ethical frameworks. Interdisciplinary collaborations and global policy guidelines are essential to ensure the equitable and responsible integration of AI in forensic science, ultimately advancing justice and equity in the criminal justice system.\n",
    "doi": "10.4103/jioh.jioh_162_24",
    "url": "https://www.semanticscholar.org/paper/99eb2faf2629e22717de14eb8210811f9f6d367f",
    "pdf_url": "",
    "venue": "Journal of International Oral Health",
    "citation_count": 6,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586702"
  },
  {
    "source": "semantic_scholar",
    "source_id": "edf7e51ec5cb32b47c9b11cede8308b252dd8eb3",
    "title": "Safely advancing a spacefaring humanity with artificial intelligence",
    "authors": [
      "C. Richards",
      "Tom Cernev",
      "A. Tzachor",
      "G. Zilgalvis",
      "Bartu Kaleagasi"
    ],
    "year": 2023,
    "abstract": "A \u201cSpace Renaissance\u201d is underway. As our efforts to understand, utilize and settle space rapidly take new form, three distinct human-space interfaces are emerging, defined here as the \u201cEarth-for-space,\u201d \u201cspace-for-Earth\u201d and \u201cspace-for-space\u201d economies. Each engenders unprecedented opportunities, and artificial intelligence (AI) will play an essential role in facilitating innovative, accurate and responsive endeavors given the hostile, expansive and uncertain nature of extraterrestrial environments. However, the proliferation of, and reliance on, AI in this context is poised to aggravate existing threats and give rise to new risks, which are largely underappreciated, especially given the potential for great power competition and arms-race-type dynamics. Here, we examine possible beneficial applications of AI through the systematic prism of the three economies, including advancing the astronomical sciences, resource efficiency, technological innovation, telecommunications, Earth observation, planetary defense, mission strategy, human life support systems and artificial astronauts. Then we consider unintended and malicious risks arising from AI in space, which could have catastrophic consequences for life on Earth, space stations and space settlements. As a response to mitigate these risks, we call for urgent expansion of existing \u201cresponsible use of AI in space\u201d frameworks to address \u201cethical limits\u201d in both civilian and non-civilian space economy ventures, alongside national, bilateral and international cooperation to enforce mechanisms for robust, explainable, secure, accountable, fair and societally beneficial AI in space.",
    "doi": "10.3389/frspt.2023.1199547",
    "url": "https://www.semanticscholar.org/paper/edf7e51ec5cb32b47c9b11cede8308b252dd8eb3",
    "pdf_url": "https://www.frontiersin.org/articles/10.3389/frspt.2023.1199547/pdf",
    "venue": "Frontiers in Space Technologies",
    "citation_count": 4,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586706"
  },
  {
    "source": "semantic_scholar",
    "source_id": "4e23bd86b40234a6bd4dba209245b0f6bb501b01",
    "title": "Role of Artificial Intelligence and Big Data in Sustainable Entrepreneurship",
    "authors": [
      "Rula Abu Shanab"
    ],
    "year": 2024,
    "abstract": "There is a pressing necessity to shift our economy, society, and culture to systems and actions that promote ecological sustainability. This radical transformation necessitates an equally radical transformation of resource utilization and decision-making strategies. Sustainable entrepreneurship (SE) is frequently touted as the solution to the triple-bottom-line challenges that businesses encounter; however, there are tangible constraints on its potential. SE is currently in the first phase of implementing technological frontier tools that provide empirical guidance throughout the entrepreneurial decision-making process. The potential for artificial intelligence (AI) to inform decision-making is advanced by Big Data (BD), which also establishes pathways to attain desired outcomes. The interactions between AI, BD, and SE have been generally under-studied thus far. The absence of work that consolidates and synthesizes this literature is the primary focus of this conceptual paper. We propose that AI and BD are capable of rapidly contributing to the continued sustainable development of the weak form, but they also hold significant potential for attaining the strong sustainability ideal. We present two proposals for the integration of AI and BD to inform and facilitate SE. Finally, we outline potential areas for future research. \nThe core of human cosmology and ethics has always been the definition of his uniqueness. He ceased to be the species situated at the center of the universe, accompanied by the sun and stars, with the arrival of Copernicus and Galileo. He ceased to be the species that was created and specially endowed by God with soul and reason with the arrival of Darwin. With Freud, he ceased to be the species whose behavior could potentially be regulated by the rational mind. He has ceased to be the species that is uniquely capable of complex, intelligent manipulation of his environment as we begin to produce mechanisms that think and learn.",
    "doi": "10.60087/jaigs.v5i1.199",
    "url": "https://www.semanticscholar.org/paper/4e23bd86b40234a6bd4dba209245b0f6bb501b01",
    "pdf_url": "https://ojs.boulibrary.com/index.php/JAIGS/article/download/199/149",
    "venue": "Journal of Artificial Intelligence General science (JAIGS) ISSN:3006-4023",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586710"
  },
  {
    "source": "semantic_scholar",
    "source_id": "34449d3d462666f17ae9082242c1b1f491b02edb",
    "title": "Unmasking AI Bias in Traditional Prognosis Models",
    "authors": [
      "Md. Rayhan Hasan",
      "Sabrina Akter Setu",
      "Shinthi Tasnim Himi",
      "Shirin Sultana",
      "Anika Afrin",
      "Mohammad Nasif Sadique Khan",
      "Shrebash Paul",
      "Natasha Tanzila Monalisa"
    ],
    "year": 2025,
    "abstract": "Artificial Intelligence (AI) in healthcare is on the rise, assisting with early disease prognosis and decision-making processes. However, A\u0130 models exhibit a propensity for bias, which can lead to unequal performance across various demographic and regional subgroups. Recent advancements in metalearning aim to enhance the generalisation of these models when faced with limited data scenarios. Yet, there is a paucity of studies investigating the behaviour of such models within low-resource clinical datasets, particularly when factoring in fairness constraints. This research employs sophisticated metalearning methodologies to assess and quantify bias in predicting rabies outcomes by implementing ProtoNet, Model-Agnostic Meta-Learning (MAML), and a Hybrid ProtoMAML model to a custom-annotated rabies dataset that has been stratified by age, gender, and district. The results demonstrate that the ProtoMAML model achieves superior fairness; however, bias remains evident across subgroups. This study underscores the importance of addressing algorithmic bias within clinical AI applications and advocates for developing equitable and inclusive medical decision-making systems.",
    "doi": "10.1109/QPAIN66474.2025.11171992",
    "url": "https://www.semanticscholar.org/paper/34449d3d462666f17ae9082242c1b1f491b02edb",
    "pdf_url": "",
    "venue": "2025 International Conference on Quantum Photonics, Artificial Intelligence, and Networking (QPAIN)",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586715"
  },
  {
    "source": "semantic_scholar",
    "source_id": "6b12bbdb9d3b5a6b1b8309595014f3398d0f0360",
    "title": "Interview Bot for Improving Human Resource Management",
    "authors": [
      "Sinung Suakanto",
      "J. Siswanto",
      "Tien Febrianti Kusumasari",
      "Ilham Reza Prasetyo",
      "Margareta Hardiyanti"
    ],
    "year": 2021,
    "abstract": "This study aims to explore the feasibility of implementing a chatbot for an interview process. The development of chatbots evolved rapidly to efficiently collect information in numerous fields, including customer service, health care, and etc. However, there was limited discussion of how chatbots are used to conduct an interview process autonomously. A human-driven interview also has some major limitations, e.g., it may only be conducted on a small-scale and is susceptible to bias. Hence, this study provides the design of a chatbot to conduct an interview, as well as processing the interview result by using Artificial Intelligence (AI) or machine learning. We have identified the difference between the typical chatbot communication method and the interview bot. This finding can be an opportunity to make a new interview bot or improve the implementation of a chatbot. In the end, we also discuss the challenges and benefits of the development of an interview bot.",
    "doi": "10.1109/ICISS53185.2021.9533248",
    "url": "https://www.semanticscholar.org/paper/6b12bbdb9d3b5a6b1b8309595014f3398d0f0360",
    "pdf_url": "",
    "venue": "International Conferences on Information Science and System",
    "citation_count": 10,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586719"
  },
  {
    "source": "semantic_scholar",
    "source_id": "f1b53dddd8bb243a43f697139a71c40903e79470",
    "title": "AI Decision Making with Dignity? Contrasting Workers\u2019 Justice Perceptions of Human and AI Decision Making in a Human Resource Management Context",
    "authors": [
      "Sarah Bankins",
      "Paul Formosa",
      "Yannick Griep",
      "Deborah Richards"
    ],
    "year": 2022,
    "abstract": "Using artificial intelligence (AI) to make decisions in human resource management (HRM) raises questions of how fair employees perceive these decisions to be and whether they experience respectful treatment (i.e., interactional justice). In this experimental survey study with open-ended qualitative questions, we examine decision making in six HRM functions and manipulate the decision maker (AI or human) and decision valence (positive or negative) to determine their impact on individuals\u2019 experiences of interactional justice, trust, dehumanization, and perceptions of decision-maker role appropriateness. In terms of decision makers, the use of human decision makers over AIs generally resulted in better perceptions of respectful treatment. In terms of decision valence, people experiencing positive over negative decisions generally resulted in better perceptions of respectful treatment. In instances where these cases conflict, on some indicators people preferred positive AI decisions over negative human decisions. Qualitative responses show how people identify justice concerns with both AI and human decision making. We outline implications for theory, practice, and future research.",
    "doi": "10.1007/s10796-021-10223-8",
    "url": "https://www.semanticscholar.org/paper/f1b53dddd8bb243a43f697139a71c40903e79470",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10796-021-10223-8.pdf",
    "venue": "Information Systems Frontiers",
    "citation_count": 123,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586723"
  },
  {
    "source": "semantic_scholar",
    "source_id": "9c5b0956d5acbdaf9da938a61d22c3c322c71262",
    "title": "Strategies and Practices for Enhancing Higher Education Faculty Teaching Capabilities through Artificial Intelligence",
    "authors": [
      "Yangpeng Zhu",
      "Linjie Zhang",
      "Nuonan Chen"
    ],
    "year": 2025,
    "abstract": "A new wave of technologies\u2014represented by generative AI, multimodal learning analytics, and human-machine collaborative systems\u2014is driving a three-dimensional transformation of higher education faculty roles. Educators are evolving from \u201cknowledge transmitters\u201d into integrated \u201clearning designers\u2014value shapers\u2014data decision-makers.\u201d Guided by the Ministry of Education's policy framework \u201cDigital Empowerment for Teacher Development,\u201d this study employs field research across over 30 universities and fuzzy set qualitative comparative analysis (fsQCA) of 280 secondary colleges. Through in-depth comparative case studies across three disciplines (STEM, humanities, arts/sports), it systematically elucidates the theoretical mechanisms, core technical architectures, and differentiated implementation pathways for AI-enhanced teaching capabilities. (fsQCA) across 280 secondary colleges, and in-depth comparative case studies across three disciplinary categories (science/engineering, humanities, physical education/arts). It systematically elucidates the theoretical mechanisms, core technological architecture, and differentiated implementation pathways for AI-empowered teaching capabilities, establishing a new triadic paradigm of \u201ctechnology-institutional-humanistic\u201d synergy. Key findings include: (1) The multimodal classroom evidence-based system can enhance the precision of teaching diagnostics, but require edge computing and federated learning to safeguard data sovereignty; (2) Enhancements in teachers' teaching efficacy exhibit disciplinary heterogeneity: STEM disciplines rely on a closed-loop system of \u201cteaching behaviors \u00d7 student feedback\u201d experimental data, while humanities disciplines depend on a dual-drive model of \u201cteaching ethics \u00d7 emotional interaction\u201d; (3) Absent ethical governance poses the primary risk for deep AI application, necessitating a three-tier firewall comprising \u201cdata classification and grading + algorithmic ethics review + teacher digital rights catalog.\u201d Based on these findings, the paper proposes an integrated teacher development model encompassing \u201cAI tools\u2014organizational support\u2014humanistic reflection\u201d and offers actionable policy recommendations for national resource repository development, discipline-differentiated training, and cross-border digital governance collaboration.",
    "doi": "10.1145/3785987.3786014",
    "url": "https://www.semanticscholar.org/paper/9c5b0956d5acbdaf9da938a61d22c3c322c71262",
    "pdf_url": "",
    "venue": "Proceedings of the 2025 2nd International Conference on Artificial Intelligence and Future Education",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586727"
  },
  {
    "source": "semantic_scholar",
    "source_id": "860190a1f02e08573bedcf82f0d45dad8653ae0e",
    "title": "Harmonizing creativity and ethics in AI systems",
    "authors": [
      "Joffrey Baeyaert"
    ],
    "year": 2025,
    "abstract": null,
    "doi": "10.1007/s43681-025-00766-w",
    "url": "https://www.semanticscholar.org/paper/860190a1f02e08573bedcf82f0d45dad8653ae0e",
    "pdf_url": "",
    "venue": "AI and Ethics",
    "citation_count": 2,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586731"
  },
  {
    "source": "semantic_scholar",
    "source_id": "5f70393e599bf3bc777339acf5b6986884bd1fb2",
    "title": "AI ethics in banking services: a systematic and bibliometric review of regulatory and consumer perspectives",
    "authors": [
      "McArthur Fundira",
      "Charles Mbohwa"
    ],
    "year": 2025,
    "abstract": null,
    "doi": "10.1007/s44163-025-00432-4",
    "url": "https://www.semanticscholar.org/paper/5f70393e599bf3bc777339acf5b6986884bd1fb2",
    "pdf_url": "",
    "venue": "Discover Artificial Intelligence",
    "citation_count": 2,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586735"
  },
  {
    "source": "semantic_scholar",
    "source_id": "027c01ee260e498c5e8450304a00209e40c067bc",
    "title": "The Study on Ethics and Biases in AI-Powered Education",
    "authors": [
      "V.G. Suchithra",
      "C.S. Arya"
    ],
    "year": 2025,
    "abstract": "Artificial Intelligence (AI) is transforming education by tailoring learning experiences, streamlining administrative tasks, and increasing student engagement. AI-powered platforms are developing personalised learning plans, automating grading processes and improving accessibility, making education more effective and inclusive. However, these innovations also pose ethical challenges, such as privacy concerns, the need for transparency in algorithms, and potential biases in AI systems. If left unaddressed, biases in AI-assisted education could increase inequalities, misrepresent students' abilities, and compromise the fairness of learning outcomes. This research explores the ethical implications of AI in education, identifying sources of bias and evaluating strategies to promote fairness and inclusivity. It highlights the need for ethical AI frameworks, transparency in algorithmic choices, and ongoing monitoring to reduce bias. The study also explores future opportunities in AI-driven education, including adaptive learning environments and improved accessibility tools. By balancing technological advancement with ethical considerations, AI can become a powerful catalyst for change in education while maintaining fairness, equity and accountability.",
    "doi": "10.59324/ejceel.2025.3(2).04",
    "url": "https://www.semanticscholar.org/paper/027c01ee260e498c5e8450304a00209e40c067bc",
    "pdf_url": "",
    "venue": "European Journal of Contemporary Education and E-Learning",
    "citation_count": 2,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586739"
  },
  {
    "source": "semantic_scholar",
    "source_id": "c62f0fb9c6ac503bf73c3b6a2cc0a61af6d64f26",
    "title": "Ethical recommendations for Artificial Intelligence technology in the Geological Sciences - with a focus on Language Models",
    "authors": [
      "Paul H. Cleverley"
    ],
    "year": 2024,
    "abstract": "Artificial Intelligence (AI) offers many opportunities for the geosciences to improve productivity, reduce uncertainty in models and stimulate discovery of new knowledge. There are also risks to geoscience, from the spread of obsolete, inaccurate and misinformation, to threats on fundamental human rights. Whilst ethical AI frameworks exist from numerous institutions such as UNESCO, they are high level and lack practical detail in the geosciences particularly for Large Language Models (LLM). This is evidenced by the misalignment between the way current geoscience AI/LLMs are being designed, trained and deployed, with core ethical principles. Using principles and frameworks from UNESCO and the International Science Council (ISC), a set of ten recommendations are proposed to bridge the gap between practice and these ethical frameworks. Critical Realism is used as an underlying philosophy which allows the potential to provide justifiable recommendations to ethical and moral questions using judgemental rationality. These recommendations may help stakeholders in the international community reach conclusions on what \u2018good looks like\u2019 for ethical AI in the geological sciences focusing on Language Models and their applications. This may inform developers, regulators, policy advisors, journal editors, geological surveys, societies, institutions and unions, publishers, funding bodies, geoscientists and decision makers. This is believed to be the first research paper on AI ethics in the geological sciences with a focus on Generative AI. Understanding the nuances of our ethical choices for both the development and use of LLMs and other AI tools in the geosciences, has the potential to positively impact science integrity, and critically, ensure fairness, personal privacy, democratic norms and human rights are safeguarded.",
    "doi": "10.4401/jgsg-63",
    "url": "https://www.semanticscholar.org/paper/c62f0fb9c6ac503bf73c3b6a2cc0a61af6d64f26",
    "pdf_url": "",
    "venue": "JOURNAL OF GEOETHICS AND SOCIAL GEOSCIENCES",
    "citation_count": 4,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586743"
  },
  {
    "source": "semantic_scholar",
    "source_id": "fe30c02ed5f26e7dcb96857811b425b41856a6e0",
    "title": "Accountability in Human and Artificial Intelligence Decision-Making as the Basis for Diversity and Educational Inclusion",
    "authors": [
      "K. Porayska-Pomsta",
      "Gnanathusharan Rajendran"
    ],
    "year": 2019,
    "abstract": null,
    "doi": "10.1007/978-981-13-8161-4_3",
    "url": "https://www.semanticscholar.org/paper/fe30c02ed5f26e7dcb96857811b425b41856a6e0",
    "pdf_url": "",
    "venue": "Artificial Intelligence and Inclusive Education",
    "citation_count": 36,
    "fields_of_study": [
      "Psychology"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586747"
  },
  {
    "source": "semantic_scholar",
    "source_id": "e9e961b64186c9d11ad3625eb9128b994ab45a21",
    "title": "Artificial Intelligence Ethik (Artificial Intelligence Ethics)",
    "authors": [
      "Julia M. Puaschunder"
    ],
    "year": 2018,
    "abstract": null,
    "doi": "10.2139/SSRN.3137926",
    "url": "https://www.semanticscholar.org/paper/e9e961b64186c9d11ad3625eb9128b994ab45a21",
    "pdf_url": "",
    "venue": "",
    "citation_count": 5,
    "fields_of_study": [
      "Political Science"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586750"
  },
  {
    "source": "semantic_scholar",
    "source_id": "10121233fc2d3ca0741945b8493596c3e1148c0b",
    "title": "Ethical Leadership and Decision-Making in AI: Navigating Educational Management Ethics in the Digital Age",
    "authors": [
      "Sippiya Chayanusasanee Jundon",
      "Busara Niyomves",
      "Somboon Kaewlamai",
      "Thanyachanok Pawala"
    ],
    "year": 2025,
    "abstract": "Background and Aims: Management ethics in the digital age is critical for maintaining trust because leaders must ensure responsible technology use, data privacy, and fairness in AI decisions. Ethical management promotes transparency, prevents the misuse of digital tools, and ensures accountability in a rapidly changing technological landscape. This paper aims to investigate Ethical Leadership and Decision-Making in AI\nMethodology: This paper used peer-reviewed literature, industry reports, and authoritative sources to conduct a systematic investigation into the intersection of ethical leadership and artificial intelligence in the digital age. It identified key trends and gaps through structured data collection and thematic analysis, and then made recommendations for promoting ethical leadership in AI decision-making.\nResults: The finding found that addressing critical ethical issues such as bias, transparency, privacy, and employment impact is critical for responsible AI management. Bias in AI algorithms can perpetuate societal inequalities, transparency issues can impede accountability, extensive data collection raises privacy concerns, and automation has the potential to disrupt labor markets. Effective management necessitates the implementation of fairness-aware algorithms, strong data security, and proactive workforce transition strategies. Leaders must establish ethical guidelines, foster an ethical AI culture, and adhere to global standards to navigate these challenges and promote responsible AI development.\nConclusion: The findings emphasize the importance of dealing with ethical issues such as bias, transparency, privacy, and employment impact to manage AI responsibly. To foster accountability and promote responsible AI development, leaders must implement algorithms that prioritize fairness, ensure data security, and establish ethical guidelines.",
    "doi": "10.60027/jelr.2025.1458",
    "url": "https://www.semanticscholar.org/paper/10121233fc2d3ca0741945b8493596c3e1148c0b",
    "pdf_url": "",
    "venue": "Journal of Education and Learning Reviews",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586754"
  },
  {
    "source": "semantic_scholar",
    "source_id": "b873498140cee0442abe8a1daab4cd60416dbd48",
    "title": "Macy Foundation Innovation Report Part I: Current Landscape of Artificial Intelligence in Medical Education.",
    "authors": [
      "Christy K Boscardin",
      "Raja-Elie E. Abdulnour",
      "Brian C. Gin"
    ],
    "year": 2025,
    "abstract": "ABSTRACT\nThe rapid emergence of artificial intelligence (AI), including generative large language models, offers transformative opportunities in medical education. This proliferation has generated numerous speculative discussions about AI's promise but has been limited in delivering a comprehensive analysis to distinguish evidence-based utility from hype while identifying context-specific limitations.In this first part of a two-part innovation report, commissioned by the Josiah Macy Jr. Foundation to inform the discussions at a conference on AI in medical education, the authors synthesize the landscape of AI in medical education, underscoring both its potential advantages and inherent challenges. To map the AI landscape, they reviewed 455 articles that targeted five medical education domains: (1) Admissions, (2) Classroom-Based Learning and Teaching, (3) Workplace-Based Learning and Teaching, (4) Assessment, Feedback, and Certification, and (5) Program Evaluation and Research.In admissions, AI-driven strategies facilitated holistic applicant reviews through predictive modeling, natural language processing, and large language model-based chatbots. Preclinical learning benefited from AI-powered virtual patients and curriculum design tools that managed expanding medical knowledge and supported robust student practice. Within clinical learning, AI aided diagnostic and interpretive processes, prompting medical education curricula to demand relevant AI competency and literacy frameworks. A few studies reported that assessment and feedback processes became more efficient through automated grading and advanced analytics, which reduced faculty workload and offered timely, targeted feedback. Program evaluation and research gained additional insights using AI on careers, diversity, and performance metrics of faculty and learners, improving resource allocations and guiding evidence-based approaches.Despite these possibilities, bias in AI algorithms, concerns about transparency, inadequate ethical guidelines, and risks of over-reliance highlighted the need for cautious, informed AI implementation. By mapping AI tasks to medical education applications, the authors provide a framework for understanding and leveraging AI's potential while addressing technical, ethical, and human-factor complexities in this evolving field.",
    "doi": "10.1097/ACM.0000000000006107",
    "url": "https://www.semanticscholar.org/paper/b873498140cee0442abe8a1daab4cd60416dbd48",
    "pdf_url": "",
    "venue": "Academic medicine : journal of the Association of American Medical Colleges",
    "citation_count": 5,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586758"
  },
  {
    "source": "semantic_scholar",
    "source_id": "c863d9e40b2c1606c1c51b9d26689f42d32b776a",
    "title": "How Copyright Law Can Fix Artificial Intelligence's Implicit Bias Problem",
    "authors": [
      "Amanda Levendowski"
    ],
    "year": 2017,
    "abstract": null,
    "doi": null,
    "url": "https://www.semanticscholar.org/paper/c863d9e40b2c1606c1c51b9d26689f42d32b776a",
    "pdf_url": "",
    "venue": "",
    "citation_count": 66,
    "fields_of_study": [
      "Engineering"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586762"
  },
  {
    "source": "semantic_scholar",
    "source_id": "ae41c7c5b2dcb76f4044dd88386b3bafe71e0c90",
    "title": "AI and ethics in business: A comprehensive review of responsible AI practices and corporate responsibility",
    "authors": [
      "Chidera Victoria",
      "Ibeh",
      "Funmilola Olatundun Olatoye",
      "Kehinde Feranmi Awonuga",
      "Noluthando Zamanjomane Mhlongo",
      "Oluwafunmi Adijat Elufioye",
      "Ndubuisi Leonard Ndubuisi"
    ],
    "year": 2024,
    "abstract": "As artificial intelligence (AI) continues to revolutionize business landscapes, the ethical implications of its deployment have garnered significant attention. This paper presents a comprehensive review of the intersection between AI and ethics in the context of corporate responsibility. The integration of AI into business processes necessitates a thorough understanding of responsible AI practices to ensure that technological advancements align with ethical standards and societal values. The first dimension explored in this review is the critical importance of transparency in AI algorithms and decision-making processes. Businesses adopting AI technologies must prioritize transparency to build trust among stakeholders, ensuring that the decision-making processes are understandable and accountable. Ethical considerations also extend to issues of bias and fairness, prompting the need for diverse and inclusive datasets to prevent discriminatory outcomes. Corporate responsibility in the realm of AI extends beyond technical aspects, encompassing the broader socio-economic impact of AI implementation. The review highlights the significance of considering the effects of AI on employment, inequality, and accessibility. Businesses are urged to adopt ethical guidelines that prioritize the well-being of employees and society at large, mitigating the potential negative consequences of AI on employment dynamics and social structures. Furthermore, the paper delves into the ethical considerations surrounding data privacy and security, emphasizing the importance of responsible data handling practices. As businesses accumulate vast amounts of data, it becomes imperative to prioritize the protection of individuals' privacy rights, reinforcing the ethical foundation of AI applications. This comprehensive review underscores the need for businesses to integrate responsible AI practices within the framework of corporate responsibility. By prioritizing transparency, fairness, and ethical data practices, organizations can navigate the complex terrain of AI implementation while ensuring alignment with societal values and ethical standards. This synthesis of AI and ethics in business is essential for fostering a sustainable and responsible technological future.",
    "doi": "10.30574/ijsra.2024.11.1.0235",
    "url": "https://www.semanticscholar.org/paper/ae41c7c5b2dcb76f4044dd88386b3bafe71e0c90",
    "pdf_url": "https://ijsra.net/sites/default/files/IJSRA-2024-0235.pdf",
    "venue": "International Journal of Science and Research Archive",
    "citation_count": 41,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586767"
  },
  {
    "source": "semantic_scholar",
    "source_id": "09c2ad9f972ef214d016d98744437dc2225ed106",
    "title": "Artificial Intelligence-Powered Robotic Technology for Transforming Palliative Care",
    "authors": [
      "Adebo Thomas",
      "Asiku Denis",
      "Wamusi Robert",
      "Simon Peter Kabiito",
      "Zaward Morish",
      "Aziku Samuel",
      "Malik Sallam",
      "Ioannis Adamopoulos"
    ],
    "year": 2025,
    "abstract": "Palliative care seeks to improve the quality of life of patients with life-threatening illnesses by addressing their physical, emotional, and psychological needs. However, global challenges such as workforce shortages, limited access to specialized care, and inconsistent care quality demand innovative solutions. Advances in artificial intelligence (AI)-powered robotics offer transformative potential to overcome these barriers and strengthen palliative care delivery. This study explores how AI-driven robotic technologies support palliative care through applications in symptom monitoring, clinical decision-making, emotional companionship, and personalized care planning. It reviews cutting-edge robotic systems, including assistive, companion, diagnostic, nursing, procedural, service, and rehabilitation robots. Enabled by machine learning, deep learning, natural language processing, and computer vision breakthroughs, these systems help monitor vital signs, manage symptoms, plan end-of-life care, deliver medication, alleviate pain, and support mobility through robotic exoskeletons. They also assist patients with daily activities and offer respite to caregivers. Despite their promise, AI-powered robotics face significant challenges, including ethical concerns, algorithmic bias, data privacy risks, cultural resistance, and resource limitations. When integrated ethically and thoughtfully, AI-powered robotics can extend the reach of palliative services, support human caregivers, and enhance outcomes for patients and families. Collaboration among healthcare professionals, AI researchers, engineers, and policymakers is crucial to ensure that robotic technologies remain patient-centered, safe, and accessible. By merging technological innovation with compassionate care, AI and robotics can redefine the future of palliative care globally.",
    "doi": "10.58496/mjaih/2025/007",
    "url": "https://www.semanticscholar.org/paper/09c2ad9f972ef214d016d98744437dc2225ed106",
    "pdf_url": "",
    "venue": "Mesopotamian Journal of Artificial Intelligence in Healthcare",
    "citation_count": 3,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586771"
  },
  {
    "source": "semantic_scholar",
    "source_id": "8725127c0bdba837fbf286982be34416798245c4",
    "title": "Ethics in AI: Balancing innovation and responsibility",
    "authors": [
      "Rishi Kumar Sharma"
    ],
    "year": 2025,
    "abstract": "The rapid advancement of artificial intelligence technologies has created unprecedented opportunities while raising significant ethical concerns across various sectors. This comprehensive article examines the challenges and strategies in implementing ethical AI frameworks, focusing on algorithmic bias, transparency, and accountability. The article investigates industry-specific applications in healthcare, financial services, and law enforcement, revealing ethical implementation and governance patterns. Through extensive research across multiple organizations, the article demonstrates the critical importance of structured ethical frameworks, stakeholder engagement, and comprehensive monitoring systems in ensuring responsible AI development. The findings highlight the need for balanced approaches that maintain technological innovation while adhering to ethical principles and human values.",
    "doi": "10.30574/ijsra.2025.14.1.0122",
    "url": "https://www.semanticscholar.org/paper/8725127c0bdba837fbf286982be34416798245c4",
    "pdf_url": "",
    "venue": "International Journal of Science and Research Archive",
    "citation_count": 9,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586775"
  },
  {
    "source": "semantic_scholar",
    "source_id": "8fabf24a07f006bd2097584770afd3953aadc4a6",
    "title": "Shaping the future of AI in healthcare through ethics and governance",
    "authors": [
      "Rabai Bouderhem"
    ],
    "year": 2024,
    "abstract": "The purpose of this research is to identify and evaluate the technical, ethical and regulatory challenges related to the use of Artificial Intelligence (AI) in healthcare. The potential applications of AI in healthcare seem limitless and vary in their nature and scope, ranging from privacy, research, informed consent, patient autonomy, accountability, health equity, fairness, AI-based diagnostic algorithms to care management through automation for specific manual activities to reduce paperwork and human error. The main challenges faced by states in regulating the use of AI in healthcare were identified, especially the legal voids and complexities for adequate regulation and better transparency. A few recommendations were made to protect health data, mitigate risks and regulate more efficiently the use of AI in healthcare through international cooperation and the adoption of harmonized standards under the World Health Organization (WHO) in line with its constitutional mandate to regulate digital and public health. European Union (EU) law can serve as a model and guidance for the WHO for a reform of the International Health Regulations (IHR).",
    "doi": "10.1057/s41599-024-02894-w",
    "url": "https://www.semanticscholar.org/paper/8fabf24a07f006bd2097584770afd3953aadc4a6",
    "pdf_url": "https://www.nature.com/articles/s41599-024-02894-w.pdf",
    "venue": "Humanities and Social Sciences Communications",
    "citation_count": 86,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586778"
  },
  {
    "source": "semantic_scholar",
    "source_id": "5821c044982322e2aebfbadbf319cdf7f6e576bf",
    "title": "Higher Education\u2019s Generative Artificial Intelligence Paradox: The Meaning of Chatbot Mania",
    "authors": [
      "Juergen Rudolph",
      "Fadhil Mohamed Mohamed Ismail",
      "Stefan Popenici"
    ],
    "year": 2024,
    "abstract": "Higher education is currently under a significant transformation due to the emergence of generative artificial intelligence (GenAI) technologies, the hype surrounding GenAI and the increasing influence of educational technology business groups over tertiary education. This commentary, prepared for the Special Issue of the Journal of University Teaching & Learning Practice (JUTLP) on \u201cEnhancing student engagement using Artificial Intelligence (AI) and chatbots,\u201d delves into the complex landscape of opportunities and threats that AI chatbots, including ChatGPT, introduce to the realm of higher education. We argue that while GenAI offers promise in enhancing pedagogy, research, administration, and student support, concerns around academic integrity, labour displacement, embedded biases, environmental sustainability, increased commercialisation, and regulatory gaps necessitate a critical approach. Our commentary advocates for the development of critical AI literacy among educators and students, emphasising the necessity to foster an environment of responsible innovation and informed use of AI. We posit that the successful integration of AI in higher education must be grounded in the principles of ethics, equity, and the prioritisation of educational aims and human values. By offering a critical and nuanced exploration of these issues, our commentary aims to contribute to the ongoing discourse on how higher education institutions can navigate the rise of GenAI, ensuring that technological advancements benefit all stakeholders while upholding core academic values.",
    "doi": "10.53761/54fs5e77",
    "url": "https://www.semanticscholar.org/paper/5821c044982322e2aebfbadbf319cdf7f6e576bf",
    "pdf_url": "https://open-publishing.org/journals/index.php/jutlp/article/download/744/754",
    "venue": "Journal of University Teaching and Learning Practice",
    "citation_count": 59,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586782"
  },
  {
    "source": "semantic_scholar",
    "source_id": "b9d6757b0170523916353062f96ee075ac915c4d",
    "title": "Demographic bias of expert-level vision-language foundation models in medical imaging",
    "authors": [
      "Yuzhe Yang",
      "Yujia Liu",
      "Xin Liu",
      "Avanti V Gulhane",
      "Domenico Mastrodicasa",
      "Wei Wu",
      "E. J. Wang",
      "Dushyant W. Sahani",
      "Shwetak N. Patel"
    ],
    "year": 2024,
    "abstract": "Advances in artificial intelligence (AI) have achieved expert-level performance in medical imaging applications. Notably, self-supervised vision-language foundation models can detect a broad spectrum of pathologies without relying on explicit training annotations. However, it is crucial to ensure that these AI models do not mirror or amplify human biases, disadvantaging historically marginalized groups such as females or Black patients. In this study, we investigate the algorithmic fairness of state-of-the-art vision-language foundation models in chest x-ray diagnosis across five globally sourced datasets. Our findings reveal that compared to board-certified radiologists, these foundation models consistently underdiagnose marginalized groups, with even higher rates seen in intersectional subgroups such as Black female patients. Such biases present over a wide range of pathologies and demographic attributes. Further analysis of the model embedding uncovers its substantial encoding of demographic information. Deploying medical AI systems with biases can intensify preexisting care disparities, posing potential challenges to equitable healthcare access and raising ethical questions about their clinical applications.",
    "doi": "10.1126/sciadv.adq0305",
    "url": "https://www.semanticscholar.org/paper/b9d6757b0170523916353062f96ee075ac915c4d",
    "pdf_url": "http://arxiv.org/pdf/2402.14815",
    "venue": "Science Advances",
    "citation_count": 43,
    "fields_of_study": [
      "Medicine",
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586787"
  },
  {
    "source": "semantic_scholar",
    "source_id": "6b8323c615566aa4d464b0d257d6e21bf0b2904c",
    "title": "Responsible AI for AI Sustainable Future: Governance, Ethics, and The Reality Behind\u00a0the\u00a0Promise",
    "authors": [
      "Miracle Atianashie",
      "Mark K. Kuffour",
      "Bernard Kyiewu",
      "Philipa Serwaa"
    ],
    "year": 2025,
    "abstract": "Artificial intelligence has emerged as a powerful force shaping global development, offering promising solutions across health, education, climate change, and governance. However, its rapid integration into critical sectors raises urgent questions about ethics, governance, and sustainability. This systematic review explores the promise and practice of responsible AI through the lens of three core objectives: the governance mechanisms guiding AI implementation, the ethical frameworks shaping its design, and the practical realities influencing its deployment across contexts. Drawing from sixty peer-reviewed articles published between 2017 and 2024, the review identifies strong global consensus on foundational principles such as fairness, accountability, and transparency. Nonetheless, a significant implementation gap persists, particularly in low-resource settings, where enforcement mechanisms and institutional readiness are often lacking. The findings also reveal that ethical commitments are frequently undermined by organizational constraints and commercial interests, leading to surface-level adherence without substantive change. Environmental sustainability, a critical dimension of responsible AI, remains underrepresented in current governance discussions despite mounting evidence of AI\u2019s carbon footprint. This review contributes to the growing body of scholarship advocating for inclusive, enforceable, and context-sensitive approaches to responsible AI. It underscores the need for deeper engagement with the political, social, and environmental realities that shape AI\u2019s impact on sustainable development. Ultimately, bridging the gap between AI\u2019s ethical aspirations and real-world outcomes requires not only technical innovation but also strong institutional leadership, interdisciplinary collaboration, and meaningful stakeholder participation.",
    "doi": "10.70715/jitcai.2025.v2.i2.012",
    "url": "https://www.semanticscholar.org/paper/6b8323c615566aa4d464b0d257d6e21bf0b2904c",
    "pdf_url": "",
    "venue": "Journal of Information Technology, Cybersecurity, and Artificial Intelligence",
    "citation_count": 2,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586791"
  },
  {
    "source": "semantic_scholar",
    "source_id": "baacd51e725c849bbc7a7ea78e9fe07d3e81dd64",
    "title": "The Ethics of Artificial Intelligence",
    "authors": [
      "Chris Rees"
    ],
    "year": 2020,
    "abstract": "This chapter focuses on the ethics of narrow, as opposed to general AI. It makes the practical as well as the philosophical case for discussion of AI ethics. It considers ethical charters, then discusses the principal ethical issues: bias, explainability, liability for failure, harmlessness, the ethical use of data, whether AIs should have legal personality, the effects on employment and society, and AIs impersonating humans. A case study is presented of AI in personal insurance. It makes the case for regulation of AI and discusses the challenges of enacting regulation. It draws conclusions, that the benefits of AI are so valuable that the ethical risks must be managed, or the benefits may be lost because of the loss of public trust. There are grounds for optimism, notably the public consciousness of the issues, the engagement of governments and the amount of private and public investment in ethical research.",
    "doi": "10.1007/978-3-030-64246-4_5",
    "url": "https://www.semanticscholar.org/paper/baacd51e725c849bbc7a7ea78e9fe07d3e81dd64",
    "pdf_url": "",
    "venue": "Unimagined Futures",
    "citation_count": 6,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586795"
  },
  {
    "source": "semantic_scholar",
    "source_id": "37ef7632480b672100aa0305addbdb4f743b5b7b",
    "title": "Artificial Intelligence and Inequality: Challenges and Opportunities",
    "authors": [
      "Milad Shahvaroughi Farahani",
      "Ghazal Ghasemi"
    ],
    "year": 2024,
    "abstract": "Integrating artificial intelligence (AI) technologies into various aspects of society has sparked both excitement and concern regarding its potential impact on inequality. This abstract provides an overview of the key issues surrounding AI and inequality, exploring the challenges and opportunities arising from the widespread adoption of AI systems.\n\nFirstly, we examine how AI technologies have the potential to exacerbate existing inequalities across various domains, including labor markets, education, healthcare, and access to services. AI-driven automation may lead to job displacement and wage polarization, widening the gap between high-skilled and low-skilled workers. Moreover, algorithmic biases embedded in AI systems can perpetuate discrimination and inequity, particularly against marginalized communities.\n\nHowever, alongside these challenges, AI also presents opportunities to address inequality and promote inclusivity. AI-powered innovations have the potential to enhance efficiency, accessibility, and affordability in sectors such as healthcare, education, and financial services, thereby reducing disparities in access to essential resources and opportunities. Additionally, initiatives focused on ethical AI development and responsible AI governance can mitigate the negative impacts of AI on inequality by promoting fairness, transparency, and accountability in algorithmic decision-making processes.\n\nIn conclusion, while AI has the potential to both exacerbate and mitigate inequality, its ultimate impact depends on the choices we make in designing, deploying, and governing AI systems. By prioritizing equity, social justice, and human welfare in AI development and implementation, we can harness the transformative power of AI to create a more equitable and inclusive society.\n",
    "doi": "10.32388/7hwuz2",
    "url": "https://www.semanticscholar.org/paper/37ef7632480b672100aa0305addbdb4f743b5b7b",
    "pdf_url": "",
    "venue": "Qeios",
    "citation_count": 32,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586799"
  },
  {
    "source": "semantic_scholar",
    "source_id": "1366dd0cf93e9e4ba85e7683fe45869e225d336e",
    "title": "Predictive Analytics in Human Resources Management: Evaluating AIHR\u2019s Role in Talent Retention",
    "authors": [
      "Ana Maria C\u0103vescu",
      "Nirvana Popescu"
    ],
    "year": 2025,
    "abstract": "This study explores the role of artificial intelligence (AI) in human resource management (HRM), with a focus on recruitment, employee retention, and performance optimization. Through a PRISMA-based systematic literature review, the paper examines many machine learning algorithms including XGBoost, SVM, random forest, and linear regression in decision-making related to employee-attrition prediction and talent management. The findings suggest that these technologies can automate HR processes, reduce bias, and personalize employee experiences. However, the implementation of AI in HRM also presents challenges, including data privacy concerns, algorithmic bias, and organizational resistance. To address these obstacles, the study highlights the importance of adopting ethical AI frameworks, ensuring transparency in decision-making, and developing effective integration strategies. Future research should focus on improving explainability, minimizing algorithmic bias, and promoting fairness in AI-driven HR practices.",
    "doi": "10.3390/appliedmath5030099",
    "url": "https://www.semanticscholar.org/paper/1366dd0cf93e9e4ba85e7683fe45869e225d336e",
    "pdf_url": "",
    "venue": "AppliedMath",
    "citation_count": 7,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586802"
  },
  {
    "source": "semantic_scholar",
    "source_id": "e8b8647f4b2a4b14fc791d1ba57edb77f21d9c19",
    "title": "Factors influencing human trust in intelligent built environment systems",
    "authors": [
      "Amir Behzadan",
      "Armita Dabiri"
    ],
    "year": 2025,
    "abstract": null,
    "doi": "10.1007/s43681-025-00813-6",
    "url": "https://www.semanticscholar.org/paper/e8b8647f4b2a4b14fc791d1ba57edb77f21d9c19",
    "pdf_url": "",
    "venue": "AI and Ethics",
    "citation_count": 1,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586806"
  },
  {
    "source": "semantic_scholar",
    "source_id": "bc95c1c9f64b40eec29592229a81d51419383ab1",
    "title": "Should Artificial Intelligence be used to support clinical ethical decision-making? A systematic review of reasons",
    "authors": [
      "Lasse Benzinger",
      "F. Ursin",
      "Wolf-Tilo Balke",
      "T. Kacprowski",
      "Sabine Salloch"
    ],
    "year": 2023,
    "abstract": "Background Healthcare providers have to make ethically complex clinical decisions which may be a source of stress. Researchers have recently introduced Artificial Intelligence (AI)-based applications to assist in clinical ethical decision-making. However, the use of such tools is controversial. This review aims to provide a comprehensive overview of the reasons given in the academic literature for and against their use. Methods PubMed, Web of Science, Philpapers.org and Google Scholar were searched for all relevant publications. The resulting set of publications was title and abstract screened according to defined inclusion and exclusion criteria, resulting in 44 papers whose full texts were analysed using the Kuckartz method of qualitative text analysis. Results Artificial Intelligence might increase patient autonomy by improving the accuracy of predictions and allowing patients to receive their preferred treatment. It is thought to increase beneficence by providing reliable information, thereby, supporting surrogate decision-making. Some authors fear that reducing ethical decision-making to statistical correlations may limit autonomy. Others argue that AI may not be able to replicate the process of ethical deliberation because it lacks human characteristics. Concerns have been raised about issues of justice, as AI may replicate existing biases in the decision-making process. Conclusions The prospective benefits of using AI in clinical ethical decision-making are manifold, but its development and use should be undertaken carefully to avoid ethical pitfalls. Several issues that are central to the discussion of Clinical Decision Support Systems, such as justice, explicability or human\u2013machine interaction, have been neglected in the debate on AI for clinical ethics so far. Trial registration This review is registered at Open Science Framework ( https://osf.io/wvcs9 ).",
    "doi": "10.1186/s12910-023-00929-6",
    "url": "https://www.semanticscholar.org/paper/bc95c1c9f64b40eec29592229a81d51419383ab1",
    "pdf_url": "https://bmcmedethics.biomedcentral.com/counter/pdf/10.1186/s12910-023-00929-6",
    "venue": "BMC Medical Ethics",
    "citation_count": 49,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586810"
  },
  {
    "source": "semantic_scholar",
    "source_id": "baee16e76433605cdd093b939e5915a0e902bcef",
    "title": "Environmentally sustainable development and use of artificial intelligence in health care",
    "authors": [
      "C. Richie"
    ],
    "year": 2022,
    "abstract": "Abstract Artificial intelligence (AI) can transform health care by delivering medical services to underserved areas, while also filling gaps in health care provider availability. However, AI may also lead to patient harm due to fatal glitches in robotic surgery, bias in diagnosis, or dangerous recommendations. Despite concerns ethicists have identified in the use of AI in health care, the most significant consideration ought not be vulnerabilities in the software, but the environmental impact of AI. Health care emits a significant amount of carbon in many countries. As AI becomes an essential part of health care, ethical reflection must include the potential to negatively impact the environment. As such, this article will first overview the carbon emissions in health care. It will, second, offer five reasons why carbon calculations are insufficient to address sustainability in health care. Third, the article will derive normative concepts from the goals of medicine, the principles of biomedical ethics, and green bioethics\u2014the very locus in which AI in health care sits\u2014to propose health, justice, and resource conservation as criteria for sustainable AI in health care. In the fourth and final part of the article, examples of sustainable and unsustainable development and use of AI in health care will be evaluated through the three\u2010fold lens of health, justice, and resource conservation. With various ethical approaches to AI in health care, the imperative for environmental sustainability must be underscored, lest carbon emissions continue to increase, harming people and planet alike.",
    "doi": "10.1111/bioe.13018",
    "url": "https://www.semanticscholar.org/paper/baee16e76433605cdd093b939e5915a0e902bcef",
    "pdf_url": "https://repository.tudelft.nl/file/File_8339643d-3753-4ac5-8131-3cc562ebf948",
    "venue": "Bioethics",
    "citation_count": 54,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586813"
  },
  {
    "source": "semantic_scholar",
    "source_id": "2cc5941e5effff3243702f5ab318ee1336442eed",
    "title": "Feeling Machines: Ethics, Culture, and the Rise of Emotional AI",
    "authors": [
      "Vivek Chavan",
      "Arsen Cenaj",
      "Shuyuan Shen",
      "A. Bar",
      "Srishti Binwani",
      "Tommaso Del Becaro",
      "Marius Funk",
      "Lynn Greschner",
      "Roberto Hung",
      "Stina Klein",
      "Romina Kleiner",
      "Stefanie Krause",
      "Sylwia Olbrych",
      "Vishvapalsinhji Ramsinh Parmar",
      "Jaleh Sarafraz",
      "Daria Soroko",
      "Daksitha Withanage Don",
      "Chang Zhou",
      "Hoang Thuy Duong Vu",
      "Parastoo Semnani",
      "Daniel Weinhardt",
      "Elisabeth Andr\u00e9",
      "Jorg Kruger",
      "Xavier Fresquet"
    ],
    "year": 2025,
    "abstract": "This paper explores the growing presence of emotionally responsive artificial intelligence through a critical and interdisciplinary lens. Bringing together the voices of early-career researchers from multiple fields, it explores how AI systems that simulate or interpret human emotions are reshaping our interactions in areas such as education, healthcare, mental health, caregiving, and digital life. The analysis is structured around four central themes: the ethical implications of emotional AI, the cultural dynamics of human-machine interaction, the risks and opportunities for vulnerable populations, and the emerging regulatory, design, and technical considerations. The authors highlight the potential of affective AI to support mental well-being, enhance learning, and reduce loneliness, as well as the risks of emotional manipulation, over-reliance, misrepresentation, and cultural bias. Key challenges include simulating empathy without genuine understanding, encoding dominant sociocultural norms into AI systems, and insufficient safeguards for individuals in sensitive or high-risk contexts. Special attention is given to children, elderly users, and individuals with mental health challenges, who may interact with AI in emotionally significant ways. However, there remains a lack of cognitive or legal protections which are necessary to navigate such engagements safely. The report concludes with ten recommendations, including the need for transparency, certification frameworks, region-specific fine-tuning, human oversight, and longitudinal research. A curated supplementary section provides practical tools, models, and datasets to support further work in this domain.",
    "doi": "10.48550/arXiv.2506.12437",
    "url": "https://www.semanticscholar.org/paper/2cc5941e5effff3243702f5ab318ee1336442eed",
    "pdf_url": "",
    "venue": "arXiv.org",
    "citation_count": 3,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586819"
  },
  {
    "source": "semantic_scholar",
    "source_id": "f5ecc97c1bdaa2a4bce0efe2fb029482150be1a4",
    "title": "Explainable AI-Driven Decision Support for Social Benefit Optimization: Improving Fairness, Reliability, and Managerial Oversight",
    "authors": [
      "Shakun Garg",
      "Amit Verma"
    ],
    "year": 2026,
    "abstract": "It has become more necessary to have fair and transparent distribution of social benefits due to the increasing dependence of governments and organizations on data-driven decision systems. However, traditional AI platforms tend to be black-box, so interpretability is usually limited, and it allows biases to exist that compromise trust and undermine managerial control. To overcome these issues, the present paper introduces a proposal of an explainable artificial intelligence-based decision support system to improve fairness, reliability, and policy compliance in the workflow of social-benefit distribution. Its approach combines interpretable prediction modelling, equity-sensitive modifications, uncertainty estimation, and human-in-the-loop oversight and places it into one pipeline. Quantitative analysis of synthetic and real-world welfare data demonstrates that the proposed structure removes demographic bias by 22.7% and decision under perturbations by 18.4 and greater explanation fidelity by 31.2 than non-explainable bases do. The system further enhances the consistency of the allocation by 17.5% and reduces the risk of policy-violation by 14.9 %, and at the same time, it sustains the competitive predictive accuracy. As experimental findings indicate, there might be not only the higher quality of generated balance and credible recommendations of benefits but the enhanced managerial control due to the transparency of decision rationales and audit-traceable procedures. The results emphasize the usefulness of explainable and decision-aware AI systems in facilitating socially responsible and accountable decision making towards the administration of the public good.",
    "doi": "10.63503/j.ijaimd.2025.195",
    "url": "https://www.semanticscholar.org/paper/f5ecc97c1bdaa2a4bce0efe2fb029482150be1a4",
    "pdf_url": "",
    "venue": "International Journal on Engineering Artificial Intelligence Management, Decision Support, and Policies",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586823"
  },
  {
    "source": "semantic_scholar",
    "source_id": "686b225718e76544cbf8472dcf85a587088b66c8",
    "title": "Navigating Ethical Challenges and Biases in Generative AI: Ensuring Trust and Fairness in B2B Sales Interactions and Decision-Making",
    "authors": [
      "Venkata Tadi"
    ],
    "year": 2024,
    "abstract": "The integration of generative artificial intelligence (AI) in business-to-business (B2B) sales processes offers significant opportunities for enhanced efficiency, personalization, and predictive capabilities. However, these advancements come with substantial ethical challenges and risks of biases that can undermine trust and fairness in AI-driven interactions. This paper explores the ethical landscape of generative AI in B2B sales, focusing on data privacy, security, transparency, accountability, and informed consent. It examines the sources of bias in AI algorithms, their impact on customer engagement and satisfaction, and the strategies to mitigate these biases. Through a comprehensive review of current literature and case studies, this research highlights the importance of building and maintaining trust in AI systems and ensuring fair treatment of all customers. Insights from industry leaders and proposed future research directions emphasize the need for continuous adaptation and learning in AI ethics. The findings underscore the critical role of ethical AI practices in fostering sustainable and trustworthy B2B sales environments. This paper aims to contribute to the development of ethical frameworks and guidelines that support fair and transparent AI systems, ensuring that the benefits of AI are realized without compromising ethical standards.",
    "doi": "10.47363/jaicc/2024(3)e104",
    "url": "https://www.semanticscholar.org/paper/686b225718e76544cbf8472dcf85a587088b66c8",
    "pdf_url": "",
    "venue": "Journal of Artificial Intelligence &amp; Cloud Computing",
    "citation_count": 3,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586827"
  },
  {
    "source": "semantic_scholar",
    "source_id": "be10e806afc9f0fd1fddaae855e7e503b1eaca89",
    "title": "The cyclical ethical effects of using artificial intelligence in education",
    "authors": [
      "E. Dieterle",
      "C. Dede",
      "Michael Walker"
    ],
    "year": 2022,
    "abstract": "Our synthetic review of the relevant and related literatures on the ethics and effects of using AI in education reveals five qualitatively distinct and interrelated divides associated with access, representation, algorithms, interpretations, and citizenship. We open our analysis by probing the ethical effects of algorithms and how teams of humans can plan for and mitigate bias when using AI tools and techniques to model and inform instructional decisions and predict learning outcomes. We then analyze the upstream divides that feed into and fuel the algorithmic divide, first investigating access (who does and does not have access to the hardware, software, and connectivity necessary to engage with AI-enhanced digital learning tools and platforms) and then representation (the factors making data either representative of the total population or over-representative of a subpopulation\u2019s preferences, thereby preventing objectivity and biasing understandings and outcomes). After that, we analyze the divides that are downstream of the algorithmic divide associated with interpretation (how learners, educators, and others understand the outputs of algorithms and use them to make decisions) and citizenship (how the other divides accumulate to impact interpretations of data by learners, educators, and others, in turn influencing behaviors and, over time, skills, culture, economic, health, and civic outcomes). At present, lacking ongoing reflection and action by learners, educators, educational leaders, designers, scholars, and policymakers, the five divides collectively create a vicious cycle and perpetuate structural biases in teaching and learning. However, increasing human responsibility and control over these divides can create a virtuous cycle that improves diversity, equity, and inclusion in education. We conclude the article by looking forward and discussing ways to increase educational opportunity and effectiveness for all by mitigating bias through a cycle of progressive improvement.",
    "doi": "10.1007/s00146-022-01497-w",
    "url": "https://www.semanticscholar.org/paper/be10e806afc9f0fd1fddaae855e7e503b1eaca89",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s00146-022-01497-w.pdf",
    "venue": "Ai & Society",
    "citation_count": 78,
    "fields_of_study": [
      "Computer Science",
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586831"
  },
  {
    "source": "semantic_scholar",
    "source_id": "87e67360dd19d2ce61af795efed9547c791fd7dd",
    "title": "Improving Fairness of Automated Chest Radiograph Diagnosis by Contrastive Learning.",
    "authors": [
      "Mingquan Lin",
      "Tianhao Li",
      "Zhaoyi Sun",
      "G. Holste",
      "Ying Ding",
      "Fei Wang",
      "George Shih",
      "Yifan Peng"
    ],
    "year": 2024,
    "abstract": "\"Just Accepted\" papers have undergone full peer review and have been accepted for publication in Radiology: Artificial Intelligence. This article will undergo copyediting, layout, and proof review before it is published in its final version. Please note that during production of the final copyedited article, errors may be discovered which could affect the content. Purpose To develop an artificial intelligence model that utilizes supervised contrastive learning to minimize bias in chest radiograph (CXR) diagnosis. Materials and Methods In this retrospective study, the proposed method was evaluated on two datasets: the Medical Imaging and Data Resource Center (MIDRC) dataset with 77,887 CXRs from 27,796 patients collected as of April 20, 2023 for COVID-19 diagnosis, and the NIH Chest x-ray 14 (NIH-CXR) dataset with 112,120 CXRs from 30,805 patients collected between 1992 and 2015. In the NIH-CXR dataset, thoracic abnormalities included atelectasis, cardiomegaly, effusion, infiltration, mass, nodule, pneumonia, pneumothorax, consolidation, edema, emphysema, fibrosis, pleural thickening, or hernia. The proposed method utilized supervised contrastive learning with carefully selected positive and negative samples to generate fair image embeddings, which were fine-tuned for subsequent tasks to reduce bias in CXR diagnosis. The method was evaluated using the marginal area under the receiver operating characteristic curve (AUC) difference (\u0394mAUC). Results The proposed model showed a significant decrease in bias across all subgroups compared with the baseline models, as evidenced by a paired T-test (P < .001). The \u0394mAUCs obtained by the proposed method were 0.01 (95% CI, 0.01-0.01), 0.21 (95% CI, 0.21-0.21), and 0.10 (95% CI, 0.10-0.10) for sex, race, and age subgroups, respectively, on MIDRC, and 0.01 (95% CI, 0.01-0.01) and 0.05 (95% CI, 0.05-0.05) for sex and age subgroups, respectively, on NIH-CXR. Conclusion Employing supervised contrastive learning can mitigate bias in CXR diagnosis, addressing concerns of fairness and reliability in deep learning-based diagnostic methods. \u00a9RSNA, 2024.",
    "doi": "10.1148/ryai.230342",
    "url": "https://www.semanticscholar.org/paper/87e67360dd19d2ce61af795efed9547c791fd7dd",
    "pdf_url": "",
    "venue": "Radiology: Artificial Intelligence",
    "citation_count": 6,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586836"
  },
  {
    "source": "semantic_scholar",
    "source_id": "0ecd310576a096e494af572ed607ecce8fa41d65",
    "title": "Implementing ethics into artificial intelligence: a contribution, from a legal perspective, to the development of an AI governance regime",
    "authors": [
      "A. Walz",
      "Kay Firth-Butterfield"
    ],
    "year": 2019,
    "abstract": null,
    "doi": null,
    "url": "https://www.semanticscholar.org/paper/0ecd310576a096e494af572ed607ecce8fa41d65",
    "pdf_url": "",
    "venue": "",
    "citation_count": 27,
    "fields_of_study": [
      "Political Science"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586840"
  },
  {
    "source": "semantic_scholar",
    "source_id": "2a18c5b720906b39133f3ef2503c6695be4e3f9a",
    "title": "Towards Risk-Free Trustworthy Artificial Intelligence: Significance and Requirements",
    "authors": [
      "Laith Alzubaidi",
      "Aiman Al-Sabaawi",
      "Jinshuai Bai",
      "Ammar Dukhan",
      "Ahmed H. Alkenani",
      "Ahmed Al-Asadi",
      "Haider A. Alwzwazy",
      "M. Manoufali",
      "M. Fadhel",
      "A. Albahri",
      "Catarina Moreira",
      "Chun Ouyang",
      "Jinglan Zhang",
      "Jos\u00e9 I. Santamar\u00eda",
      "Asma Salhi",
      "Freek Hollman",
      "Ashish Gupta",
      "Ye Duan",
      "T. Rabczuk",
      "Amin Abbosh",
      "Yuantong Gu"
    ],
    "year": 2023,
    "abstract": "Given the tremendous potential and influence of artificial intelligence (AI) and algorithmic decision-making (DM), these systems have found wide-ranging applications across diverse fields, including education, business, healthcare industries, government, and justice sectors. While AI and DM offer significant benefits, they also carry the risk of unfavourable outcomes for users and society. As a result, ensuring the safety, reliability, and trustworthiness of these systems becomes crucial. This article aims to provide a comprehensive review of the synergy between AI and DM, focussing on the importance of trustworthiness. The review addresses the following four key questions, guiding readers towards a deeper understanding of this topic: (i) why do we need trustworthy AI? (ii) what are the requirements for trustworthy AI? In line with this second question, the key requirements that establish the trustworthiness of these systems have been explained, including explainability, accountability, robustness, fairness, acceptance of AI, privacy, accuracy, reproducibility, and human agency, and oversight. (iii) how can we have trustworthy data? and (iv) what are the priorities in terms of trustworthy requirements for challenging applications? Regarding this last question, six different applications have been discussed, including trustworthy AI in education, environmental science, 5G-based IoT networks, robotics for architecture, engineering and construction, financial technology, and healthcare. The review emphasises the need to address trustworthiness in AI systems before their deployment in order to achieve the AI goal for good. An example is provided that demonstrates how trustworthy AI can be employed to eliminate bias in human resources management systems. The insights and recommendations presented in this paper will serve as a valuable guide for AI researchers seeking to achieve trustworthiness in their applications.",
    "doi": "10.1155/2023/4459198",
    "url": "https://www.semanticscholar.org/paper/2a18c5b720906b39133f3ef2503c6695be4e3f9a",
    "pdf_url": "https://downloads.hindawi.com/journals/ijis/2023/4459198.pdf",
    "venue": "International Journal of Intelligent Systems",
    "citation_count": 60,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586845"
  },
  {
    "source": "semantic_scholar",
    "source_id": "fda514d275ca73a51d72c325ab2108564bbc502f",
    "title": "Ethics of artificial intelligence in radiology: summary of the joint European and North American multisociety statement",
    "authors": [
      "J. R. Geis",
      "A. Brady",
      "Carol C. Wu",
      "Jack Spencer",
      "E. Ranschaert",
      "J. Jaremko",
      "S. Langer",
      "A. B. Kitts",
      "J. Birch",
      "William F. Shields",
      "R. V. D. H. V. Genderen",
      "E. Kotter",
      "J. W. Gichoya",
      "J. W. Gichoya",
      "T. Cook",
      "Matthew B. Morgan",
      "A. Tang",
      "Nabile M. Safdar",
      "M. Kohli"
    ],
    "year": 2019,
    "abstract": "This is a condensed summary of an international multisociety statement on ethics of artificial intelligence (AI) in radiology produced by the ACR, European Society of Radiology, RSNA, Society for Imaging Informatics in Medicine, European Society of Medical Imaging Informatics, Canadian Association of Radiologists, and American Association of Physicists in Medicine.AI has great potential to increase efficiency and accuracy throughout radiology, but also carries inherent pitfalls and biases. Widespread use of AI-based intelligent and autonomous systems in radiology can increase the risk of systemic errors with high consequence, and highlights complex ethical and societal issues. Currently, there is little experience using AI for patient care in diverse clinical settings. Extensive research is needed to understand how to best deploy AI in clinical practice.This statement highlights our consensus that ethical use of AI in radiology should promote well-being, minimize harm, and ensure that the benefits and harms are distributed among stakeholders in a just manner. We believe AI should respect human rights and freedoms, including dignity and privacy. It should be designed for maximum transparency and dependability. Ultimate responsibility and accountability for AI remains with its human designers and operators for the foreseeable future.The radiology community should start now to develop codes of ethics and practice for AI which promote any use that helps patients and the common good and should block use of radiology data and algorithms for financial gain without those two attributes.",
    "doi": "10.1186/s13244-019-0785-8",
    "url": "https://www.semanticscholar.org/paper/fda514d275ca73a51d72c325ab2108564bbc502f",
    "pdf_url": "https://insightsimaging.springeropen.com/track/pdf/10.1186/s13244-019-0785-8",
    "venue": "Insights into Imaging",
    "citation_count": 245,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586851"
  },
  {
    "source": "semantic_scholar",
    "source_id": "5bc0d85f950bb2b9126f431acf84a07ba598da9b",
    "title": "Artificial Intelligence of Internet of Things (AIoT) Technology-based Law Enforcement Process",
    "authors": [
      "Muhammad Iqbal Tarigan",
      "Noviyanti Wulandari Sitepu"
    ],
    "year": 2023,
    "abstract": "Technological developments are increasingly developing in all fields, unstoppable in the area of law and the role of this IoT technology in solving legal problems, considering Society 5.0, which focuses on building a humane and prosperous society, especially people in Indonesia. And the role of IoT on the legal side is expected to be the answer for an appropriate and fair law enforcement process. IoT Technology collaboration with all sectors of human life, for example, legal, social and economic, as well as natural resource factors and human resources, are still needed. IoT is expected to be a tool to achieve a level of accuracy, real-time, fast, and stability. In the era of Society 5.0, all aspects were asked to be fast so as not to be left behind in any sector; the ability factor of the human being, namely human resources, also determines whether a matter or case can be appropriately resolved. This article is one of the review articles on the role of IoT in law enforcement. Some parameters within the Internet of Things form Artificial Intelligence, Deep Learning, Big Data, and Machine Learning. Solutions with AI can be seen in the lie detection system.",
    "doi": "10.31763/iota.v3i1.577",
    "url": "https://www.semanticscholar.org/paper/5bc0d85f950bb2b9126f431acf84a07ba598da9b",
    "pdf_url": "https://pubs.ascee.org/index.php/iota/article/download/577/172",
    "venue": "Internet of Things and Artificial Intelligence Journal",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586855"
  },
  {
    "source": "semantic_scholar",
    "source_id": "a328514f922f3bec2ad163218985cbe3cc532d88",
    "title": "Legal Framework for Regulating AI in Smart Cities: Privacy, Surveillance, and Ethics",
    "authors": [
      "Muath Mohammed Alashqar",
      "Ahmed F. S. Abulehia",
      "Ahmad Ali Atieh",
      "Mo\u2019men Hani Mahmoud",
      "M. Alzubi"
    ],
    "year": 2025,
    "abstract": "The swift incorporation of Artificial Intelligence (AI) in smart cities markedly improves urban administration, enriches public services, and optimizes resource distribution. This technology-driven progress presents significant legal and ethical challenges, especially around data privacy, surveillance, and liability. This article assesses existing legal frameworks regulating AI in smart cities, highlighting data protection laws like GDPR, ethical implications in automated public services, as well as liability for AI-related malfunctions. The results emphasize the necessity of governmental supervision, transparency, and community involvement to guarantee that AI is utilized responsibly and conforms to human rights standards while promoting innovation. Practical recommendations are offered for policymakers to develop balanced frameworks that both enhance technical progress and protect the public's trust.",
    "doi": "10.1109/AI2E64943.2025.10983107",
    "url": "https://www.semanticscholar.org/paper/a328514f922f3bec2ad163218985cbe3cc532d88",
    "pdf_url": "",
    "venue": "2025 International Conference for Artificial Intelligence, Applications, Innovation and Ethics (AI2E)",
    "citation_count": 6,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586859"
  },
  {
    "source": "semantic_scholar",
    "source_id": "bf823a8b26bba29ff976ee85167ec113f1cdf93b",
    "title": "Ethical review of AI health research: An exploratory qualitative study on experiences and challenges of research ethics committees in Uganda",
    "authors": [
      "Sylvia Nabukenya",
      "William Wasswa",
      "Adelline Twimukye",
      "E. Mwaka"
    ],
    "year": 2025,
    "abstract": "The use of artificial intelligence (AI) in health research of both communicable and non-communicable diseases has shown an improvement in diagnosis, reduced researchers\u2019 workload, and facilitated real-time data analysis. However, several ethical concerns on public trust, privacy, accountability and fairness regarding access to AI have been pointed out to expose the users of AI to harm. Whereas AI technologies continue to grow rapidly in health research, there is limited knowledge on research ethics committees\u2019 (REC) current practices and challenges experienced when reviewing AI health research in low resource settings like Uganda. This study examined the current practices and challenges experienced by ethics committees during the review of AI health research. We adopted a qualitative exploratory approach, where in-depth interviews were conducted with 12 REC members and 6 REC administrators between May and September 2024. A thematic approach was used to analyze the results. Three themes merged from this data including current practices of RECs, challenges experienced by REC members when reviewing AI health research proposals, and the proposed solutions to the mentioned challenges. Of interest, respondents expressed concerns of limited training and expertise in field of AI, inadequate guiding and reference tools, and unreasonable demands from researchers. Therefore, it is essential to build capacity for REC members and develop comprehensive guidelines, and standard operating procedures for efficient and constructive feedback to researchers.",
    "doi": "10.1177/17470161251370400",
    "url": "https://www.semanticscholar.org/paper/bf823a8b26bba29ff976ee85167ec113f1cdf93b",
    "pdf_url": "",
    "venue": "Research Ethics",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586862"
  },
  {
    "source": "semantic_scholar",
    "source_id": "85a2a958cb6992445fab7dc3f76dc29ca1238843",
    "title": "Trust in Artificial Intelligence\u2013Based Clinical Decision Support Systems Among Health Care Workers: Systematic Review",
    "authors": [
      "H. Tun",
      "H. Rahman",
      "Lin Naing",
      "O. A. Malik"
    ],
    "year": 2024,
    "abstract": "Abstract Background Artificial intelligence\u2013based clinical decision support systems (AI-CDSSs) have enhanced personalized medicine and improved the efficiency of health care workers. Despite these opportunities, trust in these tools remains a critical factor for their successful integration into practice. Existing research lacks synthesized insights and actionable recommendations to guide the development of AI-CDSSs that foster trust among health care workers. Objective This systematic review aims to identify and synthesize key factors that influence health care workers\u2019 trust in AI-CDSSs and to provide actionable recommendations for enhancing their trust in these systems. Methods We conducted a systematic review of published studies from January 2020 to November 2024, retrieved from PubMed, Scopus, and Google Scholar. Inclusion criteria focused on studies that examined health care workers\u2019 perceptions, experiences, and trust in AI-CDSSs. Studies in non\u2013English languages and those unrelated to health care settings were excluded. Two independent reviewers followed the Cochrane Collaboration Handbook and PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) 2020 guidelines. Analysis was conducted using a developed data charter. The Critical Appraisal Skills Programme tool was applied to assess the quality of the included studies and to evaluate the risk of bias, ensuring a rigorous and systematic review process. Results A total of 27 studies met the inclusion criteria, involving diverse health care workers, predominantly in hospitalized settings. Qualitative methods were the most common (n=16, 59%), with sample sizes ranging from small focus groups to cohorts of over 1000 participants. Eight key themes emerged as pivotal in improving health care workers\u2019 trust in AI-CDSSs: (1) System Transparency, emphasizing the need for clear and interpretable AI; (2) Training and Familiarity, highlighting the importance of knowledge sharing and user education; (3) System Usability, focusing on effective integration into clinical workflows; (4) Clinical Reliability, addressing the consistency and accuracy of system performance; (5) Credibility and Validation, referring to how well the system performs across diverse clinical contexts; (6) Ethical Consideration, examining medicolegal liability, fairness, and adherence to ethical standards;(7) Human Centric Design, pioritizing patient centered approaches; (8) Customization and Control, highlighting the need to tailor tools to specific clinical needs while preserving health care providers\u2019 decision-making autonomy. Barriers to trust included algorithmic opacity, insufficient training, and ethical challenges, while enabling factors for health care workers\u2019 trust in AI-CDSS tools were transparency, usability, and clinical reliability. Conclusions The findings highlight the need for explainable AI models, comprehensive training, stakeholder involvement, and human-centered design to foster health care workers\u2019 trust in AI-CDSSs. Although the heterogeneity of study designs and lack of specific data limit further analysis, this review bridges existing gaps by identifying key themes that support trust in AI-CDSSs. It also recommends that future research include diverse demographics, cross-cultural perspectives, and contextual differences in trust across various health care professions.",
    "doi": "10.2196/69678",
    "url": "https://www.semanticscholar.org/paper/85a2a958cb6992445fab7dc3f76dc29ca1238843",
    "pdf_url": "https://doi.org/10.2196/69678",
    "venue": "Journal of Medical Internet Research",
    "citation_count": 20,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586866"
  },
  {
    "source": "semantic_scholar",
    "source_id": "3ec72020d88f68fa9102192502b80d964678eea8",
    "title": "Ethics of Artificial Intelligence in Radiology: Summary of the Joint European and North American Multisociety Statement.",
    "authors": [
      "MD \u2022 J. Raymond Geis",
      "M. F. \u2022. Adrian P. Brady",
      "MD \u2022 Carol C. Wu",
      "PhD \u2022 Jack Spencer",
      "MD Erik Ranschaert",
      "PhD \u2022 Jacob L. Jaremko",
      "P. \u2022. S. G. Md",
      "PhD \u2022 Andrea Borondy Kitts",
      "M. Ms",
      "M. M. M. \u2022. Elmar Kotter",
      "MBChB Judy Wawira Gichoya",
      "MS \u2022 Tessa S. Cook",
      "PhD \u2022 Matthew B. Morgan",
      "M. \u2022. A. Md",
      "M. \u2022. N. M. Md",
      "M. \u2022. M. Md"
    ],
    "year": 2019,
    "abstract": "This is a condensed summary of an international multisociety statement on ethics of artificial intelligence (AI) in radiology produced by the ACR, European Society of Radiology, RSNA, Society for Imaging Informatics in Medicine, European Society of Medical Imaging Informatics, Canadian Association of Radiologists, and American Association of Physicists in Medicine. AI has great potential to increase efficiency and accuracy throughout radiology, but it also carries inherent pitfalls and biases. Widespread use of AI-based intelligent and autonomous systems in radiology can increase the risk of systemic errors with high consequence and highlights complex ethical and societal issues. Currently, there is little experience using AI for patient care in diverse clinical settings. Extensive research is needed to understand how to best deploy AI in clinical practice. This statement highlights our consensus that ethical use of AI in radiology should promote well-being, minimize harm, and ensure that the benefits and harms are distributed among stakeholders in a just manner. We believe AI should respect human rights and freedoms, including dignity and privacy. It should be designed for maximum transparency and dependability. Ultimate responsibility and accountability for AI remains with its human designers and operators for the foreseeable future. The radiology community should start now to develop codes of ethics and practice for AI that promote any use that helps patients and the common good and should block use of radiology data and algorithms for financial gain without those two attributes. This article is a simultaneous joint publication in Radiology, Journal of the American College of Radiology, Canadian Association of Radiologists Journal, and Insights into Imaging. Published under a CC BY-NC-ND 4.0 license. Online supplemental material is available for this article.",
    "doi": "10.1148/radiol.2019191586",
    "url": "https://www.semanticscholar.org/paper/3ec72020d88f68fa9102192502b80d964678eea8",
    "pdf_url": "https://pubs.rsna.org/doi/pdf/10.1148/radiol.2019191586",
    "venue": "Radiology",
    "citation_count": 196,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586870"
  },
  {
    "source": "semantic_scholar",
    "source_id": "40c8d2478a3ec125b85e6d19296eab0f9d05feb7",
    "title": "Societal Issues Concerning the Application of Artificial Intelligence in Medicine",
    "authors": [
      "A. Vellido"
    ],
    "year": 2018,
    "abstract": "Background: Medicine is becoming an increasingly data-centred discipline and, beyond classical statistical approaches, artificial intelligence (AI) and, in particular, machine learning (ML) are attracting much interest for the analysis of medical data. It has been argued that AI is experiencing a fast process of commodification. This characterization correctly reflects the current process of industrialization of AI and its reach into society. Therefore, societal issues related to the use of AI and ML should not be ignored any longer and certainly not in the medical domain. These societal issues may take many forms, but they all entail the design of models from a human-centred perspective, incorporating human-relevant requirements and constraints. In this brief paper, we discuss a number of specific issues affecting the use of AI and ML in medicine, such as fairness, privacy and anonymity, explainability and interpretability, but also some broader societal issues, such as ethics and legislation. We reckon that all of these are relevant aspects to consider in order to achieve the objective of fostering acceptance of AI- and ML-based technologies, as well as to comply with an evolving legislation concerning the impact of digital technologies on ethically and privacy sensitive matters. Our specific goal here is to reflect on how all these topics affect medical applications of AI and ML. This paper includes some of the contents of the \u201c2nd Meeting of Science and Dialysis: Artificial Intelligence,\u201d organized in the Bellvitge University Hospital, Barcelona, Spain. Summary and Key Messages: AI and ML are attracting much interest from the medical community as key approaches to knowledge extraction from data. These approaches are increasingly colonizing ambits of social impact, such as medicine and healthcare. Issues of social relevance with an impact on medicine and healthcare include (although they are not limited to) fairness, explainability, privacy, ethics and legislation.",
    "doi": "10.1159/000492428",
    "url": "https://www.semanticscholar.org/paper/40c8d2478a3ec125b85e6d19296eab0f9d05feb7",
    "pdf_url": "https://www.karger.com/Article/Pdf/492428",
    "venue": "Kidney Diseases",
    "citation_count": 97,
    "fields_of_study": [
      "Sociology",
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586874"
  },
  {
    "source": "semantic_scholar",
    "source_id": "2275d507e38f03c2147983b20be75f69950c5340",
    "title": "Ethics in international HRD: examining conversational AI and HR chatbots",
    "authors": [
      "Natalie Bidnick Andreas"
    ],
    "year": 2024,
    "abstract": "\nPurpose\nThe integration of artificial intelligence (AI) technologies like conversational AI and HR chatbots in international human resource development (HRD) presents both productivity benefits and ethical challenges. This study aims to examine the ethical dimensions of AI-driven HR chatbots, emphasizing the need for fairness, autonomy and nondiscrimination. It discusses inherent biases in AI systems and addresses linguistic, cultural and accessibility issues. The paper advocates for a comprehensive risk assessment approach to guide ethical integration, proposing a \u201crisk management by design\u201d framework. By embracing ethical principles and robust risk management strategies, organizations can navigate AI-driven HR technologies while upholding fairness and equity in global workforce management.\n\n\nDesign/methodology/approach\nSystematic literature review.\n\n\nFindings\nThe paper advocates for a comprehensive risk assessment approach to guide ethical integration, proposing a \u201crisk management by design\u201d framework.\n\n\nPractical implications\nBy embracing ethical principles and robust risk management strategies, organizations can navigate AI-driven HR technologies while upholding fairness and equity in global workforce management.\n\n\nOriginality/value\nThis study explores the intricate ethical landscape surrounding AI-driven HR chatbots, spotlighting the imperatives of fairness, autonomy, and nondiscrimination. Uncovering biases inherent in AI systems, it addresses linguistic, cultural, and accessibility concerns. Proposing a pioneering \u201crisk management by design\u201d framework, the study advocates for a holistic approach to ethical integration, ensuring organizations navigate the complexities of AI-driven HR technologies while prioritizing fairness and equity in global workforce management.\n",
    "doi": "10.1108/shr-03-2024-0018",
    "url": "https://www.semanticscholar.org/paper/2275d507e38f03c2147983b20be75f69950c5340",
    "pdf_url": "",
    "venue": "Strategic HR Review",
    "citation_count": 5,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586877"
  },
  {
    "source": "semantic_scholar",
    "source_id": "653ddda1db304633a1ad4f7ac062e2295a077b59",
    "title": "Embryo selection through artificial intelligence versus embryologists: a systematic review",
    "authors": [
      "M. Salih",
      "C. Austin",
      "R. Warty",
      "C. Tiktin",
      "D. Rolnik",
      "M. Momeni",
      "H. Rezatofighi",
      "S. Reddy",
      "V. Smith",
      "B. Vollenhoven",
      "F. Horta"
    ],
    "year": 2023,
    "abstract": "Abstract STUDY QUESTION What is the present performance of artificial intelligence (AI) decision support during embryo selection compared to the standard embryo selection by embryologists? SUMMARY ANSWER AI consistently outperformed the clinical teams in all the studies focused on embryo morphology and clinical outcome prediction during embryo selection assessment. WHAT IS KNOWN ALREADY The ART success rate is \u223c30%, with a worrying trend of increasing female age correlating with considerably worse results. As such, there have been ongoing efforts to address this low success rate through the development of new technologies. With the advent of AI, there is potential for machine learning to be applied in such a manner that areas limited by human subjectivity, such as embryo selection, can be enhanced through increased objectivity. Given the potential of AI to improve IVF success rates, it remains crucial to review the performance between AI and embryologists during embryo selection. STUDY DESIGN, SIZE, DURATION The search was done across PubMed, EMBASE, Ovid Medline, and IEEE Xplore from 1 June 2005 up to and including 7 January 2022. Included articles were also restricted to those written in English. Search terms utilized across all databases for the study were: (\u2018Artificial intelligence\u2019 OR \u2018Machine Learning\u2019 OR \u2018Deep learning\u2019 OR \u2018Neural network\u2019) AND (\u2018IVF\u2019 OR \u2018in vitro fertili*\u2019 OR \u2018assisted reproductive techn*\u2019 OR \u2018embryo\u2019), where the character \u2018*\u2019 refers the search engine to include any auto completion of the search term. PARTICIPANTS/MATERIALS, SETTING, METHODS A literature search was conducted for literature relating to AI applications to IVF. Primary outcomes of interest were accuracy, sensitivity, and specificity of the embryo morphology grade assessments and the likelihood of clinical outcomes, such as clinical pregnancy after IVF treatments. Risk of bias was assessed using the Modified Down and Black Checklist. MAIN RESULTS AND THE ROLE OF CHANCE Twenty articles were included in this review. There was no specific embryo assessment day across the studies\u2014Day 1 until Day 5/6 of embryo development was investigated. The types of input for training AI algorithms were images and time-lapse (10/20), clinical information (6/20), and both images and clinical information (4/20). Each AI model demonstrated promise when compared to an embryologist\u2019s visual assessment. On average, the models predicted the likelihood of successful clinical pregnancy with greater accuracy than clinical embryologists, signifying greater reliability when compared to human prediction. The AI models performed at a median accuracy of 75.5% (range 59\u201394%) on predicting embryo morphology grade. The correct prediction (Ground Truth) was defined through the use of embryo images according to post embryologists\u2019 assessment following local respective guidelines. Using blind test datasets, the embryologists\u2019 accuracy prediction was 65.4% (range 47\u201375%) with the same ground truth provided by the original local respective assessment. Similarly, AI models had a median accuracy of 77.8% (range 68\u201390%) in predicting clinical pregnancy through the use of patient clinical treatment information compared to 64% (range 58\u201376%) when performed by embryologists. When both images/time-lapse and clinical information inputs were combined, the median accuracy by the AI models was higher at 81.5% (range 67\u201398%), while clinical embryologists had a median accuracy of 51% (range 43\u201359%). LIMITATIONS, REASONS FOR CAUTION The findings of this review are based on studies that have not been prospectively evaluated in a clinical setting. Additionally, a fair comparison of all the studies were deemed unfeasible owing to the heterogeneity of the studies, development of the AI models, database employed and the study design and quality. WIDER IMPLICATIONS OF THE FINDINGS AI provides considerable promise to the IVF field and embryo selection. However, there needs to be a shift in developers\u2019 perception of the clinical outcome from successful implantation towards ongoing pregnancy or live birth. Additionally, existing models focus on locally generated databases and many lack external validation. STUDY FUNDING/COMPETING INTERESTS This study was funded by Monash Data Future Institute. All authors have no conflicts of interest to declare. REGISTRATION NUMBER CRD42021256333",
    "doi": "10.1093/hropen/hoad031",
    "url": "https://www.semanticscholar.org/paper/653ddda1db304633a1ad4f7ac062e2295a077b59",
    "pdf_url": "https://academic.oup.com/hropen/article-pdf/2023/3/hoad031/51112668/hoad031.pdf",
    "venue": "Human Reproduction Open",
    "citation_count": 75,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586882"
  },
  {
    "source": "semantic_scholar",
    "source_id": "d3f67f5d1d8511446e61601084ee3c32bbf3a713",
    "title": "A Catalog of Fairness-Aware Practices in Machine Learning Engineering",
    "authors": [
      "Gianmario Voria",
      "Giulia Sellitto",
      "Carmine Ferrara",
      "Francesco Abate",
      "Andrea De Lucia",
      "F. Ferrucci",
      "Gemma Catolino",
      "Fabio Palomba"
    ],
    "year": 2024,
    "abstract": "Artificial Intelligence (AI)\u2019s widespread adoption in decision-making processes, particularly with the introduction of AI-based assistants, raises concerns about ethics and fairness, particularly regarding the treatment of sensitive features and potential discrimination against underrepresented groups. The software engineering community has responded by developing fairness-oriented metrics, empirical studies, and mitigation approaches. However, there remains a gap in understanding and categorizing practices for engineering fairness throughout the development lifecycle of AI-based solutions. This paper presents a catalog of practices for addressing fairness derived from a systematic mapping study. The study identifies and categorizes 28 practices from existing literature, mapping them onto different stages of the development lifecycle. From this catalog, actionable items and implications for both researchers and practitioners in software engineering were extracted. This work aims to provide a comprehensive resource for integrating fairness considerations into the development and deployment of AI systems, enhancing their reliability, accountability, and credibility.",
    "doi": "10.1145/3727967.3756824",
    "url": "https://www.semanticscholar.org/paper/d3f67f5d1d8511446e61601084ee3c32bbf3a713",
    "pdf_url": "",
    "venue": "EASE Companion",
    "citation_count": 5,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586886"
  },
  {
    "source": "semantic_scholar",
    "source_id": "cf0709674031ca3b2e3d514b7b1205df220edddf",
    "title": "Artificial Intelligence Applications to Measure Food and Nutrient Intakes: Scoping Review",
    "authors": [
      "Jiakun Zheng",
      "Junjie Wang",
      "Jing Shen",
      "R. An"
    ],
    "year": 2023,
    "abstract": "Background Accurate measurement of food and nutrient intake is crucial for nutrition research, dietary surveillance, and disease management, but traditional methods such as 24-hour dietary recalls, food diaries, and food frequency questionnaires are often prone to recall error and social desirability bias, limiting their reliability. With the advancement of artificial intelligence (AI), there is potential to overcome these limitations through automated, objective, and scalable dietary assessment techniques. However, the effectiveness and challenges of AI applications in this domain remain inadequately explored. Objective This study aimed to conduct a scoping review to synthesize existing literature on the efficacy, accuracy, and challenges of using AI tools in assessing food and nutrient intakes, offering insights into their current advantages and areas of improvement. Methods This review followed the PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses extension for Scoping Reviews) guidelines. A comprehensive literature search was conducted in 4 databases\u2014PubMed, Web of Science, Cochrane Library, and EBSCO\u2014covering publications from the databases\u2019 inception to June 30, 2023. Studies were included if they used modern AI approaches to assess food and nutrient intakes in human subjects. Results The 25 included studies, published between 2010 and 2023, involved sample sizes ranging from 10 to 38,415 participants. These studies used a variety of input data types, including food images (n=10), sound and jaw motion data from wearable devices (n=9), and text data (n=4), with 2 studies combining multiple input types. AI models applied included deep learning (eg, convolutional neural networks), machine learning (eg, support vector machines), and hybrid approaches. Applications were categorized into dietary intake assessment, food detection, nutrient estimation, and food intake prediction. Food detection accuracies ranged from 74% to 99.85%, and nutrient estimation errors varied between 10% and 15%. For instance, the RGB-D (Red, Green, Blue-Depth) fusion network achieved a mean absolute error of 15% in calorie estimation, and a sound-based classification model reached up to 94% accuracy in detecting food intake based on jaw motion and chewing patterns. In addition, AI-based systems provided real-time monitoring capabilities, improving the precision of dietary assessments and demonstrating the potential to reduce recall bias typically associated with traditional self-report methods. Conclusions While AI demonstrated significant advantages in improving accuracy, reducing labor, and enabling real-time monitoring, challenges remain in adapting to diverse food types, ensuring algorithmic fairness, and addressing data privacy concerns. The findings suggest that AI has transformative potential for dietary assessment at both individual and population levels, supporting precision nutrition and chronic disease management. Future research should focus on enhancing the robustness of AI models across diverse dietary contexts and integrating biological sensors for a holistic dietary assessment approach.",
    "doi": "10.2196/54557",
    "url": "https://www.semanticscholar.org/paper/cf0709674031ca3b2e3d514b7b1205df220edddf",
    "pdf_url": "https://doi.org/10.2196/54557",
    "venue": "Journal of Medical Internet Research",
    "citation_count": 31,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586889"
  },
  {
    "source": "semantic_scholar",
    "source_id": "f17bd30d769369c2dfc1e663adb6c2d8ccde4119",
    "title": "Redefining Architectural Ethics in the Age of AI: A Framework for Responsible Innovation",
    "authors": [
      "Walaa Hussien",
      "Amir El-Ghamry",
      "Noha Elfliky",
      "Safwat Hamad"
    ],
    "year": 2025,
    "abstract": "The combination of Artificial Intelligence (AI) and architecture is transforming how we design and build spaces, opening new possibilities for creativity, efficiency, and problem solving. Architects can now address complex challenges in ways that were previously unimaginable, thanks to AI tools that offer smarter, faster solutions. But alongside these advancements come important ethical questions, how do we ensure that these technologies are used in ways that align with human values, uphold professional integrity, and promote sustainability? This paper presents a fresh framework for integrating AI ethically in architecture, focusing on core principles such as transparency, accountability, fairness, privacy, and environmental responsibility. By exploring real world examples and potential future scenarios, we offer practical guidance to architects, AI developers, policymakers, and educators. The goal is to help them use AI not just as a tool for innovation, but to create more inclusive, sustainable, and ethically responsible built environments that truly serve communities.",
    "doi": "10.1109/GCAIoT68269.2025.11275538",
    "url": "https://www.semanticscholar.org/paper/f17bd30d769369c2dfc1e663adb6c2d8ccde4119",
    "pdf_url": "",
    "venue": "Global Conference on Artificial Intelligence and Internet of Things",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586893"
  },
  {
    "source": "semantic_scholar",
    "source_id": "3060d714cb70857530c6d366bd2276596bd9a3bd",
    "title": "A multi-institutional study using artificial intelligence to provide reliable and fair feedback to surgeons",
    "authors": [
      "Dani Kiyasseh",
      "Jasper A. Laca",
      "Taseen F. Haque",
      "B. Miles",
      "C. Wagner",
      "D. Donoho",
      "Anima Anandkumar",
      "Andrew J. Hung"
    ],
    "year": 2023,
    "abstract": "Surgeons who receive reliable feedback on their performance quickly master the skills necessary for surgery. Such performance-based feedback can be provided by a recently-developed artificial intelligence (AI) system that assesses a surgeon\u2019s skills based on a surgical video while simultaneously highlighting aspects of the video most pertinent to the assessment. However, it remains an open question whether these highlights, or explanations, are equally reliable for all surgeons. Here, we systematically quantify the reliability of AI-based explanations on surgical videos from three hospitals across two continents by comparing them to explanations generated by humans experts. To improve the reliability of AI-based explanations, we propose the strategy of training with explanations \u2013TWIX \u2013which uses human explanations as supervision to explicitly teach an AI system to highlight important video frames. We show that while AI-based explanations often align with human explanations, they are not equally reliable for different sub-cohorts of surgeons (e.g., novices vs. experts), a phenomenon we refer to as an explanation bias. We also show that TWIX enhances the reliability of AI-based explanations, mitigates the explanation bias, and improves the performance of AI systems across hospitals. These findings extend to a training environment where medical students can be provided with feedback today. Our study informs the impending implementation of AI-augmented surgical training and surgeon credentialing programs, and contributes to the safe and fair democratization of surgery. Surgeons aim to master skills necessary for surgery. One such skill is suturing which involves connecting objects together through a series of stitches. Mastering these surgical skills can be improved by providing surgeons with feedback on the quality of their performance. However, such feedback is often absent from surgical practice. Although performance-based feedback can be provided, in theory, by recently-developed artificial intelligence (AI) systems that use a computational model to assess a surgeon\u2019s skill, the reliability of this feedback remains unknown. Here, we compare AI-based feedback to that provided by human experts and demonstrate that they often overlap with one another. We also show that explicitly teaching an AI system to align with human feedback further improves the reliability of AI-based feedback on new videos of surgery. Our findings outline the potential of AI systems to support the training of surgeons by providing feedback that is reliable and focused on a particular skill, and guide programs that give surgeons qualifications by complementing skill assessments with explanations that increase the trustworthiness of such assessments. Kiyasseh et al. compare the quality of feedback provided to surgeons by artificial intelligence (AI) to that provided by human experts. Teaching an AI system to explicitly follow human explanations improves the reliability and reduces the bias of AI-based feedback.",
    "doi": "10.1038/s43856-023-00263-3",
    "url": "https://www.semanticscholar.org/paper/3060d714cb70857530c6d366bd2276596bd9a3bd",
    "pdf_url": "https://www.nature.com/articles/s43856-023-00263-3.pdf",
    "venue": "Communications Medicine",
    "citation_count": 52,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586896"
  },
  {
    "source": "semantic_scholar",
    "source_id": "2288d1bd124febc26d37828b1dfa7699cd88f1f4",
    "title": "Representation of intensivists\u2019 race/ethnicity, sex, and age by artificial intelligence: a cross-sectional study of two text-to-image models",
    "authors": [
      "M. Gisselbaek",
      "M\u00e9lanie Suppan",
      "Laurens Minsart",
      "Ekin K\u00f6selerli",
      "S. Nainan Myatra",
      "Idit Matot",
      "Odmara L. Barreto Chang",
      "Sarah Saxena",
      "J. Berger-Estilita"
    ],
    "year": 2024,
    "abstract": "Integrating artificial intelligence (AI) into intensive care practices can enhance patient care by providing real-time predictions and aiding clinical decisions. However, biases in AI models can undermine diversity, equity, and inclusion (DEI) efforts, particularly in visual representations of healthcare professionals. This work aims to examine the demographic representation of two AI text-to-image models, Midjourney and ChatGPT DALL-E 2, and assess their accuracy in depicting the demographic characteristics of intensivists. This cross-sectional study, conducted from May to July 2024, used demographic data from the USA workforce report (2022) and intensive care trainees (2021) to compare real-world intensivist demographics with images generated by two AI models, Midjourney v6.0 and ChatGPT 4.0 DALL-E 2. A total of 1,400 images were generated across ICU subspecialties, with outcomes being the comparison of sex, race/ethnicity, and age representation in AI-generated images to the actual workforce demographics. The AI models demonstrated noticeable biases when compared to the actual U.S. intensive care workforce data, notably overrepresenting White and young doctors. ChatGPT-DALL-E2 produced less female (17.3% vs 32.2%, p\u2009<\u20090.0001), more White (61% vs 55.1%, p\u2009=\u20090.002) and younger (53.3% vs 23.9%, p\u2009<\u20090.001) individuals. While Midjourney depicted more female (47.6% vs 32.2%, p\u2009<\u20090.001), more White (60.9% vs 55.1%, p\u2009=\u20090.003) and younger intensivist (49.3% vs 23.9%, p\u2009<\u20090.001). Substantial differences between the specialties within both models were observed. Finally when compared together, both models showed significant differences in the Portrayal of intensivists. Significant biases in AI images of intensivists generated by ChatGPT DALL-E 2 and Midjourney reflect broader cultural issues, potentially perpetuating stereotypes of healthcare worker within the society. This study highlights the need for an approach that ensures fairness, accountability, transparency, and ethics in AI applications for healthcare.",
    "doi": "10.1186/s13054-024-05134-4",
    "url": "https://www.semanticscholar.org/paper/2288d1bd124febc26d37828b1dfa7699cd88f1f4",
    "pdf_url": "",
    "venue": "Critical Care",
    "citation_count": 15,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586901"
  },
  {
    "source": "semantic_scholar",
    "source_id": "43f1d604433d20000db637f5ce57301d947adc76",
    "title": "Uncovering Creative Accounting Practices in MSMEs from the Perspective of Ethics and Professional Compliance",
    "authors": [
      "Joanna Azmi Alyssa Dewi",
      "Elga Yulindisti",
      "Rusliyawati Rusliyawati",
      "Marjono Marjono"
    ],
    "year": 2025,
    "abstract": "This study explores how leaders adapt to institutional changes driven by artificial intelligence (AI), focusing on leadership strategies, managerial flexibility, and their impact on human resource engagement. Using a qualitative case study with 12 key informants from a higher education institution in Riau, data were collected through in-depth interviews and analyzed thematically. Findings show that effective leadership adaptation relies on articulating a clear AI transformation vision, developing human resource capacity through continuous training, and implementing participatory communication to reduce resistance. The study concludes that leadership adaptation is crucial for sustaining AI-based transformation and contributes both theoretically and practically to adaptive leadership and HR management in the digital era.",
    "doi": "10.55927/fjst.v4i9.247",
    "url": "https://www.semanticscholar.org/paper/43f1d604433d20000db637f5ce57301d947adc76",
    "pdf_url": "",
    "venue": "Formosa Journal of Science and Technology",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586905"
  },
  {
    "source": "semantic_scholar",
    "source_id": "4541dc6e4200df5ed9cf28e529ac56d73c8017ab",
    "title": "Integrating AI Into Arbitration: Balancing Efficiency With Fairness and Legal Compliance",
    "authors": [
      "T. Alhasan"
    ],
    "year": 2025,
    "abstract": "The integration of artificial intelligence (AI) into arbitration marks a significant transformation in alternative dispute resolution, aiming to enhance efficiency, objectivity, and accessibility. Advanced AI systems now extend beyond administrative tasks to analyze complex legal data, predict case outcomes, and even generate arbitral awards. This evolution addresses the growing volume and complexity of international disputes, particularly in commercial and investment arbitration. However, the adoption of AI introduces profound legal and ethical challenges. Key concerns include the absence of human judgment, potential biases embedded in AI algorithms, and the opacity of their decision\u2010making processes, accountability issues, and data privacy risks. Critically, current legal frameworks such as the New York Convention were not designed to accommodate AI\u2010generated awards, raising questions about their legitimacy, procedural fairness, and enforceability. This article explores these intersections, focusing on how AI impacts arbitration's efficiency and objectivity, the legal and ethical challenges arising from AI integration, and the extent to which existing legal frameworks accommodate AI\u2010generated awards. Employing a multidisciplinary approach that includes legal scholarship, case studies, and technological research, the analysis examines the practical implications of AI in arbitration and the specific enforcement challenges of AI\u2010generated awards. The article concludes with recommendations for regulatory reforms and the adoption of hybrid AI\u2010human models to balance technological benefits with the necessity for human oversight and ethical accountability.",
    "doi": "10.1002/crq.21470",
    "url": "https://www.semanticscholar.org/paper/4541dc6e4200df5ed9cf28e529ac56d73c8017ab",
    "pdf_url": "",
    "venue": "Conflict Resolution Quarterly",
    "citation_count": 34,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586908"
  },
  {
    "source": "semantic_scholar",
    "source_id": "d1d173f73e6ce917000391a22745b166c6825990",
    "title": "Evaluation of Explainable Artificial Intelligence using TOPSIS Method",
    "authors": [],
    "year": 2024,
    "abstract": "Explainable Artificial Intelligence (XAI) refers to the development of AI systems are transparent, explainable and their comprehensible for results can provide explanations or predictions. As AI technologies, particularly machine learning models, become more complex and sophisticated, there is a growing need to ensure that their decisions can be comprehended and trusted by humans, especially health, Finance and such as criminal justice in important domains. Evaluating Explainable Artificial Intelligence (XAI) is essential to ensure transparency, accountability, and user trust in AI systems. Interpretability is a key factor, examining how easily the model's internal mechanisms can be understood. Model transparency, feature importance, and the clarity of visualizations contribute to this aspect. Differentiate between post-hoc and intrinsic explanations, considering whether the model inherently provides interpretable insights. The distinction between local and global explanations is crucial, as it determines whether explanations focus on individual predictions or the overall model behavior. Robustness and consistency are assessed through stability and sensitivity analysis, ensuring that explanations remain reliable across similar instances. Additionally, ethical considerations, such as fairness and transparency in decision-making, must be addressed to uncover and mitigate biases. User feedback and the relevance of explanations to the specific use case contribute to a comprehensive evaluation, fostering the development of XAI systems that are not only technically robust but also ethically sound and user-friendly. The significance of research in Explainable Artificial Intelligence (XAI) lies in addressing critical challenges associated with the adoption and deployment of AI systems in various domains. As AI technologies, particularly complex machine learning models, become integral to decision-making processes in areas such as healthcare, finance, and criminal justice, the need for transparency and interpretability becomes paramount. Topsis involves optimizing from an advantageous standpoint by simultaneously minimizing the distance to and maximizing the distance from a reference point, which is defined in relation to solutions within a set of alternative options and numerous identification criteria. The importance of Topsis criteria lies in the potential to integrate comparative weights. This study conducts a comprehensive review of Topsis, exploring various weighing schemes and employing different distance measurements. Numerous applications of Topsis are examined, particularly its utilization in comparing results for a diverse set of multiple criteria data with varying weights. Interpretable Machine Learning Models, Human-Centric Design in XAI, Ethical Implications of XAI, Industry-specific Applications of XAI and Hybrid Approaches for Model Interpretability. Interpretability Metrics, Human-Subjective Evaluation, Algorithmic Robustness and Real-world Impact. the Ranking of Evaluation Explainable Artificial Intelligence. Industry-specific Applications of XAI is got the first rank whereas is the Ethical Implications of XAI is having the Lowest rank.",
    "doi": "10.46632/cset/2/2/2",
    "url": "https://www.semanticscholar.org/paper/d1d173f73e6ce917000391a22745b166c6825990",
    "pdf_url": "",
    "venue": "Computer Science, Engineering and Technology",
    "citation_count": 4,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586911"
  },
  {
    "source": "semantic_scholar",
    "source_id": "37b8605f350501ca4b7655627dbfbcd939f2a9eb",
    "title": "Engineering a social contract: Rawlsian distributive justice through algorithmic game theory and artificial intelligence",
    "authors": [
      "H. Ashrafian"
    ],
    "year": 2022,
    "abstract": "The potential for artificial intelligence algorithms and game theory concepts\u00a0to offer prescriptive and decision-making capability for humankind is increasingly recognized. This derives from the increasing availability of granular, multivariable, well-curated data offering analytical insights for necessarily complex human behaviors and activities. Of the multitude of situations that this decision-making aptitude presents, the application to governmental policy offers a commanding case. This would allow decisions to be made for the benefit of societies and citizens based on rigorous objective information devoid of the traditional approach of choosing policies and societal values based on the opinion of a handful of selected representatives who may be exposed to a lack of comprehensive data analysis capacity and subject to personal biases. There would need to be a critical requirement of wider socially responsible data practices here, beyond those of technical considerations and the incorporation of wider societal fairness approaches. Amongst the schools of political thought particularly acquiescent to the application by this approach would be the egalitarian approach of John Rawls. Here an Original Position\u2019s pre-determination tool of Veil of Ignorance and ensuing Difference Principal presents a method of distributive justice that can be clearly mathematically defined in economics theory through Wald\u2019s Maximin principle. This offers an opportunity to apply algorithmic game theory and artificial intelligence computational approaches to implement Rawlsian distributive justice that are presented and discussed. The outputs from the algorithmic acquaintance of Rawlsian egalitarianism with applicable state data, protected with appropriate privacy, security, legal, ethical and social governance could in turn lead to automated direct governmental choices and an objective Social Contract for citizens of digitally literate nations.",
    "doi": "10.1007/s43681-022-00253-6",
    "url": "https://www.semanticscholar.org/paper/37b8605f350501ca4b7655627dbfbcd939f2a9eb",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s43681-022-00253-6.pdf",
    "venue": "AI and Ethics",
    "citation_count": 8,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586915"
  },
  {
    "source": "semantic_scholar",
    "source_id": "c0df896966a7e4bb237bf39763e27b7f0c34704c",
    "title": "Introduction to the Special Issue on AI Fairness, Trust, and Ethics",
    "authors": [
      "L. Robert",
      "G. Bansal",
      "Nigel P. Melville",
      "Thomas F. Stafford"
    ],
    "year": 2020,
    "abstract": "It is our pleasure to welcome you to this AIS Transactions on Human Computer Interaction special issue on artificial intelligence (AI) fairness, trust, and ethics. This special issue received research papers that unpacked the potential, challenges, impacts, and theoretical implications of AI. This special issue contains four papers that integrate research across diverse fields of study, such as social science, computer science, engineering, design, values, and other diverse topics related to AI fairness, trust, and ethics broadly conceptualized. This issue contains three of the four papers (along with a regular paper of the journal). The fourth or last paper of this special issue is forthcoming in March 2021. We hope that you enjoy these papers and, like us, look forward to similar research published in AIS Transactions on Human Computer Interaction.",
    "doi": "10.17705/1thci.00134",
    "url": "https://www.semanticscholar.org/paper/c0df896966a7e4bb237bf39763e27b7f0c34704c",
    "pdf_url": "https://aisel.aisnet.org/cgi/viewcontent.cgi?article=1139&context=thci",
    "venue": "AIS Trans. Hum. Comput. Interact.",
    "citation_count": 14,
    "fields_of_study": [
      "Psychology",
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586919"
  },
  {
    "source": "semantic_scholar",
    "source_id": "ce04f60c9e019ce32e564a3d9465790efd43961c",
    "title": "Exploring Gender Bias and Algorithm Transparency: Ethical Considerations of AI in HRM",
    "authors": [
      "Jiaxing Du"
    ],
    "year": 2024,
    "abstract": "Opportunities and challenges are introduced by the integration of Artificial Intelligence (AI) into Human Resource Management (HRM). The paragraph discusses the ethical implications of AI applications in HRM, focusing on gender bias and algorithm transparency. It explores how AI-driven decision-making in HRM perpetuates gender bias, the importance of transparent algorithms for trust and accountability, and the role of regulatory frameworks in safeguarding ethical standards. The paper aims to provide a comprehensive analysis of the ethical landscape of AI in HRM and offers policy recommendations to mitigate bias and enhance transparency.",
    "doi": "10.53469/jtpms.2024.04(03).06",
    "url": "https://www.semanticscholar.org/paper/ce04f60c9e019ce32e564a3d9465790efd43961c",
    "pdf_url": "https://centuryscipub.com/index.php/JTPMS/article/download/539/461",
    "venue": "Journal of Theory and Practice of Management Science",
    "citation_count": 14,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586922"
  },
  {
    "source": "semantic_scholar",
    "source_id": "f820dc201869376d29da935d9c9dab7b892ac18b",
    "title": "AI and ML ethics, Law, Diversity, and Global Impact.",
    "authors": [
      "Katherine Drabiak",
      "Skylar Kyzer",
      "Valerie Nemov",
      "I. E. El Naqa"
    ],
    "year": 2023,
    "abstract": "Artificial intelligence (AI) and its machine learning (ML) algorithms are offering new promise for personalized biomedicine and more cost-effective healthcare with impressive technical capability to mimic human cognitive capabilities. However, widespread application of this promising technology has been limited in the medical domain and expectations have been tampered by ethical challenges and concerns regarding patient privacy, legal responsibility, trustworthiness, and fairness. To balance technical innovation with ethical applications of AI/ML, developers must demonstrate the AI functions as intended and adopt strategies to minimize the risks for failure or bias. This review describes the new ethical challenges created by AI/ML for clinical care and identifies specific considerations for its practice in medicine. We provide an overview of regulatory and legal issues applicable in Europe and the United States, a description of technical aspects to consider, and present recommendations for trustworthy AI/ML that promote transparency, minimize risks of bias or error, and protect the patient well-being.",
    "doi": "10.1259/bjr.20220934",
    "url": "https://www.semanticscholar.org/paper/f820dc201869376d29da935d9c9dab7b892ac18b",
    "pdf_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10546451",
    "venue": "British Journal of Radiology",
    "citation_count": 45,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586926"
  },
  {
    "source": "semantic_scholar",
    "source_id": "bf59075b7fd5e28d7f87f6302d2537b3b37549a5",
    "title": "The Artificial Intelligence application in Aesthetic Medicine: How ChatGPT can Revolutionize the Aesthetic World",
    "authors": [
      "G. Buzzaccarini",
      "R. Degliuomini",
      "M. Borin"
    ],
    "year": 2023,
    "abstract": null,
    "doi": "10.1007/s00266-023-03416-w",
    "url": "https://www.semanticscholar.org/paper/bf59075b7fd5e28d7f87f6302d2537b3b37549a5",
    "pdf_url": "",
    "venue": "Aesthetic Plastic Surgery",
    "citation_count": 29,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586929"
  },
  {
    "source": "semantic_scholar",
    "source_id": "818f557ca8283b054d9a812112788efb198b3704",
    "title": "Ethical Concerns While Using Artificial Intelligence in Recruitment of Employees",
    "authors": [
      "Aashima Gupta",
      "Mridula Mishra"
    ],
    "year": 2022,
    "abstract": "Artificial Intelligence has evolved as an alternative to human intelligence. It affects the lives of billions of people. It mimics humans by solving problems and understanding the task. These Artificial Intelligence technologies must have some moral values and ethics incorporated within itself. The usage of AI is growing worldwide, posing more ethical issues to consider. In recent years, many companies have used various Artificial Intelligence tools such as chatbots and face recognition software for fulfilling their hiring needs. This research work will focus on such devices that help manage one of the important functions of human resources: recruitment. It will identify various challenges and ethical issues that a firm faces while assimilating Artificial Intelligence tools in the process of Recruitment. The hiring companies need to make the job seekers realize that AI-powered tools would be free from discrimination and safeguard privacy. The purpose of the study is to identify the ethical issues while incorporating Artificial Intelligence into hiring needs. The study will be based on reviews and features of applications. The study mentions various applications whose features might be unethical for job seekers. Findings reveal that the significant unethical issues faced by the hiring companies are Data privacy and unconscious biasness. The biasness is due to the algorithm that works according to the inputs fed to build it, and the programmer might have subconscious biasness in his mind. AI has restored concerns regarding privacy and data protection. According to a report by UNESCO, Women make up only 22% of all AI professionals. Gender prejudices and stereotyping are perpetuated in AI technologies due to their underrepresentation in the sector. Virtual personal assistants like Siri, Alexa, and Cortana are \u201cfemale\u201d by default, which is no accident. The submissiveness they display is an illustration of how Artificial Intelligence (AI) might continue to support and extend gender bias in our society.",
    "doi": "10.21272/bel.6(2).6-11.2022",
    "url": "https://www.semanticscholar.org/paper/818f557ca8283b054d9a812112788efb198b3704",
    "pdf_url": "https://armgpublishing.sumdu.edu.ua/wp-content/uploads/2022/07/BEL_2_2022_1.pdf",
    "venue": "Business Ethics and Leadership",
    "citation_count": 18,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586933"
  },
  {
    "source": "semantic_scholar",
    "source_id": "3229e05e2b8e2514b34973109b6bf8268c7db758",
    "title": "Auditing Fairness and Explainability in Chest X-Ray Image Classifiers",
    "authors": [
      "Gemma Bordes",
      "Alan Perotti"
    ],
    "year": 2024,
    "abstract": ": Advancements in Artificial Intelligence have produced several tools that can be used in medical decision support systems. However, these models often exhibit the so-called \u2019black-box problem\u2019: an algorithmic diagnosis is produced, but no human-understandable details about the decision process can be obtained. This raises critical questions about fairness and explainability, crucial for equitable healthcare. In this paper we focus on chest X-ray image classification, auditing the reproducibility of previous results in terms of model bias, exploring the applicability of Explainable AI (XAI) techniques, and auditing the fairness of the produced explanations. We highlight the challenges in assessing the quality of explanations provided by XAI methods, particularly in the absence of ground truth. In turn, this strongly hampers the possibility of comparing explanation quality across patients sub-groups, which is a cornerstone in fairness audits. Our experiments illustrate the complexities in achieving transparent AI interpretations in medical diagnostics, underscoring the need both for reliable XAI techniques and more robust fairness auditing methods.",
    "doi": "10.5220/0012472400003636",
    "url": "https://www.semanticscholar.org/paper/3229e05e2b8e2514b34973109b6bf8268c7db758",
    "pdf_url": "https://doi.org/10.5220/0012472400003636",
    "venue": "International Conference on Agents and Artificial Intelligence",
    "citation_count": 2,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586936"
  },
  {
    "source": "semantic_scholar",
    "source_id": "4a79f1acaee07814b54f0eb1f2eba2c909606e7a",
    "title": "Who is responsible? US Public perceptions of AI governance through the lenses of trust and ethics",
    "authors": [
      "Prabu David",
      "Hyesun Choung",
      "John S. Seberger"
    ],
    "year": 2024,
    "abstract": "The governance of artificial intelligence (AI) is an urgent challenge that requires actions from three interdependent stakeholders: individual citizens, technology corporations, and governments. We conducted an online survey (N = 525) of US adults to examine their beliefs about the governance responsibility of these stakeholders as a function of trust and AI ethics. Different dimensions of trust and different ethical concerns were associated with beliefs in governance responsibility of the three stakeholders. Specifically, belief in the governance responsibility of the government was associated with ethical concerns about AI, whereas belief in governance responsibility of corporations was related to both ethical concerns and trust in AI. Belief in governance responsibility of individuals was related to human-centered values of trust in AI and fairness. Overall, the findings point to the need for an interdependent framework in which citizens, corporations, and governments share governance responsibilities, guided by trust and ethics as the guardrails.",
    "doi": "10.1177/09636625231224592",
    "url": "https://www.semanticscholar.org/paper/4a79f1acaee07814b54f0eb1f2eba2c909606e7a",
    "pdf_url": "",
    "venue": "Public Understanding of Science",
    "citation_count": 20,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586939"
  },
  {
    "source": "semantic_scholar",
    "source_id": "360c5a973329b5ce289da96864ce2106ae83e6e3",
    "title": "Enhancing the Fairness and Performance of Edge Cameras with Explainable AI",
    "authors": [
      "Truong Thanh Hung Nguyen",
      "V. Nguyen",
      "Quoc Hung Cao",
      "Van Binh Truong",
      "Quoc Khanh Nguyen",
      "Hung Cao"
    ],
    "year": 2024,
    "abstract": "The rising use of Artificial Intelligence (AI) in human detection on Edge camera systems has led to accurate but complex models, challenging to interpret and debug. Our research presents a diagnostic method using XAI for model debugging, with expert-driven problem identification and solution creation. Validated on the Bytetrack model in a real-world office Edge network, we found the training dataset as the main bias source and suggested model augmentation as a solution. Our approach helps identify model biases, essential for achieving fair and trustworthy models.",
    "doi": "10.1109/ICCE59016.2024.10444383",
    "url": "https://www.semanticscholar.org/paper/360c5a973329b5ce289da96864ce2106ae83e6e3",
    "pdf_url": "https://arxiv.org/pdf/2401.09852",
    "venue": "IEEE International Conference on Consumer Electronics",
    "citation_count": 2,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586943"
  },
  {
    "source": "semantic_scholar",
    "source_id": "59b3cf509ae22db9f1ac8a62426e6d8040625c86",
    "title": "Algor-ethics: charting the ethical path for AI in critical care",
    "authors": [
      "J. Montomoli",
      "M. M. Bitondo",
      "M. Cascella",
      "Emanuele Rezoagli",
      "L. Romeo",
      "Valentina Bellini",
      "Federico Semeraro",
      "E. Gamberini",
      "Emanuele Frontoni",
      "V. Agnoletti",
      "Mattia Altini",
      "Paolo Benanti",
      "E. Bignami"
    ],
    "year": 2024,
    "abstract": "The integration of Clinical Decision Support Systems (CDSS) based on artificial intelligence (AI) in healthcare is groundbreaking evolution with enormous potential, but its development and ethical implementation, presents unique challenges, particularly in critical care, where physicians often deal with life-threating conditions requiring rapid actions and patients unable to participate in the decisional process. Moreover, development of AI-based CDSS is complex and should address different sources of bias, including data acquisition, health disparities, domain shifts during clinical use, and cognitive biases in decision-making. In this scenario algor-ethics is mandatory and emphasizes the integration of \u2018Human-in-the-Loop\u2019 and \u2018Algorithmic Stewardship\u2019 principles, and the benefits of advanced data engineering. The establishment of Clinical AI Departments (CAID) is necessary to lead AI innovation in healthcare, ensuring ethical integrity and human-centered development in this rapidly evolving field.",
    "doi": "10.1007/s10877-024-01157-y",
    "url": "https://www.semanticscholar.org/paper/59b3cf509ae22db9f1ac8a62426e6d8040625c86",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10877-024-01157-y.pdf",
    "venue": "Journal of clinical monitoring and computing",
    "citation_count": 21,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586947"
  },
  {
    "source": "semantic_scholar",
    "source_id": "f64670a5f54fcce339a916497a001cbf02a9a04f",
    "title": "A Review on Fairness in Machine Learning",
    "authors": [
      "Dana Pessach",
      "E. Shmueli"
    ],
    "year": 2022,
    "abstract": "An increasing number of decisions regarding the daily lives of human beings are being controlled by artificial intelligence and machine learning (ML) algorithms in spheres ranging from healthcare, transportation, and education to college admissions, recruitment, provision of loans, and many more realms. Since they now touch on many aspects of our lives, it is crucial to develop ML algorithms that are not only accurate but also objective and fair. Recent studies have shown that algorithmic decision making may be inherently prone to unfairness, even when there is no intention for it. This article presents an overview of the main concepts of identifying, measuring, and improving algorithmic fairness when using ML algorithms, focusing primarily on classification tasks. The article begins by discussing the causes of algorithmic bias and unfairness and the common definitions and measures for fairness. Fairness-enhancing mechanisms are then reviewed and divided into pre-process, in-process, and post-process mechanisms. A comprehensive comparison of the mechanisms is then conducted, toward a better understanding of which mechanisms should be used in different scenarios. The article ends by reviewing several emerging research sub-fields of algorithmic fairness, beyond classification.",
    "doi": "10.1145/3494672",
    "url": "https://www.semanticscholar.org/paper/f64670a5f54fcce339a916497a001cbf02a9a04f",
    "pdf_url": "",
    "venue": "ACM Computing Surveys",
    "citation_count": 609,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586951"
  },
  {
    "source": "semantic_scholar",
    "source_id": "45d129e9ef09133d07c4ee7bd067e78ff88370ba",
    "title": "When Artificial Intelligence and Big Data Collide\u2014How Data Aggregation and Predictive Machines Threaten our Privacy and Autonomy",
    "authors": [
      "Alex Alben"
    ],
    "year": 2020,
    "abstract": "Artificial Intelligence and Big Data represent two profound technology trends. Professor Alben\u2019s article explores how Big Data feeds AI applications and makes the case that necessity to monitor such applications has become more immediate and consequential to protect our civil discourse and personal autonomy, especially as they are expressed on social media. Like many of the revolutionary technologies that preceded it, ranging from broadcast radio to atomic power, AI can be used for purposes that benefit human beings and purposes that threaten our very existence. The challenge for the next decade is to make sure that we harness AI with appropriate safeguards and limitations. With a perspective on previous \u201crevolutionary\u201d technologies, the article explains how personal data became profiled and marketed by data brokers over the past two decades with an emphasis on dangers to privacy rights. The article observes that it is critical to adopt an approach in the public policy realm that addresses the bias dangers of a technology, while enabling a fair and transparent implementation that allows our society to reap the benefits of adoption. It advocates solutions to improve the technology and adopt the best versions, not cut off development in early stages of the new technology\u2019s evolution. Drawing on the author\u2019s work as a state-level Chief Privacy Officer and a high-tech executive, the article concludes with four policy recommendations for curbing the flow of personal information into the Big Data economy: 1. Regulating data brokers; 2. Minimizing data by default; 3. Public Records Reform and 4. Improving personal data hygiene. _______________",
    "doi": "10.47289/aiej20201106",
    "url": "https://www.semanticscholar.org/paper/45d129e9ef09133d07c4ee7bd067e78ff88370ba",
    "pdf_url": "https://42bade24-c7d1-4b33-a885-3579694f405d.filesusr.com/ugd/c57e34_26064532afa64c72a70e5084dba7ab3c.pdf",
    "venue": "AI Ethics Journal",
    "citation_count": 1,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586954"
  },
  {
    "source": "semantic_scholar",
    "source_id": "7e1f70a74429e1804c602fdab2bb1a45adb1e100",
    "title": "Navigating ethical dimensions in algorithmic radiology: A call for action to ensure representation of low-resource contexts.",
    "authors": [
      "H. Shafeeq",
      "Ahmed",
      "Shafeeq Ahmed"
    ],
    "year": 2025,
    "abstract": "Artificial intelligence (AI) has revolutionised medicine, particularly radiology, transforming our ability to interpret complex imaging data. While traditional methods rely on subjective visual assessments, AI excels at recognising intricate patterns and providing quantitative and automated evaluations. In this commentary, I delve into the various ethical considerations in algorithmic radiology, beyond the conventional concerns. Focusing on utilitarianism, patient understanding, virtue ethics, and social contract theory, the paper contributes to a comprehensive understanding of the ethical landscape surrounding AI technologies. The challenges in the use of algorithmic AI in radiology underscore the significance of the ethics of care, responsiveness to context, and the role of human emotion, whether pertaining to the practitioner, the patient, or both. The social contract theory guides the responsibilities of healthcare professionals, urging action to address biases in AI algorithms and ensuring equitable representation of various ethnic and racial populations. Diversity in data must be prioritised to avoid disparities in administering healthcare and uphold patient rights in the adoption of AI. In terms of virtue ethics, professionalism and responsibility are crucial for radiologists adopting AI. Also, an absence of explicit guidelines on the use of AI in healthcare poses challenges, necessitating further discourse. Finally, a utilitarian perspective on public health mandates a fair distribution of imaging technologies to address prevalent health issues in a given population. In conclusion, this paper advocates for an ethical approach to AI integration, which aligns technology with human values and wellbeing, as we shape the future of healthcare.",
    "doi": "10.20529/ijme.2024.089",
    "url": "https://www.semanticscholar.org/paper/7e1f70a74429e1804c602fdab2bb1a45adb1e100",
    "pdf_url": "",
    "venue": "Indian Journal of Medical Ethics",
    "citation_count": 0,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586958"
  },
  {
    "source": "semantic_scholar",
    "source_id": "585d6882524e7b8cb4ea79c2852810673151db4d",
    "title": "Corporate digital responsibility (CDR) in construction engineering\u2014ethical guidelines for the application of digital transformation and artificial intelligence (AI) in user practice",
    "authors": [
      "B. Weber-Lewerenz"
    ],
    "year": 2021,
    "abstract": "Digitization is developing fast and has become a powerful tool for digital planning, construction and operations, for instance digital twins. Now is the right time for constructive approaches and to apply ethics-by-design in order to develop and implement a safe and efficient artificial intelligence (AI) application. So far, no study has addressed the key research question: Where can corporate digital responsibility (CDR) be allocated, and how shall an adequate ethical framework be designed to support digital innovations in order to make full use of the potentials of digitization and AI? Therefore, the research on how best practices meet their corporate responsibility in the digital transformation process and the requirements of the EU for trustworthy AI and its human-friendly use is essential. Its transformation bears a high potential for companies, is critical for success and thus, requires responsible handling. This study generates data by conducting case studies and interviewing experts as part of the qualitative method to win profound insights into applied practice. It provides an assessment of demands stated in the Sustainable Development Goals by the United Nations (SDGs), White Papers on AI by international institutions, European Commission and German Government requesting the consideration and protection of values and fundamental rights, the careful demarcation between machine (artificial) and human intelligence and the careful use of such technologies. The study discusses digitization and the impacts of AI in construction engineering from an ethical perspective. This research critically evaluates opportunities and risks concerning CDR in construction industry. To the author\u2019s knowledge, no study has set out to investigate how CDR in construction could be conceptualized, especially in relation to digitization and AI, to mitigate digital transformation both in large, medium- and small-sized companies. This study applies a holistic, interdisciplinary, inclusive approach to provide guidelines for orientation and examine benefits as well as risks of AI. Furthermore, the goal is to define ethical principles which are key for success, resource-cost-time efficiency and sustainability using digital technologies and AI in construction engineering to enhance digital transformation. This study concludes that innovative corporate organizations starting new business models are more likely to succeed than those dominated by a more conservative, traditional attitude. Highlights the role model function of construction engineering in human-led and value-based AI for other sectors, creates awareness of the potential of digital transformation and offers constructive solutions to shape this process for the benefit of companies and society. Fill in the construction engineering niche in the ongoing interdisciplinary debate \u201cEthics in AI\u201d and engage nationally and internationally recognized institutes as supporters and mentors. Identify CDR with ethical principles as the key driver for success, resources-cost-time efficiency and sustainability using digital technologies and AI in construction engineering. Highlights the role model function of construction engineering in human-led and value-based AI for other sectors, creates awareness of the potential of digital transformation and offers constructive solutions to shape this process for the benefit of companies and society. Fill in the construction engineering niche in the ongoing interdisciplinary debate \u201cEthics in AI\u201d and engage nationally and internationally recognized institutes as supporters and mentors. Identify CDR with ethical principles as the key driver for success, resources-cost-time efficiency and sustainability using digital technologies and AI in construction engineering.",
    "doi": "10.1007/s42452-021-04776-1",
    "url": "https://www.semanticscholar.org/paper/585d6882524e7b8cb4ea79c2852810673151db4d",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s42452-021-04776-1.pdf",
    "venue": "SN Applied Sciences",
    "citation_count": 77,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586961"
  },
  {
    "source": "semantic_scholar",
    "source_id": "0e8e3b2828235f4372d65a7e840d88b8162c62c7",
    "title": "Applications and implementation of Generative Artificial Intelligence in cardiovascular imaging with a focus on ethical and legal considerations: what cardiovascular imagers need to know!",
    "authors": [
      "Ahmed Marey",
      "Kevin Christopher Serdysnki",
      "Benjamin Killeen",
      "Mathias Unberath",
      "Muhammad Umair"
    ],
    "year": 2024,
    "abstract": "\n Artificial intelligence (AI) has emerged as a prominent field in computer science. Machine learning (ML) and deep learning (DL) have potential applications in medicine. This overview explores the applications of artificial intelligence (AI) in cardiovascular imaging, focusing on echocardiography, cardiac magnetic resonance imaging (CMR), coronary CT angiography (CCTA), and CT morphology and function. AI, particularly deep learning (DL) approaches like convolutional neural networks (CNNs), enhances standardization and reduces operator-dependent variations in echocardiography. In CMR, undersampling techniques and DL-based reconstruction methods, such as variational neural networks (VNNs), improve efficiency and accuracy. ML in CCTA aids in diagnosing coronary artery disease, assessing stenosis severity, and analyzing plaque characteristics. Automatic segmentation of cardiac structures and vessels using AI is discussed, along with its potential in congenital heart disease diagnosis and 3D printing applications. Overall, AI integration in cardiovascular imaging shows promise for enhancing diagnostic accuracy and efficiency across modalities. The growing use of Generative Adversarial Networks in cardiovascular imaging brings substantial advancements but raises ethical concerns. The \"black box\" problem in deep learning models poses challenges for interpretability crucial in clinical practice. Evaluation metrics like ROC curves, image quality, clinical relevance, diversity, and quantitative performance assess GAI models. Automation bias highlights the risk of unquestioned reliance on AI outputs, demanding careful implementation and ethical frameworks. Ethical considerations involve transparency, respect for persons, beneficence, and justice, necessitating standardized evaluation protocols. Health disparities emerge if AI training lacks diversity, impacting diagnostic accuracy. AI language models, like GPT-4, face hallucination issues, posing ethical and legal challenges in healthcare. Regulatory frameworks and ethical governance are crucial for fair and accountable AI, addressing discrimination while preserving privacy. Ongoing research and development are vital to evolving AI ethics and ensuring ethical data handling in healthcare.",
    "doi": "10.1093/bjrai/ubae008",
    "url": "https://www.semanticscholar.org/paper/0e8e3b2828235f4372d65a7e840d88b8162c62c7",
    "pdf_url": "https://academic.oup.com/bjrai/advance-article-pdf/doi/10.1093/bjrai/ubae008/58011240/ubae008.pdf",
    "venue": "BJR|Artificial Intelligence",
    "citation_count": 6,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586965"
  },
  {
    "source": "semantic_scholar",
    "source_id": "3eb9c847fe8742a69615ba3d11b1cff57cf9f4a0",
    "title": "\u201cThe Impact of Artificial Intelligence on Modern Recruitment Practices: A Multi-Company Case Study Analysis\u201d",
    "authors": [
      "Arati Biradar",
      "Jyoti Ainapur",
      "K. K",
      "Aishwarya Aishwarya",
      "Sudharani Sudharani",
      "Shivaleela Shivaleela",
      "Monika Monika"
    ],
    "year": 2024,
    "abstract": "This study examines the impact of Artificial Intelligence (AI) on modern recruitment practices through a multi-company case study analysis. We investigate the implementation and outcomes of AI-driven recruitment tools at five major corporations: Unilever, IBM, Hilton Hotels, Siemens, and Google. The research focuses on how AI technologies, including machine learning, natural language processing, and predictive analytics, are being utilized to streamline hiring processes, reduce costs, and improve candidate selection. Through analysis of these case studies, we find that AI significantly reduces time-to-hire, with some companies reporting up to 85% reduction in recruitment time. Cost savings are substantial, with decreases in recruitment expenses of up to 30%. Moreover, AI implementation has led to improved hiring accuracy and retention rates, with one company noting a 16% improvement in retention. The study also reveals enhanced diversity in hiring outcomes and improved candidate experiences. However, challenges persist, including concerns about data privacy and potential algorithmic bias. The research concludes that while AI offers significant benefits in recruitment, a balance between technological efficiency and human judgment remains crucial for fair and effective hiring practices. These findings provide valuable insights for HR professionals, business leaders, and job seekers navigating the evolving landscape of AI-driven recruitment.",
    "doi": "10.35629/8028-1309143150",
    "url": "https://www.semanticscholar.org/paper/3eb9c847fe8742a69615ba3d11b1cff57cf9f4a0",
    "pdf_url": "",
    "venue": "International journal of business and management invention",
    "citation_count": 6,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586968"
  },
  {
    "source": "semantic_scholar",
    "source_id": "c0d410770801bf0411859c5f4d9de00c2d7ecb56",
    "title": "Responsible Artificial Intelligence (AI) for Digital Health and Medical Analytics",
    "authors": [
      "U. Sivarajah",
      "Yichuan Wang",
      "Hossein Olya",
      "Sherin Mathew"
    ],
    "year": 2023,
    "abstract": "AI could pose potential risks to care delivery by devaluing physicians\u2019 skills, failing to meet transparency standards, underestimating algorithmic biases, and neglecting the fairness of clinical deployment (Vayena et al., 2018). Such ethical dilemmas and concerns, if not adequately addressed when implementing AI for digital health and medical analytics, can not only negatively impact patients but may also tarnish the reputation of healthcare organisations (Wang et al., 2018). In response to these ethical challenges, many countries have implemented data protection regulations, such as the UK\u2019s Data Protection Act 2018, which is in line with the General Data Protection Regulation (GDPR) formulated by the European Union. These regulations aim to improve individuals\u2019 confidence in sharing personal information with healthcare organisations, leading to a scholarly and practical focus on the responsible use of AI. Responsible AI refers to the integration of ethical and responsible AI use into strategic implementation and organisational planning processes (Wang et al., 2023). It aims to design and implement ethical, transparent, and accountable AI solutions that help organizations maintain trust and minimise privacy invasion. Responsible AI places humans (e.g., patients) at the centre and aligns with stakeholder expectations as well as applicable regulations and laws. The ultimate goal of responsible AI is to strike a balance between satisfying patient needs through responsible AI use and attaining long-term economic value for healthcare organisations. Despite its importance for organisational prosperity and the significant attention devoted to it, responsible AI use in healthcare is still in its nascent stages.",
    "doi": "10.1007/s10796-023-10412-7",
    "url": "https://www.semanticscholar.org/paper/c0d410770801bf0411859c5f4d9de00c2d7ecb56",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10796-023-10412-7.pdf",
    "venue": "Information Systems Frontiers",
    "citation_count": 21,
    "fields_of_study": [
      "Medicine",
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586972"
  },
  {
    "source": "semantic_scholar",
    "source_id": "13300b6a96eba2af4b738c846787bcd2d06aa75b",
    "title": "Health Economic Implications of Artificial Intelligence Implementation for Ophthalmology in Australia: A Systematic Review",
    "authors": [
      "James Pietris",
      "Antoinette Lam",
      "Stephen Bacchi",
      "Aashray K. Gupta",
      "J. Kovoor",
      "W. Chan"
    ],
    "year": 2022,
    "abstract": "Purpose: The health care industry is an inherently resource-intense sector. Emerging technologies such as artificial intelligence (AI) are at the forefront of advancements in health care. The health economic implications of this technology have not been clearly established and represent a substantial barrier to adoption both in Australia and globally. This review aims to determine the health economic impact of implementing AI to ophthalmology in Australia. Methods: A systematic search of the databases PubMed/MEDLINE, EMBASE, and CENTRAL was conducted to March 2022, before data collection and risk of bias analysis in accordance with preferred reporting items for systematic ceviews and meta-analyses 2020 guidelines (PROSPERO number CRD42022325511). Included were full-text primary research articles analyzing a population of patients who have or are being evaluated for an ophthalmological diagnosis, using a health economic assessment system to assess the cost-effectiveness of AI. Results: Seven articles were identified for inclusion. Economic viability was defined as direct cost to the patient that is equal to or less than costs incurred with human clinician assessment. Despite the lack of Australia-specific data, foreign analyses overwhelmingly showed that AI is just as economically viable, if not more so, than traditional human screening programs while maintaining comparable clinical effectiveness. This evidence was largely in the setting of diabetic retinopathy screening. Conclusions: Primary Australian research is needed to accurately analyze the health economic implications of implementing AI on a large scale. Further research is also required to analyze the economic feasibility of adoption of AI technology in other areas of ophthalmology, such as glaucoma and cataract screening.",
    "doi": "10.1097/APO.0000000000000565",
    "url": "https://www.semanticscholar.org/paper/13300b6a96eba2af4b738c846787bcd2d06aa75b",
    "pdf_url": "https://doi.org/10.1097/apo.0000000000000565",
    "venue": "Asia - Pacific Journal of Ophthalmology",
    "citation_count": 9,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586976"
  },
  {
    "source": "semantic_scholar",
    "source_id": "36cefd885af98589472473d386507be57ed72298",
    "title": "Artificial Intelligence Needs Human Rights: How the Focus on Ethical AI Fails to Address Privacy, Discrimination and Other Concerns",
    "authors": [
      "Kate Saslow",
      "Philippe Lorenz"
    ],
    "year": 2019,
    "abstract": "AI has been a catalyst for automation and efficiency in numerous ways, but has also had harmful consequences, including: unforeseen algorithmic bias that affects already marginalized communities, as with Amazon\u2019s AI recruiting algorithm that showed bias against women; accountability and liability coming into question if an autonomous vehicle injures or kills, as seen with Uber\u2019s self-driving car casualties; even the notion of democracy is being challenged as the technology enables authoritarian and democratic states like China and the United States to practice surveillance at an unprecedented scale.<br><br>The risks as well as the need for some form of basic rules have not gone unnoticed and governments, tech companies, research consortiums or advocacy groups have broached the issue. In fact, this has been the topic of local, national, and supranational discussion for some years now, as can be seen with new legislation popping up to ban facial recognition software in public spaces. The problem with these discussions, however, is that they have been heavily dominated by how we can make AI more \u201cethical\u201d. Companies, states, and even international organizations discuss ethical principles, such as fair, accountable, responsible, or safe AI in numerous expert groups or ad hoc committees, such as the High-Level Expert Group on AI in the European Commission, the group on AI in Society of the Organization for Economic Co-operation and Development (OECD), or the select committee on Artificial Intelligence of the United Kingdom House of Lords.<br><br>This may sound like a solid approach to tackling the dangers that AI poses, but to actually be impactful, these discussions must be grounded in rhetoric that is focused and actionable. Not only may the principles be defined differently depending on the stakeholders, but there are overwhelming differences in how principles are interpreted and what requirements are necessary for them to materialize. In addition, ethical debates on AI are often dominated by American or Chinese companies, which are both propagating their own idea of ethical AI, but which may in many cases stand in conflict with the values of other cultures and nations. Not only do different countries have different ideas of which \u201cethics\u201d principles need to be protected, but different countries play starkly different roles in developing AI. Another problem is when ethical guidelines are discussed, suggestions often come from tech companies themselves, while voices from citizens or even governments are marginalized.<br><br>Self-regulation around ethical principles is too weak to address the spreading implications that AI technologies have had. Ethical principles lack clarity and enforcement capabilities. We must stop focusing the discourse on ethical principles, and instead shift the debate to human rights. Debates must be louder at the supranational level. International pressure must be put on states and companies who fail to protect individuals by propagating AI technologies that carry risks. Leadership must be defined not by actors who come up with new iterations of ethical guidelines, but by those who develop legal obligations regarding AI, which are anchored in and derived from a human rights perspective.<br><br>A way to do this would be to reaffirm the human-centric nature of AI development and deployment that follows actionable standards of human rights law. The human rights legal framework has been around for decades and has been instrumental in fighting and pressuring states to change domestic laws. Nelson Mandela referred to the duties spelled out in the Universal Declaration of Human Rights while fighting to end apartheid in South Africa; in 1973 with Roe v. Wade the United States Supreme Court followed a larger global trend of recognizing women\u2019s human rights by protecting individuals from undue governmental interference in private affairs and giving women the ability to participate fully and equally in society; more recently, open access to the Internet has been recognized as a human right essential to not only freedom of opinion, expression, association, and assembly, but also instrumental in mobilizing the population to call for equality, justice, and accountability in order to advance global respect for human rights. These examples show how human rights standards have been applied to a diverse set of domestic and international rules. That these standards are actionable and enforceable show that they are well-suited to regulate the cross-border nature of AI technologies. AI systems must be scrutinized through a human rights perspective to analyze current and future harms either created or exacerbated by AI, and take action to avoid any harm.<br><br>The adoption of AI technologies has spread across borders and has had diverse effects on societies all over the world. A globalized technology needs international obligations to mitigate the societal problems being faced at an accelerated and larger scale. Companies and states should strive for the development of AI technologies that uphold human rights. Centering the AI discourse around human rights rather than simply ethics can be one way of providing a clearer legal basis for development and deployment of AI technologies. The international community must raise awareness, build consensus, and analyze thoroughly how AI technologies violate human rights in different contexts and develop paths for effective legal remedies. Focusing the discourse on human rights rather than ethical principles can provide more accountability measures, more obligations for state and private actors, and can redirect the debate to rely on consistent and widely accepted legal principles developed over decades.",
    "doi": "10.2139/ssrn.3589473",
    "url": "https://www.semanticscholar.org/paper/36cefd885af98589472473d386507be57ed72298",
    "pdf_url": "",
    "venue": "Social Science Research Network",
    "citation_count": 4,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586979"
  },
  {
    "source": "semantic_scholar",
    "source_id": "d53093a2a4fdbaee337a2d90f243e7a8378c9c68",
    "title": "Trustworthy Artificial Intelligence and its use by Law Enforcement Authorities: where do we stand?",
    "authors": [
      "Suncana Roksandic",
      "N. Protrka",
      "M. Engelhart"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.23919/MIPRO55190.2022.9803606",
    "url": "https://www.semanticscholar.org/paper/d53093a2a4fdbaee337a2d90f243e7a8378c9c68",
    "pdf_url": "",
    "venue": "International Convention on Information and Communication Technology, Electronics and Microelectronics",
    "citation_count": 13,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586983"
  },
  {
    "source": "semantic_scholar",
    "source_id": "e9cccc30b9fb6526792691b26bbd9db4c05342f5",
    "title": "Senior High School Students Perceptions and Awareness on the Ethical Implications of Artificial Intelligence",
    "authors": [
      "Cataga Chj",
      "Cator Ta",
      "Fabrique KS*",
      "Nudalo Bja",
      "Priol Js",
      "Tabon Ja"
    ],
    "year": 2024,
    "abstract": "Artificial Intelligence aims to create intelligent devices that resemble humans by inducing intelligent behavior. This study aims\nto examine the senior high school students\u2019 perceptions and awareness on the ethical implications of artificial intelligence\nin terms of age, sex, and grade level. The study utilized a quantitative cross-sectional research design. The respondents of\nthe study were 142 senior high school students currently enrolled in a public secondary high school in Eastern Philippines\nof the school year 2024-2025 and selected using stratified and systematic random sampling techniques. The study used\nan adapted survey questionnaire. Results revealed that senior high school students have a high perception and awareness\ntowards ethical implications of artificial intelligence. Furthermore, result showed that there is a significant difference in terms\nof age of senior high school towards perceptions and attitudes on the ethical implications of artificial intelligence and there\nis no significant difference between perceptions and awareness in terms of sex and grade level. The study concludes that\nwhile students are largely optimistic about AI in education, proactive measures are crucial to ensure responsible and fair use\nof this technology. Further research should focus on addressing resource inequalities and translating ethical concerns into\nconcrete policies and practices. The study emphasizes how urgently proactive steps must be taken to guarantee the ethical and\nresponsible application of artificial intelligence in education, including addressing resource disparities and converting moral\nconsiderations into tangible rules and procedures. This highlighted a potential access to AI resources and training, raising\nconcerns about equitable implementation.",
    "doi": "10.23880/oajda-16000155",
    "url": "https://www.semanticscholar.org/paper/e9cccc30b9fb6526792691b26bbd9db4c05342f5",
    "pdf_url": "",
    "venue": "Open Access Journal of Data Science and Artificial Intelligence",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586987"
  },
  {
    "source": "semantic_scholar",
    "source_id": "171d499744efcdd871c72757714f002af5d5e5df",
    "title": "Ethical Reflections on Artificial Intelligence",
    "authors": [
      "B. Green"
    ],
    "year": 2018,
    "abstract": "Artificial Intelligence (AI) technology presents a multitude of ethical concerns, many of which are being actively considered by organizations ranging from small groups in civil society to large corporations and governments. However, it also presents ethical concerns which are not being actively considered. This paper presents a broad overview of twelve topics in ethics in AI, including function, transparency, evil use, good use, bias, unemployment, socio-economic inequality, moral automation and human de-skilling, robot consciousness and rights, dependency, social-psychological effects, and spiritual effects. Each of these topics will be given a brief discussion, though each deserves much deeper consideration.",
    "doi": "10.12775/SETF.2018.015",
    "url": "https://www.semanticscholar.org/paper/171d499744efcdd871c72757714f002af5d5e5df",
    "pdf_url": "https://apcz.umk.pl/czasopisma/index.php/SetF/article/download/SetF.2018.015/15729",
    "venue": "Scientia et Fides",
    "citation_count": 42,
    "fields_of_study": [
      "Sociology"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586990"
  },
  {
    "source": "semantic_scholar",
    "source_id": "9b688157f467a83b7f4f6ac4eae7754241018aef",
    "title": "Examining Ethical Aspects of AI: Addressing Bias and Equity in the Discipline",
    "authors": [
      "Jeff Shuford"
    ],
    "year": 2024,
    "abstract": "he rapid progress in implementing Artificial Intelligence (AI) across various domains such as healthcare decision-making, medical diagnosis, and others has raised significant concerns regarding the fairness and bias embedded within AI systems. This is particularly crucial in sectors like healthcare, employment, criminal justice, credit scoring, and the emerging field of generative AI models (GenAI) producing synthetic media. Such systems can lead to unfair outcomes and perpetuate existing inequalities, including biases ingrained in the synthetic data representation of individuals.This survey paper provides a concise yet comprehensive examination of fairness and bias in AI, encompassing their origins, ramifications, and potential mitigation strategies. We scrutinize sources of bias, including data, algorithmic, and human decision biases, shedding light on the emergent issue of generative AI bias where models may replicate and amplify societal stereotypes. Assessing the societal impact of biased AI systems, we spotlight the perpetuation of inequalities and the reinforcement of harmful stereotypes, especially as generative AI gains traction in shaping public perception through generated content.Various proposed mitigation strategies are explored, with an emphasis on the ethical considerations surrounding their implementation. We stress the necessity of interdisciplinary collaboration to ensure the effectiveness of these strategies. Through a systematic literature review spanning multiple academic disciplines, we define AI bias and its various types, delving into the nuances of generative AI bias. We discuss the adverse effects of AI bias on individuals and society, providing an overview of current approaches to mitigate bias, including data preprocessing, model selection, and post-processing. Unique challenges posed by generative AI models are highlighted, underscoring the importance of tailored strategies to address them effectively.Addressing bias in AI necessitates a holistic approach, involving diverse and representative datasets, enhanced transparency, and accountability in AI systems, and exploration of alternative AI paradigms prioritizing fairness and ethical considerations. This survey contributes to the ongoing discourse on developing fair and unbiased AI systems by outlining the sources, impacts, and mitigation strategies related to AI bias, with a particular focus on the burgeoning field of generative AI.",
    "doi": "10.60087/jaigs.v3i1.119",
    "url": "https://www.semanticscholar.org/paper/9b688157f467a83b7f4f6ac4eae7754241018aef",
    "pdf_url": "https://ojs.boulibrary.com/index.php/JAIGS/article/download/119/87",
    "venue": "Journal of Artificial Intelligence General science (JAIGS) ISSN:3006-4023",
    "citation_count": 10,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586993"
  },
  {
    "source": "semantic_scholar",
    "source_id": "b4d21b18308b6b6786c00c303bb49327934d60fd",
    "title": "How to survive in the age of artificial intelligence? Exploring the intelligent transformations of SMEs in central China",
    "authors": [
      "Jinqiang Wang",
      "Yao-bin Lu",
      "S. Fan",
      "Peng Hu",
      "Bin Wang"
    ],
    "year": 2021,
    "abstract": "PurposeThe purpose of the research is to explore how small and medium enterprises (SMEs) in central China achieve intelligent transformation through the use of artificial intelligence (AI). Because of unequal resource allocation, constraints on the intelligent transformation of SMEs in central China are different from those in economically and technologically well-developed coastal provinces. Hence, the authors focus on SMEs in central China to identify drivers of and barriers to intelligent transformation.Design/methodology/approachThe interview data were collected from 66 SMEs across 20 industries in central China. To verify the validity of the data collection method, the authors used two methods to control for retrospective bias: multi-level informants and enterprises' AI project application materials (Wei and Clegg, 2020). The final data were validated without conflicts. Next, the authors cautiously followed a two-step approach recommended by Venkatesh et\u00a0al. (2010) and used NVivo 11.0 to analyze the collected text data.FindingsSMEs in central China are enthusiastic about intelligent transformation while facing both internal and external pressures. SMEs need to pay attention to both internal (enterprise development needs, implementation cost, human resources and top management involvement) and external factors (external market pressure, convenience of AI technology and policy support) and their different impacts on intelligent transformation. However, constrained by limited resources, SMEs in central China have been forced to take a step-by-step intelligent transformation strategy based on their actual needs with the technological flexibility method in the short term.Originality/valueConsidering the large number of SMEs and their importance in promoting China's economic development and job creation (SME Bureau of MIIT, 2020), more research on SMEs with limited resources is needed. In the study, the authors confirmed that enterprises should handle \u201csocial responsibility\u201d carefully because over-emphasizing it will hinder intelligent transformation. However, firms should pay attention to the role of executives in promoting intelligent transformation and make full use of policy support to access more resources.",
    "doi": "10.1108/ijoem-06-2021-0985",
    "url": "https://www.semanticscholar.org/paper/b4d21b18308b6b6786c00c303bb49327934d60fd",
    "pdf_url": "",
    "venue": "International Journal of Emerging Markets",
    "citation_count": 43,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586997"
  },
  {
    "source": "semantic_scholar",
    "source_id": "8c32d5141b0fd8b88366550ffe17a70a8c8a8167",
    "title": "Evaluating accountability, transparency, and bias in AI-assisted healthcare decision- making: a qualitative study of healthcare professionals\u2019 perspectives in the UK",
    "authors": [
      "Saoudi CE Nouis",
      "Victoria Uren",
      "Srushti Jariwala"
    ],
    "year": 2025,
    "abstract": "While artificial intelligence (AI) has emerged as a powerful tool for enhancing diagnostic accuracy and streamlining workflows, key ethical questions remain insufficiently explored\u2014particularly around accountability, transparency, and bias. These challenges become especially critical in domains such as pathology and blood sciences, where opaque AI algorithms and non-representative datasets can impact clinical outcomes. The present work focuses on a single NHS context and does not claim broader generalization. We conducted a local qualitative study across multiple healthcare facilities in a single NHS Trust in the West Midlands, United Kingdom, to investigate healthcare professionals\u2019 experiences and perceptions of AI-assisted decision-making. Forty participants\u2014including clinicians, healthcare administrators, and AI developers\u2014took part in semi-structured interviews or focus groups. Transcribed data were analyzed using Braun and Clarke\u2019s thematic analysis framework, allowing us to identify core themes relating to the benefits of AI, ethical challenges, and potential mitigation strategies. Participants reported notable gains in diagnostic efficiency and resource allocation, underscoring AI\u2019s potential to reduce turnaround times for routine tests and enhance detection of abnormalities. Nevertheless, accountability surfaced as a pervasive concern: while clinicians felt ultimately liable for patient outcomes, they also relied on AI-generated insights, prompting questions about liability if systems malfunctioned. Transparency emerged as another major theme, with clinicians emphasizing the difficulty of trusting \u201cblack box\u201d models that lack clear rationale or interpretability\u2014particularly for rare or complex cases. Bias was repeatedly cited, especially when algorithms underperformed in minority patient groups or in identifying atypical presentations. These issues raised doubts about the fairness and reliability of AIassisted diagnoses. Although AI demonstrates promise for improving efficiency and patient care, unresolved ethical complexities around accountability, transparency, and bias may erode stakeholder confidence and compromise patient safety. Participants called for clearer regulatory frameworks, inclusive training datasets, and stronger clinician\u2013developer collaboration. Future research should incorporate patient perspectives, investigate long-term impacts of AI-driven clinical decisions, and refine ethical guidelines to ensure equitable, responsible AI deployment. : Not applicable.",
    "doi": "10.1186/s12910-025-01243-z",
    "url": "https://www.semanticscholar.org/paper/8c32d5141b0fd8b88366550ffe17a70a8c8a8167",
    "pdf_url": "",
    "venue": "BMC Medical Ethics",
    "citation_count": 16,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:06.587000"
  },
  {
    "source": "semantic_scholar",
    "source_id": "493050e590e4b8845b95c57c7d87932d432f2c28",
    "title": "Evaluating Generalization, Bias, and Fairness in Deep Learning for Metal Surface Defect Detection: A Comparative Study",
    "authors": [
      "Singharat Rattanaphan",
      "Alexia Briassouli"
    ],
    "year": 2024,
    "abstract": "In recent years, deep learning models have led to improved accuracy in industrial defect detection, often using variants of YOLO (You Only Look Once), due to its high performance at a low cost. However, the generalizability, fairness and bias of their outcomes have not been examined, which may lead to overconfident predictions. Additionally, the complexity added by co-occurring defects, single and multi-class defects, and the effect on training, is not taken into consideration. This study addresses these critical gaps by introducing new methodologies for analyzing dataset complexity and evaluating model fairness. It introduces the novel approach of co-occurrence impact analysis, examining how the co-occurrence of defects in sample images affects performance, and introducing new dimensions to dataset preparation and training. Its aim is to increase model robustness in the face of real-world scenarios where multiple defects often appear together. Our study also innovates in the evaluation of model fairness by adapting the disparate impact ratio (DIR) to consider the true positive rate (TPR) across different groups and modifying the predictive parity difference (PPD) metric to focus on biases present in industrial quality control. Experiments demonstrate by cross-validation that the model trained on combined datasets significantly outperforms others in accuracy without overfitting and results in increased fairness, as validated by our novel fairness metrics. Explainability also provides valuable insights on the effects of different training regimes, notably absent in prior works. This work not only advances the field of deep learning for defect detection but also provides a strategic framework for future advancements, emphasizing the need for balanced datasets and considerations of ethics, fairness, bias and generalizability in the deployment of artificial intelligence in industry.",
    "doi": "10.3390/pr12030456",
    "url": "https://www.semanticscholar.org/paper/493050e590e4b8845b95c57c7d87932d432f2c28",
    "pdf_url": "https://www.mdpi.com/2227-9717/12/3/456/pdf?version=1708701741",
    "venue": "Processes",
    "citation_count": 5,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.587003"
  },
  {
    "source": "semantic_scholar",
    "source_id": "5816b7cbdc7793c3447c854e0d543fed96b55988",
    "title": "Automated Decision Making in Airport Checkpoints: Bias Detection Toward Smarter Security and Fairness",
    "authors": [
      "D. Kyriazanos",
      "K. Thanos",
      "S. Thomopoulos"
    ],
    "year": 2019,
    "abstract": "Automated decision making emerges as the enabler for risk-based and smarter security. However, ethics, privacy, and the General Data Protection Regulation (GDPR) provide a very challenging setting along with monitoring fairness and bias detection when applying artificial intelligence (AI) security solutions.",
    "doi": "10.1109/MSEC.2018.2888777",
    "url": "https://www.semanticscholar.org/paper/5816b7cbdc7793c3447c854e0d543fed96b55988",
    "pdf_url": "",
    "venue": "IEEE Security and Privacy",
    "citation_count": 11,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:06.587007"
  },
  {
    "source": "semantic_scholar",
    "source_id": "150769b73fda6c0f1aeedb91dc4567ca28893bdc",
    "title": "Policies for Artificial Intelligence in Science and Innovation",
    "authors": [
      "A. Paic"
    ],
    "year": 2020,
    "abstract": "This contribution synthesizes the discussions of the special session on policies for Artificial Intelligence in Science and Innovation, organized by the OECD\u2019s Directorate for Science, Technology and Innovation. The session was opened by Dr Judith Arrieta, Minister of the Foreign Service at the Chief of Staff\u2019s Office of the Secretary of Foreign Affairs of Mexico, and the two panels included speakers from governments, industry and civil society from European countries, USA,Canada China and Australia. Participants discussed the disruptive nature of AI and the formidable challenges it poses. Most of the discussion focused under the umbrella title of ethics, but they span very different issues of human-centered values, fairness, transparency, explainability, and many more. Other challenges include employment, education, SME policy, enabling environment, access to data and computing technology. Responses by governments were also discussed with a particular focus on national strategies, whose main pillars are oriented toward knowledge creation through AI research, knowledge diffusion through linkages to the private sector, development of human capital which will underpin the development of the sector, and a strong values, ethical and regulatory framework to create the conditions for the development of trustworthy AI. \nIn a world of finite resources, discussants concluded that one cannot apply very stringent requirements to all AI decisions, and there is clearly a need to require more transparency, explainability and robustness from systems which have the greatest impact on human lives. Therefore an approach based on algorithmic impact assessment seems reasonable. Such an approach needs to be further developed and standardized.",
    "doi": "10.22323/1.372.0045",
    "url": "https://www.semanticscholar.org/paper/150769b73fda6c0f1aeedb91dc4567ca28893bdc",
    "pdf_url": "https://pos.sissa.it/372/045/pdf",
    "venue": "Proceedings of Artificial Intelligence for Science, Industry and Society \u2014 PoS(AISIS2019)",
    "citation_count": 0,
    "fields_of_study": [
      "Political Science"
    ],
    "retrieved_at": "2026-02-02T16:58:06.587010"
  },
  {
    "source": "semantic_scholar",
    "source_id": "f0340c3932c4dcc9f505f06390540f16c7ee7905",
    "title": "Towards Responsible AI in Banking: Addressing Bias for Fair Decision-Making",
    "authors": [
      "Alessandro Castelnovo"
    ],
    "year": 2024,
    "abstract": "In an era characterized by the pervasive integration of artificial intelligence into decision-making processes across diverse industries, the demand for trust has never been more pronounced. This thesis embarks on a comprehensive exploration of bias and fairness, with a particular emphasis on their ramifications within the banking sector, where AI-driven decisions bear substantial societal consequences. In this context, the seamless integration of fairness, explainability, and human oversight is of utmost importance, culminating in the establishment of what is commonly referred to as\"Responsible AI\". This emphasizes the critical nature of addressing biases within the development of a corporate culture that aligns seamlessly with both AI regulations and universal human rights standards, particularly in the realm of automated decision-making systems. Nowadays, embedding ethical principles into the development, training, and deployment of AI models is crucial for compliance with forthcoming European regulations and for promoting societal good. This thesis is structured around three fundamental pillars: understanding bias, mitigating bias, and accounting for bias. These contributions are validated through their practical application in real-world scenarios, in collaboration with Intesa Sanpaolo. This collaborative effort not only contributes to our understanding of fairness but also provides practical tools for the responsible implementation of AI-based decision-making systems. In line with open-source principles, we have released Bias On Demand and FairView as accessible Python packages, further promoting progress in the field of AI fairness.",
    "doi": "10.48550/arXiv.2401.08691",
    "url": "https://www.semanticscholar.org/paper/f0340c3932c4dcc9f505f06390540f16c7ee7905",
    "pdf_url": "",
    "venue": "arXiv.org",
    "citation_count": 8,
    "fields_of_study": [
      "Mathematics",
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:06.587014"
  },
  {
    "source": "semantic_scholar",
    "source_id": "e8b3b7510ab2b9381573b89270d5582df5645e3e",
    "title": "Toward Urban Artificial Intelligence for Developing Justice-Oriented Smart Cities",
    "authors": [
      "Xinyue Ye",
      "Galen Newman",
      "Chanam Lee",
      "Shannon Van Zandt",
      "D. Jourdan"
    ],
    "year": 2023,
    "abstract": "Urban artificial intelligence (UAI) refers to the development and deployment of artificial intelligence (AI) technologies and solutions in urban settings such as energy management, environmental monitoring, public safety, transportation, and predictive maintenance. Urban research has shifted from a data-scarce to a data-rich environment in recent years. Big data and computational algorithms have become continually integrated into the built environment and within human\u2019s daily lives, leading to a significant rise in digital twin research. Heterogeneous real-time data can be synthesized from a wide range of sources such as sensors and cameras connected to buildings, factories, green spaces, roads, sidewalks, and other urban elements. Defined as a virtual representation of a physical urban environment, digital twins can be employed to analyze, model, and simulate various aspects of urban phenomena in the fine scale. The UAI will take the source data from sensors, satellite imagery, and social media over space, time, and scale as inputs, and generate outputs that typically include predictions or simulations of how urban elements or systems will be affected by these inputs. Powered by UAI, the bi-directional flow of data between a digital twin and the physical urban environment further allows the digital twin to both reflect the current state of the city and make more informed decisions about how to optimize the urban operation (Ye et al. 2022). Furthermore, the revolution of computing power and information technology has blurred the boundary across disciplines and urban applications. Linked with immersive technologies such as virtual reality (VR) and augmented reality (AR), UAI helps people to visualize cities as they change by showing how planning and infrastructure design can alter the urban environment reflecting the diverse perspectives and needs of the community, either positively or negatively. Collaboration across disciplines and stakeholders is often essential for addressing complex urban problems. UAI has the potential to help bridge the silos within design, social, and engineering sciences as well as growing gaps between research and practice, through activities such as citizen science, community-based research, and participatory research. UAI is revolutionizing urban planning education and practice by providing new tools for planners to automate certain tasks and make informed decisions (Sanchez et al. 2022). This allows planners to focus on more creative aspects of their work and efficiently evaluate large amounts of design options, ensuring that the final delivery is an optimized solution. Simultaneously, UAI enables a collective understanding of existing urban conditions and demonstrates innovative capabilities for how to increase cyber, social, and physical resilience and efficacy beyond simple technology integration. However, UAI could possibly exacerbate existing socioeconomic inequities in the built environment if such technical strength is not designed and used by researchers and practitioners in an ethical and responsible manner. Hence, UAI needs to be used to promote knowledge co-production, which refers to the inclusive process in which knowledge is created, shared, and used through active collaboration among people with different backgrounds, experiences, and perspectives (Shrestha et al. 2017). Driven by UAI, knowledge co-production can engage a variety of relevant parties to identify research questions and co-design/ implement research projects through the process of data collection, analysis, and dissemination. In addition, UAI-based knowledge co-production can help cultivate the trust between researchers and the local residents, and increase confidence in its decision-making abilities, leading to a more comprehensive and inclusive understanding of the needs and priorities of the communities they serve. In terms of data shortage issue especially in lower-income or under-resourced communities, UAI techniques can be used to augment existing data with additional sources of information, such as public data sets or data from citizen science. UAI is highly affected by its training data and the adopted algorithms. As a result, it inherits the built-in biases embedded in these data and algorithms. The potential unfair or discriminatory outcomes may result in serious consequences for individuals or society if such biased UAI is deployed in decision-making processes. Hence, planners need to mitigate the bias by using representative training data, documenting the training process in an open-source manner, and consistently assessing the AI functions. We need to be transparent about the data employed to train UAI and the algorithms used to develop it. It is also important for developers to be aware of data ethics involved in the procedure of collecting, managing, and using sensitive data. It is vital to ensure that the data collection is with the consent of the involved individuals and that it is used in a responsible manner. In addition, the AI 1154002 JPEXXX10.1177/0739456X231154002Journal of Planning Education and ResearchEditorial editorial2023",
    "doi": "10.1177/0739456X231154002",
    "url": "https://www.semanticscholar.org/paper/e8b3b7510ab2b9381573b89270d5582df5645e3e",
    "pdf_url": "https://journals.sagepub.com/doi/pdf/10.1177/0739456X231154002",
    "venue": "Journal of planning education and research",
    "citation_count": 12,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.587017"
  },
  {
    "source": "semantic_scholar",
    "source_id": "de9289d2ed7408457d34330eda07457d252f0e14",
    "title": "Impact of Artificial Intelligence on Recruitment and Selection of Information Technology Companies",
    "authors": [
      "A. Hemalatha",
      "P. Kumari",
      "N. Nawaz",
      "Vijayakumar Gajenderan"
    ],
    "year": 2021,
    "abstract": "Artificial Intelligence (AI) is one of the promising and compelling technologies nowadays which continuously transforms human lives and massively impacts almost all spheres of the business world. While AI is constructively indiscriminately flourishing in all fields, workforce management is not an exception to the rule. The primary purpose of this research is to critically analyze the impact that Artificial Intelligence (AI) is having on Human Resource management practices, more specifically on recruitment and Selection in organizations. The researcher has concentrated on four AI capabilities, namely Natural Language Processing, Machine Vision, Automation, and Augmentation, and their impact on the Recruitment and selection process. The researcher has collected primary data through an online survey from 141 IT employees regarding Chennai city. The researcher has also focused on external secondary data (articles and reports) to demonstrate some of the findings of the impact of AI capabilities on Recruitment and Selection. The study finds that AI technologies capabilities namely NLP, Machine Vision, Automation, and Augmentation have a significant impact on the Recruitment and Selection Process with potential positive outcomes such as time & cost-saving, accuracy, removes bias, reduced workload, increased efficiency, and candidate experience.",
    "doi": "10.1109/ICAIS50930.2021.9396036",
    "url": "https://www.semanticscholar.org/paper/de9289d2ed7408457d34330eda07457d252f0e14",
    "pdf_url": "",
    "venue": "International Conference on Adaptive and Intelligent Systems",
    "citation_count": 39,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.587021"
  },
  {
    "source": "semantic_scholar",
    "source_id": "f989e1c7738a3396e5225f4f506dcbdba13dbbf1",
    "title": "Artificial Intelligence in Supply Chain Management: A Systematic Review of Emerging Trends and Evidence in Healthcare Operations",
    "authors": [
      "Akande Sodiq Adedunjoye",
      "Joy Onma Enyejo"
    ],
    "year": 2023,
    "abstract": "The increasing complexity of healthcare supply chains characterized by fluctuating demand, stringent regulatory requirements, globalized procurement networks, and the critical need for real-time resource availability has accelerated the adoption of Artificial Intelligence (AI) as a transformative operational tool. This systematic review synthesizes emerging trends, empirical findings, and technological innovations in AI-enabled supply chain management within healthcare systems. Drawing on peer-reviewed literature from the past decade, the study examines how AI-driven techniques such as machine learning, predictive analytics, natural language processing, optimization algorithms, and intelligent automation enhance procurement forecasting, inventory management, logistics optimization, clinical resource allocation, and risk mitigation.\nThe review highlights the growing integration of AI with enabling technologies such as digital twins, Internet of Medical Things (IoMT), blockchain, and cloud-based analytics to strengthen supply chain visibility, traceability, and resilience. Evidence shows that AI significantly reduces stock-outs, improves demand prediction accuracy, enhances cold-chain monitoring, and supports decision-making in critical service lines such as pharmaceuticals, surgical supplies, and emergency care. Despite these advancements, major challenges remain, including data fragmentation, interoperability limitations, model transparency concerns, workforce capacity gaps, and ethical issues relating to bias, privacy, and automation risks. The review concludes by outlining future research directions, emphasizing the need for explainable AI (XAI), scalable real-time analytics, integrated data governance frameworks, and hybrid human-AI decision architectures. This study provides a consolidated knowledge base for policymakers, healthcare administrators, and supply chain professionals seeking evidence-based pathways for AI adoption in healthcare operations.",
    "doi": "10.38124/ijsrmt.v3i12.1055",
    "url": "https://www.semanticscholar.org/paper/f989e1c7738a3396e5225f4f506dcbdba13dbbf1",
    "pdf_url": "",
    "venue": "International Journal of Scientific Research and Modern Technology",
    "citation_count": 4,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.587024"
  },
  {
    "source": "semantic_scholar",
    "source_id": "42dcd0ae8e6a3dc294250d08949db1d6beb5f1c9",
    "title": "Human biases and remedies in AI safety and alignment contexts",
    "authors": [
      "Zo\u00e9 Roy-Stang",
      "Jim Davies"
    ],
    "year": 2025,
    "abstract": null,
    "doi": "10.1007/s43681-025-00698-5",
    "url": "https://www.semanticscholar.org/paper/42dcd0ae8e6a3dc294250d08949db1d6beb5f1c9",
    "pdf_url": "",
    "venue": "AI and Ethics",
    "citation_count": 2,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:06.587028"
  },
  {
    "source": "semantic_scholar",
    "source_id": "954f7412a37649eff89da3e84df0257aa63655e9",
    "title": "The dark side of generative artificial intelligence: A critical analysis of controversies and risks of ChatGPT",
    "authors": [
      "K. Wach",
      "Cong Doanh Duong",
      "J. Ejdys",
      "R\u016bta Kazlauskait\u0117",
      "P. Korzy\u0144ski",
      "G. Mazurek",
      "Joanna Paliszkiewicz",
      "E. Ziemba"
    ],
    "year": 2023,
    "abstract": "Objective: The objective of the article is to provide a comprehensive identification and understanding of the challenges and opportunities associated with the use of generative artificial intelligence (GAI) in business. This study sought to develop a conceptual framework that gathers the negative aspects of GAI development in management and economics, with a focus on ChatGPT. Research Design & Methods: The study employed a narrative and critical literature review and developed a conceptual framework based on prior literature. We used a line of deductive reasoning in formulating our theoretical framework to make the study\u2019s overall structure rational and productive. Therefore, this article should be viewed as a conceptual article that highlights the controversies and threats of GAI in management and economics, with ChatGPT as a case study. Findings: Based on the conducted deep and extensive query of academic literature on the subject as well as professional press and Internet portals, we identified various controversies, threats, defects, and disadvantages of GAI, in particular ChatGPT. Next, we grouped the identified threats into clusters to summarize the seven main threats we see. In our opinion they are as follows: (i) no regulation of the AI market and urgent need for regulation, (ii) poor quality, lack of quality control, disinformation, deepfake content, algorithmic bias, (iii) automation-spurred job losses, (iv) personal data violation, social surveillance, and privacy violation, (v) social manipulation, weakening ethics and goodwill, (vi) widening socio-economic inequalities, and (vii) AI technostress. Implications & Recommendations: It is important to regulate the AI/GAI market. Advocating for the regulation of the AI market is crucial to ensure a level playing field, promote fair competition, protect intellectual property rights and privacy, and prevent potential geopolitical risks. The changing job market requires workers to continuously acquire new (digital) skills through education and retraining. As the training of AI systems becomes a prominent job category, it is important to adapt and take advantage of new opportunities. To mitigate the risks related to personal data violation, social surveillance, and privacy violation, GAI developers must prioritize ethical considerations and work to develop systems that prioritize user privacy and security. To avoid social manipulation and weaken ethics and goodwill, it is important to implement responsible AI practices and ethical guidelines: transparency in data usage, bias mitigation techniques, and monitoring of generated content for harmful or misleading information. Contribution & Value Added: This article may aid in bringing attention to the significance of resolving the ethical and legal considerations that arise from the use of GAI and ChatGPT by drawing attention to the contro-versies and hazards associated with these technologies.",
    "doi": "10.15678/eber.2023.110201",
    "url": "https://www.semanticscholar.org/paper/954f7412a37649eff89da3e84df0257aa63655e9",
    "pdf_url": "https://eber.uek.krakow.pl/index.php/eber/article/view/2113/852",
    "venue": "Entrepreneurial Business and Economics Review",
    "citation_count": 348,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.587031"
  },
  {
    "source": "semantic_scholar",
    "source_id": "6a1f8f8247574b831f3f2ea97f8ca146415ed255",
    "title": "Navigating and reviewing ethical dilemmas in AI development: Strategies for transparency, fairness, and accountability",
    "authors": [
      "Olatunji Akinrinola",
      "Chinwe Chinazo Okoye",
      "Onyeka Chrisanctus Ofodile",
      "Chinonye Esther Ugochukwu"
    ],
    "year": 2024,
    "abstract": "As artificial intelligence (AI) continues to permeate various aspects of our lives, the ethical challenges associated with its development become increasingly apparent. This paper navigates and reviews the ethical dilemmas in AI development, focusing on strategies to promote transparency, fairness, and accountability. The rapid growth of AI technology has given rise to concerns related to bias, lack of transparency, and the need for clear accountability mechanisms. In this exploration, we delve into the intricate ethical landscape of AI, examining issues such as bias and fairness, lack of transparency, and the challenges associated with accountability. To address these concerns, we propose strategies for transparency, including the implementation of Explainable AI (XAI), advocating for open data sharing, and embracing ethical AI frameworks. Furthermore, we explore strategies to promote fairness in AI algorithms, emphasizing the importance of fairness metrics, diverse training data, and continuous monitoring for iterative improvement. Additionally, the paper delves into strategies to ensure accountability in AI development, considering regulatory measures, ethical AI governance, and the incorporation of human-in-the-loop approaches. To provide practical insights, case studies and real-world examples are analyzed to distill lessons learned and best practices. The paper concludes with a comprehensive overview of the proposed strategies, emphasizing the importance of balancing innovation with ethical responsibility in the evolving landscape of AI development. This work contributes to the ongoing discourse on AI ethics, offering a roadmap for navigating the challenges and fostering responsible AI development practices.",
    "doi": "10.30574/gscarr.2024.18.3.0088",
    "url": "https://www.semanticscholar.org/paper/6a1f8f8247574b831f3f2ea97f8ca146415ed255",
    "pdf_url": "https://gsconlinepress.com/journals/gscarr/sites/default/files/GSCARR-2024-0088.pdf",
    "venue": "GSC Advanced Research and Reviews",
    "citation_count": 97,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.587035"
  },
  {
    "source": "semantic_scholar",
    "source_id": "29ab6634af3a6772404b03bb00895d21a6416524",
    "title": "Exploring the potential of Claude 2 for risk of bias assessment: Using a large language model to assess randomized controlled trials with RoB 2",
    "authors": [
      "Angelika Eisele-Metzger",
      "Judith-Lisa Lieberum",
      "M. Toews",
      "Waldemar Siemens",
      "Felix Heilmeyer",
      "Christian Haverkamp",
      "D. Boehringer",
      "Joerg J. Meerpohl"
    ],
    "year": 2024,
    "abstract": "Systematic reviews are essential for evidence based healthcare, but conducting them is time and resource consuming. To date, efforts have been made to accelerate and (semi-) automate various steps of systematic reviews through the use of artificial intelligence and the emergence of large language models (LLMs) promises further opportunities. One crucial but complex task within systematic review conduct is assessing the risk of bias of included studies. Therefore, the aim of this study was to test the LLM Claude 2 for risk of bias assessment of 100 randomized controlled trials using the revised Cochrane risk of bias tool (\"RoB 2\"; involving judgements for five specific domains and an overall judgement). We assessed the agreement of risk of bias judgements by Claude with human judgements published in Cochrane Reviews. The observed agreement between Claude and Cochrane authors ranged from 41% for the overall judgement to 71% for domain 4 (\"outcome measurement\"). Cohen's Kappa was lowest for domain 5 (\"selective reporting\"; 0.10 (95% confidence interval (CI): -0.10-0.31)) and highest for domain 3 (\"missing data\"; 0.31 (95% CI: 0.10-0.52)), indicating slight to fair agreement. Fair agreement was found for the overall judgement (Cohen's Kappa: 0.22 (95% CI: 0.06-0.38)). Sensitivity analyses using alternative prompting techniques or the more recent version Claude 3 did not result in substantial changes. Currently, Claude's RoB 2 judgements cannot replace human risk of bias assessment. However, the potential of LLMs to support risk of bias assessment should be further explored.",
    "doi": "10.1017/rsm.2025.12",
    "url": "https://www.semanticscholar.org/paper/29ab6634af3a6772404b03bb00895d21a6416524",
    "pdf_url": "https://doi.org/10.1101/2024.07.16.24310483",
    "venue": "medRxiv",
    "citation_count": 9,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:06.587039"
  },
  {
    "source": "semantic_scholar",
    "source_id": "6c1441fbc440f0dcc1a94bdcf1cb61a2eb7738b2",
    "title": "Artificial Intelligence Involvement in Graphic Game Development",
    "authors": [
      "Safal Antony",
      "Sabari T",
      "R. I. Joshua",
      "N. Jayapandian"
    ],
    "year": 2023,
    "abstract": "Games have always been a popular form of entertainment and with the advancements in technology, the integration of Artificial Intelligence (AI) in gaming has revolutionized the gaming industry. This research article aims to explore the various applications of AI in gaming and its impact on the industry and player experience. Unlike the typical straightforward nature of AI, this research paper takes a more human approach to discussing the topic. It delves into the evolution of AI in games and the various types of AI used in game development. These include rule-based AI, learning- based AI, and evolutionary AI, which have all contributed to the development of increasingly immersive gaming experiences. The benefits and challenges of using AI in games are also explored, considering the impact on player experience. While AI-powered opponents can provide a greater challenge, balancing the difficulty level is critical to ensuring the game remains enjoyable. The potential ethical concerns of using AI in games are also discussed, such as data privacy, bias, and fairness. Furthermore, this research paper looks into the future of AI in games and how it may shape the gaming industry and player experience in the years to come. With the continued development of AI techniques such as reinforcement learning and GANs, the possibilities for more immersive and engaging gaming experiences are endless.",
    "doi": "10.1109/ICAISS58487.2023.10250553",
    "url": "https://www.semanticscholar.org/paper/6c1441fbc440f0dcc1a94bdcf1cb61a2eb7738b2",
    "pdf_url": "",
    "venue": "2023 Second International Conference on Augmented Intelligence and Sustainable Systems (ICAISS)",
    "citation_count": 3,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.587042"
  },
  {
    "source": "semantic_scholar",
    "source_id": "0bb7a2c972d341efe80e76a09beaa69b2efd38e3",
    "title": "Toward Fairness, Morality and Transparency in Artificial Intelligence through Experiential AI",
    "authors": [
      "D. Hemment",
      "Vaishak Belle",
      "R. Aylett",
      "Dave Murray-Rust",
      "Larissa Pschetz",
      "Frank Broz"
    ],
    "year": 2019,
    "abstract": "https://doi.org/10.1162/leon_a_01795 \u00a92019 ISAST The new research Theme experienTial ai, at Edin\u00ad burgh Futures Institute, responds to concerns around the societal impacts of artificial intelligence (AI) and proposes a cross\u00addisciplinary AI research and practice between art and science [1]. The last year has been a watershed for the conjunction of art and AI, reflected in Ars Electronica introducing a new category in their Prix [2]. Elsewhere, capabilities of AI were often overclaimed in reporting on the first artwork \u201ccreated by an algorithm\u201d to be sold at Christie\u2019s [3]. Increasingly, art\u00ad ists are experimenting with machine learning algorithms as subject and tool. Something of an emerging machine learning aesthetic reveals and manifests distortions in the ways algo\u00ad rithms interpret the world. The misshapen imagery that can result, named by one proponent the \u201cFrancis Bacon effect\u201d [4], arguably enables the character of machine reasoning and vision to be made explicit and its artifacts tangible [5]. Other artists have addressed the social and ethical conse\u00ad quences of algorithms. CV Dazzle by Adam Harvey presents hair styling and makeup as camouflage from face\u00addetection technology [6], and Mushon Zer\u00adAviv questions the con\u00ad struction of prejudice and normalcy in The Normalizing Machine [7]. The fairness and morality of AI systems, a topic so far little explored by the current generation of artists working with machine learning algorithms, is already under inves\u00ad tigation by AI scientists. Because most prediction systems look for frequent patterns, algorithms trained on data em\u00ad bodying specific historical and cultural biases produce, un\u00ad surprisingly, systems exhibiting these same biases. Thus, AI researchers are devising definitions that enable predictions to respect fairness constraints with respect to gender, race and other \u201cprotected attributes\u201d despite biases in data. Fairness is, however, one part of a larger picture. AI al\u00ad gorithms are frequently used for recruitment and trading stocks but also in self\u00addriving cars and domestic robots that act physically on the environment and with people. What biases might these robotic applications infer from long\u00adterm interactions with us? Conversely, what values would we like them to embody? Should we strive for a shared computa\u00ad tional framework enabling machines to reason about their actions and ethical implications? How can we make such systems sufficiently transparent that we can understand and critique their reasoning? The design of moral machines needs to account for the con\u00ad tingency of human value systems across contexts, cultures and demographic groups. The logic of computation shapes political and public discourse in its image, in ways that can be inimical to societal values. There are, therefore, longstanding concerns about translating morals from the domain of human ethics and politics into a framework using numeric repre\u00ad sentations. We must both consider machines that can engage in ethical reasoning and simultaneously recommend social domains that are not suited to automated decision\u00admaking. Fairness, morality and transparency will be the theme of the first program in Experiential AI. Participating artists will experiment with new ideas, data and technologies and engage both AI practitioners and publics in envisioning fu\u00ad tures for ethical and responsible AI. Their works can allow audiences to explore future scenarios and experience various aspects of the moral dimension, making algorithmic mecha\u00ad nisms vividly apparent. As a methodology and approach, experiential AI can ques\u00ad tion data harvesting, algorithms and the outcomes of their application, and how a system is understood. Art can create experiences around social impacts and consequences of tech\u00ad nology, giving audiences direct experience of philosophical and computational principles. It can challenge what the algo\u00ad rithms are and how they are used. This can lead to significant new works and create insights to feed into the design of these technologies.",
    "doi": "10.1162/leon_a_01795",
    "url": "https://www.semanticscholar.org/paper/0bb7a2c972d341efe80e76a09beaa69b2efd38e3",
    "pdf_url": "https://www.pure.ed.ac.uk/ws/files/106508348/Toward_Fairness_Morality_HEMMENT_DoA090719_AFV.pdf",
    "venue": "Leonardo: Journal of the International Society for the Arts, Sciences and Technology",
    "citation_count": 1,
    "fields_of_study": [
      "Psychology"
    ],
    "retrieved_at": "2026-02-02T16:58:06.587046"
  },
  {
    "source": "semantic_scholar",
    "source_id": "ae45f035d155b4001c53436fc7e7147c3d39eb39",
    "title": "Beyond fairness, accountability, and transparency in the ethics of algorithms: Contributions and perspectives from LIS",
    "authors": [
      "A. Hoffmann",
      "Sarah T. Roberts",
      "Christine T. Wolf",
      "Stacy Wood"
    ],
    "year": 2018,
    "abstract": null,
    "doi": "10.1002/PRA2.2018.14505501084",
    "url": "https://www.semanticscholar.org/paper/ae45f035d155b4001c53436fc7e7147c3d39eb39",
    "pdf_url": "",
    "venue": "ASIS&T Annual Meeting",
    "citation_count": 22,
    "fields_of_study": [
      "Computer Science",
      "Sociology"
    ],
    "retrieved_at": "2026-02-02T16:58:06.587049"
  }
]