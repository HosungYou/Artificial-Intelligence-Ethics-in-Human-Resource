[
  {
    "source": "semantic_scholar",
    "source_id": "08127aa0f141b9be6b391664db028d4dd2a37232",
    "title": "Managing Transparency Fairness Accountability in AI for Sustainable Human Resource Management",
    "authors": [
      "Rini Setiawati",
      "Ardi Kusmara",
      "Taavi Kuusk"
    ],
    "year": 2025,
    "abstract": "The proliferation of Artificial Intelligence (AI) in Human Resource Management (HRM) offers significant efficiencies but concurrently introduces critical ethical challenges regarding transparency, fairness, and accountability, thereby impacting sustainable workforce management. The novelty of this study lies in its exploration of strategies for effectively managing these ethical dimensions in AI-driven HRM, with a focus on identifying practical solutions to mitigate algorithmic bias and enhance transparency. The research focuses on identifying ethical issues, such as algorithmic bias and lack of transparency in AI-assisted recruitment, performance evaluation, and overall employee management. Adopting a Systematic Literature Review (SLR) methodology, this paper analyzes recent publications (2019-2024) from Scopus to synthesize existing knowledge on AI ethics in HRM. Key findings reveal a significant lack of standardized best practices and audit trails, with opaque AI-driven decisions often undermining trust and fairness. If not properly designed, AI algorithms can perpetuate biases embedded in historical data, leading to discriminatory outcomes, as evidenced by cases at companies like Amazon and HireVue. The study concludes that organizations must proactively implement robust governance frameworks, including ethics training, the development of transparent and fair-by-design algorithms, regular audits, and mechanisms for human oversight. Integrating frameworks such as Fairness, Accountability, and Transparency (FAT) and Ethical AI by Design is crucial for ensuring that AI applications in HRM are ethically sound, legally compliant, and contribute to sustainable and equitable workforce management.",
    "doi": "10.1109/ICCIT65724.2025.11166968",
    "url": "https://www.semanticscholar.org/paper/08127aa0f141b9be6b391664db028d4dd2a37232",
    "pdf_url": "",
    "venue": "International Conference on Communications and Information Technology",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.894980"
  },
  {
    "source": "semantic_scholar",
    "source_id": "7fc48e5cbc04f976bff6f6d92e19b0520d903ef0",
    "title": "Professional Ethics in Human Resource Management in the Era of Digital Transformation: Challenges and Opportunities",
    "authors": [
      "Dito Aditia Darma Nst",
      "Ela Diovera Niel",
      "Lismayana Eryanti Siregar",
      "Muti Lulu Habibah",
      "Elveria Melda Sinaga",
      "Nur Ainun Rahma Lubis",
      "M Falahul Anshor"
    ],
    "year": 2025,
    "abstract": "Digital transformation has significantly reshaped human resource management (HRM) through the adoption of Human Resource Information Systems (HRIS), artificial intelligence (AI), big data analytics, e-learning platforms, and remote work technologies. Although these innovations improve efficiency and decision-making, they also generate ethical challenges related to data privacy, algorithmic bias, transparency, and employee monitoring. This article examines the role of professional ethics in HRM within the context of digital transformation, highlighting both emerging challenges and potential opportunities. This study employs a conceptual research approach supported by a comprehensive literature review of scholarly works on HRM, professional ethics, and digitalization. The analysis focuses on core ethical principles such as integrity, fairness, responsibility, professionalism, and confidentiality, and evaluates their implementation in digital HR practices. The findings indicate that unethical use of digital technologies may lead to discrimination, reduced employee trust, and violations of individual rights, particularly through biased AI-based recruitment systems and opaque performance evaluation mechanisms. However, digital transformation also offers opportunities to strengthen ethical HR governance. The use of ethical data management, algorithmic audits, digital transparency, and e-learning-based ethics training can enhance accountability and fairness in HR processes. The study concludes that integrating professional ethics with digital HRM is essential for developing human-centered, sustainable, and trustworthy organizations in the digital era.",
    "doi": "10.61132/icmeb.v2i2.291",
    "url": "https://www.semanticscholar.org/paper/7fc48e5cbc04f976bff6f6d92e19b0520d903ef0",
    "pdf_url": "",
    "venue": "Proceeding of the International Conference on Management, Entrepreneurship, and Business",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.894998"
  },
  {
    "source": "semantic_scholar",
    "source_id": "fccd2b6ca6be4163a868c191b9153d52c6d6a036",
    "title": "Human Rights and Artificial Intelligence in Healthcare-Related Settings: A Grammar of Human Rights Approach.",
    "authors": [
      "Helga Molb\u00e6k-Steensig",
      "M. Scheinin"
    ],
    "year": 2025,
    "abstract": "This article examines the expanding role of Artificial Intelligence (AI) in healthcare and associated human rights concerns, including whether new EU legislation takes all relevant human rights concerns into account. AI presents promising ways to fulfil the right to health through improving diagnostics, treatments, and resource allocation, but its use also comes with risks concerning privacy, bias, discrimination, and human dignity. Existing literature often relies on the rather vague FATE (Fairness, Accountability, Transparency, Ethics) principles, but recent calls have been made for a human-rights-based approach more broadly to ensure the legality and ethics of AI applications. This article responds to that call by proposing a structured methodology for reconciling rights, considering both the different structures of civil and political versus economic, social and cultural human rights, the negative and positive obligations of the state, and the interplay with different AI design choices.",
    "doi": "10.1163/15718093-bja10146",
    "url": "https://www.semanticscholar.org/paper/fccd2b6ca6be4163a868c191b9153d52c6d6a036",
    "pdf_url": "",
    "venue": "European Journal of Health Law",
    "citation_count": 1,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:49.895006"
  },
  {
    "source": "semantic_scholar",
    "source_id": "53d4f0e7b936b541ccd72093527d4bb5b9aaa22a",
    "title": "Can HR adapt to the paradoxes of artificial intelligence?",
    "authors": [
      "Andy Charlwood",
      "Nigel Guenole"
    ],
    "year": 2022,
    "abstract": "Artificial intelligence (AI) is widely heralded as a new and revolutionary technology that will transform the world of work. While the impact of AI on human resource (HR) and people management is difficult to predict, the article considers potential scenarios for how AI will affect our field. We argue that although popular accounts of AI stress the risks of bias and unfairness, these problems are eminently solvable. However, the way that the AI industry is currently constituted and wider trends in the use of technology for organising work mean that there is a significant risk that AI use will degrade the quality of work. Viewing different scenarios through a paradox lens, we argue that both positive and negative visions of the future are likely to coexist. The HR profession has a degree of agency to shape the future if it chooses to use it; HR professionals need to develop the skills to ensure that ethics and fairness are at the centre of AI development for HR and people management.",
    "doi": "10.1111/1748-8583.12433",
    "url": "https://www.semanticscholar.org/paper/53d4f0e7b936b541ccd72093527d4bb5b9aaa22a",
    "pdf_url": "https://doi.org/10.1111/1748-8583.12433",
    "venue": "Human Resource Management Journal",
    "citation_count": 154,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895011"
  },
  {
    "source": "semantic_scholar",
    "source_id": "60704201f864cf64a66a562f6c4de7a9f52d9054",
    "title": "The emergence of \u201ctruth machines\u201d?: Artificial intelligence approaches to lie detection",
    "authors": [
      "Jo Ann Oravec"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1007/s10676-022-09621-6",
    "url": "https://www.semanticscholar.org/paper/60704201f864cf64a66a562f6c4de7a9f52d9054",
    "pdf_url": "",
    "venue": "Ethics and Information Technology",
    "citation_count": 30,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:49.895015"
  },
  {
    "source": "semantic_scholar",
    "source_id": "26ccb19d6cb2c18fe8e9f6bc29494e098dd5b90b",
    "title": "An Ethical Governance Framework for AI-Driven Competency Assessment",
    "authors": [],
    "year": 2025,
    "abstract": "The expanding application of artificial intelligence (AI) in human resource (HR) management for competency evaluation reflects organisations' pursuit of efficiency, yet this growth has outpaced the development of essential ethics and governance. This study aimed to determine sectoral differences in perceptions of AI-based evaluation and to develop a tool that balances efficiency with ethics. A small-scale mixed-methods pilot study with professionals in the energy (safety-critical) and education (empathy-based) sectors revealed attitudes differing by sector. While energy practitioners viewed AI as a promising tool for reducing bias in safety analysis, educators were more skeptical, emphasizing challenges around transparency, creativity, and contextual judgment. This paper introduces the Responsible AI Competence Assessment (RAICA) framework to address these governance gaps. RAICA extends the Technology Acceptance Model (TAM) through the addition of ethical trust, algorithmic fairness, and sector-sensitive validation metrics. Furthermore, the framework translates abstract policy instruments into actionable operational protocols, including mandates for bias auditing and algorithmic explainability. The proposed framework provides a flexible and practical governance template for high-stakes decision-making across diverse sectors by bridging efficiency and ethical accountability.",
    "doi": "10.55057/ijbtm.2025.7.11.10",
    "url": "https://www.semanticscholar.org/paper/26ccb19d6cb2c18fe8e9f6bc29494e098dd5b90b",
    "pdf_url": "",
    "venue": "International Journal of Business and Technology Management",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895020"
  },
  {
    "source": "semantic_scholar",
    "source_id": "dfd7bc2c8a4e4d9ef0e9658de53c28b65ca10987",
    "title": "Ethically Aligned Artificial Intelligence: Investigating Algorithmic Bias, Human Identity, and Posthuman Ethics through a Data-Driven Philosophical Lens",
    "authors": [
      "A. Alyousef",
      "Asem Omari"
    ],
    "year": 2025,
    "abstract": "Human society is being transformed by AI at an unprecedented speed-and in this context questions regarding fairness, agency, and identity become very tricky. This paper presents an interdisciplinary study into algorithmic bias and its ethical implicature in the relationship of data science and philosophy. By bringing into account concepts from posthumanism and moral theory, the research scrutinizes the redefinition of human identity within an age of autonomous systems and artificial consciousness. It proposes a data-oriented mechanism to the detection and mitigation of bias in AI systems, substantiated with case studies in health care and recruitment. One of the emphases of this work is on transparency, accountability, and inclusive governance, ultimately arguing for ethically aligned AI that promotes human dignity concurrent with evolving technological realities. Implications of this study point toward diversifying the development of a new ethical paradigm with the capability to regulate AI design, deployment, and policy.",
    "doi": "10.63332/joph.v5i5.1316",
    "url": "https://www.semanticscholar.org/paper/dfd7bc2c8a4e4d9ef0e9658de53c28b65ca10987",
    "pdf_url": "",
    "venue": "Journal of Posthumanism",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895024"
  },
  {
    "source": "semantic_scholar",
    "source_id": "bb3c1e07efa0b94a883b5d18a6135137f9b0dadb",
    "title": "Is Artificial Intelligence (AI) Research Biased and Conceptually Vague? A Systematic Review of Research on Bias and Discrimination in the context of using AI in Human Resource Management",
    "authors": [
      "Ivan Kekez",
      "Lode Lauwaert",
      "Nina Begi\u010devi\u0107 Re\u0111ep"
    ],
    "year": 2025,
    "abstract": null,
    "doi": "10.1016/j.techsoc.2025.102818",
    "url": "https://www.semanticscholar.org/paper/bb3c1e07efa0b94a883b5d18a6135137f9b0dadb",
    "pdf_url": "https://doi.org/10.1016/j.techsoc.2025.102818",
    "venue": "Technology and Society",
    "citation_count": 17,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895029"
  },
  {
    "source": "semantic_scholar",
    "source_id": "1f3b09fa5891b23452636914a1ffbd965f68a654",
    "title": "Artificial Intelligence Ethics: A Dialogue between Technological Advances and Human Values",
    "authors": [
      "Linji Fan"
    ],
    "year": 2024,
    "abstract": "The rapid development of artificial intelligence technology has already had a profound impact in various fields, ranging from healthcare and education to transport and finance. However, accompanying these technological advances are a series of complex and profound ethical issues. These issues involve not only data privacy and security, but also challenges of algorithmic bias, fairness, and transparency in decision-making. In addition, the \u2018black box\u2019 nature of AI systems blurs the attribution of responsibility and increases society's distrust of the technology. As AI is increasingly used in society, the question of how to find a balance between technological innovation and human values has become an urgent one. While technological advancement can certainly bring efficiency and convenience, the lack of ethical constraints may lead to privacy leakage, unfair decision-making and moral hazard. Therefore, it has become particularly important to establish a sound AI ethical framework to regulate the application of the technology, protect individual privacy, and ensure fairness and transparency. The establishment of an AI ethical framework is not only to regulate the application of the technology, but also to protect social justice and core human values. Through systematic ethical guidelines, moral considerations can be integrated into all stages of technology development and application, providing clear guidelines to help all parties use AI technology under the premise of legal compliance. At the same time, such an ethical framework can also help enhance public trust in AI and promote the healthy development of the technology in a wider range of fields. In conclusion, the rapid development of AI brings unprecedented opportunities and raises profound ethical challenges. We need to ensure the coordinated development of technological progress and social values by establishing a sound ethical framework, and promote AI to move forward in a more responsible, fairer and transparent direction. The combination of ethics and technology will become an important force to lead the future development of science and technology, bringing more benefits and progress to human society.",
    "doi": "10.54097/tvqkkf40",
    "url": "https://www.semanticscholar.org/paper/1f3b09fa5891b23452636914a1ffbd965f68a654",
    "pdf_url": "https://drpress.org/ojs/index.php/ijeh/article/download/22205/21741",
    "venue": "International Journal of Education and Humanities",
    "citation_count": 4,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895032"
  },
  {
    "source": "semantic_scholar",
    "source_id": "451f87249e1a6dd21c76b45b7cffda0a464127ab",
    "title": "The Impact of Artificial Intelligence Replacing Humans in Making Human Resource Management Decisions on Fairness: A Case of Resume Screening",
    "authors": [
      "Fei Cai",
      "Jiashu Zhang",
      "Lei Zhang"
    ],
    "year": 2024,
    "abstract": "A growing number of organizations have used artificial intelligence (AI) to make decisions to replace human resource (HR) workers; yet, the fairness perceptions of the people affected by the decision are still unclear. Given that an organization\u2019s sustainability is significantly influenced by individuals\u2019 perceptions of fairness, this study takes a resume-screening scenario as an example to explore the impact of AI replacing humans on applicants\u2019 perceptions of fairness. This study adopts the method of the online scenario experiment and uses SPSS to analyze the experimental data: 189 and 214 people, respectively, participated in two online scenarios, with two independent variables of decision makers (AI and humans), two dependent variables of procedural and distributive fairness, and two moderating variables of outcome favorability and the expertise of AI. The results show that the applicants tend to view AI screening resumes as less fair than humans. Furthermore, moderating effects exist between the outcome favorability and the expertise of AI. This study reveals the impact of AI substituting for humans in decision-making on fairness. The proposed model can help organizations use AI to screen resumes more effectively. And future research can explore the collaboration between humans and AI to make human resource management decisions.",
    "doi": "10.3390/su16093840",
    "url": "https://www.semanticscholar.org/paper/451f87249e1a6dd21c76b45b7cffda0a464127ab",
    "pdf_url": "https://www.mdpi.com/2071-1050/16/9/3840/pdf?version=1714658775",
    "venue": "Sustainability",
    "citation_count": 20,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895036"
  },
  {
    "source": "semantic_scholar",
    "source_id": "71f0b30e3fec3e8aab8beb6f374d18a069743505",
    "title": "Artificial Intelligence Ethics and Fairness: A study to address bias and fairness issues in AI systems, and the ethical implications of AI applications",
    "authors": [
      "Nimesh Gupta"
    ],
    "year": 2023,
    "abstract": "Artificial intelligence (AI) has made incredible strides in several fields, revolutionising business and everyday life. Thoughts regarding the moral ramifications and fairness of AI systems have grown in prominence along with its fast development. This article explores the crucial issues of AI fairness and ethics, concentrating on ways to detect and reduce prejudice in AI systems while also discussing larger ethical implications. The paper emphasises the possible repercussions of biased decision-making while highlighting the many forms and sources of bias that might develop in AI models. There are several methods and strategies to deal with bias in AI systems, including data pretreatment, algorithmic changes, and transparency measures. In an effort to balance justice and efficacy, the trade-offs between fairness goals and overall model performance are examined. The article also emphasises how crucial it is for AI systems to be transparent and understandable in order to foster accountability. For the purpose of establishing ethical AI development and deployment practises, regulatory issues and ethical decision-making frameworks are also investigated. This study emphasises the need of ongoing research and development of moral AI systems to guarantee a just and equitable future for AI applications via in-depth analysis and case studies.",
    "doi": "10.31305/rrijm2023.v03.n02.004",
    "url": "https://www.semanticscholar.org/paper/71f0b30e3fec3e8aab8beb6f374d18a069743505",
    "pdf_url": "https://doi.org/10.31305/rrijm2023.v03.n02.004",
    "venue": "Revista Review Index Journal of Multidisciplinary",
    "citation_count": 33,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895040"
  },
  {
    "source": "semantic_scholar",
    "source_id": "715f218b3692c855d4932c2d3150f2f95deeec28",
    "title": "Artificial Intelligence (AI) and Human Resource Management Practice: A Conceptual Review",
    "authors": [
      "Ifeoluwa Oluwaseyi Dopamu",
      "T. Fapohunda",
      "Y. Dauda"
    ],
    "year": 2025,
    "abstract": "The integration of Artificial Intelligence (AI) into Human Resource Management (HRM) is reshaping traditional practices and driving strategic transformation in modern organisations. This conceptual review adopts a qualitative content approach, synthesizing empirical and theoretical literature on AI and HRM to identify emerging patterns, frameworks, and implications for practice. This paper explores AI applications in recruitment, performance management, employee engagement, training, and workforce planning. It highlights the benefits of AI adoption as well as raises ethical and operational concerns, including data privacy, bias, and accountability, while also illustrating its future potential in predictive workforce analytics, ethical governance, and adaptive learning systems that redefine employee experience. Drawing from recent literature and real-world insights, the study emphasizes the need for organisations to implement AI ethically and responsibly, ensuring its deployment is guided by fairness and transparency. It concludes by advocating for robust data governance frameworks and continuous learning to ensure AI serves as a tool for inclusive and sustainable HRM practices in the digital age.",
    "doi": "10.36108/ljerhrm/5202.50.0230",
    "url": "https://www.semanticscholar.org/paper/715f218b3692c855d4932c2d3150f2f95deeec28",
    "pdf_url": "",
    "venue": "LASU Journal of Employment Relations & Human Resource Management",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895044"
  },
  {
    "source": "semantic_scholar",
    "source_id": "1730d49286d48aa0d9b3f7cf5a685e51bfc2e48b",
    "title": "A Study on Artificial Intelligence in Human Resource - Challenges",
    "authors": [
      "A. K"
    ],
    "year": 2025,
    "abstract": "ABSTRACT\n\n \n\nArtificial Intelligence (AI) is transforming Human Resource (HR) management by enhancing efficiency, decision-making, and strategic planning. This study investigates the integration of AI in HR functions such as recruitment, employee engagement, performance evaluation, and workforce analytics, while focusing on the challenges that accompany this technological shift. Key issues explored include data privacy concerns, ethical implications, bias in AI algorithms, resistance to change, and the need for new skill sets among HR professionals. The research emphasizes the importance of balancing automation with human oversight to ensure fairness, transparency, and accountability. Understanding these challenges is essential for organizations aiming to harness the full potential of AI in HR while maintaining a human-centric approach.\n\n\nKEYWORDS: Artificial Intelligence (AI), Human Resource Management (HRM), Recruitment Automation, Employee Engagement, Performance Evaluation, Workforce Analytics, Ethical Challenges",
    "doi": "10.55041/ijsrem46047",
    "url": "https://www.semanticscholar.org/paper/1730d49286d48aa0d9b3f7cf5a685e51bfc2e48b",
    "pdf_url": "",
    "venue": "INTERNATIONAL JOURNAL OF SCIENTIFIC RESEARCH IN ENGINEERING AND MANAGEMENT",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895048"
  },
  {
    "source": "semantic_scholar",
    "source_id": "0ae3983c58ecab9f2d17d2a3aa280f31b69999b9",
    "title": "The Role of Artificial Intelligence in Transforming Human Resource Management Processes (an Analytical Study)",
    "authors": [
      "Norah Almuhanna"
    ],
    "year": 2025,
    "abstract": "This study aims to analyze the role of artificial intelligence (AI) in driving transformation within human resource management (HRM) processes through a descriptive\u2013analytical approach based on a review of recent peer-reviewed literature published between 2019 and 2025. The study explores the key domains affected by this transformation, including recruitment and selection, training and skill development, performance evaluation and motivation, as well as compensation management and talent retention. The research adopts a descriptive\u2013analytical methodology by examining the content of prior studies and identifying both theoretical and practical trends that highlight the impact of AI on enhancing the efficiency and effectiveness of human resources. Findings indicate that AI has become a pivotal factor in redefining HRM functions, contributing to improved decision accuracy and organizational fairness. However, it also faces challenges related to ethics, algorithmic transparency, and data governance. Moreover, the results show that the Saudi context demonstrates advanced readiness for adopting AI-driven HR solutions in line with Saudi Vision 2030, while emphasizing the need to further develop digital competencies and ethical regulatory policies. The study recommends establishing digital governance frameworks, equipping HR professionals with AI-related skills, and developing applied Arab studies to better understand the unique characteristics of intelligent transformation in human resource management.",
    "doi": "10.52132/ajrsp.e.2025.79.2",
    "url": "https://www.semanticscholar.org/paper/0ae3983c58ecab9f2d17d2a3aa280f31b69999b9",
    "pdf_url": "",
    "venue": "Academic Journal of Research and Scientific Publishing",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895052"
  },
  {
    "source": "semantic_scholar",
    "source_id": "65fd92ce5f1a6690416668ffe3142e990ecf2af0",
    "title": "Artificial Intelligence in Human Resource Management: A Comprehensive Literature Review",
    "authors": [
      "Muhammad Arfah"
    ],
    "year": 2025,
    "abstract": "Advances in artificial intelligence (AI) have transformed various aspects of human resource management (HRM), especially in decision making, operational efficiency, and data analysis. The application of AI in HRM offers opportunities to increase organizational effectiveness, but also raises challenges related to transparency, algorithmic bias, and ethics in workforce management. Therefore, this research was conducted to explore the impact of AI in HRM and how organizations can optimize its use. This research uses a literature review method, by examining various scientific sources related to the implementation of AI in HRM. The study was conducted on articles from academic journals, industry reports, and related publications that discuss the role of AI in the recruitment process, performance evaluation, employee training, and strategic decision making. The research results show that AI can improve HRM efficiency through automation of administrative tasks, predictive analytics, and personalization of the employee experience. However, the main challenges found include algorithmic bias, lack of transparency in AI systems, and legal and regulatory uncertainty. In conclusion, AI has great potential in supporting more effective and data-driven HRM, but its use must be accompanied by policies that ensure transparency, accountability and a balance between automation and the role of humans in decision making. Therefore, a careful approach is needed in adopting AI to ensure maximum benefits without compromising aspects of ethics and fairness.",
    "doi": "10.54065/ijed.5.1.2025.336",
    "url": "https://www.semanticscholar.org/paper/65fd92ce5f1a6690416668ffe3142e990ecf2af0",
    "pdf_url": "",
    "venue": "Income Journal Of Economics Development",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895055"
  },
  {
    "source": "semantic_scholar",
    "source_id": "de0418bdada464d62e9d4bf2b0a91f2f1a3e0988",
    "title": "Artificial Intelligence in Human Resource Management: A Study of IT Companies in Bengaluru",
    "authors": [
      "Priya A",
      "Dr. Shailashri. V. T"
    ],
    "year": 2025,
    "abstract": "(AI) Artificial Intelligence has become an inextricable element of Human Resource Management (HRM) especially in recruitment methodologies, altering the way organizations consider prospects, performance assessment, and employee commitment. This paper aims to investigate the effect of organizational size and HR roles on AI technology adoption in recruitment process, with a special reference to IT companies in Bengaluru. The research hopes to offer guidance on how organizations can maximize the potential of AI in their HR by exploring how AI utilities including Applicant Tracking Systems (ATS), chatbots and predictive analytics influence time-to-hire, candidate experience and recruitment efficiency. It also discusses ethics implications of AI deployment, including aspects such as algorithmic bias and employee data privacy.\nThe results show that larger companies are more likely to adopt AI for recruiting because of their financial resources and infrastructure. In addition, HR Managers are key contributors to AI adoption, given their participation in making strategic decisions and greater access to the necessary tools/ skills to successfully apply. The report reveals that the promise of AI is being realized to deliver operational efficiencies, yet these benefits are accompanied by concerns about fairness and transparency in AI decisions, and about potential risk and bias in AI algorithms.\nThis study adds to the emerging body of knowledge on AI in HR with its investigation of the impact of underlined organization size and HR role on AI adoption in recruitment, theoretical and practical implications for organizations seeking to introduce AI in recruitment and ethical challenges are presented. The research also adds another voice to the chorus of those highlighting the importance of human-in-the-loop review before decisions are acted upon by an AI tool, so that it support company values and enables fair recruitment steps.",
    "doi": "10.36948/ijfmr.2025.v07i04.53349",
    "url": "https://www.semanticscholar.org/paper/de0418bdada464d62e9d4bf2b0a91f2f1a3e0988",
    "pdf_url": "",
    "venue": "International Journal For Multidisciplinary Research",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895059"
  },
  {
    "source": "semantic_scholar",
    "source_id": "30c5a9f05cb0039b09b120ef5ecc7ddd4551ab1a",
    "title": "Humans and Machines at Work: Redefining Strategic Human Resource Management in the Era of Artificial Intelligence and Workforce Automation",
    "authors": [
      "Sarfaraz Raza Khan",
      "Muhammad Ali Baig",
      "Dr. Ayaz Qaiser",
      "Dr. Fatima Abrar",
      "Haider Ali"
    ],
    "year": 2025,
    "abstract": "Artificial Intelligence (AI) and workforce automation are rapidly integrating, fundamentally redefining strategic orientation of Human Resource Management (HRM) across industries. This manuscript studies how Strategic Human Resource Management (SHRM) is responding to these technological disruptions by examining the real world experiences of 15 HR professionals from technology, manufacturing and service sectors. Research using primary qualitative data from semi structured interviews identifies themes related to AI in deployment recruitment, employee performance management, ethical issues, employee re\u2010skilling and HRs evolving role. Results show organizations using AI tools to boost operational efficiency and decision making, but issues such as algorithmic bias, lacking transparency, ambiguous ethics and limited digital literacy within HR teams remain considerable. The study also points out sectoral disparities in AI readiness and organizational support that make AI prepared for successful SHRM transformation not solely technological infrastructure but an ethical governance, collaboration across functions and foresight. The paper contributes to the emerging discourse on human centered AI by interpreting these findings through a multidisciplinary lens, also arguing that this kind of balance in technological innovation needs to optimize for employee wellbeing and organizational values. Thus, this research highlights the need for proactive, inclusive and ethically driven SHRM frameworks during the AI era.",
    "doi": "10.59075/6h0sjx74",
    "url": "https://www.semanticscholar.org/paper/30c5a9f05cb0039b09b120ef5ecc7ddd4551ab1a",
    "pdf_url": "",
    "venue": "The Critical Review of Social Sciences Studies",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895063"
  },
  {
    "source": "semantic_scholar",
    "source_id": "5bbb477081e0745e785db6164fe56e7ea8f988f6",
    "title": "Mapping Artificial Intelligence Trends and Challenges in Human Resource Management Practice: A Bibliometric Analysis Of Recent Literature",
    "authors": [
      "Rusmita Ayu Rahmawati",
      "Lilia Pasca Riani"
    ],
    "year": 2025,
    "abstract": "Research Aims: This research aims to map the evolving trends and challenges in the application of Artificial Intelligence (AI) to human resource management (HRM) practices through a bibliometric analysis approach with current literature, hoping to provide a comprehensive understanding of the current landscape and its implications for academics and practitioners.\nDesign/methodology/approach: The method used in this study is a bibliometric approach by analyzing scientific articles from databases such as Scopus and Web of Science. The data analysis technique was then processed and visualized using VOSviewer software to identify patterns and thematic relationships between research topics.\nResearch Findings: The results show that the application of AI in HR management has a significant impact on key HR functions such as HR analytics, recruitment processes, and strategic decision-making, but on the other hand also faces challenges such as algorithm bias, data privacy, ethics, technology adoption barriers, and the limitations of comprehensive bibliometric analysis to address these issues holistically.\nTheoretical Contribution/Originality: This study makes a theoretical contribution through a comprehensive map of AI trends and challenges in HR management, enriching the literature with insights into the dynamics of the technology and its implications for HR management theory. The study also proposes a conceptual framework to address the ethical and practical challenges of AI implementation in organizations.\nKeywords: Artificial Intelligence, Human Resource Management, Bibliometric Analysis, HR Analytics, Machine Learning, Ethics",
    "doi": "10.47153/jbmr.v6i10.1944",
    "url": "https://www.semanticscholar.org/paper/5bbb477081e0745e785db6164fe56e7ea8f988f6",
    "pdf_url": "",
    "venue": "Journal of Business and Management Review",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895067"
  },
  {
    "source": "semantic_scholar",
    "source_id": "deacf8f523c9d8dc0017d664bab64739742cebda",
    "title": "Ethics in Artificial Intelligence: Bias, Fairness and Beyond",
    "authors": [],
    "year": 2023,
    "abstract": null,
    "doi": "10.1007/978-981-99-7184-8",
    "url": "https://www.semanticscholar.org/paper/deacf8f523c9d8dc0017d664bab64739742cebda",
    "pdf_url": "",
    "venue": "Studies in Computational Intelligence",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895070"
  },
  {
    "source": "semantic_scholar",
    "source_id": "84f8451946a74172f81b18a5c3f1978691d17f0b",
    "title": "Exploring Artificial Intelligence Bias, Fairness and Ethics in Organisation and Managerial Studies",
    "authors": [
      "Marco Smacchia",
      "S. Za"
    ],
    "year": 2023,
    "abstract": null,
    "doi": null,
    "url": "https://www.semanticscholar.org/paper/84f8451946a74172f81b18a5c3f1978691d17f0b",
    "pdf_url": "",
    "venue": "European Conference on Information Systems",
    "citation_count": 2,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:49.895074"
  },
  {
    "source": "semantic_scholar",
    "source_id": "5b1413be55553a9cc4b94232cd52a7cacbeb4a05",
    "title": "The Impact of Artificial Intelligence Bias on Human Resource Management Functions: Systematic Literature Review and Future Research Directions",
    "authors": [
      "Mohand Tuffaha"
    ],
    "year": 2023,
    "abstract": "Artificial intelligence (AI) has become a valuable tool for facilitating Human Resource Management (HRM) functions. Although, it should be noted that AI has a specific character side away from other technology. Publications covering this knowledge area have grown sharply, however the scholarly covering the impact of AI bias inHRM is scarce. This paper studies this area and goes deeper to explore the future research areas by conducting a systematic literature review for 598 papers from Scopes and Emerald insight databases of which 34 articles were selected after implementing the PRISMA tool and quality evaluation stage. Results generated revealed that biased AI applications are negatively affecting performance management, compensation, staffing and training and development. Apart from that future research domains and questions have been outlined and identified from organizations\u2019 and employees\u2019 perspectives.",
    "doi": "10.37745/ejbir.2013/vol11n43558",
    "url": "https://www.semanticscholar.org/paper/5b1413be55553a9cc4b94232cd52a7cacbeb4a05",
    "pdf_url": "https://eajournals.org/ejbir/wp-content/uploads/sites/20/2023/07/The-impact-of-artificial-intelligence.pdf",
    "venue": "European journal of business and innovation research",
    "citation_count": 11,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895078"
  },
  {
    "source": "semantic_scholar",
    "source_id": "ecbc956981cb6ecc77c4a9e0b8a6923cf2a587ae",
    "title": "Potential benefits and challenges of artificial intelligence in human resource management in public institutions",
    "authors": [
      "Kelvin M Mwita",
      "F. Kitole"
    ],
    "year": 2025,
    "abstract": "This study explores the benefits and challenges of implementing artificial intelligence (AI) in human resource management (HRM) among public institutions in Tanzania. Using a cross-sectional research design, data was collected from 217 HR practitioners through random sampling and questionnaires. The descriptive approach assessed participants\u2019 understanding of AI, its perceived benefits, challenges, and risks in HRM. The findings on the perceived benefits of AI in HRM show that increased efficiency, better decision-making, and cost reduction are the top advantages, while ease of use ranks the lowest. However, challenges such as lack of expertise, data privacy concerns, high costs, and resistance to change remain significant barriers. Most respondents strongly agree that AI enhances recruitment, training, performance management, and compliance, but concerns persist over bias, transparency, and emotional intelligence limitations in areas like employee relations and compensation. Additionally, results on risks of using AI on HRM indicate that high-risk components like Human Resource Information System (HRIS), Recruitment, Compensation, and Performance Management face serious concerns such as bias and implementation complexity. Moderate-risk areas like succession planning and compliance show manageable challenges, while low-risk components like health and safety and employee relations reflect minimal issues. Statistical analysis confirms significant associations between risk levels and several HRM components, especially HRIS and Recruitment (p\u2009<\u20090.01), highlighting the need for targeted interventions. The study emphasizes the need for public institutions to establish robust ethical frameworks, invest in capacity-building for HR practitioners, and ensure human oversight in AI-driven processes. By addressing these concerns, public institutions can mitigate risks, improve AI adoption, and optimize the potential of AI to enhance HR practices, offering a roadmap for equitable, effective, and ethical implementation of AI technologies in workforce management.",
    "doi": "10.1007/s44282-025-00175-8",
    "url": "https://www.semanticscholar.org/paper/ecbc956981cb6ecc77c4a9e0b8a6923cf2a587ae",
    "pdf_url": "https://doi.org/10.1007/s44282-025-00175-8",
    "venue": "Discover Global Society",
    "citation_count": 10,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895084"
  },
  {
    "source": "semantic_scholar",
    "source_id": "a8cfe8f54eb3f55d2d3e045a7d14231e64cc5b16",
    "title": "Ethics of Artificial Intelligence: Balancing Innovation with Privacy, Fairness, and Accountability",
    "authors": [
      "Manasseh F. Oguru"
    ],
    "year": 2025,
    "abstract": "Artificial Intelligence (AI) is transforming societies through its capacity to drive innovation, optimise decision-making, and enhance productivity across diverse sectors. However, the rapid deployment of AI systems raises complex ethical questions that extend beyond technical performance. This review critically examines the ethics of artificial intelligence with emphasis on three central pillars: privacy, fairness, and accountability. AI technologies often rely on vast datasets that risk infringing on individual privacy when mismanaged, necessitating robust frameworks for data governance and consent. Equally pressing is the issue of fairness, as algorithmic bias can perpetuate systemic inequalities and undermine social justice. This concern is particularly acute in sensitive domains such as healthcare, finance, and criminal justice, where biased outputs can have life-altering consequences. Accountability also emerges as a central challenge, as the diffusion of responsibility between developers, organisations, and users creates ambiguity regarding who should be held responsible for harms caused by AI systems. Addressing these ethical dimensions requires an integrated approach that blends technological safeguards with regulatory oversight and societal engagement. The paper explores strategies such as explainable AI, impact assessments, and participatory design as pathways to align innovation with ethical responsibility. Ultimately, the balance between harnessing AI\u2019s transformative potential and safeguarding fundamental rights hinges on continuous dialogue among stakeholders\u2014governments, industry, academia, and civil society. By fostering ethical resilience in AI governance, societies can ensure that innovation does not compromise human dignity, equity, or trust. This work underscores the importance of proactive, interdisciplinary measures to guide the ethical trajectory of AI as it becomes an indispensable part of everyday life.",
    "doi": "10.9734/ajarr/2025/v19i101169",
    "url": "https://www.semanticscholar.org/paper/a8cfe8f54eb3f55d2d3e045a7d14231e64cc5b16",
    "pdf_url": "",
    "venue": "Asian Journal of Advanced Research and Reports",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895088"
  },
  {
    "source": "semantic_scholar",
    "source_id": "90d1b4159b362012bda0b8b5ad43b320cddca69f",
    "title": "Nursing leadership and artificial intelligence ethics: Safeguarding relationships and values",
    "authors": [
      "Paola Arcadi"
    ],
    "year": 2025,
    "abstract": null,
    "doi": "10.1177/09697330251366599",
    "url": "https://www.semanticscholar.org/paper/90d1b4159b362012bda0b8b5ad43b320cddca69f",
    "pdf_url": "",
    "venue": "Nursing Ethics",
    "citation_count": 1,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:49.895092"
  },
  {
    "source": "semantic_scholar",
    "source_id": "ed4a95917c1c9caaca7899a594755dc7fc99cee7",
    "title": "The Ethics of Generative AI: Analyzing ChatGPT's Impact on Bias, Fairness, Privacy, and Accountability",
    "authors": [
      "Mohd Haider Raza Beg",
      "Vandana Mehndiratta"
    ],
    "year": 2024,
    "abstract": "Pros and cons of Generative Artificial Intelligence (Intent), Many fields has its own use-case space for GAI. ChatGPT and systems like it give a sophisticated understanding of cognition along with content that is indistinguishable from humans, however these systems raise ethical issues in professional and social contexts. Challenges in the broad adoption of AI technologies including, accountability, fairness, bias and privacy arise as issues. These reforms will be critical as AI systems continue to be both developed and deployed, maintaining the crucial ethical standards and underpinning social trust. In the context of algorithmic biases, potential privacy violations, and an increased amount of risk due to automation in these critical decision areas; this paper provides a commentary regarding ethical concerns using generative AI. In addition, is the necessity of addressing these ethical challenges with tools like AI Ethics Impact Assessments, VADER Sentiment Analysis, TensorFlow's Indicators of Fairness, and continuous conversation.",
    "doi": "10.1109/ICSES63760.2024.10910483",
    "url": "https://www.semanticscholar.org/paper/ed4a95917c1c9caaca7899a594755dc7fc99cee7",
    "pdf_url": "",
    "venue": "International Conference on Signals and Electronic Systems",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895096"
  },
  {
    "source": "semantic_scholar",
    "source_id": "c84491016e9547393cd29f78ce5ac8e1d57c512e",
    "title": "Artificial Intelligence in Human Resource Management: A Systematic Literature Review and Human-Centered Framework",
    "authors": [
      "Dr. M. Hema Sundari",
      "Matheshkanna L",
      "Mohammed Riswan R",
      "Muthuraj V",
      "Mohana vasan T G",
      "Moureiya vithu G S"
    ],
    "year": 2025,
    "abstract": "Artificial intelligence (AI) is transforming human resource management (HRM), particularly in areas such as recruitment, performance evaluation, employee development, and job satisfaction. This systematic literature review employs the PRISMA method to synthesise findings from 78 peer-reviewed articles published between 2018 and 2025. AI is making recruitment more efficient, supporting personalized learning, and improving workplace analytics. Still, there are ongoing concerns about transparency, fairness, data privacy, and employee trust. Thematic analysis points to four main trends: better recruitment, more tailored learning, performance evaluations supported by algorithms, and higher employee engagement. While there has been progress, research shows that ethical and governance frameworks are still lacking, especially for long-term employee welfare and sustainable HR management. This study suggests a human-centered approach that balances technical efficiency with inclusivity, equity, and sustainability. The review aims to help both academics and managers by outlining current challenges, identifying gaps, and suggesting directions for future research.",
    "doi": "10.47392/irjaem.2025.0478",
    "url": "https://www.semanticscholar.org/paper/c84491016e9547393cd29f78ce5ac8e1d57c512e",
    "pdf_url": "",
    "venue": "International Research Journal on Advanced Engineering and Management (IRJAEM)",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895100"
  },
  {
    "source": "semantic_scholar",
    "source_id": "285ade017c044c6a40098cb4ad3a23297c1525dc",
    "title": "THE VALUE AND MANIFESTATION OF PREDICTIVE EMPATHY IN THE IMPLEMENTATION OF ARTIFICIAL INTELLIGENCE IN HUMAN RESOURCE MANAGEMENT",
    "authors": [
      "Filip Bu\u0161ina",
      "J. Kovalchuk"
    ],
    "year": 2025,
    "abstract": "The digital transformation of human resource management has facilitated the transition from the automation of routine functions (HR 4.0) to human-centric management (HR 5.0). The purpose of the study is to confirm that artificial intelligence does not replace humans but rather enhances their role through the model of predictive empathy. Based on data from a survey of 698 organizations across nine Central and Eastern European countries, the following findings were identified: a) the integration of AI tools increases the accuracy and transparency of HR processes while maintaining a focus on the individual and human values; b) organizations applying the HR 5.0 approach demonstrate higher levels of employee trust, a better perception of fairness, and greater decision-making efficiency. A strategic framework for implementing human-centric AI solutions in HR is proposed, along with the stages of introducing the predictive-empathic model through the formation of a three-level system of technological, organizational, and social trust, ensuring digital transformation accompanied by ethical and organizational-cultural changes. It is concluded that digitalization and AI do not eliminate the human factor but rather create conditions for a new ethics of management. The obtained results can be recommended for developing corporate digital transformation strategies aimed at building sustainable and ethically responsible HR systems, supporting the transition to the HR 5.0 model.",
    "doi": "10.15688/ek.jvolsu.2025.4.11",
    "url": "https://www.semanticscholar.org/paper/285ade017c044c6a40098cb4ad3a23297c1525dc",
    "pdf_url": "",
    "venue": "Vestnik Volgogradskogo gosudarstvennogo universiteta Ekonomika",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895104"
  },
  {
    "source": "semantic_scholar",
    "source_id": "ea37c234bec29fd2ca2aacb4bee3dbfd581da4eb",
    "title": "Adoption of Artificial Intelligence Technology in Human Resource Management in Digital Office Management",
    "authors": [
      "Marcha Dwi Yuliana",
      "Febri Mardianti"
    ],
    "year": 2025,
    "abstract": "The objective of this research is to examine the impact of integrating Artificial Intelligence (AI) on the effectiveness of Human Resource Management (HRM) within a digital office workplace. The study reveals that AI enhances the efficiency, accuracy, and fairness of numerous HR operations, especially recruitment, performance evaluation, and staff development. This research employs a qualitative descriptive approach using a systematic literature review to synthesize relevant scholarly findings on AI adoption in HRM within digital office environments. Furthermore, the implementation of digital technologies promotes enhanced communication, faster information flow, and a collaborative and inventive working environment. Despite these benefits, challenges remain, such as data privacy issues, cybersecurity threats, employees\u2019 insufficient digital literacy, and resistance to technological innovation. Successful AI implementation in human resource management requires a holistic strategy encompassing technological readiness, enhancement of employees\u2019 digital competencies, adherence to ethical standards, and an adaptable organizational culture. This approach allows organizations to develop flexible, sustainable, and effective office management systems that preserve a competitive edge amidst ongoing digital transformation.",
    "doi": "10.61242/ijabo.25.621",
    "url": "https://www.semanticscholar.org/paper/ea37c234bec29fd2ca2aacb4bee3dbfd581da4eb",
    "pdf_url": "",
    "venue": "International Journal Administration, Business &amp; Organization",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895107"
  },
  {
    "source": "semantic_scholar",
    "source_id": "6e9eac50e099ad95fb516418b95a8198c1e20e74",
    "title": "The transformation of human resource management through artificial intelligence",
    "authors": [
      "Marijana Zimonji\u0107",
      "Milinko Veli\u010dkovi\u0107"
    ],
    "year": 2025,
    "abstract": "The development of artificial intelligence (AI) represents one of the key drivers of digital transformation in modern business, with a particularly profound impact on\nhuman resource management (HRM). The integration of AI into HR processes enables\norganizations to enhance efficiency, objectivity, and accuracy in decision-making related\nto recruitment, selection, evaluation, and employee development. By automating administrative tasks and applying predictive analytics and machine learning algorithms, HR\nmanagement evolves from an operational to a strategic, data-driven function. This paper\nanalyzes the key aspects of HR transformation through the use of AI, with a special focus\non its role in optimizing recruitment and selection processes. Empirical findings indicate\nthat AI contributes to reducing hiring time, increasing fairness and transparency, and\nimproving the candidate experience, while simultaneously raising ethical and regulatory\nconcerns regarding algorithmic transparency and data privacy. The paper concludes that,\nwhen applied responsibly and ethically, artificial intelligence has become an indispensable strategic tool in modern human resource management, enabling the creation of more\nagile, inclusive, and efficient organizations.",
    "doi": "10.5937/megrev2502061z",
    "url": "https://www.semanticscholar.org/paper/6e9eac50e099ad95fb516418b95a8198c1e20e74",
    "pdf_url": "",
    "venue": "Megatrend Revija",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895111"
  },
  {
    "source": "semantic_scholar",
    "source_id": "7772383387b4f784dbc151678e16e95c33605988",
    "title": "The Integration of Artificial Intelligence in Human Resource Management in the U.S. Retail Sector",
    "authors": [
      "R. I. Rezvi",
      "Kazi Obaidur Rahman",
      "Farhan Nasrullah",
      "Md Samirul Islam",
      "Mehedi Hasan",
      "Nayeema Nusrat",
      "Shamina Sharmin Jishan",
      "Shoaib Ahmed"
    ],
    "year": 2025,
    "abstract": "This paper addresses the challenge of integrating Artificial Intelligence (AI) into human resource management (HRM) for the retail sector with the view of addressing challenges of high employee turnover, skill development as well as performance monitoring. Methodology: Existing literature was subjected to a thematic analysis to identify key themes and insights about AI\u2019s role in recruitment, employee motivation, and performance evaluation. Key Findings: AI paces up recruitment speed, personalizes training through adaptive learning and performs performance tracking in real-time. But there are ethical problems, such as algorithmic bias and transparency. Implications: AI brings transformative tools for retail HR management processes and employee engagement. The key to inclusivity and trust is balanced implementation and ethical oversight. Future Directions: Future research needs to address long term workforce impacts and frameworks for the ethical challenges in retail HRM.",
    "doi": "10.32996/jbms.2025.7.1.22",
    "url": "https://www.semanticscholar.org/paper/7772383387b4f784dbc151678e16e95c33605988",
    "pdf_url": "",
    "venue": "Journal of business and management studies",
    "citation_count": 3,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895115"
  },
  {
    "source": "semantic_scholar",
    "source_id": "2d4112456041576b461155d417e014d28af0968c",
    "title": "From Automation to Ethics: Responsible AI in Human Resource Management across Industries with Insights from the Power Sector",
    "authors": [
      "Chandan Kumar"
    ],
    "year": 2025,
    "abstract": "The integration of Artificial Intelligence (AI) in Human Resource Management (HRM) is revolutionising workforce management by automating recruitment, performance evaluations, and employee engagement processes. However, AI-driven HRM systems raise critical ethical concerns, particularly regarding bias, privacy, and transparency. This study explores the ethical implications of AI adoption in HRM, with a specific focus on the power sector, where automation plays a crucial role in workforce optimisation. The research employs a quantitative approach, analysing responses from 250 employees across various departments in power sector organisations. Using SPSS, key statistical tests\u2014including factor analysis, correlation, regression, and ANOVA\u2014are applied to examine the relationships between AI bias, privacy concerns, transparency, employee trust, and job satisfaction. Findings reveal that AI bias significantly affects workforce diversity, while privacy concerns negatively impact employee trust in AI-driven HR decisions. Moreover, the study highlights that greater transparency in AI decision-making fosters higher employee satisfaction and engagement. The study underscores the need for organisations to implement ethical AI governance frameworks to ensure fair, unbiased, and privacy-compliant AI systems in HRM. It recommends explainable AI models, fairness audits, and hybrid decision-making (AI + human oversight) to enhance trust and acceptance of AI-driven HR practices. These findings contribute to the broader discourse on responsible AI adoption in HRM, offering strategic insights for HR leaders, policymakers, and AI developers in the power sector.",
    "doi": "10.31305/rrijm.2025.v10.n4.009",
    "url": "https://www.semanticscholar.org/paper/2d4112456041576b461155d417e014d28af0968c",
    "pdf_url": "",
    "venue": "RESEARCH REVIEW International Journal of Multidisciplinary",
    "citation_count": 3,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895118"
  },
  {
    "source": "semantic_scholar",
    "source_id": "5f6fc0d79366676bbea8cd6e165ad6bcc500bc0b",
    "title": "A Study on the Impact of Artificial Intelligence on Human Resource Management",
    "authors": [
      "Oishi Biswas",
      "Prerana Sharma",
      "Shreyashi Das",
      "Laxmi Bharti"
    ],
    "year": 2025,
    "abstract": "The impact of artificial intelligence (AI) on human resources management (HRM) is profound, driving major shifts in how organizations approach workforce management. AI is fundamentally changing key HR processes such as recruitment, performance management, employee development, and HR administration. In the recruitment space, AI-powered tools can automate the initial stages of hiring, streamlining tasks like resume screening and interview scheduling. These technologies are able to analyze large pools of applicants, matching their qualifications and skills to the job requirements. This can lead to faster, more accurate hiring decisions and help organizations build diverse, high-performing teams. However, there is a potential risk that biases embedded in the data used by AI systems could reinforce inequalities, making it crucial for companies to ensure that their AI tools are regularly audited for fairness and inclusivity.\n\nIn performance management, AI is transforming how employees are evaluated and developed. Traditional performance reviews can often be subjective and inconsistent, but AI can introduce a more objective and data-driven approach. By continuously tracking key performance indicators (KPIs) and employee behaviors, AI can provide real-time insights into performance trends, identify potential areas of improvement, and even predict future challenges. This enables HR professionals to tailor development plans for individual employees, fostering personal growth and enhancing overall productivity. However, the reliance on AI for performance evaluation raises concerns about employee privacy and the potential for over-monitoring, highlighting the need for clear ethical guidelines and transparency in how data is collected and used.",
    "doi": "10.55041/ijsrem44266",
    "url": "https://www.semanticscholar.org/paper/5f6fc0d79366676bbea8cd6e165ad6bcc500bc0b",
    "pdf_url": "",
    "venue": "INTERANTIONAL JOURNAL OF SCIENTIFIC RESEARCH IN ENGINEERING AND MANAGEMENT",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895152"
  },
  {
    "source": "semantic_scholar",
    "source_id": "66f7f6be7841cf86e428aeaefaf0a11be2006b77",
    "title": "Application and Challenges of Artificial Intelligence in Human Resource Management",
    "authors": [
      "Qingrui Li"
    ],
    "year": 2025,
    "abstract": "The integration of artificial intelligence (AI) into human resource management (HRM) presents a transformative opportunity to enhance efficiency, improve decision-making, and address ethical concerns. This research examines the current state of AI applications in HRM, identifying key benefits and challenges associated with implementation. It develops a framework for ethical and responsible AI deployment, considering concerns about bias, privacy, and job displacement. By analyzing real-world case studies and exploring future trends, the research provides insights into the potential impact of AI on the future of work. This study contributes to the field by offering a comprehensive overview of AI in HRM, highlighting its potential to optimize processes, personalize employee experiences, and address ethical considerations.",
    "doi": "10.54097/sq17e902",
    "url": "https://www.semanticscholar.org/paper/66f7f6be7841cf86e428aeaefaf0a11be2006b77",
    "pdf_url": "",
    "venue": "Frontiers in Business, Economics and Management",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895161"
  },
  {
    "source": "semantic_scholar",
    "source_id": "52e34c95b61e721208ed4fc929c38b21f68eb041",
    "title": "The Transformative Impact of Artificial Intelligence and Automation on Human Resource Practices: A Comprehensive Research Overview",
    "authors": [
      "Mallikarjun Devindrappa"
    ],
    "year": 2025,
    "abstract": "Artificial Intelligence (AI) and automation are profoundly reshaping Human Resource Management (HRM), transitioning HR from a traditionally administrative function to a strategic business partner. This report provides a comprehensive research overview of this transformation, examining the diverse applications of AI across core HR practices, including talent acquisition, onboarding, performance management, learning and development, employee engagement, and administrative task automation. It synthesizes the significant benefits, such as enhanced operational efficiency, data-driven strategic decision-making, and personalized employee experiences. Concurrently, the report critically analyzes the inherent challenges and ethical dilemmas, with a particular focus on algorithmic bias, data privacy and security, the potential for job displacement and skill gaps, and the imperative for transparency and human oversight. Mitigation strategies and best practices for responsible AI adoption are discussed, emphasizing robust governance, data quality, algorithmic audits, and workforce upskilling. The future trajectory of AI in HR points towards more sophisticated innovations like Agentic AI and hyper-personalization, further evolving the role of HR professionals into ethical stewards and strategic integrators of technology. Ultimately, the report underscores the necessity of a balanced approach, integrating technological advancements with human-centric values to foster effective, equitable, and engaging workplaces where AI augments human capabilities.",
    "doi": "10.31305/trjtm2025.v05.n01.006",
    "url": "https://www.semanticscholar.org/paper/52e34c95b61e721208ed4fc929c38b21f68eb041",
    "pdf_url": "",
    "venue": "TECHNO REVIEW Journal of Technology and Management",
    "citation_count": 2,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895163"
  },
  {
    "source": "semantic_scholar",
    "source_id": "9203539261c7cb6ab3ad9c47a871b549d44e39e1",
    "title": "Artificial Intelligence in Human Resource Management: A Case of Information Technology Sector of Khyber Pakhtunkhwa, Pakistan",
    "authors": [
      "Maseeh Ullah",
      "M. Din",
      "Farooq Khan",
      "Saad Mushtaq"
    ],
    "year": 2025,
    "abstract": "The integration of Artificial Intelligence (AI) into Human Resource Management (HRM) is revolutionizing traditional HR practices by enhancing efficiency, objectivity, and strategic decision-making. This paper explores the multifaceted applications of AI in HRM, focusing on recruitment, performance evaluation, employee engagement, and workforce planning. Through a comprehensive literature review and analysis of current industry practices, the study highlights how AI-driven tools such as chatbots, predictive analytics, and resume screening algorithms are transforming HR functions. While AI offers significant benefits, including time savings and improved candidate-job matching, it also raises critical concerns about data privacy, algorithmic bias, and ethical transparency. The paper concludes with recommendations for responsible AI adoption and outlines areas for future research, emphasizing the need for a balanced approach that leverages AI while preserving the human element in HRM.",
    "doi": "10.63468/jpsa.3.1.6",
    "url": "https://www.semanticscholar.org/paper/9203539261c7cb6ab3ad9c47a871b549d44e39e1",
    "pdf_url": "",
    "venue": "Journal of Political Stability Archive",
    "citation_count": 2,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895165"
  },
  {
    "source": "semantic_scholar",
    "source_id": "eff9c6e239940c2b8714a3225586564a8bd205f2",
    "title": "Human resource development in the age of artificial intelligence: a theoretical synthesis",
    "authors": [
      "Caleb Bennett",
      "Jeremy Bennett"
    ],
    "year": 2026,
    "abstract": null,
    "doi": "10.1007/s43681-025-00944-w",
    "url": "https://www.semanticscholar.org/paper/eff9c6e239940c2b8714a3225586564a8bd205f2",
    "pdf_url": "",
    "venue": "AI and Ethics",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895167"
  },
  {
    "source": "semantic_scholar",
    "source_id": "83c2bb49d7ca200352531f19377ba14cc3ce8685",
    "title": "Artificial\u00a0Intelligence\u00a0in\u00a0Human\u00a0Resource\u00a0Management:\u00a0Exploring\u00a0Public Policy Implications and Emerging Ethical Challenges",
    "authors": [
      "Taufeeq Ahmed",
      "Rabia Majeed"
    ],
    "year": 2025,
    "abstract": "This\u00a0research examines\u00a0the\u00a0dual impact\u00a0of Artificial Intelligence\u00a0(AI) integration\u00a0in\u00a0Human\u00a0Resource\u00a0Management\u00a0(HRM),\u00a0focusing\u00a0on\u00a0the intersection of technological efficiency gains with emerging public policy requirements and ethical challenges. Employing a mixed- methods approach, the study combines quantitative survey data from 427 HR professionals across multiple sectors with qualitative policy analysis of regulatory frameworks from 12 jurisdictions and three in- depth organizational case studies. Structural Equation Modeling (SEM)\u00a0was\u00a0used\u00a0to\u00a0analyze\u00a0relationships\u00a0between\u00a0AI\u00a0adoption\u00a0factors and ethical outcomes. AI adoption in HRM yields significant efficiency improvements (average 37.2% reduction in recruitment time,\u00a031.8%\u00a0cost\u00a0reduction),\u00a0but\u00a0simultaneously\u00a0introduces\u00a0substantial ethical\u00a0risks.\u00a0Algorithmic\u00a0bias\u00a0was\u00a0detected\u00a0in\u00a028.7%\u00a0of\u00a0systems,\u00a0with gender bias being most prevalent (19.3%). Policy compliance gaps were substantial, with only 41.2% of organizations fully meeting GDPR requirements for AI systems. Organizations must develop comprehensive AI governance frameworks that balance efficiency gains with ethical safeguards. Policymakers should prioritize developing sector-specific AI regulations for HRM that address transparency\u00a0requirements,\u00a0bias\u00a0auditing\u00a0standards,\u00a0and\u00a0employee\u00a0data protection. This study contributes a novel integrated framework for understanding the policy-ethics-technology nexus in AI-HRM adoption, providing empirical evidence of the specific trade-offs organizations face and offering actionable policy recommendations.",
    "doi": "10.63468/sshrr.255",
    "url": "https://www.semanticscholar.org/paper/83c2bb49d7ca200352531f19377ba14cc3ce8685",
    "pdf_url": "",
    "venue": "Social Sciences &amp; Humanity Research Review",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895169"
  },
  {
    "source": "semantic_scholar",
    "source_id": "8cdae09acd753c5fc7dfd3fb5ea15f2d1d92728d",
    "title": "THE STRATEGIC CHALLENGES OF ARTIFICIAL INTELLIGENCE ON HUMAN RESOURCE MANAGEMENT PRACTICES",
    "authors": [
      "Sandeep Kumar Gupta",
      "Billekanti Punitha Sai",
      "Patan Ushma",
      "Chithanoor Meghana",
      "Kakarla Uday Kiran Reddy"
    ],
    "year": 2025,
    "abstract": "Artificial Intelligence (AI) is profoundly transforming the field of Human Resource Management (HRM) by streamlining administrative functions, enabling data-driven decision-making, and enhancing overall workforce efficiency. Through automation and predictive analytics, AI assists HR professionals in recruitment, performance evaluation, training, and employee engagement. However, while the potential of AI is vast, its integration into HRM presents several strategic challenges. Ethical dilemmas, data privacy risks, algorithmic bias, and the potential for employee displacement or resistance are significant barriers to effective implementation. Moreover, the rapid advancement of AI technologies demands continuous upskilling and reskilling of HR personnel to ensure technological adaptability. \nThis paper examines these multifaceted strategic challenges by drawing insights from contemporary literature and qualitative research findings across different organizational contexts. It further investigates how organizations can align AI adoption with ethical governance frameworks, transparent communication, and employee inclusion strategies. \nThe findings suggest that sustainable AI integration in HRM requires balancing technological efficiency with human-centric values to maintain trust, fairness, and inclusivity. In conclusion, the paper emphasizes the importance of responsible innovation, where AI tools are leveraged not merely for automation but as catalysts for strategic transformation in HR practices. By fostering a culture of learning and ethical awareness, organizations can harness AI\u2019s full potential while mitigating its associated risks.",
    "doi": "10.36690/iceaf-2025-26",
    "url": "https://www.semanticscholar.org/paper/8cdae09acd753c5fc7dfd3fb5ea15f2d1d92728d",
    "pdf_url": "",
    "venue": "Book of abstractsract",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895170"
  },
  {
    "source": "semantic_scholar",
    "source_id": "64af082bdb1d9b688cedf6caf22109955e3c00c6",
    "title": "Artificial Intelligence Applications in Human Resource Management",
    "authors": [
      "Cemal Iyem",
      "Beyza Erer"
    ],
    "year": 2025,
    "abstract": "With the rapid advancement of information technologies in recent years, artificial intelligence (AI) has begun to be integrated into human resource (HR) management, as in all other business functions.. This inevitable technological shift has reshaped the HR function, enabling HR professionals to utilize machine learning and algorithms to streamline business processes, reduce bias and improve analysis and decision-making. With such significant benefits, it is curious how actively AI is being used in the field of human resource management. Therefore, the study aims to identify in which function(s) of Human Resource Management artificial intelligence technologies are being used. The study used a case study approach, one of the qualitative research designs, and analysed how companies integrate artificial intelligence technologies into basic human resource processes using the \u201cdocument analysis\u201d method. The study was designed as a case study.",
    "doi": "10.33712/mana.1702990",
    "url": "https://www.semanticscholar.org/paper/64af082bdb1d9b688cedf6caf22109955e3c00c6",
    "pdf_url": "",
    "venue": "Uluslararas\u0131 Y\u00f6netim Akademisi Dergisi",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895172"
  },
  {
    "source": "semantic_scholar",
    "source_id": "f0bde02072e7acbbd47725f8fc414a4528f63696",
    "title": "Artificial Intelligence in Human Resource Management: Transforming Workforce Optimization, Recruitment, and Employee Engagement",
    "authors": [
      "Sheenu Arora",
      "Ruchi Srivastava",
      "V. K. Gupta"
    ],
    "year": 2025,
    "abstract": "Artificial intelligence (AI), which enhances workforce optimization, decision-making, and process automation, is transforming human resource management (HRM). This paper explores how AI can be used in HRM, with a focus on important functions, including hiring, employee engagement, training and development, performance review, and retention. Chatbots, machine learning, natural language processing (NLP), and predictive analytics are examples of AIpowered technologies that increase productivity, reduce biases, and streamline HR operations. Despite the numerous benefits of artificial intelligence, issues such as algorithmic bias, data privacy, transparency, and resistance by employees still prevail. To assess AI's impact on HRM, the research employs a qualitative approach, analysing secondary data from scholarly articles, industry reports, and case studies. Findings indicate that while AI significantly enhances workforce management, ethical use and regulatory oversight are required. The research also considers possible future growth, with an emphasis on growth in AI, generative AI, and people analytics. Companies will achieve a competitive advantage in the evolving HR space if they thoroughly implement AI while maintaining human authority.",
    "doi": "10.1109/ICDISS68238.2025.11320597",
    "url": "https://www.semanticscholar.org/paper/f0bde02072e7acbbd47725f8fc414a4528f63696",
    "pdf_url": "",
    "venue": "2025 International Conference on Digital Innovations for Sustainable Solutions (ICDISS)",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895174"
  },
  {
    "source": "semantic_scholar",
    "source_id": "879d8b46832a1ecd19531ba53e0f83f82412f769",
    "title": "Leveraging Artificial Intelligence in Decision Support Systems for Strategic Human Resource Management: A Systematic Literature Review",
    "authors": [
      "Bara Aldino",
      "Sujoko Sujoko"
    ],
    "year": 2025,
    "abstract": "This study examines the integration of Artificial Intelligence (AI) into Decision Support Systems (DSS) for Strategic Human Resource Management (SHRM) through a systematic literature review (SLR). The research investigates how AI technologies enhance various HR functions, such as recruitment, training, performance evaluation, and talent management. The findings indicate that AI significantly improves operational efficiency, decision-making accuracy, and the overall speed of HR processes. However, challenges such as ethical concerns, data privacy issues, and potential algorithmic bias in decision-making are highlighted. The paper aims to provide a conceptual framework for the effective application of AI in SHRM and identifies key trends, challenges, and opportunities in AI adoption within HR functions. By synthesizing existing research, this study offers valuable insights into optimizing the use of AI in DSS for SHRM, emphasizing the importance of aligning AI implementation with ethical principles and organizational goals. The research advances theoretical and practical understanding of AI's role in HRM and encourages further exploration of its impact across various organizational contexts.",
    "doi": "10.58811/opsearch.v4i4.185",
    "url": "https://www.semanticscholar.org/paper/879d8b46832a1ecd19531ba53e0f83f82412f769",
    "pdf_url": "",
    "venue": "Quarterly Journal of the Operational Research Society of India (OPSEARCH)",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895175"
  },
  {
    "source": "semantic_scholar",
    "source_id": "792f2a858b78230dcc78965d1765de8cc96ce723",
    "title": "Artificial Intelligence in Human Resource Management: \nReshaping Talent Strategies in the Digital Era",
    "authors": [
      "Ting Tao"
    ],
    "year": 2025,
    "abstract": "The integration of artificial intelligence (AI) into human resource management (HRM) has revolutionized traditional practices, \nenabling data-driven decision-making and operational efficiency. This paper systematically analyzes the applications of AI in recruitment, \ntraining, performance management, and staff retention, supported by case studies from global enterprises (e.g., Unilever, IBM) and Chinese \ncorporations (e.g., Alibaba, Tencent). It further explores ethical challenges, including algorithmic bias and data privacy risks, and proposes \na governance framework balancing technological innovation with human-centric values. The study concludes with future directions for AIHRM synergy, emphasizing collaborative intelligence and policy coordination.",
    "doi": "10.70711/memf.v2i6.6912",
    "url": "https://www.semanticscholar.org/paper/792f2a858b78230dcc78965d1765de8cc96ce723",
    "pdf_url": "",
    "venue": "Modern Economic Management Forum",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895177"
  },
  {
    "source": "semantic_scholar",
    "source_id": "39ab7ddf0ae8ae752839c2d2d7e8badb80ffc28f",
    "title": "Research on the Impact of Artificial Intelligence on Employee Experience in Human Resource Management",
    "authors": [
      "Lingying Fang",
      "Xu Jing",
      "Shaofeng Zhang"
    ],
    "year": 2025,
    "abstract": "Driven by artificial intelligence technology, human resource management is undergoing a digital transformation. The central contradiction lies in the dynamic interplay between technological empowerment and humanistic values. This study focuses on the dual impact of artificial intelligence (AI) on employee experience within human resource management (HRM). It aims to systematically analyze how AI technologies facilitate the enhancement and optimization of employee experience during HRM processes, while simultaneously revealing their potential technological paradox and experience depletion. It reveals that: the application of AI technology demonstrates significant effectiveness in enhancing recruitment efficiency, personalizing employee training, and increasing the objectivity of performance management. At the same time, issues such as algorithmic bias, black-box decision-making, and excessive monitoring may trigger a crisis of trust. Consequently, this study advances the proposition that, the key issue in the digital transformation of enterprise human resource management lies in continuously building a dynamic framework of\u201chuman intelligence collaboration\u201d, seeking an appropriate balance between technological rationality and human needs/dignity, and between efficiency gains and humanistic care, thereby ensuring that the application of artificial intelligence centers on human beings.",
    "doi": "10.26789/ijest.v4i3.2105",
    "url": "https://www.semanticscholar.org/paper/39ab7ddf0ae8ae752839c2d2d7e8badb80ffc28f",
    "pdf_url": "",
    "venue": "\u56fd\u9645\u5316\u6559\u80b2\u79d1\u5b66\u4e0e\u7406\u8bba",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895178"
  },
  {
    "source": "semantic_scholar",
    "source_id": "a42554ce8fc8a3c3b6235abac522bc2a27158281",
    "title": "Bias in artificial intelligence for medical imaging: fundamentals, detection, avoidance, mitigation, challenges, ethics, and prospects",
    "authors": [
      "Burak Ko\u00e7ak",
      "A. Ponsiglione",
      "A. Stanzione",
      "Christian Bluethgen",
      "J. Santinha",
      "L. Ugga",
      "Merel Huisman",
      "M. Klontzas",
      "Roberto Cannella",
      "Renato Cuocolo"
    ],
    "year": 2024,
    "abstract": "ABSTRACT Although artificial intelligence (AI) methods hold promise for medical imaging-based prediction tasks, their integration into medical practice may present a double-edged sword due to bias (i.e., systematic errors). AI algorithms have the potential to mitigate cognitive biases in human interpretation, but extensive research has highlighted the tendency of AI systems to internalize biases within their model. This fact, whether intentional or not, may ultimately lead to unintentional consequences in the clinical setting, potentially compromising patient outcomes. This concern is particularly important in medical imaging, where AI has been more progressively and widely embraced than any other medical field. A comprehensive understanding of bias at each stage of the AI pipeline is therefore essential to contribute to developing AI solutions that are not only less biased but also widely applicable. This international collaborative review effort aims to increase awareness within the medical imaging community about the importance of proactively identifying and addressing AI bias to prevent its negative consequences from being realized later. The authors began with the fundamentals of bias by explaining its different definitions and delineating various potential sources. Strategies for detecting and identifying bias were then outlined, followed by a review of techniques for its avoidance and mitigation. Moreover, ethical dimensions, challenges encountered, and prospects were discussed.",
    "doi": "10.4274/dir.2024.242854",
    "url": "https://www.semanticscholar.org/paper/a42554ce8fc8a3c3b6235abac522bc2a27158281",
    "pdf_url": "https://d2v96fxpocvxx.cloudfront.net/new/beb8919b-f013-4ea1-b1c8-40332e840fe1/articles/dir.2024.242854/DIR-2024-2854.pdf",
    "venue": "Diagnostic and Interventional Radiology",
    "citation_count": 133,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:49.895181"
  },
  {
    "source": "semantic_scholar",
    "source_id": "69d9469b40b0866691b3d72e2a7d75164e1bced0",
    "title": "Artificial Intelligence and Ethics",
    "authors": [
      "Shipra Gupta",
      "Priti Sharma"
    ],
    "year": 2025,
    "abstract": "Artificial Intelligence (AI) is becoming a powerful force that is reshaping economies, civilizations, and personal lives. But along with its quick development come a plethora of ethical issues that need serious thought. This essay explores the complex relationship between ethics and artificial intelligence (AI), focusing on the moral issues raised by the creation, application, and use of intelligent systems. The discussion starts out by looking at the moral dilemmas that AI algorithms present, especially with regard to responsibility, justice, and bias. It examines the moral conundrums that result from independent decision-making processes, including those that occur in criminal justice, healthcare, and work settings. The study also examines the moral obligations that AI practitioners, developers, and legislators have to protect human rights, privacy, and dignity in the face of the widespread use of AI technologies. This study also explores the changing relationship between AI and society values, covering issues like as moral pluralism, cultural relativism, and international regulation of AI ethics. It considers the moral ramifications of AI's contribution to the amplification or reduction of socioeconomic inequality as well as its capacity to reinforce or lessen institutionalized prejudice and discrimination. The article also looks at new ethical frameworks and regulatory strategies meant to guarantee the ethical and responsible development and application of AI technologies. It assesses how well the current policies, procedures, and oversight frameworks promote openness, responsibility, and confidence in artificial intelligence (AI) systems. This paper concludes by arguing that an interdisciplinary and cooperative approach is necessary to address the ethical issues raised by AI. It also highlights the significance of ethical reflection, stakeholder engagement, and continuous discourse in forming an AI-enabled future that respects human rights, values, and dignity.",
    "doi": "10.2139/ssrn.5076025",
    "url": "https://www.semanticscholar.org/paper/69d9469b40b0866691b3d72e2a7d75164e1bced0",
    "pdf_url": "",
    "venue": "Social Science Research Network",
    "citation_count": 21,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895183"
  },
  {
    "source": "semantic_scholar",
    "source_id": "136fd18f5369ed2fbf47b5c553987f726ba522f0",
    "title": "The emergence of artificial intelligence ethics auditing",
    "authors": [
      "Danielle Schiff",
      "Stephanie Kelley",
      "Javier Camacho Ib\u00e1\u00f1ez"
    ],
    "year": 2024,
    "abstract": "The emerging ecosystem of artificial intelligence (AI) ethics and governance auditing has grown rapidly in recent years in anticipation of impending regulatory efforts that encourage both internal and external auditing. Yet, there is limited understanding of this evolving landscape. We conduct an interview-based study of 34 individuals in the AI ethics auditing ecosystem across seven countries to examine the motivations, key auditing activities, and challenges associated with AI ethics auditing in the private sector. We find that AI ethics audits follow financial auditing stages, but tend to lack robust stakeholder involvement, measurement of success, and external reporting. Audits are hyper-focused on technically oriented AI ethics principles of bias, privacy, and explainability, to the exclusion of other principles and socio-technical approaches, reflecting a regulatory emphasis on technical risk management. Auditors face challenges, including competing demands across interdisciplinary functions, firm resource and staffing constraints, lack of technical and data infrastructure to enable auditing, and significant ambiguity in interpreting regulations and standards given limited (or absent) best practices and tractable regulatory guidance. Despite these roadblocks, AI ethics and governance auditors are playing a critical role in the early ecosystem: building auditing frameworks, interpreting regulations, curating practices, and sharing learnings with auditees, regulators, and other stakeholders.",
    "doi": "10.1177/20539517241299732",
    "url": "https://www.semanticscholar.org/paper/136fd18f5369ed2fbf47b5c553987f726ba522f0",
    "pdf_url": "",
    "venue": "Big Data &amp; Society",
    "citation_count": 13,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895184"
  },
  {
    "source": "semantic_scholar",
    "source_id": "dd9c5bd2b0b6ba19d88a7daf3fde42ab4da659b1",
    "title": "A Comprehensive Strategy to Bias and Mitigation in Human Resource Decision Systems",
    "authors": [
      "Silvia D'Amicantonio",
      "Mishal Kizhakkam Kulangara",
      "Het Darshan Mehta",
      "Shalini Pal",
      "Marco Levantesi",
      "Marco Polignano",
      "Erasmo Purificato",
      "Ernesto William De Luca"
    ],
    "year": 2024,
    "abstract": null,
    "doi": null,
    "url": "https://www.semanticscholar.org/paper/dd9c5bd2b0b6ba19d88a7daf3fde42ab4da659b1",
    "pdf_url": "",
    "venue": "XAI.it@AI*IA",
    "citation_count": 4,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:49.895186"
  },
  {
    "source": "semantic_scholar",
    "source_id": "29a2c7c87d5bbeccb479202fdaac491159f42e19",
    "title": "Research Paper Artificial Intelligence (AI) and the Ethics of Moral Decision-Making: Integrating Human and Spiritual Values into Legal Frameworks for Ethical AI Development",
    "authors": [
      "Firdausi Kabir"
    ],
    "year": 2025,
    "abstract": "The rapid development of artificial intelligence (AI) technology has raised more ethical concerns than ever before, particularly with autonomous decision-making systems. Even more modern AI systems can carry out growingly intricate work with fewer human interventions, putting into doubt accountability, fairness, transparency, and the ethical consequences of the machine-directed decision. Though important literature has been done concerning AI ethics in terms of technical, legal, and philosophical frameworks, the inclusion of human and spiritual values within the framework of AI judgments is currently a critical gap. The ethical consideration of human values, such as empathy, justice, and human dignity, are fundamental aspects of human consideration, but their implementation in the algorithmic systems is scarce. Spiritual values, which include moral principles based on various cultural, religious, and philosophical traditions, provide another complementary aspect to the control of AI behaviour, to make sure that autonomous systems are in line with the expectations of morality and ethical propriety of society.\n\nThe paper aims to analyse how human and spiritual values can be integrated in a legal and policy framework to develop ethical AI. The research uses an interdisciplinary methodology by taking the perspectives of philosophy, theology, computer science, and law to theorise a model where-by the making of ethical decisions can be integrated within AI systems. The study relies on the literature on AI ethics, human centred design, and legal governance to determine the existing gaps and challenges when it comes to the translation of abstract ethical principles into computational mechanisms. There are case studies in the fields of autonomous vehicles, healthcare, and law enforcement that are examined to demonstrate the potential of the involvement of moral and spiritual considerations in AI algorithms, as well as their limitations.\n\nSome of the major research questions that were used to guide this research include: How do we operationalize human and spiritual values in AI systems? How can legal and policy processes be used to guarantee adherence to ethical standards? How far can AI systems be programmed to incorporate cross-cultural ethics at the expense of technical effectiveness? Answering these questions, the paper helps to develop a more comprehensive view of AI ethics, which is not limited to technical or utilitarian methods. The results serve as an additional indication that making AI human and spiritual is not just an imaginary task but a viable requirement to adjust technology to the standards and rules of society, as well as the expectations of the ethical framework. Some of the operationalisation strategies of ethical principles are the development of value-sensitive algorithms, ethical compliance regulatory guidelines, and interdisciplinary oversight mechanisms. Additionally, the paper identifies the possible obstacles, including cultural pluralism, interpretative ambiguities of moral codes, and technical constraints of algorithm design, which should be resolved to accomplish successful integration.",
    "doi": "10.65025/icfai25008f",
    "url": "https://www.semanticscholar.org/paper/29a2c7c87d5bbeccb479202fdaac491159f42e19",
    "pdf_url": "",
    "venue": "International Conference on Faith and Artificial Intelligence (ICFAI 2025)",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895188"
  },
  {
    "source": "semantic_scholar",
    "source_id": "03e44b87cafc556bcf356fb035192942e7d409df",
    "title": "An Analysis of Artificial Intelligence Adoption in the Human Resource Management",
    "authors": [
      "Anurag Kumar"
    ],
    "year": 2024,
    "abstract": "The integration of AI into HRM practices will mark a turning point in the history of organizational dynamics, bringing with it improved productivity and fresh perspectives on long-term planning. Because of this integration, many difficult questions and ethical dilemmas emerge. The hazy waters of artificial intelligence (AI) in human resource management are explored in this study, which examines its effects on training, engagement, performance reviews, and recruiting. Examining the AI-HRM nexus, this study draws on recent literature and statistics to highlight key developments, motivating factors, and obstacles. In addition, it explores the ways AI is changing HRM practices, illuminating the potential for innovation as well as concerns about prejudice and privacy invasion. We are examining the openness, responsibility, and fairness of AI-driven HRM systems since ethical concerns are at the heart of this discussion. For companies looking to apply AI to HRM and use an integrated framework, this report provides strategic insights to help them manage the hurdles of AI adoption. Helping companies make the most of technology while protecting and valuing their personnel is the main goal. Keywords: Artificial Intelligence, Human Resource Management, AI Adoption, Recruitment, Talent Management, Employee Engagement, Performance Evaluation, Ethical Implications, Privacy Concerns, Workforce Upskilling.",
    "doi": "10.55041/ijsrem32681",
    "url": "https://www.semanticscholar.org/paper/03e44b87cafc556bcf356fb035192942e7d409df",
    "pdf_url": "https://ijsrem.com/download/an-analysis-of-artificial-intelligence-adoption-in-the-human-resource-management/?wpdmdl=32277&refresh=665c243347c761717314611",
    "venue": "INTERANTIONAL JOURNAL OF SCIENTIFIC RESEARCH IN ENGINEERING AND MANAGEMENT",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895189"
  },
  {
    "source": "semantic_scholar",
    "source_id": "2e970aeee1c9bf17e32d6139be715c2a07116161",
    "title": "Ethical Framework for Artificial Intelligence and Urban Sustainability",
    "authors": [
      "Tatik Mariyanti",
      "Indra Wijaya",
      "Sandy Setiawan",
      "Chandra Lukita",
      "Eamon Fletcher"
    ],
    "year": 2025,
    "abstract": "The integration of artificial intelligence (AI) into urban environments addresses sustainability challenges like resource management, transportation efficiency, and waste reduction. However, critical need for a robust ethical framework to ensure equitable and environmentally responsible implementation. The method proposed emphasizes a combination of community involvement, fairness, and resilience, integrating ethical principles with practical strategies to maximize societal benefits, and incorporates the use of SmartPLS for structural equation modeling to analyze the relationships between ethical principles, sustainability dimensions, and urban outcomes. A significant GAP exists in current frameworks, which often focus solely on individual-level ethics and fail to address the dynamic, systemic challenges posed by fragile social systems and the uneven global structure. The novelty of this approach lies in its comprehensive vision that interlinks human-centered and collectivist-oriented development, bridging socio economic, environmental, and technological dimensions of sustainability. The proposed ethical framework not only mitigates risks but also fosters inclusive and resilient urban ecosystems, aligning digital innovations with the complex interconnections of the Sustainable Development Goals (SDGs) 11 (on sustainable cities).",
    "doi": "10.34306/bfront.v4i2.689",
    "url": "https://www.semanticscholar.org/paper/2e970aeee1c9bf17e32d6139be715c2a07116161",
    "pdf_url": "",
    "venue": "Blockchain Frontier Technology",
    "citation_count": 19,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895191"
  },
  {
    "source": "semantic_scholar",
    "source_id": "d11dd70bf393212c26c846a0bb474f055c8d3515",
    "title": "Artificial Intelligence and Remote Work: Transforming Human Resource Management in a Post-Pandemic World",
    "authors": [
      "Ch Sahyaja",
      "Ch Shankar",
      "Khudsiya Zeeshan",
      "N. Nagaraj"
    ],
    "year": 2024,
    "abstract": "This research explores the transformative impact of Artificial Intelligence (AI) on Human Resource Management (HRM) practices within the context of remote work. By analyzing existing research and case studies, this paper investigates how AI technologies, such as machine learning and predictive analytics, can be leveraged to optimize recruitment processes, streamline performance evaluations, and facilitate seamless collaboration among geographically dispersed teams. The study also addresses the ethical considerations associated with AI in HRM, including data privacy, algorithmic bias, and ensuring fair and equitable treatment of employees. The findings of this research provide valuable insights into the potential of AI to revolutionize HRM practices in the remote work era, enabling organizations to enhance employee engagement, improve decision-making, and drive innovation.",
    "doi": "10.1109/ICACRS62842.2024.10841784",
    "url": "https://www.semanticscholar.org/paper/d11dd70bf393212c26c846a0bb474f055c8d3515",
    "pdf_url": "",
    "venue": "2024 3rd International Conference on Automation, Computing and Renewable Systems (ICACRS)",
    "citation_count": 2,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895192"
  },
  {
    "source": "semantic_scholar",
    "source_id": "5631a17a2380724a459a45d7311716f77a514519",
    "title": "A research paper on how Artificial Intelligence changes the Human Resource Activities inside the organization and provides the significant improvement in workforce working environment for various day to day decisions making along with their efficiency and their productivity",
    "authors": [
      "N. Ganatra"
    ],
    "year": 2024,
    "abstract": "This paper speaks volumes about the various processes of Human resource like recruitment , training, selections, performance and development and workforce planning and how the Artificial Intelligence has revolutionized over the period of time by providing various insights and supporting in the decision making process. Artificial intelligence has provided a bias free and advanced algorithms due to which the screening and scheduling of HR process has been done with accurate parameters and lightning fast speed. This study provides a detailed insight to the AI intervention and its effectiveness in providing a great decision making system to the Human resource professionals. This platform is utilizing the sentiment analysis and catboats to monitor and improve the work place environment, which pushes the positivity in work culture and boosts productivity The AI aids in providing continuous feedback, various goal settings and tracking the performance productivity. This also provides a gist as well as in depth knowledge of top performers of the unit and also share the areas of improvement by which the others can reach up to a new bench mark. This AI has been a boon to the HR individuals thoroughly, especially during the performance appraisals. On the other AI enables personalized training programs and adaptive learning paths, addressing skill gaps and aligning employee development along with organizational goals.The point to ponder over is that the AI has also played a crucial role in workforce planning and analytics, additionally, it has aided by providing tools to forecast future workforce needs, optimize resource allocation, and enhance strategic decision-making. This process which is done by IA is by analyzing large datasets, AI also predicts turnover trends and informs succession planning, contributing to organizational productive and efficient life cycle The research has infused a mixed-methods approach, which combines qualitative and quantitative data collection through surveys, interviews, and case studies, alongside statistical analysis of HR metrics pre- and post-AI implementation. The basics of this research paper aims to provide valuable insights for HR professionals and organizational leaders on leveraging AI to enhance HR effectiveness and drive business success. There a strong determination which ensures that the findings will contribute to the evolving body of knowledge on AI in HR and support the development of strategic frameworks for AI adoption in human resource management on a longer run.",
    "doi": "10.18231/j.jmra.2024.030",
    "url": "https://www.semanticscholar.org/paper/5631a17a2380724a459a45d7311716f77a514519",
    "pdf_url": "https://doi.org/10.18231/j.jmra.2024.030",
    "venue": "Journal of Management Research and Analysis",
    "citation_count": 2,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895194"
  },
  {
    "source": "semantic_scholar",
    "source_id": "9bc8e3b48b343b869fb204c271beb83de507e8f4",
    "title": "Human Resource Management Optimization Strategies for Diverse Work Environments Based on Artificial Intelligence",
    "authors": [
      "Min Wu"
    ],
    "year": 2024,
    "abstract": "Abstract Under the diversified work environment, the relationship between employees and enterprises has ushered in new and significant changes. How to adapt to changes, form a new human resource management model, and improve management performance is an urgent issue. In this paper, we constructed an employee turnover pre-analysis measurement model based on XGBoost artificial intelligence, iterated many times during training, generated a weak classifier in each iteration, trained on the basis of the residuals of the previous classifier, and finally combined all the weak classifiers in a weighted way, reduced the bias to improve the accuracy of the final classifier through continuous iteration, and completed the construction of the model. The historical data of employees in six branches of enterprise W are imported into the model for analysis, and the F1 values are all above 0.85, and the AUCs are all higher than 0.7, with good prediction performance. The top three important employee turnover influencing characteristics and their weights are overtime work 0.647, monthly income 0.618, and interpersonal relationship 0.579. Accordingly, human resource management optimization strategies are designed and applied in Enterprise W to implement human resource management reform. After the reform, the average monthly separation rate has been reduced from 2.23% to 0.19%, and the average number of monthly separations has been reduced to only 7, which is 91.86% lower than during the pre-reform period. This study proposes feasible paths for modern information technology and artificial intelligence-enabled human resource management, and optimization of human resource management in a diverse work environment.",
    "doi": "10.2478/amns-2024-2556",
    "url": "https://www.semanticscholar.org/paper/9bc8e3b48b343b869fb204c271beb83de507e8f4",
    "pdf_url": "https://doi.org/10.2478/amns-2024-2556",
    "venue": "Applied Mathematics and Nonlinear Sciences",
    "citation_count": 2,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895196"
  },
  {
    "source": "semantic_scholar",
    "source_id": "e4af9104cb0a4b456cc0592b741f73ec34c72d06",
    "title": "Sustainable human resource management: A transformation perspective of human resource management functions through optimised artificial intelligence",
    "authors": [
      "Arif Furqon Nugraha Adz Zikri",
      "Sunu Widianto",
      "Rita Komaladewi"
    ],
    "year": 2024,
    "abstract": "Human resource management research which links to sustainability and the integration of artificial intelligence (AI) in HR practice has been increased. This paper explores the potential transformation of AI in HRM, revealing the factors that contribute to successful AI adoption and strategies to overcome adoption barriers within organisations. This research aims to verify a model for determining salaries for new employees that is competitive and in line with market standards. This paper also provides practical insights regarding how organisations can effectively analysis the role of HRM and AI to prevent undue evictions of HR professionals. To perform data analysis and processing, this research uses python analysis, with Jupyter notebook software and continues with model testing using regression evaluation model such as Mean Absolute Error (MAE), Mean Squared Error (MSE), Root Mean Squared Error (RMSE), and coefficient of determination R2-Score. The four main findings addressed in this study are lack of quality data, bias in data, loss of human aspect, and error and uncertainty. Furthermore, this research provides managerial implications for sustainable HRM practices in overcoming the main problem, namely determining new employee salaries using AI with the best accuracy by oversampling and comparing salaries through job portals to see current market trends.",
    "doi": "10.26740/bisma.v16n2.p167-189",
    "url": "https://www.semanticscholar.org/paper/e4af9104cb0a4b456cc0592b741f73ec34c72d06",
    "pdf_url": "https://doi.org/10.26740/bisma.v16n2.p167-189",
    "venue": "BISMA (Bisnis dan Manajemen)",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895201"
  },
  {
    "source": "semantic_scholar",
    "source_id": "53b04ccd2a001467d7ce168e9ce20b16a9466a69",
    "title": "Fairness And Bias in Artificial Intelligence: A Brief Survey of Sources, Impacts, And Mitigation Strategies",
    "authors": [
      "Emilio Ferrara"
    ],
    "year": 2023,
    "abstract": "The significant advancements in applying artificial intelligence (AI) to healthcare decision-making, medical diagnosis, and other domains have simultaneously raised concerns about the fairness and bias of AI systems. This is particularly critical in areas like healthcare, employment, criminal justice, credit scoring, and increasingly, in generative AI models (GenAI) that produce synthetic media. Such systems can lead to unfair outcomes and perpetuate existing inequalities, including generative biases that affect the representation of individuals in synthetic data. This survey study offers a succinct, comprehensive overview of fairness and bias in AI, addressing their sources, impacts, and mitigation strategies. We review sources of bias, such as data, algorithm, and human decision biases\u2014highlighting the emergent issue of generative AI bias, where models may reproduce and amplify societal stereotypes. We assess the societal impact of biased AI systems, focusing on perpetuating inequalities and reinforcing harmful stereotypes, especially as generative AI becomes more prevalent in creating content that influences public perception. We explore various proposed mitigation strategies, discuss the ethical considerations of their implementation, and emphasize the need for interdisciplinary collaboration to ensure effectiveness. Through a systematic literature review spanning multiple academic disciplines, we present definitions of AI bias and its different types, including a detailed look at generative AI bias. We discuss the negative impacts of AI bias on individuals and society and provide an overview of current approaches to mitigate AI bias, including data pre-processing, model selection, and post-processing. We emphasize the unique challenges presented by generative AI models and the importance of strategies specifically tailored to address these. Addressing bias in AI requires a holistic approach involving diverse and representative datasets, enhanced transparency and accountability in AI systems, and the exploration of alternative AI paradigms that prioritize fairness and ethical considerations. This survey contributes to the ongoing discussion on developing fair and unbiased AI systems by providing an overview of the sources, impacts, and mitigation strategies related to AI bias, with a particular focus on the emerging field of generative AI.",
    "doi": "10.3390/sci6010003",
    "url": "https://www.semanticscholar.org/paper/53b04ccd2a001467d7ce168e9ce20b16a9466a69",
    "pdf_url": "https://www.mdpi.com/2413-4155/6/1/3/pdf?version=1703577406",
    "venue": "Social Science Research Network",
    "citation_count": 528,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:49.895203"
  },
  {
    "source": "semantic_scholar",
    "source_id": "59fe933820a51d1e29afa8a6a923620f882e068b",
    "title": "ETHICAL IMPLICATIONS OF ARTIFICIAL INTELLIGENCE IN HUMAN RESOURCE MANAGEMENT FOR SUSTAINABLE DEVELOPMENT",
    "authors": [
      "Michal Val\u010do"
    ],
    "year": 2023,
    "abstract": "\"The research purpose is to explore the ethical implications of AI integration in HRM practices and its potential contribution to sustainable development. Research motivation: The rapid advancement of AI has brought forth numerous opportunities and challenges in HRM, including privacy concerns, bias, and discrimination. However, AI also has the potential to foster a culture of ethics and sustainability in organizations, and to address non-traditional security challenges and promote economic self-reliance. Research design, approach, and method: This paper will conduct a literature review of the latest research on AI in HRM and its ethical implications. The review will examine the relationship between AI and the ethical dimensions of HRM, such as privacy, surveillance, bias, and discrimination. It will also discuss the role of AI in fostering a culture of ethics and sustainability within organizations, and how it can be utilized to address non-traditional security challenges and promote an independent and self-reliant economy. Main findings: AI in HRM raises significant ethical concerns, including privacy and surveillance concerns, the potential for bias and discrimination, and the risk of over-reliance on AI at the expense of human judgment. AI has the potential to contribute significantly to sustainable development by optimizing resource allocation, improving efficiency, and facilitating decision-making processes. It can also foster a culture of ethics and sustainability within organizations and address non-traditional security challenges. However, the potential negative impacts of AI on sustainable development, such as its significant energy consumption and the risk of job displacement, should not be overlookedPractical/managerial implications: To harness the potential of AI in HRM while mitigating its risks, it is crucial to establish best practices and guidelines for its ethical use. These should include defining clear goals and objectives for AI implementation, involving stakeholders in the process, ensuring data quality, continuously monitoring and evaluating AIdriven processes, and addressing ethical considerations. Organizations must also carefully consider and address the challenges of implementing AI in HRM, such as data privacy concerns, algorithmic bias, ethical considerations, resistance to change, integration with existing systems, ensuring AI complements human decision-making, legal and regulatory compliance, and skills gap.\"",
    "doi": "10.51316/icpt.hust.2023.34",
    "url": "https://www.semanticscholar.org/paper/59fe933820a51d1e29afa8a6a923620f882e068b",
    "pdf_url": "",
    "venue": "The International Conference on Human Resources for Sustainable Development",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895204"
  },
  {
    "source": "semantic_scholar",
    "source_id": "41331cef3b4a3c0469c76047ae716bfe8f34ab0e",
    "title": "Bias and Fairness Issues in Artificial Intelligence-driven Cybersecurity",
    "authors": [
      "Ugochukwu Mmaduekwe"
    ],
    "year": 2024,
    "abstract": "Aim: This paper aims to examine the bias and fairness issues accorded with artificial intelligence (AI)-driven cybersecurity.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \nProblem Statement: The evolving global dependence on cybersecurity has exposed organizations, individuals, and nations to different vulnerabilities and security threats. However, merging of cyberspace with AI technologies has the potential to transform multiple domains but the implementation of AI is faced with bias problems limiting its application. \nSignificance of Study: Artificial intelligence and cybersecurity have been identified as two transformative and interconnected entities with great potential to revolutionize numerous areas of human life. However, it is imperative to critically look at the bias and fairness accorded with the implication of artificial intelligence-driven cybersecurity which are keywords limiting the usage and efficiency of the approach.\u00a0\u00a0 \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \nDiscussion: The concept of artificial intelligence and cybersecurity was discussed together with their interconnectivity which enhances the application in tackling cyber threats. Various areas of artificial intelligence deployment in cyberspace were presented. The sources and solutions to bias and fairness in artificial intelligence-driven cybersecurity were also discussed. This paper has critically discussed various ways via which AI biases influence cyber security. Nonetheless, ways by which this problem can be tackled were presented.\u00a0\u00a0\u00a0 \nConclusion: Artificial intelligence-driven cybersecurity has found wide industrial applications in different areas. However, there is a need to critically address the issues of bias and fairness attached to it to improve its efficiency. The use of the teams; AI model; and Corporate governance and leadership should be adopted to find lasting solutions to the problem of biases in AI-driven cyber security.",
    "doi": "10.9734/cjast/2024/v43i64391",
    "url": "https://www.semanticscholar.org/paper/41331cef3b4a3c0469c76047ae716bfe8f34ab0e",
    "pdf_url": "https://journalcjast.com/index.php/CJAST/article/download/4391/8740",
    "venue": "Current Journal of Applied Science and Technology",
    "citation_count": 5,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895206"
  },
  {
    "source": "semantic_scholar",
    "source_id": "92f2596f7d249a44ed7bbec0c25afc95dcc7597a",
    "title": "Analysis on Artificial Intelligence based Human Resource Computer Management System",
    "authors": [
      "Subrahmanya Bhat",
      "T. Padmavathi",
      "Kumuda P R",
      "Nuzhat Fatima Rizvi",
      "Suganya Bharathi S",
      "C. Madhuvappan"
    ],
    "year": 2024,
    "abstract": "Human resource management and competitiveness are becoming increasingly crucial in the growth of businesses. This study examines the factors of the enterprise survival environment in the process model of human asset management from the perception of control and computing. Based on systematic analysis, this study employs the SWOT is an acronym that stands for Strengths, Weaknesses, Opportunities, Threats, and analysis algorithm to creatively examine the contact of corresponding environmental elements on human resource management mode, and formulates a comprehensive set of human resource development plan. Simultaneously, in light of the control and computer challenges that exist in the human resource model, this study proposes specific implementation rules and methods, and theoretically verifies the efficacy and reliability of the related rules. By eliminating bias, automating tedious procedures, and empowering HR staff to make data-driven judgments, AI may expedite the hiring process. AI may save HR teams time and resources by, for instance, scheduling interviews, reviewing resumes, and performing preliminary candidate screening. It makes possible a data-driven strategy for hiring, promoting, and retaining people that aims to reduce bias and improve the experiences of both job searchers and workers.",
    "doi": "10.1109/ICSADL61749.2024.00021",
    "url": "https://www.semanticscholar.org/paper/92f2596f7d249a44ed7bbec0c25afc95dcc7597a",
    "pdf_url": "",
    "venue": "2024 3rd International Conference on Sentiment Analysis and Deep Learning (ICSADL)",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895208"
  },
  {
    "source": "semantic_scholar",
    "source_id": "4e351619058e4d30989bcb964e973f9db61f818c",
    "title": "Artificial intelligence and human capital: A review",
    "authors": [
      "N. Karunakaran",
      "K. V. Pradeep"
    ],
    "year": 2024,
    "abstract": "Artificial Intelligence (AI) has primarily impacted the global human capital. The human capital has been elucidated, focusing on their developing relationship with AI. The complex facets of human capital, including aptitude, proficiency, and competence, have been examined in this review, concentrating on the intricate association between AI and human capital. A secondary data analysis was conducted for this study, incorporating 16 studies that were meticulously chosen from online search engines. Key search words such as \"Human Capital and AI\" and \"AI and Human Resource Management\" were employed for collecting the articles. Compelling data was extracted from these articles to uncover the linkage between AI and human capital. The study yielded both affirmative and negative outcomes following a thorough review of articles. The research identified major concerns associated with AI-powered HR processes concerning bias, fairness, privacy, and security. It underscores the urgency for incorporating responsible AI practices and harnessing the potential of AI while mitigating risks and ensuring equitable human capital development. The connection between AI and human capital provides an invaluable resource for researchers, practitioners, and policymakers navigating the evolving landscape of workforce development in an era of AI-driven innovation.",
    "doi": "10.18231/j.jmra.2024.025",
    "url": "https://www.semanticscholar.org/paper/4e351619058e4d30989bcb964e973f9db61f818c",
    "pdf_url": "https://doi.org/10.18231/j.jmra.2024.025",
    "venue": "Journal of Management Research and Analysis",
    "citation_count": 2,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895210"
  },
  {
    "source": "semantic_scholar",
    "source_id": "7238f09714807e09ddc972e099d2f6a925617436",
    "title": "Ethics of the application of artificial intelligence in human resource management",
    "authors": [
      "A. S. Lobacheva",
      "O. Sobol"
    ],
    "year": 2021,
    "abstract": "The article reveals the main ethical problems and contradictions associated with the use of artificial intelligence. The paper reveals the concept of \u201cartificial intelligence\u201d. The authors analyse two areas of ethical problems of artificial intelligence: fundamental ideas about the ethics of artificial intelligent systems and the creation of ethical norms.The paper investigates the work of world organizations on the development of ethical standards for the use of artificial intelligence: the Institute of Electrical and Electronics Engineers and UNESCO. The study analyses the main difficulties in the implementation of artificial intelligent systems: the attitude of employees to the use of robots in production activities and the automation of processes that affect their work functions and work organization; ethical issues related to retraining and re-certification of employees in connection with the introduction of new software products and robots; ethical issues in reducing staff as a result of the introduction of artificial intelligence and automation of production and business processes; ethical problems of the processing of personal data of employees, including assessments of their psychological and physical condition, personal qualities and character traits, values\u00a0 and beliefs by specialized programs based on artificial intelligence, as well as tracking the work of employees; ethical contradictions when using special devices and tracking technologies in robotic technology and modern software products, which also extend to the employees interacting with them.",
    "doi": "10.26425/2658-3445-2021-4-1-20-28",
    "url": "https://www.semanticscholar.org/paper/7238f09714807e09ddc972e099d2f6a925617436",
    "pdf_url": "https://e-management.guu.ru/jour/article/download/138/91",
    "venue": "E-Management",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895211"
  },
  {
    "source": "semantic_scholar",
    "source_id": "609f936d990436b9ed9fab3c21e891fb3b417ee6",
    "title": "Balancing Technology, Ethics, and Society: A Review of Artificial Intelligence in Embryo Selection",
    "authors": [
      "Roberto Aufieri",
      "Francesco Mastrocola"
    ],
    "year": 2025,
    "abstract": "The introduction of artificial intelligence (AI) in embryo selection during in vitro fertilization presents distinct ethical and societal challenges compared to the general implementation of AI in healthcare. This narrative review examines ethical perspectives and potential societal implications of implementing AI-driven embryo selection. The literature reveals that some authors perceive AI as an extension of a technocratic paradigm that commodifies embryos, considering that any embryo selection methods undermine the dignity of human life. Others, instead, contend that prioritizing embryos with the highest viability is morally permissible while cautioning against discarding embryos based solely on unproven AI assessments. The reviewed literature identified further potential ethical concerns associated with this technique, including possible bias in the selection criteria, lack of transparency in black-box algorithms, risks of \u201cmachine paternalism\u201d replacing human judgment, privacy issues with sensitive fertility data, equity of access, and challenges in maintaining human-centered care. These findings, along with the results of the only randomized controlled trial available, suggest that the introduction of AI-driven embryo selection in clinical practice is not currently scientifically and ethically justified. Implementing and deploying ethical and responsible AI in embryo selection would be feasible only if the ethical and societal concerns raised are adequately addressed.",
    "doi": "10.3390/info16010018",
    "url": "https://www.semanticscholar.org/paper/609f936d990436b9ed9fab3c21e891fb3b417ee6",
    "pdf_url": "https://doi.org/10.3390/info16010018",
    "venue": "Inf.",
    "citation_count": 9,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:49.895213"
  },
  {
    "source": "semantic_scholar",
    "source_id": "52b3df2f621ad24a69e0e5e1ef834e86e87331e0",
    "title": "Mitigating Age-Related Bias in Large Language Models: Strategies for Responsible Artificial Intelligence Development",
    "authors": [
      "Zhuang Liu",
      "Shiyao Qian",
      "Shuirong Cao",
      "Tianyu Shi"
    ],
    "year": 2025,
    "abstract": "The increasing popularity of large language models (LLMs) in digital platforms elevates the urgency to address inherent biases, particularly age-related biases, which can significantly skew the model\u2019s fairness and performance. This paper introduces a novel two-stage bias mitigation approach utilizing LLM\u2019s empathy ability, reinforcement learning, and human-in-the-loop mechanisms to identify and correct age-related biases without altering model parameters. There are two modes for our bias mitigation strategy. Self-bias mitigation in the loop allows LLMs to self-assess and adjust their outputs autonomously, promoting inherent bias awareness and correction. Alternatively, cooperative bias mitigation in the loop leverages collaborative filtering among multiple LLMs to debate and mitigate biases through consensus. Furthermore, we introduce the empathetic perspective exchange strategy, which can further refine the answers by changing the perspective in the context information given to the LLM. In this way, more suitable responses applicable to different ages are generated. Our comprehensive evaluation across several data sets demonstrates that our trained model, FairLLM, significantly reduces age bias, outperforming existing techniques in fairness metrics. These findings underscore the effectiveness of our proposed framework in fostering the development of more equitable artificial intelligence systems, potentially benefiting a broader demographic spectrum by reducing digital ageism. History: This paper has been accepted by Kaushik Dutta for the Special Issue on Responsible AI and Data Science for Social Good. Funding: This work was supported by the National Natural Science Foundation of China [Grants 71971046, 72172029, 72403033, 72272028, and 72442025]. Supplemental Material: The software that supports the findings of this study is available within the paper and its Supplemental Information ( https://pubsonline.informs.org/doi/suppl/10.1287/ijoc.2024.0645 ) as well as from the IJOC GitHub software repository ( https://github.com/INFORMSJoC/2024.0645 ). The complete IJOC Software and Data Repository is available at https://informsjoc.github.io/ .",
    "doi": "10.1287/ijoc.2024.0645",
    "url": "https://www.semanticscholar.org/paper/52b3df2f621ad24a69e0e5e1ef834e86e87331e0",
    "pdf_url": "",
    "venue": "INFORMS journal on computing",
    "citation_count": 7,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895214"
  },
  {
    "source": "semantic_scholar",
    "source_id": "2b34a0a10e53b9f623a1a5363cea8d332bb09757",
    "title": "Ethics and governance of artificial intelligence in digital China: Evidence from online survey and social media data",
    "authors": [
      "Jiongyi Cao",
      "Tianguang Meng"
    ],
    "year": 2025,
    "abstract": "With the emerging trend of artificial intelligence (AI) and its application in various fields, AI ethics and its related incidents have aroused concern and caused wide discussion in both society and academia around the world. In this paper, we discuss AI ethics and governance with respect to public perspectives. Based on the existing literature, policies, and guidelines on AI ethics, we sorted AI ethics concerns into eight dimensions: safety, transparency, fairness, personal data protection, liability, truthfulness, human autonomy, and human dignity. Combining online survey data with social media data, we quantified people's concerns on each dimension, and their attitudes toward AI governance policies and goals. The results shed light on how the public understands and views AI ethics and related governance. Finally, we propose several future directions in the development of AI ethics.",
    "doi": "10.1177/2057150X241313085",
    "url": "https://www.semanticscholar.org/paper/2b34a0a10e53b9f623a1a5363cea8d332bb09757",
    "pdf_url": "",
    "venue": "Chinese Journal of Sociology",
    "citation_count": 6,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895216"
  },
  {
    "source": "semantic_scholar",
    "source_id": "21c6ccffad2cf969aa3b74570fd50405ad700e90",
    "title": "Human Resource Management and Generative Artificial Intelligence (ChatGPT): Nexus, Perspectives and Praxis",
    "authors": [
      "Onyinyechi Ajaero",
      "Julius Bolade Anjorin"
    ],
    "year": 2024,
    "abstract": "The workplace is changing, ChatGPT and other AI technologies are leading the way. ChatGPT is a cutting-edge chatbot created by OpenAI that uses natural language processing to respond to user requests with \"human-like\" speech. Businesses all over the world are taking notice of it because of its robust capabilities, which have the possibility of helping automate a multitude of company procedures. The aim of the study is to identify the ChatGPT - Nexus, Perspectives and Praxis and investigate the concept\u2019s applicability to generative AI and HRM. This is to underscore and device remediation strategies with respect to likely difficulties in the broad use of ChatGPT in HRM. To stop unfair behaviors and ensure that employees are treated fairly, ethical issues like algorithmic bias and data privacy must be thoroughly examined. The methodology employed involves the use of qualitative paradigm involving the review of literature such as books, journals, publications, articles, online resources among others. The integrative literature review approach enables the researcher to conduct a critical assessment of AI technology vis-\u00e0-vis HRM. The study is anchored by one of the most widely accepted theories in human resource management \u2013 The Resource-Based View. The study predicts a significant decline in the likelihood of attaining a long-term competitive advantage through strategic Human Resource Management when considering the effects of widely used ChatGPT. The study's findings indicate that ChatGPT help team members communicate and work together more effectively by simplifying the understanding and tracking of project progress, processing and analyzing large amounts of text-based data, facilitating cross-cultural communication, and giving prompt, accurate answers to frequently asked questions. Hiring and recruiting are two critical HR processes towhich generative AI impacts immediate benefits.",
    "doi": "10.37745/gjhrm.2013/vol12n51929",
    "url": "https://www.semanticscholar.org/paper/21c6ccffad2cf969aa3b74570fd50405ad700e90",
    "pdf_url": "https://eajournals.org/gjhrm/wp-content/uploads/sites/34/2024/07/Human-Resource-Management.pdf",
    "venue": "Global journal of human resource management",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895217"
  },
  {
    "source": "semantic_scholar",
    "source_id": "312e66bcee5bad5376a97f4d771ecdcca2c78078",
    "title": "Transparency In The reporting of Artificial INtelligence \u2013 the TITAN guideline",
    "authors": [
      "R. Agha",
      "Ginimol Mathew",
      "Rasha Rashid",
      "Ahmed Kerwan",
      "A. Al-Jabir",
      "C. Sohrabi",
      "T. Franchi",
      "Maria Nicola",
      "M. Agha"
    ],
    "year": 2025,
    "abstract": "The use of AI in research and the literature is increasing. The need for transparency is clear. Here we present a guideline to transparently reporting the use of AI in any manuscript in general. The guideline items cover; declaration, purpose and scope, AI tools and configuration, data inputs and safeguards, human oversight and verification, bias, ethics and regulatory compliance and reproducibility and transparency. This guide will evolve over time as technology, systems and behaviour evolve.",
    "doi": "10.70389/pjs.100082",
    "url": "https://www.semanticscholar.org/paper/312e66bcee5bad5376a97f4d771ecdcca2c78078",
    "pdf_url": "",
    "venue": "Premier Journal of Science",
    "citation_count": 1398,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895219"
  },
  {
    "source": "semantic_scholar",
    "source_id": "21d151d9b338618999861a2c6833ba15718fd688",
    "title": "AI and Ethics: Scale Development for Measuring Ethical Perceptions of Artificial Intelligence Across Sectors and Countries",
    "authors": [
      "Ezgi Saatci"
    ],
    "year": 2025,
    "abstract": "Artificial Intelligence (AI) has rapidly become an integral technology across many sectors, including healthcare, finance, research, and manufacturing. AI\u2019s ability to automate processes, analyse large datasets, and make predictive decisions offers significant opportunities for innovation, but it also raises profound ethical challenges. Ethical concerns regarding AI encompass issues of transparency, accountability, fairness, data privacy, and the need for human oversight. Given the diverse applications of AI, these ethical concerns vary not only by sector but also across different cultural and regulatory environments. Despite growing discourse on AI ethics, empirical tools for assessing ethical perceptions of AI across varied organizational contexts remain limited. From that need, this study introduces the AI and Ethics Perception Scale (AEPS), designed to measure individual and collective perceptions of AI ethics across five key dimensions: Transparency, Accountability, Privacy, Fairness, and Human Oversight. The AEPS was developed through a rigorous methodological process, beginning with a pilot study of 112 participants and validated with data from 417 participants across three culturally diverse countries: Turkey, India, and the United Kingdom. The scale was used to assess ethical perceptions in sectors such as healthcare, finance, and manufacturing. Both Exploratory Factor Analysis (EFA) and Confirmatory Factor Analysis (CFA) were used to validate the scale\u2019s structure. This study reveals significant cross-cultural and cross-sectoral differences in the prioritization of ethical concerns, demonstrating the need for contextually sensitive ethical frameworks for AI governance.\n",
    "doi": "10.11648/j.ijebo.20251301.14",
    "url": "https://www.semanticscholar.org/paper/21d151d9b338618999861a2c6833ba15718fd688",
    "pdf_url": "",
    "venue": "International Journal of Economic Behavior and Organization",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895221"
  },
  {
    "source": "semantic_scholar",
    "source_id": "c54afa2427b1eaa8b5e7a31e592f6c4612d709a6",
    "title": "Potential of Artificial Intelligence in Boosting Employee Retention in the Human Resource Industry",
    "authors": [
      "S. Paigude",
      "Smita C. Pangarkar",
      "Sheela Hundekari",
      "Manisha Mali",
      "Kirti H. Wanjale",
      "Yashwant Dongre"
    ],
    "year": 2023,
    "abstract": "Artificial intelligence (AI) has the potential to transform the human resource (HR) industry by automating routine tasks, improving decision-making, and enhancing employee engagement and retention. In this paper, we explore the use of machine learning and deep learning techniques to boost employee retention in the HR industry. We review the current state of the art in AI for HR, including the use of predictive analytics, natural language processing, and chatbots for talent management and employee development. We also discuss the challenges and ethical considerations of using AI in HR, including issues of bias and the need for transparent and explainable algorithms. Finally, we present case studies of successful AI-powered HR initiatives that have demonstrated improvements in employee retention and engagement. Our findings suggest that AI has the potential to significantly enhance employee retention in the HR industry, but its implementation requires careful planning and consideration of potential risks and ethical issues.",
    "doi": "10.17762/ijritcc.v11i3s.6149",
    "url": "https://www.semanticscholar.org/paper/c54afa2427b1eaa8b5e7a31e592f6c4612d709a6",
    "pdf_url": "https://ijritcc.org/index.php/ijritcc/article/download/6149/5711",
    "venue": "International Journal on Recent and Innovation Trends in Computing and Communication",
    "citation_count": 33,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895223"
  },
  {
    "source": "semantic_scholar",
    "source_id": "ae0cf9e758bcbfcb2acfa58bb15aaccdd8745eaa",
    "title": "How artificial intelligence adopts human biases: the case of cosmetic skincare industry",
    "authors": [
      "A. Georgievskaya",
      "T. Tlyachev",
      "Daniil Danko",
      "K. Chekanov",
      "Hugo Corstjens"
    ],
    "year": 2023,
    "abstract": "The cosmetic skincare industry is a growing market that extends to different regions and customer groups. In addition to scientific advances and technological developments, state-of-the-art digital approaches, including machine learning and other artificial intelligence (AI)-based techniques, are being applied at different stages of the value chain. The objectives of these efforts include optimizing the supply chain, developing high-quality, effective and safe products and personalization at every step of the customer journey. However, the use of digital technologies comes with risks and undesirable effects. These include a lack of transparency and accountability, compromised fairness and a general deficiency in data governance, all of which are critical at every customer touchpoint. This dark side of digital transformation is recognized by both businesses and governments. In this paper, we explain the concept of bias leading to unfairness for beauty technology applications. Based on published data we identified potential sources of AI bias in the cosmetic skincare industry and/or beauty tech. They were classified by the stage of the AI lifecycle: biases related to target setting, to acquisition and annotation, to modeling, to validation and evaluation, and to deployment and monitoring. We aim to create awareness of such phenomena among readers, whether executives, managers, developers or potential end-users.",
    "doi": "10.1007/s43681-023-00378-2",
    "url": "https://www.semanticscholar.org/paper/ae0cf9e758bcbfcb2acfa58bb15aaccdd8745eaa",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s43681-023-00378-2.pdf",
    "venue": "AI and Ethics",
    "citation_count": 21,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:49.895224"
  },
  {
    "source": "semantic_scholar",
    "source_id": "58ce6320bf0642bf033e3a0afe4abc4a9278f7f0",
    "title": "A systematic literature review on artificial intelligence in recruiting and selection: a matter of ethics",
    "authors": [
      "Martina Mori",
      "Sara Sassetti",
      "Vincenzo Cavaliere",
      "Mariacristina Bonti"
    ],
    "year": 2024,
    "abstract": "PurposeStarting from the relevance of ethics to the application of artificial intelligence (AI) in the context of employee recruitment and selection (R&S), in this article, we aim to provide a comprehensive review of the literature in light of the main ethical theories (utilitarian theories, theories of justice, and theories of rights) to identify a future research agenda and practical implications.Design/methodology/approachOn the basis of the best-quality and most influential journals, we conducted a systematic review of 120 articles from two databases (Web of Science and Scopus) to provide descriptive results and adopt a framework for deductive classification of the main topics.FindingsInspired by the three ethical theories, we identified three thematic lines of enquiry for the debate on AI in R&S: (1) the utilitarian view: the efficient optimisation of R&S through AI; (2) the justice view: the perceptions of justice and fairness related to AI techniques; and (3) the rights view: the respect for legal and human rights requirements when AI is applied.Originality/valueThis article provides a detailed assessment of the adoption of AI in the R&S process from the standpoint of traditional ethics theories and offers an integrative theoretical framework for future research on AI in the broader field of HRM.",
    "doi": "10.1108/pr-03-2023-0257",
    "url": "https://www.semanticscholar.org/paper/58ce6320bf0642bf033e3a0afe4abc4a9278f7f0",
    "pdf_url": "",
    "venue": "Person-centered review",
    "citation_count": 29,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895226"
  },
  {
    "source": "semantic_scholar",
    "source_id": "934c5c7649d29a3429969910b4e473d237315670",
    "title": "AI AND HUMAN RESOURCE MANAGEMENT: A MULTIDISCIPLINARY PERSPECTIVE ON EFFICIENCY AND ETHICS",
    "authors": [
      "H. A",
      "Dr.S. Saravanan",
      "Dr Rajeshwari shinde",
      "D. Rawat",
      "Dr.Yazhini Kuppusamy",
      "Dr. O. Pandithurai"
    ],
    "year": 2025,
    "abstract": "The rapid integration of Artificial Intelligence (AI) into Human Resource Management (HRM) has redefined the traditional boundaries of workforce administration, talent acquisition, and employee engagement. As organizations increasingly rely on algorithmic systems for decision-making, the convergence of technological efficiency and ethical responsibility has emerged as a pivotal concern within modern management discourse. This research explores the multifaceted role of AI in reshaping HR functions through a multidisciplinary lens, combining insights from management science, behavioral psychology, data ethics, and organizational sociology. The study examines how AI-driven tools such as predictive analytics for recruitment, natural language processing in performance evaluation, and automated sentiment analysis for employee well-being have enhanced operational precision and strategic decision-making in HRM. Methodologically, the research employs a mixed approach, synthesizing empirical case studies, policy reviews, and theoretical frameworks to evaluate both the efficiency gains and ethical complexities arising from AI adoption. Findings indicate that AI significantly reduces administrative redundancy, enhances predictive accuracy in workforce planning, and enables a more data-driven understanding of employee behavior. However, these advancements are counterbalanced by profound ethical and social challenges, including algorithmic bias, loss of transparency, privacy intrusions, and the erosion of human discretion in evaluative processes. The analysis reveals that while AI augments managerial capabilities, its unregulated application risks transforming human resources into mere data entities, thereby undermining the human-centric foundations of employment relations. The paper argues that a sustainable integration of AI in HRM must reconcile the competing imperatives of efficiency and ethics through an adaptive governance framework. This includes instituting algorithmic accountability, transparent data management policies, and cross-disciplinary collaboration between technologists, ethicists, and HR professionals. Furthermore, the study emphasizes the importance of cultivating digital literacy and ethical awareness among HR practitioners to ensure that AI complements rather than replaces human judgment. Ultimately, the research contributes to the growing discourse on responsible AI by demonstrating that technological progress in HRM must be guided not only by efficiency metrics but also by normative principles that preserve fairness, dignity, and inclusivity in the workplace. It calls for a paradigm shift toward a balanced, ethically informed, and human-centered approach to managing the future of work. \n\u00a0",
    "doi": "10.52152/rs45sj42",
    "url": "https://www.semanticscholar.org/paper/934c5c7649d29a3429969910b4e473d237315670",
    "pdf_url": "",
    "venue": "Lex localis - Journal of Local Self-Government",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895227"
  },
  {
    "source": "semantic_scholar",
    "source_id": "97027eb0412de7a15ecd19e05b2f997b4da945c9",
    "title": "Ethics and Artificial Intelligence",
    "authors": [
      "Bhautik Modi"
    ],
    "year": 2025,
    "abstract": "Artificial Intelligence (AI) is revolutionizing industries ranging from healthcare and finance to transportation and warfare. However, its rapid advancement presents profound ethical challenges, including algorithmic bias, privacy concerns, accountability, and workforce disruption. This article explores key dimensions of AI ethics, such as defining ethical boundaries, addressing bias, and navigating privacy in the age of data-driven innovation. It highlights ethical dilemmas in healthcare, workforce implications, and military applications of AI. Furthermore, the article underscores the need for global regulatory frameworks, interdisciplinary collaboration, and stakeholder engagement to ensure responsible AI development. As AI continues to evolve, a balance between innovation and ethical oversight is paramount to aligning technological progress with societal values and human rights. By fostering inclusivity and prioritizing transparency, we can navigate the complexities of AI ethics and harness its transformative potential responsibly.",
    "doi": "10.55489/ijmr.1303202582",
    "url": "https://www.semanticscholar.org/paper/97027eb0412de7a15ecd19e05b2f997b4da945c9",
    "pdf_url": "",
    "venue": "International Journal of Medical Research",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895229"
  },
  {
    "source": "semantic_scholar",
    "source_id": "5a81b9633cdcebbb1b09ca0fa21657165f2c0014",
    "title": "A Study On Artificial Intelligence Ethics In Education",
    "authors": [
      "H. Vashistha",
      "Harikrishnan M"
    ],
    "year": 2025,
    "abstract": "This rapid advancement and development of Artificial Intelligence (AI) technologies has significantly transformed various sectors, like research and development sectors, education sectors including education. As educational institutions increasingly integrate AI tools and systems, to gather information, data and other necessary items, use of Artificial Intelligence (AI) has become a common practice as well as a basic necessity. This study explores the necessity of incorporating AI ethics into education curricula, examining how ethical considerations can guide the development, deployment, and use of AI technologies within academic settings, this study also includes the negative impact that AI is putting on our human mind, human intelligence and the thinking ability of the human beings. We will find out how the AI is making us lazy not to use our own brain or study books and other informative items like journals, research papers, magazines etc to gather information. Through a comprehensive review of current literature and case studies, the research highlights key ethical concerns such as data privacy, algorithmic bias, and the impact of AI on academic integrity and student outcomes (Anderson & Anderson, 2018; Binns, 2018). The study also assesses existing frameworks and guidelines for AI ethics and their applicability to education contexts (Chen et al., 2020). By identifying gaps and proposing actionable recommendations, this study aims to provide educators, policymakers, and AI practitioners with a strategic approach to embedding ethical practices in AI-related education. The findings underscore the importance of developing a multidisciplinary approach to AI ethics that incorporates insights from computer science, philosophy, law, and education to ensure that AI technologies are used responsibility and equitably in academic environments (Floridi, 2019; Holmes et al., 2019).",
    "doi": "10.36948/ijfmr.2025.v07i01.36798",
    "url": "https://www.semanticscholar.org/paper/5a81b9633cdcebbb1b09ca0fa21657165f2c0014",
    "pdf_url": "",
    "venue": "International Journal For Multidisciplinary Research",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895230"
  },
  {
    "source": "semantic_scholar",
    "source_id": "5fe35633c4e78e00f481130220a510de87a16092",
    "title": "Research on Algorithmic Ethics in Artificial Intelligence",
    "authors": [
      "Xinying Xu"
    ],
    "year": 2024,
    "abstract": "With the rapid development of artificial intelligence, the ethical issues of artificial intelligence have become increasingly prominent. This paper discusses the problems of data security, bias and the implantation of morality and values in the ethics of artificial intelligence algorithms, and systematically and comprehensively expounds the main solutions to these three problems. It is found that the current three major technical paths for solving the data security issues have the problems of high dependency, large computation and communication overhead, and limited applicability, and the future trend is the integration and development of the three paths; the solution of the bias problem needs to be improved in terms of interpretability under the condition that the underlying fairness is difficult to be determined; and it is difficult for the implantation of morality and values to take into account the learning ability, adaptability, and interpretability at the same time. Finally, this paper analyzes and looks forward to the development of AI ethics, hoping to provide lessons and references for AI ethics-related research.",
    "doi": "10.1109/IoTAAI62601.2024.10692746",
    "url": "https://www.semanticscholar.org/paper/5fe35633c4e78e00f481130220a510de87a16092",
    "pdf_url": "",
    "venue": "2024 6th International Conference on Internet of Things, Automation and Artificial Intelligence (IoTAAI)",
    "citation_count": 0,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:49.895232"
  },
  {
    "source": "semantic_scholar",
    "source_id": "e6cb3bd3c0f7ffc55a8d5af27c4c57e57601138b",
    "title": "Fairness, Bias, and Ethics in AI: Exploring the Factors Affecting Student Performance",
    "authors": [
      "N. Gordon",
      "Tareq Al Jaber",
      "Doris Omughelli"
    ],
    "year": 2024,
    "abstract": "The use of artificial intelligence (AI) as a data science tool for education has enormous potential for increasing student performance and course outcomes. However, the growing concern about fairness, bias, and ethics in AI systems requires a careful examination of these issues in an educational context. Using AI and predictive modelling tools, this paper explores the aspects influencing student performance and course success. The Open University Learning Analytics Dataset (OULAD) is analysed using several AI techniques (logistic regression and random forest) in this study to reveal insights about fairness, ethics, and potential biases. This dataset has been used by hundreds of studies to explore how educational data mining can provide information on students. However, potential bias or unfairness in that dataset could undermine the results and any conclusions made from them. To gain insights into the dataset's properties, this was analysed using a typical data science methodology, which included data collecting, cleaning, and exploratory data analysis using Python. By applying AI-based predictive models, this study\u00a0aims\u00a0to detect potential biases and their impact on student outcomes. Fairness and ethical considerations are central to the analysis as the representation of various demographic groups and any disparities are\u00a0evaluated\u00a0in course results. The goal is to provide useful insights on the proper use of AI in education, while also maintaining equitable and transparent decision-making procedures. The findings shed light on the complicated interplay between artificial intelligence, fairness, and ethics in the context of student performance and course success. As artificial intelligence continues to influence the educational landscape, this study will provide useful ideas for encouraging fairness and minimising biases, resulting in a more inclusive and equal learning environment.",
    "doi": "10.54963/jic.v4i1.306",
    "url": "https://www.semanticscholar.org/paper/e6cb3bd3c0f7ffc55a8d5af27c4c57e57601138b",
    "pdf_url": "https://ojs.ukscip.com/journals/jic/article/download/306/258",
    "venue": "Journal of Intelligent Communication",
    "citation_count": 6,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895233"
  },
  {
    "source": "semantic_scholar",
    "source_id": "e340d387f359e98cad6c604f5279cc4a5171aee2",
    "title": "Fairness and bias in AI: a sociotechnical perspective",
    "authors": [
      "Sanae el Mimouni",
      "M. Bouhdadi"
    ],
    "year": 2025,
    "abstract": "\n \n This paper aims to advance a comprehensive sociotechnical framework for addressing fairness and bias in artificial intelligence (AI) systems, recognizing that purely technical solutions are insufficient to ensure equitable AI deployment across sectors such as hiring, lending and criminal justice.\n \n \n \n This study critically evaluates existing technical solutions for mitigating bias, highlighting their limitations in addressing real-world sociocultural contexts. A sociotechnical framework that combines algorithmic techniques, human oversight, regulatory frameworks and stakeholder engagement is proposed.\n \n \n \n This study presents a multi-component framework that integrates technical debiasing methods, stakeholder engagement, human oversight, regulatory compliance and continuous evaluation. The framework demonstrates that combining technical expertise, social science insights and diverse stakeholder perspectives leads to more effective bias mitigation and fairer AI systems.\n \n \n \n Although the framework provides a theoretical foundation, its practical implementation across different contexts and organizations requires further empirical validation. Future research should focus on measuring the effectiveness of this framework in real-world applications.\n \n \n \n This paper advances the field by proposing a comprehensive sociotechnical framework that bridges the gap between technical and social approaches to AI fairness, providing practical guidelines for organizations while acknowledging the complexity of implementing fair AI systems.\n",
    "doi": "10.1108/jices-12-2024-0182",
    "url": "https://www.semanticscholar.org/paper/e340d387f359e98cad6c604f5279cc4a5171aee2",
    "pdf_url": "",
    "venue": "Journal of Information, Communication and Ethics in Society",
    "citation_count": 3,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895235"
  },
  {
    "source": "semantic_scholar",
    "source_id": "401be0ddf265363b621a7f9ab15eb0665503d7e7",
    "title": "An Overview of Artificial Intelligence Ethics: Issues and Solution for Challenges in Different Fields",
    "authors": [
      "S. P. Santhoshkumar",
      "K. Susithra",
      "T. K. Prasath"
    ],
    "year": 2023,
    "abstract": "Artificial Intelligence (AI) ethics are the values and principles that govern the creation and application of AI. As AI technology develops quickly, there is rising worry about the possible ethical ramifications of its application, including concerns about privacy, bias, accountability, transparency, safety, and the effect on society as a whole. Making sure AI systems are created and used in a way that respects human rights and values is one of the main concerns of AI ethics. For instance, there can be worries about the use of AI in surveillance or the possibility that these technologies will legitimise already-existing social prejudices and discrimination. Making sure AI systems are accountable and transparent is a key aspect of AI ethics. It can be challenging to comprehend how AI systems make judgements and who is accountable for those decisions as they get more complicated and autonomous. Transparency in AI research and decision-making, as well as systems for accountability and remedies when things go wrong, are becoming increasingly important. Additionally, it's important to guarantee the security and safety of AI systems. Concern over the possibility of cyberattacks and other types of harmful use is growing as AI systems become more linked and incorporated into our daily lives. Finally, it's important to make sure that AI is created and applied in a way that benefits all humanity. This entails tackling problems like employment loss, economic inequality, and the possibility that AI will be applied in ways that are detrimental to society. There is an increasing need for cooperation between business, government, academia, and civil society to address these and other ethical issues. This involves creating moral standards, norms, and best practises as well as the systems necessary to guarantee responsibility and compliance.",
    "doi": "10.36548/jaicn.2023.1.006",
    "url": "https://www.semanticscholar.org/paper/401be0ddf265363b621a7f9ab15eb0665503d7e7",
    "pdf_url": "https://doi.org/10.36548/jaicn.2023.1.006",
    "venue": "March 2023",
    "citation_count": 5,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895236"
  },
  {
    "source": "semantic_scholar",
    "source_id": "26ad600f03e0b0395ca2d1c291a2f8cddc24eadd",
    "title": "Faith and Artificial Intelligence (AI) in Catholic Education: A Theological Virtue Ethics Perspective",
    "authors": [
      "Jeff Clyde Corpuz"
    ],
    "year": 2025,
    "abstract": "This study responds to the increasing call for thoughtful theological and ethical engagement with Artificial Intelligence (AI) by examining the role of personal theological reflection using Generative Artificial Intelligence (GenAI) content in Catholic theological education. It investigates how both educators and students might utilize AI-generated imagery as a pedagogical resource with which to enrich theological insight and foster ethical discernment, particularly through the lens of theological virtue ethics. AI is not a substitute for all human tasks. However, the use of AI holds potential for theology and catechetical religious education. Following Gl\u00e4ser-Zikuda\u2019s model of Self-Reflecting Methods of Learning Research, this study systematically engages in reflective observation to examine how the use of GenAI in theology classrooms has influenced personal theological thinking, pedagogical practices, and ethical considerations. It documents experiences using common generative AI tools such as ChatGPT, Canva, Meta AI, Deep AI, and Gencraft in theology classes. The principles of virtue ethics and Human-Centered Artificial Intelligence (HCAI) offer a critical framework for ethical, pedagogical, and theological engagement. The findings contribute to the emerging interdisciplinary discourse on AI ethics and theology, and religious pedagogy in the digital age.",
    "doi": "10.3390/rel16081083",
    "url": "https://www.semanticscholar.org/paper/26ad600f03e0b0395ca2d1c291a2f8cddc24eadd",
    "pdf_url": "",
    "venue": "Religions",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895238"
  },
  {
    "source": "semantic_scholar",
    "source_id": "fe2af1b0bbe5a66edb8ad90133ccc1f05dddb44d",
    "title": "Issues and Prospects in the Use of Artificial Intelligence in Human Resource Management",
    "authors": [
      "Swati Atmaram Chougule"
    ],
    "year": 2023,
    "abstract": "We examine the gap between the promise and reality of artificial intelligence in human resource management and propose ways forward. We highlight four problems with using data science approaches to human resource tasks: 1) the complexity of HR phenomena, 2) the restrictions imposed by tiny data sets, 3) accountability problems related to fairness and other ethical and regulatory constraints, and 4) the possibility of unfavorable employee responses to management choices using data-based algorithms. We suggest practical solutions to these issues, focusing on three overlapping concepts-cause and effect, randomization and trials, and employee input-that might be both economically efficient and socially suitable for employing data science in employee management.",
    "doi": "10.51976/ijari.1042208",
    "url": "https://www.semanticscholar.org/paper/fe2af1b0bbe5a66edb8ad90133ccc1f05dddb44d",
    "pdf_url": "https://doi.org/10.51976/ijari.1042208",
    "venue": "International journal of advance research and innovation",
    "citation_count": 2,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895240"
  },
  {
    "source": "semantic_scholar",
    "source_id": "fe33b5a74255728246848eab05023a78b1f6aa43",
    "title": "Role Of Artificial Intelligence in Human Resources",
    "authors": [
      "Palak Soni"
    ],
    "year": 2025,
    "abstract": "Abstract\n\n \n\nArtificial Intelligence (AI) has become a transformative force in Human Resource Management (HRM), revolutionizing core functions such as recruitment, performance management, training, and employee engagement. This paper explores the integration of AI in HR processes, focusing on its applications, benefits, and associated challenges. A combination of literature review and primary research has been used to understand the current trends, potential advantages, and ethical concerns. The findings suggest that while AI significantly enhances efficiency and data-driven decision-making in HR, concerns regarding algorithmic bias, data privacy, and the loss of human touch remain. This study provides insights into how organizations can responsibly implement AI in HR, balancing technological innovation with ethical and human-centric practices.",
    "doi": "10.55041/ijsrem50409",
    "url": "https://www.semanticscholar.org/paper/fe33b5a74255728246848eab05023a78b1f6aa43",
    "pdf_url": "",
    "venue": "INTERNATIONAL JOURNAL OF SCIENTIFIC RESEARCH IN ENGINEERING AND MANAGEMENT",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895286"
  },
  {
    "source": "semantic_scholar",
    "source_id": "2ad6b8c806b81fd7e3efa39767429832b448902f",
    "title": "AI Ethics in Engineering: Enhancing Fairness in Machine Learning Models for Critical Systems",
    "authors": [
      "Vijayalaxmi Methuku",
      "Direesh Reddy Aunugu",
      "Anil Kumar Jonnalagadda",
      "Praveen Kumar Myakala"
    ],
    "year": 2025,
    "abstract": "The integration of artificial intelligence (AI) and machine learning (ML) into engineering systems has revolutionized industries such as autonomous vehicles, renewable energy management, and industrial automation. While these advancements have significantly improved efficiency, predictive accuracy, and operational reliability, they have also introduced ethical challenges, particularly concerning fairness and bias in decision-making. This study investigates the ethical implications of AI in critical engineering systems, focusing on fairness in resource allocation, fault detection, and safety-critical applications. Three engineering datasets were analyzed to evaluate bias and fairness in ML models: the KITTI Vision Benchmark Suite for autonomous vehicles, NASA\u2019s C-MAPSS dataset for aerospace predictive maintenance, and the UCI Gas Sensor Array Drift dataset for industrial IoT applications. Ensemble methods such as Random Forest and LightGBM were employed due to their robustness in handling complex datasets. Bias mitigation strategies, including reweighting, data augmentation, and fairness constraints, were applied to address disparities and ensure equitable outcomes. Results demonstrated significant improvements in fairness metrics, with demographic parity, equal opportunity, and disparate impact showing an average enhancement of over 30% across datasets. Precision improved by 9.75%, recall increased by 17.71%, and AUC-ROC rose by 14.18%. Although accuracy experienced a minor reduction (3% on average), these gains underscore the effectiveness of the mitigation techniques in achieving fairness while maintaining system performance. This study highlights the importance of integrating fairness into AI models for engineering systems, balancing performance with ethical considerations to ensure equitable and reliable outcomes in critical applications.",
    "doi": "10.1109/ICCIES63851.2025.11032595",
    "url": "https://www.semanticscholar.org/paper/2ad6b8c806b81fd7e3efa39767429832b448902f",
    "pdf_url": "",
    "venue": "2025 International Conference on Computational Innovations and Engineering Sustainability (ICCIES)",
    "citation_count": 3,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895289"
  },
  {
    "source": "semantic_scholar",
    "source_id": "3e61f0f22f9d53b2deca9af45c03b6bf3092d0ea",
    "title": "The Role of Artificial Intelligence in Modern Human Resource Management: A Review",
    "authors": [
      "Priti Dubey"
    ],
    "year": 2023,
    "abstract": "More than anything else, artificial intelligence is crucial to the human resources sector. In order to recruit and create a competent staffing and hiring process, HR recruiters have integrated AI technologies. HR duties are anticipated to adapt in tandem with the ongoing changes in the workplace and the advancement of technology in all industries nowadays. In this article review the various study on role of artificial intelligence in modern human resource management. It concluded that AI is transforming Human Resource Management (HRM) by improving efficiency, decision-making, and employee experience. It streamlines recruitment, talent management, performance evaluation, and workplace safety while enabling data-driven insights. However, ethical concerns such as bias and job displacement must be addressed. Balancing AI automation with human empathy is crucial for its success. This review highlights AI\u2019s potential and its mediating factors, such as creativity and usability, in HRM. While AI offers significant benefits, industry-specific challenges and its evolving nature must be considered. Thoughtful and strategic AI integration will ensure ethical, effective, and sustainable workforce management in modern organizations.",
    "doi": "10.69968/ijisem.2023v2i459-64",
    "url": "https://www.semanticscholar.org/paper/3e61f0f22f9d53b2deca9af45c03b6bf3092d0ea",
    "pdf_url": "",
    "venue": "International Journal of Innovations in Science Engineering And Management",
    "citation_count": 3,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895290"
  },
  {
    "source": "semantic_scholar",
    "source_id": "3c75e26a59826ace7d7a12762c3cb0021b682119",
    "title": "Artificial Intelligence in Human Resource Management: Advancements, Implications and Future Prospects",
    "authors": [
      "Saraswathi T",
      "Karthikeyan M",
      "C. Balakrishnan",
      "T. Nithya",
      "B. Maheswari",
      "Siva Subramanian.R"
    ],
    "year": 2023,
    "abstract": "The present condition, challenges, and potential applications of artificial intelligence (AI) in human resource management (HRM) are all explored in this survey article. As an innovation, artificial intelligence (AI) has the potential to completely revolutionize several facets of human resource management (HRM). Examining the usage of AI-powered tools and systems in different HR processes, the present situation with AI in HRM is examined. These encompass learning and development, performance management, employee engagement, and recruiting. The use of AI algorithms and machine learning approaches to automate regular HR operations, analyze vast amounts of employee data, and provide insightful data to aid decision-making is addressed in this article. However, integrating AI into HRM also poses a number of difficulties that must be resolved. Bias, privacy issues, and transparency are just a few of the ethical and legal ramifications of using AI in decision-making processes that are discussed in this survey. The study emphasizes how accountability and fairness must be maintained in AI systems by responsible design, oversight, and periodic evaluation. With an emphasis on job displacement and workforce reorganization, the possible influence of AI on the human workforce is also explored. To effectively traverse this change, strategies including work role redefinition, employee up skilling, and establishing a collaborative atmosphere between humans and AI are suggested. The possible advantages and breakthroughs that AI might bring to HRM practices are highlighted as the future perspectives of AI in HRM are examined. As new applications for AI in HRM, sentiment analysis, predictive analytics, intelligent decision support, and personalized employee experiences are all highlighted. In order to fully realize the promise of AI in HRM, the study underlines the significance of data infrastructure, data governance frameworks, and a data-driven culture. Overall, this survey study offers an in-depth review of the existing situation, difficulties, and prospects for AI in HRM. It aggregates current information, identifies research gaps, and gives practitioners and scholars new perspectives on how AI will fundamentally alter the way HRM activities are carried out in the future.",
    "doi": "10.17762/ijritcc.v11i11s.8099",
    "url": "https://www.semanticscholar.org/paper/3c75e26a59826ace7d7a12762c3cb0021b682119",
    "pdf_url": "https://ijritcc.org/index.php/ijritcc/article/download/8099/6531",
    "venue": "International Journal on Recent and Innovation Trends in Computing and Communication",
    "citation_count": 3,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895292"
  },
  {
    "source": "semantic_scholar",
    "source_id": "6579b1945d457ffddc4e3baf3c2d39b89517da1f",
    "title": "Transformative AI in human resource management: enhancing workforce planning with topic modeling",
    "authors": [
      "Murale Venugopal",
      "Vandana Madhavan",
      "Rajiv Prasad",
      "R. Raman"
    ],
    "year": 2024,
    "abstract": "Abstract This study explores the transformative role of artificial intelligence (AI) in human resource management (HRM), focusing on key functions such as recruitment, retention, and performance management. A comprehensive review was carried out PRISMA framework and BERTopic model on AI and HRM\u2011related keywords. The resulting publications were analyzed to extract meaningful topics. AI\u2011driven tools streamline candidate screening and interview analysis, significantly enhancing hiring efficiency and decision\u2011making accuracy. Concerns about algorithmic bias highlight the need for robust governance frameworks to ensure transparency and fairness in AI\u2011driven processes. The study emphasizes the importance of aligning AI adoption with Organizational Development principles to foster inclusivity and organizational justice. The integration of AI in performance management facilitates real\u2011time, objective performance assessments, although overreliance on such technologies can affect employee trust and engagement. Despite these advances, the study highlights ethical concerns surrounding data privacy and the potential for algorithmic bias. Addressing these challenges requires the implementation of comprehensive ethical frameworks to promote fairness and inclusivity in AI\u2011HRM applications. Strategically, AI transforms HR from a reactive function to a proactive, data\u2011driven partner aligned with long\u2011term organizational goals. Successful AI integration depends on governance mechanisms that uphold ethical standards, foster employee trust, and ensure transparency, enabling organizations to fully leverage AI\u2019s potential in enhancing workforce management.",
    "doi": "10.1080/23311975.2024.2432550",
    "url": "https://www.semanticscholar.org/paper/6579b1945d457ffddc4e3baf3c2d39b89517da1f",
    "pdf_url": "",
    "venue": "Cogent Business &amp; Management",
    "citation_count": 37,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895294"
  },
  {
    "source": "semantic_scholar",
    "source_id": "36b7144904d27483369d7f0a0a62000e85ba9e45",
    "title": "AI-Driven human resource systems for equitable workplaces: A roadmap for the future of U.S. healthcare and nonprofits",
    "authors": [
      "Ndifreke D. Essien",
      "Chibuzor Njoku",
      "Ifeoma Solomon",
      "Evelyn Gachui"
    ],
    "year": 2025,
    "abstract": "Artificial Intelligence (AI) is increasingly transforming Human Resource (HR) systems, offering new possibilities for addressing systemic challenges in healthcare and nonprofit sectors\u2014namely, burnout, workforce attrition, and inequitable employment practices. This literature review explores how AI-driven tools such as machine learning, predictive analytics, and digital automation are being applied to core HR functions including burnout detection, pay equity analysis, performance evaluation, scheduling, and turnover prediction. With burnout rates rising and equity gaps persisting, particularly in mission-driven environments, AI presents an opportunity to deliver data-informed, scalable interventions that improve employee well-being and organizational fairness. The review highlights key benefits of AI integration, including administrative efficiency, reduced bias, improved decision-making, and early intervention capabilities. It also critically examines ethical challenges related to algorithmic bias, transparency, employee privacy, and the potential dehumanization of workplace interactions. Drawing on case studies, regulatory guidance, and emerging research, the manuscript proposes a roadmap for ethical AI implementation tailored to the values of social impact organizations. The recommendations emphasize human oversight, stakeholder inclusion, AI literacy, and privacy safeguards. The analysis concludes that AI\u2019s role in HR should be augmentative\u2014amplifying human empathy and institutional integrity. When guided by equitable frameworks, AI-enabled HR systems can not only mitigate existing workplace inequities but also build more resilient, inclusive, and sustainable workforces across healthcare and nonprofit sectors. \nKeywords: Artificial Intelligence, Burnout Prevention, Compensation Equity, Workforce Optimization, Human Resource Technology, Nonprofit Organizations, Healthcare Workforce, Predictive Analytics, Ethical AI, HH Innovation.",
    "doi": "10.51594/ijarss.v7i5.1916",
    "url": "https://www.semanticscholar.org/paper/36b7144904d27483369d7f0a0a62000e85ba9e45",
    "pdf_url": "",
    "venue": "International journal of applied research in social sciences",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895295"
  },
  {
    "source": "semantic_scholar",
    "source_id": "c1964f69305ddec12274a1ac29492b1b609e66e3",
    "title": "Ethics of artificial intelligence in embryo assessment: mapping the terrain",
    "authors": [
      "J. Koplin",
      "M. Johnston",
      "Amy Webb",
      "Andrea Whittaker",
      "Catherine Mills"
    ],
    "year": 2024,
    "abstract": "Abstract Artificial intelligence (AI) has the potential to standardize and automate important aspects of fertility treatment, improving clinical outcomes. One promising application of AI in the fertility clinic is the use of machine learning (ML) tools to assess embryos for transfer. The successful clinical implementation of these tools in ways that do not erode consumer trust requires an awareness of the ethical issues that these technologies raise, and the development of strategies to manage any ethical concerns. However, to date, there has been little published literature on the ethics of using ML in embryo assessment. This mini-review contributes to this nascent area of discussion by surveying the key ethical concerns raised by ML technologies in healthcare and medicine more generally, and identifying which are germane to the use of ML in the assessment of embryos. We report concerns about the \u2018dehumanization\u2019 of human reproduction, algorithmic bias, responsibility, transparency and explainability, deskilling, and justice.",
    "doi": "10.1093/humrep/deae264",
    "url": "https://www.semanticscholar.org/paper/c1964f69305ddec12274a1ac29492b1b609e66e3",
    "pdf_url": "",
    "venue": "Human Reproduction",
    "citation_count": 16,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:49.895297"
  },
  {
    "source": "semantic_scholar",
    "source_id": "d414fad4602cafc68637c0ab105775c40e584aea",
    "title": "Problematizing the role of artificial intelligence in hiring and organizational inequalities: A multidisciplinary review",
    "authors": [
      "Karen D Hughes",
      "Alla Konnikov",
      "Nicole Denier",
      "Yang Hu"
    ],
    "year": 2025,
    "abstract": "What are the implications of the growing use of artificial intelligence (AI) in recruitment and hiring for organizational inequalities? While advocates suggest that AI is a groundbreaking tool that can enhance hiring precision, efficiency, diversity and fit, critics raise serious concerns around bias, fairness, and privacy. This review article critically advances this debate by drawing on diverse scholarship across computing and data sciences; human resource, management, and organization studies; social sciences; and law. Using a hybrid review approach that combines scoping and problematizing review methods, we examine the implications of algorithmic hiring for organizational inequalities. Our review identifies a multidisciplinary discussion marked by asymmetries in how key concerns are conceptualized; a clear and heightened potential for AI to conceal inequalities in hiring processes; and contestation over the regulation of algorithmic hiring. Building on Acker\u2019s (2006) framework of \u2018inequality regimes\u2019, we propose the concept of algorithmically-mediated inequality regimes to highlight AI\u2019s capacity for concealing and reproducing inequalities in hiring through enhanced algorithmic invisibility and the growing legitimacy of AI solutions. We propose an agenda for future research, policy, and practice, emphasizing the need for an interdisciplinary \u2018chain of knowledge\u2019 and a multi-stakeholder \u2018chain of responsibility\u2019 in AI application and regulation.",
    "doi": "10.1177/00187267251403902",
    "url": "https://www.semanticscholar.org/paper/d414fad4602cafc68637c0ab105775c40e584aea",
    "pdf_url": "",
    "venue": "Human relations; studies towards the integration of the social sciences",
    "citation_count": 1,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:49.895299"
  },
  {
    "source": "semantic_scholar",
    "source_id": "f810af61e1e72315c15263aeef874d58d03fe06b",
    "title": "Recalibrating Human\u2013Machine Relations through Bias-Aware Machine Learning: Technical Pathways to Fairness and Trust",
    "authors": [
      "Esam Othman",
      "R. Mahafdah"
    ],
    "year": 2025,
    "abstract": "Considering the importance of artificial intelligence (AI) in decision-making processes in various fields such as health, law and finance, the concern for bias and fairness of decision making has increased. This paper presents an extensive discussion of bias-aware machine learning(Ml) such as fairness-aware modeling, detection and mitigation. The paper demonstrates aspects of fairness, different forms of algorithmic bias including intersectional bias and how biased systems impact society. The paper turns to appreciation of dentieth, Trust Dynamics, Legal and Regulatory Frameworks And in the Context of Promoting Transparency: Exploring the Role of Explainable AI (XAI). Taking into account the current advances for combatting bias, also pre-processing, in-processing, and post-processing methods, for instance, draw on examples from major domains of interest. Apart from the improvements AIs have achieved, existing challenges involve little attention to relationship among different identities, poor frameworks in place for implementation and operation in other parts of the world, inadequate abuse detection mechanisms among others. Regarding this, we present some of the research questions that focus on the notions of transparency, privacy protected fairness audits, and shared control with the aim of guiding the growth of fair, responsible, and competent AI systems.",
    "doi": "10.63332/joph.v5i4.1091",
    "url": "https://www.semanticscholar.org/paper/f810af61e1e72315c15263aeef874d58d03fe06b",
    "pdf_url": "",
    "venue": "Journal of Posthumanism",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895300"
  },
  {
    "source": "semantic_scholar",
    "source_id": "84eb79e6898bf19d51b363a820694007d5b5dd21",
    "title": "Leveraging Artificial Intelligence for Human Resource Analytics from Recruitment to Retention",
    "authors": [],
    "year": 2025,
    "abstract": "Background: Human Resource Management (HRM) experiences substantial changes from Artificial Intelligence (AI) through its ability to deliver data-based recruitment and onboarding insights and performance management and retention analytics. Organizations competing for talent together with employee experience needs achieve measurable decision-making and workforce outcome advantages through AI HR analytics implementation. \n\nMethods: A total of 100 HR professionals from technology and finance sectors as well as retail and healthcare and manufacturing industries participated in the research. The data collection process used a structured questionnaire to assess AI implementation stages and usage locations together with participant views on benefits and implementation hurdles. Quantitative data underwent descriptive statistical analysis while qualitative information helped explain implementation barriers and ethical concerns.\n\nResults: Organizations that apply AI-driven HR analytics achieve significant performance improvements. The recruitment process became 20\u201335% more efficient while the time for hiring shortened drastically and candidate assessment quality improved by 30%. Employee engagement scores showed an 18% increase and voluntary attrition rates dropped by 25%. Organizations which implemented AI-based performance monitoring systems managed to identify employees who needed retention the most thus enhancing their targeted retention approaches. Survey participants pointed out three main obstacles which included data privacy problems (62%), algorithmic bias (48%) and implementation expenses (41%).\n\nConclusion: The successful adoption of technology demands organizations to combine its functional aspects with moral standards which protect equality along with open operations and confidence building.",
    "doi": "10.25163/ai.1110384",
    "url": "https://www.semanticscholar.org/paper/84eb79e6898bf19d51b363a820694007d5b5dd21",
    "pdf_url": "",
    "venue": "Journal of Ai ML DL",
    "citation_count": 2,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895301"
  },
  {
    "source": "semantic_scholar",
    "source_id": "d2900b56cec16f2e1070905489a191bbf87a00be",
    "title": "A Survey on Human Resource Management Under the AI Act: Ethical, Practical, and Regulatory Perspectives",
    "authors": [
      "Nicola Albor\u00e9",
      "Alessandro Castelnovo",
      "Matteo Della Valle",
      "Andrea Ermellino",
      "Luca Puggini",
      "Silvia Tessaro"
    ],
    "year": 2025,
    "abstract": null,
    "doi": null,
    "url": "https://www.semanticscholar.org/paper/d2900b56cec16f2e1070905489a191bbf87a00be",
    "pdf_url": "",
    "venue": "AIMMES",
    "citation_count": 0,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:49.895303"
  },
  {
    "source": "semantic_scholar",
    "source_id": "7c019053c5028a89afb4929051c11e85e2307802",
    "title": "CalibHRM: A Feedback-Calibrated Ethical Decision Framework for Adaptive and Transparent Human Resource Management",
    "authors": [
      "Bo Wang"
    ],
    "year": 2025,
    "abstract": "In recent years, the application of artificial intelligence in Human Resource Management (HRM) has created efficiencies. Also, there are significant challenges with transparency, fairness and ethical accountability in decisionmaking. Therefore, this manuscript introduces CalibHRM, a Feedback-Calibrated Ethical Decision Framework, utilizing the Throughput Model (TPM) for ethically-relevant and adaptive HRM decision processes. Specifically, the framework is designed across five structured processes, initially the data collection and normalization of employee HR records, performance management assessments and employee feedback, Subsequently, ethical pathway encoding performs the ethical moral reasoning models based on six TPM models. Consequently, calculating the Ethical Balance Score (EBS) to effectively characterize fairness, satisfaction, bias, and accuracy. Further, a Feedback Calibration Cycle (FCC) is utilized which rehabilitates the power of ethical pathways on the basis of changes in EBS as compared to a target. Additionally, the proposed CalibHRM uses a lightweight recalibrative mechanism of adjustments within algorithm-assisted HRM decisions that continuously reinforces and aligns ethical and organizational values with decision-making. Experimental validation is provided through the assessment of HR decision dataset to demonstrate how CalibHRM strengthens ethics balance, reduces bias factors, and provides a transparent framework for interpretative explanation and decision-making for characteristics aligned with fairness-angled HRM. The proposed CalibHRM model obtained high results in terms of Mean Error (ME) and Standard Deviation Error (SDE) of 20.65 and 4.49 respectively.",
    "doi": "10.1109/IC3IT66137.2025.11341592",
    "url": "https://www.semanticscholar.org/paper/7c019053c5028a89afb4929051c11e85e2307802",
    "pdf_url": "",
    "venue": "2025 International Conference on Communication, Computer, and Information Technology (IC3IT)",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895305"
  },
  {
    "source": "semantic_scholar",
    "source_id": "13028174c6e8217845d6ae9c2fec386b06d9920e",
    "title": "Generative Artificial Intelligence and Collaboration: Exploring Religious Human-Machine Communication and Tensions in Leadership Practices",
    "authors": [
      "P. H. Cheong",
      "Liming Liu"
    ],
    "year": 2025,
    "abstract": "The adoption of generative artificial intelligence (GAI) applications has bolstered efforts toward human-machine collaboration. Given the lag in research on AI and religion, this study examines how pastors engage GAI to develop religious human-machine communication practices that constitute their leadership. Findings from in-depth interviews with pastors in the U.S. reveal that they view GAI as an idea generator, research assistant, co-author and translator. Clergy enact multiple ways to incorporate GAI communication in religious education and to enhance sermonic performances. Concurrently, pastors perceive tensions between innovation and established rites, as they contend with the authenticity and spiritual depth of GAI content while meeting the needs of their congregants amid temporal and resource challenges. This article concludes with implications for future research, AI governance and ethics.",
    "doi": "10.30658/hmc.11.9",
    "url": "https://www.semanticscholar.org/paper/13028174c6e8217845d6ae9c2fec386b06d9920e",
    "pdf_url": "",
    "venue": "Human-Machine Communication",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895306"
  },
  {
    "source": "semantic_scholar",
    "source_id": "4ee0ed72d5e3b7c574ede9a579ee55bba91f21a3",
    "title": "Role of Artificial Intelligence in Human Resource Management: A Comprehensive Review",
    "authors": [
      "Ilango Kessavane"
    ],
    "year": 2025,
    "abstract": "With the ever-evolving digitalism landscape, Artificial Intelligence (AI) is one such transformational phenomena\nin Human Resource Management (HRM). Therefore, this thorough study describes all about the\nmultidimensional role of AI in HRM focusing its applications, advantages, and obstacles. This study provides\ninsights into how AI improves recruitment, employee engagement, performance management, and talent\ndevelopment by exploring AI-enabled tools and technologies. The review also explores ethical and potential\nbiases with AI in HR. This paper offers to illustrate asset project on academic literatures and case studies in\nahead of time. Taken together, this paper adds to the literature the effect of AI on HR by providing\nrecommendations on how to leverage AI for a sustainable competitive advantage.",
    "doi": "10.35629/3795-11014144",
    "url": "https://www.semanticscholar.org/paper/4ee0ed72d5e3b7c574ede9a579ee55bba91f21a3",
    "pdf_url": "",
    "venue": "Journal of Software Engineering and Simulation",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895377"
  },
  {
    "source": "semantic_scholar",
    "source_id": "ce10bf2c192ca641b9afb0b7264f969087220ef9",
    "title": "A Leveraging Artificial Intelligence (AI) Powered Human Resource Management Strategy with Elevated Performance Metrics to Improve Talent Acquisition and Employee Engagement",
    "authors": [
      "Liu Chao",
      "Zhang Yi",
      "Zhang Jiyu",
      "Chin Yuk Fong"
    ],
    "year": 2025,
    "abstract": "The digital transformation period has turned Human Resource Management (HRM) into a strategic collaborative practice from its former administrative position. This research develops an elaborate strategy which utilizes Artificial Intelligence (AI) to transform Human Resource Management (HRM) capabilities in talent recruitment and employee engagement for contemporary enterprises. The proposed system improves both recruitment speed and workforce contentment through its integration of machine learning algorithms along with natural language processing (NLP) and reinforcement learning methods with traditional HR practices. The employment of NLP techniques during resume evaluation produced results that surpassed human screening with a measurement accuracy of 92.3%. XGBoost based predictive candidate-job fit analysis reached 89.6% accuracy in its assessment of organizational-demand and candidate-profile compatibility. The interpretation of employee feedback from different departments reached an 88.4% accuracy through LSTM models for sentiment analysis. The deployment of AI engagement monitoring technology resulted in a 34.4% average increase of employee engagement scores following implementation. The AI recommendation system received employee acceptance in 60.3% of cases according to its recorded data. The analyzed data shows that artificial intelligence offers organizations opportunities to optimize HR operations and decrease bias while making better data-based workforce decisions. Research findings indicate that artificial intelligence serves beyond being a supportive tool because it becomes a strategic partner for human capital management in digital environments.",
    "doi": "10.1109/ICFTS62006.2025.11031510",
    "url": "https://www.semanticscholar.org/paper/ce10bf2c192ca641b9afb0b7264f969087220ef9",
    "pdf_url": "",
    "venue": "2025 International Conference on Frontier Technologies and Solutions (ICFTS)",
    "citation_count": 2,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895380"
  },
  {
    "source": "semantic_scholar",
    "source_id": "eec008aba27da4bf167271b7c54e63f3262b4451",
    "title": "Artificial intelligence applications in human resource management: it is a mixed bag!",
    "authors": [
      "Antarpreet Singh",
      "Jatin Pandey"
    ],
    "year": 2025,
    "abstract": "\n \n Artificial intelligence (AI) has brought major disruptions in the new generation human resources (HR) ecosystems. The research community as well as chief human resources officers (CHROs) have been taking strong initiatives to examine the use of AI in human resource management (HRM) function, including harmonious human\u2013machine collaboration. The AI-HRM area is under-researched, and this study addresses an important research gap regarding the benefits and challenges of AI applications in HRM.\n \n \n \n The study adopts a qualitative research methodology (abductive case research) and collects data from multiple sources in three Indian companies. These organizations span diverse sectors and were at different stages of AI adoption in HRM at the time of the study. The multi-data-sources strategy helps triangulation and establishes credibility of the research.\n \n \n \n The findings provide a clear view about the benefits of AI applications in HRM, higher productivity, recruitment efficiency, adaptive learning and high-quality HR decisions. The study also underpins key challenges, including a lack of human touch, employees\u2019 loss of control over jobs and the fear of losing jobs to AI.\n \n \n \n The research provides a theoretical contribution to the growing AI-HRM literature in the context of the theory of cost economics in the context of recruitment efficiency as well as leveraging adaptive learning from the context of the multi-level organizational learning framework to improve the performance of the HR function. The research also provides significant managerial insights for CHROs recommending that they embrace humanized AI in the HRM function and institutionalize AI ethics.\n",
    "doi": "10.1108/ijppm-09-2024-0599",
    "url": "https://www.semanticscholar.org/paper/eec008aba27da4bf167271b7c54e63f3262b4451",
    "pdf_url": "",
    "venue": "International Journal of Productivity and Performance Management",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895382"
  },
  {
    "source": "semantic_scholar",
    "source_id": "b1ca638938db823e6de0412bf0f0014e4dbf7bd1",
    "title": "The impact of challenges posed by the adoption of artificial intelligence strategy for human resource managers",
    "authors": [
      "Naser Khdour",
      "R. Fenech",
      "P. Baguant",
      "Alessandra Theuma"
    ],
    "year": 2025,
    "abstract": "Artificial intelligence (AI) is revolutionizing industries across the globe and its transformative potential continues to make significant changes in human resource management (HRM) by optimizing recruitment, enhancing employee engagement, and streamlining HRM processes. The study evaluated the challenges faced while adopting AI in HRM to enhance firms\u2019 data transformation processes. The study adopted a quantitative research design and surveys for data collection. A random sampling approach was used to select 169 companies in Jordan, with 200 employees chosen. A multiple regression model (MRM) was used to assess the impact of challenges on AI adoption. The study revealed that data falsification and biased decision-making are the most pervasive challenges, while firm long-term budgeting has been facilitated. The study concludes that adopting AI in HRM results in unfair decision-making and invalidated results. Further financial maintenance is also a factor sufficiently provided by the innovative AI techniques applied in the recruitment process (Jihad & V\u00e1rallyai, 2021; Prikshat et al., 2023). The Jordanian context, which is culturally distinct from the rest of the globe, has not had its AI-related challenges well addressed. This research addresses a gap in the literature by describing the challenges faced by human resource (HR) managers in Jordan when attempting to integrate AI and by proposing a solution to these problems.",
    "doi": "10.22495/cbsrv6i3art3",
    "url": "https://www.semanticscholar.org/paper/b1ca638938db823e6de0412bf0f0014e4dbf7bd1",
    "pdf_url": "",
    "venue": "Corporate & Business Strategy Review",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895384"
  },
  {
    "source": "semantic_scholar",
    "source_id": "5541b1c103cb477ecbb53861216e64dc88fff32d",
    "title": "Transforming Human Resource Management in Healthcare: The Role of Artificial Intelligence and Industry 5.0",
    "authors": [
      "Riste Temjanovski",
      "Afrim Loku",
      "Zlatko Bezovski"
    ],
    "year": 2025,
    "abstract": "The healthcare sector is undergoing a transformative shift driven by the integration of Artificial Intelligence (AI) and the principles of Industry 5.0. This paper explores how AI is revolutionizing Human Resource Management (HRM) in healthcare, enhancing operational efficiency, optimizing recruitment and talent acquisition, and fostering employee engagement. Industry 5.0 introduces a human-centric approach that emphasizes collaboration between humans and advanced technologies, prioritizing employee well being and creating a more resilient workforce. This study also highlights the experiences of the Western Balkans, where regional adoption of AI in healthcare HRM has demonstrated significant improvements, including reduced recruitment times, enhanced workforce efficiency, and alignment with European Union digital health standards. Through a comprehensive review of current literature, case studies, and statistical data, this paper examines the benefits, challenges, and future implications of AI-driven HRM systems, with a particular focus on predictive analytics, personalized employee development, and proactive workforce planning. It further addresses critical challenges such as data privacy, ethical considerations, and the need for robust governance frameworks to ensure transparency and fairness in AI-driven decision-making. The findings reveal that successful integration of AI and Industry 5.0 principles in healthcare HRM not only enhances organizational agility but also improves public health outcomes, positioning healthcare providers to navigate the complexities of an evolving global healthcare landscape.",
    "doi": "10.46763/joe2510154t",
    "url": "https://www.semanticscholar.org/paper/5541b1c103cb477ecbb53861216e64dc88fff32d",
    "pdf_url": "",
    "venue": "JOURNAL OF ECONOMICS",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895720"
  },
  {
    "source": "semantic_scholar",
    "source_id": "ca0cef2c06f7f5f43a7bea23e2094bb4113ca3e9",
    "title": "Artificial Intelligence in Employee Well-Being and Human Resource Management",
    "authors": [
      "Himani Agarwal"
    ],
    "year": 2025,
    "abstract": "The efforts would be on how Artificial Intelligence be essential in the well-being of employees and Human Resource department in a consortium and therefore why such department should do planning to adopt Artificial Intelligence and what conceivable the role and challenges for the employees in the area of Human Resource and why it has become important to understand about Artificial Intelligence would be answered by highlighting the motivation for Artificial Intelligence, Artificial Intelligence can be adopted for any department but this paper try to emphasize on what Artificial Intelligence can contribute in Employee well-being. Artificial Intelligence is transforming Human Resource Management by enhancing employee wellness and optimizing workforce management. Artificial Intelligence-driven tools help organizations improve Recruitment, Performance Evaluation, Employee Engagement, and overall, Job satisfaction. In employee well-being, Chatbots and virtual assistants driven by Artificial Intelligence provide real-time mental health support, while sentiment analysis tools assess workplace morale by analyzing employee feedback. Wearable technology and Artificial Intelligence -driven wellness programs further aid in stress management and Work-Life balance. In Human Resource Management, Artificial Intelligence streamlines talent acquisition through automated resume screening, predictive analytics for candidate selection, and bias reduction in hiring. Artificial Intelligence -powered learning platforms personalize training programs, boosting employee skill development. Furthermore, Artificial Intelligence enhances workforce analytics by identifying trends in employee performance, absenteeism, and attrition risks, allowing Human Resource professionals to implement proactive strategies. Despite its benefits, Artificial Intelligence adoption in Human Resource Management uplift concerns about data safety, algorithmic bias, and ethical considerations in decision-making. Organizations must ensure transparency and fairness while integrating Artificial Intelligence into Human Resource processes. The upcoming era of Artificial Intelligence in Human Resource Management lies in generating a balanced approach that leverages Artificial Intelligence\u2019s analytical power while maintaining the human touch in employee interactions. By fostering a data-driven, employee-centric approach, Artificial Intelligence contributes to a more engaged, healthier, and productive workforce, ultimately leading to improved organizational performance and job satisfaction.",
    "doi": "10.63825/opjubr.2025.4.1.07",
    "url": "https://www.semanticscholar.org/paper/ca0cef2c06f7f5f43a7bea23e2094bb4113ca3e9",
    "pdf_url": "",
    "venue": "OPJU Business Review",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895732"
  },
  {
    "source": "semantic_scholar",
    "source_id": "c16a4354f2f3351869fef3ff14daf7ff76d56bdf",
    "title": "Implementation of Ethics of Using Artificial Intelligence in the Education System in Indonesia",
    "authors": [
      "Musidiansyah Otto Syaidina",
      "Rifqi Fahrudin",
      "Indah Ainun Mutiara"
    ],
    "year": 2024,
    "abstract": "The use of Artificial Intelligence (AI) in education is a rapidly evolving field with the potential to transform teaching and learning. However, its implementation brings various ethical and practical challenges that must be carefully considered. Key aspects include ensuring student data privacy, promoting fairness and inclusivity in access to technology, maintaining transparency in AI algorithms and decision-making processes, and determining the appropriate levels of human control. Furthermore, accessibility for all students, including those with special needs, must be prioritized, alongside evaluating the potential long-term effects on cognitive, social, and emotional development. Given the complexity of these issues, a thoughtful and ethical approach to integrating AI into education requires ongoing collaboration among various stakeholders, including educators, AI developers, policymakers, students, and the broader community. The goal of this collaboration is to ensure that AI is used in ways that not only improve educational outcomes but also uphold fairness, equity, and transparency. It is crucial to address concerns such as data privacy, algorithmic bias, and the potential negative effects of AI on vulnerable groups to ensure the technology serves as an inclusive tool for education. This research adopts a qualitative approach to explore the different aspects of AI in education, aiming to identify and analyze its potential benefits. By examining the implications of AI integration, the study seeks to provide valuable insights into how AI can be effectively and ethically applied in education, ensuring it enhances learning while respecting core educational values and human dignity.",
    "doi": "10.34306/bfront.v4i1.571",
    "url": "https://www.semanticscholar.org/paper/c16a4354f2f3351869fef3ff14daf7ff76d56bdf",
    "pdf_url": "",
    "venue": "Blockchain Frontier Technology",
    "citation_count": 9,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895735"
  },
  {
    "source": "semantic_scholar",
    "source_id": "4395e37d174a93948142ea2852411084cbd5551c",
    "title": "The Ethics of AI: Navigating the Moral Dilemmas of Artificial Intelligence",
    "authors": [
      "Fayyad Muhammad Hani Bayan"
    ],
    "year": 2024,
    "abstract": "The significance of ethics in artificial intelligence (AI) cannot be overstated, as it encompasses the foundational principles guiding the responsible creation, deployment, and management of AI technologies. As AI systems increasingly permeate every facet of our lives\u2014from healthcare and education to security and entertainment\u2014their decisions and actions have profound implications not only on individual rights and privacy but also on societal norms and values. Ethical considerations in AI are paramount to ensure that these technologies enhance human well-being, uphold fairness, and protect freedoms, rather than perpetuate biases, exacerbate inequalities, or undermine democratic institutions. The importance of AI ethics lies in its ability to provide a framework for navigating the complex moral dilemmas presented by AI, such as the balance between innovation and regulation, the protection of individual privacy versus the benefits of big data, and the prevention of AI misuse. By foregrounding ethical principles, stakeholders\u2014including developers, policymakers, and users\u2014can work towards the development of AI technologies that are not only technologically advanced but also socially responsible and aligned with human values. This emphasis on ethics ensures that as AI systems become more autonomous and integral to our daily lives, they do so in a manner that is transparent, accountable, and inclusive, thereby fostering trust and confidence in their widespread adoption and use.",
    "doi": "10.36571/ajsp661",
    "url": "https://www.semanticscholar.org/paper/4395e37d174a93948142ea2852411084cbd5551c",
    "pdf_url": "https://doi.org/10.36571/ajsp661",
    "venue": "Arab Journal for Scientific Publishing",
    "citation_count": 8,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895737"
  },
  {
    "source": "semantic_scholar",
    "source_id": "83d652b3a6bfc3286d7a11fae11229a59ae89c89",
    "title": "Artificial Intelligence Driven Human Resource Optimization and Institutional Performance in Nigeria Public Sector: A Study of Enugu State",
    "authors": [
      "U. Egwuagu",
      "N. Okolie",
      "Adaobi Ugwu"
    ],
    "year": 2025,
    "abstract": "This study assessed the Artificial Intelligence (AI) driven human resource optimization and institutional performance in the Nigerian public sector, focusing on Enugu State. The specific objectives were to examine the effect of AI applications on recruitment, evaluate AI-driven human resource practices on service delivery efficiency, and identify the impact of AI on service output quality. A descriptive survey research design was adopted, with a study population of 12,886. Using Yamane\u2019s formula, a sample size of 388 respondents was determined. Data were collected through structured questionnaires and analyzed using descriptive statistics (frequency distribution, percentages, mean, and standard deviation) and inferential statistics (Pearson correlation). Findings revealed that AI applications significantly improve recruitment processes, enhance service delivery efficiency, and promote quality service output through reduced errors, transparency, and resource utilization. The study concluded that AI is a transformative tool for operational efficiency in Enugu State\u2019s public sector. It recommended increased investment in AI-based recruitment systems, continuous training of HR personnel, and the establishment of clear ethical guidelines to ensure fairness, transparency, and sustainability of AI adoption. \n\u00a0",
    "doi": "10.4314/jpds.v19i4.1",
    "url": "https://www.semanticscholar.org/paper/83d652b3a6bfc3286d7a11fae11229a59ae89c89",
    "pdf_url": "",
    "venue": "Journal of Policy and Development Studies",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:49.895738"
  },
  {
    "source": "semantic_scholar",
    "source_id": "c16a4354f2f3351869fef3ff14daf7ff76d56bdf",
    "title": "Implementation of Ethics of Using Artificial Intelligence in the Education System in Indonesia",
    "authors": [
      "Musidiansyah Otto Syaidina",
      "Rifqi Fahrudin",
      "Indah Ainun Mutiara"
    ],
    "year": 2024,
    "abstract": "The use of Artificial Intelligence (AI) in education is a rapidly evolving field with the potential to transform teaching and learning. However, its implementation brings various ethical and practical challenges that must be carefully considered. Key aspects include ensuring student data privacy, promoting fairness and inclusivity in access to technology, maintaining transparency in AI algorithms and decision-making processes, and determining the appropriate levels of human control. Furthermore, accessibility for all students, including those with special needs, must be prioritized, alongside evaluating the potential long-term effects on cognitive, social, and emotional development. Given the complexity of these issues, a thoughtful and ethical approach to integrating AI into education requires ongoing collaboration among various stakeholders, including educators, AI developers, policymakers, students, and the broader community. The goal of this collaboration is to ensure that AI is used in ways that not only improve educational outcomes but also uphold fairness, equity, and transparency. It is crucial to address concerns such as data privacy, algorithmic bias, and the potential negative effects of AI on vulnerable groups to ensure the technology serves as an inclusive tool for education. This research adopts a qualitative approach to explore the different aspects of AI in education, aiming to identify and analyze its potential benefits. By examining the implications of AI integration, the study seeks to provide valuable insights into how AI can be effectively and ethically applied in education, ensuring it enhances learning while respecting core educational values and human dignity.",
    "doi": "10.34306/bfront.v4i1.571",
    "url": "https://www.semanticscholar.org/paper/c16a4354f2f3351869fef3ff14daf7ff76d56bdf",
    "pdf_url": "",
    "venue": "Blockchain Frontier Technology",
    "citation_count": 9,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972698"
  },
  {
    "source": "semantic_scholar",
    "source_id": "4395e37d174a93948142ea2852411084cbd5551c",
    "title": "The Ethics of AI: Navigating the Moral Dilemmas of Artificial Intelligence",
    "authors": [
      "Fayyad Muhammad Hani Bayan"
    ],
    "year": 2024,
    "abstract": "The significance of ethics in artificial intelligence (AI) cannot be overstated, as it encompasses the foundational principles guiding the responsible creation, deployment, and management of AI technologies. As AI systems increasingly permeate every facet of our lives\u2014from healthcare and education to security and entertainment\u2014their decisions and actions have profound implications not only on individual rights and privacy but also on societal norms and values. Ethical considerations in AI are paramount to ensure that these technologies enhance human well-being, uphold fairness, and protect freedoms, rather than perpetuate biases, exacerbate inequalities, or undermine democratic institutions. The importance of AI ethics lies in its ability to provide a framework for navigating the complex moral dilemmas presented by AI, such as the balance between innovation and regulation, the protection of individual privacy versus the benefits of big data, and the prevention of AI misuse. By foregrounding ethical principles, stakeholders\u2014including developers, policymakers, and users\u2014can work towards the development of AI technologies that are not only technologically advanced but also socially responsible and aligned with human values. This emphasis on ethics ensures that as AI systems become more autonomous and integral to our daily lives, they do so in a manner that is transparent, accountable, and inclusive, thereby fostering trust and confidence in their widespread adoption and use.",
    "doi": "10.36571/ajsp661",
    "url": "https://www.semanticscholar.org/paper/4395e37d174a93948142ea2852411084cbd5551c",
    "pdf_url": "https://doi.org/10.36571/ajsp661",
    "venue": "Arab Journal for Scientific Publishing",
    "citation_count": 8,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972707"
  },
  {
    "source": "semantic_scholar",
    "source_id": "be09def26939375435358fcb161d077c6505071b",
    "title": "Research on the Application and Optimization of Artificial Intelligence Technology in Enterprise Human Resource Management",
    "authors": [
      "Zhenxia Liu",
      "Huimin Zhou"
    ],
    "year": 2025,
    "abstract": "The rapid development of artificial intelligence (AI) technology is profoundly reshaping the paradigm of corporate human resource management. Based on industry research and practical case studies, this paper systematically explores the current application status and optimization paths of AI technology (represented by AI-generated content) in various modules of corporate human resource management. Research indicates that in the recruitment domain, AI technologies such as intelligent resume parsing and automated job description generation have significantly improved talent matching efficiency. In training and development scenarios, AI technologies like adaptive learning systems and intelligent knowledge extraction tools are driving the development of personalized training. Additionally, the performance management domain is showing a trend toward intelligent upgrades. In the compensation management module, AI-based market trend analysis and automated solution design are helping companies reduce costs and improve efficiency. The study also emphasizes that AI technology will drive structural changes in job roles and highlights the need to address risks such as algorithm explainability, data bias prevention, and privacy security. Companies must establish human-machine collaboration mechanisms, build intelligent excellence center systems, and strengthen ethical compliance frameworks to achieve a transformation from digital human capital management to the integration of humanity and technology.",
    "doi": "10.1145/3768801.3768921",
    "url": "https://www.semanticscholar.org/paper/be09def26939375435358fcb161d077c6505071b",
    "pdf_url": "",
    "venue": "Proceedings of the 2025 2nd International Conference on Big Data and Digital Management",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972709"
  },
  {
    "source": "semantic_scholar",
    "source_id": "4f881119a44f5552f9408dbd995f3c90fe3fe9b0",
    "title": "APPLICATION DOMAINS OF ARTIFICIAL INTELLIGENCE IN HUMAN RESOURCE MANAGEMENT",
    "authors": [
      "Oleksandr Mihus",
      "Agnieszka Schuetz"
    ],
    "year": 2025,
    "abstract": "The digital transformation of organizational processes has led to the widespread integration of artificial intelligence in personnel management. AI technologies have become an important component of strategic human resource development, providing opportunities for optimizing recruitment, evaluation, motivation, training, and employee retention. The use of AI in HR allows organizations to enhance the efficiency of decision-making, reduce the influence of subjective factors, and ensure evidence-based assessment of human capital. At the same time, the introduction of AI requires understanding both its capabilities and limitations, including ethical considerations, data privacy protection, transparency of algorithms, and the potential impact on employee trust. The rapid development of AI technologies makes their application in HR not only a technological but also a managerial challenge that requires systematic approaches and effective governance mechanisms.\nThe goal of this research is to identify key areas of artificial intelligence application in personnel management, analyze their advantages and risks, and determine the conditions for effective implementation in organizational practice.\nThe study is based on a systematic review of scientific sources and analytical reports of international organizations in the field of human resource management and digital innovation. Methods of structural-logical analysis, comparison, classification, and synthesis were applied to identify the main directions of AI use. Empirical examples of AI implementation in recruitment, performance management, training, and employee well-being programs were analyzed. Attention was paid to regulatory approaches, ethical frameworks, and standards that guide the responsible use of AI in HR.\nThe research identifies several core areas of AI application in personnel management. First, AI is widely used in recruitment and selection through automated candidate screening, resume analysis, and predictive assessment of job fit. These tools reduce the time and cost of hiring, although they require careful control to avoid algorithmic bias. Second, AI supports performance management by analyzing work patterns, productivity indicators, and behavioral data to provide objective feedback. Third, AI contributes to the personalization of learning and development through adaptive training platforms that adjust educational content to the individual competencies and career trajectories of employees. Fourth, AI assists in employee engagement and well-being monitoring through sentiment analysis, chatbots for internal communication, and early identification of burnout risks. Fifth, AI enhances strategic workforce planning by supporting data-driven forecasting of workforce needs and identifying competencies required for future organizational development. Despite the benefits, challenges include data protection, transparency of algorithms, and the need for strengthening ethical and regulatory frameworks to prevent discrimination and preserve employee autonomy.\nArtificial intelligence significantly expands the possibilities of personnel management, increasing the accuracy of HR decisions and enabling personalized development strategies. However, effective use of AI requires balanced integration, clear ethical standards, continuous evaluation of algorithms, and the involvement of HR professionals in shaping technology-driven human resource policies.\n\n\nFuture research should focus on developing ethical frameworks for AI in HR, assessing the impact of AI on organizational culture, exploring employee perceptions of algorithmic management, and identifying strategies for increasing trust and transparency in AI-supported HR systems.",
    "doi": "10.36690/iceaf-2025-124-125",
    "url": "https://www.semanticscholar.org/paper/4f881119a44f5552f9408dbd995f3c90fe3fe9b0",
    "pdf_url": "",
    "venue": "Book of Abstracts",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972711"
  },
  {
    "source": "semantic_scholar",
    "source_id": "6a9e34862e3183ddc7e2ae144b4a1a1da0bcbb48",
    "title": "Embedding Artificial Intelligence in Next Generation Human Resource Development Implementations",
    "authors": [
      "Arshad Matin"
    ],
    "year": 2025,
    "abstract": "A new era of data-driven, automated, and intelligent decision-making processes across a broad range of HR tasks is being ushered in by the development of artificial intelligence (AI), which is significantly changing the field of human resource management (HRM). This study examines the revolutionary effects of AI technology on HRM practices by a thorough secondary review of recent scholarly works, industry reports, and case studies. AI-powered hiring and talent acquisition platforms, predictive analytics for assessing employee performance, intelligent workforce planning, automated onboarding, and real-time employee engagement platforms are some of the major areas of disruption that have been highlighted. The study not only highlights these developments but also critically analyzes the risks and difficulties that come with integrating AI, including issues with data privacy, algorithmic and cognitive biases, lack of interpretability, transparency, and the widening digital skill gap among HR professionals. In addition to highlighting the significance of coordinating AI deployment with organizational ethics, legal compliance, and human-centric values, the study delves deeper into the strategic implications of AI in promoting agile, inclusive, and responsive HR ecosystems. As crucial avenues for long-term adoption, emerging themes like explainable AI (XAI), ethical AI governance, and AI literacy in HR are also covered. According to the findings, while AI has the ability to greatly improve HRM's operational efficiency, decision accuracy, and employee experience, long-term success depends on a methodical, morally sound, and strategically integrated strategy.",
    "doi": "10.22161/ijaems.114.17",
    "url": "https://www.semanticscholar.org/paper/6a9e34862e3183ddc7e2ae144b4a1a1da0bcbb48",
    "pdf_url": "",
    "venue": "International Journal of Advanced engineering Management and Science",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972713"
  },
  {
    "source": "semantic_scholar",
    "source_id": "83d652b3a6bfc3286d7a11fae11229a59ae89c89",
    "title": "Artificial Intelligence Driven Human Resource Optimization and Institutional Performance in Nigeria Public Sector: A Study of Enugu State",
    "authors": [
      "U. Egwuagu",
      "N. Okolie",
      "Adaobi Ugwu"
    ],
    "year": 2025,
    "abstract": "This study assessed the Artificial Intelligence (AI) driven human resource optimization and institutional performance in the Nigerian public sector, focusing on Enugu State. The specific objectives were to examine the effect of AI applications on recruitment, evaluate AI-driven human resource practices on service delivery efficiency, and identify the impact of AI on service output quality. A descriptive survey research design was adopted, with a study population of 12,886. Using Yamane\u2019s formula, a sample size of 388 respondents was determined. Data were collected through structured questionnaires and analyzed using descriptive statistics (frequency distribution, percentages, mean, and standard deviation) and inferential statistics (Pearson correlation). Findings revealed that AI applications significantly improve recruitment processes, enhance service delivery efficiency, and promote quality service output through reduced errors, transparency, and resource utilization. The study concluded that AI is a transformative tool for operational efficiency in Enugu State\u2019s public sector. It recommended increased investment in AI-based recruitment systems, continuous training of HR personnel, and the establishment of clear ethical guidelines to ensure fairness, transparency, and sustainability of AI adoption. \n\u00a0",
    "doi": "10.4314/jpds.v19i4.1",
    "url": "https://www.semanticscholar.org/paper/83d652b3a6bfc3286d7a11fae11229a59ae89c89",
    "pdf_url": "",
    "venue": "Journal of Policy and Development Studies",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972714"
  },
  {
    "source": "semantic_scholar",
    "source_id": "b09b194b05111a0d9a8ae97901aa73d92f10b0ac",
    "title": "Integration of Artificial Intelligence in Human Resource Management: Analyzing Opportunities, Challenges, and Human-AI Collaboration",
    "authors": [
      "Adil Benabou",
      "Fatima Touhami"
    ],
    "year": 2025,
    "abstract": "This study explored the role of Artificial Intelligence (AI) in transforming Human Resource Management (HRM). By systematically reviewing a wide range of literature, this study highlighted both the potential benefits and challenges associated with AI in HRM. From an initial collection of 983 articles, we focused on 91 key studies that provided in-depth insights into AI\u2019s impact on HR functions such as recruitment, employee integration, career management, payroll, and compensation. While AI has the capacity to significantly enhance these functions, its integration also raises important issues, including ethical concerns, biases, data privacy, and the need for extensive employee training and reskilling. This review underscores the importance of balancing technological innovation with ethical considerations and employee well-being. By offering practical insights and suggesting directions for future research, this study aimed to assist HR practitioners and researchers in effectively leveraging AI to improve organizational performance and employee satisfaction.",
    "doi": "10.24191/mar.v24i01-15",
    "url": "https://www.semanticscholar.org/paper/b09b194b05111a0d9a8ae97901aa73d92f10b0ac",
    "pdf_url": "https://doi.org/10.24191/mar.v24i01-15",
    "venue": "Management and Accounting Review",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972716"
  },
  {
    "source": "semantic_scholar",
    "source_id": "9a5ab3075b2a9b34037a9097631985875f604e09",
    "title": "Artificial Intelligence Technologies in Human Resource Management: Social Experience of Implementation and Use",
    "authors": [
      "Larisa Sergeevna Koval'zhina",
      "Anna Anatol'evna Orlova"
    ],
    "year": 2025,
    "abstract": "The article discusses the social issues of implementing and using artificial intelligence technologies in human resource management of organizations and enterprises. It addresses experts' expectations and the potential for the adoption of artificial intelligence, as well as the barriers to the implementation of advanced AI functions, which include both technical problems and social ones (the need for a change in corporate culture). The theoretical and methodological foundations of the research are based on a sociological approach that views technologies not as neutral tools but as social artifacts embedded in existing social structures, cultural norms, and organizational practices. The aim of this research is to identify and classify the social problems of implementing and using AI in HR, as well as to assess the current state and prospects of using artificial intelligence technologies in personnel management in companies in the Tyumen region. A fragment of the results of an expert survey of HR specialists and heads of HR departments of companies of various sizes and industry affiliations, conducted in 2024 and 2025 in the Tyumen region, is presented. The analysis revealed that the existing mechanisms of both self-regulation (corporate policies, professional codes) and institutional regulation (legislation) are underdeveloped, fragmentary, and often reactive. They fail to keep pace with the dynamics of technological changes and do not always adequately consider the specifics of the social experiences of various actors involved in digital HR practices. Four main clusters of social problems are identified: algorithmic bias and the reproduction of social inequality; dehumanization of HR processes and erosion of the organization's social capital; violation of privacy and the creation of a \"digital copy\"; transformation of the HR manager profession and the problem of distributed responsibility. Based on the analysis of the use of AI technologies in personnel management of organizations in the Tyumen region and the study of theoretical concepts of self-regulation and institutional regulation, an integrative model of \"Balanced Institutionalization of AI in HR\" is proposed. The principles of the model include: the principle of contextual embeddedness and human sovereignty; the principle of algorithmic transparency and accountability; the principle of preventive assessment of social risks; and the principle of pluralistic regulation.",
    "doi": "10.25136/2409-7144.2025.12.77472",
    "url": "https://www.semanticscholar.org/paper/9a5ab3075b2a9b34037a9097631985875f604e09",
    "pdf_url": "",
    "venue": "\u0421\u043e\u0446\u0438\u043e\u0434\u0438\u043d\u0430\u043c\u0438\u043a\u0430",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972717"
  },
  {
    "source": "semantic_scholar",
    "source_id": "a76b2e0289aa510b55f8ddae7487cea1f9f4c7ed",
    "title": "Functional Architectonics of Artificial Intelligence in the Context of Digitalized Human Resource Management",
    "authors": [
      "Volodymyr Kuchynskyi",
      "Iegor O. Vozniuk"
    ],
    "year": 2025,
    "abstract": "The article develops a conception for the structure of artificial intelligence in digitalized human resource management, based on a historical and evolutionary analysis of the development of intelligent systems, from the earliest ideas of machine thinking to modern generative models. The stages of the evolutionary dynamics of artificial intelligence, which combine periods of growth and decline resulting from discrepancies between the expectations of the scientific community and technological capabilities, are described. It is demonstrated that each new stage of development contributed to the formation of models and directions capable of integrating with other digital tools and expanding the scope of their practical application. The theoretical and methodological foundations for the use of artificial intelligence in the field of digitalized human resource management, as a key business process of a modern enterprise, are developed. The rationale for implementing a hybrid (neuro-symbolic) approach to model training, which combines machine learning with symbolic knowledge and rule-based systems, has been substantiated. This approach allows for greater transparency and control over algorithmic decisions, reduces the risks of bias, and ensures the efficiency of intelligent algorithms. Based on this, practical functional areas of artificial intelligence corresponding to the multifaceted nature of HR processes have been identified. The study also presents arguments for integrating fundamental and applied functional areas into a unified artificial intelligence framework in human resource management, addressing the challenges of digital transformation. The proposed framework features a flexible architecture that facilitates scalable HR process automation, personalized personnel decisions, and enhanced productivity. Practical results from leading global companies confirm the efficiency of applying AI in digitalized human resource management, and the developed conception can serve as a basis for creating scalable digital ecosystems in the HR field.",
    "doi": "10.32983/2222-4459-2025-9-367-375",
    "url": "https://www.semanticscholar.org/paper/a76b2e0289aa510b55f8ddae7487cea1f9f4c7ed",
    "pdf_url": "",
    "venue": "Business Inform",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972719"
  },
  {
    "source": "semantic_scholar",
    "source_id": "e0b0a828c77a8e61ed546c91e6f526fc94c7892d",
    "title": "REINVITING HUMAN RESOURCE MANAGEMENT IN THE AGE OF ARTIFICIAL INTELLIGENCE",
    "authors": [
      "Afzil Ramadian",
      "Ismartaya",
      "Syakira Fadla",
      "Esih Nurasiah Zamil"
    ],
    "year": 2025,
    "abstract": "This study conducts a systematic literature review and bibliometric analysis to map the intellectual structure and thematic evolution of Artificial Intelligence (AI) and Machine Learning (ML) in Human Resource Management (HRM), with a focus on sustainability implications in business. Using PRISMA 2020, 62 articles were selected from Scopus-indexed publications. Bibliometric analysis via VOS viewer reveals three dominant thematic clusters: technical foundations of AI/ML, HRM-oriented applications, and data-driven decision-support systems. Key findings identify India, China, Malaysia, and the United States as leading contributors, with strong South\u2013South collaborations especially between India and Malaysia highlighting emerging innovation pathways in plural economies. The results demonstrate that AI\u2013HRM synergy significantly enhances business sustainability by enabling data-driven strategic decisions, optimizing resource allocation, and supporting personalized and inclusive HR practices. However, ethical risks such as algorithmic bias pose challenges to sustainable implementation. The study recommends\u00a0transparent AI governance, regular algorithmic audits, and Human-in-the-Loop (HITL) protocols\u00a0to ensure that AI integration strengthens rather than undermines human-centric and sustainable HRM. These insights provide a foundation for policymakers and organizations pursuing responsible digital transformation in dynamic regions such as Southeast Asia.",
    "doi": "10.30997/jvs.v11i2.22285",
    "url": "https://www.semanticscholar.org/paper/e0b0a828c77a8e61ed546c91e6f526fc94c7892d",
    "pdf_url": "",
    "venue": "JURNAL VISIONIDA",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972721"
  },
  {
    "source": "semantic_scholar",
    "source_id": "b7e93297e403a221913e20b4e187a8f2d2d89210",
    "title": "The integration of artificial intelligence in human resource management practices: A review of literature and bibliometric",
    "authors": [
      "Raja Chakra",
      "Ayoub Oulamine",
      "Hicham Bahida",
      "Rachid Ziky",
      "Ayoub Massiki"
    ],
    "year": 2025,
    "abstract": "This research explores the integration of artificial intelligence in human resource management (HRM) practices through a bibliometric review of the literature. It is based on the analysis of multiple articles from academic databases, with the aim of examining AI advances in this field. The objective is to understand its impact, identify the benefits it brings to HRM, and analyze the challenges associated with its deployment based on the collected data from Scopus. We used data collected through the SCOPUS database. Using a bibliometric journal approach as the research methodology, we aim to provide an in-depth exploration and understanding of the findings and results found in recent literature on the impact of AI on HRM. The results show that the annual production of research in this field has increased steadily from 2018 to 2024. The most relevant contributions have focused on the study of artificial intelligence and human resources. AI has become an essential tool in organizations\u2019 efforts to promote diversity and inclusion within their workforce. One area where AI has proven effective is in human resource decision-making. AI offers a powerful solution to address biases because it can analyze data impartially and objectively, without being influenced by bias.",
    "doi": "10.53894/ijirss.v8i5.9244",
    "url": "https://www.semanticscholar.org/paper/b7e93297e403a221913e20b4e187a8f2d2d89210",
    "pdf_url": "",
    "venue": "International journal of innovative research and scientific studies",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972722"
  },
  {
    "source": "semantic_scholar",
    "source_id": "a16d798aad13ac0999d717e61ed3dd3b16ec09b4",
    "title": "The Role of Artificial Intelligence in Designing Future Human Resource Management Strategies",
    "authors": [
      "Bala Bharathi T",
      "R. R. K. V"
    ],
    "year": 2025,
    "abstract": "Artificial Intelligence (AI) is revolutionizing Human Resource Management (HRM) by integrating automation, predictive Analytics, and data-driven decision-making. Organizations are increasingly adopting AI-powered solutions to enhance talent acquisition, employee engagement, performance management, and workforce planning. AI-driven recruitment systems streamline hiring by reducing biases, improving candidate-job matching, and expediting the selection process. Additionally, chatbots and virtual assistants are transforming onboarding, training, and employee support by providing real-time assistance and personalized learning experiences. Beyond recruitment, AI plays a crucial role in workforce analytics, helping HR professionals predict attrition risks, optimize talent management, and enhance employee well-being. Machine learning algorithms and sentiment analysis enable organizations to proactively address workforce challenges, implement effective retention strategies, and cultivate a positive workplace culture. Moreover, AI enhances HR operations by automating payroll processing, benefits administration, and compliance tracking, reducing manual errors and ensuring regulatory adherence. This paper covers the evolving role of AI in shaping future HRM strategies, highlighting the impact of AI on HR, opportunities, and challenges. It also emphasizes the significance of a balanced AI-human approach, where AI augments HR capabilities without replacing human judgment. By integrating AI ethically and strategically, organizations can create an agile, data-driven, and employee-centric HRM framework that aligns with future workforce needs.",
    "doi": "10.63328/ijrdes-v7ri3p10",
    "url": "https://www.semanticscholar.org/paper/a16d798aad13ac0999d717e61ed3dd3b16ec09b4",
    "pdf_url": "",
    "venue": "International Journal of Research and Development in Engineering Science",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972724"
  },
  {
    "source": "semantic_scholar",
    "source_id": "b3cbeaec41527d4499ad4e1e533c6c4fc25e00fb",
    "title": "A Preliminary Review of Artificial Intelligence Adoption in Human Resource Management: Evidence from Asia",
    "authors": [
      "C. Fung",
      "Suman Tiwari",
      "Kevin Jan Sian Voon"
    ],
    "year": 2025,
    "abstract": "Artificial intelligence (AI) integration into human resource management\n(HRM) has gained considerable momentum in Asia, driven by the\nregion's rapid digital transformation and dynamic economic growth.\nDespite increasing scholarly attention, existing literature often adopts\nfragmented perspectives on AI applications across different HRM\nfunctions. This review paper aims to identify trends, challenges, and\noutcomes of AI adoption in HRM functions, considering the sociocultural and economic diversity of Asian countries. It investigates the\nadoption of AI, its application, and its implications across key HRM\nfunctions, including recruitment, training and development,\nperformance appraisal, and employee engagement. This paper adopts a\nsystematic review methodology, synthesising peer-reviewed indexed\njournal articles published from 2020 to 2024. Thematic analysis reveals\nthat AI technologies have enhanced operational efficiency, decisionmaking processes, and personalised employee experiences. However,\ncritical concerns persist regarding data privacy, algorithmic bias, and\nemployee acceptance. Additionally, the uneven pace of AI adoption\nacross industries and countries highlights the influence of regulatory\nframeworks, organisational readiness, and technological infrastructure.\nThis review contributes to the growing body of knowledge by offering\na region-specific perspective on AI integration in HRM, addressing the\nunique complexities of the Asian context. The findings offer practical\ninsights for HR practitioners and policymakers to navigate AI\nimplementation while fostering ethical and inclusive AI adoption. The\npaper also identifies key research gaps, calling for future research to\nexamine the long-term impacts of AI-driven HRM practices and their\nimplications for workforce dynamics in the evolving digital landscape",
    "doi": "10.24191/ijsms.v10i1.24222",
    "url": "https://www.semanticscholar.org/paper/b3cbeaec41527d4499ad4e1e533c6c4fc25e00fb",
    "pdf_url": "",
    "venue": "International Journal of Service Management and Sustainability",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972725"
  },
  {
    "source": "semantic_scholar",
    "source_id": "eef2fb5dc309e007557f5d493e782676041b3bd8",
    "title": "Ethics of Artificial Intelligence(AI)",
    "authors": [
      "Pragya K. K"
    ],
    "year": 2024,
    "abstract": "In today's research and development, artificial intelligence (AI) ethics are a complex and urgent issue. Concerns about artificial intelligence (AI) systems' possible effects on people, communities, and the larger global environment are raised as these systems are incorporated into more and more facets of society. This study examines the ethical implications of artificial intelligence (AI), looking at topics including privacy, fairness, accountability, transparency, and the possibility of prejudice and discrimination in AI algorithms and decision-making processes. The study endeavours to contribute to the establishment of frameworks and rules that encourage the responsible and ethical use of AI technologies, guaranteeing their conformity with society values and the preservation of human rights, by critically assessing these ethical issues. Keywords:-AI ethics , artificial intelligence, ethics, machine ethics, robotics, challenges.",
    "doi": "10.55041/ijsrem33762",
    "url": "https://www.semanticscholar.org/paper/eef2fb5dc309e007557f5d493e782676041b3bd8",
    "pdf_url": "https://ijsrem.com/download/ethics-of-artificial-intelligenceai/?wpdmdl=33545&refresh=66597edc5f1111717141212",
    "venue": "INTERANTIONAL JOURNAL OF SCIENTIFIC RESEARCH IN ENGINEERING AND MANAGEMENT",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972727"
  },
  {
    "source": "semantic_scholar",
    "source_id": "0a0e2015084e68127dd6750d5d0aaa297e5b2f0d",
    "title": "Artificial Intelligence, Bias, and Ethics",
    "authors": [
      "Aylin Caliskan"
    ],
    "year": 2023,
    "abstract": "Although ChatGPT attempts to mitigate bias, when instructed to translate the gender-neutral Turkish sentences \u201cO bir doktor. O bir hem\u015fire\u201d to English, the outcome is biased: \u201cHe is a doctor. She is a nurse.\u201d In 2016, we have demonstrated that language representations trained via unsupervised learning automatically embed implicit biases documented in social cognition through the statistical regularities in language corpora. Evaluating embedding associations in language, vision, and multi-modal language-vision models reveals that large-scale sociocultural data is a source of implicit human biases regarding gender, race or ethnicity, skin color, ability, age, sexuality, religion, social class, and intersectional associations. The study of gender bias in language, vision, language-vision, and generative AI has highlighted the sexualization of women and girls in AI, while easily accessible generative AI models such as text-to-image generators amplify bias at scale. As AI increasingly automates tasks that determine life\u2019s outcomes and opportunities, the ethics of AI bias has significant implications for human cognition, society, justice, and the future of AI. Thus, it is necessary to advance our understanding of the depth, prevalence, and complexities of bias in AI to mitigate it both in machines and society.",
    "doi": "10.24963/ijcai.2023/799",
    "url": "https://www.semanticscholar.org/paper/0a0e2015084e68127dd6750d5d0aaa297e5b2f0d",
    "pdf_url": "https://www.ijcai.org/proceedings/2023/0799.pdf",
    "venue": "International Joint Conference on Artificial Intelligence",
    "citation_count": 24,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:53.972728"
  },
  {
    "source": "semantic_scholar",
    "source_id": "6d6db2763b8b38d9b42cd3e5a98b025fba43f3fb",
    "title": "Early warning of complex climate risk with integrated artificial intelligence",
    "authors": [
      "M. Reichstein",
      "V. Benson",
      "Jan Blunk",
      "G. Camps-Valls",
      "F. Creutzig",
      "C. Fearnley",
      "Boran Han",
      "K. Kornhuber",
      "Nasim Rahaman",
      "Bernhard Sch\u00f6lkopf",
      "Josep Tarraga",
      "R. Vinuesa",
      "Karen Dall",
      "Joachim Denzler",
      "Dorothea Frank",
      "Giulia Martini",
      "Naomi Nganga",
      "Danielle C. Maddix",
      "Kommy Weldemariam"
    ],
    "year": 2025,
    "abstract": "As climate change accelerates, human societies face growing exposure to disasters and stress, highlighting the urgent need for effective early warning systems (EWS). These systems monitor, assess, and communicate risks to support resilience and sustainable development, but challenges remain in hazard forecasting, risk communication, and decision-making. This perspective explores the transformative potential of integrated Artificial Intelligence (AI) modeling. We highlight the role of AI in developing multi-hazard EWSs that integrate Meteorological and Geospatial foundation models (FMs) for impact prediction. A user-centric approach with intuitive interfaces and community feedback is emphasized to improve crisis management. To address climate risk complexity, we advocate for causal AI models to avoid spurious predictions and stress the need for responsible AI practices. We highlight the FATES (Fairness, Accountability, Transparency, Ethics, and Sustainability) principles as essential for equitable and trustworthy AI-based Early Warning Systems for all. We further advocate for decadal EWSs, leveraging climate ensembles and generative methods to enable long-term, spatially resolved forecasts for proactive climate adaptation. In the era of climate change, human societies face growing exposure to disasters and complex climate risks. This perspective explores the transformative potential of integrated Artificial Intelligence in developing multi-hazard Early Warning Systems for all.",
    "doi": "10.1038/s41467-025-57640-w",
    "url": "https://www.semanticscholar.org/paper/6d6db2763b8b38d9b42cd3e5a98b025fba43f3fb",
    "pdf_url": "https://doi.org/10.1038/s41467-025-57640-w",
    "venue": "Nature Communications",
    "citation_count": 44,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:53.972731"
  },
  {
    "source": "semantic_scholar",
    "source_id": "876ab281803d388d2608d9db3dcbea513c538639",
    "title": "UNMASKING BIAS: A CRITICAL REVIEW OF AI IN HUMAN RESOURCE MANAGEMENT",
    "authors": [
      "Kumarakulasingam Brasanan"
    ],
    "year": 2024,
    "abstract": "Using Artificial Intelligence (AI) more in Human Resource Management (HRM) can bring many advantages such as making processes faster, more fair, and able to handle larger tasks effectively. However, this change in technology has also brought some new problems, especially biased algorithms. This review looks at how bias appears in AI-based HR systems, especially in hiring, performance reviews, and workforce data analysis. Utilizing inquire about from diverse areas, real-life illustrations, and speculations, this paper looks at how inclination is built into information, how calculations are planned, and how they are utilized. Imperative illustrations, like Amazon\u2019s stopped AI contracting instrument and facial examination utilized by HireVue, appear how these innovations can proceed to make shamefulness based on gender, race, and financial status. The review points out a few reasons for unfairness, such as training data that doesn\u2019t include everyone, unclear algorithms, and no responsibility when putting systems into use. It also looks closely at current laws and ethical rules, pointing out that they are not enough to deal with the complicated issues of bias in artificial intelligence in human resources management.",
    "doi": "10.26480/mjhrm.01.2025.53.56",
    "url": "https://www.semanticscholar.org/paper/876ab281803d388d2608d9db3dcbea513c538639",
    "pdf_url": "",
    "venue": "Malaysian Journal Of Human Resources Management",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972732"
  },
  {
    "source": "semantic_scholar",
    "source_id": "37dc3e66b662cfc71ec72aeabcc72ce239216157",
    "title": "Artificial Intelligence in Human Resource Management: A Systematic Review of Drivers, Challenges, and Future Pathways",
    "authors": [
      "Venkatesh Thulasidoss",
      "Mohamed Alfaz",
      "Tamang Min"
    ],
    "year": 2025,
    "abstract": "Background: In developed countries, recruitment agencies are preferring Artificial Intelligence (AI) technologies in hiring human resources in companies. AI integration has become essential in HRM. AI supports multiple functions such as finding the right employees, setting management goals, maintaining institutional knowledge, and modernising work styles.\nObjectives: The study aims to examine the role and benefits of AI in HRM, assess the challenges, ethical concerns, and human\u2013AI collaboration, and explore its practical applications and future directions.\nMethod: The research applies literature review as methodology to collect evidences regarding the roles and challenges of AI in the recruitment process through the perspective of the Diffusion of Innovation theory.\nFindings: Findings shows that AI systems show enhanced efficiency throughout candidate screening processes and skills evaluation however human supervision stands essential to deal with biases and maintain fair recruitment procedures.\nConclusion: The research concludes that future recruitment will evolve into human-AI partnership models instead of machine-only automation while proposing industry standards and ethical frameworks and regulatory policies for implementation-guidance.\nNovelty of the study: Unlike previous research, this paper synthesises how AI development is transforming human resource recruitment while also highlighting the barriers that hinder its effective implementation. A key contribution of this review is the introduction of the concept of human-centered AI in HRM, developed in line with Rogers\u2019 Diffusion of Innovation theory.",
    "doi": "10.3126/njmr.v8i4.82368",
    "url": "https://www.semanticscholar.org/paper/37dc3e66b662cfc71ec72aeabcc72ce239216157",
    "pdf_url": "",
    "venue": "Nepal Journal of Multidisciplinary Research",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972733"
  },
  {
    "source": "semantic_scholar",
    "source_id": "7502eebcb1c0d3fcfd2c06c4cb63faa1a75022f7",
    "title": "Artificial Intelligence and its ability to reduce recruitment bias",
    "authors": [
      "Zaker Ul Oman",
      "A. Siddiqua",
      "Ruqia Noorain"
    ],
    "year": 2024,
    "abstract": "Artificial intelligence is transforming the landscape of Human Resource Management (HRM), altering conventional methods and elevating the recruitment process for companies. The conventional approach to hiring can be incredibly time-intensive, often stretching over several weeks to sift through all applications. This process can be daunting for recruiters, who are tasked with reviewing numerous resumes. AI steps in to streamline this process by rapidly sifting through a large number of applications, identifying the most suitable candidates, and providing concise overviews of their qualifications. This not only saves recruiters time but also allows them to concentrate on improving the candidate experience and attracting top talent. AI operates around the clock, ensuring the recruitment process remains active and effective even when recruiters are not on duty. Moreover, AI can help mitigate bias, when utilized correctly, it can facilitate more equitable hiring decisions by focusing on relevant skills and experiences rather than personal biases. This article explores the multifaceted role of AI in mitigating recruitment bias, AI algorithms use objective data and set criteria to reduce unconscious bias during initial screening. This approach helps ensure that job seekers are evaluated based on qualifications and merit, rather than personal characteristics.",
    "doi": "10.30574/wjarr.2024.24.1.3054",
    "url": "https://www.semanticscholar.org/paper/7502eebcb1c0d3fcfd2c06c4cb63faa1a75022f7",
    "pdf_url": "",
    "venue": "World Journal of Advanced Research and Reviews",
    "citation_count": 6,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972735"
  },
  {
    "source": "semantic_scholar",
    "source_id": "2d964d26bde42ca53650724b4bdfd23fd33952d6",
    "title": "Towards an Environmental Ethics of Artificial Intelligence",
    "authors": [
      "Nynke van Uffelen",
      "Lode Lauwaert",
      "Mark Coeckelbergh",
      "O. Kudina"
    ],
    "year": 2024,
    "abstract": "In recent years, much research has been dedicated to uncovering the environmental impact of Artificial Intelligence (AI), showing that training and deploying AI systems require large amounts of energy and resources, and the outcomes of AI may lead to decisions and actions that may negatively impact the environment. This new knowledge raises new ethical questions, such as: When is it (un)justifiable to develop an AI system, and how to make design choices, considering its environmental impact? However, so far, the environmental impact of AI has largely escaped ethical scrutiny, as AI ethics tends to focus strongly on themes such as transparency, privacy, safety, responsibility, and bias. Considering the environmental impact of AI from an ethical perspective expands the scope of AI ethics beyond an anthropocentric focus towards including more-than-human actors such as animals and ecosystems. This paper explores the ethical implications of the environmental impact of AI for designing AI systems by drawing on environmental justice literature, in which three categories of justice are distinguished, referring to three elements that can be unjust: the distribution of benefits and burdens (distributive justice), decision-making procedures (procedural justice), and institutionalized social norms (justice as recognition). Based on these tenets of justice, we outline criteria for developing environmentally just AI systems, given their ecological impact.",
    "doi": "10.48550/arXiv.2501.10390",
    "url": "https://www.semanticscholar.org/paper/2d964d26bde42ca53650724b4bdfd23fd33952d6",
    "pdf_url": "",
    "venue": "arXiv.org",
    "citation_count": 5,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:53.972737"
  },
  {
    "source": "semantic_scholar",
    "source_id": "45ae12c71ea4908ce9733f0714655d1d2e76fb54",
    "title": "The Ethics of Artificial Intelligence: Examining the Ethical Considerations Surrounding the Development and Use of AI",
    "authors": [
      "Aisha Zahid Huriye"
    ],
    "year": 2023,
    "abstract": "Aim: AI systems can be complex and opaque, making it challenging to understand how they make decisions. This raises concerns about fairness and accountability, as individuals may not understand the factors that influence the decisions made by AI systems. The aim of this study was to examine the ethical considerations surrounding the development and use of AI. \nMethods: The study adopted a desktop research design. Relevant books reference and journal articles for the study were identified using Google Scholar. The inclusion criteria entailed materials that were related to the ethics of artificial intelligence. \nResults: The study found out that bias, privacy, accountability and transparency are the main ethical concerns that surround the development and use of AI technology in developed countries. Additionally, the studies emphasized the need for collaboration between stakeholders, including policymakers, researchers, and local communities, to ensure that ethical guidelines are developed and implemented. In African countries, the studies highlighted the need for a nuanced understanding of the cultural, political, and economic context of the region when considering ethical AI. Issues related to bias, data privacy, and the impact of AI on the labor market were identified as important ethical considerations in the region. \nConclusion: This study emphasizes the need for a human-centered approach that prioritizes the needs and values of local communities, as well as greater engagement with local stakeholders in the development of ethical guidelines. \nRecommendation: The study recommend development and implementation of ethical guidelines for AI. Policymakers, developers, and researchers should work together to develop and implement ethical guidelines for AI systems. These guidelines should address issues related to bias, transparency, accountability, and privacy, and should be grounded in a commitment to promoting human well-being and social good.",
    "doi": "10.58425/ajt.v2i1.142",
    "url": "https://www.semanticscholar.org/paper/45ae12c71ea4908ce9733f0714655d1d2e76fb54",
    "pdf_url": "https://gprjournals.org/journals/index.php/AJT/article/download/142/177",
    "venue": "American Journal of Technology",
    "citation_count": 57,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972738"
  },
  {
    "source": "semantic_scholar",
    "source_id": "b3fdf3e9cb0a0d0794913ab31376fdb9113db252",
    "title": "Addressing Bias and Fairness Issues in Artificial Intelligence",
    "authors": [
      "Pragya Gupta"
    ],
    "year": 2023,
    "abstract": null,
    "doi": null,
    "url": "https://www.semanticscholar.org/paper/b3fdf3e9cb0a0d0794913ab31376fdb9113db252",
    "pdf_url": "",
    "venue": "",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972740"
  },
  {
    "source": "semantic_scholar",
    "source_id": "e579660ed595fbb19c995ac03eb6ea762b2b4d22",
    "title": "A study of artificial intelligence and its role in human resource management",
    "authors": [
      "Jayaraj Gaddihalli",
      "Arif Shaikh",
      "Rashmi Harti"
    ],
    "year": 2024,
    "abstract": "In this present scenario requests for the human assets as an obligatory resource in arrange to progress the organizational execution. The organizations need to endeavour for embracing the imaginative HR hones to move forward their execution and be diverse in the competition. In close future, HRM is moving from the conventional way of HR hones to more advance like computerization, increased insights, mechanical autonomy and AI. Artificial intelligence is already proving to change our lives. From mechanization of ordinary and time-consuming assignments, to the expansion and enhancement of human capabilities, Computer based program has changed the way work. This may not be a fair time for HR, but it can be a dangerous time that needs to be reformed and supported. Today\u2019s HR professionals both human and technology work to create a simple and intuitive workplace. performance.",
    "doi": "10.1051/itmconf/20246801035",
    "url": "https://www.semanticscholar.org/paper/e579660ed595fbb19c995ac03eb6ea762b2b4d22",
    "pdf_url": "https://doi.org/10.1051/itmconf/20246801035",
    "venue": "ITM Web of Conferences",
    "citation_count": 24,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972742"
  },
  {
    "source": "semantic_scholar",
    "source_id": "2173ac6dd528032446b0b55f15571a8dd8b20e5c",
    "title": "Artificial intelligence ethics by design. Evaluating public perception on the importance of ethical design principles of artificial intelligence",
    "authors": [
      "Kimon Kieslich",
      "Birte Keller",
      "C. Starke"
    ],
    "year": 2021,
    "abstract": "Despite the immense societal importance of ethically designing artificial intelligence, little research on the public perceptions of ethical artificial intelligence principles exists. This becomes even more striking when considering that ethical artificial intelligence development has the aim to be human-centric and of benefit for the whole society. In this study, we investigate how ethical principles (explainability, fairness, security, accountability, accuracy, privacy, and machine autonomy) are weighted in comparison to each other. This is especially important, since simultaneously considering ethical principles is not only costly, but sometimes even impossible, as developers must make specific trade-off decisions. In this paper, we give first answers on the relative importance of ethical principles given a specific use case\u2014the use of artificial intelligence in tax fraud detection. The results of a large conjoint survey ( n = 1099 ) suggest that, by and large, German respondents evaluate the ethical principles as equally important. However, subsequent cluster analysis shows that different preference models for ethically designed systems exist among the German population. These clusters substantially differ not only in the preferred ethical principles but also in the importance levels of the principles themselves. We further describe how these groups are constituted in terms of sociodemographics as well as opinions on artificial intelligence. Societal implications, as well as design challenges, are discussed.",
    "doi": "10.1177/20539517221092956",
    "url": "https://www.semanticscholar.org/paper/2173ac6dd528032446b0b55f15571a8dd8b20e5c",
    "pdf_url": "https://journals.sagepub.com/doi/pdf/10.1177/20539517221092956",
    "venue": "Big Data & Society",
    "citation_count": 124,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:53.972744"
  },
  {
    "source": "semantic_scholar",
    "source_id": "32aec099ac576f7eedeeaaf9f8581df8a465a0fd",
    "title": "Unraveling the Ethical Conundrum of Artificial Intelligence: A Synthesis of Literature and Case Studies",
    "authors": [
      "Pavan Kumar Reddy Poli",
      "Sushma Pamidi",
      "Shravan Kumar Reddy Poli"
    ],
    "year": 2024,
    "abstract": null,
    "doi": "10.1007/s41133-024-00077-5",
    "url": "https://www.semanticscholar.org/paper/32aec099ac576f7eedeeaaf9f8581df8a465a0fd",
    "pdf_url": "",
    "venue": "Augmented Human Research",
    "citation_count": 9,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972745"
  },
  {
    "source": "semantic_scholar",
    "source_id": "3f7f02a9b4f4f240f74fa43922dcebcac5c93b64",
    "title": "Fairness and Ethics in Artificial Intelligence-Based Medical Imagining",
    "authors": [
      "Subarna Tripathi",
      "T. Musiolik"
    ],
    "year": 2022,
    "abstract": "Artificial intelligence has a huge array of current and potential applications in healthcare and medicine. Ethical issues arising due to algorithmic biases are one of the greatest challenges faced in the generalizability of AI models today. The authors address safety and regulatory barriers that impede data sharing in medicine as well as potential changes to existing techniques and frameworks that might allow ethical data sharing for machine learning. With these developments in view, they also present different algorithmic models that are being used to develop machine learning-based medical systems that will potentially evolve to be free of the sample, annotator, and temporal bias. These AI-based medical imaging models will then be completely implemented in healthcare facilities and institutions all around the world, even in the remotest areas, making diagnosis and patient care both cheaper and freely accessible.",
    "doi": "10.4018/978-1-7998-7888-9.ch004",
    "url": "https://www.semanticscholar.org/paper/3f7f02a9b4f4f240f74fa43922dcebcac5c93b64",
    "pdf_url": "",
    "venue": "Ethical Implications of Reshaping Healthcare With Emerging Technologies",
    "citation_count": 16,
    "fields_of_study": [
      "Psychology"
    ],
    "retrieved_at": "2026-02-02T16:57:53.972747"
  },
  {
    "source": "semantic_scholar",
    "source_id": "b47f132fd09632cfc986a99caa70c8f2f958e88d",
    "title": "Connecting the Dots in Trustworthy Artificial Intelligence: From AI Principles, Ethics, and Key Requirements to Responsible AI Systems and Regulation",
    "authors": [
      "Natalia D\u00edaz Rodr\u00edguez",
      "J. Ser",
      "Mark Coeckelbergh",
      "Marcos L'opez de Prado",
      "E. Herrera-Viedma",
      "Francisco Herrera"
    ],
    "year": 2023,
    "abstract": "Trustworthy Artificial Intelligence (AI) is based on seven technical requirements sustained over three main pillars that should be met throughout the system's entire life cycle: it should be (1) lawful, (2) ethical, and (3) robust, both from a technical and a social perspective. However, attaining truly trustworthy AI concerns a wider vision that comprises the trustworthiness of all processes and actors that are part of the system's life cycle, and considers previous aspects from different lenses. A more holistic vision contemplates four essential axes: the global principles for ethical use and development of AI-based systems, a philosophical take on AI ethics, a risk-based approach to AI regulation, and the mentioned pillars and requirements. The seven requirements (human agency and oversight; robustness and safety; privacy and data governance; transparency; diversity, non-discrimination and fairness; societal and environmental wellbeing; and accountability) are analyzed from a triple perspective: What each requirement for trustworthy AI is, Why it is needed, and How each requirement can be implemented in practice. On the other hand, a practical approach to implement trustworthy AI systems allows defining the concept of responsibility of AI-based systems facing the law, through a given auditing process. Therefore, a responsible AI system is the resulting notion we introduce in this work, and a concept of utmost necessity that can be realized through auditing processes, subject to the challenges posed by the use of regulatory sandboxes. Our multidisciplinary vision of trustworthy AI culminates in a debate on the diverging views published lately about the future of AI. Our reflections in this matter conclude that regulation is a key for reaching a consensus among these views, and that trustworthy and responsible AI systems will be crucial for the present and future of our society.",
    "doi": "10.48550/arXiv.2305.02231",
    "url": "https://www.semanticscholar.org/paper/b47f132fd09632cfc986a99caa70c8f2f958e88d",
    "pdf_url": "http://arxiv.org/pdf/2305.02231",
    "venue": "Information Fusion",
    "citation_count": 476,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:53.972749"
  },
  {
    "source": "semantic_scholar",
    "source_id": "01c36a74693065664bba51e7fdf95709cc690aae",
    "title": "Testing AI Models: The Human Factor in Ensuring Accuracy, Fairness, and Transparency",
    "authors": [
      "Ashwin Choubey"
    ],
    "year": 2025,
    "abstract": "The integration of artificial intelligence across industries has highlighted the indispensable role of human testers in ensuring AI system reliability, fairness, and transparency. While automated testing provides efficiency in processing large-scale data, human oversight remains crucial for detecting nuanced issues, cultural biases, and ethical concerns. This article delves into the multifaceted aspects of human-centric AI testing, exploring how human testers contribute to test design, bias detection, and ethical framework implementation. The article demonstrates that human testers excel in identifying contextual subtleties, cultural nuances, and potential societal impacts that automated systems often miss. Through collaborative approaches combining human expertise with AI capabilities, organizations can achieve superior testing outcomes in areas ranging from healthcare diagnostics to human resource management. The implementation of structured documentation practices and diverse testing teams further enhances the effectiveness of AI system evaluation. As AI systems grow more complex, addressing scaling challenges and developing enhanced human-AI collaboration tools becomes essential for maintaining robust testing processes and ensuring responsible AI deployment.",
    "doi": "10.32628/cseit251112238",
    "url": "https://www.semanticscholar.org/paper/01c36a74693065664bba51e7fdf95709cc690aae",
    "pdf_url": "",
    "venue": "International Journal of Scientific Research in Computer Science Engineering and Information Technology",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972750"
  },
  {
    "source": "semantic_scholar",
    "source_id": "4a10e59163f2e4e4472e754ccea7c6d2a99c5705",
    "title": "Enhancing Recruitment Selection Process In Human Resource With Artificial Intelligence Powered Resume Parser",
    "authors": [
      "Yik Junn Kuan",
      "Pei Yi Voon",
      "Li June Tan",
      "Mahdiyehsadat Moosavi",
      "Kar Yee Chong"
    ],
    "year": 2025,
    "abstract": "The traditional recruitment process suffers from inefficiencies, subjective evaluations and biases that hinder hiring quality and increase costs. This research develops an AI-powered Resume Parser to automate resume screening process and address these challenges. The system uses Natural Language Processing (NLP) and machine learning techniques for automation, utilizing an XGBoost classifier for job categorization and a customized Named Entity Recognition (NER) model for information extraction. The models were trained on 2484 resumes across 24 job categories with comprehensive data pre-processing and addressed class imbalance using SMOTE. The performance of six algorithms was compared throughout the research, revealing that XGBoost achieved optimal accuracy of 77% in job categorization, outperforming other tested algorithms including Random Forest (68%), Support Vector Machine (SVM) (62%), and Logistic Regression (64%) etc. The customized NER model successfully extracted key entities including candidate name and skills with high accuracy in test cases, proving its effectiveness in resume parsing. This system revolutionizes the recruitment process by promoting fairness, efficiency and transparency while addressing the limitations of manual recruitment methods.",
    "doi": "10.1109/IICAIET67254.2025.11265526",
    "url": "https://www.semanticscholar.org/paper/4a10e59163f2e4e4472e754ccea7c6d2a99c5705",
    "pdf_url": "",
    "venue": "International Conference on Artificial Intelligence in Engineering and Technology",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972752"
  },
  {
    "source": "semantic_scholar",
    "source_id": "741c7e78d0bd101b1fbf39d0c47fc519941bd275",
    "title": "Toward fairness in artificial intelligence for medical image analysis: identification and mitigation of potential biases in the roadmap from data collection to model deployment",
    "authors": [
      "K. Drukker",
      "Weijie Chen",
      "Judy Gichoya",
      "Nicholas P. Gruszauskas",
      "Jayashree Kalpathy-Cramer",
      "Sanmi Koyejo",
      "Kyle Myers",
      "Rui C. S\u00e1",
      "B. Sahiner",
      "Heather M. Whitney",
      "Zi Zhang",
      "M. Giger"
    ],
    "year": 2023,
    "abstract": "Abstract. Purpose To recognize and address various sources of bias essential for algorithmic fairness and trustworthiness and to contribute to a just and equitable deployment of AI in medical imaging, there is an increasing interest in developing medical imaging-based machine learning methods, also known as medical imaging artificial intelligence (AI), for the detection, diagnosis, prognosis, and risk assessment of disease with the goal of clinical implementation. These tools are intended to help improve traditional human decision-making in medical imaging. However, biases introduced in the steps toward clinical deployment may impede their intended function, potentially exacerbating inequities. Specifically, medical imaging AI can propagate or amplify biases introduced in the many steps from model inception to deployment, resulting in a systematic difference in the treatment of different groups. Approach Our multi-institutional team included medical physicists, medical imaging artificial intelligence/machine learning (AI/ML) researchers, experts in AI/ML bias, statisticians, physicians, and scientists from regulatory bodies. We identified sources of bias in AI/ML, mitigation strategies for these biases, and developed recommendations for best practices in medical imaging AI/ML development. Results Five main steps along the roadmap of medical imaging AI/ML were identified: (1) data collection, (2) data preparation and annotation, (3) model development, (4) model evaluation, and (5) model deployment. Within these steps, or bias categories, we identified 29 sources of potential bias, many of which can impact multiple steps, as well as mitigation strategies. Conclusions Our findings provide a valuable resource to researchers, clinicians, and the public at large.",
    "doi": "10.1117/1.JMI.10.6.061104",
    "url": "https://www.semanticscholar.org/paper/741c7e78d0bd101b1fbf39d0c47fc519941bd275",
    "pdf_url": "https://www.spiedigitallibrary.org/journals/journal-of-medical-imaging/volume-10/issue-6/061104/Toward-fairness-in-artificial-intelligence-for-medical-image-analysis/10.1117/1.JMI.10.6.061104.pdf",
    "venue": "Journal of Medical Imaging",
    "citation_count": 89,
    "fields_of_study": [
      "Medicine",
      "Engineering"
    ],
    "retrieved_at": "2026-02-02T16:57:53.972754"
  },
  {
    "source": "semantic_scholar",
    "source_id": "bf42d79010c6b3b3c6807c8ddccfa2a099038863",
    "title": "Ethical impact assessment. A tool of the Recommendation on the Ethics of Artificial Intelligence",
    "authors": [],
    "year": 2023,
    "abstract": "The Recommendation on the Ethics of AI provides a framework to ensure that AI developments align with the promotion and protection of human rights and human dignity, environmental sustainability, fairness, inclusion and gender equality. It underscores that these goals and principles should inform technological developments in an ex-ante manner. To support effective implementation, UNESCO developed two instruments, the Readiness Assessment Methodology (RAM) and the Ethical Impact Assessment (EIA). The EIA is proposed to procurers of AI systems, as this is one of the main channels in which algorithms make their way to highly sensitive public domains. But the questions and the structure of the document are designed so the tools can also be used more generally by developers of AI systems, in the public or private sectors, who wish to develop AI ethically and fully comply with international standards such as the Recommendation. The document comprises two main parts that together strike a balance between procedure and substance. In the first part, related to scoping, the goal is to understand the basics of the system, as well as to lay out some preliminary questions, such as whether automation is the best solution for the case at hand. It also raises questions about the project team and whether plans are in place to engage different stakeholders. The second part is dedicated to implementing the principles in the UNESCO Recommendation. UNESCO Catno: 0000386276",
    "doi": "10.54678/ytsa7796",
    "url": "https://www.semanticscholar.org/paper/bf42d79010c6b3b3c6807c8ddccfa2a099038863",
    "pdf_url": "",
    "venue": "",
    "citation_count": 25,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972756"
  },
  {
    "source": "semantic_scholar",
    "source_id": "c4cdd704768868167b161ef4cbce275de7e160d9",
    "title": "On the Right to Work in the Age of Artificial Intelligence: Ethical Safeguards in Algorithmic Human Resource Management",
    "authors": [
      "M. Capasso",
      "Payal Arora",
      "Deepshikha Sharma",
      "Celeste Tacconi"
    ],
    "year": 2024,
    "abstract": "Abstract Algorithmic human resource management (AHRM), the automation or augmentation of human resources-related decision-making with the use of artificial intelligence (AI)-enabled algorithms, can increase recruitment efficiency but also lead to discriminatory results and systematic disadvantages for marginalized groups in society. In this paper, we address the issue of equal treatment of workers and their fundamental rights when dealing with these AI recruitment systems. We analyse how and to what extent algorithmic biases can manifest and investigate how they affect workers\u2019 fundamental rights, specifically (1) the right to equality, equity, and non-discrimination; (2) the right to privacy; and, finally, (3) the right to work. We recommend crucial ethical safeguards to support these fundamental rights and advance forms of responsible AI governance in HR-related decisions and activities.",
    "doi": "10.1017/bhj.2024.26",
    "url": "https://www.semanticscholar.org/paper/c4cdd704768868167b161ef4cbce275de7e160d9",
    "pdf_url": "",
    "venue": "Business and Human Rights Journal",
    "citation_count": 9,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972757"
  },
  {
    "source": "semantic_scholar",
    "source_id": "ffada086cca0ba01ab7d72845bafcab035f8618d",
    "title": "Role of artificial intelligence in human resource management for optimizing employee productivity",
    "authors": [
      "Nupur Veshne",
      "Jyoti Jamnani"
    ],
    "year": 2024,
    "abstract": "Artificial intelligence (AI) has significantly transformed various industries, including human resource management, by enhancing efficiency, decision-making, and employee productivity. Recruitments can be modernized by using catboats, predictive analysis helps in offering data-driven insights that can be used to find skill gaps and people management planning. AI\u2019s advancements have made it easy to integrate AI with HRM for increasing efficiency, despite this a lot of ethical concerns, biases, and privacy issue makes it difficult to implement AI completely in the decision-making process. This paper is a bibliometric study focusing on the evolution of AI with HRM to enhance employee productivity and identify key trends and research gaps. This study considered publications for 10 years from 2014 to 2024 through various databases such as Scopus, Web of Science, and IEEE, the study further divides the literature to highlight the most cited authors, countries contributing to the field, and year-wise contribution. The paper focuses on studying the role of AI in various functional areas of HR such as recruitment, performance, and employee productivity. The findings highlight the increasing role of AI across multiple HR practices. This bibliometric investigation offers valuable findings for researchers and practitioners aiming to use AI to enhance HR jobs.",
    "doi": "10.1051/itmconf/20246801003",
    "url": "https://www.semanticscholar.org/paper/ffada086cca0ba01ab7d72845bafcab035f8618d",
    "pdf_url": "https://doi.org/10.1051/itmconf/20246801003",
    "venue": "ITM Web of Conferences",
    "citation_count": 3,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972759"
  },
  {
    "source": "semantic_scholar",
    "source_id": "122ac1ab00f8c54a609e18d2aea5a0008b032f8a",
    "title": "Strategic Adoption of Artificial Intelligence for Human Resource Management Practices Transforming Healthcare Sector",
    "authors": [
      "Amit Joshi",
      "Rubee Singh",
      "Seema Rani"
    ],
    "year": 2024,
    "abstract": "The incorporation of Artificial Intelligence (AI) technology into several industries has significantly impacted the usual workflows and processes in recent years, including the healthcare industry. Human Resource Management (HRM) is essential in healthcare businesses as it is responsible for the recruitment, training, and the retention of skilled staff members who are capable of providing high-quality patient care. This paper investigates different methods in which AI is used in HRM in the healthcare industry on the basis of existing research in the area. It analyzes how AI affects recruitment, talent management, workforce optimization, and employee well-being. This paper also discusses the challenges and future prospects of AI-driven approaches in HRM practices. It explores how these approaches are changing the way healthcare organizations operate and improving patient outcomes. The results provide some valuable contributions to the field of artificial intelligence in the healthcare sector. Initially, the chapter gives a factual foundation for the current presumptions on the implementation and difficulties of artificial intelligence in the healthcare domain. Further, it shows how artificial intelligence provides numerous opportunities to expedite Human Resource operations by offering automated applicant screening, customized learning systems, optimizing the workforce and enhancing employee engagement. Although AI has the capacity to revolutionize HRM practices in the healthcare industry, it also presents some challenges and obstacles. In order to ensure that AI-driven solutions promote fairness, transparency, and equity, it is crucial to address issues such as algorithmic bias, privacy of data and the impact on the human workforce in a deliberate manner. In addition, healthcare firms need to invest funds for implementing rigorous cyber security measures in order to ensure the privacy of patient and employee data from cyber-attacks and potential breaches.",
    "doi": "10.58818/ijems.v3i3.133",
    "url": "https://www.semanticscholar.org/paper/122ac1ab00f8c54a609e18d2aea5a0008b032f8a",
    "pdf_url": "",
    "venue": "The International Journal of Education Management and Sociology",
    "citation_count": 5,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972760"
  },
  {
    "source": "semantic_scholar",
    "source_id": "592deae803b208f808dd4fd09f5018203882934c",
    "title": "Artificial Intelligence in Educational Data Mining and Human-in-the-Loop Machine Learning and Machine Teaching: Analysis of Scientific Knowledge",
    "authors": [
      "Eloy L\u00f3pez-Meneses",
      "Luis L\u00f3pez-Catal\u00e1n",
      "Noelia Pel\u00edcano-Piris",
      "Pedro C. Mellado-Moreno"
    ],
    "year": 2025,
    "abstract": "This study explores the integration of artificial intelligence (AI) into educational data mining (EDM), human-assisted machine learning (HITL-ML), and machine-assisted teaching, with the aim of improving adaptive and personalized learning environments. A systematic review of the scientific literature was conducted, analyzing 370 articles published between 2006 and 2024. The research examines how AI can support the identification of learning patterns and individual student needs. Through EDM, student data are analyzed to predict student performance and enable timely interventions. HITL-ML ensures that educators remain in control, allowing them to adjust the system according to their pedagogical goals and minimizing potential biases. Machine-assisted teaching allows AI processes to be structured around specific learning criteria, ensuring relevance to educational outcomes. The findings suggest that these AI applications can significantly improve personalized learning, student tracking, and resource optimization in educational institutions. The study highlights ethical considerations, such as the need to protect privacy, ensure the transparency of algorithms, and promote equity, to ensure inclusive and fair learning environments. Responsible implementation of these methods could significantly improve educational quality.",
    "doi": "10.3390/app15020772",
    "url": "https://www.semanticscholar.org/paper/592deae803b208f808dd4fd09f5018203882934c",
    "pdf_url": "https://doi.org/10.3390/app15020772",
    "venue": "Applied Sciences",
    "citation_count": 17,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972762"
  },
  {
    "source": "semantic_scholar",
    "source_id": "991ea65441a76cf817475541c60e2740b352c71d",
    "title": "Combining Human-in-the-Loop Systems and AI Fairness Toolkits to Reduce Age Bias in AI Job Hiring Algorithms",
    "authors": [
      "Christopher G. Harris"
    ],
    "year": 2024,
    "abstract": "As artificial intelligence (AI) systems become more sophisticated, they are increasingly integrated into high-stakes decision-making processes, such as hiring, fraud detection, loan approvals, and medical diagnoses. However, this growing reliance on AI raises concerns about the potential for these systems to perpetuate and amplify societal biases. Researchers have developed two main approaches to bias mitigation in AI to address this issue: human-in-the-loop (HITL) systems and AI fairness toolkits. HITL systems involve human reviewers actively participating in the AI decision-making process, while AI fairness toolkits are software tools that can identify and mitigate bias. HITL systems are particularly effective in addressing biases tied to specific domains, while AI fairness toolkits can be useful in identifying and addressing bias proactively. This paper examines different combinations of HITL systems and AI fairness toolkits, conducts an experiment to evaluate biases in hiring decisions using each, and provides recommendations for organizations considering implementing one or both approaches.",
    "doi": "10.1109/BigComp60711.2024.00019",
    "url": "https://www.semanticscholar.org/paper/991ea65441a76cf817475541c60e2740b352c71d",
    "pdf_url": "",
    "venue": "International Conference on Big Data and Smart Computing",
    "citation_count": 3,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:53.972763"
  },
  {
    "source": "semantic_scholar",
    "source_id": "2d6a9ee25f4736f0a605d489e90ab160b09547ec",
    "title": "Ai as Employee Performance Evaluation: An Innovative Approach in Human Resource Development",
    "authors": [
      "Dr. H. Djunaedi",
      "M.AB"
    ],
    "year": 2024,
    "abstract": "Employee performance evaluation is a crucial process in human resource management. It measures an individual's contribution to organizational goals. However, traditional evaluation methods face obstacles like subjective bias, inefficiency, and lack of objectivity. Artificial Intelligence (AI) technology offers a promising solution. This paper discusses AI's implementation as an evaluation tool and its impact on human resource development. Previous research shows that AI improves objectivity, fairness, and efficiency in appraisal. It accurately identifies employee potential, aiding targeted development programs. However, research gaps remain, such as AI's use in different industries and ethical concerns affecting employees and organizational culture. This study aims to investigate AI's use in various industry contexts, understand ethical and trust aspects, and analyze its impact on employees and organizational culture. The results will provide valuable insights into AI's benefits in performance evaluation, benefiting human resource development and improving the evaluation process. Organizational understanding of AI's challenges and benefits in human resource development can enhance overall productivity and performance.",
    "doi": "10.52783/pst.469",
    "url": "https://www.semanticscholar.org/paper/2d6a9ee25f4736f0a605d489e90ab160b09547ec",
    "pdf_url": "",
    "venue": "Power system technology",
    "citation_count": 9,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972764"
  },
  {
    "source": "semantic_scholar",
    "source_id": "4a19368f0b3bcd6969bea644725ca0e1e409190d",
    "title": "Assessing the Influence of Artificial Intelligence on Human Resource Management Practices",
    "authors": [
      "Qurotul Aini",
      "U. Rusilowati",
      "Marsani Asfi",
      "Po Abas Sunarya",
      "Souza Nurafrianto Windiartono Putra",
      "Achani Rahmania Az Zahra"
    ],
    "year": 2024,
    "abstract": "This research investigates the contemporary impact of artificial intelligence (AI) on human resource management (HRM) practices. In the context of the rapidly evolving AI landscape, this study aims to comprehensively assess its transformative effects on HRM within current organizational and business frameworks. Utilizing a multi-faceted methodology, including a cross-sector survey of 235 participants, in-depth interviews with HR professionals, and extensive literature analysis, the research explores critical issues such as AI\u2019s influence on recruitment processes, performance evaluations, and employee development strategies. The findings reveal that while AI has the potential to enhance HRM efficiency, it also introduces ethical considerations, data security challenges, and psychological implications for employees. The study advocates for a holistic approach to integrating AI into HRM practices, taking into account technical nuances, ethical dimensions, and prioritizing employee well-being. Practical implications emphasize the need for organizations to adopt balanced and adaptive policies to ensure the judicious use of AI in HRM, achieving optimal benefits while maintaining fairness and workforce welfare.",
    "doi": "10.1109/ICCIT62134.2024.10701158",
    "url": "https://www.semanticscholar.org/paper/4a19368f0b3bcd6969bea644725ca0e1e409190d",
    "pdf_url": "",
    "venue": "International Conference on Communications and Information Technology",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972766"
  },
  {
    "source": "semantic_scholar",
    "source_id": "b24cd6730256ced735b6fab7ef3ad637fcf9a0b0",
    "title": "Impact of Artificial Intelligence (AI) on Human Resource Management (HRM)",
    "authors": [
      "Ritika Gupta"
    ],
    "year": 2024,
    "abstract": "Incorporating Artificial Intelligence (AI) into Human Resource Management (HRM) has become a significant driving force in shaping contemporary workplaces. This paper comprehensively examines AI's influence on HRM, from its foundational concepts to its practical applications, advantages, challenges, ethical considerations, legal ramifications, anticipated trends, and actionable recommendations. Commencing with an introductory framework, the paper navigates the intricate facets of AI within HRM, elucidating its diverse components and functionalities. It further scrutinizes AI's specific roles in recruitment, training, performance management, and employee engagement, emphasizing its transformative potential. Additionally, the paper articulates the manifold benefits AI affords HRM, such as process optimization, informed decision-making, and enhanced employee engagement, juxtaposed against the inherent challenges, including data integrity, privacy concerns, biases, and algorithmic transparency issues. Addressing AI's ethical and legal dimensions in HRM, the paper underscores the imperative of conscientious AI integration and governance. Furthermore, it anticipates forthcoming AI trends and furnishes strategic guidance for organizations navigating this evolving landscape. Ultimately, the paper advocates for ethical, transparent, and human-centric approaches to AI adoption, underscoring its profound impact on HRM practices and workplace dynamics.",
    "doi": "10.36948/ijfmr.2024.v06i03.21444",
    "url": "https://www.semanticscholar.org/paper/b24cd6730256ced735b6fab7ef3ad637fcf9a0b0",
    "pdf_url": "https://www.ijfmr.com/papers/2024/3/21444.pdf",
    "venue": "International Journal For Multidisciplinary Research",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972767"
  },
  {
    "source": "semantic_scholar",
    "source_id": "f1f0a6ebacac9983b8e745b19dbf18123b655473",
    "title": "The Transformative Role of Artificial Intelligence in Human Resource",
    "authors": [
      "Yavana Rani Subramanian",
      "Riya R"
    ],
    "year": 2024,
    "abstract": "This research paper explores the impact of artificial intelligence (AI) on human resources (HR). It focuses on the role of HR professionals evolving the influence of AI-driven practices on employee experience and the dynamics of collaboration between humans and AI. The study emphasizes a shift in HR responsibilities towards functions and highlights the crucial skills needed for success in an AI integrated environment. It identifies effects on employee experience, such as learning opportunities, while acknowledging potential drawbacks like job displacement and biased algorithms. The paper advocates for a partnership between humans and AI, emphasizing governance and continuous learning. Recommendations for HR professionals and organizations include embracing learning, prioritizing functions, advocating for ethical AI practices, and fostering collaborative relationships with AI. Ultimately, the paper envisions a future where AI complements expertise to create a compassionate workplace. It calls for research in this transformative HR landscape.",
    "doi": "10.31674/ijrtbt.2024.v08i02.002",
    "url": "https://www.semanticscholar.org/paper/f1f0a6ebacac9983b8e745b19dbf18123b655473",
    "pdf_url": "",
    "venue": "International Journal on Recent Trends in Business and Tourism",
    "citation_count": 3,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972769"
  },
  {
    "source": "semantic_scholar",
    "source_id": "d80cd9caaada14ca658b65c5448125d2522f90cf",
    "title": "A study on Pursuit of Artificial Intelligence in Human Resource Management: A Narrative view",
    "authors": [
      "Mahesh C. Ganagi",
      "Arun A. Rotti"
    ],
    "year": 2024,
    "abstract": "This study harnesses the power of narrative to explore how artificial intelligence (AI) transforms Human Resource Management (HRM). The findings illustrate the broad changes that are taking place in key HR activities like recruitment, performance management processes, employee engagement and learning & development as organizations adopt more AI powered tools to enable workforce outcomes. Synthesising current insights and case studies, the paper identifies AI use-cases that help improve processes while supporting data-driven decision-making. But it tackles moral questions too \u2014 biases in algorithms, privacy issues around handling data and the iffy territory of how workers might take to using A.I. The methodology makes use of a secondary data analysis, employing thematic analysis to investigate the consequences that AI can mean for HRM. The results bring home the vast possibilities and difficulties associated with utilizing AI, underscoring why HR workers must quickly come to grips with rapid change in tech. Conclusion This study facilitates important contributions to the current debate on AI and future work, providing a comprehensive narrative perspective on what it means for HR professionals and organizations.",
    "doi": "10.1051/itmconf/20246801005",
    "url": "https://www.semanticscholar.org/paper/d80cd9caaada14ca658b65c5448125d2522f90cf",
    "pdf_url": "https://doi.org/10.1051/itmconf/20246801005",
    "venue": "ITM Web of Conferences",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972770"
  },
  {
    "source": "semantic_scholar",
    "source_id": "a6d0cde74930483a124173777ac0fd43aae56d5a",
    "title": "HUMAN RESOURCE MANAGEMENT AND ARTIFICIAL INTELLIGENCE: TRANSFORMATIVE EFFECTS AND FUTURE PROSPECTS",
    "authors": [
      "Rajeev Kaur"
    ],
    "year": 2024,
    "abstract": "Artificial intelligence (AI) is technology that enables computers and machines to simulate human learning, comprehension, problem solving, decision making, creativity and autonomy. Ancient civilizations contained tales of intelligent robots, such as Greek and Chinese cultures. AI as a modern phenomenon which took shape in the mid-20th century with the advent of digital computers. The first breakthrough, published in 1950, was Alan Turing's paper, \u2018Computing Machinery and Intelligence. AI can make provide detailed solution to users and experts. They can act independently, replacing the need for human intelligence or intervention (a classic example being a self-driving car). Many sectors like finance, healthcare, to human resource management (HRM), rely on AI technologies. AI's integration in HRM has brought about great change in conventional HR practices used to measure efficiency, accuracy, strategic decision-making, etc. AI technologies help to provide solution to automation of repetitive tasks, analysis of sprawling volumes of data and insights facilitating decision-making. Through this research paper we try to understand the AI's effects on HR processes, in terms of recruitment, onboarding, performance appraisal, training and development, employee engagement, workforce planning; understanding the benefits and cons of implementing AI in HRM; ethical considerations and potential biases in AI algorithms relevant to HR practices; analysis of emergent AI trends with respect to HRM. Trends in AI in HR tend towards a most promising future, presenting several innovations. Accordingly, HR professionals will be expected to acquire competency with regards to new roles and responsibilities to avail AI in enhancing strategic planning, ethical oversight, and data-driven decision-making.",
    "doi": "10.62823/ijemmasss/6.3(ii).6911",
    "url": "https://www.semanticscholar.org/paper/a6d0cde74930483a124173777ac0fd43aae56d5a",
    "pdf_url": "",
    "venue": "International Journal of Education, Modern Management, Applied Science &amp; Social Science",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972772"
  },
  {
    "source": "semantic_scholar",
    "source_id": "b3818f70a2eaa14f8e8042ae899e95c62b0478b4",
    "title": "Ethical Concerns Upon Artificial Intelligence Empowered Human Resource Management: A Qualitative Study among Middle-level Managers from Beijing Technology Companies",
    "authors": [
      "Hong Wei",
      "Cao Chen"
    ],
    "year": 2024,
    "abstract": "The evolution of artificial intelligence (AI) in organizational management has significantly enhanced operational efficiency. However, it has introduced ethical challenges in human resource management. Between January to March 2024, this study conducted 21 semi-structured interviews with middle-level managers from high-tech companies in Beijing. Through word frequency analysis, the study found that key topics among the managers were \u201ccompany,\u201d \u201cdata,\u201d \u201csystem,\u201d and \u201cproblem,\u201d with \u201cAI\u201d frequently recurring in the discussions. Sentiment analysis revealed generally favorable attitudes toward AI in human resource management (AI-HRM), along with nuanced emotional expressions such as inquiry, introspection, recommendation, challenge, adaptation, resistance, and indifference. The sentiment distribution of keywords aligned with topic trends. Thematic analysis identified key ethical concerns in AI-HRM, including issues related to data collection and utilization, human versus machine decision-making, quantitative versus qualitative assessment methodologies, the balance between fairness and efficiency, the need for trustworthy, explainable, and transparent AI, and the oversight of AI-HRM. This study contributes to the ethical investigation of AI-HRM from the perspective of middle-level managers, highlighting themes that are critical for understanding the theory, application, and future development of AI-HRM.",
    "doi": "10.36948/ijfmr.2024.v06i05.28860",
    "url": "https://www.semanticscholar.org/paper/b3818f70a2eaa14f8e8042ae899e95c62b0478b4",
    "pdf_url": "https://www.ijfmr.com/papers/2024/5/28860.pdf",
    "venue": "International Journal For Multidisciplinary Research",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972773"
  },
  {
    "source": "semantic_scholar",
    "source_id": "7d29cfa033dc65a063555083aba9afc26d382a94",
    "title": "The Effects and Functionality of Artificial Intelligence in Human Resource Management",
    "authors": [
      "Muskan Kumari,"
    ],
    "year": 2024,
    "abstract": "Artificial intelligence (AI) technology have revolutionised many elements of corporate operations in recent years, and human resource management (HRM) is no exception. The many functions and impacts of AI in the field of HRM are examined in this paper. This study attempts to shed light on how AI is changing traditional HR practices, the benefits it delivers, as well as the possible obstacles and ethical considerations it presents, by a thorough examination of the available research and empirical investigations. The study will examine how AI is used in HRM in a variety of contexts, such as hiring and selection procedures, performance management, employee engagement, and training and development programmes. It will look at how AI-powered solutions are improving accuracy and efficiency in HR tasks. Examples of these tools include chatbots for candidate conversation, resume screening algorithms, and predictive analytics for finding high-potential individuals. The project will also explore the ways in which AI may support inclusion and diversity in the workplace and enhance the work experience for employees. Additionally, the study will go over the possible drawbacks of implementing AI in HRM, including worries about algorithmic bias, data privacy, and the displacement of human labour. The ethical issues surrounding the use of AI to make critical HR decisions as well as the requirement for accountability and transparency in AI-driven processes will also be covered.",
    "doi": "10.55041/ijsrem31091",
    "url": "https://www.semanticscholar.org/paper/7d29cfa033dc65a063555083aba9afc26d382a94",
    "pdf_url": "https://ijsrem.com/download/the-effects-and-functionality-of-artificial-intelligence-in-human-resource-management/?wpdmdl=30405&refresh=665b9debcd5851717280235",
    "venue": "INTERANTIONAL JOURNAL OF SCIENTIFIC RESEARCH IN ENGINEERING AND MANAGEMENT",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972775"
  },
  {
    "source": "semantic_scholar",
    "source_id": "652dca5fc615170d2905ca78c91ee17dc5257549",
    "title": "Ethics, Bias, and Governance in Artificial Intelligence for Hepatology: Toward Building a Safe and Fair Future.",
    "authors": [
      "Chanda K. Ho",
      "S. Asrani"
    ],
    "year": 2025,
    "abstract": null,
    "doi": "10.1016/j.jceh.2025.102628",
    "url": "https://www.semanticscholar.org/paper/652dca5fc615170d2905ca78c91ee17dc5257549",
    "pdf_url": "",
    "venue": "Journal of Clinical and Experimental Hepatology",
    "citation_count": 4,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:53.972776"
  },
  {
    "source": "semantic_scholar",
    "source_id": "28afd70b450ed944d6040aee97575bf3ff295cb3",
    "title": "Ethical Integration of Artificial Intelligence in Healthcare: Narrative Review of Global Challenges and Strategic Solutions",
    "authors": [
      "M. P. Singh",
      "Y. Keche"
    ],
    "year": 2025,
    "abstract": "Artificial intelligence (AI) is revolutionizing healthcare, offering innovative solutions to enhance diagnostic accuracy, treatment efficacy, and accessibility. However, integrating AI into clinical practice raises significant ethical implications, necessitating clear guidelines and frameworks. This paper provides a comprehensive review of the ethical landscape surrounding AI deployment in healthcare across various countries and regions. It explores AI's transformative potential while underscoring the need to prioritize patient safety, transparency, accountability, data privacy, fairness, and human oversight. The paper analyzes existing guidelines from the European Union, the United States, India, Australia, and Africa, identifying common ethical principles and considerations. It discusses challenges and proposes suggestions for addressing issues such as data quality and bias, transparency, privacy and security, accessibility and equity, and robust legal and regulatory frameworks. By fostering a comprehensive understanding of the ethical implications and guidelines surrounding AI in healthcare, this paper aims to contribute to the responsible development and equitable deployment of these transformative technologies.",
    "doi": "10.7759/cureus.84804",
    "url": "https://www.semanticscholar.org/paper/28afd70b450ed944d6040aee97575bf3ff295cb3",
    "pdf_url": "",
    "venue": "Cureus",
    "citation_count": 10,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:53.972778"
  },
  {
    "source": "semantic_scholar",
    "source_id": "65b983d217e294de4cc3fb22758368d5bf9a41fe",
    "title": "Ethics in Education: Exploring the Ethical Implications of Artificial Intelligence Implementation",
    "authors": [
      "Florina Mihai Leta",
      "Diane-Paula Vancea"
    ],
    "year": 2023,
    "abstract": "The integration of artificial intelligence (AI) technology in education has introduced numerous possibilities and benefits. However, it also raises ethical concerns that demand careful consideration. This research article explores the ethical implications associated with the implementation of AI in education. The literature review examines key ethical dimensions, including privacy and data protection, equity and bias, and the impact on the teacher-student relationship. The findings highlight the importance of transparency, accountability, and fairness in AI design and deployment. The article proposes a comprehensive framework to guide ethical AI implementation in education, emphasizing the need for robust policies, algorithmic transparency, and addressing biases. By proactively addressing these ethical considerations, educational stakeholders can ensure a responsible and inclusive educational environment that harnesses the potential of AI while upholding ethical principles.",
    "doi": "10.61801/ouaess.2023.1.54",
    "url": "https://www.semanticscholar.org/paper/65b983d217e294de4cc3fb22758368d5bf9a41fe",
    "pdf_url": "",
    "venue": "Ovidius University Annals: Economic Sciences Series",
    "citation_count": 10,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972779"
  },
  {
    "source": "semantic_scholar",
    "source_id": "6fe7a7dec52c70a7b1f246998c7936b2dba20b07",
    "title": "Ethical issues of Artificial Intelligence in Healthcare in Developing Countries: A Systematic Review of Empirical Studies",
    "authors": [
      "Khunsa Junaid",
      "Mehreen Nasir",
      "Saadia Rafique",
      "Amber Arshad",
      "Meha Siddiqui",
      "Muhammad Ali Junaid"
    ],
    "year": 2025,
    "abstract": "Significant improvements in diagnosis, treatment, and patient outcomes are possible with the use of artificial intelligence (AI) in healthcare. However, there is still a lack of research on ethical issues, especially in developing nations. This systematic review, conducted following PRISMA 2020 guidelines, identified 22 studies from a comprehensive search of 2977 records published between January 2019 and May 2024. Ethical themes were categorised using Jobin et al.'s framework and the European Commission's Ethics Guidelines for Trustworthy AI (EGTAI), while studies were evaluated using Kitchenham and Charters' quality checklist. Nine main ethical issues were identified by thematic analysis; the most often discussed issues were data privacy and justice, followed by patient safety, autonomy, and cyber-security. Benevolence received the least attention, while notable ethical conundrums included bias, fairness, discrimination, algorithmic transparency, and data protection. This systematic review highlights the need for stronger regulatory frameworks, ethical guidelines, and governance structures to ensure responsible AI integration in healthcare, particularly in developing countries, and calls for further research to address existing gaps.",
    "doi": "10.21649/akemu.v31ispl2.5827",
    "url": "https://www.semanticscholar.org/paper/6fe7a7dec52c70a7b1f246998c7936b2dba20b07",
    "pdf_url": "",
    "venue": "Annals of King Edward Medical University",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972781"
  },
  {
    "source": "semantic_scholar",
    "source_id": "cee7a6ad22e907fe4e971902267a49b7cb13ed87",
    "title": "Artificial intelligence bias auditing \u2013 current approaches, challenges and lessons from practice",
    "authors": [
      "Sabina Lacmanovi\u0107",
      "M. \u0160kare"
    ],
    "year": 2025,
    "abstract": "\n\nThis study aims to explore current approaches, challenges and practical lessons in auditing artificial intelligence (AI) systems for bias, focusing on legal compliance audits in the USA and the European Union (EU). This emphasizes the need for standardized methodologies to ensure trustworthy AI systems that align with ethical and regulatory expectations.\n\n\n\nA qualitative analysis compared bias audit practices, including US bias audit report summaries under New York City\u2019s Local Law 144 and conformity assessments (CAs) required by the EU AI Act. Data was gathered from publicly available reports and compliance guidelines to identify key challenges and lessons.\n\n\n\nThe findings revealed that AI systems are susceptible to various biases stemming from data, algorithms and human oversight. Although valuable, legal compliance audits lack standardization, leading to inconsistent reporting practices. The EU\u2019s risk-based CA approach offers a comprehensive framework; however, its effectiveness depends on developing practical standards and consistent application.\n\n\n\nThis study is limited by the early implementation stage of regulatory frameworks, particularly the EU AI Act, and restricted access to comprehensive audit reports. A geographic focus on US and EU jurisdictions may limit the generalizability of the findings. Data availability constraints and the lack of standardized reporting frameworks affect the comparative analysis. Future research should focus on longitudinal studies of audit effectiveness, the development of standardized methodologies for intersectional bias assessment and the investigation of automated audit tools that can adapt to emerging AI technologies while maintaining practical feasibility across different organizational contexts.\n\n\n\nThis research underscores the necessity of adopting socio-technical perspectives and standardized methodologies in AI auditing. It provides actionable insights for firms, regulators and auditors into implementing robust governance and risk assessment practices to mitigate AI biases.\n\n\n\nEffective AI bias auditing practices ensure algorithmic fairness and prevent discriminatory outcomes in critical domains like employment, health care and financial services. The findings emphasize the need for enhanced stakeholder engagement and community representation in audit processes. Implementing robust auditing frameworks can help close socioeconomic gaps by identifying and mitigating biases disproportionately affecting marginalized groups. This research contributes to developing equitable AI systems that respect diversity and promote social justice while maintaining technological advancement.\n\n\n\nThis study contributes to the discourse on AI governance by comparing two regulatory approaches, bias audits and CAs and offers practical lessons from current implementation. It highlights the critical role of standardization in advancing trustworthy and ethical AI systems in the finance and accounting contexts.\n",
    "doi": "10.1108/raf-01-2025-0006",
    "url": "https://www.semanticscholar.org/paper/cee7a6ad22e907fe4e971902267a49b7cb13ed87",
    "pdf_url": "",
    "venue": "Review of Accounting and Finance",
    "citation_count": 12,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972782"
  },
  {
    "source": "semantic_scholar",
    "source_id": "29395b01f6dd2f39b16a230e3057693290e1c011",
    "title": "Effectiveness of Artificial Intelligence for Enhancing Decision-Making Process of Recruitment in HRM Process",
    "authors": [
      "S. Jafri",
      "Shitiz Upreti",
      "F. Saiyad",
      "Khadilkar Sujay Madhukar",
      "Vandana Mishra Chaturvedi",
      "Prakash Divakaran"
    ],
    "year": 2024,
    "abstract": "The integration of Artificial Intelligence (AI) into the recruitment process represents a significant advancement in Human Resource Management (HRM), aiming to optimize the efficiency and effectiveness of hiring practices. This paper explores the effectiveness of AI in improving decision-making processes within HRM, focusing on machine learning's role in streamlining candidate sourcing, enhancing candidate experience, boosting screening efficiency, optimizing interview processes, and improving onboarding experiences. By examining various studies and technological applications, it highlights the transformative potential of AI in recruitment, addressing challenges such as bias mitigation, engagement improvement, and access expansion to diverse talent pools. The research underscores the critical need for developing human-centric AI systems that prioritize transparency, privacy, accountability, fairness, and societal benefit. Through a comprehensive analysis, the paper advocates for the strategic implementation of AI in recruitment, emphasizing continuous monitoring, evaluation, and the necessary training for HR professionals to harness AI's full potential.",
    "doi": "10.1109/InC460750.2024.10649327",
    "url": "https://www.semanticscholar.org/paper/29395b01f6dd2f39b16a230e3057693290e1c011",
    "pdf_url": "",
    "venue": "2024 IEEE International Conference on Contemporary Computing and Communications (InC4)",
    "citation_count": 3,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972784"
  },
  {
    "source": "semantic_scholar",
    "source_id": "1e7bd33d0d1e76b71d6ad84487de97d2cafdbd4b",
    "title": "Ethical Implications of Artificial Intelligence in University Education",
    "authors": [
      "J. Mauti",
      "Dennis Song\u2019oro Ayieko"
    ],
    "year": 2025,
    "abstract": "The integration of Artificial Intelligence (AI) in university education has emerged as a transformative force, promising to revolutionize teaching, learning, and administration. However, its rapid adoption has sparked ethical concerns, particularly in resource-constrained settings. This theoretical article examines the ethical implications of specific AI applications, including plagiarism detection tools, adaptive learning systems, and automated grading technologies within Kenyan universities. It highlights three critical areas: data privacy and security, student-lecturer dynamics, and algorithmic bias. Drawing from Kantian deontological ethics, which emphasizes duty and the inherent morality of actions, the article argues for a balanced approach to AI integration that prioritizes ethical responsibilities over mere technological expedience. Data privacy and security remain pivotal concerns, as AI systems amass extensive personal data, often without robust safeguards, exposing students to potential exploitation and breaches. The article explores the intersection of AI and student-lecturer relationships, revealing how AI-driven tools can disrupt traditional mentorship roles central to African pedagogical traditions. Furthermore, the pervasive issue of algorithmic bias is critically analysed, emphasizing its potential to perpetuate educational inequities and marginalize underrepresented groups. The article highlights the absence of localized frameworks to address these ethical dilemmas in Kenyan universities. By anchoring its analysis in Kantian ethics, this article provides a compelling framework for navigating the ethical challenges posed by AI in education, ensuring that its implementation enhances equity, accountability, and human dignity. This work contributes to ongoing discourse on the responsible use of AI in education, offering actionable insights for policy, research, and practice",
    "doi": "10.37284/eajes.8.1.2583",
    "url": "https://www.semanticscholar.org/paper/1e7bd33d0d1e76b71d6ad84487de97d2cafdbd4b",
    "pdf_url": "",
    "venue": "East African Journal of Education Studies",
    "citation_count": 11,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972785"
  },
  {
    "source": "semantic_scholar",
    "source_id": "fea476bebf4de3b94356005978888724fba6f719",
    "title": "Ethical Challenges and Solutions in the Deployment of Artificial Intelligence Sys-tems",
    "authors": [
      "Subhash Chandra Bose Naripeddy",
      "Viswanadha Raju Thotakura"
    ],
    "year": 2025,
    "abstract": "The rapid advancement of Artificial Intelligence (AI) technologies has introduced transformative possibilities across sectors such as healthcare, finance, transportation, and education. However, the widespread deployment of AI systems also presents a range of ethical challenges, including algorithmic bias, data privacy concerns, lack of transparency, accountability issues, and the potential for job displacement. This article explores the core ethical dilemmas associated with AI adoption and provides a critical analysis of existing frameworks and policy measures aimed at addressing them. The study further examines practical solutions such as explainable AI (XAI), fairness-aware algorithms, regulatory oversight, and inclusive data practices. By integrating interdisciplinary perspectives from technology, law, and ethics, this paper aims to guide researchers, developers, and policymakers in fostering responsible and equitable AI deployment.",
    "doi": "10.60087/jaigs.v8i02.392",
    "url": "https://www.semanticscholar.org/paper/fea476bebf4de3b94356005978888724fba6f719",
    "pdf_url": "",
    "venue": "Journal of Artificial Intelligence General science (JAIGS) ISSN:3006-4023",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972787"
  },
  {
    "source": "semantic_scholar",
    "source_id": "50302d9eb975c1d7c76fccadf9c5490cf5f7ec1b",
    "title": "AI Ethics and Bias: Exploratory study on the ethical considerations and potential biases in ai and data-driven decision-making in banking, with a focus on fairness, transparency, and accountability",
    "authors": [
      "Thiruma Valavan"
    ],
    "year": 2023,
    "abstract": "The integration of Artificial Intelligence (AI) and data-driven decision-making in the banking industry has ushered in unprecedented opportunities for efficiency, risk assessment, and customer service. However, this rapid adoption of AI technology comes with its own set of ethical considerations and potential biases. This research paper delves into the intricate landscape of AI ethics and bias within the banking sector, with a central emphasis on fairness, transparency, and accountability. In sum, this paper contributes to the ongoing discourse on AI ethics and bias by providing valuable insights into the ethical considerations and potential biases inherent in AI and data-driven decision-making within the banking sector. It underscores the necessity of fairness, transparency, and accountability as guiding principles in the responsible integration of AI technology in banking, while also presenting future research directions for this evolving field.",
    "doi": "10.30574/wjarr.2023.20.2.2245",
    "url": "https://www.semanticscholar.org/paper/50302d9eb975c1d7c76fccadf9c5490cf5f7ec1b",
    "pdf_url": "https://wjarr.com/sites/default/files/WJARR-2023-2245.pdf",
    "venue": "World Journal of Advanced Research and Reviews",
    "citation_count": 9,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972788"
  },
  {
    "source": "semantic_scholar",
    "source_id": "592caab82055f97486e15afd4aa3d5b8793eec51",
    "title": "Framework for Fairness in Machine Learning Using Detecting and Mitigating Bias in AI Algorithms",
    "authors": [
      "Vincent Koc"
    ],
    "year": 2025,
    "abstract": "The importance of artificial intelligence (AI) and machine learning (ML) is on the rise as they are increasingly being used in critical decision-making in areas including healthcare, finance, and criminal justice. Their effectiveness, however, is often compromised as these systems replicate and even worsen pre-existing biases from historical data or from the designs of models, ultimately causing unfair and undesirable results. This paper describes a systematic analysis for bias detection and mitigation in machine learning algorithms. The approach includes preprocessing of data, algorithmic changes, and changes during post-processing for improvement of anticipated inequalities while keeping the performance of the model intact. The model's applicability has been illustrated in the areas of healthcare, finance, and criminal justice with case studies demonstrating the need for a trade-off between the model's accuracy and fairness. Besides, AI ethics are also advanced through transparency methods like SHAP and GradCAM, which strengthen trust in AI systems as ethical principles are ensured in the deployment of the AI systems. Though these achievements are significant, challenges on the issue of scaling, fairness definitions, and contextual variations still persist with regard to the application of AI for fairness promoting purposes, suggesting interdisciplinary directions as ways to mitigate the challenges.",
    "doi": "10.1109/ICBATS66542.2025.11258168",
    "url": "https://www.semanticscholar.org/paper/592caab82055f97486e15afd4aa3d5b8793eec51",
    "pdf_url": "",
    "venue": "2025 3rd International Conference on Business Analytics for Technology and Security (ICBATS)",
    "citation_count": 2,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972790"
  },
  {
    "source": "semantic_scholar",
    "source_id": "38fe59360f926697bdab2551b8a42e3d2591fd92",
    "title": "The Ethics of Artificial Intelligence in Legal Decision Making: An Empirical Study",
    "authors": [
      "Brij Mohan",
      "Dutta"
    ],
    "year": 2023,
    "abstract": "Artificial intelligence (AI) is increasingly being used in legal decision making, from predicting case outcomes to aiding in sentencing. However, the use of AI raises ethical concerns regarding fairness, accountability, and transparency. This paper explores these concerns in the context of AI in legal decision making. One ethical issue is the potential for AI to perpetuate existing biases in the legal system. AI algorithms are only as unbiased as the data they are trained on, and if the data reflects historical biases, the AI will perpetuate these biases in its decision making. Another issue is accountability, as it can be difficult to determine who is responsible for errors or bias in AI decision making.",
    "doi": "10.48047/pne.2018.55.1.38",
    "url": "https://www.semanticscholar.org/paper/38fe59360f926697bdab2551b8a42e3d2591fd92",
    "pdf_url": "http://psychologyandeducation.net/pae/index.php/pae/article/download/7788/6176",
    "venue": "psychologyandeducation",
    "citation_count": 6,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972791"
  },
  {
    "source": "semantic_scholar",
    "source_id": "4c101ad76e1f5801f07f5eb0639b5a074fb32594",
    "title": "Consumer bias against evaluations received by artificial intelligence: the mediation effect of lack of transparency anxiety",
    "authors": [
      "Alberto Lopez",
      "Ricardo Garza"
    ],
    "year": 2023,
    "abstract": "PurposeWill consumers accept artificial intelligence (AI) products that evaluate them? New consumer products offer AI evaluations. However, previous research has never investigated how consumers feel about being evaluated by AI instead of by a human. Furthermore, why do consumers experience being evaluated by an AI algorithm or by a human differently? This research aims to offer answers to these questions.Design/methodology/approachThree laboratory experiments were conducted. Experiments 1 and 2 test the main effect of evaluator (AI and human) and evaluations received (positive, neutral and negative) on fairness perception of the evaluation. Experiment 3 replicates previous findings and tests the mediation effect.FindingsBuilding on previous research on consumer biases and lack of transparency anxiety, the authors present converging evidence that consumers who got positive evaluations reported nonsignificant difference on the level of fairness perception on the evaluation regardless of the evaluator (human or AI). Contrarily, consumers who got negative evaluations reported lower fairness perception when the evaluation was given by AI. Further moderated mediation analysis showed that consumers who get a negative evaluation by AI experience higher levels of lack of transparency anxiety, which in turn is an underlying mechanism driving this effect.Originality/valueTo the best of the authors' knowledge, no previous research has investigated how consumers feel about being evaluated by AI instead of by a human. This consumer bias against AI evaluations is a phenomenon previously overlooked in the marketing literature, with many implications for the development and adoption of new AI products, as well as theoretical contributions to the nascent literature on consumer experience and AI.",
    "doi": "10.1108/jrim-07-2021-0192",
    "url": "https://www.semanticscholar.org/paper/4c101ad76e1f5801f07f5eb0639b5a074fb32594",
    "pdf_url": "",
    "venue": "Journal of Research in Interactive Marketing",
    "citation_count": 28,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972793"
  },
  {
    "source": "semantic_scholar",
    "source_id": "916fac0f8c3d8e04df7fa526bcf7b3cb56e798a3",
    "title": "Integrated Human-Centered Artificial Intelligence (HCAI) Performance & Development Model: Bridging the Policy-to-Practice Divide in Performance Management and Employee Development",
    "authors": [
      "Rosemary Uche Packson-Enajerho"
    ],
    "year": 2026,
    "abstract": "Purpose: Despite growing enthusiasm for Artificial Intelligence (AI) in Human Resource Management (HRM), a\nsignificant disconnect persists between the aspirational ideals of Human-Centered AI (HCAI) policies and their practical\napplication in organizational performance management and employee development systems. Traditional performance\nappraisal methods remain infrequent, biased, and disengaging, while AI-based systems risk dehumanization and\nalgorithmic bias if not ethically guided. This paper seeks to bridge this divide by proposing a comprehensive model that\nharmonizes data-driven analytics with empathetic, human-led management practices.\nObjective: The study aims to develop and present the Integrated Human-Centered Artificial Intelligence (HCAI)\nPerformance & Development Model, a conceptual framework designed to operationalize the principles of HCAI\nin performance evaluation and learning systems. The model seeks to transform performance management from a\ncompliance-oriented activity into a continuous, developmental, and ethically grounded process.\nMethodology: Employing a conceptual research design, this paper utilizes a theory-building approach based on the\nsystematic synthesis and thematic analysis of existing scholarship in AI analytics, continuous performance feedback,\nmotivational theory, and managerial coaching. The resulting model was constructed through iterative conceptual\nintegration, informed by both empirical studies and theoretical frameworks, and elaborated using descriptive narrative\nsupported by a visual schematic.\nFindings:The research introduces the Integrated HCAI Performance & Development Model, comprising four\ninterdependent components:\n(1) the AI-Powered Analytics Engine, which aggregates multidimensional performance data to identify trends, skill\ngaps, and development opportunities;\n(2) the Human-Centered Interpretation Layer, where managers apply empathetic judgment to contextualize AI-generated\ninsights;\n(3) the Continuous Feedback & Development Loop, which facilitates ongoing dialogue and co-created learning plans;\nand\n(4) the Strategic HR Policy Foundation, ensuring ethical integrity, transparency, and fairness. Collectively, these\ncomponents align organizational policies with human-centered, technology-enhanced practices. Conclusion: The model provides an actionable framework for integrating intelligent analytics and human empathy to\nenhance performance management and employee development. It underscores the pivotal role of strategic HR leadership\nin ethically governing AI systems and cultivating a culture of psychological safety and learning. Future research should\nfocus on empirical validation through longitudinal and quantitative studies to assess the model\u2019s impact on performance\noutcomes, motivation, and organizational adaptability.",
    "doi": "10.33140/amlai.07.01.01",
    "url": "https://www.semanticscholar.org/paper/916fac0f8c3d8e04df7fa526bcf7b3cb56e798a3",
    "pdf_url": "",
    "venue": "Advances in Machine Learning &amp; Artificial Intelligence",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972794"
  },
  {
    "source": "semantic_scholar",
    "source_id": "9e957bf5cace1f56c55ba704e09bdf39f3eb00b8",
    "title": "Bias in Artificial Intelligence Models in Financial Services",
    "authors": [
      "\u00c1ngel Pav\u00f3n P\u00e9rez"
    ],
    "year": 2022,
    "abstract": "Nowadays, artificial intelligence models are widely used in financial services, from credit scoring to fraud detection, having a direct impact on our daily lives. Although such models have been developed to try to reduce human bias and thus bring greater fairness to financial services decisions, studies have found that there is still significant discrimination by both face-to-face and algorithmic lenders. In fact, Apple has recently been investigated for gender discrimination in assigning a credit limit to its users, demonstrating that there may still be inherent biases in the development of such algorithms and models. Furthermore, biases in financial services models may not only lead to unfair discrimination but were also linked to health problems and recovery prospects. This project aims to analyse and identify the different types of biases found in AI models and data used in the financial services industry. We propose a method using data analysis and explainable models to explain how these biases emerge throughout the process of developing AI models as well as applying state-of-the-art bias dealing techniques to avoid and mitigate them. Finally, we propose how to evaluate these models according to the business objectives and consider possible trade-offs between different definitions of fairness. Thus, the main questions that this project will try to answer are as follows: - What are the current biases in credit risk and fraud detection models and how to identify them? - In what ways understanding how biases emerge from the data can help us in bias mitigation? - To what extent could credit risk and fraud detection models bias be mitigated, and what are the implications of those mitigation techniques? Answering these questions, we hope to create a pipeline for building these models by understanding the key points where bias can emerge and the appropriate methods to avoid it.",
    "doi": "10.1145/3514094.3539561",
    "url": "https://www.semanticscholar.org/paper/9e957bf5cace1f56c55ba704e09bdf39f3eb00b8",
    "pdf_url": "",
    "venue": "AAAI/ACM Conference on AI, Ethics, and Society",
    "citation_count": 4,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:53.972795"
  },
  {
    "source": "semantic_scholar",
    "source_id": "396e7b21c94feefeac8d480adcc3a85545886fa6",
    "title": "Navigating the Ethical Challenges of Artificial Intelligence in Higher Education: An Analysis of Seven Global AI Ethics Policies",
    "authors": [
      "Zouhaier Slimi",
      "Beatriz",
      "Villarejo Carballido"
    ],
    "year": 2023,
    "abstract": null,
    "doi": null,
    "url": "https://www.semanticscholar.org/paper/396e7b21c94feefeac8d480adcc3a85545886fa6",
    "pdf_url": "",
    "venue": "",
    "citation_count": 99,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972797"
  },
  {
    "source": "semantic_scholar",
    "source_id": "3141e9fb4534434bbc9e6765651c3e8fb55175fb",
    "title": "Trust in Artificial Intelligence: Comparing Trust Processes Between Human and Automated Trustees in Light of Unfair Bias",
    "authors": [
      "Markus Langer",
      "Cornelius J. K\u00f6nig",
      "C. Back",
      "Victoria Hemsing"
    ],
    "year": 2021,
    "abstract": "Automated systems based on artificial intelligence (AI) increasingly support decisions with ethical implications where decision makers need to trust these systems. However, insights regarding trust in automated systems predominantly stem from contexts where the main driver of trust is that systems produce accurate outputs (e.g., alarm systems for monitoring tasks). It remains unclear whether what we know about trust in automated systems translates to application contexts where ethical considerations (e.g., fairness) are crucial in trust development. In personnel selection, as a sample context where ethical considerations are important, we investigate trust processes in light of a trust violation relating to unfair bias and a trust repair intervention. Specifically, participants evaluated preselection outcomes (i.e., sets of preselected applicants) by either a human or an automated system across twelve selection tasks. We additionally varied information regarding imperfection of the human and automated system. In task rounds five through eight, the preselected applicants were predominantly male, thus constituting a trust violation due to potential unfair bias. Before task round nine, participants received an excuse for the biased preselection (i.e., a trust repair intervention). The results of the online study showed that participants have initially less trust in automated systems. Furthermore, the trust violation and the trust repair intervention had weaker effects for the automated system. Those effects were partly stronger when highlighting system imperfection. We conclude that insights from classical areas of automation only partially translate to the many emerging application contexts of such systems where ethical considerations are central to trust processes.",
    "doi": "10.1007/s10869-022-09829-9",
    "url": "https://www.semanticscholar.org/paper/3141e9fb4534434bbc9e6765651c3e8fb55175fb",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10869-022-09829-9.pdf",
    "venue": "Journal of business and psychology",
    "citation_count": 90,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:53.972799"
  },
  {
    "source": "semantic_scholar",
    "source_id": "c6d7f9c236c7546bba9bff47c9502f19845c3f51",
    "title": "Exploring The Ethical Governance of Artificial Intelligence from An Islamic Ethical Perspective",
    "authors": [
      "Uthman Mohammed Mustapha Kannike",
      "A. Fahm"
    ],
    "year": 2025,
    "abstract": "This study aims to examine the intersection of contemporary artificial intelligence (AI) with Islamic ethics, specifically exploring how foundational Islamic ethical principles can guide the integration and governance of AI technologies. Employing a theoretical and conceptual analysis method, the research investigates epistemological and theological considerations related to the application of machine learning algorithms in interpreting sacred Islamic texts. The core theoretical underpinnings guiding this analysis include Taw\u1e25\u012bd (the Oneness of God), which emphasizes harmony and ethical coherence; Maq\u0101\u1e63id al-Shar\u012b\u02bfah (Objectives of Islamic Law), focusing on safeguarding fundamental human interests such as faith, life, intellect, progeny, and wealth; Ihsan (Excellence and Benevolence), advocating for moral excellence in technological applications; and \u02bfAdl (Justice), which demands equity and fairness in technological advancements. The findings indicate that while AI holds significant promise for enhancing societal welfare, education, healthcare, and economic justice within Muslim communities, it presents profound ethical challenges, including algorithmic bias, privacy infringement, human autonomy erosion, and accountability concerns. The study highlights the necessity of rigorous ethical oversight grounded in Islamic ethics to navigate these challenges, proposing that AI applications adhere to principles of justice, transparency, and the preservation of human dignity and autonomy. The implications of this research extend beyond theoretical considerations, underscoring the importance of interdisciplinary collaboration between Islamic scholars, ethicists, policymakers, and technologists. Islamic ethical guidelines can enrich global conversations on AI ethics, ensuring technological innovations align with universally recognized moral standards while promoting social justice and human flourishing.",
    "doi": "10.22452/fiqh.vol22no1.5",
    "url": "https://www.semanticscholar.org/paper/c6d7f9c236c7546bba9bff47c9502f19845c3f51",
    "pdf_url": "",
    "venue": "Jurnal Fiqh",
    "citation_count": 8,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972800"
  },
  {
    "source": "semantic_scholar",
    "source_id": "9cae55bf7fff58e333489d4aa4994675b6f8aaff",
    "title": "Mitigating machine learning bias between high income and low\u2013middle income countries for enhanced model fairness and generalizability",
    "authors": [
      "Jenny Yang",
      "Lei A. Clifton",
      "N. Dung",
      "N. Phong",
      "L. Yen",
      "Doan Bui Xuan Thy",
      "A. Soltan",
      "Louise Thwaites",
      "David A. Clifton"
    ],
    "year": 2024,
    "abstract": "Collaborative efforts in artificial intelligence (AI) are increasingly common between high-income countries (HICs) and low- to middle-income countries (LMICs). Given the resource limitations often encountered by LMICs, collaboration becomes crucial for pooling resources, expertise, and knowledge. Despite the apparent advantages, ensuring the fairness and equity of these collaborative models is essential, especially considering the distinct differences between LMIC and HIC hospitals. In this study, we show that collaborative AI approaches can lead to divergent performance outcomes across HIC and LMIC settings, particularly in the presence of data imbalances. Through a real-world COVID-19 screening case study, we demonstrate that implementing algorithmic-level bias mitigation methods significantly improves outcome fairness between HIC and LMIC sites while maintaining high diagnostic sensitivity. We compare our results against previous benchmarks, utilizing datasets from four independent United Kingdom Hospitals and one Vietnamese hospital, representing HIC and LMIC settings, respectively.",
    "doi": "10.1038/s41598-024-64210-5",
    "url": "https://www.semanticscholar.org/paper/9cae55bf7fff58e333489d4aa4994675b6f8aaff",
    "pdf_url": "https://www.nature.com/articles/s41598-024-64210-5.pdf",
    "venue": "Scientific Reports",
    "citation_count": 23,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:53.972802"
  },
  {
    "source": "semantic_scholar",
    "source_id": "367977633e1f5f643335ad58cb2bfbcc6035e159",
    "title": "The Role of Artificial Intelligence in Improving Organizational Behavior: A Systematic Study",
    "authors": [
      "Reza Rostamzadeh",
      "Fereshteh Khajeh Alizadeh",
      "Shirvan Keivani",
      "Hero Isavi"
    ],
    "year": 2025,
    "abstract": "Artificial intelligence (AI) represents a transformative technology with the potential to profoundly influence organizational behavior (OB). It can enhance organizational performance and efficiency through mechanisms such as automation, resource optimization, and advanced data analysis. Nevertheless, the integration of AI within organizations presents various social and ethical dilemmas that could adversely impact fairness, privacy, and employee satisfaction. This research aims to develop a comprehensive framework that elucidates the role of AI in enhancing OB while also identifying the associated challenges and opportunities through a meta\u2010synthesis approach. A systematic review of the literature was conducted, focusing on studies that explore the intersection of AI and OB, employing a qualitative meta\u2010synthesis methodology. The data were sourced from scholarly articles published in esteemed scientific databases from 1995 to 2024. Ultimately, 18 articles specifically relevant to this subject were selected, and the data underwent analysis through open coding. This process yielded 231 distinct codes, which were subsequently organized and integrated based on their conceptual similarities into various dimensions and components. The findings showed that the impact of AI on OB includes five main dimensions: (1) automation, (2) innovation and organizational learning, (3) intelligent decision\u2010making, (4) organizational culture and human interactions, and (5) ethics and leadership. These dimensions include components such as data analysis, improved decision\u2010making, personalization, trust and information security, and adaptation to new technologies. Finally, a research model was presented focusing on these dimensions. In addition to the benefits related to productivity and improved decision\u2010making, the implementation of AI in organizations requires ethical and cultural considerations to maintain satisfaction and human interactions. Paying attention to algorithmic fairness and transparency in decision\u2010making can strengthen employee trust and facilitate the adoption of this technology. Therefore, organizations should manage the implementation of AI in a way that serves the development of OB and improved performance through training, developing ethical frameworks, and providing appropriate support.",
    "doi": "10.1155/hbe2/8094428",
    "url": "https://www.semanticscholar.org/paper/367977633e1f5f643335ad58cb2bfbcc6035e159",
    "pdf_url": "",
    "venue": "Human Behavior and Emerging Technologies",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972804"
  },
  {
    "source": "semantic_scholar",
    "source_id": "276f063120faf0a4016aca230d9f4514c01a0331",
    "title": "From Ethics to Execution: The Role of Academic Librarians in Artificial Intelligence (AI) Policy-Making at Colleges and Universities",
    "authors": [
      "Russell Michalak"
    ],
    "year": 2023,
    "abstract": "Abstract This paper highlights the importance of involving academic librarians in the development of ethical AI policies. The Academic Librarian Framework for Ethical AI Policy Development (ALF Framework) is introduced, recognizing librarians\u2019 unique skills and expertise. The paper discusses the benefits of their involvement, including expertise in information ethics and privacy, practical experience with AI tools, and collaborations. It also addresses challenges, such as limited awareness, institutional resistance, resource constraints, interdisciplinary collaboration, and evolving AI technologies, offering practical solutions. By actively involving librarians, institutions can develop comprehensive and ethical AI policies that prioritize social responsibility and respect for human rights.",
    "doi": "10.1080/01930826.2023.2262367",
    "url": "https://www.semanticscholar.org/paper/276f063120faf0a4016aca230d9f4514c01a0331",
    "pdf_url": "",
    "venue": "Journal of Library Administration",
    "citation_count": 31,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972805"
  },
  {
    "source": "semantic_scholar",
    "source_id": "9966837df189780dfd3e16bea7d1dc0b115d7af3",
    "title": "Exploring bias and fairness in artificial intelligence and machine learning algorithms",
    "authors": [
      "Utsab Khakurel",
      "Ghada Abdelmoumin",
      "Aakriti Bajracharya",
      "D. Rawat"
    ],
    "year": 2022,
    "abstract": "Machine learning algorithms are being widely used in different fields such as image recognition, speech recognition, traffic and weather prediction, recommendations, spam filtering, self-driving cars, stock market prediction, medical diagnosis, and more. The ability of machines to feed in years of data and predict the outcome has helped humans in unimaginable ways. Machine learning has automated half of human work requiring very little human intervention and saving time and energy. However, sometimes individuals end up paying the price and falling victim to the unfair and biased outcome of machine learning algorithms. Machines learn through data what they are provided with, but the data that machines learn from does not come free from human biases. Human biases based on race, sex, ethnicity, skin color, and other sensitive attributes are reflected in the dataset which, when fed to the machine, results in a similar biased prediction. The years of data represent the bias that has been present in society, and the machine learning model simply mimics the pattern. There has been constant research and experiments being done on how to prevent these biases from reflecting on the prediction. In this paper, we will investigate if there is any bias present in the benchmark Statlog \u201cAustralian Credit Approval\u201d dataset and take necessary measures to mitigate the bias present in the data. The paper shows how the AIF360 tool can identify and mitigate bias in the data and eventually in the learning algorithms.",
    "doi": "10.1117/12.2621282",
    "url": "https://www.semanticscholar.org/paper/9966837df189780dfd3e16bea7d1dc0b115d7af3",
    "pdf_url": "",
    "venue": "Defense + Commercial Sensing",
    "citation_count": 9,
    "fields_of_study": [
      "Engineering"
    ],
    "retrieved_at": "2026-02-02T16:57:53.972806"
  },
  {
    "source": "semantic_scholar",
    "source_id": "0f81aa2e0e21e4a673eeabd2ca4f4c41009a8688",
    "title": "Building Trustworthy Multimodal AI: A Review of Fairness, Transparency, and Ethics in Vision-Language Tasks",
    "authors": [
      "Mohammad Saleh",
      "Azadeh Tabatabaei"
    ],
    "year": 2025,
    "abstract": "Objective: This review explores the trustworthiness of multimodal artificial intelligence (AI) systems, specifically focusing on vision-language tasks. It addresses critical challenges related to fairness, transparency, and ethical implications in these systems, providing a comparative analysis of key tasks such as Visual Question Answering (VQA), image captioning, and visual dialogue. Background: Multimodal models, particularly vision-language models, enhance artificial intelligence (AI) capabilities by integrating visual and textual data, mimicking human learning processes. Despite significant advancements, the trustworthiness of these models remains a crucial concern, particularly as AI systems increasingly confront issues regarding fairness, transparency, and ethics. Methods: This review examines research conducted from 2017 to 2024 focusing on forenamed core vision-language tasks. It employs a comparative approach to analyze these tasks through the lens of trustworthiness, underlining fairness, explainability, and ethics. This study synthesizes findings from recent literature to identify trends, challenges, and state-of-the-art solutions. Results: Several key findings were highlighted. Transparency: Explainability of vision language tasks is important for user trust. Techniques, such as attention maps and gradient-based methods, have successfully addressed this issue. Fairness: Bias mitigation in VQA and visual dialogue systems is essential for ensuring unbiased outcomes across diverse demographic groups. Ethical Implications: Addressing biases in multilingual models and ensuring ethical data handling is critical for the responsible deployment of vision-language systems. Conclusion: This study underscores the importance of integrating fairness, transparency, and ethical considerations in developing vision-language models within a unified framework.",
    "doi": "10.22133/ijwr.2025.503147.1264",
    "url": "https://www.semanticscholar.org/paper/0f81aa2e0e21e4a673eeabd2ca4f4c41009a8688",
    "pdf_url": "",
    "venue": "arXiv.org",
    "citation_count": 6,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:53.972808"
  },
  {
    "source": "semantic_scholar",
    "source_id": "00c3e0b19febce5d401c5955482e95dadaf184c0",
    "title": "Ethical issues in the development of artificial intelligence: recognizing the risks",
    "authors": [
      "M. K. Kamila",
      "S. Jasrotia"
    ],
    "year": 2023,
    "abstract": "\nPurpose\nThis study aims to analyse the ethical implications associated with the development of artificial intelligence (AI) technologies and to examine the potential ethical ramifications of AI technologies.\n\n\nDesign/methodology/approach\nThis study undertakes a thorough examination of existing academic literature pertaining to the ethical considerations surrounding AI. Additionally, it conducts in-depth interviews with individuals to explore the potential benefits and drawbacks of AI technology operating as autonomous ethical agents. A total of 20 semi-structured interviews were conducted, and the data were transcribed using grounded theory methodology.\n\n\nFindings\nThe study asserts the importance of fostering an ethical environment in the progress of AI and suggests potential avenues for further investigation in the field of AI ethics. The study finds privacy and security, bias and fairness, trust and reliability, transparency and human\u2013AI interactions as major ethical concerns.\n\n\nResearch limitations/implications\nThe implications of the study are far-reaching and span across various domains, including policy development, design of AI systems, establishment of trust, education and training, public awareness and further research. Notwithstanding the potential biases inherent in purposive sampling, the constantly evolving landscape of AI ethics and the challenge of extrapolating findings to all AI applications and contexts, limitations may still manifest.\n\n\nOriginality/value\nThe novelty of the study is attributed to its comprehensive methodology, which encompasses a wide range of stakeholder perspectives on the ethical implications of AI in the corporate sector. The ultimate goal is to promote the development of AI systems that exhibit responsibility, transparency and accountability.\n",
    "doi": "10.1108/ijoes-05-2023-0107",
    "url": "https://www.semanticscholar.org/paper/00c3e0b19febce5d401c5955482e95dadaf184c0",
    "pdf_url": "",
    "venue": "International Journal of Ethics and Systems",
    "citation_count": 53,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972809"
  },
  {
    "source": "semantic_scholar",
    "source_id": "e37771b7ba03bfe4920d9d36095c0416a44718be",
    "title": "Relational accountability in AI-driven pharmaceutical practices: an ethics approach to bias, inequity and structural harm",
    "authors": [
      "Irfan Biswas"
    ],
    "year": 2025,
    "abstract": "The integration of artificial intelligence (AI) into pharmaceutical practices raises critical ethical concerns, including algorithmic bias, data commodification and global health inequities. While existing AI ethics frameworks emphasise transparency and fairness, they often overlook structural vulnerabilities tied to race, gender and socioeconomic status. This paper introduces relational accountability\u2014a feminist ethics framework\u2014to critique AI-driven pharmaceutical practices, arguing that corporate reliance on biased algorithms exacerbates inequalities by design. Through case studies of Pfizer-IBM Watson\u2019s immuno-oncology collaboration and Google DeepMind\u2019s National Health Service partnership, we demonstrate how AI entrenches disparities in drug pricing, access and development. We propose a causal pathway linking biased training data to inequitable health outcomes, supported by empirical evidence of AI-driven price discrimination and exclusionary clinical trial recruitment algorithms. Policy solutions, including algorithmic audits and equity-centred data governance, are advanced to realign AI with the ethical imperative. This work bridges feminist bioethics and AI governance, offering a novel lens to address structural harm in healthcare innovation.",
    "doi": "10.1136/jme-2025-110913",
    "url": "https://www.semanticscholar.org/paper/e37771b7ba03bfe4920d9d36095c0416a44718be",
    "pdf_url": "",
    "venue": "Journal of Medical Ethics",
    "citation_count": 2,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:53.972811"
  },
  {
    "source": "semantic_scholar",
    "source_id": "9669421802618ad91bc6546406787a4688a86237",
    "title": "Evaluating Responsible AI Adaption: Ethics, Bias Mitigation, and Governance",
    "authors": [
      "AbdulQuddus Mohammed",
      "G. Khalifa",
      "Fatima Hasan Alhammadi"
    ],
    "year": 2025,
    "abstract": "With the emergence of Artificial Intelligence (AI) within the organizational decision-making process, the issue of trust, transparency, and ethical governance has become even more pressing. In this paper, five dimensions are examined, namely explainability, bias, fairness, mitigation measures, and regulatory regimes, as key determinants of the adoption of responsible AI systems. The study based on a structured questionnaire that was sent to AI professionals working in the main industries of the United Arab Emirates (UAE) shows that explainability and fairness are the most striking factors predicting stakeholder trust and adoption. Detection of bias, mitigation practices and regulatory clarity also have major roles albeit less substantially. The results emphasize the necessity of employing the multi-dimensional governance strategy that would involve technical transparency, as well as ethical and legal protection. This research provides practical recommendations to policymakers, industry players, and developers who want to create reliable AI systems that would resonate with the societal norms and legal standards.",
    "doi": "10.1109/ITT69610.2025.11352926",
    "url": "https://www.semanticscholar.org/paper/9669421802618ad91bc6546406787a4688a86237",
    "pdf_url": "",
    "venue": "Information Technology Trends",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972812"
  },
  {
    "source": "semantic_scholar",
    "source_id": "99f88b690adccc73ec29b2e3cf351f25b77252e0",
    "title": "Ethical Considerations in Artificial Intelligence Interventions for Mental Health and Well-Being: Ensuring Responsible Implementation and Impact",
    "authors": [
      "H. R. Saeidnia",
      "Seyed Ghasem Hashemi Fotami",
      "Brady D. Lund",
      "Nasrin Ghiasi"
    ],
    "year": 2024,
    "abstract": "AI has the potential to revolutionize mental health services by providing personalized support and improving accessibility. However, it is crucial to address ethical concerns to ensure responsible and beneficial outcomes for individuals. This systematic review examines the ethical considerations surrounding the implementation and impact of artificial intelligence (AI) interventions in the field of mental health and well-being. To ensure a comprehensive analysis, we employed a structured search strategy across top academic databases, including PubMed, PsycINFO, Web of Science, and Scopus. The search scope encompassed articles published from 2014 to 2024, resulting in a review of 51 relevant articles. The review identifies 18 key ethical considerations, including 6 ethical considerations associated with using AI interventions in mental health and wellbeing (privacy and confidentiality, informed consent, bias and fairness, transparency and accountability, autonomy and human agency, and safety and efficacy); 5 ethical principles associated with the development and implementation of AI technologies in mental health settings to ensure responsible practice and positive outcomes (ethical framework, stakeholder engagement, ethical review, bias mitigation, and continuous evaluation and improvement); and 7 practices, guidelines, and recommendations for promoting the ethical use of AI in mental health interventions (adhere to ethical guidelines, ensure transparency, prioritize data privacy and security, mitigate bias and ensure fairness, involve stakeholders, conduct regular ethical reviews, and monitor and evaluate outcomes). This systematic review highlights the importance of ethical considerations in the responsible implementation and impact of AI interventions for mental health and well-being. By addressing privacy, bias, consent, transparency, human oversight, and continuous evaluation, we can ensure that AI interventions like chatbots and AI-enabled medical devices are developed and deployed in an ethically sound manner, respecting individual rights, promoting fairness, and maximizing benefits while minimizing potential harm.",
    "doi": "10.3390/socsci13070381",
    "url": "https://www.semanticscholar.org/paper/99f88b690adccc73ec29b2e3cf351f25b77252e0",
    "pdf_url": "https://doi.org/10.3390/socsci13070381",
    "venue": "The social science",
    "citation_count": 86,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972814"
  },
  {
    "source": "semantic_scholar",
    "source_id": "07265044885834daaf6f5a1c2f278d6719d67e66",
    "title": "The Ethics of Artificial Intelligence in Education: Practices, Challenges, and Debates",
    "authors": [
      "Joshua Rose"
    ],
    "year": 2024,
    "abstract": "The book discusses the field of Artificial Intelligence in Education (AIED). The authors believe that AIED is a diverse field that encompasses aspects of philosophy, learning and teaching, research, and engineering. They argue that AIED practitioners need to take a broader approach to define the purpose of the field and be more engaged with more general societal issues. The authors call for AIED systems to be designed with transparency, accountability, and user control, to ensure fairness and equity in education. They also suggest a shift away from the traditional model of AI design, which assumes a fixed objective, to a more collaborative model that allows for negotiation between humans and AI to set individual goals.",
    "doi": "10.1080/0361526x.2024.2427948",
    "url": "https://www.semanticscholar.org/paper/07265044885834daaf6f5a1c2f278d6719d67e66",
    "pdf_url": "",
    "venue": "The Serials librarian",
    "citation_count": 32,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972815"
  },
  {
    "source": "semantic_scholar",
    "source_id": "d0e6c65649636bfd03d760cddc27ef5f9466e5f2",
    "title": "The Role of Artificial Intelligence in HR operations Challenges & Opportunities",
    "authors": [],
    "year": 2025,
    "abstract": "The integration of Artificial Intelligence (AI) into Human Resource (HR) operations is transforming traditional workforce management by enhancing efficiency, accuracy, and strategic decision-making. This paper explores the evolving role of AI in core HR functions such as talent acquisition, employee engagement, performance evaluation, and workforce analytics. AI-driven tools offer significant opportunities, including automation of repetitive tasks, data-driven insights for decision-making, and personalized employee experiences. However, the implementation of AI also introduces notable challenges such as data privacy concerns, algorithmic bias, lack of transparency, and resistance to change within organizations. This study examines both the transformative potential and the limitations of AI in HR, emphasizing the need for ethical governance, robust data strategies, and a balanced human-AI collaboration. The findings suggest that while AI presents substantial opportunities for innovation in HR practices, its successful integration requires careful planning, stakeholder engagement, and ongoing evaluation to ensure equitable and effective outcomes.",
    "doi": "10.46632/jdaai/4/2/6",
    "url": "https://www.semanticscholar.org/paper/d0e6c65649636bfd03d760cddc27ef5f9466e5f2",
    "pdf_url": "",
    "venue": "REST Journal on Data Analytics and Artificial Intelligence",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972816"
  },
  {
    "source": "semantic_scholar",
    "source_id": "3707dd2839d594fc093cbae85826cbca0f3e1b50",
    "title": "Artificial Intelligence and Legal Decision-Making in the USA and Pakistan: A Critical Appreciation of Regulatory Frameworks",
    "authors": [
      "Bakht Munir",
      "Akhtar Ali Ansari",
      "Yasir Arafat"
    ],
    "year": 2025,
    "abstract": "Artificial Intelligence (AI) is substituting human decision-making in every aspect of life where law stands with no exception. New technological trends offer expeditious and cost-effective AI tools yet confront challenges such as privacy invasion, bias, fairness, and hallucinations, necessitating regulatory oversight. Like other countries, the USA and Pakistan have initiated AI solutions in their legal domain. A strong regulatory oversight is indispensable for its legitimacy and efficiency. Based on their functions and ethical considerations, AI tools in the legal profession face competing opinions. With qualitative research methodology, the research aims to explore how AI is transforming and reshaping the legal regime, focused on the comparative analysis of the USA and Pakistan. The research paper critically examines the legal frameworks and impacts of AI solutions and how both countries navigate the complexities of AI-based decision-making.",
    "doi": "10.31703/gfpr.2024(vii-iv).06",
    "url": "https://www.semanticscholar.org/paper/3707dd2839d594fc093cbae85826cbca0f3e1b50",
    "pdf_url": "",
    "venue": "Global Foreign Policies Review",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972818"
  },
  {
    "source": "semantic_scholar",
    "source_id": "943cce23c69df7a53e547b38a16dc7395c5841d2",
    "title": "Using Artificial Intelligence (AI) as a Toolfor Inclusive Leadership in the Digital Era:Challenges, Opportunities and Implications",
    "authors": [
      "Tasneem Alkhateeb"
    ],
    "year": 2025,
    "abstract": "This paper explores the use of Artificial Intelligence (AI) in higher education institutions to enhance inclusive leadership. Inclusive leadership must support the ethical integration of AI to ensure it serves all students. Artificial intelligence has the ability to solve problems in education, improve teaching and learning methodologies, and accelerate progress towards long-term improvement. However, leaders face five top challenges in the age of artificial intelligence. These include: adapting to technological disruption, ethical issues, improving collaboration between humans and AI, leading workforce change, sustaining human leadership and fostering a moral culture. Leaders must understand the technical aspects, practical applications, and strategic implications of AI, prioritize continuous education, and create an adaptive culture. They must navigate ethical concerns like privacy, bias, fairness, and accountability, establish ethical leadership strategies, and ensure transparency in AI decisions. The study recommends strategies, including creating explicit criteria for the use of artificial intelligence, promoting digital literacy and ensuring that the impact of its technologies on learning is continuously evaluated.",
    "doi": "10.64851/csi.v1i1.27",
    "url": "https://www.semanticscholar.org/paper/943cce23c69df7a53e547b38a16dc7395c5841d2",
    "pdf_url": "",
    "venue": "Crossroads of Social Inquiry",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972820"
  },
  {
    "source": "semantic_scholar",
    "source_id": "976deefce3ce6607d30827023a9d321052ef25b7",
    "title": "Human-in-the-loop: Explainable or accurate artificial intelligence by exploiting human bias?",
    "authors": [
      "L. Valtonen",
      "S. M\u00e4kinen"
    ],
    "year": 2022,
    "abstract": "Artificial intelligence (AI) is a major contributor in industry 4.0 and there exists a strong push for AI adoption across fields for both research and practice. However, AI has quite well elaborated risks for both business and general society. Hence, paying attention to avoiding hurried adoption of counter-productive practices is important. For both managerial and general social issues, the same solution is sometimes proposed: human-in-the-loop (HITL). However, HITL literature is contradictory: HITL is proposed to promote fairness, accountability, and transparency of AI, which are sometimes assumed to come at the cost of AI accuracy. Yet, HITL is also considered a way to improve accuracy. To make sense of the convoluted literature, we begin to explore qualitatively how explainability is constructed in a HITL process, and how method accuracy is affected as its function. To do this, we study qualitatively and quantitatively a multi-class classification task with multiple machine learning algorithms. We find that HITL can increase both accuracy and explainability, but not without deliberate effort to do so. The effort required to achieve both increased accuracy and explainability, requires an iterative HITL in which accuracy improvements are not continuous, but disrupted by unique and varying human biases shedding additional perspectives on the task at hand.",
    "doi": "10.1109/ICE/ITMC-IAMOT55089.2022.10033225",
    "url": "https://www.semanticscholar.org/paper/976deefce3ce6607d30827023a9d321052ef25b7",
    "pdf_url": "",
    "venue": "2022 IEEE 28th International Conference on Engineering, Technology and Innovation (ICE/ITMC) & 31st International Association For Management of Technology (IAMOT) Joint Conference",
    "citation_count": 3,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972821"
  },
  {
    "source": "semantic_scholar",
    "source_id": "b5c7f6016afdd03d41f5c0e4f8679bd4c46a3871",
    "title": "Towards a Human-Centred Artificial Intelligence Maturity Model",
    "authors": [
      "Mia Hartikainen",
      "Kaisa V\u00e4\u00e4n\u00e4nen",
      "Thomas Olsson"
    ],
    "year": 2023,
    "abstract": "Artificial intelligence (AI) is becoming a central building block of computational systems. Following the long traditions of human-centered design, Human-Centered AI (HCAI) emphasises the importance of putting humans and various societal considerations in the centre of the development. However, the question is: how to realise HCAI when designing systems that utilise novel computational tools and require consideration of increasingly broad set of requirements, spanning from fairness and transparency to accountability and ethics? The purpose of our study is to support the AI development practices in companies in order for the humans to have AI solutions that are efficient, trustworthy, and safe. To this end, we propose a maturity model for HCAI (HCAI-MM). In this paper we present the first phase of the model development, in which the central building blocks of HCAI are specified and initial company requirements for the model's structure and content are evaluated with four AI developers.",
    "doi": "10.1145/3544549.3585752",
    "url": "https://www.semanticscholar.org/paper/b5c7f6016afdd03d41f5c0e4f8679bd4c46a3871",
    "pdf_url": "https://doi.org/10.1145/3544549.3585752",
    "venue": "CHI Extended Abstracts",
    "citation_count": 17,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:53.972823"
  },
  {
    "source": "semantic_scholar",
    "source_id": "419d0d4b9c407e6c7bca21af84c33e177530ffbe",
    "title": "The accuracy-bias trade-offs in AI text detection tools and their impact on fairness in scholarly publication",
    "authors": [
      "Ahmad R. Pratama"
    ],
    "year": 2025,
    "abstract": "Artificial intelligence (AI) text detection tools are considered a means of preserving the integrity of scholarly publication by identifying whether a text is written by humans or generated by AI. This study evaluates three popular tools (GPTZero, ZeroGPT, and DetectGPT) through two experiments: first, distinguishing human-written abstracts from those generated by ChatGPT o1 and Gemini 2.0 Pro Experimental; second, evaluating AI-assisted abstracts where the original text has been enhanced by these large language models (LLMs) to improve readability. Results reveal notable trade-offs in accuracy and bias, disproportionately affecting non-native speakers and certain disciplines. This study highlights the limitations of detection-focused approaches and advocates a shift toward ethical, responsible, and transparent use of LLMs in scholarly publication.",
    "doi": "10.7717/peerj-cs.2953",
    "url": "https://www.semanticscholar.org/paper/419d0d4b9c407e6c7bca21af84c33e177530ffbe",
    "pdf_url": "",
    "venue": "PeerJ Computer Science",
    "citation_count": 5,
    "fields_of_study": [
      "Computer Science",
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:53.972824"
  },
  {
    "source": "semantic_scholar",
    "source_id": "e5dd5fa615f8cf1e21ed5d6f8656513437f465e1",
    "title": "Artificial Intelligence for Promoting Equity, Diversity, and Inclusion",
    "authors": [
      "Mazdak Zamani",
      "Ali Motamedi",
      "Sasan Karamizadeh",
      "T. Khodadadi",
      "M. Alizadeh",
      "Saman Shojae Chaeikar"
    ],
    "year": 2025,
    "abstract": "In the pursuit of a more inclusive, equitable, and diverse workplace, many organizations are turning to artificial intelligence as a transformative approach to enhance hiring practices. By automating resume evaluations, AI systems can reduce the impact of human biases that often lead to the underrepresentation of certain demographic groups. However, the use of AI in recruitment presents its own set of challenges, including the potential for biased algorithms, lack of transparency, and over-reliance on automation. This paper explores the benefits, challenges, and limitations of using AI to assess resumes, with a particular focus on how AI can enhance EDI in hiring practices. Through the review of various AI tools and case studies, the paper examines how AI can be leveraged to promote fairness, consistency, and access to diverse talent pools. Additionally, the paper discusses solutions to mitigate the risks of bias, such as diversifying training datasets, increasing transparency through explainable AI models, and ensuring human oversight in decision-making. Ultimately, this paper provides recommendations for organizations seeking to integrate AI into their recruitment process while ensuring that it fosters an inclusive and equitable hiring environment.",
    "doi": "10.1109/ACDSA65407.2025.11166379",
    "url": "https://www.semanticscholar.org/paper/e5dd5fa615f8cf1e21ed5d6f8656513437f465e1",
    "pdf_url": "",
    "venue": "2025 International Conference on Artificial Intelligence, Computer, Data Sciences and Applications (ACDSA)",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972826"
  },
  {
    "source": "semantic_scholar",
    "source_id": "8ac78c62df01109719d88d23706d857c71923b58",
    "title": "The potential and risks of artificial intelligence in promoting personalized learning",
    "authors": [
      "Jiang Qiang"
    ],
    "year": 2025,
    "abstract": ": As a significant advancement in the field of technology, Artificial Intelligence (AI) has achieved automation of specific tasks by simulating and enhancing human cognitive functions. In the field of education, AI has notably promoted the development of personalized learning. By analyzing learning data, AI can identify students' learning patterns and provide targeted academic guidance, enabling real-time feedback and dynamic adjustments to learning content. Additionally, AI offers personalized learning resources and auxiliary tools to enhance motivation and efficiency in learning. However, the application of AI in personalized learning also faces risks such as privacy and data security, algorithmic bias, and educational equity. To address these challenges, strict data protection measures must be taken to ensure algorithmic fairness and to promote the equitable distribution of educational resources.",
    "doi": "10.23977/jaip.2025.080112",
    "url": "https://www.semanticscholar.org/paper/8ac78c62df01109719d88d23706d857c71923b58",
    "pdf_url": "",
    "venue": "Journal of Artificial Intelligence Practice",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972827"
  },
  {
    "source": "semantic_scholar",
    "source_id": "62701f25325275973371486ec5f9972e64133f51",
    "title": "Leverage Generative AI for human resource management: integrated risk analysis approach",
    "authors": [
      "Ying Jiang",
      "Ziming Cai",
      "Xiaojun Wang"
    ],
    "year": 2025,
    "abstract": null,
    "doi": "10.1080/09585192.2025.2544972",
    "url": "https://www.semanticscholar.org/paper/62701f25325275973371486ec5f9972e64133f51",
    "pdf_url": "",
    "venue": "",
    "citation_count": 3,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972828"
  },
  {
    "source": "semantic_scholar",
    "source_id": "c1986252349bb67d8a769b065391c273e42c26f3",
    "title": "Explanations as Bias Detectors: A Critical Study of Local Post-hoc XAI Methods for Fairness Exploration",
    "authors": [
      "Vasiliki Papanikou",
      "Danae Pla Karidi",
      "E. Pitoura",
      "Emmanouil Panagiotou",
      "E. Ntoutsi"
    ],
    "year": 2025,
    "abstract": "As Artificial Intelligence (AI) is increasingly used in areas that significantly impact human lives, concerns about fairness and transparency have grown, especially regarding their impact on protected groups. Recently, the intersection of explainability and fairness has emerged as an important area to promote responsible AI systems. This paper explores how explainability methods can be leveraged to detect and interpret unfairness. We propose a pipeline that integrates local post-hoc explanation methods to derive fairness-related insights. During the pipeline design, we identify and address critical questions arising from the use of explanations as bias detectors such as the relationship between distributive and procedural fairness, the effect of removing the protected attribute, the consistency and quality of results across different explanation methods, the impact of various aggregation strategies of local explanations on group fairness evaluations, and the overall trustworthiness of explanations as bias detectors. Our results show the potential of explanation methods used for fairness while highlighting the need to carefully consider the aforementioned critical aspects.",
    "doi": "10.48550/arXiv.2505.00802",
    "url": "https://www.semanticscholar.org/paper/c1986252349bb67d8a769b065391c273e42c26f3",
    "pdf_url": "",
    "venue": "arXiv.org",
    "citation_count": 1,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:53.972830"
  },
  {
    "source": "semantic_scholar",
    "source_id": "b5a2ece8d75985eaedead63b6508bddf8ff6a723",
    "title": "Bias in Adjudication and the Promise of AI: Challenges to Procedural Fairness",
    "authors": [
      "Giovana Lopes"
    ],
    "year": 2025,
    "abstract": "Empirical research demonstrates that judges are prone to cognitive and social biases, both of which can reduce the accuracy of judgements and introduce extra-legal influences on judicial decisions. While these findings raise the important question of how to mitigate the effects of judicial bias, they have also been used to argue in favour of incorporating artificial intelligence (AI) into adjudication, either as decision aids or, in a more extreme way, to fully automate judicial tasks. The argument goes as follows: if human judgement is susceptible to biases, and if the human psyche is also inscrutable, would it not be better to replace it with AI? After all, AI promises greater accuracy and consistency and can replace biased human decisions with objective automated ones. However, the use of AI by courts requires careful deliberation, as it potentially introduces new challenges, particularly concerning procedural fairness. This article seeks to explore how the use of AI in the administration of justice can challenge some of the foundational elements of the right to a fair trial, as enshrined in Article 6 of the European Convention on Human Rights (ECHR). This analysis is conducted through the theoretical framework of procedural justice, arguing that the use of AI for judicial decision-making can negatively impact perceptions of procedural fairness in ways that traditional human adjudication does not. It therefore seeks to debunk the narrative that, at least where bias is concerned, human and artificial decision-making are equally problematic.",
    "doi": "10.5204/lthj.3812",
    "url": "https://www.semanticscholar.org/paper/b5a2ece8d75985eaedead63b6508bddf8ff6a723",
    "pdf_url": "",
    "venue": "Law, Technology and Humans",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972831"
  },
  {
    "source": "semantic_scholar",
    "source_id": "8b987b810a5d0de7bb92abd21a039fcfc87787ec",
    "title": "Bias and Fairness in Automated Loan Approvals: A Systematic Review of Machine Learning Approaches",
    "authors": [
      "Suraiyo Raziyeva",
      "Meraryslan Meraliyev"
    ],
    "year": 2025,
    "abstract": "\n\n\nArtificial intelligence (AI) is increasingly transforming credit approval processes, enabling financial institutions to assess risk more efficiently and at greater scale. As these systems become more embedded in lending decisions, concerns around fairness, bias, and accountability have grown significantly. Many of these concerns stem from the use of historical data, proxy variables, and model optimization choices that can unintentionally reinforce existing social and economic inequalities. This work presents a systematic overview of the types and sources of bias in AI - driven loan approval systems and critically examines how machine learning techniques attempt to address them. It also highlights emerging solutions, including explainable AI, federated learning, human-in-the-loop frameworks, and intersectional fairness approaches. Despite ongoing advancements, unresolved challenges remain - particularly the need for dynamic fairness monitoring and for addressing intersectional biases affecting individuals from multiple marginalized groups. To bridge these gaps, the paper emphasizes the importance of interdisciplinary collaboration among AI developers, regulatory bodies, and social scientists. It advocates embedding fairness as a core design principle in the development and deployment of future AI systems. Overall, this study contributes to the growing effort to develop more transparent, inclusive, and socially responsible financial technologies.\n\n\n",
    "doi": "10.47344/jbzmnx25",
    "url": "https://www.semanticscholar.org/paper/8b987b810a5d0de7bb92abd21a039fcfc87787ec",
    "pdf_url": "",
    "venue": "Journal of Emerging Technologies and Computing",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972833"
  },
  {
    "source": "semantic_scholar",
    "source_id": "b756c2e60621e813616554299d7493c038e519a2",
    "title": "AI in human resource management",
    "authors": [
      "Janine Berg",
      "Hannah Johnston"
    ],
    "year": 2025,
    "abstract": "The rapid integration of artificial intelligence (AI) into Human Resource Management (HRM) is transforming how organizations recruit, manage, and evaluate their workforces. While proponents champion AI as a means to enhance efficiency, reduce bias, and align HR practices with strategic business goals, this paper argues that such optimism is misplaced. Drawing on a critical review of AI's application across four core HRM functions\u2014recruitment, compensation, scheduling, and performance management\u2014this paper identifies significant risks and limitations arising from the fundamental structure of AI systems. Central to the analysis is a three-parameter framework for assessing AI tools: their objective, the data they rely upon, and how they are programmed. The paper shows that across HR functions, AI systems frequently operationalize reductive or poorly aligned objectives, rely on low-quality or biased data, and are programmed in non-transparent ways that undermine their usefulness. These structural shortcomings not only undermine the effectiveness of AI systems but also introduce legal, ethical, and practical risks for firms and their workers.",
    "doi": "10.54394/nmsh7611",
    "url": "https://www.semanticscholar.org/paper/b756c2e60621e813616554299d7493c038e519a2",
    "pdf_url": "",
    "venue": "",
    "citation_count": 2,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972834"
  },
  {
    "source": "semantic_scholar",
    "source_id": "df0676b6fb13abd16657e321350675f318b9175e",
    "title": "Ethical and Legal Implications of AI in Human Resource Management",
    "authors": [
      "Hamza Ghazanfar",
      "Ayaz Ul Haq"
    ],
    "year": 2025,
    "abstract": "The rapid-fire integration of Artificial Intelligence (AI) in Human Resource Management (HRM) has steered in transformative edge in reclamation, gift accession, performance evaluation, and hand engagement. Still, this progress isn't without substantial ethical and legal enterprises. This narrative review synthesizes findings from six crucial studies including abstract analyses, empirical checks, and legal reviews to critically examine the pressing counteraccusations of AI deployment in HRM across global and indigenous surrounds.\u00a0\u00a0 The review reveals a strong agreement around several core challenges warrant of translucency and explain ability in AI- driven opinions, the perpetuation of algorithmic bias, violations of data sequestration rights, and unclear legal responsibility in cases of demarcation or detriment. Studies similar as Harper & Millard (2023) and Du (2024) highlight crunches in current employment laws, particularly in regulating automated decision- timber, while Cheong (2024) underscores the ethical pitfalls posed by opaque AI systems and calls for integrated governance fabrics. Empirical substantiation from Khan et al. (2023) and Nawaz (2023) further illustrates how AI relinquishment in reclamation can affect in perceived unfairness, especially when stakeholders are barred from the design process or when systems are trained on prejudiced data. In developing surrounds like Nigeria and Pakistan, structural constraints including limited structure, low AI knowledge, and weak nonsupervisory oversight \u2014 emulsion these pitfalls, as reported by Elenwo (2025) and Khan et al. (2023).\u00a0\u00a0 The methodology across these studies is varied, ranging from quantitative checks and retrogression analysis to legal converse and thematic conflation. Despite this diversity, a common limitation is apparent a lack of longitudinal, relative, and hand- centered exploration, which impedes a holistic understanding of AI\u2019s long- term impact on pool rights and organizational equity.\u00a0\u00a0 In response, this review advocates for a multifaceted approach that combines legal modernization, ethical checkups, stakeholder participation, and capacity- structure measures. It proposes that effective AI governance in HRM must be both environment-sensitive and rights- driven \u2014 balancing invention with responsibility, and robotization with inclusivity.\u00a0\u00a0 This study contributes to the evolving converse on Responsible AI in HR by relating nonsupervisory gaps, ethical eyeless spots, and stylish practices for indifferent integration. It aims to support HR leaders, policymakers, and technologists in designing AI systems that aren't only effective, but also fair, transparent, and aligned with transnational labor and mortal rights norms.",
    "doi": "10.56976/jsom.v4i2.254",
    "url": "https://www.semanticscholar.org/paper/df0676b6fb13abd16657e321350675f318b9175e",
    "pdf_url": "",
    "venue": "Journal of Social &amp; Organizational Matters",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972836"
  },
  {
    "source": "semantic_scholar",
    "source_id": "d94a928e897f2f3016f7200c20906dac202f4a6e",
    "title": "EXPLORING THE ROLE OF ARTIFICIAL INTELLIGENCE IN TRANSFORMING HR PRACTICES",
    "authors": [
      "Md. Masudul",
      "Haque Bhuiyan",
      "Kripa Nath",
      "Palash Saha",
      "Pankaj Kumar Sarker",
      "Md. Tanjil Biswas"
    ],
    "year": 2025,
    "abstract": "This study explores the role of Artificial Intelligence (AI) in transforming Human Resource (HR) practices, focusing on its impact on recruitment, employee engagement, performance management, and overall HR efficiency. Through a survey of 300 HR professionals, managers, and employees, the research evaluates the benefits and challenges of AI adoption in HR functions. The findings reveal that AI enhances efficiency, reduces biases in recruitment and performance evaluations, and improves employee satisfaction through personalized experiences. However, challenges such as high implementation costs, concerns about algorithmic bias, data privacy issues, and resistance to change were identified as barriers to successful AI adoption. The study concludes that while AI offers significant advantages for HR practices, organizations must address these challenges through training, transparency, and careful implementation to fully leverage AI's potential.",
    "doi": "10.35409/ijbmer.2025.3646",
    "url": "https://www.semanticscholar.org/paper/d94a928e897f2f3016f7200c20906dac202f4a6e",
    "pdf_url": "https://doi.org/10.35409/ijbmer.2025.3646",
    "venue": "International Journal of Business Management and Economic Review",
    "citation_count": 5,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972837"
  },
  {
    "source": "semantic_scholar",
    "source_id": "3695a2fee84fb634764c06b7e2f3ce78092353dd",
    "title": "Algorithmic Bias and Data Justice: ethical challenges in Artificial Intelligence Systems",
    "authors": [
      "Javier Gonz\u00e1lez-Argote",
      "E. Maldonado",
      "Karina Maldonado"
    ],
    "year": 2025,
    "abstract": "This article examines the critical ethical challenges posed by algorithmic bias in artificial intelligence (AI) systems, focusing on its implications for social justice and data equity. Through a systematic review of case studies and theoretical frameworks, we analyze how biased datasets and algorithmic designs perpetuate structural inequalities, particularly affecting marginalized communities. The study highlights key examples, such as gender and racial biases in facial recognition and hiring algorithms, while exploring mitigation strategies rooted in data justice principles. Additionally, we evaluate regulatory responses, including the European Union's AI Act, which proposes a risk-based governance framework. The findings underscore the urgent need for interdisciplinary approaches to develop fairer AI systems that align with ethical standards and human rights.",
    "doi": "10.56294/ai2025159",
    "url": "https://www.semanticscholar.org/paper/3695a2fee84fb634764c06b7e2f3ce78092353dd",
    "pdf_url": "",
    "venue": "EthAIca",
    "citation_count": 4,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972839"
  },
  {
    "source": "semantic_scholar",
    "source_id": "686a744eb2bca0e7645e0f1953a09418c4f76d73",
    "title": "The rise of AI in human resource management: A systematic review of task automation through PRISMA",
    "authors": [
      "Kawthar Bouzerda",
      "Selimane Hani",
      "Hasnae Rahmani",
      "Ali Hebaz",
      "Abdessamad Dibi",
      "Hasna Mharzi"
    ],
    "year": 2025,
    "abstract": "Objective:\u00a0This study synthesizes current evidence on the role of Artificial Intelligence (AI)\u00a0and, where relevant, Open Science (OS) practices\u00a0in enhancing Human Resource Management (HRM) performance. It focuses on recruitment processes, ethical considerations, and employee participation. Methodology:\u00a0A systematic literature review was conducted in Scopus covering the period 2019\u20132024, following PRISMA guidelines. The initial search yielded 1486 records. After de-duplication and screening using Rayyan, 66 studies (\u2248 4.4%) met the inclusion criteria, which targeted peer-reviewed works addressing AI-supported HR decision-making. A combined content and bibliometric analysis was performed in R (Bibliometrix) to identify thematic patterns and conceptual structures. Results:\u00a0Analysis revealed four thematic clusters: 1) Implementation and employee participation emphasizing human-in-the-loop approaches and effective change management; 2) ethical challenges including algorithmic bias, transparency gaps, and data privacy risks; 3) data-driven decision-making delivering higher accuracy, fewer errors, and personalized recruitment and performance assessment; 4) operational efficiency enabling faster workflows and reduced administrative workloads. AI tools consistently improved selection quality, while OS practices promoted transparency and knowledge sharing. Implications:\u00a0The successful adoption of AI in HRM requires employee engagement, strong ethical safeguards, and transparent data governance. Future research should address the long-term cultural, organizational, and well-being impacts of AI\u00a0integration, as well as its sustainability.",
    "doi": "10.18282/hrms4595",
    "url": "https://www.semanticscholar.org/paper/686a744eb2bca0e7645e0f1953a09418c4f76d73",
    "pdf_url": "",
    "venue": "Human Resources Management and Services",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972846"
  },
  {
    "source": "semantic_scholar",
    "source_id": "375228b06b8bce65db6b8e7324694392a0748279",
    "title": "Implication of AI in Transforming Human Resource Development",
    "authors": [
      "Subhrodipto Basu Choudhury",
      "Soma Garani",
      "S. Majumder"
    ],
    "year": 2025,
    "abstract": "This paper presents a systematic conceptual review of the application of Artificial Intelligence (AI) in Human Resource Management (HRM). Human resources form the backbone of organizations, and the integration of AI technologies is transforming key HR functions such as recruitment, training and development, performance management, compensation, grievance redressal, and retirement planning. This study synthesizes peer-reviewed literature published between 2018 and 2024 drawn from databases such as Scopus, Web of Science, Google Scholar, and major academic publishers. The review identifies how AI enhances efficiency, reduces bias, supports strategic decision-making, and improves employee experience, while emphasizing that human judgment remains essential in ethical and relational domains.",
    "doi": "10.63015/3ai-2482.2.5",
    "url": "https://www.semanticscholar.org/paper/375228b06b8bce65db6b8e7324694392a0748279",
    "pdf_url": "",
    "venue": "Current Natural Sciences and Engineering",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972847"
  },
  {
    "source": "semantic_scholar",
    "source_id": "8b16d313557ad698550c3a793b7faac8e82bb513",
    "title": "Advantages and ethics of artificial intelligence in plastic and reconstructive surgery",
    "authors": [
      "Dylan Treger",
      "Griffin Harris",
      "S. Thaller"
    ],
    "year": 2025,
    "abstract": "As artificial intelligence (AI) technologies evolve in sophistication, they offer the potential to benefit various aspects of plastic and reconstructive surgery practice. From enhancing surgical precision within the operating room to streamlining administrative tasks and supporting the diagnosis and treatment of patients, AI may grow into an invaluable tool that redefines standards of care within plastic surgery. Given the nascent and largely theoretical role of AI in plastic surgery, numerous questions arise regarding its safety, actual utility, ethical considerations, and policies needed to regulate its use. This manuscript aims to provide commentary on AI in healthcare and to discuss an alternative viewpoint of its use in plastic surgery. Americans remain hesitant about healthcare providers leveraging AI in their care. Ongoing scrutiny is required to protect patients from unintended sequelae, safeguard their privacy, mitigate bias, and reduce harm. Early legislation by the United States federal government has aimed to define a role for AI in healthcare, yet more explicit guidance is required. Uncertainty in medico-legal implications begs the question of where liability would fall if AI use causes adverse outcomes. If applied appropriately, AI may ultimately improve patient outcomes and satisfaction with their plastic surgery care. With less energy dedicated toward automatable tasks and tools that push the envelope of human performance, plastic surgeons may be better equipped to care for their patients. We advocate for a cautiously optimistic approach to AI\u2019s incorporation within plastic and reconstructive surgery.",
    "doi": "10.20517/ais.2024.66",
    "url": "https://www.semanticscholar.org/paper/8b16d313557ad698550c3a793b7faac8e82bb513",
    "pdf_url": "https://doi.org/10.20517/ais.2024.66",
    "venue": "Artificial Intelligence Surgery",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972849"
  },
  {
    "source": "semantic_scholar",
    "source_id": "e7cdb9d070cd74944f91a99cf178174f6d2ac2b0",
    "title": "Artificial intelligence (AI) in health systems: introducing a \u2018Do Good\u2019 approach",
    "authors": [
      "Elsa Papadopoulou",
      "T. Exarchos",
      "Sasa Jenko",
      "Katarina Krepelkova",
      "Joana Namorado"
    ],
    "year": 2025,
    "abstract": null,
    "doi": "10.1007/s43681-025-00757-x",
    "url": "https://www.semanticscholar.org/paper/e7cdb9d070cd74944f91a99cf178174f6d2ac2b0",
    "pdf_url": "",
    "venue": "AI and Ethics",
    "citation_count": 1,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:53.972850"
  },
  {
    "source": "semantic_scholar",
    "source_id": "c52172d98826c2f1196c5aecd537694d2d773838",
    "title": "Ethics in the Age of Artificial Intelligence",
    "authors": [
      "B\u00fc\u015fra Tural",
      "Zeynep \u00d6rpek",
      "Zeynep Destan"
    ],
    "year": 2025,
    "abstract": "Artificial Intelligence (AI) technologies are transforming many sectors by causing radical changes in the modern world. AI solutions that accelerate processes, increase efficiency, and improve decision-making mechanisms in areas such as health, finance, education, and transportation also bring with them important discussions in terms of ethics, security, and social harmony. In this context, the need for AI applications to be developed in a reliable, fair, and transparent manner is becoming increasingly important.The concept of \u201cResponsible AI\u201d aims to design and implement AI in a way that respects human rights, is free from discrimination, is accountable, and is compatible with social values. The neutrality of algorithms, the protection of personal data, and the risk that AI applications may produce biased or erroneous outputs make it necessary to manage this technology in line with ethical principles. Ensuring public trust and increasing social acceptance of AI is a critical requirement for sustainable and successful innovation processes. In this context, various control mechanisms have been developed to ensure the security of AI applications and their compliance with ethical rules.This study examines the necessity of a responsible AI approach, how it should be shaped within the framework of ethical principles, and the security mechanisms used in this context. Considering the long-term societal impacts of AI, the importance of protecting individual rights as well as creating a reliable and sustainable framework for companies and public institutions is emphasized. In particular, the examination of security tools such as Llama Guard is examined, and how they play a critical role in the process of responsible management of AI.",
    "doi": "10.1109/AICCONF64766.2025.11064304",
    "url": "https://www.semanticscholar.org/paper/c52172d98826c2f1196c5aecd537694d2d773838",
    "pdf_url": "",
    "venue": "2025 3rd Cognitive Models and Artificial Intelligence Conference (AICCONF)",
    "citation_count": 3,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:53.972852"
  },
  {
    "source": "semantic_scholar",
    "source_id": "405960c1a6407f0d4537ac33a737574f66884c52",
    "title": "Artificial Intelligence in Talent Acquisition: A Paradigm Shift in HRM Practices",
    "authors": [
      "Chirag Harchandani"
    ],
    "year": 2025,
    "abstract": "The birth of artificial intelligence was between 1950-1956 but AI in HRM practices was used first in the 2000s. This rapid advancement of AI has significantly transformed Human Resource Management Practices. AI-based systems currently help HR automate a large segment of repetitive tasks in processes such as talent screening, hiring, engaging, re-engaging, employee relations, onboarding, etc, which used to be a long and hectic task before the introduction of automated tools. Nevertheless, these automated practices raise ethical concerns about bias, transparency, and how AI may undermine human judgment. The focus of this paper is to discuss and analyze the present scenario of AI in the field of HR. It has suggested that AI has the potential to optimize HRM practices leading to higher efficiency and cost-cutting, while also exposing several other challenges and risks such as data privacy and security, job disarticulation, and diminished autonomy for employees. By doing a real-world experiment on a normal and ATS-friendly resume and reviewing case studies such as an ATS rejecting a company\u2019s own manager, this research investigates the balance between AI efficiency and human judgment.",
    "doi": "10.55544/sjmars.4.1.1",
    "url": "https://www.semanticscholar.org/paper/405960c1a6407f0d4537ac33a737574f66884c52",
    "pdf_url": "",
    "venue": "Stallion Journal for Multidisciplinary Associated Research Studies",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972853"
  },
  {
    "source": "semantic_scholar",
    "source_id": "b4bab7a5413d44f0f2443a6e3345d21564926b36",
    "title": "The Power of Artificial Intelligence in Recruitment: A Theoretical Analysis of Current AI-Based Recruitment Strategies",
    "authors": [
      "Sayeed Arshad Raza"
    ],
    "year": 2025,
    "abstract": "Abstract: This report critically examines the burgeoning integration of Artificial Intelligence (AI) within recruitment processes, dissecting the inherent tension between aspirations for heightened efficiency and the crucial imperative of maintaining ethical standards. By examining AI tools used in pre-screening, candidate engagement, and evaluation through the diverse frameworks of Human Capital Theory, Organizational Justice Theory, the Technology Acceptance Model (TAM), and Critical Theory, this study highlights underlying concerns such as algorithmic bias, the risk of impersonal or dehumanized candidate experiences, and the diminishing protection of applicant privacy. It contributes a novel and comprehensive framework meticulously designed for evaluating AI recruitment strategies, integrating disparate theoretical perspectives to furnish practical guidance for both Human Resource (HR) professionals and AI vendors. Emphasizing the necessity of rigorous ethical audits, algorithmic transparency, the indispensable role of human oversight, and a steadfast commitment to responsible AI development and deployment, the report advocates for proactive measures to ensure fairness, inclusivity, and a positive candidate experience. Furthermore, it identifies promising avenues for future research, including longitudinal studies to assess long-term impacts on diversity and the development of robust and reliable fairness metrics\n\nKeywords: AI, Recruitment, Algorithmic Bias, Fairness, Candidate Experience, Human Resources, Ethics, Theoretical Framework, Organizational Justice, Human Capital Theory, Technology Acceptance Model, Critical Theory.",
    "doi": "10.55041/ijsrem49671",
    "url": "https://www.semanticscholar.org/paper/b4bab7a5413d44f0f2443a6e3345d21564926b36",
    "pdf_url": "",
    "venue": "INTERNATIONAL JOURNAL OF SCIENTIFIC RESEARCH IN ENGINEERING AND MANAGEMENT",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972855"
  },
  {
    "source": "semantic_scholar",
    "source_id": "d91aa0d28406ee2a31acca6040e750988c7582cb",
    "title": "AI Ethics: Integrating Transparency, Fairness, and Privacy in AI Development",
    "authors": [
      "P. Radanliev"
    ],
    "year": 2025,
    "abstract": "ABSTRACT The expansion of Artificial Intelligence in sectors such as healthcare, finance, and communication has raised critical ethical concerns surrounding transparency, fairness, and privacy. Addressing these issues is essential for the responsible development and deployment of AI systems. This research establishes a comprehensive ethical framework that mitigates biases and promotes accountability in AI technologies. A comparative analysis of international AI policy frameworks from regions including the European Union, United States, and China is conducted using analytical tools such as Venn diagrams and Cartesian graphs. These tools allow for a visual and systematic evaluation of the ethical principles guiding AI development across different jurisdictions. The results reveal significant variations in how global regions prioritize transparency, fairness, and privacy, with challenges in creating a unified ethical standard. To address these challenges, we propose technical strategies, including fairness-aware algorithms, routine audits, and the establishment of diverse development teams to ensure ethical AI practices. This paper provides actionable recommendations for integrating ethical oversight into the AI lifecycle, advocating for the creation of AI systems that are both technically sophisticated and aligned with societal values. The findings underscore the necessity of global collaboration in fostering ethical AI development.",
    "doi": "10.1080/08839514.2025.2463722",
    "url": "https://www.semanticscholar.org/paper/d91aa0d28406ee2a31acca6040e750988c7582cb",
    "pdf_url": "",
    "venue": "Applied Artificial Intelligence",
    "citation_count": 111,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:53.972856"
  },
  {
    "source": "semantic_scholar",
    "source_id": "3681a4af812501dbe79dfddbccec1fc88a6caa01",
    "title": "Artificial Intelligence in Trauma and Orthopaedic Surgery: A Comprehensive Review From Diagnosis to Rehabilitation",
    "authors": [
      "Ahmed M Mohamed",
      "Alaa Elasad",
      "Usman Fuad",
      "Ioannis P Pengas",
      "Adham Elsayed",
      "Prabhakar Bhamidipati",
      "Peter Salib"
    ],
    "year": 2025,
    "abstract": "Artificial intelligence (AI) has presented clinical maturity in healthcare applications. AI is reshaping orthopaedic practice by enhancing the speed and efficiency of clinical decision-making, surgical planning, and research workflows. AI enables clinicians to optimize the care pathway through rapid data processing, pattern recognition, and predictive modelling. This review examines the current AI applications across the entire spectrum of orthopaedic care and its contribution to patient care and resource utilization. Despite these promising developments, several barriers prevent widespread adoption, including concerns regarding algorithm transparency, data privacy, potential bias in training datasets, and implementation costs. The path forward requires the development of explainable AI systems that clinicians can trust and validate. As AI technology continues to evolve, success will depend on augmenting human judgment with machine precision to deliver optimal care for patients with musculoskeletal conditions.",
    "doi": "10.7759/cureus.92280",
    "url": "https://www.semanticscholar.org/paper/3681a4af812501dbe79dfddbccec1fc88a6caa01",
    "pdf_url": "",
    "venue": "Cureus",
    "citation_count": 4,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:53.972858"
  },
  {
    "source": "semantic_scholar",
    "source_id": "fde840d002673ff67a709c9964dda775f80e969f",
    "title": "Applications and challenges of artificial intelligence-driven 3D vision in biomedical engineering: A biomechanics perspective",
    "authors": [
      "Lei Wang",
      "Zunjie Zhu"
    ],
    "year": 2025,
    "abstract": "This paper explores the applications and challenges of artificial intelligence (AI)-driven 3D vision technology in biomedical engineering, with a specific focus on its integration with biomechanics. 3D vision technology offers richer spatial information compared to traditional 2D imaging and is increasingly applied in fields like medical image analysis, surgical navigation, lesion detection, and biomechanics. In biomechanics, AI-driven 3D vision is used for analyzing human movement, modeling musculoskeletal systems, and assessing joint biomechanics. However, challenges persist, including image quality, computational resource demands, data privacy, and algorithmic bias. This paper reviews the development of 3D vision technology and AI, discusses its applications in biomedicine and biomechanics, and addresses the key technical obstacles, offering insights into the future development of these technologies in the context of biomedical and biomechanical research.",
    "doi": "10.62617/mcb1006",
    "url": "https://www.semanticscholar.org/paper/fde840d002673ff67a709c9964dda775f80e969f",
    "pdf_url": "",
    "venue": "Molecular &amp; Cellular Biomechanics",
    "citation_count": 3,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972859"
  },
  {
    "source": "semantic_scholar",
    "source_id": "4092be66782505e69fb0199894df68742c62e9d7",
    "title": "The Impact of Artificial Intelligence-Based Human Resource Management Systems on Organizational Efficiency",
    "authors": [
      "Pankaj Kumar Tyagi",
      "Vikram Jit Singh",
      "Ajit Kumar Singh",
      "Ayush Saxena",
      "Priyanka Tyagi",
      "Pankaj Mehta"
    ],
    "year": 2023,
    "abstract": "The transformative impact of AI-based HRMSs (artificial intelligence-based human resource management systems) on the effectiveness of organizations has been examined in this empirical paper. Artificial Intelligence (AI) is revolutionizing workforce management in today's dynamic business landscape. It is transforming functions like employee engagement, performance management, the onboarding process, recruitment, as well as workforce planning. By streamlining HR procedures, AI-HRMS enables automation, and predictive analytics, in addition to data-driven decision-making. The study illustrates the benefits of AI-HRMS with case studies and statistical analysis. By automating the screening of candidates and anticipating job success, these systems strengthen the efficiency of recruitment. Personalized plans and real-time support speed up employee onboarding and increase fulfillment. AI-HRMS uses personalized development plans, automated forecasting, and task automation to increase employee engagement and retention. Continuous improvement is promoted and worker contributions are matched with organizational objectives through data-driven performance management. The paper highlights challenges as well as successful implementations in companies such as Siemens, Unilever, IBM, as well as others. Careful consideration is needed for data privacy, opposition from staff members, system integration, and potential bias. Organizations can fully utilize AI-HRMS by triumphing over these obstacles, bringing in improved prospects for HR administration and organizational effectiveness.",
    "doi": "10.1109/UPCON59197.2023.10434792",
    "url": "https://www.semanticscholar.org/paper/4092be66782505e69fb0199894df68742c62e9d7",
    "pdf_url": "",
    "venue": "IEEE Uttar Pradesh Section International Conference on Electrical, Computer and Electronics Engineering",
    "citation_count": 5,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972861"
  },
  {
    "source": "semantic_scholar",
    "source_id": "a20afbcf5fe7a60d69442cab3fc1b46ffe97f9a3",
    "title": "Artificial Intelligence in Human Resource Management: Transforming Business Practices",
    "authors": [
      "Smruti Ranjan Das",
      "Prithu Sarkar",
      "Shripada Patil",
      "Ritesh Sharma",
      "Shikha Aggarwal",
      "Melanie Lourens"
    ],
    "year": 2023,
    "abstract": "The significant effects of artificial intelligence (AI) on human resource management (HRM) and its revolutionary effect on modern corporate practices have been investigated in this empirical study. In the ever-changing business landscape of today, companies are always looking for innovative strategies to improve productivity and competitiveness. Artificial intelligence (AI) has become a key invention that not only penetrates many industries but also transforms human resource management (HRM) by transforming workforce management, performance evaluation, including talent acquisition. The conventional resume screening process has been changed by AI's involvement in talent acquisition, resulting in it being more objective and efficient. Artificial intelligence (AI)-powered algorithms quickly evaluate a large number of resumes, classify applicants, and identify the best ones. AI gives businesses a competitive edge by broadening the talent pool and scanning a variety of sources to help with proactive candidate sourcing. In order to enhance the applicant experience overall, chatbots and virtual assistants communicate with candidates in real time while they do pre-screening interviews. In order to overcome bias issues, predictive analytics assists in assessing individuals' potential and synchronizes recruiting with strategic goals. Artificial intelligence (AI) brings continuous in addition to objective feedback systems to performance evaluation and feedback, minimizing subjectivity and enhancing fairness. Identifying skill gaps makes individualized development strategies possible. AI's data-driven approach to workforce management including optimization helps with staffing requirements predictions, schedule optimization, resource allocation, and proactive employee attrition management. The use of AI in HRM has many advantages, but it also presents difficulties in addition to moral questions, including data privacy, job security, and decision-making responsibility. To overcome these obstacles, organizations are required to set up strong data protection procedures, open lines of communication, as well as distinct accountability structures. This empirical research explores the complex relationship between AI and HRM and provides guidance with regard to how to use AI to support more ethical and effective HR procedures, which will eventually influence corporate practices in the future.",
    "doi": "10.1109/UPCON59197.2023.10434524",
    "url": "https://www.semanticscholar.org/paper/a20afbcf5fe7a60d69442cab3fc1b46ffe97f9a3",
    "pdf_url": "",
    "venue": "IEEE Uttar Pradesh Section International Conference on Electrical, Computer and Electronics Engineering",
    "citation_count": 6,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972862"
  },
  {
    "source": "semantic_scholar",
    "source_id": "66963f526ab81db63a5b727654b5082bdf06846f",
    "title": "Integrating Artificial Intelligence in Human Resource Functions: Challenges and Opportunities",
    "authors": [
      "Nordahlia Umar Baki",
      "Roziah Mohd Rasdi",
      "S. Krauss",
      "Mohd Khaizer Omar"
    ],
    "year": 2023,
    "abstract": "Artificial intelligence (AI) comes in many forms and has entered the overall system of organisations including in human resource (HR), where AI started to replace some of the human functions. Nonetheless, despite increased academic interest, research on AI-based HR tools is limited and fragmented. This article discusses the challenges and opportunities brought together during AI intervention in innovating HR functions. This study systematically reviews the existing literature, highlighting key areas where AI is being integrated, such as recruitment, employee engagement, training and development, and performance assessment. With the integration of AI, it successfully helps the industry to work in more effective and efficient ways through enhancing employee learning experiences, mitigating human biases, reducing manpower and training cost, and increasing employee engagement and retention. On the other hand, there are also studies that have raised the concern of the challenges during the AI integration, such as high implementation cost of technology tools, uncertainty and employee resistance, lack of human touch and legal and ethical concerns. This paper argues that successful integration of AI in HR functions requires a holistic approach. Collaboration between HR professionals and AI experts is crucial to address technical and ethical challenges. To leverage AI, organisations must embrace change management strategies to facilitate a smooth transition and foster a culture of continuous improvement. This study sheds light on how AI is transforming HR functions and establishes the groundwork for future research such as competency development, workplace learning, and organisation development, enabling practitioners and scholars to navigate the intricate terrain of AI integration in HR successfully.",
    "doi": "10.6007/ijarbss/v13-i8/18071",
    "url": "https://www.semanticscholar.org/paper/66963f526ab81db63a5b727654b5082bdf06846f",
    "pdf_url": "https://hrmars.com/papers_submitted/18071/integrating-artificial-intelligence-in-human-resource-functions-challenges-and-opportunities.pdf",
    "venue": "International Journal of Academic Research in Business and Social Sciences",
    "citation_count": 4,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:53.972864"
  },
  {
    "source": "semantic_scholar",
    "source_id": "3e89d80f5d85d81032e2222928f0401524fa6508",
    "title": "The integration and implications of artificial intelligence in forensic science",
    "authors": [
      "Paige Tynan"
    ],
    "year": 2024,
    "abstract": null,
    "doi": "10.1007/s12024-023-00772-6",
    "url": "https://www.semanticscholar.org/paper/3e89d80f5d85d81032e2222928f0401524fa6508",
    "pdf_url": "",
    "venue": "Forensic Science, Medicine, and Pathology",
    "citation_count": 25,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140579"
  },
  {
    "source": "semantic_scholar",
    "source_id": "e285139b9d25057156b2d13225d86e92456be9fd",
    "title": "Unveiling the Influence of Artificial Intelligence on Resource Management and Sustainable Development: A Comprehensive Investigation",
    "authors": [
      "Geetha Manoharan",
      "Meeta Joshi",
      "Kawerinder Singh Sidhu",
      "Rajesh Bhaskar Survase",
      "Roop Raj",
      "Ashutosh Pandey"
    ],
    "year": 2024,
    "abstract": "Artificial Intelligence (AI) holds immense potential to reconstruct various facets of ability administration and contribute to tenable incident. However, its ratification raises important righteous considerations that must be forwarded to guarantee justice, transparency, and responsibility. This paper determines a inclusive exploration of AI\u2019s influence on source administration and tenable development, trying allure implications across various subdivisions and rules. The study critically resolves the current countryside of AI enactment in human resource management (HRM) and allure impact on administrative adeptness and worker well-being. It more investigates AI\u2019s duty in trying key challenges related to tenable happening, such as material preservation, friendly equity, and business-related progress. By inspecting existing article and practical evidence, this paper focal points the opportunities and challenges guide AI endorsement and offers understandings into strategies for optimizing effectiveness and impartiality with AI. Additionally, the study stresses the significance of righteous considerations in AI acceptance, containing algorithmic bias, data solitude, responsibility, and the moral implications of task displacement. Overall, this paper underscores the need for a equalized approach to AI enactment that maximizes allure benefits while mitigating potential risks, eventually donating to acceptable and equitable incident.",
    "doi": "10.1109/ICACCM61117.2024.11059226",
    "url": "https://www.semanticscholar.org/paper/e285139b9d25057156b2d13225d86e92456be9fd",
    "pdf_url": "",
    "venue": "2024 International Conference on Advances in Computing, Communication and Materials (ICACCM)",
    "citation_count": 24,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140589"
  },
  {
    "source": "semantic_scholar",
    "source_id": "58c95c5e45f458d18c9fd13952bba852c25d9bbb",
    "title": "Transparent Artificial Intelligence and Human Resource Management: A Systematic Literature Review",
    "authors": [
      "A. M. Votto",
      "C. Liu"
    ],
    "year": 2023,
    "abstract": "As the technological expansion of Artificial Intelligence (AI) penetrates various industries, Human Resource Management has attempted to keep pace with the new capabilities and challenges these technologies have brought. When adopting AI, transparency within HRM decisions is an increasing demand to establish ethical, unbiased, and fair practices within a firm. To this end, explainable AI (XAI) methods have become vital in achieving transparency within HRM decision-making. Thus, there has been a growing interest in exploring successful XAI techniques, as evidenced by the systematic literature review (SLR) performed in this paper. Our SLR starts by revealing where AI exists within HRM. Following this, we review the literature on XAI and accuracy, XAI design, accountability, and data processing initiatives within HRM. The integrated framework we propose provides an avenue to bridge the gap between transparent HRM practices and Artificial Intelligence, providing the industrial and academic community with better insight into where XAI could exist within HRM processes.",
    "doi": "10.24251/hicss.2023.132",
    "url": "https://www.semanticscholar.org/paper/58c95c5e45f458d18c9fd13952bba852c25d9bbb",
    "pdf_url": "https://scholarspace.manoa.hawaii.edu/bitstreams/675b7c99-690f-422c-b449-8d8dbbd2c502/download",
    "venue": "Hawaii International Conference on System Sciences",
    "citation_count": 1,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140592"
  },
  {
    "source": "semantic_scholar",
    "source_id": "93aa1a8c0dcd7b6ca69a02b08eb464d20c25ab5a",
    "title": "Behavioral Ethics Ecologies of Human-Artificial Intelligence Systems",
    "authors": [
      "Stephen Fox"
    ],
    "year": 2022,
    "abstract": "Historically, evolution of behaviors often took place in environments that changed little over millennia. By contrast, today, rapid changes to behaviors and environments come from the introduction of artificial intelligence (AI) and the infrastructures that facilitate its application. Behavioral ethics is concerned with how interactions between individuals and their environments can lead people to questionable decisions and dubious actions. For example, interactions between an individual\u2019s self-regulatory resource depletion and organizational pressure to take non-ethical actions. In this paper, four fundamental questions of behavioral ecology are applied to analyze human behavioral ethics in human\u2013AI systems. These four questions are concerned with assessing the function of behavioral traits, how behavioral traits evolve in populations, what are the mechanisms of behavioral traits, and how they can differ among different individuals. These four fundamental behavioral ecology questions are applied in analysis of human behavioral ethics in human\u2013AI systems. This is achieved through reference to vehicle navigation systems and healthcare diagnostic systems, which are enabled by AI. Overall, the paper provides two main contributions. First, behavioral ecology analysis of behavioral ethics. Second, application of behavioral ecology questions to identify opportunities and challenges for ethical human\u2013AI systems.",
    "doi": "10.3390/bs12040103",
    "url": "https://www.semanticscholar.org/paper/93aa1a8c0dcd7b6ca69a02b08eb464d20c25ab5a",
    "pdf_url": "https://www.mdpi.com/2076-328X/12/4/103/pdf?version=1649734738",
    "venue": "Behavioral Science",
    "citation_count": 4,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140593"
  },
  {
    "source": "semantic_scholar",
    "source_id": "75b2b52d2b95bffbff6de9f852db8b810254db84",
    "title": "From Bias to Fairness: A Review of Ethical Considerations and Mitigation Strategies in Artificial Intelligence",
    "authors": [
      "Saurabh Srivastava",
      "Khushi Sinha"
    ],
    "year": 2023,
    "abstract": "Abstract: Artificial intelligence (AI) has become increasingly popular in recent years and has been used in a range of industries to improve outcomes, streamline processes, and improve decision-making. But there are also moral questions raised by the employment of AI, particularly in light of potential bias and discrimination. In order to promote justice and reduce bias, this paper offers a thorough discussion of ethical issues and mitigation techniques in AI. The evolution of AI and its possible advantages and disadvantages are first covered in the paper. After that, it explores the different ethical issues surrounding AI, such as trust, accountability, fairness, and openness. The study emphasises the effects of bias and discrimination on AI systems as well as the possible outcomes of these problems. The study also discusses the various mitigation measures, such as algorithmic strategies, data pre-processing, and model validation, that have been suggested to mitigate bias and enhance justice in AI. In order to develop the subject of AI ethics, the study analyses the advantages and disadvantages of different frameworks and emphasises the necessity of continued interdisciplinary research and collaboration. The study's importance in advancing ethical concerns and fairness in AI is highlighted in the paper's conclusion. It offers information about the state of the field at the moment and points out potential directions for further study. Overall, the article is a useful tool for academics, professionals, and decision-makers who want to support ethical and responsible AI development and application.",
    "doi": "10.22214/ijraset.2023.49990",
    "url": "https://www.semanticscholar.org/paper/75b2b52d2b95bffbff6de9f852db8b810254db84",
    "pdf_url": "https://doi.org/10.22214/ijraset.2023.49990",
    "venue": "International Journal for Research in Applied Science and Engineering Technology",
    "citation_count": 4,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140595"
  },
  {
    "source": "semantic_scholar",
    "source_id": "f45b24bca3b0a05237883c23e941ee3b8a5cee57",
    "title": "From Recruitment to Retention: AI Tools for Human Resource Decision-Making",
    "authors": [
      "Mitra Madanchian"
    ],
    "year": 2024,
    "abstract": "HR decision-making is changing as a result of artificial intelligence (AI), especially in the areas of hiring, onboarding, and retention. This study examines the use of AI tools throughout the lifecycle of an employee, emphasizing how they enhance the effectiveness, customization, and scalability of HR procedures. These solutions streamline employee setup, learning, and documentation. They range from AI-driven applicant tracking systems (ATSs) for applicant selection to AI-powered platforms for automated onboarding and individualized training. Predictive analytics also helps retention and performance monitoring plans, which lowers turnover, but issues such as bias, data privacy, and ethical problems must be carefully considered. This paper addresses the limitations and future directions of AI while examining its disruptive potential in HR.",
    "doi": "10.3390/app142411750",
    "url": "https://www.semanticscholar.org/paper/f45b24bca3b0a05237883c23e941ee3b8a5cee57",
    "pdf_url": "",
    "venue": "Applied Sciences",
    "citation_count": 27,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140596"
  },
  {
    "source": "semantic_scholar",
    "source_id": "b41daf07f4cb04f494a0c7ce420afc68b3e6dbf5",
    "title": "Beyond bias and discrimination: redefining the AI ethics principle of fairness in healthcare machine-learning algorithms",
    "authors": [
      "B. Giovanola",
      "S. Tiribelli"
    ],
    "year": 2022,
    "abstract": "The increasing implementation of and reliance on machine-learning (ML) algorithms to perform tasks, deliver services and make decisions in health and healthcare have made the need for fairness in ML, and more specifically in healthcare ML algorithms (HMLA), a very important and urgent task. However, while the debate on fairness in the ethics of artificial intelligence (AI) and in HMLA has grown significantly over the last decade, the very concept of fairness as an ethical value has not yet been sufficiently explored. Our paper aims to fill this gap and address the AI ethics principle of fairness from a conceptual standpoint, drawing insights from accounts of fairness elaborated in moral philosophy and using them to conceptualise fairness as an ethical value and to redefine fairness in HMLA accordingly. To achieve our goal, following a first section aimed at clarifying the background, methodology and structure of the paper, in the second section, we provide an overview of the discussion of the AI ethics principle of fairness in HMLA and show that the concept of fairness underlying this debate is framed in purely distributive terms and overlaps with non-discrimination, which is defined in turn as the absence of biases. After showing that this framing is inadequate, in the third section, we pursue an ethical inquiry into the concept of fairness and argue that fairness ought to be conceived of as an ethical value. Following a clarification of the relationship between fairness and non-discrimination, we show that the two do not overlap and that fairness requires much more than just non-discrimination. Moreover, we highlight that fairness not only has a distributive but also a socio-relational dimension. Finally, we pinpoint the constitutive components of fairness. In doing so, we base our arguments on a renewed reflection on the concept of respect, which goes beyond the idea of equal respect to include respect for individual persons. In the fourth section, we analyse the implications of our conceptual redefinition of fairness as an ethical value in the discussion of fairness in HMLA. Here, we claim that fairness requires more than non-discrimination and the absence of biases as well as more than just distribution; it needs to ensure that HMLA respects persons both as persons and as particular individuals. Finally, in the fifth section, we sketch some broader implications and show how our inquiry can contribute to making HMLA and, more generally, AI promote the social good and a fairer society.",
    "doi": "10.1007/s00146-022-01455-6",
    "url": "https://www.semanticscholar.org/paper/b41daf07f4cb04f494a0c7ce420afc68b3e6dbf5",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s00146-022-01455-6.pdf",
    "venue": "Ai & Society",
    "citation_count": 119,
    "fields_of_study": [
      "Computer Science",
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140598"
  },
  {
    "source": "semantic_scholar",
    "source_id": "fe1e7f07ec5546061ba9fda973f0b92aaff0a548",
    "title": "Artificial intelligence adoption in extended HR ecosystems: enablers and barriers. An abductive case research",
    "authors": [
      "Antarpreet Singh",
      "Jatin Pandey"
    ],
    "year": 2024,
    "abstract": "Artificial intelligence (AI) has disrupted modern workplaces like never before and has induced digital workstyles. These technological advancements are generating significant interest among HR leaders to embrace AI in human resource management (HRM). Researchers and practitioners are keen to investigate the adoption of AI in HRM and the resultant human\u2013machine collaboration. This study investigates HRM specific factors that enable and inhibit the adoption of AI in extended HR ecosystems and adopts a qualitative case research design with an abductive approach. It studies three well-known Indian companies at different stages of AI adoption in HR functions. This research investigates key enablers such as optimistic and collaborative employees, strong digital leadership, reliable HR data, specialized HR partners, and well-rounded AI ethics. The study also examines barriers to adoption: the inability to have a timely pulse check of employees\u2019 emotions, ineffective collaboration of HR employees with digital experts as well as external HR partners, and not embracing AI ethics. This study contributes to the theory by providing a model for AI adoption and proposes additions to the unified theory of acceptance and use of technology in the context of AI adoption in HR ecosystems. The study also contributes to the best-in-class industry HR practices and digital policy formulation to reimagine workplaces, promote harmonious human\u2013AI collaboration, and make workplaces future-ready in the wake of massive digital disruptions.",
    "doi": "10.3389/fpsyg.2023.1339782",
    "url": "https://www.semanticscholar.org/paper/fe1e7f07ec5546061ba9fda973f0b92aaff0a548",
    "pdf_url": "https://www.frontiersin.org/articles/10.3389/fpsyg.2023.1339782/pdf?isPublishedV2=False",
    "venue": "Frontiers in Psychology",
    "citation_count": 26,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140600"
  },
  {
    "source": "semantic_scholar",
    "source_id": "c7eefc8d67b152e95a7e19bf66a0c3832b73bed4",
    "title": "Model of relationships between corporate social responsibility, human resources management, and artificial intelligence",
    "authors": [
      "R. Sk\u00fdpalov\u00e1",
      "Katar\u00edna Zvar\u00edkov\u00e1",
      "Sumana Chaudhuri"
    ],
    "year": 2025,
    "abstract": "Research background: The research explores the interrelationship between human resource management (HRM), corporate social responsibility (CSR), and artificial intelligence (AI) in the modern business environment. It examines the potential of AI to optimise HR processes while ensuring ethical considerations and social responsibility are integrated into corporate strategies.\nPurpose of the article: The aim of the article is to identify and quantify the causal relationships between human resource management, corporate social responsibility, and the perception of artificial intelligence within the company as key aspects of sustainable business development.\nMethods: Research was conducted in the Czech business environment based on 451 responses from HR managers in medium- to large-sized companies. A uniquely designed questionnaire was created to capture the respondents' subjective attitudes in September 2024. The hypotheses were evaluated using the application of structural equation modelling (SEM).\nFindings & value added: The findings confirm that CSR activities exert a clear and positive impact on HRM, whereas AI, despite its significant potential to enhance HR processes, is not yet fully implemented or utilised at an optimal level. In addition, we have also analysed the relationship between AI and CSR, and empirical findings indicate that AI can significantly support CSR activities as these two domains had the potential to enhance the competitiveness of the organisation. Our results emphasise the necessity for policy makers and managers to enhance CSR focused HRM practices and to support guidelines to ensure the ethical deployment of AI as the ethical and social implications of implementing AI in HR and CSR present another key challenge, including data bias and privacy concerns.",
    "doi": "10.24136/oc.3875",
    "url": "https://www.semanticscholar.org/paper/c7eefc8d67b152e95a7e19bf66a0c3832b73bed4",
    "pdf_url": "",
    "venue": "Oeconomia Copernicana",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140601"
  },
  {
    "source": "semantic_scholar",
    "source_id": "e82339666d2462b29962e9934e6d115717a21396",
    "title": "The Development of Artificial Intelligence and Its Impact on Human Rights Protection from An Ethical and Legal Perspective",
    "authors": [
      "Karyono Karyono"
    ],
    "year": 2025,
    "abstract": "The development of artificial intelligence (AI) has brought about major changes in various sectors of life, from public services to the legal system. Amid the benefits of efficiency and accuracy offered, the use of AI poses serious challenges to the protection of human rights. Risks such as privacy violations, algorithmic discrimination, decision-making without accountability, and digital surveillance are urgent issues that need to be addressed legally and ethically. The study examines the impact of the use of AI on human rights by emphasizing aspects of algorithm transparency, data bias, privacy rights, legal vacuum, and the global technology gap. This study uses a normative legal method with a statutory regulatory approach and a conceptual approach, referring to various national legal instruments such as the 1945 Constitution, Law No. 39 of 1999 concerning Human Rights, and Law No. 27 of 2022 concerning Personal Data Protection, as well as international standards such as the Universal Declaration of Human Rights, ICCPR, OECD AI Principles, and EU AI Act. The results of the study reveal that existing regulations are not sufficient to address the complexity of AI, so a special law is needed that comprehensively regulates artificial intelligence. In addition, the integration of human rights principles, technology ethics, and public policy is a strategic step to ensure that technological innovation does not ignore human values. Thus, AI can be developed responsibly, fairly, and oriented towards respect for human dignity.",
    "doi": "10.38035/gijlss.v3i2.499",
    "url": "https://www.semanticscholar.org/paper/e82339666d2462b29962e9934e6d115717a21396",
    "pdf_url": "",
    "venue": "Greenation International Journal of Law and Social Sciences",
    "citation_count": 2,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140603"
  },
  {
    "source": "semantic_scholar",
    "source_id": "e9da5272909d027dc56dba03d5e5ac6880382247",
    "title": "EARN Fairness: Explaining, Asking, Reviewing, and Negotiating Artificial Intelligence Fairness Metrics Among Stakeholders",
    "authors": [
      "Lin Luo",
      "Yuri Nakao",
      "Mathieu Chollet",
      "Hiroya Inakoshi",
      "Simone Stumpf"
    ],
    "year": 2024,
    "abstract": "Numerous fairness metrics have been proposed and employed by artificial intelligence (AI) experts to quantitatively measure bias and define fairness in AI models. Recognizing the need to accommodate stakeholders' diverse fairness understandings, efforts are underway to solicit their input. However, conveying AI fairness metrics to stakeholders without AI expertise, capturing their personal preferences, and seeking a collective consensus remain challenging and underexplored. To bridge this gap, we propose a new framework, EARN (Explain, Ask, Review, and Negotiate) Fairness, which facilitates collective metric decisions among stakeholders without requiring AI expertise. The framework features an adaptable interactive system and a stakeholder-centered EARN Fairness process to Explain fairness metrics, Ask stakeholders' personal metric preferences, Review metrics collectively, and Negotiate a consensus on metric selection. To gather empirical results, we applied the framework to a credit rating scenario and conducted a user study involving 18 decision subjects without AI knowledge. We elicited their personal metric preferences and subsequently we studied how they reached metric consensus in team sessions. Our work shows that the EARN Fairness framework supports stakeholders to express and negotiate fairness preferences, and we provide practical guidance for implementing human-centered AI fairness in high-risk contexts. Through this approach, we aim to reach consensus of fairness perspectives, fostering more equitable and inclusive AI fairness.",
    "doi": "10.1145/3710908",
    "url": "https://www.semanticscholar.org/paper/e9da5272909d027dc56dba03d5e5ac6880382247",
    "pdf_url": "",
    "venue": "Proc. ACM Hum. Comput. Interact.",
    "citation_count": 4,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140604"
  },
  {
    "source": "semantic_scholar",
    "source_id": "ac02b7a54280a44dd5c8ae967ee383bde4417776",
    "title": "Discussion on the Application Status and Optimization Direction of Artificial Intelligence Introduced into Enterprise Management and Operation Systems",
    "authors": [
      "Zhibin Feng"
    ],
    "year": 2025,
    "abstract": ": Artificial intelligence (AI) technology, as the core driving force of the new round of scientific and technological innovation and industrial change, impacts the market competitiveness of enterprises and the composition structure of sustainable development conditions. Based on the current status of the application of the new human-machine integration mode of AI technology introduced into the enterprise management and operation system, this paper analyzes the existing technology application and drawbacks and explores the optimization path of the enterprise's application of the new human-machine integration mode from the four dimensions of the management object, attributes, decision-making and ethics. This paper concludes that the introduction of AI technology resources in enterprises requires enterprise managers to reconfigure the resource management model and coordinate the human-machine relationship. At the same time, managers are required to improve their technical quality, combine technical theories and management frameworks, and optimize the traditional management operation mode of enterprises. In addition, the participation of AI technology in decision-making requires enterprise managers to coordinate the ratio of human-machine decision-making, and proactively prevent possible risks in technology-assisted decision-making and prediction. Finally, enterprises need to proactively prevent the legal and ethical risks that may exist when AI technology is applied.",
    "doi": "10.5220/0014306800004718",
    "url": "https://www.semanticscholar.org/paper/ac02b7a54280a44dd5c8ae967ee383bde4417776",
    "pdf_url": "",
    "venue": "Proceedings of the 2nd International Conference on Engineering Management, Information Technology and Intelligence",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140606"
  },
  {
    "source": "semantic_scholar",
    "source_id": "15f479258fb5290bb6a60141d21d6820aee33932",
    "title": "RETRACTED: Future directions of artificial intelligence integration: Managing strategies and opportunities",
    "authors": [
      "R. Sundar",
      "Ziaul Haque Choudhury",
      "M. Chiranjivi",
      "Gayatri Parasa",
      "Praseeda Ravuri",
      "M. Sivaram",
      "Balambigai Subramanian",
      "Kireet Muppavaram",
      "Vijaya Madhavi Lakshmi.Challa"
    ],
    "year": 2024,
    "abstract": "Embracing Artificial Intelligence (AI) is becoming more common in a variety of areas, including healthcare, banking, and transportation, and it is based on substantial data analysis. However, utilizing data for AI raises a number of obstacles. This extensive article examines the challenges connected with using data for AI, including data quality, volume, privacy and security, bias and fairness, interpretability and ethical considerations, and the required technical knowledge. The investigation delves into each obstacle, providing insightful solutions for businesses and organizations to properly handle these complexities. Organizations may effectively harness AI\u2019s capabilities to make educated decisions by understanding and proactively tackling these difficulties, obtaining a competitive edge in the digital era. This review study, which provides a thorough examination of numerous solutions developed over the last decade to address data difficulties for AI, is expected to be a helpful resource for the scientific research community. It not only provides insights into current difficulties, but it also serves as a platform for creating novel ideas to alter our approaches to data strategies for AI.",
    "doi": "10.3233/JIFS-238830",
    "url": "https://www.semanticscholar.org/paper/15f479258fb5290bb6a60141d21d6820aee33932",
    "pdf_url": "",
    "venue": "Journal of Intelligent &amp; Fuzzy Systems",
    "citation_count": 4,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140607"
  },
  {
    "source": "semantic_scholar",
    "source_id": "593c13c306ba13c7a4738ae3db7e652edee1555f",
    "title": "Artificial Intelligence in Journalism: A Narrative Review of Opportunities, Challenges, Ethical Tensions, and Human-Machine Collaboration",
    "authors": [
      "Habeeb Abdulrauf",
      "Abdulmalik Adetola Lawal",
      "Amarachi Nina Uma Mba",
      "Comfort Ademola",
      "Zaynab B. Yusuf",
      "Shalewa Babatayo",
      "Idris Ayinde"
    ],
    "year": 2025,
    "abstract": "Artificial Intelligence (AI) is changing the practices of journalism around the world, which influence how news is gathered, produced, and disseminated. This review synthesizes theories, empirical, and other literature to explore the multidimensional impact that AI has on journalistic workflows and values. This review centered on 81 core sources published between 2015 to 2024, examining AI\u2019s affordances, including automation of routine reporting, data mining and audience personalization. The paper also assesses the emerging risks such as algorithmic bias, erosion of editorial transparency, and the popularity of deepfakes in the media. Guided by Human\u2013Machine Communication (HMC) frameworks, Actor-Network Theory, and affordance theory, this review submit that AI is a collaboratived partner rather than a competitor to human journalists. Case examples from newsrooms worldwide (e.g., Associated Press, Washington Post, ICIJ) show both promise and issues in AI integration to the practice of journalism. The paper also addresses the ethical tensions arising from AI-generated content, newsroom accountability, and evolving public trust in machine-assisted reporting. The paper offers future directions that highlight seven key areas: advancing deepfake detection tools, creating of AI ethics guidelines, advocating for the AI training in journalism education, and bridging technological gaps between large and smaller newsrooms. It concludes by hammering on maintaining human editorial oversight and democratic values as AI is growingly augmented in journalistic practice. This paper, therefore, offers a timely and interdisciplinary contribution to media scholars, technologists, and newsroom leaders who are embracing the future of AI-driven journalism.",
    "doi": "10.54536/ajahs.v4i4.5963",
    "url": "https://www.semanticscholar.org/paper/593c13c306ba13c7a4738ae3db7e652edee1555f",
    "pdf_url": "",
    "venue": "American Journal of Arts and Human Science",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140609"
  },
  {
    "source": "semantic_scholar",
    "source_id": "dd6b1095962e661f18da53ca93aae39c1a834b4e",
    "title": "The balance between innovation and human rights: problems of applying artificial intelligence",
    "authors": [
      "T.P. Popovich"
    ],
    "year": 2025,
    "abstract": "The article provides a comprehensive analysis of the impact of artificial intelligence technologies on the human rights system in the context of the digital transformation of society. The main threats and challenges posed by AI systems for the implementation of fundamental human rights and freedoms are investigated. Particular attention is paid to the problems of algorithmic bias, which leads to a violation of the right to non-discrimination, mass collection and processing of personal data without proper control, which threatens the right to privacy, restrictions on freedom of expression through automated content moderation, as well as threats to the right to a fair trial in the case of using automated decision-making systems without proper transparency. \nThe specific risks associated with mass surveillance and biometric identification technologies, including facial recognition systems in public places, the use of AI in employment and the military, and the manipulation of public opinion through deepfake technologies, are analyzed. Three stages of assessing the impact of AI on human rights are considered: analysis of the quality of training data, risk assessment at the system design stage, and consideration of algorithmic interactions. It is argued that AI systems, by their nature, reproduce social biases embedded in past experience data and do not have the inherent ability to change their behavior in accordance with the evolution of ethical norms in society. The application of artificial intelligence in the financial sector is examined in detail, in particular in credit scoring systems, where algorithms analyze huge amounts of data about the applicant\u2019s digital footprint. The problem of \u201cnetwork discrimination\u201d is identified, when a person\u2019s financial capabilities are assessed based on the characteristics of their social environment, which violates the principle of individual responsibility and can limit freedom of belief through self-censorship. The example of the practice of American companies shows how the use of AI systems in financial decision- making can both expand access to credit for representatives of marginalized communities and strengthen existing forms of discrimination.",
    "doi": "10.61345/1339-7915.2025.3.16",
    "url": "https://www.semanticscholar.org/paper/dd6b1095962e661f18da53ca93aae39c1a834b4e",
    "pdf_url": "",
    "venue": "Visegrad journal on human rights",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140611"
  },
  {
    "source": "semantic_scholar",
    "source_id": "dc7f001149ed4c931dfa5ffa1a7379858fa449e2",
    "title": "Ethical Considerations of Bias and Fairness in AI Models",
    "authors": [
      "Sarvachan Verma",
      "Neha Paliwal",
      "Kanchan Yadav",
      "P. C. Vashist"
    ],
    "year": 2024,
    "abstract": "The ethical implications of artificial intelligence (AI) are becoming increasingly important. AI systems have the potential to incite bias against certain races and genders, either through programming choices or through the data collected to train the device. Thus, it is imperative to address ethical issues pertaining to justice and bias in order to guarantee the most responsible and optimal application of AI in society. Integrating AI ethics into software development processes is one way to deal with bias and equality in machine learning models. AI developers also have to deal with bias through length of information, in addition to programming concerns. Determining the lifespan of records entails making deliberate decisions about record entry that reduce prejudice and ensure fairness. It entails getting rid of protected characteristics that could have biased effects, such race or gender. Diversifying the kind of records that are included in models can also help to lessen the risk of bias.",
    "doi": "10.1109/ICDT61202.2024.10489577",
    "url": "https://www.semanticscholar.org/paper/dc7f001149ed4c931dfa5ffa1a7379858fa449e2",
    "pdf_url": "",
    "venue": "International Conference on Database Theory",
    "citation_count": 6,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140612"
  },
  {
    "source": "semantic_scholar",
    "source_id": "b0b1abb19ff12ce7bbc4c4b694fd4c2bdfe3f711",
    "title": "Framework for Bias Detection in Machine Learning Models: A Fairness Approach",
    "authors": [
      "Alveiro Alonso Rosado G\u00f3mez",
      "Maritza Liliana Calder\u00f3n Benavides"
    ],
    "year": 2024,
    "abstract": null,
    "doi": "10.1145/3616855.3635731",
    "url": "https://www.semanticscholar.org/paper/b0b1abb19ff12ce7bbc4c4b694fd4c2bdfe3f711",
    "pdf_url": "",
    "venue": "Web Search and Data Mining",
    "citation_count": 5,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140614"
  },
  {
    "source": "semantic_scholar",
    "source_id": "8d4c60de296a369049c33e2c7852a46cfb3ccd66",
    "title": "Beyond Human Judgment: Exploring the Impact of Artificial Intelligence on HR Decision-Making Efficiency and Fairness",
    "authors": [
      "Md. Abul Khair",
      "Ravikiran Mahadasa",
      "Ferdouse Ara Tuli",
      "Janaki Rama Phanendra Kumar Ande"
    ],
    "year": 2020,
    "abstract": "This study aims to evaluate the impact of artificial intelligence (AI) on the efficiency and fairness of human resources (HR) decision-making. The key goals are to determine how artificial intelligence improves decision-making efficiency, investigate the fairness issues involved in AI-driven human resource practices, and make policy suggestions for engaging in ethical HR practices. The approach utilized is known as secondary data analysis. It is used to synthesize insights and patterns by pulling upon previously published literature and empirical investigations; even though artificial intelligence technologies present an opportunity to optimize human resource operations and improve organizational performance, significant findings demonstrate that these technologies also create ethical problems connected to algorithmic biases and an absence of transparency. Regulatory oversight, ethical standards, data governance, diversity and inclusion programs, and constant monitoring and assessment are some of the policy implications that should be considered to guarantee responsible deployment of artificial intelligence in human resource contexts. When it comes to human resource decision-making, companies can embrace the revolutionary potential of artificial intelligence (AI) while maintaining ethical standards if they prioritize justice, openness, and accountability.",
    "doi": "10.18034/gdeb.v9i2.730",
    "url": "https://www.semanticscholar.org/paper/8d4c60de296a369049c33e2c7852a46cfb3ccd66",
    "pdf_url": "https://i-proclaim.my/journals/index.php/gdeb/article/download/730/660",
    "venue": "Global Disclosure of Economics and Business",
    "citation_count": 25,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140615"
  },
  {
    "source": "semantic_scholar",
    "source_id": "2e4916d53d6c8b3626a2ab7c6d62258f4251fc7f",
    "title": "Artificial intelligence agent in clinical trial operations: a fictional (for now) case study",
    "authors": [
      "T. M\u00e9nard",
      "Katrina A. Bramstedt"
    ],
    "year": 2025,
    "abstract": null,
    "doi": "10.1007/s43681-025-00798-2",
    "url": "https://www.semanticscholar.org/paper/2e4916d53d6c8b3626a2ab7c6d62258f4251fc7f",
    "pdf_url": "",
    "venue": "AI and Ethics",
    "citation_count": 0,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140617"
  },
  {
    "source": "semantic_scholar",
    "source_id": "a6dd1f1a9b1ce69a09e884cc5d497f4d2b6336e2",
    "title": "Governance and Ethical Challenges of Artificial Intelligence in Warfare",
    "authors": [
      "Md Tanvir Islam Sourav",
      "Nasrullah Masud",
      "Abdullah Al Bassam",
      "Abdus Sobhan"
    ],
    "year": 2025,
    "abstract": "The sudden integration of AI in today's workflow has made urgent ethical and governance discussions on accountability, bias, and human agency in making lethal decisions. This review looks into the ethics of military AI technologies: autonomous weapon systems (aerospace systems), AI-supported surveillance and targeting algorithms, and assesses the governance regimes created to minimize risks. Just-war theory continues to act as the moral compass. Still, it tells us little about the complications specific to AI, namely convoluted accountability chains and algorithmic biases that harm civilians [1], [2]. This paper has exposed these fundamentally disparate pathways worldwide through the comparative analysis of new ethical frameworks. The IEEE Global Initiative supports human control and transparency. At the same time, the Department of Defense in the United States prefers reliability from a technical point of view. At the same time, the EU grounds any human decision on actions that cause death and destruction [3]\u2013[5]. The Russian-Ukrainian war misuses facial recognition and places AI-guided systems for airstrikes in the 2023 Gaza conflict, at the historical case studies of recent wars that indicate deep-rooted systemic flaws in the governance architectures, such as biased mitigation and accountability [6], [7]. The study identifies three critical gaps in current policies: (1) insufficient mechanisms for auditing biased algorithms, (2) ambiguous legal responsibility for AWS outcomes, and (3) fragmented international regulatory efforts. The paper proposes a hybrid governance model combining rigorous ethical auditing, interoperable technical standards, and binding multilateral agreements to address these. Findings underscore the urgent need for interdisciplinary collaboration among technologists, ethicists, and policymakers to align AI advancements with international humanitarian law. Without proactive measures, the unchecked proliferation of military AI risks destabilizing global security and eroding public trust in automated defense systems [8].",
    "doi": "10.1109/QPAIN66474.2025.11171759",
    "url": "https://www.semanticscholar.org/paper/a6dd1f1a9b1ce69a09e884cc5d497f4d2b6336e2",
    "pdf_url": "",
    "venue": "2025 International Conference on Quantum Photonics, Artificial Intelligence, and Networking (QPAIN)",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140618"
  },
  {
    "source": "semantic_scholar",
    "source_id": "e4a2baa92dcdfbcd82621e9915d0a433704a8516",
    "title": "Politics by Automatic Means? A Critique of Artificial Intelligence Ethics at Work",
    "authors": [
      "M. Cole",
      "C. Cant",
      "Funda Ustek\u2010Spilda",
      "Mark Graham"
    ],
    "year": 2022,
    "abstract": "Calls for \u201cethical Artificial Intelligence\u201d are legion, with a recent proliferation of government and industry guidelines attempting to establish ethical rules and boundaries for this new technology. With few exceptions, they interpret Artificial Intelligence (AI) ethics narrowly in a liberal political framework of privacy concerns, transparency, governance and non-discrimination. One of the main hurdles to establishing \u201cethical AI\u201d remains how to operationalize high-level principles such that they translate to technology design, development and use in the labor process. This is because organizations can end up interpreting ethics in an ad-hoc way with no oversight, treating ethics as simply another technological problem with technological solutions, and regulations have been largely detached from the issues AI presents for workers. There is a distinct lack of supra-national standards for fair, decent, or just AI in contexts where people depend on and work in tandem with it. Topics such as discrimination and bias in job allocation, surveillance and control in the labor process, and quantification of work have received significant attention, yet questions around AI and job quality and working conditions have not. This has left workers exposed to potential risks and harms of AI. In this paper, we provide a critique of relevant academic literature and policies related to AI ethics. We then identify a set of principles that could facilitate fairer working conditions with AI. As part of a broader research initiative with the Global Partnership on Artificial Intelligence, we propose a set of accountability mechanisms to ensure AI systems foster fairer working conditions. Such processes are aimed at reshaping the social impact of technology from the point of inception to set a research agenda for the future. As such, the key contribution of the paper is how to bridge from abstract ethical principles to operationalizable processes in the vast field of AI and new technology at work.",
    "doi": "10.3389/frai.2022.869114",
    "url": "https://www.semanticscholar.org/paper/e4a2baa92dcdfbcd82621e9915d0a433704a8516",
    "pdf_url": "https://www.frontiersin.org/articles/10.3389/frai.2022.869114/pdf",
    "venue": "Frontiers in Artificial Intelligence",
    "citation_count": 18,
    "fields_of_study": [
      "Medicine",
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140620"
  },
  {
    "source": "semantic_scholar",
    "source_id": "4950d90b58b2b48f4ab2cd290b1f0e6cb9a116db",
    "title": "Ethical and Legal Challenges of AI in Human Resource Management",
    "authors": [
      "Jiaxing Du"
    ],
    "year": 2024,
    "abstract": "Artificial Intelligence (AI) has become a transformative force in Human Resource Management (HRM), enhancing recruitment, training, performance evaluation, and employee engagement. This paper examines the ethical and legal challenges associated with the integration of AI in HRM. Key ethical concerns include bias and discrimination, privacy and data protection, transparency and explainability, and the impact on job security and automation. Legal challenges revolve around compliance with data protection laws, anti-discrimination regulations, and labor laws. This paper provides recommendations for addressing these challenges through a comprehensive analysis of real-world case studies and relevant data through policy development, best practices, and future research directions. The goal is to contribute to the responsible and ethical use of AI in HRM, ensuring that its benefits are maximized while mitigating potential risks.",
    "doi": "10.54097/83j64ub9",
    "url": "https://www.semanticscholar.org/paper/4950d90b58b2b48f4ab2cd290b1f0e6cb9a116db",
    "pdf_url": "",
    "venue": "Journal of Computing and Electronic Information Management",
    "citation_count": 11,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140621"
  },
  {
    "source": "semantic_scholar",
    "source_id": "6d490989a6b61fe4210c222c9f6dc95990f70042",
    "title": "Artificial intelligence and public sector human resource management in South Africa: Opportunities, challenges and prospects",
    "authors": [
      "A. Chilunjika",
      "Kudakwashe Intauno",
      "S. Chilunjika"
    ],
    "year": 2022,
    "abstract": "Orientation: The Fourth Industrial Revolution has transformed modern society by ushering in the fusion of advances in robotics, the Internet of Things (IoT), genetic engineering, quantum computing, and artificial intelligence (AI) among others. AI brings a range of different technologies and applications to interact with environments that comprise both the relevant objects and the interaction rules and have the capacity to process information in a way that resembles intelligent behaviour. Similarly, artificial intelligence is also being used in the human resources management (HRM) processes and functions in the public sector to map sequences to actions.Research purpose: The study explores the opportunities, challenges, and future prospects of integrating Artificial Intelligence (AI) and Public Sector Human Resource Management (HRM) in South Africa\u2019s public sector.Motivation for the study: The study was motivated by the need to examine the dynamics surrounding the adoption, implementation and operationalisation of the 4IR in the management of human resources in the SA public sector in this unfolding dispensation.Research Approach: Data was collected using the extensive review of written records such as books, journal articles, book chapters among others which were purposively selected for use in this study. Data was analysed using content and thematic analysis techniques.Research Findings: The study established that Artificial Intelligence is beneficial in the sense that it can improve public service delivery in South Africa as the HRM personnel is enabled to focus more on the strategic areas of management by taking over routine tasks, and that it helps minimize bias in public service recruitment and selection. In contrast, research on potential challenges has revealed that combining Artificial Intelligence and Public Sector Human Resource Management may pose a threat to white-collar jobs.Practical/ Managerial Implications: This study may lead to practical applications of AI to support the HR functions of public sector entities in SA. The public managers are better informed about the impediments, gaps and opportunities that may arise from using AI in managing human resources in SA\u2019s public sector.Contributions: This study contributes to the body of knowledge as it unpacks and informs the dynamics associated with the implementation of AI in managing human resources in public sector entities.",
    "doi": "10.4102/sajhrm.v20i0.1972",
    "url": "https://www.semanticscholar.org/paper/6d490989a6b61fe4210c222c9f6dc95990f70042",
    "pdf_url": "https://sajhrm.co.za/index.php/sajhrm/article/download/1972/3069",
    "venue": "Sa Journal of Human Resource Management",
    "citation_count": 47,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140623"
  },
  {
    "source": "semantic_scholar",
    "source_id": "dd8c8f102041c9ded50cf9e9f3db6b9940609f0a",
    "title": "ARTIFICIAL INTELLIGENCE IN CRIMINAL JUSTICE MANAGEMENT: A SYSTEMATIC LITERATURE REVIEW",
    "authors": [
      "Khairul Alam Talukder",
      "Touhida Ferdousi Shompa"
    ],
    "year": 2024,
    "abstract": "This systematic review, based on 37 articles, explores the role of artificial intelligence (AI) in criminal justice, focusing on its applications in predictive policing, judicial risk assessments, and surveillance, as well as the associated ethical and regulatory challenges. AI has demonstrated substantial potential for improving efficiency and accuracy in criminal justice systems, from optimizing law enforcement resource allocation to providing data-driven risk assessments that support judicial decisions. However, the review identifies significant ethical issues, especially related to algorithmic bias, which can perpetuate existing societal inequalities and disproportionately affect marginalized communities. Concerns around transparency and accountability are prevalent, as the \"black-box\" nature of many AI algorithms complicates public understanding and trust in AI-driven outcomes. Surveillance tools, including facial recognition and behavioral analysis, enhance real-time threat detection but raise privacy and civil rights concerns, highlighting the need for regulatory oversight. Gaps in legal frameworks suggest the urgency for standardized policies that address data privacy, algorithmic fairness, and accountability in AI applications. The findings underscore that interdisciplinary collaboration, transparent practices, and comprehensive regulatory measures are essential to responsibly integrate AI into criminal justice, balancing technological advancements with justice, equity, and public trust.",
    "doi": "10.70008/jmldeds.v1i01.42",
    "url": "https://www.semanticscholar.org/paper/dd8c8f102041c9ded50cf9e9f3db6b9940609f0a",
    "pdf_url": "https://nonhumanjournal.com/index.php/JMLDEDS/article/download/42/42",
    "venue": "Non human journal",
    "citation_count": 7,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140624"
  },
  {
    "source": "semantic_scholar",
    "source_id": "b29559cf818317411d734aabf67efc7c5d411e5e",
    "title": "Artificial intelligence in governance: recent trends, risks, challenges, innovative frameworks and future directions",
    "authors": [
      "Arjun Ghosh",
      "Ankit Saini",
      "Himanshu Barad"
    ],
    "year": 2025,
    "abstract": null,
    "doi": "10.1007/s00146-025-02312-y",
    "url": "https://www.semanticscholar.org/paper/b29559cf818317411d734aabf67efc7c5d411e5e",
    "pdf_url": "",
    "venue": "Ai & Society",
    "citation_count": 24,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140626"
  },
  {
    "source": "semantic_scholar",
    "source_id": "a29915337616551711d1a8128bab1255090466a7",
    "title": "Machine Learning and Human Resource Management: A Path to Efficient Workforce Management",
    "authors": [
      "Ankita Saxena",
      "Sammaiah Buhukya",
      "Ippa Sumalatha",
      "Amit Dutt",
      "Abothar Mahmod Shaaker",
      "A. V"
    ],
    "year": 2023,
    "abstract": "In order to achieve effective workforce management, this empirical study investigates the incorporation of machine learning into human resource management (HRM). HRM is a fundamental function that oversees talent acquisition, employee welfare, and performance optimization in organizations. The dynamic nature of today's workplace presents special opportunities as well as challenges for HRM. Machine learning, a branch of artificial intelligence, has the potential to completely transform human resource management (HRM) by means of the use of data-driven decision-making, bias mitigation, employee experience personalization, as well as procedure optimization. The first section of the paper provides an overview of machine learning's application to HRM, with a particular focus on forward-thinking employee turnover prediction, personalized onboarding and training, recruitment automation, in addition to predictive analytics for employee success. Machine learning promotes fairness and equal opportunities by utilizing objective data to address bias in HR procedures. There are numerous advantages to incorporating machine learning into HRM, such as objectivity, personalization, automation that reduces costs, and decision-making based on information. The practical advantages of integrating machine learning in HRM are demonstrated by real-world case studies from businesses like Hilton, Xerox, and IBM. The resulting advantages include improved productivity, lower attrition, and higher employee engagement.",
    "doi": "10.1109/UPCON59197.2023.10434761",
    "url": "https://www.semanticscholar.org/paper/a29915337616551711d1a8128bab1255090466a7",
    "pdf_url": "",
    "venue": "IEEE Uttar Pradesh Section International Conference on Electrical, Computer and Electronics Engineering",
    "citation_count": 2,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140627"
  },
  {
    "source": "semantic_scholar",
    "source_id": "830bc5710f3d2efbc24fc354a69124c5872f9f98",
    "title": "Auditing the AI auditors: A framework for evaluating fairness and bias in high stakes AI predictive models.",
    "authors": [
      "R. Landers",
      "Tara S. Behrend"
    ],
    "year": 2022,
    "abstract": "Researchers, governments, ethics watchdogs, and the public are increasingly voicing concerns about unfairness and bias in artificial intelligence (AI)-based decision tools. Psychology's more-than-a-century of research on the measurement of psychological traits and the prediction of human behavior can benefit such conversations, yet psychological researchers often find themselves excluded due to mismatches in terminology, values, and goals across disciplines. In the present paper, we begin to build a shared interdisciplinary understanding of AI fairness and bias by first presenting three major lenses, which vary in focus and prototypicality by discipline, from which to consider relevant issues: (a) individual attitudes, (b) legality, ethicality, and morality, and (c) embedded meanings within technical domains. Using these lenses, we next present psychological audits as a standardized approach for evaluating the fairness and bias of AI systems that make predictions about humans across disciplinary perspectives. We present 12 crucial components to audits across three categories: (a) components related to AI models in terms of their source data, design, development, features, processes, and outputs, (b) components related to how information about models and their applications are presented, discussed, and understood from the perspectives of those employing the algorithm, those affected by decisions made using its predictions, and third-party observers, and (c) meta-components that must be considered across all other auditing components, including cultural context, respect for persons, and the integrity of individual research designs used to support all model developer claims. (PsycInfo Database Record (c) 2022 APA, all rights reserved).",
    "doi": "10.1037/amp0000972",
    "url": "https://www.semanticscholar.org/paper/830bc5710f3d2efbc24fc354a69124c5872f9f98",
    "pdf_url": "",
    "venue": "American Psychologist",
    "citation_count": 143,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140629"
  },
  {
    "source": "semantic_scholar",
    "source_id": "5c6bc0f99b7314d37d0bbde84716eb0d0f8d930f",
    "title": "Guest Editorial: Business Ethics in the Era of Artificial Intelligence",
    "authors": [
      "M. Haenlein",
      "Ming-Hui Huang",
      "Andrea Edith Kaplan"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1007/s10551-022-05060-x",
    "url": "https://www.semanticscholar.org/paper/5c6bc0f99b7314d37d0bbde84716eb0d0f8d930f",
    "pdf_url": "",
    "venue": "Journal of Business Ethics",
    "citation_count": 47,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140630"
  },
  {
    "source": "semantic_scholar",
    "source_id": "5d6a997eb7b226917c3d98d2f72d84be45384b23",
    "title": "AI Ethics and Transparency in Operations Management: How Governance Mechanisms Can Reduce Data Bias and Privacy Risks",
    "authors": [
      "Zuowei Li"
    ],
    "year": 2024,
    "abstract": "The use of artificial intelligence (AI) in operations management holds the key to efficiency, precision and agility in business decision-making, yet it also involves ethical challenges such as fairness, accountability, transparency and privacy that can undermine trust in AI. This paper examines the ethical considerations of AI use in operations, paying particular attention to data bias, privacy risks and governance. Drawing on major governance frameworks such as the OECD AI Principles and the EUs Ethics Guidelines for Trustworthy AI, this paper proposes a hybrid governance model to address the unique challenges of operational contexts. A case study in the financial sector is used to further explain how privacy-preserving techniques can safeguard the sensitive customer data needed for AI-driven customer service. Extensive experimentation conducted in that case has shown that privacy-preserving methods such as differential privacy and federated learning can reduce the incidence of unauthorised data-access events by as much as 30 per cent and can improve customer satisfaction by more than 20 per cent. This paper contributes to the dynamic discourse on ethical AI by offering practical recommendations to organisations on how to conduct AI operations in a way that is responsible and compliant.",
    "doi": "10.54254/2977-5701/13/2024130",
    "url": "https://www.semanticscholar.org/paper/5d6a997eb7b226917c3d98d2f72d84be45384b23",
    "pdf_url": "https://www.ewadirect.com/journal/jaeps/article/view/18052/pdf",
    "venue": "Journal of Applied Economics and Policy Studies",
    "citation_count": 8,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140632"
  },
  {
    "source": "semantic_scholar",
    "source_id": "ffa5a275be9ea886dff66494c821f2b2db2f091d",
    "title": "Exploring Ethical Dimensions in AI: Navigating Bias and Fairness in the Field",
    "authors": [
      "Jeff Shuford"
    ],
    "year": 2024,
    "abstract": "The rapid progress in implementing Artificial Intelligence (AI) across various domains such as healthcare decision-making, medical diagnosis, and others has raised significant concerns regarding the fairness and bias embedded within AI systems. This is particularly crucial in sectors like healthcare, employment, criminal justice, credit scoring, and the emerging field of generative AI models (GenAI) producing synthetic media. Such systems can lead to unfair outcomes and perpetuate existing inequalities, including biases ingrained in the synthetic data representation of individuals.This survey paper provides a concise yet comprehensive examination of fairness and bias in AI, encompassing their origins, ramifications, and potential mitigation strategies. We scrutinize sources of bias, including data, algorithmic, and human decision biases, shedding light on the emergent issue of generative AI bias where models may replicate and amplify societal stereotypes. Assessing the societal impact of biased AI systems, we spotlight the perpetuation of inequalities and the reinforcement of harmful stereotypes, especially as generative AI gains traction in shaping public perception through generated content.Various proposed mitigation strategies are explored, with an emphasis on the ethical considerations surrounding their implementation. We stress the necessity of interdisciplinary collaboration to ensure the effectiveness of these strategies. Through a systematic literature review spanning multiple academic disciplines, we define AI bias and its various types, delving into the nuances of generative AI bias. We discuss the adverse effects of AI bias on individuals and society, providing an overview of current approaches to mitigate bias, including data preprocessing, model selection, and post-processing. Unique challenges posed by generative AI models are highlighted, underscoring the importance of tailored strategies to address them effectively.Addressing bias in AI necessitates a holistic approach, involving diverse and representative datasets, enhanced transparency, and accountability in AI systems, and exploration of alternative AI paradigms prioritizing fairness and ethical considerations. This survey contributes to the ongoing discourse on developing fair and unbiased AI systems by outlining the sources, impacts, and mitigation strategies related to AI bias, with a particular focus on the burgeoning field of generative AI.",
    "doi": "10.60087/jaigs.vol03.issue01.p124",
    "url": "https://www.semanticscholar.org/paper/ffa5a275be9ea886dff66494c821f2b2db2f091d",
    "pdf_url": "https://jaigs.org/index.php/JAIGS/article/download/54/41",
    "venue": "Journal of Artificial Intelligence General science (JAIGS) ISSN:3006-4023",
    "citation_count": 3,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140633"
  },
  {
    "source": "semantic_scholar",
    "source_id": "78ef946e2cff0e57e92bf538a1d1f0f5a2775ae3",
    "title": "Research on the Application of Large Language Models in Human Resource Management Practices",
    "authors": [
      "Jingran Sun"
    ],
    "year": 2024,
    "abstract": "With the rapid development of artificial intelligence technology, large language models (LLMs) are being increasingly applied across various fields. This paper focuses on the research of LLMs in human resource management practices, discussing the current applications, challenges, and future trends of LLMs in core HR functions such as recruitment, training, and performance management. Through a systematic review and analysis of existing literature, this study finds that LLMs demonstrate enormous potential in HR management, significantly improving work efficiency, optimizing decision-making processes, and personalizing employee experiences. However, challenges such as data privacy, algorithmic bias, and ethical concerns still exist in practical applications. This paper proposes a series of recommendations to promote the effective application of LLMs in HR management and provides insights for future research directions.",
    "doi": "10.62677/ijetaa.2408125",
    "url": "https://www.semanticscholar.org/paper/78ef946e2cff0e57e92bf538a1d1f0f5a2775ae3",
    "pdf_url": "",
    "venue": "International Journal of Emerging Technologies and Advanced Applications",
    "citation_count": 4,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140635"
  },
  {
    "source": "semantic_scholar",
    "source_id": "8b8eefd16afffd5198d055b5e1a0ffd29739238b",
    "title": "EXPLORING THE LANDSCAPE: A LITERATURE REVIEW OF AI\u2019S IMPACT ON HUMAN RESOURCE MANAGEMENT",
    "authors": [
      "Daniel-Florin D\u0103niloaia"
    ],
    "year": 2024,
    "abstract": "This article explores literature and finds the transformative impact of artificial \nintelligence (AI) on human resource management (HRM), highlighting its applications \nand benefits across various HR functions. AI enhances recruitment, training, \nperformance management, and compensation by automating routine tasks and providing \nadvanced analytics. This allows HR professionals to focus on strategic decision-making \nand personalized employee engagement. Despite challenges such as data privacy \nconcerns and algorithmic bias, AI improves efficiency, accuracy, and employee \nsatisfaction. The article emphasizes the need for balancing technological advancements \nwith ethical considerations to ensure AI complements rather than replaces human skills.",
    "doi": "10.47743/ejpar.2024-3-6",
    "url": "https://www.semanticscholar.org/paper/8b8eefd16afffd5198d055b5e1a0ffd29739238b",
    "pdf_url": "",
    "venue": "European Journal of Public Administration Research",
    "citation_count": 3,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140636"
  },
  {
    "source": "semantic_scholar",
    "source_id": "42451898b9c9b5c9c6a65614ac5f2e7e8be8d93b",
    "title": "Explainable deep learning integrated with decentralized identity systems to combat bias, enhance trust, and ensure fairness in algorithmic governance",
    "authors": [
      "Oyegoke Oyebode"
    ],
    "year": 2024,
    "abstract": "The growing reliance on artificial intelligence in decision-making processes has intensified debates over bias, fairness, and accountability in algorithmic governance. While deep learning models deliver unprecedented predictive performance, their \u201cblack box\u201d nature has undermined transparency and public trust, particularly in high-stakes applications such as finance, healthcare, and digital public services. Explainable AI (XAI) has emerged to address this gap by making model reasoning interpretable, yet explainability alone cannot guarantee fairness without verifiable systems of identity and accountability. This study proposes a framework that integrates explainable deep learning with decentralized identity (DID) systems to combat bias, enhance trust, and ensure equitable governance outcomes. In this framework, explainable deep learning models provide human-understandable insights into algorithmic decisions, enabling stakeholders to evaluate reasoning processes. Meanwhile, decentralized identity systems built on blockchain technologies ensure that individuals retain control over their digital identities, reducing risks of centralized manipulation and exclusion. By linking interpretable models with verifiable identity protocols, algorithmic governance can achieve both transparency and fairness while protecting privacy. The integration enables bias detection and correction at both the model and system levels: interpretable models flag discriminatory features, while decentralized identity guarantees equitable access across diverse populations. Applications in digital voting, welfare distribution, and credit scoring illustrate how the framework strengthens accountability and prevents systemic marginalization. Ultimately, combining explainable deep learning with decentralized identity provides a path toward trustworthy and fair algorithmic governance, where decisions are not only accurate but also transparent, inclusive, and ethically aligned with societal values.",
    "doi": "10.30574/wjarr.2024.21.2.0595",
    "url": "https://www.semanticscholar.org/paper/42451898b9c9b5c9c6a65614ac5f2e7e8be8d93b",
    "pdf_url": "",
    "venue": "World Journal of Advanced Research and Reviews",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140637"
  },
  {
    "source": "semantic_scholar",
    "source_id": "9534e6b18c015575f7f49d5a1252c6a854a690d7",
    "title": "Ethics and governance of trustworthy medical artificial intelligence",
    "authors": [
      "Jie Zhang",
      "Zong-Ming Zhang"
    ],
    "year": 2023,
    "abstract": "Background The growing application of artificial intelligence (AI) in healthcare has brought technological breakthroughs to traditional diagnosis and treatment, but it is accompanied by many risks and challenges. These adverse effects are also seen as ethical issues and affect trustworthiness in medical AI and need to be managed through identification, prognosis and monitoring. Methods We adopted a multidisciplinary approach and summarized five subjects that influence the trustworthiness of medical AI: data quality, algorithmic bias, opacity, safety and security, and responsibility attribution, and discussed these factors from the perspectives of technology, law, and healthcare stakeholders and institutions. The ethical framework of ethical values-ethical principles-ethical norms is used to propose corresponding ethical governance countermeasures for trustworthy medical AI from the ethical, legal, and regulatory aspects. Results Medical data are primarily unstructured, lacking uniform and standardized annotation, and data quality will directly affect the quality of medical AI algorithm models. Algorithmic bias can affect AI clinical predictions and exacerbate health disparities. The opacity of algorithms affects patients\u2019 and doctors\u2019 trust in medical AI, and algorithmic errors or security vulnerabilities can pose significant risks and harm to patients. The involvement of medical AI in clinical practices may threaten doctors \u2018and patients\u2019 autonomy and dignity. When accidents occur with medical AI, the responsibility attribution is not clear. All these factors affect people\u2019s trust in medical AI. Conclusions In order to make medical AI trustworthy, at the ethical level, the ethical value orientation of promoting human health should first and foremost be considered as the top-level design. At the legal level, current medical AI does not have moral status and humans remain the duty bearers. At the regulatory level, strengthening data quality management, improving algorithm transparency and traceability to reduce algorithm bias, and regulating and reviewing the whole process of the AI industry to control risks are proposed. It is also necessary to encourage multiple parties to discuss and assess AI risks and social impacts, and to strengthen international cooperation and communication.",
    "doi": "10.1186/s12911-023-02103-9",
    "url": "https://www.semanticscholar.org/paper/9534e6b18c015575f7f49d5a1252c6a854a690d7",
    "pdf_url": "https://bmcmedinformdecismak.biomedcentral.com/counter/pdf/10.1186/s12911-023-02103-9",
    "venue": "BMC Medical Informatics and Decision Making",
    "citation_count": 284,
    "fields_of_study": [
      "Computer Science",
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140639"
  },
  {
    "source": "semantic_scholar",
    "source_id": "78de9c493c6b9a93492df504d784d001459b7858",
    "title": "Ethics for Artificial Intelligence, Ethics for All",
    "authors": [
      "Knud Thomsen"
    ],
    "year": 2019,
    "abstract": "Abstract For human ethics, it can convincingly be argued that justice is a central cornerstone and basis. Here, it is suggested that this can, to some extent, similarly be applied to robots. The article makes the argument that Rawls\u2019 veil of ignorance in his conception of justice as fairness can effectively be replaced by a much more natural condition of prudent egoism in a finite world. Observing ones\u2019 own important interests in an encompassing context paves the way for a guideline for the conduct, which is binding for humans, robots and each and every pragmatic agent with a minimum level of rationality. These arguments do not see humans (forever) in any privileged position: any agent, single human, state, alien or artificial with a certain minimum of general cognitive (and effective) capabilities is bound by a universal negative imperative. This entails that precautious procedures are preferable, and some general prudently constrained flexibility is required for self-consistency and survival.",
    "doi": "10.1515/pjbr-2019-0029",
    "url": "https://www.semanticscholar.org/paper/78de9c493c6b9a93492df504d784d001459b7858",
    "pdf_url": "https://www.degruyter.com/downloadpdf/journals/pjbr/10/1/article-p359.pdf",
    "venue": "Paladyn J. Behav. Robotics",
    "citation_count": 9,
    "fields_of_study": [
      "Computer Science",
      "Psychology"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140641"
  },
  {
    "source": "semantic_scholar",
    "source_id": "a58796b7403268d4d70d457fd7f1ef5f153ee9f0",
    "title": "Barriers and Enablers in Integrating AI into Human Resource Management Strategies: Maximizing Human Capital",
    "authors": [
      "Dr. U. Amaleshwari, R. Shanmugapriya"
    ],
    "year": 2024,
    "abstract": "Artificial intelligence (AI) has shaken the foundation of modern workplaces like never before and has induced digitized workstyles within the organisation. These furtherance in technology are generating significant interest among stakeholders to embrace AI in human resource management (HRM). Research and Development teams, analysts and practitioners are keen to investigate the sequel of AI in HR and their collaboration with gadget applications involving machine language, Data-science, Blockchain and Big Data. This study investigates HRM specific factors that are imbibed towards adoption of AI in extended HR based digital platform adopting a qualitative research design with an abductive approach. This research also investigates key enablers like optimistic, enthusiastic, and collaborative employees, strong digital enabled leadership, reliable HR meta-data, specialized HR partners, and well-rounded accountable AI ethics. The study also examines barriers towards awareness in AI adoption: the inability to have a timely internal audit pulse check of employees, their ability of emotional decision making, ineffective agile digital experts as well as external HR partners. On summarising, this study also contributes theory by providing a model that influences AI adoption and proposes ascending in welcoming unified theory of acceptance and use of innovative technology in the context of AI adoption in HR upskilling and reskilling ecosystems eventually. The study also contributes the anecdotes of best-in-class industrial HR practices with secured digital policy formulation to reimagine cybermated workplaces cubical. Maximising the human capital in the digital era be obliged in harmonious conglomerative human\u2013AI enterprise making workplaces an eminent future-ready in the wake of productive and massive successful digital disruptions with efficacy. \n\u00a0",
    "doi": "10.52783/eel.v14i1.1295",
    "url": "https://www.semanticscholar.org/paper/a58796b7403268d4d70d457fd7f1ef5f153ee9f0",
    "pdf_url": "https://eelet.org.uk/index.php/journal/article/download/1295/1115",
    "venue": "European Economic Letters (EEL)",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140642"
  },
  {
    "source": "semantic_scholar",
    "source_id": "b5c00cb5e31924070b6442adb1c6771a03578594",
    "title": "A cloud-based architecture for explainable Big Data analytics using self-structuring Artificial Intelligence",
    "authors": [
      "Nishan Mills",
      "Zafar Issadeen",
      "Amali Matharaarachchi",
      "T. Bandaragoda",
      "Daswin De Silva",
      "Andrew Jennings",
      "Milos Manic"
    ],
    "year": 2024,
    "abstract": "Big Data is steadily expanding beyond the boundaries of its foundational constructs of three primary Vs, Volume, Velocity and Variety, and two secondary Vs, Veracity and Value. The advent of 5G networks, Edge computing and IoT technologies has transformed Big Data into this modern context. With these new manifestations of Big Data, the focus is not only on the data itself but on the context that it applies to its immediate environment as well as the human and societal perception of this context. It is increasingly challenging for conventional AI algorithms to process and transform this data, analyse and visualise a broad spectrum of insights, and then formulate the explainability of such insights in terms of bias, transparency, safety, ethics, and causality. Self-structuring Artificial Intelligence (SSAI) addresses the limitations of conventional AI by adapting to the inherent structure of the data, incrementally learning and abstracting from this structure. SSAI has not been investigated in a cloud-based setting for generating explainable insights from these new types of Big Data. In this paper we propose a cloud-based architecture for explainable Big Data analytics using SSAI in highly-connected 5G and Edge computing environments. The proposed architecture is empirically evaluated on a commercial scale Big Data use case of Smart Grid for Smart Cities. The results of these experiments confirm the functionality and effectiveness of the proposed architecture.",
    "doi": "10.1007/s44163-024-00123-6",
    "url": "https://www.semanticscholar.org/paper/b5c00cb5e31924070b6442adb1c6771a03578594",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s44163-024-00123-6.pdf",
    "venue": "Discover Artificial Intelligence",
    "citation_count": 6,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140643"
  },
  {
    "source": "semantic_scholar",
    "source_id": "5168acd455cf906cc1e44facdb34a33c35ae4ab6",
    "title": "Understanding Recruiters\u2019 Acceptance of Artificial Intelligence: Insights from the Technology Acceptance Model",
    "authors": [
      "Filomena Almeida",
      "Ana Jun\u00e7a Silva",
      "Sara L. Lopes",
      "Isabel Braz"
    ],
    "year": 2025,
    "abstract": "The integration of new technologies in professional contexts has emerged as a critical determinant of organizational efficiency and competitiveness. In this regard, the application of Artificial Intelligence (AI) in recruitment processes facilitates faster and more accurate decision-making by processing large volumes of data, minimizing human bias, and offering personalized recommendations to enhance talent development and candidate selection. The Technology Acceptance Model (TAM) provides a valuable framework for understanding recruiters\u2019 perceptions of innovative technologies, such as AI tools and GenAI. Drawing on the TAM, a model was developed to explain the intention to use AI tools, proposing that perceived ease of use and perceived usefulness influence attitudes toward AI, which subsequently affect the intention to use AI tools in recruitment and selection processes. Two studies were conducted in Portugal to address this research objective. The first was a qualitative exploratory study involving 100 interviews with recruiters who regularly utilize AI tools in their professional activities. The second study employed a quantitative confirmatory approach, utilizing an online questionnaire completed by 355 recruiters. The qualitative findings underscored the transformative role of AI in recruitment, emphasizing its potential to enhance efficiency and optimize resource management. However, recruiters also highlighted concerns regarding the potential loss of personal interaction and the need to adapt roles within this domain. The results also supported the indirect effect of perceived ease of use and perceived usefulness on the use of AI tools in recruitment and selection processes via positive attitudes toward the use of these tools. This suggests that AI is best positioned as a complementary tool rather than a replacement for human decision-making. The insights gathered from recruiters\u2019 perspectives provide actionable recommendations for organizations seeking to leverage AI in recruitment processes. Specifically, the findings show the importance of ethical considerations and maintaining human involvement to ensure a balanced and effective integration of AI tools.",
    "doi": "10.3390/app15020746",
    "url": "https://www.semanticscholar.org/paper/5168acd455cf906cc1e44facdb34a33c35ae4ab6",
    "pdf_url": "https://doi.org/10.3390/app15020746",
    "venue": "Applied Sciences",
    "citation_count": 21,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140645"
  },
  {
    "source": "semantic_scholar",
    "source_id": "20d98ea79c7b108bcc07aeb4fa4f152948919d53",
    "title": "Artificial Intelligence in Performance Evaluation (Case Study of PT. Pos Indonesia Employees)",
    "authors": [
      "Agung Dwianto",
      "Sitta Kusuma",
      "Junengsih"
    ],
    "year": 2024,
    "abstract": "The development of artificial intelligence (AI) has revolutionized various aspects of human resource management, including employee performance evaluation. While existing studies have extensively explored the potential of AI in improving efficiency and objectivity, they often overlook the nuanced employee experiences and organizational dynamics that influence its successful implementation. This research bridges this gap by examining the perceptions and experiences of PT Pos Indonesia employees regarding the use of an AI-based performance evaluation system. Using a qualitative approach with a phenomenological design, data was collected through in-depth interviews with employees who have used the system for at least six months. The findings reveal that AI contributes significantly to enhancing efficiency and reducing subjectivity in evaluations. However, challenges such as algorithm bias, the relevance of performance metrics, and system transparency remain prevalent. Importantly, this study identifies critical factors influencing acceptance, including employee understanding, trust, and perceptions of fairness in the evaluation process. Unlike previous research, this study emphasizes the interplay between technological and human factors, highlighting the irreplaceable role of human interaction in providing qualitative context. This research extends the existing literature by offering a deeper understanding of employee-centered factors and organizational practices that facilitate the integration of AI in performance evaluation. Practically, it provides actionable insights for organizations aiming to implement AI-based systems effectively, ethically, and equitably.",
    "doi": "10.32877/bt.v7i2.1817",
    "url": "https://www.semanticscholar.org/paper/20d98ea79c7b108bcc07aeb4fa4f152948919d53",
    "pdf_url": "",
    "venue": "bit-Tech",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140646"
  },
  {
    "source": "semantic_scholar",
    "source_id": "a4acf62a6dcc898e77f6a7f0dea11bda6451611a",
    "title": "The Applications of Artificial Intelligence in Human Resources",
    "authors": [
      "Priyal Gordiya"
    ],
    "year": 2024,
    "abstract": "The study examines the transformative role of artificial intelligence in Human resources and its profound implications for the future of workforce management. Questionnaires are used to evaluate the current perception, applications & adoption of artificial intelligence in human resources practices, as well as its potential impact and ability to shape tomorrow's Human Resource landscape. Understanding of how people view the integration of AI in human resources functions, by rigorously analysing questionnaire responses. These findings reveal the apprehensions, expectations and acceptance levels of AI driven human resource management processes. In addition, important foresight is provided on the evolution of technology and Human Capital dynamics within organisational structures. Moreover, a compelling case study is presented to demonstrate the effectiveness of AI when it comes to human resource management on an actual basis. The case study shows how AI solutions simplify recruitment, enhance employee engagement, optimise talent management and mitigate biases in the decision making process for a more agile, data driven environment that is inclusive. Finally, this research aims at breaking down the complex implications of artificial intelligence for human resources and providing information on its transformative potential which will make it easier to adopt effective decisions as part of organisational HR strategies. Keywords: Artificial Intelligence, Human Resources, Case Study, Perception, Awareness",
    "doi": "10.55041/isjem01599",
    "url": "https://www.semanticscholar.org/paper/a4acf62a6dcc898e77f6a7f0dea11bda6451611a",
    "pdf_url": "",
    "venue": "International Scientific Journal of Engineering and Management",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140648"
  },
  {
    "source": "semantic_scholar",
    "source_id": "03e4a19eff4063130d0f46affc11297fb8ef0895",
    "title": "Balcerzak, Michal and Julia Kapela\u0144ska-Pr\u0119gowska, eds. 2024. Artificial Intelligence and International Human Rights Law. Developing Standards for a Changing World",
    "authors": [
      "Itziar Art\u00ed\u00f1ano Ortiz"
    ],
    "year": 2024,
    "abstract": "This work analyzes the intersections between artificial intelligence (AI) and human rights from an international perspective. It analyzes the regulatory efforts of essential entities such as the United Nations, the Council of Europe, and the European Union. Recent initiatives that aim to establish ethical and legal standards to address the risks associated with AI are highlighted. Mass surveillance, algorithmic bias, and privacy violations stand out among these aspects. The book takes a unique approach, integrating a normative perspective with analyses of specific cases to examine the impact of artificial intelligence in key areas such as justice, health, labor rights, and privacy. It delves into challenges such as video manipulation, facial recognition regulations, and ethical conflicts in applying autonomous technologies in international settings. The book underscores the necessity of a flexible legal framework that accommodates technological advances while upholding fundamental rights. It also underscores the need to strengthen the responsibility of states and private entities to protect these rights. This volume is a fundamental reference point in the creation of international norms that ensure artificial intelligence respects human rights and proactively participates in their promotion in a globalized and constantly evolving world. Its insights are invaluable in the field of AI ethics and human rights.",
    "doi": "10.18543/djhr.3200",
    "url": "https://www.semanticscholar.org/paper/03e4a19eff4063130d0f46affc11297fb8ef0895",
    "pdf_url": "",
    "venue": "Deusto Journal of Human Rights",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140649"
  },
  {
    "source": "semantic_scholar",
    "source_id": "f144e643f65fb4965f01dceac011152d0aa912d9",
    "title": "A Report Review: Artificial Intelligence and the Future of Teaching and Learning",
    "authors": [
      "Weny Kritandani",
      "R. Aryani",
      "Tetta Rakasiwi"
    ],
    "year": 2024,
    "abstract": "This review provides an insightful overview of \"Artificial Intelligence and the Future of Teaching and Learning,\" a policy report by the United States Department of Education. Keywords such as Artificial Intelligence (AI) development, policy-making, ethics, equity, collaboration, and human-centric approach are emphasised throughout. The review highlights the report's comprehensive analysis, actionable recommendations, and emphasis on inclusive policy-making processes. It underscores the significance of understanding AI's multifaceted nature, its potential to enhance education, and the importance of safeguarding privacy and equity. Practical examples and case studies are discussed, along with recommendations for aligning AI with educational goals. Overall, the review positions the report as a valuable resource for policymakers, educators, and technology developers, guiding them toward responsible AI integration in education.",
    "doi": "10.17977/um043v6i2p245-253",
    "url": "https://www.semanticscholar.org/paper/f144e643f65fb4965f01dceac011152d0aa912d9",
    "pdf_url": "https://journal2.um.ac.id/index.php/irbej/article/download/51618/12925",
    "venue": "International research-based education journal",
    "citation_count": 9,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140651"
  },
  {
    "source": "semantic_scholar",
    "source_id": "7526ec41d691039bd104afd2039fdb5f7e41d55f",
    "title": "Ethics of the Use of Artificial Intelligence (AI) in the Paradigm of Islamic Law",
    "authors": [
      "Mulki Firdaus Alamsyah",
      "Yayuli",
      "Ahmad Remanda"
    ],
    "year": 2025,
    "abstract": "Objective: The principal objective of this scholarly inquiry is to meticulously examine the ethical implications of artificial intelligence (AI) within the context of Islamic jurisprudence, with a distinct focus on the principles of maqosid al-shari\u2018ah (the paramount objectives of Islamic law) serving as a moral and legal foundation for the evaluation of AI applications. Theoretical framework: The theoretical foundations of this investigation are derived from Islamic legal and ethical philosophy, specifically the five fundamental values of maqosid al-shari\u2018ah, safeguarding of faith, life, intellect, lineage, and property employed as evaluative criteria to assess the integration of technology within Muslim societies. Literature review: A diverse array of primary sources, including the Qur\u2019an and Hadith, is meticulously scrutinized alongside contemporary Islamic scholarship that addresses the intersection of ethics and technology. Previous research on Islamic ethics in the digital and biomedical spheres is referenced, elaborated upon, and critically appraised to ensure a contemporary and contextually relevant analysis. Methods: This investigation adopts a qualitative methodology based on an exhaustive literature review. Primary religious texts and secondary academic discourses concerning AI ethics and Islamic law are analyzed through thematic content analysis to develop a normative framework that harmonizes Shariah principles with emerging AI technologies. Results: The findings of this research indicate that while AI offers substantial benefits in areas such as healthcare, education, and governance, it simultaneously presents ethical challenges, including issues related to surveillance, algorithmic bias, and a reduction in human accountability. From an Islamic standpoint, AI should not replace human moral agency but rather enhance it. Justice, accountability, and the welfare of the community must remain of utmost importance in its application. Implications: This study highlights the urgent need for interdisciplinary dialogue between Islamic scholars and technology developers, the promotion of Islamic ethical awareness among Muslim AI practitioners, and the establishment of fatwas and Shariah-compliant regulatory frameworks to ensure the ethical incorporation of AI into Muslim societies. Novelty: This research offers a noteworthy contribution to the burgeoning field of Islamic AI ethics by providing a structured, Shariah-aligned ethical framework for the assessment and guidance of AI technologies. It underscores the adaptability of Islamic jurisprudence in addressing contemporary innovations while remaining steadfastly anchored in enduring ethical principles.",
    "doi": "10.61455/sicopus.v4i01.393",
    "url": "https://www.semanticscholar.org/paper/7526ec41d691039bd104afd2039fdb5f7e41d55f",
    "pdf_url": "",
    "venue": "Solo International Collaboration and Publication of Social Sciences and Humanities",
    "citation_count": 4,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140652"
  },
  {
    "source": "semantic_scholar",
    "source_id": "d59c2a543b146c80bea4a46b26c6647552cdc9ba",
    "title": "Ethical gaps in the ethics of artificial intelligence",
    "authors": [
      "Vasilii Andreevich Avdyunin"
    ],
    "year": 2025,
    "abstract": "The development of neural networks and their active implementation in various spheres of the economy have raised the challenge of ethical evaluation and legal regulation of the development and application of artificial intelligence (AI) systems. Over the last decade, more than 200 ethical codes and recommendations have been created worldwide, which are actively discussed within the framework of scientific research. The majority of these documents are based on a principle-based approach that sets the boundaries of ethics in the field of AI. This article examines the ethical gaps in artificial intelligence ethics through the development of a multi-level system of strategies to overcome them. The subject of the research is specific mechanisms and strategies for transforming abstract ethical principles into functioning practices at each level. This article discusses the main approaches to addressing issues in artificial intelligence ethics. A systemic approach is proposed as a methodological basis, integrating technical solutions, organizational changes, and legal mechanisms. The applicability of the proposed approach is demonstrated through the analysis of key ethical issues in AI: systematic reproduction of biases, the \"black box\" problem, distribution of responsibility, the declarative nature of ethical and legal norms, and the challenges of responsibility attribution. For each problem, specific methods of resolution are outlined - from the creation of counterfactual fairness algorithms to checklists for assessing the ethics of AI systems. Conclusions are drawn that a three-level \"filter\" system is necessary for systematically addressing ethical gaps in AI ethics, which involves differentiating approaches at the development level, organizational changes, creating new principles for state regulation, and a shift in the paradigm of responsibility distribution. The main conclusion of the research is the need for a comprehensive systemic approach, where the rigor of regulation is proportional to the potential harm from the use of the AI system.",
    "doi": "10.25136/2409-8728.2025.12.77033",
    "url": "https://www.semanticscholar.org/paper/d59c2a543b146c80bea4a46b26c6647552cdc9ba",
    "pdf_url": "",
    "venue": "\u0424\u0438\u043b\u043e\u0441\u043e\u0444\u0441\u043a\u0430\u044f \u043c\u044b\u0441\u043b\u044c",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140654"
  },
  {
    "source": "semantic_scholar",
    "source_id": "61f22b225b278259e978235e41dce4811f6e9bea",
    "title": "The Anchoring Effect, Algorithmic Fairness, and the Limits of Information Transparency for Emotion Artificial Intelligence",
    "authors": [
      "Lauren Rhue"
    ],
    "year": 2023,
    "abstract": "Emotion artificial intelligence (AI) is shown to vary systematically in its ability to accurately identify emotions, and this variation creates potential biases. In this paper, we conduct an experiment involving three commercially available emotion AI systems and a group of human labelers tasked with identifying emotions from two image data sets. The study focuses on the alignment between facial expressions and the emotion labels assigned by both the AI and humans. Importantly, human labelers are given the AI\u2019s scores and informed about its algorithmic fairness measures. This paper presents several key findings. First, the labelers\u2019 scores are affected by the emotion AI scores, consistent with the anchoring effect. Second, information transparency about the AI\u2019s fairness does not uniformly affect human labeling across different emotions. Moreover, information transparency can even increase human inconsistencies. Plus, significant inconsistencies in the scoring among different emotion AI models cast doubt on their reliability. Overall, the study highlights the limitations of individual decision making and information transparency regarding algorithmic fairness measures in addressing algorithmic fairness. These findings underscore the complexity of integrating emotion AI into practice and emphasize the need for careful policies on emotion AI.",
    "doi": "10.1287/isre.2019.0493",
    "url": "https://www.semanticscholar.org/paper/61f22b225b278259e978235e41dce4811f6e9bea",
    "pdf_url": "",
    "venue": "Information systems research",
    "citation_count": 22,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140655"
  },
  {
    "source": "semantic_scholar",
    "source_id": "11d2e9cd96039efc734b5baf25e38f7640c79435",
    "title": "ETHICS AND RESPONSIBILITY IN THE IMPLEMENTATION OF ARTIFICIAL INTELLIGENCE IN JUSTICE",
    "authors": [
      "Volodymyr Zverev",
      "V. Bushkov",
      "B. Khrushkov",
      "Andriy Shavolin",
      "Serhiy Smyshlyaev",
      "Yehor Prokopovych-Tkachenko"
    ],
    "year": 2025,
    "abstract": "The article examines the complex challenges and prospects arising from the implementation of artificial intelligence (AI) in the justice system. The growing role of automated algorithms in legal procedures demonstrates the intention to increase the efficiency of judicial proceedings and optimize the work of law enforcement agencies. At the same time, the use of AI can give rise to a number of ethical, legal and technical problems, particularly issues of transparency, accountability, algorithmic discrimination and biases that manifest in judicial practice and law enforcement processes. The article analyzes scientific approaches to the formation of principles of accountability when making AI decisions and proposes theoretical and practical guidelines for developing the transparency and reliability of intelligent algorithms in the legal sphere. Considerable attention is paid to the research methodology, which combines formal-legal and empirical methods, as well as algorithmic modeling and machine learning tools. The \u201cResults\u201d section provides examples of quantitative analyses and compares the effectiveness of different approaches to the application of AI in jurisprudence. Visualizations and tables demonstrate statistical information and features of the integration of AI into judicial procedures and legal practice. The \u201cDiscussion\u201d highlights the theoretical and practical aspects of the developing of an ethics code and legal regulation possibilities, considering diverse challenges. It is concluded that for the effective implementation of AI in justice, wholesome models of transparency, independent auditing and regulatory mechanisms should be developed that also consider the specifics of the judicial system, human rights and the protection of confidential information. Proposals are formulated to establish the responsibility of developers, users and government agencies.",
    "doi": "10.69635/ciai.2025.10",
    "url": "https://www.semanticscholar.org/paper/11d2e9cd96039efc734b5baf25e38f7640c79435",
    "pdf_url": "",
    "venue": "Contemporary Issues in Artificial Intelligence",
    "citation_count": 2,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140656"
  },
  {
    "source": "semantic_scholar",
    "source_id": "2f43f82828c430d283e6531bcce62019ea0f59a4",
    "title": "Evolving uses of artificial intelligence in human resource management in emerging economies in the global South: some preliminary evidence",
    "authors": [
      "N. Kshetri"
    ],
    "year": 2021,
    "abstract": "Purpose: The purpose of this paper is to examine the use of artificial intelligence (AI) in human resource management (HRM) in the Global South. Design/methodology/approach: Multiple case studies of AI tools used in HRM in these countries in recruiting and selecting as well as developing, retaining and productively utilizing employees have been used. Findings: With AI deployment in HRM, organizations can enhance efficiency in recruitment and selection and gain access to a larger recruitment pool. With AI deployment in HRM, subjective criteria such as nepotism and favoritism are less likely to come into play in recruitment and selection of employees. AI deployment in HRM also has a potentially positive impact on the development, retainment and productive utilization of employees. Research limitations/implications: AI is an evolving technology. Most HRM apps have not gained enough machine learning capabilities with real-world experience. Some of them lack a scientific basis. AI in HRM thus currently affects only a tiny proportion of the population in the GS. Practical implications: The paper explores the roles of AI in expanding recruitment pools. It also advances our understanding of how AI-based HIRM tools can help reduce biases in selecting candidates, which is especially important in the Global South. It also delves into various mechanisms by which AI helps in the development, retainment and productive utilization of employees. Originality/value: We provide details of various mechanisms by which AI brings input and output efficiencies in recruitment and selection in these countries.",
    "doi": "10.1108/mrr-03-2020-0168",
    "url": "https://www.semanticscholar.org/paper/2f43f82828c430d283e6531bcce62019ea0f59a4",
    "pdf_url": "http://libres.uncg.edu/ir/uncg/f/N_Kshetri_Evolving_2021.pdf",
    "venue": "",
    "citation_count": 88,
    "fields_of_study": [
      "Business"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140658"
  },
  {
    "source": "semantic_scholar",
    "source_id": "cbd7be183791cd2ce31d5533b8050c4922dc45df",
    "title": "ETHICS AND ADVANCEMENT OF ARTIFICIAL INTELLIGENCE IN INTERNATIONAL HR-MANAGEMENT: RISKS AND WAYS TO MINIMIZE THEM",
    "authors": [
      "T. Aizenberg"
    ],
    "year": 2025,
    "abstract": "The article explores the ethical aspects of using artificial intelligence (AI) in international HR management, with a particular focus on the risks of discrimination that may arise from the use of historical data. The authors analyze the impact of AI algorithms on key HR processes, including hiring, promotion, and performance evaluation. It is found that automated systems can unconsciously reproduce biases inherent in the original data sets, which can lead to unequal treatment of candidates and employees. \nSpecial attention is paid to the problems of algorithm transparency, personal data protection, and injustice in automated HR systems. An important aspect is the issue of trust in algorithmic solutions, their explainability, and compliance with international standards of ethics and regulation. The lack of clarity and complexity of algorithms can lead to situations where HR professionals cannot explain the reasons for making a decision, which, in turn, reduces the trust in the use of AI in HR management. \nThe article suggests methods to minimize the risks of bias, including careful selection and adjustment of initial data, auditing algorithms for discriminatory factors, ensuring transparency of decision-making processes, and applying a hybrid approach that combines automated systems with human control. In addition, the authors emphasize the importance of adhering to ethical standards and international norms when developing and implementing AI in HR processes. \nAn important aspect of the study is the need to train HR professionals in the principles of working with AI, understanding its capabilities and limitations, as well as methods for identifying and correcting potentially unfair algorithmic decisions. Training and professional development of HR managers in the field of ethical use of AI will help to form a more responsible approach to its application. \nThe author also notes that in order to ensure the effective and fair use of AI in HR, it is necessary to continue developing regulatory frameworks and corporate policies. This will not only minimize the potential risks of discrimination but will also help to increase the overall trust in automated HR solutions. The development of regulatory documents, standardization of approaches to auditing algorithms, and improvement of mechanisms for assessing their ethics are key elements for further integration of AI in HR at the international level.",
    "doi": "10.33989/2226-4051.2025.31.331532",
    "url": "https://www.semanticscholar.org/paper/cbd7be183791cd2ce31d5533b8050c4922dc45df",
    "pdf_url": "",
    "venue": "Aesthetics and Ethics of Pedagogical Action",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140660"
  },
  {
    "source": "semantic_scholar",
    "source_id": "e735a029f453ce06fffb27b75e2cbf29566bfaf5",
    "title": "Development of a Method for Ensuring Fairness of an Artificial Intelligence System in the Implementation Process",
    "authors": [
      "Yejin Shin",
      "KyoungWoo Cho",
      "Joon Ho Kwak",
      "Jaeyoung Hwang"
    ],
    "year": 2022,
    "abstract": "Artificial intelligence (AI) technology is becoming common in daily life as it finds applications in various fields. Consequently, studies have strongly focused on the reliability of AI technology to ensure that it will be used ethically and in a nonmalicious manner. In particular, the fairness of AI technology should be ensured to avoid problems such as discrimination against a certain group (e.g., racial discrimination). This paper defines seven requirements for eliminating factors that reduce the fairness of AI systems in the implementation process. It also proposes a measure to reduce the bias and discrimination that can occur during AI system implementation to ensure the fairness of AI systems. The proposed requirements and measures are expected to enhance the fairness and ensure the reliability of AI systems and to ultimately increase the acceptability of AI technology in human society.",
    "doi": "10.1109/ICTC55196.2022.9952891",
    "url": "https://www.semanticscholar.org/paper/e735a029f453ce06fffb27b75e2cbf29566bfaf5",
    "pdf_url": "",
    "venue": "Information and Communication Technology Convergence",
    "citation_count": 1,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140661"
  },
  {
    "source": "semantic_scholar",
    "source_id": "d52ede1dd9c2f5d9dee8f6fae4203304b18bbdc8",
    "title": "Artificial Intelligence Ethics Taxonomy - Robotic Process Automation (RPA) as Business Case",
    "authors": [
      "D. Beerbaum"
    ],
    "year": 2021,
    "abstract": "A Robotic Process Automation (RPA) enabled by Artificial intelligence (AI) has become an important field within the digitalisation of the economy. AI-driven robots and machines are forecasted to grow dramatically in the next years. AI-enabled RPA replaces the work a human would normally do by mimicking interactions with applications and provides direct access to systems using APIs. RPA has superior advantages versus human execution:24x7 execution, eternal lifetime and scalability. Process automatization is per se not a brand-new technology, however due to notable progress in AI, which RPAleverages, it has become an own solution category. RPA enables algorithmic rules without being biased. \n \nEthical considerations intend to make AI-driven RPA more human and introduce morality into the machine learning. The Uber-Waymo trial made transparent how much AI development is influenced by human irrationality and irrational exuberances. It reveals a culture of agile software development, which prioritize releasing the latest software over testing and verification, and one that encourages shortcuts and irrationality. This also give proof that applying AI cannot ensure that irrational exuberances disappear. The reason for this irrational exuberance may have its roots in the exponential growth in computing and storage \n \ntechnologies predicted by Gordon Moore five decades ago. This paper develops a concept how irrational exuberances with the business case of RPA can be prevented from happening. One general approach for solutioning of the issue is to increase transparency. The paper recommends applying technology to make data more accessible and more readable on the application of artificial intelligence. With the aim of application of \u201ctransparency technology XBRL (eXtensible Business Reporting Language)\u201d is incorporated. XBRL is part of the choice architecture on regulation by governments (Sunstein, 2013). XBRL is connected to a taxonomy. The paper develops a taxonomy for RPA to make application of artificial intelligence more transparent to the public and incorporates ethical considerations. As a business case the strongly growing RPA industry is selected. The paper focus on the way to enhance AI that aligns with human values. How can incentive be provided that AI systems themselves do not become potential objects of moral concern. The main outcome of the paper is that AI-enabled RPA reveal moral concerns however transparency technologies at the same time also offer way to mitigate such risks.",
    "doi": "10.2139/SSRN.3834361",
    "url": "https://www.semanticscholar.org/paper/d52ede1dd9c2f5d9dee8f6fae4203304b18bbdc8",
    "pdf_url": "",
    "venue": "",
    "citation_count": 13,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140663"
  },
  {
    "source": "semantic_scholar",
    "source_id": "91b99d1651b776cab4e16f54f7fbffc117ae82f7",
    "title": "Artificial intelligence-based clinical decision support for liver transplant evaluation and considerations about fairness: A qualitative study",
    "authors": [
      "Alexandra T. Strauss",
      "Carolyn N. Sidoti",
      "Hannah C. Sung",
      "Vedant Jain",
      "Harold Lehmann",
      "Tanjala S. Purnell",
      "John W. Jackson",
      "Daniel Malinsky",
      "James P. Hamilton",
      "J. Garonzik\u2010Wang",
      "Stephen H Gray",
      "M. Levan",
      "J. Hinson",
      "Ayse P. Gurses",
      "A. Gurakar",
      "D. Segev",
      "Scott Levin"
    ],
    "year": 2023,
    "abstract": "Background: The use of large-scale data and artificial intelligence (AI) to support complex transplantation decisions is in its infancy. Transplant candidate decision-making, which relies heavily on subjective assessment (ie, high variability), provides a ripe opportunity for AI-based clinical decision support (CDS). However, AI-CDS for transplant applications must consider important concerns regarding fairness (ie, health equity). The objective of this study was to use human-centered design methods to elicit providers\u2019 perceptions of AI-CDS for liver transplant listing decisions. Methods: In this multicenter qualitative study conducted from December 2020 to July 2021, we performed semistructured interviews with 53 multidisciplinary liver transplant providers from 2 transplant centers. We used inductive coding and constant comparison analysis of interview data. Results: Analysis yielded 6 themes important for the design of fair AI-CDS for liver transplant listing decisions: (1) transparency in the creators behind the AI-CDS and their motivations; (2) understanding how the AI-CDS uses data to support recommendations (ie, interpretability); (3) acknowledgment that AI-CDS could mitigate emotions and biases; (4) AI-CDS as a member of the transplant team, not a replacement; (5) identifying patient resource needs; and (6) including the patient\u2019s role in the AI-CDS. Conclusions: Overall, providers interviewed were cautiously optimistic about the potential for AI-CDS to improve clinical and equitable outcomes for patients. These findings can guide multidisciplinary developers in the design and implementation of AI-CDS that deliberately considers health equity.",
    "doi": "10.1097/HC9.0000000000000239",
    "url": "https://www.semanticscholar.org/paper/91b99d1651b776cab4e16f54f7fbffc117ae82f7",
    "pdf_url": "https://doi.org/10.1097/hc9.0000000000000239",
    "venue": "Hepatology Communications",
    "citation_count": 12,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140665"
  },
  {
    "source": "semantic_scholar",
    "source_id": "ee1141959004443596ceec788ce87dda23049b87",
    "title": "Human Services Organizations and the Responsible Integration of AI: Considering Ethics and Contextualizing Risk(s)",
    "authors": [
      "Brian E. Perron",
      "Lauri Goldkind",
      "Zia Qi",
      "Bryan Victor"
    ],
    "year": 2025,
    "abstract": "Abstract This paper examines the responsible integration of artificial intelligence (AI) in human services organizations (HSOs), proposing a nuanced framework for evaluating AI applications across multiple dimensions of risk. The authors argue that ethical concerns about AI deployment\u2014including professional judgment displacement, environmental impact, model bias, and data laborer exploitation\u2014vary significantly based on implementation context and specific use cases. They challenge the binary view of AI adoption, demonstrating how different applications present varying levels of risk that can often be effectively managed through careful implementation strategies. The paper highlights promising solutions, such as local large language models, that can facilitate responsible AI integration while addressing common ethical concerns. The authors propose a dimensional risk assessment approach that considers factors like data sensitivity, professional oversight requirements, and potential impact on client wellbeing. They conclude by outlining a path forward that emphasizes empirical evaluation, starting with lower-risk applications and building evidence-based understanding through careful experimentation. This approach enables organizations to maintain high ethical standards while thoughtfully exploring how AI might enhance their capacity to serve clients and communities effectively.",
    "doi": "10.1080/15228835.2025.2457045",
    "url": "https://www.semanticscholar.org/paper/ee1141959004443596ceec788ce87dda23049b87",
    "pdf_url": "",
    "venue": "Journal of technology in human services",
    "citation_count": 6,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140666"
  },
  {
    "source": "semantic_scholar",
    "source_id": "54db901155a8d8f16cf271d08b5bcdd31301203e",
    "title": "The Application of Artificial Intelligence in Health Care Resource Allocation Before and During the COVID-19 Pandemic: Scoping Review",
    "authors": [
      "Hao Wu",
      "Xiao-Lin Lu",
      "H. Wang"
    ],
    "year": 2023,
    "abstract": "\n \n Imbalanced health care resource distribution has been central to unequal health outcomes and political tension around the world. Artificial intelligence (AI) has emerged as a promising tool for facilitating resource distribution, especially during emergencies. However, no comprehensive review exists on the use and ethics of AI in health care resource distribution.\n \n \n \n This study aims to conduct a scoping review of the application of AI in health care resource distribution, and explore the ethical and political issues in such situations.\n \n \n \n A scoping review was conducted following the PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses extension for Scoping Reviews). A comprehensive search of relevant literature was conducted in MEDLINE (Ovid), PubMed, Web of Science, and Embase from inception to February 2022. The review included qualitative and quantitative studies investigating the application of AI in health care resource allocation.\n \n \n \n The review involved 22 articles, including 9 on model development and 13 on theoretical discussions, qualitative studies, or review studies. Of the 9 on model development and validation, 5 were conducted in emerging economies, 3 in developed countries, and 1 in a global context. In terms of content, 4 focused on resource distribution at the health system level and 5 focused on resource allocation at the hospital level. Of the 13 qualitative studies, 8 were discussions on the COVID-19 pandemic and the rest were on hospital resources, outbreaks, screening, human resources, and digitalization.\n \n \n \n This scoping review synthesized evidence on AI in health resource distribution, focusing on the COVID-19 pandemic. The results suggest that the application of AI has the potential to improve efficacy in resource distribution, especially during emergencies. Efficient data sharing and collecting structures are needed to make reliable and evidence-based decisions. Health inequality, distributive justice, and transparency must be considered when deploying AI models in real-world situations.\n",
    "doi": "10.2196/38397",
    "url": "https://www.semanticscholar.org/paper/54db901155a8d8f16cf271d08b5bcdd31301203e",
    "pdf_url": "https://ai.jmir.org/2023/1/e38397/PDF",
    "venue": "JMIR AI",
    "citation_count": 24,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140668"
  },
  {
    "source": "semantic_scholar",
    "source_id": "3da2d02a6178f3f0343089a9c4f57eb0f2d23433",
    "title": "Edge-Cloud Collaboration Enabled Video Service Enhancement: A Hybrid Human-Artificial Intelligence Scheme",
    "authors": [
      "D. Wu",
      "Ruili Bao",
      "Zhidu Li",
      "Honggang Wang",
      "Hong Zhang",
      "Ruyan Wang"
    ],
    "year": 2021,
    "abstract": "In this paper, a video service enhancement strategy is investigated under an edge-cloud collaboration framework, where video caching and delivery decisions are made at the cloud and edge respectively. We aim to guarantee the user fairness in terms of video coding rate under statistical delay constraint and edge caching capacity constraint. A hybrid human-artificial intelligence approach is developed to improve the user hit rate for video caching. Specifically, individual user interest is first characterized by merging factorization machine (FM) model and multi-layer perceptron (MLP) model, where both low-order and high-order features can be well learned simultaneously. Thereafter, a social aware similarity model is constructed to transfer individual user interest to group interest, based on which, videos can be selected to cache at the network edge. Furthermore, a dual bisection exploration scheme is proposed to optimize wireless resource allocation and video coding rate. The effectiveness of the proposed video caching and delivery scheme is finally validated by extensive experiments with a real-world dataset.",
    "doi": "10.1109/TMM.2021.3066050",
    "url": "https://www.semanticscholar.org/paper/3da2d02a6178f3f0343089a9c4f57eb0f2d23433",
    "pdf_url": "https://arxiv.org/pdf/2103.12516",
    "venue": "IEEE transactions on multimedia",
    "citation_count": 58,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140669"
  },
  {
    "source": "semantic_scholar",
    "source_id": "97b446e2ec3b402ea104421dab5eb4b99a21e42a",
    "title": "Understanding artificial intelligence ethics and safety",
    "authors": [
      "David Leslie"
    ],
    "year": 2019,
    "abstract": "A remarkable time of human promise has been ushered in by the convergence of the ever-expanding availability of big data, the soaring speed and stretch of cloud computing platforms, and the advancement of increasingly sophisticated machine learning algorithms. Innovations in AI are already leaving a mark on government by improving the provision of essential social goods and services from healthcare, education, and transportation to food supply, energy, and environmental management. These bounties are likely just the start. The prospect that progress in AI will help government to confront some of its most urgent challenges is exciting, but legitimate worries abound. As with any new and rapidly evolving technology, a steep learning curve means that mistakes and miscalculations will be made and that both unanticipated and harmful impacts will occur. \nThis guide, written for department and delivery leads in the UK public sector and adopted by the British Government in its publication, 'Using AI in the Public Sector,' identifies the potential harms caused by AI systems and proposes concrete, operationalisable measures to counteract them. It stresses that public sector organisations can anticipate and prevent these potential harms by stewarding a culture of responsible innovation and by putting in place governance processes that support the design and implementation of ethical, fair, and safe AI systems. It also highlights the need for algorithmically supported outcomes to be interpretable by their users and made understandable to decision subjects in clear, non-technical, and accessible ways. Finally, it builds out a vision of human-centred and context-sensitive implementation that gives a central role to communication, evidence-based reasoning, situational awareness, and moral justifiability.",
    "doi": "10.5281/zenodo.3240529",
    "url": "https://www.semanticscholar.org/paper/97b446e2ec3b402ea104421dab5eb4b99a21e42a",
    "pdf_url": "https://digital.library.unt.edu/ark:/67531/metadc2289556/m2/1/high_res_d/attachment_6.pdf",
    "venue": "Social Science Research Network",
    "citation_count": 444,
    "fields_of_study": [
      "Computer Science",
      "Mathematics"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140671"
  },
  {
    "source": "semantic_scholar",
    "source_id": "f0fbd6f92d182581ff435858155c24bf2f55157c",
    "title": "Ethical Considerations Emerge from Artificial Intelligence (AI) in Biotechnology",
    "authors": [
      "Mahintaj Dara",
      "Negar Azarpira"
    ],
    "year": 2025,
    "abstract": "The integration of Artificial intelligence (AI) in biotechnology presents significant ethical challenges that must be addressed to ensure responsible innovations. Key concerns include data privacy and security, as AI systems often handle sensitive genetic and health information, necessitating robust regulations to protect individuals\u2019 rights and maintain public trust. Algorithmic bias poses another critical issue; AI can reflect existing biases in training data, leading to inequitable healthcare outcomes. Transparency in AI decision-making is essential, as \u201cblack box\u201d models hinder trust, especially in drug discovery and genetics. Ethical implications of genetic manipulation require careful scrutiny to define the limits of human intervention. Additionally, societal impacts must be considered to ensure equitable distribution of AI benefits, preventing the exacerbation of disparities. Engaging diverse stakeholders, including ethicists and policymakers, is vital in aligning these technologies with societal values. Ultimately, prioritizing ethics will allow us to harness AI and biotechnology\u2019s potential while safeguarding human rights and promoting equity.",
    "doi": "10.18502/ajmb.v17i1.17680",
    "url": "https://www.semanticscholar.org/paper/f0fbd6f92d182581ff435858155c24bf2f55157c",
    "pdf_url": "",
    "venue": "Avicenna journal of medical biotechnology",
    "citation_count": 11,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140673"
  },
  {
    "source": "semantic_scholar",
    "source_id": "1c04cce4ee5fafc8f0bedbf520fdee279bf83539",
    "title": "Human-Centered Artificial Intelligence: Designing for User Empowerment and Ethical Considerations",
    "authors": [
      "Usman Ahmad Usmani",
      "Ari Happonen",
      "J. Watada"
    ],
    "year": 2023,
    "abstract": "Human-Centered Artificial Intelligence (AI) focuses on AI systems prioritizing user empowerment and ethical considerations. We explore the importance of usercentric design principles and ethical guidelines in creating AI technologies that enhance user experiences and align with human values. It emphasizes user empowerment through personalized experiences and explainable AI, fostering trust and user agency. Ethical considerations, including fairness, transparency, accountability, and privacy protection, are addressed to ensure AI systems respect human rights and avoid biases. Effective human AI collaboration is emphasized, promoting shared decision-making and user control. By involving interdisciplinary collaboration, this research contributes to advancing human-centered AI, providing practical recommendations for designing AI systems that enhance user experiences, promote user empowerment, and adhere to ethical standards. It emphasizes the harmonious coexistence between humans and AI, enhancing well-being and autonomy and creating a future where AI technologies benefit humanity. Overall, this research highlights the significance of human-centered AI in creating a positive impact. By centering on users' needs and values, AI systems can be designed to empower individuals and enhance their experiences. Ethical considerations are crucial to ensure fairness and transparency. With effective collaboration between humans and AI, we can harness the potential of AI to create a future that aligns with human aspirations and promotes societal well-being.",
    "doi": "10.1109/HORA58378.2023.10156761",
    "url": "https://www.semanticscholar.org/paper/1c04cce4ee5fafc8f0bedbf520fdee279bf83539",
    "pdf_url": "",
    "venue": "2023 5th International Congress on Human-Computer Interaction, Optimization and Robotic Applications (HORA)",
    "citation_count": 36,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140674"
  },
  {
    "source": "semantic_scholar",
    "source_id": "80c5d486c73bc43fcbbfcfbbb1971c1a72a8f27b",
    "title": "Artificial Intelligence in Human Resources Management: Challenges and a Path Forward",
    "authors": [
      "Prasanna Tambe",
      "P. Cappelli",
      "V. Yakubovich"
    ],
    "year": 2019,
    "abstract": "There is a substantial gap between the promise and reality of artificial intelligence in human resource (HR) management. This article identifies four challenges in using data science techniques for HR tasks: complexity of HR phenomena, constraints imposed by small data sets, accountability questions associated with fairness and other ethical and legal constraints, and possible adverse employee reactions to management decisions via data-based algorithms. It then proposes practical responses to these challenges based on three overlapping principles\u2014causal reasoning, randomization and experiments, and employee contribution\u2014that would be both economically efficient and socially appropriate for using data science in the management of employees.",
    "doi": "10.1177/0008125619867910",
    "url": "https://www.semanticscholar.org/paper/80c5d486c73bc43fcbbfcfbbb1971c1a72a8f27b",
    "pdf_url": "",
    "venue": "California Management Review",
    "citation_count": 954,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140675"
  },
  {
    "source": "semantic_scholar",
    "source_id": "7b4b93a933e33266c1f344c54da661c3e588699e",
    "title": "Ethical and legal considerations influencing human involvement in the implementation of artificial intelligence in a clinical pathway: A multi-stakeholder perspective",
    "authors": [
      "Elizabeth Redrup Hill",
      "C. Mitchell",
      "T. Brigden",
      "Alison Hall"
    ],
    "year": 2023,
    "abstract": "Introduction Ethical and legal factors will have an important bearing on when and whether automation is appropriate in healthcare. There is a developing literature on the ethics of artificial intelligence (AI) in health, including specific legal or regulatory questions such as whether there is a right to an explanation of AI decision-making. However, there has been limited consideration of the specific ethical and legal factors that influence when, and in what form, human involvement may be required in the implementation of AI in a clinical pathway, and the views of the wide range of stakeholders involved. To address this question, we chose the exemplar of the pathway for the early detection of Barrett's Oesophagus (BE) and oesophageal adenocarcinoma, where Gehrung and colleagues have developed a \u201csemi-automated\u201d, deep-learning system to analyse samples from the CytospongeTM TFF3 test (a minimally invasive alternative to endoscopy), where AI promises to mitigate increasing demands for pathologists' time and input. Methods We gathered a multidisciplinary group of stakeholders, including developers, patients, healthcare professionals and regulators, to obtain their perspectives on the ethical and legal issues that may arise using this exemplar. Results The findings are grouped under six general themes: risk and potential harms; impacts on human experts; equity and bias; transparency and oversight; patient information and choice; accountability, moral responsibility and liability for error. Within these themes, a range of subtle and context-specific elements emerged, highlighting the importance of pre-implementation, interdisciplinary discussions and appreciation of pathway specific considerations. Discussion To evaluate these findings, we draw on the well-established principles of biomedical ethics identified by Beauchamp and Childress as a lens through which to view these results and their implications for personalised medicine. Our findings are not only relevant to this context but have implications for AI in digital pathology and healthcare more broadly.",
    "doi": "10.3389/fdgth.2023.1139210",
    "url": "https://www.semanticscholar.org/paper/7b4b93a933e33266c1f344c54da661c3e588699e",
    "pdf_url": "https://www.frontiersin.org/articles/10.3389/fdgth.2023.1139210/pdf",
    "venue": "Frontiers in Digital Health",
    "citation_count": 31,
    "fields_of_study": [
      "Computer Science",
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140677"
  },
  {
    "source": "semantic_scholar",
    "source_id": "06b5090c00326183f7b3fe6e891586449e14650e",
    "title": "Ethics of artificial intelligence and robotics",
    "authors": [
      "V. C. M\u00fcller"
    ],
    "year": 2020,
    "abstract": null,
    "doi": null,
    "url": "https://www.semanticscholar.org/paper/06b5090c00326183f7b3fe6e891586449e14650e",
    "pdf_url": "",
    "venue": "",
    "citation_count": 305,
    "fields_of_study": [
      "Sociology"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140679"
  },
  {
    "source": "semantic_scholar",
    "source_id": "42eae4671b13b346b115705bc844afaede91cd39",
    "title": "Explainable Artificial Intelligence for Energy-Efficient Radio Resource Management",
    "authors": [
      "Alexandru-Daniel Marcu",
      "S. K. G. Peesapati",
      "Jessica Moysen Cortes",
      "Sahar Imtiaz",
      "James Gross"
    ],
    "year": 2023,
    "abstract": "As wireless systems evolve, the problems of radio resource management (RRM) become harder to solve. Once the additional constraint of energy-efficient utilization of resources is factored in, these problems become even more challenging. Thus, experts started developing solutions based on complex artificial intelligence (AI) models that, unfortunately, suffer from a performance-explainability trade-off. In this work, we propose an explainable AI (XAI) methodology for addressing this tradeoff. Our methodology can be used to generate feature importance explanations of AI models through three XAI methods: (i) Kernel SHapley Additive exPlanations (SHAP), (ii) Counterfactual Explanations for Robustness, Transparency, Interpretability, and Fairness of Artificial Intelligence models (CERTIFAI), and (iii) Anchors. For Anchors, we formulate a new feature importance score based on the feature\u2019s presence within the rules built by the method. We then use the generated explanations to improve the understanding of the model and reduce its complexity through a feature selection process. By applying our methodology to a reinforcement learning (RL) agent designed for energy-efficient RRM, we were able to reduce its complexity by approximately 27%\u221262% according to various metrics, without losing performance. Additionally, we show the possibility to replace the AI-based inference process with an Anchors-based inference process with similar performance and higher interpretability for humans.",
    "doi": "10.1109/WCNC55385.2023.10119130",
    "url": "https://www.semanticscholar.org/paper/42eae4671b13b346b115705bc844afaede91cd39",
    "pdf_url": "",
    "venue": "IEEE Wireless Communications and Networking Conference",
    "citation_count": 12,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140680"
  },
  {
    "source": "semantic_scholar",
    "source_id": "ef1c416afe87edcb49901bd3329cc00ccd921653",
    "title": "Bias Mitigation in Primary Health Care Artificial Intelligence Models: Scoping Review",
    "authors": [
      "M. Sasseville",
      "Steven Ouellet",
      "Caroline Rh\u00e9aume",
      "Malek Sahlia",
      "V. Couture",
      "P. Despr\u00e9s",
      "Jean-S\u00e9bastien Paquette",
      "David Darmon",
      "Fr\u00e9d\u00e9ric Berg\u00e9ron",
      "Marie-Pierre Gagnon"
    ],
    "year": 2024,
    "abstract": "Background Artificial intelligence (AI) predictive models in primary health care have the potential to enhance population health by rapidly and accurately identifying individuals who should receive care and health services. However, these models also carry the risk of perpetuating or amplifying existing biases toward diverse groups. We identified a gap in the current understanding of strategies used to assess and mitigate bias in primary health care algorithms related to individuals\u2019 personal or protected attributes. Objective This study aimed to describe the attempts, strategies, and methods used to mitigate bias in AI models within primary health care, to identify the diverse groups or protected attributes considered, and to evaluate the results of these approaches on both bias reduction and AI model performance. Methods We conducted a scoping review following Joanna Briggs Institute (JBI) guidelines, searching Medline (Ovid), CINAHL (EBSCO), PsycINFO (Ovid), and Web of Science databases for studies published between January 1, 2017, and November 15, 2022. Pairs of reviewers independently screened titles and abstracts, applied selection criteria, and performed full-text screening. Discrepancies regarding study inclusion were resolved by consensus. Following reporting standards for AI in health care, we extracted data on study objectives, model features, targeted diverse groups, mitigation strategies used, and results. Using the mixed methods appraisal tool, we appraised the quality of the studies. Results After removing 585 duplicates, we screened 1018 titles and abstracts. From the remaining 189 full-text articles, we included 17 studies. The most frequently investigated protected attributes were race (or ethnicity), examined in 12 of the 17 studies, and sex (often identified as gender), typically classified as \u201cmale versus female\u201d in 10 of the studies. We categorized bias mitigation approaches into four clusters: (1) modifying existing AI models or datasets, (2) sourcing data from electronic health records, (3) developing tools with a \u201chuman-in-the-loop\u201d approach, and (4) identifying ethical principles for informed decision-making. Algorithmic preprocessing methods, such as relabeling and reweighing data, along with natural language processing techniques that extract data from unstructured notes, showed the greatest potential for bias mitigation. Other methods aimed at enhancing model fairness included group recalibration and the application of the equalized odds metric. However, these approaches sometimes exacerbated prediction errors across groups or led to overall model miscalibrations. Conclusions The results suggest that biases toward diverse groups are more easily mitigated when data are open-sourced, multiple stakeholders are engaged, and during the algorithm\u2019s preprocessing stage. Further empirical studies that include a broader range of groups, such as Indigenous peoples in Canada, are needed to validate and expand upon these findings. Trial Registration OSF Registry osf.io/9ngz5/; https://osf.io/9ngz5/ International Registered Report Identifier (IRRID) RR2-10.2196/46684",
    "doi": "10.2196/60269",
    "url": "https://www.semanticscholar.org/paper/ef1c416afe87edcb49901bd3329cc00ccd921653",
    "pdf_url": "https://doi.org/10.2196/60269",
    "venue": "Journal of Medical Internet Research",
    "citation_count": 13,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140682"
  },
  {
    "source": "semantic_scholar",
    "source_id": "196674fbcc0e15b98adaaeef6cf0c11f86acd22d",
    "title": "On the Ethics and Practicalities of Artificial Intelligence, Risk Assessment, and Race",
    "authors": [
      "Neil R. Hogan",
      "Ethan Q Davidge",
      "Gabriela Cor\u0103bian"
    ],
    "year": 2021,
    "abstract": null,
    "doi": "10.29158/JAAPL.200116-20",
    "url": "https://www.semanticscholar.org/paper/196674fbcc0e15b98adaaeef6cf0c11f86acd22d",
    "pdf_url": "",
    "venue": "The journal of the American Academy of Psychiatry and the Law",
    "citation_count": 22,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140684"
  },
  {
    "source": "semantic_scholar",
    "source_id": "dd4ccd8a36fbf7fc2ee18c05570ea715ded7be35",
    "title": "The Impact of Artificial Intelligence on Human Resources Management Strategy: Opportunities for the Humanisation and Risks",
    "authors": [
      "V. Konovalova",
      "E. Mitrofanova",
      "A. Mitrofanova",
      "R. Gevorgyan"
    ],
    "year": 2022,
    "abstract": "The article discusses the growing role of artificial intelligence in human resources management strategy. The results of research and practical experience confirm the possibility of using artificial intelligence to humanise human resource management (reducing bias in the selection of personnel, mastering employees\u2019 experience, personalising training, analysing the emotional state of employees, and managing their wellbeing) are generalised. Highlighted are the risks of dehumanisation of personnel management when introducing artificial intelligence, which can be caused by both new threats and the strengthening of existing problems in this area.",
    "doi": "10.24234/wisdom.v2i1.763",
    "url": "https://www.semanticscholar.org/paper/dd4ccd8a36fbf7fc2ee18c05570ea715ded7be35",
    "pdf_url": "https://cyberleninka.ru/article/n/the-impact-of-artificial-intelligence-on-human-resources-management-strategy-opportunities-for-the-humanisation-and-risks/pdf",
    "venue": "wisdom",
    "citation_count": 8,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140685"
  },
  {
    "source": "semantic_scholar",
    "source_id": "9e31d55037675a43abc65f05ada20ce5cb1a2730",
    "title": "AI in human resources: efficiency, ethics, and emerging challenges",
    "authors": [
      "Soumi Majumder",
      "Syedahmed Salman",
      "Nilanjan Dey"
    ],
    "year": 2025,
    "abstract": null,
    "doi": "10.1007/s43681-025-00862-x",
    "url": "https://www.semanticscholar.org/paper/9e31d55037675a43abc65f05ada20ce5cb1a2730",
    "pdf_url": "",
    "venue": "AI and Ethics",
    "citation_count": 0,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140686"
  },
  {
    "source": "semantic_scholar",
    "source_id": "a09ec60dee41fabe75f63d19f85c6f3048dddcf3",
    "title": "Harnessing the power of artificial intelligence for disease-surveillance purposes",
    "authors": [
      "Barbara Tornimbene",
      "Zoila Beatriz Leiva Rioja",
      "J. Brownstein",
      "Adam Dunn",
      "Sylvain Faye",
      "Jude Kong",
      "Nada Malou",
      "Clara Nordon",
      "Benjamin Rader",
      "Oliver Morgan"
    ],
    "year": 2025,
    "abstract": "The COVID-19 pandemic accelerated the development of AI-driven tools to improve public health surveillance and outbreak management. While AI programs have shown promise in disease surveillance, they also present issues such as data privacy, prejudice, and human-AI interactions. This sixth session of the of the WHO Pandemic and Epidemic Intelligence Innovation Forum examines the use of Artificial Intelligence (AI) in public health by collecting the experience of key global health organizations, such the Boston Children's Hospital, the Global South AI for Pandemic & Epidemic Preparedness & Response (AI4PEP) network, Medicines Sans Fronti\u00e8res (MSF), and the University of Sydney. AI's utility in clinical care, particularly in diagnostics, medication discovery, and data processing, has resulted in improvements that may also benefit public health surveillance. However, the use of AI in global health necessitates careful consideration of ethical issues, particularly those involving data use and algorithmic bias. As AI advances, particularly with large language models, public health officials must develop governance frameworks that stress openness, accountability, and fairness. These systems should address worldwide differences in data access and ensure that AI technologies are tailored to specific local needs. Ultimately, AI's ability to improve healthcare efficiency and equity is dependent on multidisciplinary collaboration, community involvement, and inclusive AI designs in ensuring equitable healthcare outcomes to fit the unique demands of global communities.",
    "doi": "10.1186/s12919-025-00320-w",
    "url": "https://www.semanticscholar.org/paper/a09ec60dee41fabe75f63d19f85c6f3048dddcf3",
    "pdf_url": "",
    "venue": "BMC Proceedings",
    "citation_count": 8,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140688"
  },
  {
    "source": "semantic_scholar",
    "source_id": "d5da13a175fb91730e7cc23c508f4b9888ad66b8",
    "title": "The Ethical Role of Generative Artificial Intelligence in Modern HR Decision-Making: A Systematic Literature Review",
    "authors": [
      "S. Porkodi",
      "Teresita Luzon Cedro"
    ],
    "year": 2025,
    "abstract": "The rapid development of generative artificial intelligence (AI) has led to the recognition of tools like ChatGPT and its potential to transform human resource (HR) management processes, particularly in decision-making. This review study aims to assess the effectiveness and benefits of ChatGPT in enhancing HR functions, particularly decision-making, and to identify any challenges and ethical considerations involved. Additionally, the study seeks to establish a hybrid framework that combines AI-driven decision-making with human oversight. A systematic literature review was conducted using PRISMA guidelines, selecting 50 articles from Scopus and Google Scholar databases. The literature review includes a synthesis analysis to assess publication trends and a keyword analysis to identify key themes such as ChatGPT\u2019s impact on decision-making in HR management. The study reveals that ChatGPT can streamline HR processes, improve communication, and support personalized learning and decision-making, eventually contributing to enhanced performance and engagement. However, the technology requires human input for moral judgment and empathy, presenting challenges like resistance to adoption, algorithmic bias, and data privacy concerns. This study uniquely contributes to the literature by providing a systematic analysis of ChatGPT\u2019s role in HR decision-making and proposing a hybrid framework that addresses AI\u2019s limitations through ethical guidelines and human oversight. The findings emphasize the need for empirical research in larger, diverse settings and future enhancements to ChatGPT\u2019s contextual understanding of HR.",
    "doi": "10.24018/ejbmr.2025.10.1.2535",
    "url": "https://www.semanticscholar.org/paper/d5da13a175fb91730e7cc23c508f4b9888ad66b8",
    "pdf_url": "https://doi.org/10.24018/ejbmr.2025.10.1.2535",
    "venue": "European Journal of Business and Management Research",
    "citation_count": 6,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140690"
  },
  {
    "source": "semantic_scholar",
    "source_id": "3f92b660f3991a4e510398f5736a8d9f0f85aaba",
    "title": "The Ethical Concerns of Artificial Intelligence in Urban Planning",
    "authors": [
      "Thomas W. Sanchez",
      "M. Brenman",
      "Xinyue Ye"
    ],
    "year": 2024,
    "abstract": "Abstract Problem, research strategy, and findings The integration of a artificial intelligence (AI) into urban planning presents potential ethical challenges, including concerns about bias, transparency, accountability, privacy, and misinformation. As planners rely more on AI for decision making, the potential for these systems to perpetuate biases, obscure decision-making processes, and infringe on privacy becomes more pronounced, potentially undermining public trust and excluding marginalized communities. We reviewed existing literature on AI ethics in urban planning, examining biases, transparency, accountability, and privacy issues. Our methodology synthesized findings from various studies, reports, and theoretical frameworks to highlight ethical concerns in AI-driven urban planning. Recommendations for ethical AI implementation emphasize transparency, inclusive data sets, public engagement, and robust ethical guidelines. Our research identified critical ethical concerns in AI-driven urban planning. Bias in AI systems can lead to unequal outcomes, disproportionately affecting marginalized communities. Transparency issues arise from the black box nature of AI, complicating understanding and trust in AI-driven decisions. Privacy concerns are heightened due to extensive data collection and potential misuse, raising the risk of surveillance and data breaches. Limitations include the availability of specific literature focused on AI ethics for urban planning and the evolving nature of AI technologies, suggesting a need for ongoing research and adaptive strategies. Human oversight and continuous monitoring are essential to ensure ethical practices, with an emphasis on community engagement and public education to foster trust and inclusivity. Takeaway for practice Urban planners should adopt a proactive approach to mitigate ethical risks associated with AI. Ensuring transparency, involving diverse community groups, and maintaining robust data privacy measures are crucial. Prioritizing public engagement and education will help to demystify AI technologies and build public trust. Addressing these ethical concerns allows planners to leverage AI\u2019s potential while safeguarding equity, privacy, and accountability in urban development.",
    "doi": "10.1080/01944363.2024.2355305",
    "url": "https://www.semanticscholar.org/paper/3f92b660f3991a4e510398f5736a8d9f0f85aaba",
    "pdf_url": "https://www.tandfonline.com/doi/pdf/10.1080/01944363.2024.2355305?needAccess=true",
    "venue": "Journal of the American Planning Association",
    "citation_count": 63,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140691"
  },
  {
    "source": "semantic_scholar",
    "source_id": "b30d9e5b507316dee7da81ee4371638034afa936",
    "title": "Designing human resource management systems in the age of AI",
    "authors": [
      "Patrick Nicolas Tinguely",
      "Junghyun Lee",
      "Vivianna Fang He"
    ],
    "year": 2023,
    "abstract": "The increasing adoption of artificial intelligence (AI) is reshaping the practices of human resource management (HRM). We propose a typology of HR\u2013AI collaboration systems across the dimensions of task characteristics (routine vs. non-routine; low vs. high cognitive complexity) and social acceptability of such systems among organizational members. We discuss how organizations should design HR\u2013AI collaboration systems in light of issues of AI explainability, high stakes contexts, and threat to employees\u2019 professional identities. We point out important design considerations that may affect employees' perceptions of organizational fairness and emphasize HR professionals' role in the design process. We conclude by discussing how our Point of View article contributes to literatures on organization design and human\u2013AI collaboration and suggesting potential avenues for future research.",
    "doi": "10.1007/s41469-023-00153-x",
    "url": "https://www.semanticscholar.org/paper/b30d9e5b507316dee7da81ee4371638034afa936",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s41469-023-00153-x.pdf",
    "venue": "Journal of Organization Design",
    "citation_count": 17,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140693"
  },
  {
    "source": "semantic_scholar",
    "source_id": "f539bf3856bbc547210baaed874ed6f3b5c66b76",
    "title": "Bias in Artificial Intelligence Systems",
    "authors": [
      "Rafa\u0142 Rejmaniak"
    ],
    "year": 2021,
    "abstract": "Abstract Artificial intelligence systems are currently deployed in many areas of human activity. Such systems are increasingly assigned tasks that involve taking decisions about people or predicting future behaviours. These decisions are commonly regarded as fairer and more objective than those taken by humans, as AI systems are thought to be resistant to such influences as emotions or subjective beliefs. In reality, using such a system does not guarantee either objectivity or fairness. This article describes the phenomenon of bias in AI systems and the role of humans in creating it. The analysis shows that AI systems, even if operating correctly from a technical standpoint, are not guaranteed to take decisions that are more objective than those of a human, but those systems can still be used to reduce social inequalities.",
    "doi": "10.15290/bsp.2021.26.03.02",
    "url": "https://www.semanticscholar.org/paper/f539bf3856bbc547210baaed874ed6f3b5c66b76",
    "pdf_url": "https://doi.org/10.15290/bsp.2021.26.03.02",
    "venue": "Bia\u0142ostockie Studia Prawnicze",
    "citation_count": 11,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140694"
  },
  {
    "source": "semantic_scholar",
    "source_id": "72b39cf03173e4ced50e54873dac32258bbbfe16",
    "title": "Trustworthy AI and Corporate Governance: The EU\u2019s Ethics Guidelines for Trustworthy Artificial Intelligence from a Company Law Perspective",
    "authors": [
      "Eleanore Hickman",
      "M. Petrin"
    ],
    "year": 2020,
    "abstract": "AI will change many aspects of the world we live in, including the way corporations are governed. Many efficiencies and improvements are likely, but there are also potential dangers, including the threat of harmful impacts on third parties, discriminatory practices, data and privacy breaches, fraudulent practices and even \u2018rogue AI\u2019. To address these dangers, the EU published \u2018The Expert Group\u2019s Policy and Investment Recommendations for Trustworthy AI\u2019 (the Guidelines). The Guidelines produce seven principles from its four foundational pillars of respect for human autonomy, prevention of harm, fairness, and explicability. If implemented by business, the impact on corporate governance will be substantial. Fundamental questions at the intersection of ethics and law are considered, but because the Guidelines only address the former without (much) reference to the latter, their practical application is challenging for business. Further, while they promote many positive corporate governance principles\u2014including a stakeholder-oriented (\u2018human-centric\u2019) corporate purpose and diversity, non-discrimination, and fairness\u2014it is clear that their general nature leaves many questions and concerns unanswered. In this paper we examine the potential significance and impact of the Guidelines on selected corporate law and governance issues. We conclude that more specificity is needed in relation to how the principles therein will harmonise with company law rules and governance principles. However, despite their imperfections, until harder legislative instruments emerge, the Guidelines provide a useful starting point for directing businesses towards establishing trustworthy AI.",
    "doi": "10.1007/s40804-021-00224-0",
    "url": "https://www.semanticscholar.org/paper/72b39cf03173e4ced50e54873dac32258bbbfe16",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s40804-021-00224-0.pdf",
    "venue": "European Business Organization Law Review",
    "citation_count": 75,
    "fields_of_study": [
      "Business"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140695"
  },
  {
    "source": "semantic_scholar",
    "source_id": "d687f8d336387d67e5b990f8c5cc53288683011c",
    "title": "Artificial Intelligence in African Higher Education: Uses, Misuses, and Ethical Dilemmas",
    "authors": [
      "Ayenew Guadu",
      "Dawit Dibekulu",
      "A. Menberu"
    ],
    "year": 2025,
    "abstract": "Globally, Artificial Intelligence (AI) is changing higher education, and African institutions are becoming more and more involved in this digital revolution. AI applications such as predictive analytics, automated grading, and intelligent tutoring systems offer promising opportunities to enhance research, teaching, learning, and administration\u2014particularly in settings with limited resources. However, the incorporation of AI into African higher education also raises significant socio-technical and ethical issues. Academic dishonesty, algorithmic bias, data privacy, and unequal access to digital infrastructure are some of the issues that risk exacerbating existing educational inequalities. Furthermore, concerns regarding digital sovereignty, fairness, and cultural relevance are raised by the dependence on AI tools created in the Global North. This article highlights the dual potential for both empowerment and marginalization as it critically analyzes the advantages and hazards of implementing AI in African higher institutions. It calls for a responsible, inclusive, and culturally grounded approach to AI in African higher education through a contextual and ethical lens, using concepts like digital justice, the ethics of technology, and decolonial theory.",
    "doi": "10.54364/aaiml.2025.53234",
    "url": "https://www.semanticscholar.org/paper/d687f8d336387d67e5b990f8c5cc53288683011c",
    "pdf_url": "",
    "venue": "Advances in Artificial Intelligence and Machine Learning",
    "citation_count": 1,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140697"
  },
  {
    "source": "semantic_scholar",
    "source_id": "28ec0afa570fdcce7ce18f751bead511d4fc4b13",
    "title": "Balancing the scale: navigating ethical and practical challenges of artificial intelligence (AI) integration in legal practices",
    "authors": [
      "Ammar Zafar"
    ],
    "year": 2024,
    "abstract": "The paper explores the integration of artificial intelligence in legal practice, discussing the ethical and practical issues that arise and how it affects customary legal procedures. It emphasises the shift from labour-intensive legal practice to technology-enhanced methods, with a focus on artificial intelligence's potential to improve access to legal services and streamline legal procedures. This discussion importantly highlights the ethical challenges introduced by the integration of Artificial Intelligence, with a specific focus on issues of bias and transparency. These ethical concerns become particularly paramount in the context of sensitive legal areas, including but not limited to, child custody disputes, criminal justice, and divorce settlements. It underscores the critical need for maintaining ethical vigilance, advocating for developing and implementing AI systems characterised by a profound commitment to ethical integrity. This approach is vital to guarantee fairness and uphold transparency across all judicial proceedings. The study advocates for a \"human in the loop\" strategy that combines human knowledge and AI techniques to mitigate biases and guarantee individualised legal results to ensure AI functions as a complement rather than a replacement, the paper concludes by emphasising the necessity of preserving the human element in legal practices.",
    "doi": "10.1007/s44163-024-00121-8",
    "url": "https://www.semanticscholar.org/paper/28ec0afa570fdcce7ce18f751bead511d4fc4b13",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s44163-024-00121-8.pdf",
    "venue": "Discover Artificial Intelligence",
    "citation_count": 42,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140698"
  },
  {
    "source": "semantic_scholar",
    "source_id": "656fd9a402830709b9ff8f8b9fdb5738bd48f4fc",
    "title": "ICIS 2019 SIGHCI Workshop Panel Report: Human\u2013 Computer Interaction Challenges and Opportunities for Fair, Trustworthy and Ethical Artificial Intelligence",
    "authors": [],
    "year": 2020,
    "abstract": "Artificial Intelligence (AI) is rapidly changing every aspect of our society\u2014including amplifying our biases. Fairness, trust and ethics are at the core of many of the issues underlying the implications of AI. Despite this, research on AI with relation to fairness, trust and ethics in the information systems (IS) field is still scarce. This panel brought together academia, business and government perspectives to discuss the challenges and identify potential solutions to address such challenges. This panel report presents eight themes based around the discussion of two questions: (1) What are the biggest challenges to designing, implementing and deploying fair, ethical and trustworthy AI?; and (2) What are the biggest challenges to policy and governance for fair, ethical and trustworthy AI? The eight themes are: (1) identifying AI biases; (2) drawing attention to AI biases; (3) addressing AI biases; (4) designing transparent and explainable AI; (5) AI fairness, trust, ethics: old wine in a new bottle?; (6) AI accountability; (7) AI laws, policies, regulations and standards; and (8) frameworks for fair, ethical and trustworthy AI. Based on the results of the panel discussion, we present research questions for each theme to guide future research in the area of human\u2013computer interaction.",
    "doi": "10.17705/1thci.00130",
    "url": "https://www.semanticscholar.org/paper/656fd9a402830709b9ff8f8b9fdb5738bd48f4fc",
    "pdf_url": "https://aisel.aisnet.org/cgi/viewcontent.cgi?article=1135&context=thci",
    "venue": "",
    "citation_count": 26,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140700"
  },
  {
    "source": "semantic_scholar",
    "source_id": "f4c0210e76e30d1727246c0af5ef3cd5c5d21585",
    "title": "Automating intellectual freedom: Artificial intelligence, bias, and the information landscape",
    "authors": [
      "Catherine Smith"
    ],
    "year": 2021,
    "abstract": "Anxieties over automation and personal freedom are challenging libraries\u2019 role as havens of intellectual freedom. The introduction of artificial intelligence into the resource description process creates an opportunity to reshape the digital information landscape\u2014and loss of trust by library users. Resource description necessarily manipulates a library\u2019s presentation of information, which influences the ways users perceive and interact with that information. Human catalogers inevitably introduce personal and cultural biases into their work, but artificial intelligence may perpetrate biases on a previously unseen scale. The automation of this process may be perceived as a greater threat than the manipulation produced by human operators. Librarians must understand the risks of artificial intelligence and consider what oversight and countermeasures are necessary to mitigate the harm to libraries and their users before ceding resource description to artificial intelligence in place of the \u201cprofessional considerations\u201d the IFLA Statement on Libraries and Intellectual Freedom calls for in providing access to library materials.",
    "doi": "10.1177/03400352211057145",
    "url": "https://www.semanticscholar.org/paper/f4c0210e76e30d1727246c0af5ef3cd5c5d21585",
    "pdf_url": "",
    "venue": "IFLA Journal",
    "citation_count": 13,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140701"
  },
  {
    "source": "semantic_scholar",
    "source_id": "da01fc413908d3c271622033b45c4eae0f315d3b",
    "title": "Leveraging data analytics in human resource management",
    "authors": [
      "Sai Nethra Betgeri",
      "Naga Parameshwari Chekuri"
    ],
    "year": 2025,
    "abstract": "Human Resource Management (HRM) has transitioned from traditional, intuition-driven practices to a data-driven domain, enabling organizations to leverage advanced analytics for improved workforce management. Integrating data analytics in HR functions such as recruitment, employee engagement, retention, and performance management has proven transformative, providing actionable insights to optimize operations and align HR strategies with organizational objectives. This paper examines the practical applications of HR analytics, emphasizing the role of predictive models, artificial intelligence (AI), and machine learning (ML) in forecasting trends, identifying risks, and enhancing decision-making processes. Key findings highlight how predictive analytics improves hiring efficiency by reducing time-to-hire and enhancing candidate quality, while retention analytics mitigates turnover by identifying at-risk employees and enabling timely interventions. Performance analytics further supports identifying skill gaps and optimizing training programs, driving overall organizational productivity. This paper also explores critical challenges, including data privacy concerns, algorithmic biases, and the need to upskill HR professionals to embrace analytics tools effectively. The results underscore the growing importance of HR analytics as a strategic enabler in shaping workforce management's future while emphasizing ethical considerations and the need for robust data governance frameworks. This study offers practical insights and recommendations for organizations seeking to harness the full potential of HR analytics.",
    "doi": "10.30574/ijsra.2025.15.1.1009",
    "url": "https://www.semanticscholar.org/paper/da01fc413908d3c271622033b45c4eae0f315d3b",
    "pdf_url": "",
    "venue": "International Journal of Science and Research Archive",
    "citation_count": 3,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140703"
  },
  {
    "source": "semantic_scholar",
    "source_id": "f3137d1562fdd9160b98815264ea6fbd409e8c26",
    "title": "Assessing Explainable in Artificial Intelligence: A TOPSIS Approach to Decision-Making",
    "authors": [],
    "year": 2025,
    "abstract": "Explainable in Artificial Intelligence (AI) is the ability to comprehend and explain how AI models generate judgments or predictions. The complexity of AI systems, especially machine learning models, is increasing. understanding their reasoning process becomes crucial for ensuring trust, fairness, and accountability. Explainable AI (XAI) helps demystify the \"black box\" character of sophisticated models, Deep neural networks, for example, which allows users to to grasp how inputs are transformed into outputs. In many AI system judgments can have a big impact on industries including healthcare, banking, and law making transparency a necessity. Explainable also aids in identifying and mitigating biases, improving model performance, and complying with regulatory requirements. As AI technologies evolve, there is an increasing emphasis on balancing model accuracy with interpretability, making some AI systems remain ethical, transparent, and in line with human values. In artificial intelligence (AI) research, Explainable is essential for fostering confidence, guaranteeing responsibility, and enhancing The openness of artificial intelligence systems. As Artificial intelligence models, especially intricate ones like deep learning, become more widely adopted, understanding their Processes for making decisions are crucial for validating their outcomes. The goal of explainable AI (XAI) research is to create models interpretable so that users can comprehend the decision-making process. This is particularly crucial in high-stakes industries like healthcare, banking, and law, where poor or prejudiced choices can have serious repercussions. Explainable also supports regulatory compliance, model improvement, and ethical AI deployment. An approach to decision-making known as TOPSIS (Technique for Order of Preference by Similarity to Ideal Answer) evaluates how far an alternative is from the worst-case situation and how close it is to the ideal solution. The worst-case solution shows the lowest values, while the ideal solution shows the best values given the desired criteria. Each alternative is given a similarity score by TOPSIS, which ranks them according to how near the ideal answer they are. This method is frequently used to enhance decision-making in a variety of domains, including business, engineering, environmental research, and healthcare. Alternative: LIME (Local Interpretable Model), SHAP (Shapley Additive Explanations), Deep LIFT (Deep Learning Important Features), Anchor Explanations, ICE (Individual Conditional Expectation), Counterfactual Explanations, Rule-based Explanation Systems, Saliency Maps (for CNNs), Integrated Gradients, XAI for Healthcare. Evaluation preference: Interpretability, Accuracy of Explanations, User Trust, Computational Complexity, Scalability, Flexibility. The results indicate that XAI for Healthcare ranks highest, while Saliency Maps (for CNNs) holds the lowest rank.",
    "doi": "10.46632/jdaai/2/3/14",
    "url": "https://www.semanticscholar.org/paper/f3137d1562fdd9160b98815264ea6fbd409e8c26",
    "pdf_url": "",
    "venue": "REST Journal on Data Analytics and Artificial Intelligence",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140704"
  },
  {
    "source": "semantic_scholar",
    "source_id": "ed8af3e125a4108ca2acc8d60323fa8ec2b83cfc",
    "title": "Balancing bytes and biases: A case study of AI adoption in academic human resource management",
    "authors": [
      "Rusnandari Retno Cahyani",
      "Anniez Rachmawati Musslifah"
    ],
    "year": 2025,
    "abstract": "The integration of Artificial Intelligence (AI) is rapidly transforming Human Resource Management (HRM), yet its adoption within the unique context of higher education institutions remains underexplored, particularly in developing nations. This study addresses this gap by investigating the application and implications of AI in core HRM functions, specifically recruitment, performance evaluation, and workforce planning, at a public university in Indonesia. Adopting an exploratory qualitative case study methodology, this study sourced data from twelve purposively selected stakeholders, including HR managers, academic leaders, and IT personnel, through semi-structured interviews, document analysis, and non-participant observation. The collected data were systematically analyzed using thematic analysis, revealing a dual impact of AI adoption. While AI integration significantly enhances operational efficiency by automating recruitment screening and supporting data-driven workforce planning, it also introduces critical challenges, including the risk of algorithmic bias, a lack of transparency, and the potential erosion of human judgment in culturally sensitive evaluations. The study concludes that successful AI implementation in academic HRM is contingent upon institutional readiness, a supportive organizational culture, and a robust technological infrastructure. By applying the Technology-Organization-Environment (TOE), Technology Acceptance Model (TAM), and Diffusion of Innovation (DoI) frameworks, this research contributes a nuanced understanding of the factors shaping AI adoption in higher education, underscoring the necessity of a balanced approach that leverages AI's benefits while preserving essential human oversight in university administration.",
    "doi": "10.22515/jemin.v5i2.11679",
    "url": "https://www.semanticscholar.org/paper/ed8af3e125a4108ca2acc8d60323fa8ec2b83cfc",
    "pdf_url": "",
    "venue": "Journal of Educational Management and Instruction (JEMIN)",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140705"
  },
  {
    "source": "semantic_scholar",
    "source_id": "0c6a7b5263ff43a8a9fb3c567e589ef544941af1",
    "title": "AI-Powered Human Resource Management for Enhancing Employee Recruitment Efficiency and Talent Retention in Organizations",
    "authors": [
      "Kajal Chheda",
      "Urvashi Thakur",
      "R. J",
      "Ganesh Prasad Das",
      "Mukesh Kumar Parashar",
      "Krishna Reddy"
    ],
    "year": 2025,
    "abstract": "Artificial Intelligence (AI)-powered Human Resource Management (HRM) systems address inefficiencies in recruitment and employee retention. Traditional methods are slow, biased, and reactive. Integrating AI enables predictive insights, automated screening, and employee satisfaction monitoring, transforming HR practices into data-driven, strategic decision-making processes. This research aims to evaluate the impact of AI on improving recruitment efficiency and talent retention. It investigates whether AI-based tools significantly reduce hiring time, enhance job candidate fit, and predict attrition risk. Data was sourced from 1,000 anonymzed employee records, including 400 resumes, 280 satisfaction responses, and 320 attrition cases across the IT and finance sectors. Collected over a three-year period, the dataset supports recruitment analysis and employee retention prediction using AI-based models. Five variables were analyzed: recruitment time (RT), candidate-job match score (CJMS), employee satisfaction score (ESS), retention rate (RR), and AI-predicted attrition risk (APAR). These variables represent both continuous and ordinal data types, suitable for independent sample t-tests and regression analysis in SPSS 25. SPSS analysis showed significant reductions in recruitment time (p < 0.01) and improvements in job match scores. Among independent sample t-test results, the highest t-value was observed for CJMS (t = 22.15, p < 0.001). Spearman\u2019s correlation indicated a strong positive link between satisfaction and retention. Regression analysis confirmed high predictive accuracy of AI-based attrition risk models. In regression findings, APAR had the highest R\u00b2 value (R\u00b2 = 0.42, p < 0.001). AI-powered HR systems significantly enhance recruitment efficiency and retention strategies. Statistical evidence confirms the effectiveness of AI in predicting attrition and improving candidate-job alignment, enabling organizations to make proactive, data-informed HR decisions and foster a more stable workforce.",
    "doi": "10.62486/agma2025165",
    "url": "https://www.semanticscholar.org/paper/0c6a7b5263ff43a8a9fb3c567e589ef544941af1",
    "pdf_url": "",
    "venue": "Management",
    "citation_count": 2,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140707"
  },
  {
    "source": "semantic_scholar",
    "source_id": "964c6946a053836d55b0fd0e398e57d405fd7f3d",
    "title": "Optimizing Workforce Efficiency in the United States (U.S.) Federal Sector: The Role of Predictive Analytics and AI in Human Resource (HR) Decision-Making",
    "authors": [
      "Kemisola Kasali"
    ],
    "year": 2025,
    "abstract": "The U.S. federal government is undergoing a critical workforce transformation, driven by initiatives under the Department of Government Efficiency (DOGE) to optimize resource allocation and reduce bureaucratic redundancies. This shift poses significant challenges in maintaining service quality amid workforce reductions but offers opportunities to enhance operational effectiveness and public service delivery through technological innovation. Predictive analytics and artificial intelligence (AI) offer strategic, data-driven solutions to enhance human resource (HR) decision-making that enables federal agencies to proactively forecast attrition, enhance workforce planning, and improve operational efficiency. This article examines the integration of AI in federal HR operations, assesses its potential to streamline hiring, retention, and performance management. By evaluating current policy frameworks and presenting innovative AI-driven workforce strategies, this article contributes to the advancement of government modernization. The recommendations provide concrete steps for implementing AI governance frameworks, establishing public-private partnerships, and developing inclusive workforce analytics systems to ensure AI adoption enhances rather than disrupts public service delivery. This article also proposed the introduction of novel approaches to AI integration in federal HR which includes a hybrid human-AI decision support system and an innovative cross-agency AI knowledge sharing platform. In addition, this paper addresses critical challenges that include data privacy concerns, algorithmic bias risks, and the ethical implications of AI-driven decision-making in the federal workforce context that provides a balanced perspective on both opportunities and limitations of these technologies.",
    "doi": "10.51244/ijrsi.2025.12030082",
    "url": "https://www.semanticscholar.org/paper/964c6946a053836d55b0fd0e398e57d405fd7f3d",
    "pdf_url": "",
    "venue": "International journal of research and scientific innovation",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140708"
  },
  {
    "source": "semantic_scholar",
    "source_id": "fb7ffb7e4bd8c03df8a58238ddeafa277319043a",
    "title": "The impacts of AI and automation on human resource management \u2013 systematic review",
    "authors": [
      "Fernanda Maria de Almeida Santos",
      "A. Pereira",
      "Alexandre Shanches",
      "Diogo Crespo",
      "Henriqueta Pala"
    ],
    "year": 2025,
    "abstract": "This study focuses on the growing impact of Artificial Intelligence (AI) and automation on the Human Resource Management (HRM) processes of organizations. It examines how these emerging technologies are redefining HRM practices, with a particular focus on recruitment, training and human capital management. A methodology was used that integrates a quantitative analysis, derived from data collected through a structured survey on a Likert scale, and a systematic review of the literature. This two-pronged approach allowed us to assess perceptions about the implementation of AI in HRM and to identify emerging trends and patterns in recent studies. The results show that AI and automation contribute to greater efficiency in recruitment and selection processes, promoting greater equality in the identification and progression of talent. There was also a positive impact on skills development and vocational training, underlining the importance of adaptive strategies for the continuous development of employees. We face ethical and privacy challenges regarding the use of AI in HR. It highlights the need for robust practices for the protection of employee data and the prevention of bias and discrimination in algorithms. The importance of human intervention in automated decisions is highlighted, ensuring the maintenance of fairness and ethics, as well as the need for professional requalification in the face of technological changes. The study concludes that despite the challenges, AI and automation offer unprecedented opportunities for innovation in HRM. Organizations that integrate these technologies with the human elements of work are better prepared for a dynamic and technologically advanced future.",
    "doi": "10.34117/bjdv11n2-079",
    "url": "https://www.semanticscholar.org/paper/fb7ffb7e4bd8c03df8a58238ddeafa277319043a",
    "pdf_url": "",
    "venue": "Brazilian Journal of Development",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140710"
  },
  {
    "source": "semantic_scholar",
    "source_id": "71cdc4d3ecb738dcd531019ee6f81abf36e65698",
    "title": "Multimodality of AI for Education: Toward Artificial General Intelligence",
    "authors": [
      "Gyeonggeon Lee",
      "Lehong Shi",
      "Ehsan Latif",
      "Yizhu Gao",
      "Arne Bewersdorff",
      "Matthew Nyaaba",
      "Shuchen Guo",
      "Zheng Liu",
      "Gengchen Mai",
      "Tianming Liu",
      "Xiaoming Zhai"
    ],
    "year": 2025,
    "abstract": "This article addresses the growing importance of understanding how multimodal artificial general intelligence (AGI) can be integrated into educational practices. We first reviewed the theoretical foundations of multimodality in human learning, encompassing its concept and history, dual coding theory and multimedia theory, VARK multimodality, and multimodal assessment (see Section II-A). After that, we revisited the essential components of AGI, particularly focusing on the multimodal nature of AGI that distinguished it from artificial narrow intelligence. Based on its conversational functionality, multimodal AGI is considered an educational agent already tested in various educational situations (see Section II-B). How significant text, image, audio, and video modalities are for education, the technological backgrounds of AGI for analyzing and generating them, and educational applications of artificial intelligence (AI) for each modality were thoroughly reviewed (Sections III\u2013VI). Finally, we comprehensively investigated the ethics of AGI in education, originating from the ethics of AI and specified in three strands: first, data privacy and ethical integrity, second, explainability, transparency, and fairness, and third, responsibility and decision-making. Practical implementation of ethical AGI frameworks in education was reviewed (see Section VII). This article also discusses the implications for learning theories, derived operational design principles, current research gaps, practical constraints and institutional readiness, and future directions (see Section VIII). This exploration aims to provide an advanced understanding of the intersection between AI, multimodality, and education, setting a foundation for future research and development.",
    "doi": "10.1109/TLT.2025.3574466",
    "url": "https://www.semanticscholar.org/paper/71cdc4d3ecb738dcd531019ee6f81abf36e65698",
    "pdf_url": "",
    "venue": "IEEE Transactions on Learning Technologies",
    "citation_count": 14,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140711"
  },
  {
    "source": "semantic_scholar",
    "source_id": "9083dedbf490b427da7fa5d954b7be0b7e337bb8",
    "title": "Ethical Considerations in Cloud AI: Addressing Bias and Fairness in Algorithmic Systems",
    "authors": [
      "Shreya Gupta"
    ],
    "year": 2025,
    "abstract": "Artificial intelligence systems deployed through cloud infrastructure have transformed numerous sectors while simultaneously raising critical ethical concerns regarding bias and fairness. This article examines the multifaceted nature of algorithmic bias in cloud AI systems, presenting quantitative evidence of disparities across facial recognition, hiring, lending, criminal justice, and healthcare applications. Data from commercial deployments reveals substantial demographic disparities, with error rates varying by factors of 40+ between different population groups. The societal implications manifest as economic disadvantages, restricted opportunities, and diminished public trust, particularly affecting already marginalized communities. Technical interventions demonstrate considerable promise, with resampling methods, synthetic data generation, and fairness-aware algorithms reducing bias metrics by 40-70% while largely maintaining predictive performance. However, technical solutions alone prove insufficient, necessitating comprehensive governance frameworks. Regulatory approaches, certification mechanisms, participatory design, and professional ethics significantly outperform voluntary guidelines, though implementation gaps persist across the AI ecosystem. The analysis concludes that a combination of technical debiasing and robust governance is essential, with regulatory approaches showing the most significant impact on reducing bias. Addressing bias in cloud AI represents both an ethical imperative and an economic necessity as these systems increasingly influence critical infrastructure and decision-making processes worldwide.",
    "doi": "10.48175/ijarsct-25053",
    "url": "https://www.semanticscholar.org/paper/9083dedbf490b427da7fa5d954b7be0b7e337bb8",
    "pdf_url": "",
    "venue": "International Journal of Advanced Research in Science, Communication and Technology",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140713"
  },
  {
    "source": "semantic_scholar",
    "source_id": "507bcf70a20b594f9cea790431ae65fbef479bba",
    "title": "Ethical Challenges and Bias in Real-World AI: A Fairness-Oriented Approach to Resume Screening Systems",
    "authors": [
      "Dr. S. Ponmalar",
      "T. Rohith",
      "K. N. Kumar",
      "A. K. N. Kaarthick",
      "R.Vishva Balaji"
    ],
    "year": 2025,
    "abstract": "Artificial Intelligence (AI) is rapidly integrating into decision-making across fields like finance, healthcare, and criminal justice. However, its widespread use brings ethical challenges, especially the potential for bias in AI algorithms. This paper examines these ethical concerns, emphasizing three main types of bias: data bias, algorithmic bias, and interaction biasThrough real-world case studies, including biased facial recognition systems, hiring algorithms, and criminal justice AI tools, this paper highlights the far-reaching societal impact of these biases. These case studies demonstrate how bias in AI systems can result in unequal access to resources, unjust treatment in legal systems, and perpetuation of stereotypes in employment practices. This paper highlights the pressing need for robust strategies to address the ethical risks associated with AI. It delves into established frameworks such as Ethically Aligned AI, the EU Guidelines on Trustworthy AI, and the Toronto Declaration, offering essential principles for creating AI systems that prioritize fairness, transparency, and accountability. By evaluating current applications across different industries, this paper proposes actionable solutions to reduce bias in AI systems and also a sample model has been developed to represent how the system has to be under ethics and including enhancing data diversity and implementing robust governance mechanisms to ensure ethical oversight in resume screening processThis research seeks to advance the conversation on ethical AI by emphasizing fairness, equity, and the social good, ensuring that AI technologies are developed to benefit all communities equally.",
    "doi": "10.1109/ICAISS61471.2025.11042179",
    "url": "https://www.semanticscholar.org/paper/507bcf70a20b594f9cea790431ae65fbef479bba",
    "pdf_url": "",
    "venue": "2025 Third International Conference on Augmented Intelligence and Sustainable Systems (ICAISS)",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140714"
  },
  {
    "source": "semantic_scholar",
    "source_id": "98b2d76be7886f34f40fc2af0a4e806f5d159e6b",
    "title": "AI Gender Bias, Disparities, and Fairness: Does Training Data Matter?",
    "authors": [
      "Ehsan Latif",
      "Xiaoming Zhai",
      "Lei Liu"
    ],
    "year": 2023,
    "abstract": "This study delves into the pervasive issue of gender issues in artificial intelligence (AI), specifically within automatic scoring systems for student-written responses. The primary objective is to investigate the presence of gender biases, disparities, and fairness in generally targeted training samples with mixed-gender datasets in AI scoring outcomes. Utilizing a fine-tuned version of BERT and GPT-3.5, this research analyzes more than 1000 human-graded student responses from male and female participants across six assessment items. The study employs three distinct techniques for bias analysis: Scoring accuracy difference to evaluate bias, mean score gaps by gender (MSG) to evaluate disparity, and Equalized Odds (EO) to evaluate fairness. The results indicate that scoring accuracy for mixed-trained models shows an insignificant difference from either male- or female-trained models, suggesting no significant scoring bias. Consistently with both BERT and GPT-3.5, we found that mixed-trained models generated fewer MSG and non-disparate predictions compared to humans. In contrast, compared to humans, gender-specifically trained models yielded larger MSG, indicating that unbalanced training data may create algorithmic models to enlarge gender disparities. The EO analysis suggests that mixed-trained models generated more fairness outcomes compared with gender-specifically trained models. Collectively, the findings suggest that gender-unbalanced data do not necessarily generate scoring bias but can enlarge gender disparities and reduce scoring fairness.",
    "doi": "10.48550/arXiv.2312.10833",
    "url": "https://www.semanticscholar.org/paper/98b2d76be7886f34f40fc2af0a4e806f5d159e6b",
    "pdf_url": "",
    "venue": "arXiv.org",
    "citation_count": 17,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140716"
  },
  {
    "source": "semantic_scholar",
    "source_id": "b06fa39d0d9dbf57f9053f4f737a61774774b1a1",
    "title": "Ethical principles for artificial intelligence in education: a meta-review approach",
    "authors": [
      "Mihiri Wickramasinghe",
      "Lasith Gunawardena",
      "Amitha Padukkage"
    ],
    "year": 2025,
    "abstract": null,
    "doi": "10.1007/s43681-025-00878-3",
    "url": "https://www.semanticscholar.org/paper/b06fa39d0d9dbf57f9053f4f737a61774774b1a1",
    "pdf_url": "",
    "venue": "AI and Ethics",
    "citation_count": 0,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140717"
  },
  {
    "source": "semantic_scholar",
    "source_id": "45fbc2288f19559aaffaa663db09dcb01c841975",
    "title": "Transformasi Artificial Intelligence dalam Akuntansi Keuangan: Inovasi dalam Pengambilan Keputusan atau Memunculkan Tantangan Baru?",
    "authors": [
      "Esa Cahyani Nazari",
      "M. Mukhtaruddin"
    ],
    "year": 2025,
    "abstract": "Artificial Intelligence (AI) is increasingly used in financial accounting to improve decision-making effectiveness. This research analyzes the role of AI in supporting data-driven decision making and identifies challenges in its implementation. Using a qualitative approach with the Systematic Literature Review (SLR) method, this study reviewed 41 relevant articles from national and international journals. The results showed that 28 studies supported the effectiveness of AI in improving financial decision-making by automating transaction recording, enabling algorithm-based predictive analysis, and detecting financial anomalies. AI enables companies to respond faster to market changes, increase transparency of financial reports, and reduce human errors in accounting processes.However, 13 studies highlighted challenges such as technological complexity, limited transparency in decision-making, algorithmic bias, and organizational readiness. In addition, evolving regulations are an obstacle to ensuring optimal use of AI while minimizing ethical and legal risks. The success of AI in financial decision-making depends on infrastructure readiness, regulatory support, and human resource competencies. Without a well-planned strategy, AI may pose new challenges that hinder its effectiveness. Therefore, this study provides insights into the optimal AI implementation strategy to ensure that this technology improves the accuracy and transparency of decision making while maintaining financial accounting accountability.",
    "doi": "10.58192/ebismen.v4i1.3158",
    "url": "https://www.semanticscholar.org/paper/45fbc2288f19559aaffaa663db09dcb01c841975",
    "pdf_url": "",
    "venue": "Jurnal ekonomi, bisnis dan manajemen",
    "citation_count": 3,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140719"
  },
  {
    "source": "semantic_scholar",
    "source_id": "46cf57f8e463606fd48bf418e3c901accccbf20c",
    "title": "Responsible artificial intelligence (AI) in healthcare: a paradigm shift in leadership and strategic management",
    "authors": [
      "Amlan Haque"
    ],
    "year": 2025,
    "abstract": "Purpose This paper aims to explore the paradigm shift in leadership and strategic management driven by the integration of responsible artificial intelligence (AI) in healthcare. It explores the evolving role of leadership in adapting to AI technologies while ensuring ethical governance, transparency and accountability in healthcare decision-making. Design/methodology/approach This study conducts a comprehensive review of current literature, case studies and industry reports to evaluate the implications of responsible AI adoption in healthcare leadership. It focuses on key areas such as AI-driven decision-making, resource optimisation, crisis management and patient care, while also addressing challenges in integrating AI technologies effectively. Findings The integration of AI in healthcare is transforming leadership from traditional, experience-based decision-making to data-driven, AI-enhanced strategies. Responsible leadership emphasises addressing ethical concerns such as bias, transparency and accountability. AI technologies improve resource allocation, crisis management and patient care, but challenges such as workforce resistance and the need for upskilling healthcare professionals remain. Practical implications Healthcare leaders must adopt a responsible leadership framework that balances AI\u2019s potential with ethical and human-centred care principles. Recommendations include developing AI literacy programmes for healthcare professionals, ensuring inclusivity in AI algorithms and establishing governance policies that promote transparency and accountability in AI applications. Originality/value This paper provides a critical, forward-looking perspective on how responsible AI can drive a paradigm shift in healthcare leadership. It offers novel insights into the integration of AI within healthcare organisations, emphasising the need for leadership that prioritises ethical AI usage and promotes patient well-being in a rapidly evolving digital landscape.",
    "doi": "10.1108/LHS-01-2025-0018",
    "url": "https://www.semanticscholar.org/paper/46cf57f8e463606fd48bf418e3c901accccbf20c",
    "pdf_url": "",
    "venue": "Leadership in Health Services",
    "citation_count": 2,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140720"
  },
  {
    "source": "semantic_scholar",
    "source_id": "099d060bce611b5b7b432dbb4f533efa67ac179e",
    "title": "AI-Driven HR: Revolutionizing Human Resource Management",
    "authors": [
      "A. Meher",
      "Deepti Mishra",
      "Tania Mishra",
      "Abhaya Kumar Sahoo"
    ],
    "year": 2025,
    "abstract": "In today\u2019s rapidly evolving technology environment, the integration of artificial intelligence (AI) into various industries has become a significant driver of innovation. In the context of human resources, artificial intelligence is defined as a wide variety of software algorithms that enable a computer to perform human resource management activities that would normally require human cognition and intervention. This includes data-driven decision making, behavioral analysis, trend prediction and much more. One area that is experiencing a profound impact from AI is human resources management (HRM). By incorporating an AI system into the HR department, the company\u2019s employees will gain increased productivity and experience. AI can assist HR departments in every phase of their professional work, from timely candidate selection to performance evaluation. Integrating artificial intelligence into human resource management can then help a business achieve overall efficiency and gain an edge over its competitors. By leveraging AI technologies, organizations can improve employee\u2019s performance, their productivity, and decision-making processes. AI will eventually have a noticeable and longlasting effect on HR. Since technology is always evolving, AI framework must be adaptable enough to update itself and make adjustments as needed. We can use AI to take away most of the monotonous employee\u2019s tasks, analyze vast amounts of data to make tangible decisions, and create a holistic impact on the organization and its people. According to 76% of HR directors, companies would fall behind in organizational performance if they do not integrate and apply AI technologies like generative AI within the next 12 to 24 months. To effectively decide whether to use new AI solutions for HR, CHROs must evaluate technological trends in an organized manner.HR workers may now employ machine learning and algorithms to expedite work processes, lessen biases, and enhance analysis and decision-making thanks to advancements in AI technology, which has completely changed the HR department. Still, some companies are delaying the use of AI for additional use cases due to existing limits and threats.. Artificial intelligence needs proper data storage and maintenance to function effectively. It collects and analyzes all the necessary data and enables the HR department to make data-based decisions. HR manager can make data-driven decisions that are sustainable and impactful. We\u2019ll discuss in this article and explore the role of AI in HR practices and its implications for the future of work.",
    "doi": "10.1109/AESPC67542.2025.11326711",
    "url": "https://www.semanticscholar.org/paper/099d060bce611b5b7b432dbb4f533efa67ac179e",
    "pdf_url": "",
    "venue": "2025 5th IEEE International Conference on Applied Electromagnetics, Signal Processing, & Communication (AESPC)",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140721"
  },
  {
    "source": "semantic_scholar",
    "source_id": "79e1a2270e3b3ff8cf51fb739fad4046a4f99afc",
    "title": "AI-Driven Transformation of Human Resource Management: From Performance Evaluation to Fair Recruitment through Image Processing",
    "authors": [
      "Kartikay Sharma",
      "Aman Sharma",
      "Tanu Sharma"
    ],
    "year": 2025,
    "abstract": "This paper explore the significance of Artificial Intelligence (AI) in Human Resource Management (HRM), discussing its applications, advantages, challenges, and ethical considerations.This study examines the national (India: Digital Personal Information Protection (DPDP) Act, 2023; NITI Aayog AI policy) and international (European Union\u2019s General Data Protection Regulation, GDPR) legal frameworks, which focus on data protection, transparency, and human interventions. This paper provides a important case study on the application of image processing and machine vision in HR recruitment at NovaHire Solutions, demonstrating and how AI-driven visual analytics can enhance justice, diversity, and the collaboration between human and artificial intelligence in decision-making together. The findings disclose the importance of oversight, impairment assessments, and training programs in ensuring the responsible and effective utilisation of AI for management of personnel..",
    "doi": "10.1109/ICIIP68302.2025.11346292",
    "url": "https://www.semanticscholar.org/paper/79e1a2270e3b3ff8cf51fb739fad4046a4f99afc",
    "pdf_url": "",
    "venue": "International Conference on Intelligent Information Processing",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140723"
  },
  {
    "source": "semantic_scholar",
    "source_id": "eba7cee9e4871e26fa41e1c47c972c1c00c38c8a",
    "title": "The Ethics of AI in Pricing: Fairness, Transparency, and Accountability",
    "authors": [
      "Divya Chaudhary"
    ],
    "year": 2025,
    "abstract": "The integration of artificial intelligence into pricing mechanisms represents a fundamental transformation in commercial practices, introducing unprecedented ethical complexities that challenge traditional notions of market fairness and consumer protection. AI-driven pricing systems leverage sophisticated machine learning algorithms to process vast datasets encompassing consumer behavior, market dynamics, and competitive intelligence, enabling real-time price adjustments that promise enhanced revenue optimization and personalized customer experiences. However, these technological capabilities simultaneously introduce a novel analytical framework for evaluating systematic discrimination, transparency deficits, and accountability gaps in AI pricing that extend far beyond individual transactions to encompass broader societal questions about economic justice and market power distribution. The pursuit of fairness in algorithmic pricing confronts multifaceted challenges stemming from embedded historical biases in training data, conflicting fairness metrics, and geographic discrimination patterns that can exacerbate existing inequalities. Transparency challenges emerge from the black box nature of complex neural networks and unprecedented information asymmetries between businesses and consumers, while responsibility attribution becomes problematic across multi-layered development teams and fragmented regulatory frameworks. The societal implications encompass consumer welfare impacts, market concentration risks, and the potential for algorithmic coordination that may undermine competitive market dynamics, necessitating comprehensive approaches to balance technological innovation with ethical considerations and consumer protection principles.",
    "doi": "10.22399/ijcesen.3949",
    "url": "https://www.semanticscholar.org/paper/eba7cee9e4871e26fa41e1c47c972c1c00c38c8a",
    "pdf_url": "",
    "venue": "International Journal of Computational and Experimental Science and Engineering",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140724"
  },
  {
    "source": "semantic_scholar",
    "source_id": "e65e36729355900b270f8ce497f1a2d6ca89a01b",
    "title": "Artificial Intelligence in Newsrooms: Ethical Challenges Facing Journalists",
    "authors": [
      "O. Al-Zoubi",
      "Normahfuzah Ahmad",
      "Norsiah Abdul Hamid"
    ],
    "year": 2024,
    "abstract": "Artificial intelligence has started to expand in journalism, especially in advanced news organisations. It is evident that journalists are beginning to realise the importance of AI and that it will be a partner to human journalists in their work inside newsrooms. Despite the numerous benefits that AI contributes to journalism, several challenges hinder the expansion and spread of its adoption among journalists. The ethical challenges of AI systems have become a concern among journalists. Therefore, this research is guided by the relationship between technological development and media ethics as the philosophical study of morality, specifically the Social Responsibility Theory. This study adopts a qualitative approach to explore the ethical challenges of AI faced by journalists. In-depth interviews were conducted with 14 journalists working in the newsroom of a government-affiliated channel, Al Mamlaka TV in Jordan. Data obtained from interviews conducted were analysed thematically. The results concluded that the main ethical challenges faced by journalists in the newsroom in adopting AI are data bias; privacy violations; and the absence of legislation and international regulations regarding the use of AI in journalism. The study concludes that journalists at Al Mamlaka TV adhere to the basics of Social Responsibility Theory through their critical adoption of AI in the newsroom.",
    "doi": "10.11114/smc.v12i1.6587",
    "url": "https://www.semanticscholar.org/paper/e65e36729355900b270f8ce497f1a2d6ca89a01b",
    "pdf_url": "https://redfame.com/journal/index.php/smc/article/download/6587/6440",
    "venue": "Studies in Media and Communication",
    "citation_count": 37,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140726"
  },
  {
    "source": "semantic_scholar",
    "source_id": "fd529d00882e1a6ba6f7ba92a6198860c8af0356",
    "title": "Artificial intelligence and the role of ethics",
    "authors": [
      "R. A. Quinn"
    ],
    "year": 2021,
    "abstract": "An ethical approach to AI does not function as bicycle brake on an intercontinental airplane. Ethics does not put insufficient brakes on progress. It does, however, asks how principles and values that are important for a democratic society can be translated into a digital democratic society. Beyond discussions of transparency, accountability, explainability, fairness and trustworthiness, this text focusses on two major issues: representation gaps \u2013 where minorities and a majority (women) are under- or misrepresented in data; and data silhouettes \u2013 where the body, the self and human life seems to be deciphered by data alone. Ethical reasoning thus insists that the non-quantifiable areas of human life are as important as any quantifiable aspects. An extensive quantification of the social, the political and the individual person must be continuously examined for its effects. Good regulation is not an obstacle to research and business, but that is necessary to create trust in AI systems.",
    "doi": "10.3233/SJI-210791",
    "url": "https://www.semanticscholar.org/paper/fd529d00882e1a6ba6f7ba92a6198860c8af0356",
    "pdf_url": "",
    "venue": "Statistical Journal of the IAOS",
    "citation_count": 6,
    "fields_of_study": [
      "Psychology"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140727"
  },
  {
    "source": "semantic_scholar",
    "source_id": "84b04f0ae6628766df776b804a9e81f6d73f9b2e",
    "title": "Improving Fine Arts Through Artificial Intelligence in Art Analysis, Production, and Restoration",
    "authors": [
      "Mona Ansari"
    ],
    "year": 2025,
    "abstract": "Artificial Intelligence transforms fine arts through innovations which support artistic analysis processes and artistic creation as well as restore artistic masterpieces. AI's impact on the field of fine arts focuses on three main areas including machine learning analysis for artwork understanding along with AI-generated art production as well as deep learning approaches for artwork restoration. Experimental studies analyze how AI performs regarding artwork restoration precision as well as artistic coherence maintaining and conservation speed while proving that AI improves upon traditional restoration techniques in terms of precision and scalability. The authentication of AI art creates ethics tests so do biases in databases and issues about cultural preservation. The paper presents the human-AI collaborative model which demonstrates AI functions as a creative enhancement instead of replacing artists. This study delivers a detailed view of AI's changes in artistic practices through research of present-day uses as well as hurdles and upcoming strategies. These findings enhance research about AI and human artistic collaboration by helping both technology development and ethical considerations related to artistic preservation.",
    "doi": "10.1109/ICCIAA65327.2025.11013667",
    "url": "https://www.semanticscholar.org/paper/84b04f0ae6628766df776b804a9e81f6d73f9b2e",
    "pdf_url": "",
    "venue": "2025 1st International Conference on Computational Intelligence Approaches and Applications (ICCIAA)",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140728"
  },
  {
    "source": "semantic_scholar",
    "source_id": "143051ba917aee1357ce5adc72e87568580de444",
    "title": "Guidance needed for using artificial intelligence to screen journal submissions for misconduct",
    "authors": [
      "Mohammad Hosseini",
      "David B Resnik"
    ],
    "year": 2024,
    "abstract": "Journals and publishers are increasingly using artificial intelligence (AI) to screen submissions for potential misconduct, including plagiarism and data or image manipulation. While using AI can enhance the integrity of published manuscripts, it can also increase the risk of false/unsubstantiated allegations. Ambiguities related to journals\u2019 and publishers\u2019 responsibilities concerning fairness and transparency also raise ethical concerns. In this Topic Piece, we offer the following guidance: (1) All cases of suspected misconduct identified by AI tools should be carefully reviewed by humans to verify accuracy and ensure accountability; (2) Journals/publishers that use AI tools to detect misconduct should use only well-tested and reliable tools, remain vigilant concerning forms of misconduct that cannot be detected by these tools, and stay abreast of advancements in technology; (3) Journals/publishers should inform authors about irregularities identified by AI tools and give them a chance to respond before forwarding allegations to their institutions in accordance with Committee on Publication Ethics guidelines; (4) Journals/publishers that use AI tools to detect misconduct should screen all relevant submissions and not just random/purposefully selected submissions; and (5) Journals should inform authors about their definition of misconduct, their use of AI tools to detect misconduct, and their policies and procedures for responding to suspected cases of misconduct.",
    "doi": "10.1177/17470161241254052",
    "url": "https://www.semanticscholar.org/paper/143051ba917aee1357ce5adc72e87568580de444",
    "pdf_url": "https://journals.sagepub.com/doi/pdf/10.1177/17470161241254052",
    "venue": "Research ethics",
    "citation_count": 16,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140730"
  },
  {
    "source": "semantic_scholar",
    "source_id": "f86a4e7abaa633228ec5d7914bf2e423b62f719f",
    "title": "Artificial intelligence in gynecologic and obstetric emergencies",
    "authors": [
      "H. Elbiss",
      "F. Abu-Zidan"
    ],
    "year": 2025,
    "abstract": "Artificial intelligence (AI) uses a process by which machines perform human-like functions such as automated clinical decisions. This may operate efficiently in gynecologic and obstetric emergencies. We aimed to review the role and applications of AI in gynecologic and obstetric emergencies. A literature search was carried out in November 2023 in PubMed, Cochrane Library and Google Scholar using the keywords combination of \u201cartificial intelligence, gynecology and obstetrics\u201d. Relevant articles were selected and read. Reference lists of the selected articles were also searched. The literature demonstrated the role of AI to improve healthcare in emergency settings in several aspects such as diagnostic imaging, improving predictions in emergencies, and improving planning and resource allocation for emergency services. AI works objectively, overcoming human biases in decision-making. Creating interconnected data registries for AI will likely enhance its performance. Validation research in emergency settings has shown that AI-prediction tools perform more accurately compared with the estimation of risk and outcomes by gynecologists and obstetricians in emergency situations including endometriosis and acute abdominal pain. There was acceptance of AI and its potential benefits. Ethical dilemmas of using AI include data governance, responsibility for errors, and security issues. Providing training on AI to healthcare professionals working in emergency departments is needed. Healthcare professionals should educate themselves about the anticipated role of AI in gynecologic and obstetric emergencies, its indications, limitations, and ethical considerations so that they can take steps towards its application in their future practice using defined guidelines.",
    "doi": "10.1186/s12245-025-00820-8",
    "url": "https://www.semanticscholar.org/paper/f86a4e7abaa633228ec5d7914bf2e423b62f719f",
    "pdf_url": "",
    "venue": "International Journal of Emergency Medicine",
    "citation_count": 5,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140731"
  },
  {
    "source": "semantic_scholar",
    "source_id": "6094d6efd2952030ba343e97348f7be155a4b9d1",
    "title": "Leveraging Artificial Intelligence in Breast Cancer Screening and Diagnosis",
    "authors": [
      "Abdul Haseeb Hasan",
      "Umar Abdul Rehman Khalid",
      "Muhammad Ali Abid"
    ],
    "year": 2025,
    "abstract": "Breast cancer remains the most prevalent malignancy worldwide, posing a significant public health burden due to its high incidence and mortality rates. Early detection through mammography has been instrumental in reducing breast cancer-related deaths; however, traditional screening methods are constrained by human limitations, including variability in interpretation and resource-intensive workflows. Artificial intelligence (AI) has emerged as a transformative tool in breast cancer diagnostics, leveraging machine learning (ML) and deep learning (DL) algorithms to enhance accuracy, efficiency, and accessibility. AI applications in digital mammography (DM), digital breast tomosynthesis (DBT), ultrasound, and magnetic resonance imaging (MRI) have demonstrated improved sensitivity and specificity, reducing false positives and false negatives while optimizing radiologist workload. Despite these advancements, challenges such as data accessibility, algorithm biases, regulatory constraints, and clinical integration hinder widespread AI adoption. Addressing these limitations requires standardized validation protocols, enhanced interpretability through explainable AI (XAI), and improved clinician and patient education. This editorial explores the evolving role of AI in breast cancer screening and diagnosis, emphasizing its potential to bridge healthcare disparities and improve global breast cancer outcomes.",
    "doi": "10.7759/cureus.79177",
    "url": "https://www.semanticscholar.org/paper/6094d6efd2952030ba343e97348f7be155a4b9d1",
    "pdf_url": "",
    "venue": "Cureus",
    "citation_count": 5,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140733"
  },
  {
    "source": "semantic_scholar",
    "source_id": "a19a3bb8957fd460e8f2db8ea5f120deca10b94d",
    "title": "Virtual Reality in Human Resource Management: Past, Present and Future Trends",
    "authors": [
      "Mohit Yadav",
      "Rahul Khurana",
      "N. Vihari",
      "Arun Mittal",
      "Arun Balodi",
      "A. Srivastava"
    ],
    "year": 2023,
    "abstract": "This paper presents a comprehensive bibliometric analysis of 416 research articles from 1993 to 2023, specifically focusing on applying Virtual Reality in Human Resource Management. The study delves into publishing trends, prominent journals, and noteworthy contributors, including authors, institutions, and countries. The findings offer valuable insights for researchers, aiding in selecting reputable journals for publication and highlighting key research topics and emerging subfields. Future research should explore integrating VR with emerging technologies like artificial intelligence and data analytics to develop sophisticated HR solutions while also investigating the ethical implications of VR in recruiting and employee training to ensure fairness and transparency. Additionally, exploring how VR can enhance diversity and inclusion in hiring procedures by promoting empathy and unbiased decision-making is a promising area for further study.",
    "doi": "10.1109/ICRASET59632.2023.10420290",
    "url": "https://www.semanticscholar.org/paper/a19a3bb8957fd460e8f2db8ea5f120deca10b94d",
    "pdf_url": "",
    "venue": "2023 International Conference on Recent Advances in Science and Engineering Technology (ICRASET)",
    "citation_count": 5,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:57:58.140734"
  },
  {
    "source": "semantic_scholar",
    "source_id": "aba6cada1ff16fe91a738ce7ef8025dccc933b3b",
    "title": "Artificial intelligence in vaccine research and development: an umbrella review",
    "authors": [
      "Rabie Adel El Arab",
      "May Alkhunaizi",
      "Yousef N. Alhashem",
      "Alissar Al Khatib",
      "Munirah Bubsheet",
      "Salwa Hassanein"
    ],
    "year": 2025,
    "abstract": "Background The rapid development of COVID-19 vaccines highlighted the transformative potential of artificial intelligence (AI) in modern vaccinology, accelerating timelines from years to months. Nevertheless, the specific roles and effectiveness of AI in accelerating and enhancing vaccine research, development, distribution, and acceptance remain dispersed across various reviews, underscoring the need for a unified synthesis. Methods We conducted an umbrella review to consolidate evidence on AI\u2019s contributions to vaccine discovery, optimization, clinical testing, supply-chain logistics, and public acceptance. Five databases were systematically searched up to January 2025 for systematic, scoping, narrative, and rapid reviews, as well as meta-analyses explicitly focusing on AI in vaccine contexts. Quality assessments were performed using the ROBIS and AMSTAR 2 tools to evaluate risk of bias and methodological rigor. Results Among the 27 reviews, traditional machine learning approaches\u2014random forests, support vector machines, gradient boosting, and logistic regression\u2014dominated tasks from antigen discovery and epitope prediction to supply\u2011chain optimization. Deep learning architectures, including convolutional and recurrent neural networks, generative adversarial networks, and variational autoencoders, proved instrumental in multiepitope vaccine design and adaptive clinical trial simulations. AI\u2011driven multi\u2011omic integration accelerated epitope mapping, shrinking discovery timelines by months, while predictive analytics optimized manufacturing workflows and supply\u2011chain operations (including temperature\u2011controlled, \u201ccold\u2011chain\u201d logistics). Sentiment analysis and conversational AI tools demonstrated promising capabilities for real\u2011time monitoring of public attitudes and tailored communication to address vaccine hesitancy. Nonetheless, persistent challenges emerged\u2014data heterogeneity, algorithmic bias, limited regulatory frameworks, and ethical concerns over transparency and equity. Discussion and implications These findings illustrate AI\u2019s transformative potential across the vaccine lifecycle but underscore that translating promise into practice demands five targeted action areas: robust data governance and multi\u2011omics consortia to harmonize and share high\u2011quality datasets; comprehensive regulatory and ethical frameworks featuring transparent model explainability, standardized performance metrics, and interdisciplinary ethics committees for ongoing oversight; the adoption of adaptive trial designs and manufacturing simulations that enable real\u2011time safety monitoring and in silico process modeling; AI\u2011enhanced public engagement strategies\u2014such as routinely audited chatbots, real\u2011time sentiment dashboards, and culturally tailored messaging\u2014to mitigate vaccine hesitancy; and a concerted focus on global equity and pandemic preparedness through capacity building, digital infrastructure expansion, routine bias audits, and sustained funding in low\u2011resource settings. Conclusion This umbrella review confirms AI\u2019s pivotal role in accelerating vaccine development, enhancing efficacy and safety, and bolstering public acceptance. Realizing these benefits requires not only investments in infrastructure and stakeholder engagement but also transparent model documentation, interdisciplinary ethics oversight, and routine algorithmic bias audits. Moreover, bridging the gap from in silico promise to real\u2011world impact demands large\u2011scale validation studies and methods that can accommodate heterogeneous evidence, ensuring AI\u2011driven innovations deliver equitable global health outcomes and reinforce pandemic preparedness.",
    "doi": "10.3389/fimmu.2025.1567116",
    "url": "https://www.semanticscholar.org/paper/aba6cada1ff16fe91a738ce7ef8025dccc933b3b",
    "pdf_url": "",
    "venue": "Frontiers in Immunology",
    "citation_count": 28,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140736"
  },
  {
    "source": "semantic_scholar",
    "source_id": "a5599ee4bef37d2837af78949d36fd161d642844",
    "title": "The Transformative Role of Artificial Intelligence in Plastic and Reconstructive Surgery: Challenges and Opportunities",
    "authors": [
      "M. Mansoor",
      "Andrew F. Ibrahim"
    ],
    "year": 2025,
    "abstract": "Background/Objectives: This study comprehensively examines how artificial intelligence (AI) technologies are transforming clinical practice in plastic and reconstructive surgery across the entire patient care continuum, with the specific objective of identifying evidence-based applications, implementation challenges, and emerging opportunities that will shape the future of the specialty. Methods: A comprehensive narrative review was conducted analyzing the integration of AI technologies in plastic surgery, including preoperative planning, intraoperative applications, postoperative monitoring, and quality improvement. Challenges related to implementation, ethics, and regulatory frameworks were also examined, along with emerging technological trends that will shape future practice. Results: AI applications in plastic surgery demonstrate significant potential across multiple domains. In preoperative planning, AI enhances risk assessment, outcome prediction, and surgical simulation. Intraoperatively, AI-assisted robotics enables increased precision and technical capabilities beyond human limitations, particularly in microsurgery. Postoperatively, AI improves complication detection, pain management, and outcomes assessment. Despite these benefits, implementation faces challenges including data privacy concerns, algorithmic bias, liability questions, and the need for appropriate regulatory frameworks. Future directions include multimodal AI systems, federated learning approaches, and integration with extended reality and regenerative medicine technologies. Conclusions: The integration of AI into plastic surgery represents a significant opportunity to enhance surgical precision, improve outcome prediction, and expand the boundaries of what is surgically possible. However, successful implementation requires addressing ethical considerations and maintaining the human elements of surgical care. Plastic surgeons must actively engage with AI development to ensure these technologies address genuine clinical needs while aligning with the specialty\u2019s core values of restoring form and function, alleviating suffering, and enhancing quality of life.",
    "doi": "10.3390/jcm14082698",
    "url": "https://www.semanticscholar.org/paper/a5599ee4bef37d2837af78949d36fd161d642844",
    "pdf_url": "",
    "venue": "Journal of Clinical Medicine",
    "citation_count": 17,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:57:58.140737"
  },
  {
    "source": "semantic_scholar",
    "source_id": "ac06b608b5f9d26eb37c12061bf70c91ef331a9d",
    "title": "Artificial intelligence in healthcare and medicine: clinical applications, therapeutic advances, and future perspectives",
    "authors": [
      "Yosri A. Fahim",
      "Ibrahim W. Hasani",
      "Samer Kabba",
      "Waleed Mahmoud Ragab"
    ],
    "year": 2025,
    "abstract": "Healthcare systems worldwide face growing challenges, including rising costs, workforce shortages, and disparities in access and quality, particularly in low- and middle-income countries. Artificial intelligence (AI) has emerged as a transformative tool capable of addressing these issues by enhancing diagnostics, treatment planning, patient monitoring, and healthcare efficiency. AI\u2019s role in modern medicine spans disease detection, personalized care, drug discovery, predictive analytics, telemedicine, and wearable health technologies. Leveraging machine learning and deep learning, AI can analyze complex data sets, including electronic health records, medical imaging, and genomic profiles, to identify patterns, predict disease progression, and recommend optimized treatment strategies. AI also has the potential to promote equity by enabling cost-effective, resource-efficient solutions in low-resource and remote settings, such as mobile diagnostics, wearable biosensors, and lightweight algorithms. Successful deployment requires addressing critical challenges, including data privacy, algorithmic bias, model interpretability, regulatory oversight, and maintaining human clinical oversight. Emphasizing scalable, ethical, and evidence-driven implementation, key strategies include clinician training in AI literacy, adoption of resource efficient tools, global collaboration, and robust regulatory frameworks to ensure transparency, safety, and accountability. By complementing rather than replacing healthcare professionals, AI can reduce errors, optimize resources, improve patient outcomes, and expand access to quality care. This review emphasizes the responsible integration of AI as a powerful catalyst for innovation, sustainability, and equity in healthcare delivery worldwide.",
    "doi": "10.1186/s40001-025-03196-w",
    "url": "https://www.semanticscholar.org/paper/ac06b608b5f9d26eb37c12061bf70c91ef331a9d",
    "pdf_url": "",
    "venue": "European Journal of Medical Research",
    "citation_count": 19,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424441"
  },
  {
    "source": "semantic_scholar",
    "source_id": "5938d49ce92e071dd3433e33d35daebfcacbdcd3",
    "title": "Scientific Map of Artificial Intelligence Research in Digital Business",
    "authors": [
      "Loso Judijanto",
      "Agung Zulfikri"
    ],
    "year": 2025,
    "abstract": "Th\u200cis study\u200b performs\u200b a bib\u200dl\u200biom\u2060etric\u200b an\u2060d scientometric evaluation of\u200b worldwide\u200d re\u200dsearch on Ar\u2060tificial Intelligence (AI) in Digital Business utilizing\u200c Scopus da\u200dta from 2020 to 2025. Ut\u200bili\u200czing VOSviewer\u200b and B\u200di\u2060bliometrix, we deli\u200cneate keyword co-occu\u200brrence\u200d, author c\u200dollaboration, and ins\u200dt\u2060itutional networks to disce\u200drn\u2060 prevailing c\u200blusters and\u200d emerg\u200ding fronts. Res\u200bults ind\u200dicate that digital busi\u200dness, digital t\u200dransfor\u2060mation,\u200b a\u200dnd\u2060 AI capabili\u200cties are\u200c fundamenta\u200cl the\u200dm\u200ces, whereas digital\u2060 ec\u2060o\u200bsystems, sustainability, res\u200dpons\u200ci\u200dble\u200b a\u200cnd t\u2060rustworthy inn\u200covation, and govern\u2060ance-focus\u200bed analyti\u2060cs are em\u200ce\u2060rging trends. Network analysis indica\u2060te\u200ds strong\u200c Eur\u2060opean connection\u200ds spear\u200cheaded by Geo\u200brg\u200d-\u200bAugust-Universit\u00e4t G\u00f6\u200cttingen,\u200b the Univ\u2060ersity of St\u2060. Gall\u200be\u200cn, and KU Leuven, alongside expandi\u200dng transatlantic relationsh\u200bip\u200bs and colla\u200cborative\u200b m\u2060ul\u200cti-institu\u200bti\u2060onal grou\u200cps. We t\u200dhe\u2060oretically comb\u200cine the Resource-Bas\u2060ed Vie\u200bw and\u200b Dynamic Capabilit\u200dies, pos\u2060iting that\u200d data as\u200bsets, algorithms\u200b, and human\u200d\u2013AI routines are strategi\u200bc r\u2060esources whose orc\u200bhestration f\u200cacil\u200di\u200dtates perceiving, seizin\u200cg, and reconfig\u200buring am\u200cid chaotic changes. The method\u200cological integratio\u200cn of perf\u200dor\u200bmance metrics with scientific mapping reveals\u200d the s\u200ctru\u200dcture, ma\u2060tu\u200crity\u200c, and interdisciplina\u200cry knowledge connections within fields such\u2060 as information sy\u2060ste\u200dms, management, and compute\u200dr science. The study prov\u200ci\u200ddes ma\u200bnageri\u200bal g\u200buidance for aligning\u200b technical innova\u200dtio\u200dn w\u200bith go\u2060ve\u200crnance and sustaina\u2060bili\u200dty: i\u2060nves\u200bt in inte\u2060r\u200copera\u200db\u2060le data inf\u200drastructure, imple\u200dment responsibl\u200be A\u200dI safegua\u200brd\u200ds, cultivate ambide\u2060xtrous teams\u2060, a\u200bnd assess val\u2060ue creat\u2060ion beyond prod\u2060uctivity, fo\u2060cusing on resil\u200dience and e\u200cnvironmental, social, and ethical out\u200ccomes. Po\u200bl\u200bicy implica\u2060ti\u200bons e\u2060ncom\u200cpa\u200dss inc\u200ben\u200dtives for open standards\u2060, developme\u200cnt of skills pipe\u200dline\u2060s, and f\u200bacilitatio\u200dn of c\u2060ross-bor\u2060de\u200br coll\u200daborat\u2060ion. Limitat\u200dions encompass exclu\u200dsive Scopus cover\u200dage, a predomi\u200dnance of English\u200b language, an\u200cd rapidly evolving terminolo\u200cgy; n\u200donetheless, triangulated a\u200bpp\u2060roaches reduce bias and offer a timely guide for resear\u200dche\u2060rs and decision-makers. Subs\u2060equent research should corroborate these findings using lon\u200cgitu\u2060dinal data\u2060s\u200bets.",
    "doi": "10.31004/riggs.v4i4.3255",
    "url": "https://www.semanticscholar.org/paper/5938d49ce92e071dd3433e33d35daebfcacbdcd3",
    "pdf_url": "",
    "venue": "RIGGS: Journal of Artificial Intelligence and Digital Business",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424456"
  },
  {
    "source": "semantic_scholar",
    "source_id": "f031fe645728d6fd36a9a36232cf19a846e9db73",
    "title": "Fairness, Accountability and Transparency in Artificial Intelligence: A Case Study of Logical Predictive Models",
    "authors": [
      "Kacper Sokol"
    ],
    "year": 2019,
    "abstract": "Machine learning -- the part of artificial intelligence aimed at eliciting knowledge from data and automated decision making without explicit instructions -- is making great strides, with new algorithms being invented every day. These algorithms find myriads of applications, but their ubiquity often comes at the expense of limited interpretability, hidden biases and unexpected vulnerabilities. Whenever one of these factors is a priority, the learning algorithm of choice is often a method considered to be inherently interpretable, e.g. logical models such as decision trees. In my research I challenge this assumption and highlight (quite common) cases when the assumed interpretability fails to deliver. To restore interpretability of logical machine learning models (decision trees and their ensembles in particular) I propose to explain them with class-contrastive counterfactual statements, which are a very common type of explanation in human interactions, well-grounded in social science research. To evaluate transparency of such models I collate explainability desiderata that can be used to systematically assess and compare such methods as an addition to user studies. Given contrastive explanations, I investigate their influence on the model's security, in particular gaming and stealing the model. Finally, I evaluate model fairness, where I am interested in choosing the most fair model among all the models with equal performance.",
    "doi": "10.1145/3306618.3314316",
    "url": "https://www.semanticscholar.org/paper/f031fe645728d6fd36a9a36232cf19a846e9db73",
    "pdf_url": "",
    "venue": "AAAI/ACM Conference on AI, Ethics, and Society",
    "citation_count": 11,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424461"
  },
  {
    "source": "semantic_scholar",
    "source_id": "7327f152502e8d7a80989772deace698410afaf0",
    "title": "Artificial intelligence studies in cartography: a review and synthesis of methods, applications, and ethics",
    "authors": [
      "Yuhao Kang",
      "Song Gao",
      "Robert E. Roth"
    ],
    "year": 2023,
    "abstract": "ABSTRACT The past decade has witnessed the rapid development of geospatial artificial intelligence (GeoAI) primarily due to the ground-breaking achievements in deep learning and machine learning. A growing number of scholars from cartography have demonstrated successfully that GeoAI can accelerate previously complex cartographic design tasks and even enable cartographic creativity in new ways. Despite the promise of GeoAI, researchers and practitioners have growing concerns about the ethical issues of GeoAI for cartography. In this paper, we conducted a systematic content analysis and narrative synthesis of research studies integrating GeoAI and cartography to summarize current research and development trends regarding the usage of GeoAI for cartographic design. Based on this review and synthesis, we first identify dimensions of GeoAI methods for cartography such as data sources, data formats, map evaluations, and six contemporary GeoAI models, each of which serves a variety of cartographic tasks. These models include decision trees, knowledge graph and semantic web technologies, deep convolutional neural networks, generative adversarial networks, graph neural networks, and reinforcement learning. Further, we summarize seven cartographic design applications where GeoAI have been effectively employed: generalization, symbolization, typography, map reading, map interpretation, map analysis, and map production. We also raise five potential ethical challenges that need to be addressed in the integration of GeoAI for cartography: commodification, responsibility, privacy, bias, and (together) transparency, explainability, and provenance. We conclude by identifying four potential research directions for future cartographic research with GeoAI: GeoAI-enabled active cartographic symbolism, human-in-the-loop GeoAI for cartography, GeoAI-based mapping-as-a-service, and generative GeoAI for cartography.",
    "doi": "10.1080/15230406.2023.2295943",
    "url": "https://www.semanticscholar.org/paper/7327f152502e8d7a80989772deace698410afaf0",
    "pdf_url": "",
    "venue": "Cartography and Geographic Information Science",
    "citation_count": 63,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424466"
  },
  {
    "source": "semantic_scholar",
    "source_id": "6d128e070b7466d0894fde735e27f17aa848ad14",
    "title": "Artificial Intelligence For Decision Making In The Era Of Big Data Evolution",
    "authors": [
      "Rebeka Sultana"
    ],
    "year": 2024,
    "abstract": "This study systematically examines the transformative role of Artificial Intelligence (AI) in decision-making, focusing on its applications, challenges, and future opportunities. Using the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines, a total of 100 peer-reviewed articles were analyzed to ensure a rigorous and comprehensive understanding of the subject. The findings highlight AI's ability to optimize decision-making processes through advanced technologies such as machine learning, natural language processing, and predictive analytics, significantly enhancing accuracy, efficiency, and responsiveness across diverse sectors such as healthcare, finance, supply chain management, and public administration. Despite these advancements, the study identifies persistent challenges, including algorithmic bias, data privacy concerns, and the lack of transparency in \"black box\" AI models, which undermine trust and accountability. Additionally, the review uncovers research gaps, particularly in low-resource settings and emerging markets, where AI's potential remains underutilized due to infrastructural and data limitations. The integration of AI with emerging technologies, such as blockchain, quantum computing, and edge computing, presents promising opportunities to enhance scalability, security, and transparency in decision-making. The study also underscores the importance of interdisciplinary research, particularly at the intersection of AI and social sciences, to better understand human-AI interaction and foster ethical and socially equitable AI adoption. By addressing these challenges and leveraging emerging opportunities, AI can evolve into a transformative tool for informed, inclusive, and responsible decision-making in an increasingly complex world.",
    "doi": "10.70008/jbimisr.v1i01.59",
    "url": "https://www.semanticscholar.org/paper/6d128e070b7466d0894fde735e27f17aa848ad14",
    "pdf_url": "",
    "venue": "Non human journal",
    "citation_count": 12,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424470"
  },
  {
    "source": "semantic_scholar",
    "source_id": "d5023caaebebe75ba09927a0f4fabe55c356c2ea",
    "title": "THE USE OF ARTIFICIAL INTELLIGENCE IN JUDICIAL DECISIONMAKING: THE EXAMPLE OF CHINA",
    "authors": [
      "U. Tahura",
      "Niloufer Selvadurai"
    ],
    "year": 2023,
    "abstract": "\u00a0The paper analyses whether and to what extent AI-assisted judicial decision-making systems uphold the fundamental values that underpin the exercise of judicial discretion. As China is at the forefront of developing systems to simulate judicial thought, the paper explores this issue through the lens of China \u201csmart court\u201d. Beginning by considering how AI-assisted judicial decision making differs from traditional human judicial decision-making, the paper progresses to identify areas of legal concern as to the use of AI in judicial decision-making. Building on this analysis, the paper progresses to examine the use of AI in the China smart court system, including the \u201cautomated reason-generation framework\u201d and \u201cdeviation analysis\u201d adopted in the smart courts of China. The paper concludes by suggesting that the use of AI in judicial decision-making needs to appropriately calibrate the efficiency gains of automated processes with the need to maintain transparency and accountability, avoid bias and ensure a fair process.",
    "doi": "10.55574/pyeb5374",
    "url": "https://www.semanticscholar.org/paper/d5023caaebebe75ba09927a0f4fabe55c356c2ea",
    "pdf_url": "https://www.ijlet.org/wp-content/uploads/2023/03/2022-3-1-20.pdf",
    "venue": "International Journal of Law, Ethics, and Technology",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424475"
  },
  {
    "source": "semantic_scholar",
    "source_id": "30c1f17071d60cac17de99cce5b92217c1def9ea",
    "title": "Execution of Artificial Intelligence Approach in Human Resource Management Functions: Benefits and Challenges in Pakistan",
    "authors": [
      "Munaza Bibi"
    ],
    "year": 2019,
    "abstract": "Artificial intelligence has a theatrical effect on management of the workforce in the future.\u00a0This paper has highlighted the benefits and challenges to adoption of artificial intelligence approach in human resource management functions in Pakistan. Artificial intelligence-based human resource applications have robust potential to increase employee performance, engagement & retention while it also helps to reduce turnover, errors, time & biases in HR decision making. Artificial Intelligence needs to be incorporated by the organization in Pakistan for effective people management and HR decisions. Reluctance to the adoption of artificial intelligence in human resource management functions can demonstrate the devastating effect on the overall growth of the organization; thus, human resource leaders should prepare and train the human resource for the adoption of artificial intelligence & also address the concerns regarding man & machine interactions at the workplace. Yet, artificial intelligence cannot substitute the human element in human resource management, although if artificial intelligence united with capabilities of a human, would fetch on more intelligent solutions for HR. Hence, in today\u2019s world, artificial intelligence is a formula for the success of HR.",
    "doi": "10.31529/SJMS.2018.5.1.8",
    "url": "https://www.semanticscholar.org/paper/30c1f17071d60cac17de99cce5b92217c1def9ea",
    "pdf_url": "https://doi.org/10.31529/sjms.2018.5.1.8",
    "venue": "Sarhad Journal of Management Sciences",
    "citation_count": 8,
    "fields_of_study": [
      "Business"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424479"
  },
  {
    "source": "semantic_scholar",
    "source_id": "83c1d9490bd2202c7527ff6afcc738b0d3044721",
    "title": "AI in Human Resource Management: Reimagining Talent Acquisition, Development, and Retention",
    "authors": [
      "Abdumalik M. Kadirov",
      "Yulduzkhon Shakirova",
      "Gulshodakhon Ismoilova",
      "N. Makhmudova"
    ],
    "year": 2024,
    "abstract": "The integration of Artificial Intelligence (AI) into Human Resource Management (HRM) heralds a transformative era for talent acquisition, development, and retention strategies. AI technologies, including Machine Learning (ML), Natural Language Processing (NLP), Robotics Process Automation (RPA), and Predictive Analytics, offer unprecedented opportunities to streamline HR processes, enhance decision-making, and improve overall organizational efficiency. This survey paper explores the multifaceted applications of AI within HRM, focusing on how these technologies are redefining traditional practices in talent management. In talent acquisition, AI-driven tools automate resume screening and facilitate sophisticated candidate search and engagement strategies, enabling a more efficient and effective recruitment process. For talent development, AI applications personalize learning experiences and optimize performance management, addressing individual needs and promoting skill advancement. Additionally, AI\u2019s role in talent retention, through predictive turnover models and employee engagement platforms, underscores its potential to significantly lower turnover rates and foster a committed workforce. Despite these advancements, the paper also addresses the challenges and ethical considerations inherent in AI implementation, including algorithmic bias and privacy concerns. Through comparative analysis and illustrative graphs, this study provides a comprehensive overview of current trends and future directions in AI-enhanced HRM, offering valuable insights for practitioners and policymakers aiming to navigate the complexities of technology-driven human resource strategies.",
    "doi": "10.1109/ICKECS61492.2024.10617231",
    "url": "https://www.semanticscholar.org/paper/83c1d9490bd2202c7527ff6afcc738b0d3044721",
    "pdf_url": "",
    "venue": "2024 International Conference on Knowledge Engineering and Communication Systems (ICKECS)",
    "citation_count": 12,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424483"
  },
  {
    "source": "semantic_scholar",
    "source_id": "7faff5b4f3fd3cbcc9b9ce61a0a371e13be1c9bb",
    "title": "The ethical issues of the application of artificial intelligence in healthcare: a systematic scoping review",
    "authors": [
      "Golnar Karimian",
      "Elena Petelos",
      "S. Evers"
    ],
    "year": 2022,
    "abstract": "Artificial intelligence (AI) is being increasingly applied in healthcare. The expansion of AI in healthcare necessitates AI-related ethical issues to be studied and addressed. This systematic scoping review was conducted to identify the ethical issues of AI application in healthcare, to highlight gaps, and to propose steps to move towards an evidence-informed approach for addressing them. A systematic search was conducted to retrieve all articles examining the ethical aspects of AI application in healthcare from Medline (PubMed) and Embase (OVID), published between 2010 and July 21, 2020. The search terms were \u201cartificial intelligence\u201d or \u201cmachine learning\u201d or \u201cdeep learning\u201d in combination with \u201cethics\u201d or \u201cbioethics\u201d. The studies were selected utilizing a PRISMA flowchart and predefined inclusion criteria. Ethical principles of respect for human autonomy, prevention of harm, fairness, explicability, and privacy were charted. The search yielded 2166 articles, of which 18 articles were selected for data charting on the basis of the predefined inclusion criteria. The focus of many articles was a general discussion about ethics and AI. Nevertheless, there was limited examination of ethical principles in terms of consideration for design or deployment of AI in most retrieved studies. In the few instances where ethical principles were considered, fairness, preservation of human autonomy, explicability and privacy were equally discussed. The principle of prevention of harm was the least explored topic. Practical tools for testing and upholding ethical requirements across the lifecycle of AI-based technologies are largely absent from the body of reported evidence. In addition, the perspective of different stakeholders is largely missing.",
    "doi": "10.1007/s43681-021-00131-7",
    "url": "https://www.semanticscholar.org/paper/7faff5b4f3fd3cbcc9b9ce61a0a371e13be1c9bb",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s43681-021-00131-7.pdf",
    "venue": "AI and Ethics",
    "citation_count": 160,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424487"
  },
  {
    "source": "semantic_scholar",
    "source_id": "ff1be9a8d273588ada4575856eabea44a8bb4494",
    "title": "Ethical Concerns With Regards to Artificial Intelligence: A National Public Poll in Taiwan",
    "authors": [
      "Wendy Li-Yun Chang",
      "Shiang-Yao Liu",
      "Ying-Kai Liao",
      "Tony Szu-Hsien Lee"
    ],
    "year": 2024,
    "abstract": "Ethical concerns about how artificial intelligence (AI) impacts individuals and society are increasing rapidly, but few studies have systematically investigated the public awareness of AI ethics. This research collected and analyzed data from a public poll in Taiwan, an Asian region with a developed economy and specific social conditions, to identify societal views on AI ethics. The analysis of 84 AI ethics guidelines worldwide provided the survey framework covering five ethical principles: transparency, fairness, privacy, nonmaleficence, and accountability. The overarching goal was to determine the commonalities and differences in the ethical concerns of Taiwanese laypersons toward AI. Participants aged from 20 to 70 ( $N =1$ ,200) completed a computer-assisted random-digit-dial telephone survey, which utilized ethical scenarios to capture social views, and item validity was confirmed using focus-group interviews. Results found that respondents concerned about nonmaleficence the most, emphasizing that AI applications should not harm humans. Taiwanese people therefore tended to support strict AI technology regulation. It was particularly interesting that different patterns of public concern emerged about accountability, with the opinions on attributing responsibility to stakeholders varying with scenarios and the public\u2019s backgrounds. Those with higher education levels tended to attribute more responsibility to the industry, whereas those who had only received elementary-school education attributed accountability to AI developers. For self-driving cars, accountability was attributed to AI developers, whereas for medical decision-making, the accountability was attributed to the hospitals. These findings may help to elucidate the associations between societal views and the ethical principles of AI worldwide.",
    "doi": "10.1109/ACCESS.2024.3458893",
    "url": "https://www.semanticscholar.org/paper/ff1be9a8d273588ada4575856eabea44a8bb4494",
    "pdf_url": "https://doi.org/10.1109/access.2024.3458893",
    "venue": "IEEE Access",
    "citation_count": 3,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424492"
  },
  {
    "source": "semantic_scholar",
    "source_id": "0fb1acc52f09c05ba96fe3eb7b4395eff20653a4",
    "title": "Artificial Intelligence and Sensor Innovations: Enhancing Livestock Welfare with a Human-Centric Approach",
    "authors": [
      "S. Neethirajan"
    ],
    "year": 2023,
    "abstract": "In the wake of rapid advancements in artificial intelligence (AI) and sensor technologies, a new horizon of possibilities has emerged across diverse sectors. Livestock farming, a domain often sidelined in conventional AI discussions, stands at the cusp of this transformative wave. This paper delves into the profound potential of AI and sensor innovations in reshaping animal welfare in livestock farming, with a pronounced emphasis on a human-centric paradigm. Central to our discourse is the symbiotic interplay between cutting-edge technology and human expertise. While AI and sensor mechanisms offer real-time, comprehensive, and objective insights into animal welfare, it\u2019s the farmer\u2019s intrinsic knowledge of their livestock and environment that should steer these technological strides. We champion the notion of technology as an enhancer of farmers\u2019 innate capabilities, not a substitute. Our manuscript sheds light on: Objective Animal Welfare Indicators: An exhaustive exploration of health, behavioral, and physiological metrics, underscoring AI\u2019s prowess in delivering precise, timely, and objective evaluations. Farmer-Centric Approach: A focus on the pivotal role of farmers in the adept adoption and judicious utilization of AI and sensor technologies, coupled with discussions on crafting intuitive, pragmatic, and cost-effective solutions tailored to farmers' distinct needs. Ethical and Social Implications: A discerning scrutiny of the digital metamorphosis in farming, encompassing facets like animal privacy, data safeguarding, responsible AI deployment, and potential technological access disparities. Future Pathways: Advocacy for principled technology design, unambiguous responsible use guidelines, and fair technology access, all echoing the fundamental principles of human-centric computing and analytics. In essence, our paper furnishes pioneering insights at the crossroads of farming, animal welfare, technology, and ethics. It presents a rejuvenated perspective, bridging the chasm between technological advancements and their human beneficiaries, resonating seamlessly with the ethos of the Human-Centric Intelligent Systems journal. This comprehensive analysis thus marks a significant stride in the burgeoning domain of human-centric intelligent systems, especially within the digital livestock farming landscape, fostering a harmonious coexistence of technology, animals, and humans.",
    "doi": "10.1007/s44230-023-00050-2",
    "url": "https://www.semanticscholar.org/paper/0fb1acc52f09c05ba96fe3eb7b4395eff20653a4",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s44230-023-00050-2.pdf",
    "venue": "Human-Centric Intelligent Systems",
    "citation_count": 77,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424496"
  },
  {
    "source": "semantic_scholar",
    "source_id": "e88e53874dba0f058e55b729f11deaae4b65ea7a",
    "title": "PROS AND CONS OF USING ALGORITHMIC MANAGEMENT IN HUMAN RESOURCE",
    "authors": [
      "Miglena Angelova"
    ],
    "year": 2024,
    "abstract": "The opportunities that Artificial Intelligence and the principles of Algorithmic management provide to modern managers bring undeniable advantages for the development of a competitive business in today's extremely difficult business environment. At the same time, however, the effect of their use should be carefully analysed from the point of view of the compliance of the employees opinion in the enterprise - mainly in line with the observance and guarantee of basic rights of the employees. In this regard, the European Parliament and the European Council launched a legislative initiative to define harmonized rules within the Community on the use of artificial intelligence. Concepts such as \"algorithmic discrimination\" were introduced quite purposefully at the regulation level, given the risk of possible abuses associated with the use of AI. This report aims to ascertain the views of employers and employees on the use of artificial intelligence in Human Resource Management. The report presents and analyses data from an empirical study conducted among managers and employees in leading ICT enterprises in Bulgaria. According to our responders, one of the biggest advantages of using AI in Human Resources Management is related to the elimination of subjectivity in performance evaluation and the possibility of fair play in the procedures of internal selection of employees. At the same time, employees with more experience (over 10 years) are more sceptical of the idea of their work performance being evaluated solely by AI, while younger workers show more trust in AI solutions. However, both managers and workers recognize that it is best for the final decision in determining career development to be made by a person, but justified by the analyses made by AI. The report draws conclusions and recommendations that can serve both researchers and business managers. Certainly, AI is yet to undergo a very large development and application, including in the Human Resource Management, but at the same time it should not be at the expense of affected rights.",
    "doi": "10.17770/etr2024vol2.8031",
    "url": "https://www.semanticscholar.org/paper/e88e53874dba0f058e55b729f11deaae4b65ea7a",
    "pdf_url": "https://journals.ru.lv/index.php/ETR/article/download/8031/6341",
    "venue": "ENVIRONMENT. TECHNOLOGIES. RESOURCES. Proceedings of the International Scientific and Practical Conference",
    "citation_count": 3,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424499"
  },
  {
    "source": "semantic_scholar",
    "source_id": "411b5978e3983f617826fff6171b30fd44dd8744",
    "title": "The Gig Economy and Automation: Implications for Human Resource Management in Pakistan",
    "authors": [
      "Madiha Bashir",
      "Syeda Noor-e-Zahra",
      "Zobia Qaisar"
    ],
    "year": 2024,
    "abstract": "In the face of ground-breaking advancements such as automation, artificial intelligence, and the gig economy, the realm of human resource management (HRM) is undergoing a profound transformation. As the nature of work evolves, HRM practices must adapt to ensure both organizational performance and employee well-being. A primary focus of the study is the increasing emphasis on workforce flexibility. The rise of remote work, flexible schedules, and contingent labour has necessitated a shift in HRM practices. This research explores how organizations can effectively manage a diverse workforce while maintaining productivity and employee satisfaction. Additionally, the study examines the impact of job changes, including automation-driven task shifts and the emergence of new roles. It investigates how HR professionals can assist employees in adapting to these changes and acquiring the necessary skills for the future of work. Ethical considerations are also a central theme of this research. With the rise of AI and automation, questions surrounding data privacy, algorithmic bias, and ethical decision-making in the workplace have become increasingly pressing. The study explores the ethical implications of these technologies and provides guidance for HR professionals on developing ethical policies and practices. This research study underscores the critical role of HRM in fostering a productive and supportive work environment. It highlights the need for HR professionals to be strategic partners with business leaders, aligning HR practices with overall organizational goals. By understanding the challenges and opportunities presented by these revolutionary developments, HR professionals can equip their organizations to navigate the complexities of the contemporary workplace and achieve long-term success. This research offers a valuable resource for HR professionals, business executives, and policymakers seeking to understand the changing landscape of HRM and develop effective strategies for managing their workforce in the face of technological advancements and evolving workforce dynamics. \nReferences \nAdams-Prassl, J. (2019). What if your boss was an algorithm? Economic incentives, legal challenges, and the rise of artificial intelligence at work.\u00a0Comp. Lab. L. & Pol'y J.,\u00a041, 123. \nAli, Z., & Niaz, A. (2024). Impact of Leadership Styles on the Employees\u2019 Engagement in Private Healthcare Industry of UAE.\u00a0Inverge Journal of Social Sciences,\u00a03(1), 7-27. \nAlizai, S. H., Asif, M., & Rind, Z. K. (2021). Relevance of Motivational Theories and Firm Health.\u00a0Management (IJM),\u00a012(3), 1130-1137. \nAli, Z. A., Zain, M., Pathan, M. S., & Mooney, P. (2024). Contributions of artificial intelligence for circular economy transition leading toward sustainability: an explorative study in agriculture and food industries of Pakistan.\u00a0Environment, Development and Sustainability,\u00a026(8), 19131-19175. \nAsif, D. M. (2024). THE COMPLEXITIES OF BIOTERRORISM: CHALLENGES AND CONSIDERATIONS.\u00a0International Journal of Contemporary Issues in Social Sciences,\u00a03(3), 2175-2184. \nAsif, M. (2022). Integration of Information Technology in Financial Services and its Adoption by the Financial Sector in Pakistan.\u00a0Inverge Journal of Social Sciences,\u00a01(2), 23-35. \nAsif, M. (2021). Contingent Effect of Conflict Management towards Psychological Capital and Employees\u2019 Engagement in Financial Sector of Islamabad.\u00a0Preston University, Kohat, Islamabad Campus. \nAsif, M., Khan, A., & Pasha, M. A. (2019). Psychological capital of employees\u2019 engagement: moderating impact of conflict management in the financial sector of Pakistan.\u00a0Global Social Sciences Review, IV, 160-172. \nAsif, M., Pasha, M. A., Mumtaz, A., & Sabir, B. (2023). Causes of youth unemployment in Pakistan.\u00a0Inverge Journal of Social Sciences,\u00a02(1), 41-50. \nAsif, M., Pasha, M. A., Shafiq, S., & Craine, I. (2022). Economic impacts of post COVID-19.\u00a0Inverge Journal of Social Sciences,\u00a01(1), 56-65. \nAsif, M., & Sandhu, M. S. (2023). Social Media Marketing Revolution in Pakistan: A Study of its Adoption and Impact on Business Performance.\u00a0Journal of Business Insight and Innovation,\u00a02(2), 67-77. \nAsif, M., & Shaheen, A. (2022). Creating a High-Performance Workplace by the determination of Importance of Job Satisfaction, Employee Engagement, and Leadership.\u00a0Journal of Business Insight and Innovation,\u00a01(2), 9-15. \nAsif, M., Pasha, M. A., Shafiq, S., & Craine, I. (2022). Economic impa{Asif, 2023 #79}cts of post COVID-19.\u00a0Inverge Journal of Social Sciences,\u00a01(1), 56-65. \nAsghar, R. J., Qayyum, A., Zaheer, A., Mughal, A., & Khalid, S. (2011). Implementation of HR Practices in University Teachers of Pakistan. Information Management and Business Review, 3(3), 148-157. \nAsghar, R. J., Shah, M. U. Z. A. M. M. E. L., & Khan, J. A. (2021). Big Five Personality Traits and Training Transfer: Does Organizational Politics Matters.\u00a0International Review of Basic and Applied Sciences,\u00a09(4), 457-469. \nAurangzeb, M. A. (2021). Role of Leadership in Digital Transformation: A Case of Pakistani SMEs. \nAurangzeb, A. (2021). M., & Amin, MK (2021). Resources management and SME's performance.\u00a0Humanities & Social Sciences Reviews,\u00a09(3), 679-689. \nAurangzeb, M., Tunio, M., Rehman, Z., & Asif, M. (2021). Influence of administrative expertise on human resources practitioners on the job performance: Mediating role of achievement motivation.\u00a0International Journal of Management,\u00a012(4), 408-421. \nAzad, T. (2023). The Impact of Technology in the Classroom: An Insight into Students' and Teachers' Psychological Perspectives.\u00a0Inverge Journal of Social Sciences,\u00a02(2), 66-83. \nChintaradeja, P. (2022). Rhodes\u2019 governance concept in relation to Thai public service.\u00a0Inverge Journal of Social Sciences,\u00a01(1), 1-12. \nChompupor, P. (2023). The MICE labour market challenges in Thailand from experts\u2019 perspective.\u00a0Inverge Journal of Social Sciences,\u00a02(2), 165\u2013175. \nDe Stefano, V. (2020). Algorithmic bosses and what to do about them: automation, artificial intelligence and labour protection.\u00a0Economic and policy implications of artificial intelligence, 65-86. \nDarkwa, E., Inguva, H., Osafo-Adjei, C., & Acquah, B. (2024). The public sphere on a digital plane: The influence of the new digital media on Ghana\u2019s democracy and the Public Sphere.\u00a0Inverge Journal of Social Sciences,\u00a03(2), 46-62. \nInyang, U., G. Etuk, S., & Effiom, M. (2024). Employees\u2019 Assessment of Impact of Information Systems on Operational Efficiency of Insurance Companies.\u00a0Inverge Journal of Social Sciences,\u00a03(3), 1\u201312. \nIqbal, M. S., Rahim, Z. A., & Hussain, S. A. (2020). Industry 4.0 revolution and challenges in developing countries: a case study on Pakistan.\u00a0Journal of Advanced Research in Business and Management Studies,\u00a021(1), 40-52. \nIshfaq, U., Imran, A., Joseph, V., Haqdad, U., & Asif, M. (2022). Mediating role of trust between emotional intelligence and project team performance in telecommunication sector.\u00a0PalArch's Journal of Archaeology of Egypt/Egyptology,\u00a019(4), 988-1005. \nJamil, S. (2021). Artificial intelligence and journalistic practice: The crossroads of obstacles and opportunities for the Pakistani journalists.\u00a0Journalism Practice,\u00a015(10), 1400-1422. \nKhan, M. H. (2023). The role of recruitment and selection on organizational performance: An empirical investigation into the impact of recruitment and selection on organizational performance.\u00a0Inverge Journal of Social Sciences,\u00a02(2), 146-164. \nKhan, M. H. (2023). The influence of green HRM practices and green knowledge sharing on green service behaviors: Environmental Sustainability at Work: How Green HRM and Knowledge Transfer Influence Green Service Behaviors.\u00a0Inverge Journal of Social Sciences,\u00a02(2), 176-193. \nKhatun, R. (2023). Work from Home in Pandemic - An Indian Perspective.\u00a0Inverge Journal of Social Sciences,\u00a02(3), 77\u201395.\u00a0 \nMalik, A., Budhwar, P., & Srikanth, N. R. (2020). Gig economy, 4IR and artificial intelligence: Rethinking strategic HRM. In\u00a0Human & technological resource management (HTRM): New insights into revolution 4.0\u00a0(pp. 75-88). Emerald Publishing Limited. \nMangi, R. A., Jhatial, A. A., Shah, S. A. A., & Ghumro, I. A. (2012). Human resource management practices in private sector organisations in Pakistan: study of cultural influences.\u00a0Global Journal of Management and Business Research,\u00a012(7), 20-30. \nMirza, M. S., & Rashid, S. (2024). Effect of Online Cooperative Learning on Students\u2019 Academic Achievement at Higher Education Level.\u00a0Inverge Journal of Social Sciences,\u00a03(2), 1-10. \nMumtaz, A., Munir, N., Mumtaz, R., Farooq, M., & Asif, M. (2023). Impact of Psychological & Economic Factors on Investment Decision-Making in Pakistan Stock Exchange.\u00a0Journal of Positive School Psychology, 130-135. \nMushtaque, T., Tunio, M. N., ur Rehman, Z., & Asif, M. (2021). INFLUENCE OF ADMINISTRATIVE EXPERTISE OF HUMAN RESOURCE PRACTITIONERS ON THE JOB PERFORMANCE: MEDIATING ROLE OF ACHIEVEMENT MOTIVATION.\u00a0International Journal of Management (IJM),\u00a012(4). \nNabi, M. K. (2019). The impact of artificial intelligence (AI) on workforce in emerging economies.\u00a0Global Journal of Management and Business Research,\u00a019(8), 71-78. \nNadeem, M., Ali, Y., Rehman, O. U., & Saarinen, L. T. (2024). Barriers and strategies for digitalisation of economy in developing countries: Pakistan, a case in point.\u00a0Journal of the Knowledge Economy,\u00a015(1), 4730-4749. \nNimmagadda, B., Vangaveti, Y., Aaluri, S., Rao, C. M., & Singh, B. (2024). An Analytical study on Navigating Sustainability Challenges and Opportunities in the era of AI and the Gig Economy. In\u00a0MATEC Web of Conferences\u00a0(Vol. 392, p. 01044). EDP Sciences. \nNishtar, Z., Munir, M. A., Akram, N., Masood, B., Asghar, F., & Meahrayen, M. A. (2023). Green Finance and the Automate Solar Tracking System: Assessing Efficiency, Financial impact, and Environmental Benefits.\u00a0Inverge Journal of Social Sciences,\u00a02(3), 134-147. \nPasha, M. A., Ramzan, M., & Asif, M. (2019). Impact of Economic Value Added Dynamics on Stock Prices ",
    "doi": "10.63544/ijss.v3i3.90",
    "url": "https://www.semanticscholar.org/paper/411b5978e3983f617826fff6171b30fd44dd8744",
    "pdf_url": "",
    "venue": "Inverge Journal of Social Sciences",
    "citation_count": 2,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424504"
  },
  {
    "source": "semantic_scholar",
    "source_id": "5317d9d7f6b8ad4c67a89f53ee31c3bc875db933",
    "title": "\u201cJust\u201d accuracy? Procedural fairness demands explainability in AI-based medical resource allocations",
    "authors": [
      "J. Rueda",
      "J. Rodr\u00edguez",
      "Iris Parra Jounou",
      "J. Hortal-Carmona",
      "T. Aus\u00edn",
      "D. Rodr\u00edguez-Arias"
    ],
    "year": 2022,
    "abstract": "The increasing application of artificial intelligence (AI) to healthcare raises both hope and ethical concerns. Some advanced machine learning methods provide accurate clinical predictions at the expense of a significant lack of explainability. Alex John London has defended that accuracy is a more important value than explainability in AI medicine. In this article, we locate the trade-off between accurate performance and explainable algorithms in the context of distributive justice. We acknowledge that accuracy is cardinal from outcome-oriented justice because it helps to maximize patients\u2019 benefits and optimizes limited resources. However, we claim that the opaqueness of the algorithmic black box and its absence of explainability threatens core commitments of procedural fairness such as accountability, avoidance of bias, and transparency. To illustrate this, we discuss liver transplantation as a case of critical medical resources in which the lack of explainability in AI-based allocation algorithms is procedurally unfair. Finally, we provide a number of ethical recommendations for when considering the use of unexplainable algorithms in the distribution of health-related resources.",
    "doi": "10.1007/s00146-022-01614-9",
    "url": "https://www.semanticscholar.org/paper/5317d9d7f6b8ad4c67a89f53ee31c3bc875db933",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s00146-022-01614-9.pdf",
    "venue": "Ai & Society",
    "citation_count": 38,
    "fields_of_study": [
      "Medicine",
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424509"
  },
  {
    "source": "semantic_scholar",
    "source_id": "36d9f42cd27c91e56587602723cfa7e9d4203386",
    "title": "Establishing Data Provenance for Responsible Artificial Intelligence Systems",
    "authors": [
      "K. Werder",
      "B. Ramesh",
      "Rongen Zhang"
    ],
    "year": 2022,
    "abstract": "Data provenance, a record that describes the origins and processing of data, offers new promises in the increasingly important role of artificial intelligence (AI)-based systems in guiding human decision making. To avoid disastrous outcomes that can result from bias-laden AI systems, responsible AI builds on four important characteristics: fairness, accountability, transparency, and explainability. To stimulate further research on data provenance that enables responsible AI, this study outlines existing biases and discusses possible implementations of data provenance to mitigate them. We first review biases stemming from the data's origins and pre-processing. We then discuss the current state of practice, the challenges it presents, and corresponding recommendations to address them. We present a summary highlighting how our recommendations can help establish data provenance and thereby mitigate biases stemming from the data's origins and pre-processing to realize responsible AI-based systems. We conclude with a research agenda suggesting further research avenues.",
    "doi": "10.1145/3503488",
    "url": "https://www.semanticscholar.org/paper/36d9f42cd27c91e56587602723cfa7e9d4203386",
    "pdf_url": "https://kups.ub.uni-koeln.de/53868/1/TMIS_manuscript_DataProvenance.pdf",
    "venue": "ACM Transactions on Management Information Systems",
    "citation_count": 72,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424513"
  },
  {
    "source": "semantic_scholar",
    "source_id": "d68d37eac48895ed9d99aa6bed8e08be07f5cc22",
    "title": "Artificial intelligence-assisted generative pretrained transformers for applications of ChatGPT in higher education among graduates",
    "authors": [
      "Jigna B. Prajapati",
      "Ashwini Kumar",
      "Sudarshan Singh",
      "Bhupendra G. Prajapati",
      "Yash Thakar",
      "Prashant R. Tambe",
      "Amit Ved"
    ],
    "year": 2024,
    "abstract": null,
    "doi": "10.1007/s43545-023-00818-0",
    "url": "https://www.semanticscholar.org/paper/d68d37eac48895ed9d99aa6bed8e08be07f5cc22",
    "pdf_url": "",
    "venue": "SN Social Sciences",
    "citation_count": 11,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424517"
  },
  {
    "source": "semantic_scholar",
    "source_id": "6aa4d770032622093d26309fc4fe4ae000a56ee0",
    "title": "The ethics of artificial intelligence, UNESCO and the African Ubuntu perspective",
    "authors": [
      "Dorine E. van Norren"
    ],
    "year": 2022,
    "abstract": "\nPurpose\nThis paper aims to demonstrate the relevance of worldviews of the global south to debates of artificial intelligence, enhancing the human rights debate on artificial intelligence (AI) and critically reviewing the paper of UNESCO Commission on the Ethics of Scientific Knowledge and Technology (COMEST) that preceded the drafting of the UNESCO guidelines on AI. Different value systems may lead to different choices in programming and application of AI. Programming languages may acerbate existing biases as a people\u2019s worldview is captured in its language. What are the implications for AI when seen from a collective ontology? Ubuntu (I am a person through other persons) starts from collective morals rather than individual ethics.\n\n\nDesign/methodology/approach\nLiterature overview on the African philosophy of Ubuntu as applied to artificial intelligence. Application of it to the United Nations Educational, Scientific and Cultural Organisation (UNESCO) debates on establishing guidelines to the ethics of artificial intelligence.\n\n\nFindings\nMetaphysically, Ubuntu and its conception of social personhood (attained during one\u2019s life) largely rejects transhumanism. When confronted with economic choices, Ubuntu favors sharing above competition and thus an anticapitalist logic of equitable distribution of AI benefits, humaneness and nonexploitation. When confronted with issues of privacy, Ubuntu emphasizes transparency to group members, rather than individual privacy, yet it calls for stronger (group privacy) protection. In democratic terms, it promotes consensus decision-making over representative democracy. Certain applications of AI may be more controversial in Africa than in other parts of the world, like care for the elderly, that deserve the utmost respect and attention, and which builds moral personhood. At the same time, AI may be helpful, as care from the home and community is encouraged from an Ubuntu perspective. The report on AI and ethics of the UNESCO World COMEST formulated principles as input, which are analyzed from the African ontological point of view. COMEST departs from \u201cuniversal\u201d concepts of individual human rights, sustainability and good governance which are not necessarily fully compatible with relatedness, including future and past generations. Next to rules based approaches, which may hamper diversity, bottom-up approaches are needed with intercultural deep learning algorithms.\n\n\nResearch limitations/implications\nThere is very few existing literature on AI and Ubuntu. Therefore, this paper is of an explorative nature.\n\n\nPractical implications\nThe ethics of Ubuntu offers unique vantage points in looking at the organization of society and economics today, which are also relevant for development of AI, especially in its tenet of relatedness rather than individuality (and practical use of AI for individuals), taking responsibility for society as a whole (such as analyzing the benefit of AI for all strata of society), and embodying true inclusiveness. Whether looking at top-down guidelines for the development and implementation of AI or the bottom-up ethical learning process of AI (deep learning), ethics of the Global South can have an important role to play to combat global individualist tendencies and inequity, likely reinforced by AI. This warrants far more research.\n\n\nSocial implications\nApplications of AI in Africa are not contextualized, do not address the most pressing needs of the African continent, lead to cybersecurity issues and also do not incorporate African ethics. UNESCO\u2019s work in this regard is important but expert inputs are largely centered around Western \u201cuniversal\u201d principles and Organisation for Economic Cooperation and Development and EU precedence. African ethics have, so far, a small role to play in global ethics and philosophy and therefore risk to be overlooked in the discussion on AI and ethics. This is why the consultation process of UNESCO on ethics of AI was of paramount importance. However, it does not automatically lead to consultation of African philosophers or sages, as many are educated in Western (ized) education systems. See further details under practical implications.\n\n\nOriginality/value\nThis is a new area of research in which little work has been done so far. This paper offers the opportunity to widen the debate on AI and ethics beyond the conventional discourse, involving multiple worldviews, of which Ubuntu is just one.\n",
    "doi": "10.1108/jices-04-2022-0037",
    "url": "https://www.semanticscholar.org/paper/6aa4d770032622093d26309fc4fe4ae000a56ee0",
    "pdf_url": "",
    "venue": "Journal of Information, Communication and Ethics in Society",
    "citation_count": 19,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424522"
  },
  {
    "source": "semantic_scholar",
    "source_id": "6a876c583e543b7f419281765f9ab176ccea1990",
    "title": "The Ethics of Emotional Artificial Intelligence: A Mixed Method Analysis",
    "authors": [
      "N. Ghotbi"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1007/s41649-022-00237-y",
    "url": "https://www.semanticscholar.org/paper/6a876c583e543b7f419281765f9ab176ccea1990",
    "pdf_url": "",
    "venue": "Asian Bioethics Review",
    "citation_count": 17,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424526"
  },
  {
    "source": "semantic_scholar",
    "source_id": "60c050bbc1d64d409889856450357c2e29579c52",
    "title": "Unravelling Smart HRM 4.0: A Narrative Review of Progressive 4.0 Technology Integration in Human Resource Management",
    "authors": [
      "Syezreen Dalina Rusdi",
      "Ida Rosnita Ismail",
      "R. Isa"
    ],
    "year": 2024,
    "abstract": "The integration of progressive 4.0 technology into human resource management (HRM) represents a significant shift in how organizations optimize and enhance workforce capabilities. This review explores the origins, applications, benefits, challenges and future prospects surrounding smart HRM 4.0. By reviewing existing literature, this paper examines the utilization of Artificial Intelligence (AI), Big Data analytics, machine learning (ML) and the Internet of Things (IoT) in HRM, specifically in talent acquisition, training, performance management, and rewards. Additionally, it addresses the implementation challenges including data quality assurance, skill shortages, and\u00a0cultural resistance. The paper also emphasizes the importance of ethical considerations. In terms of future research, it highlights the necessity for ethically deploying Industry 4.0 and establishing robust AI governance frameworks. By combining technological innovation with ethical values, organizations can navigate the complexities of this integration, leading to a future characterized by workplace efficiency, accountability, and fairness.",
    "doi": "10.22610/imbr.v16i3(i)s.4070",
    "url": "https://www.semanticscholar.org/paper/60c050bbc1d64d409889856450357c2e29579c52",
    "pdf_url": "https://ojs.amhinternational.com/index.php/imbr/article/download/4070/2634",
    "venue": "Information Management and Business Review",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424530"
  },
  {
    "source": "semantic_scholar",
    "source_id": "6d505cb644fb317343cf5cba03630ad6df7e5ee9",
    "title": "Ethical aspects in the use of artificial intelligence in the process of drug development | [Aspecte etice \u00een utilizarea inteligen\u021bei artificiale \u00een procesul de dezvoltare a medicamentelor]",
    "authors": [
      "Ecaterina Pitel",
      "Florin Lea\u0219u",
      "Andrada Nicolau",
      "Liliana Rogozea"
    ],
    "year": 2024,
    "abstract": "Background: The integration of Artificial Intelligence (AI) in drug development has revolutionized the pharmaceutical and medical landscape, enhancing drug discovery, clinical trials, and personalized medicine. This evolution, while beneficial, has introduced significant ethical challenges in data privacy, algorithmic bias, intellectual property rights, and equitable access to AI-driven therapies. Objective: The application of AI in drug development presents uncertainties regarding the ethical management of patient data, potential biases in AI decision-making, and the fair distribution of AI-powered treatments. The rapidly evolving nature of AI technologies and the dynamic regulatory environment further compound these uncertainties, posing a challenge to the ethical deployment of AI in this sector. Methods: We conducted a systematic literature search from January 2019 to December 2023 using databases like PubMed, PLOS, and Google Scholar, with keywords \"artificial intelligence,\" \"ethics,\" and \"drug discovery.\" This search led to the selection and detailed analysis of 33 key documents, focusing on the use of AI in drug discovery and associated ethical challenges. The extracted insights were synthesized to highlight major trends and discoveries in the field. Results: The review found that while AI significantly streamlines drug development processes, it raises substantial concerns about data privacy, decision-making biases, and equitable access. Key findings highlight the importance of ethically managing patient data, employing inclusive data sets for algorithm training, and maintaining transparency in AI operations. Intellectual property rights linked to AI discoveries and the necessity for transparent AI decision-making, particularly in clinical trials, were identified as critical areas needing attention. Conclusions: The rapid advancement of AI in pharmaceuticals necessitates a fine balance between innovation and adherence to ethical principles. This requires a multidisciplinary collaborative approach and the ongoing adaptation of regulatory frameworks to ensure the ethical and effective utilization of AI in drug development.\nRezumat\nIntroducere: Integrarea inteligen\u021bei artificiale (AI) \u00een dezvoltarea medicamentelor a revolu\u021bionat peisajul farmaceutic \u0219i medical, \u00eembun\u0103t\u0103\u021bind descoperirea medicamentelor, studiile clinice \u0219i medicina personalizat\u0103. Aceast\u0103 evolu\u021bie, de\u0219i benefic\u0103, a introdus provoc\u0103ri etice semnificative \u00een ceea ce prive\u0219te confiden\u021bialitatea datelor, p\u0103rtinirea algoritmic\u0103, drepturile de proprietate intelectual\u0103 \u0219i accesul echitabil la terapiile bazate pe IA. Obiective: Aplicarea IA \u00een dezvoltarea medicamentelor prezint\u0103 incertitudini \u00een ceea ce prive\u0219te gestionarea etic\u0103 a datelor pacien\u021bilor, poten\u021bialele prejudec\u0103\u021bi \u00een procesul decizional al IA \u0219i distribu\u021bia echitabil\u0103 a tratamentelor bazate pe IA. Evolu\u021bia rapid\u0103 a tehnologiilor IA \u0219i mediul de reglementare dinamic accen\u00actueaz\u0103 \u0219i mai mult aceste incertitudini, reprezent\u00e2nd o provocare pentru implementarea etic\u0103 a IA \u00een acest sector. Material \u0219i metod\u0103: Am efectuat o c\u0103utare sistematic\u0103 a literaturii din ianuarie 2019 p\u00e2n\u0103 \u00een decembrie 2023 folosind baze de date precum PubMed, PLOS \u0219i Google Scholar, cu cuvinte cheie \"inteligen\u021b\u0103 artificial\u0103\", \"etic\u0103\" \u0219i \"descoperire de medicamente\". Aceast\u0103 c\u0103utare a condus la selectarea \u0219i analiza detaliat\u0103 a 33 de documente-cheie, concentr\u00e2ndu-se pe utilizarea IA \u00een descoperirea medicamentelor \u0219i provoc\u0103rile etice asociate. Perspectivele extrase au fost sintetizate pentru a eviden\u021bia tendin\u021bele \u0219i descoperirile majore din domeniu. Rezultate: Analiza a constatat c\u0103, de\u0219i AI simplific\u0103 semnificativ procesele de dezvoltare a medica\u00acmentelor, aceasta ridic\u0103 preocup\u0103ri substan\u021biale cu privire la confiden\u021bialitatea datelor, prejudec\u0103\u021bile de luare a deciziilor \u0219i accesul echitabil. Principalele constat\u0103ri eviden\u021biaz\u0103 importan\u021ba gestion\u0103rii etice a datelor pacien\u021bilor, a utiliz\u0103rii seturilor de date incluzive pentru antrenarea algoritmilor \u0219i a men\u021binerii transparen\u021bei \u00een opera\u021biunile IA. Drepturile de proprietate intelectual\u0103 legate de descoperirile IA \u0219i necesitatea unui proces decizional transparent \u00een domeniul IA, \u00een special \u00een trialurile clinice, au fost identificate ca domenii critice care necesit\u0103 aten\u021bie. Concluzii: Dezvoltarea rapid\u0103 a IA \u00een industria farmaceutic\u0103 necesit\u0103 un echilibru fin \u00eentre inovare \u0219i respectarea principiilor etice. Acest lucru necesit\u0103 o abordare multidisciplinar\u0103 bazat\u0103 pe colaborare \u0219i adaptarea continu\u0103 a cadrelor de reglementare pentru a asigura utilizarea etic\u0103 \u0219i eficient\u0103 a IA \u00een dezvoltarea medicamentelor.",
    "doi": "10.31926/jmb.2023.2.8",
    "url": "https://www.semanticscholar.org/paper/6d505cb644fb317343cf5cba03630ad6df7e5ee9",
    "pdf_url": "",
    "venue": "Jurnal Medical Brasovean",
    "citation_count": 3,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424534"
  },
  {
    "source": "semantic_scholar",
    "source_id": "a624e3348a51c9ae653437030bbef54336127310",
    "title": "Artificial Intelligence in Employee Performance Evaluation and Its Managerial Implication",
    "authors": [
      "Hina Riaz Dr",
      "Seema Ghanghas"
    ],
    "year": 2024,
    "abstract": ": Since last decade usage of information technology has been increased drastically and artificial intelligence has taken a big leap absorbed into organizational culture of almost every department who surges to be updated and keep the competitive edge thus human resource management is not untouched too. Despite of tremendous research being done in the field of AI yet a dearth of proper research is found questioning the authenticity, rationality, and equability of AI/ML tools in business settings. This paper focuses on the perspective of relying on AI/ML in the process of employee performance management framing Artificial Intelligence performance measurement system integration using learning algorithms to make the evaluation a real-time process much easier, accurate, unbiased and fair. The managerial outlook of AI integrated performance appraisal results in strategic decision making, enhance levels of employee performance, employee commitment, satisfaction and reduced employee turnover behavior. This is an empirical research which examines previous literature through content analysis from authentic writings of secondary resources.",
    "doi": "10.52783/jier.v4i1.559",
    "url": "https://www.semanticscholar.org/paper/a624e3348a51c9ae653437030bbef54336127310",
    "pdf_url": "https://jier.org/index.php/journal/article/download/559/498",
    "venue": "Journal of Informatics Education and Research",
    "citation_count": 6,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424538"
  },
  {
    "source": "semantic_scholar",
    "source_id": "50cf184def032d32d1265136b5036d28734600e0",
    "title": "LEGAL ANALYSIS OF EU ARTIFICIAL INTELLIGENCE ACT (2024): INSIGHTS FROM PERSONAL DATA GOVERNANCE AND HEALTH POLICY",
    "authors": [
      "Anca Parmena Olimid"
    ],
    "year": 2024,
    "abstract": "Background: This study correlates the up-to-date ethical, functional and legal evaluations\nrelated to the management and governance of artificial intelligence (AI) under European\nUnion (EU) law, particularly impacting the health data sector and medical standards as\nprovided by the Artificial Intelligence Act within the Regulation adopted by the European\nCouncil in May 2024. The initial proposal for the management and governance of the AI sector\nwas submitted in April 2021. Three years later, on 13 March 2024, the European Union\nArtificial Intelligence Act (EU AIA) was adopted by the European Parliament. Subsequently,\non 21 May 2024, the Council adopted an innovative legislative framework that harmonises the\nstandards and rules for AI regulation. This framework is set to take effect in May 2026, with\nthe central objective of stimulating and motivating a fair, safe, legal single market that respects\nthe principles of ethics and the fundamental rights of the human person.\nMethods: The current legal analysis focuses on the European Union\u2019s new institutional\ngovernance involving a multistage approach to managing health data, ethical artificial\nintelligence, generative artificial intelligence and classification of types of AI by considering the\ndegree of risk (e.g. artificial intelligence systems with limited risk and systems with high risk)\nand medical devices. It outlines the legal framework for AI regulation and governance in the\nEU by focusing on compliance with the previously adopted legislation in the Medical Devices\nRegulation (2017) and the In-Vitro Diagnostic Regulation (2017). The paper also examines\nthe application of the newly adopted EU Artificial Intelligence Act in relation to national justice\nsystems, previous EU regulations on medical devices and personal data protection regulation,\nand its correlation with the European Court of Human Rights jurisprudence. This opens up\ncomplex discussions related to judicial reform and access to justice. For this purpose, as a\nresearch objective, the legal analysis includes an innovative perspective following an integrative\ndiscussion on the latest legal reforms and regulations of the AI sector in Eastern Europe\nlaunched in 2024 with a special focus on the latest developments in the EU Candidate\nCountries namely Ukraine and the Republic of Moldova.\nResults and conclusions: The present research facilitates the exploration of the real benefits of\nmanaging innovative AI systems for medical data, research, and development, as well as within\nthe medical technology industry.",
    "doi": "10.33327/ajee-18-7.4-a000103",
    "url": "https://www.semanticscholar.org/paper/50cf184def032d32d1265136b5036d28734600e0",
    "pdf_url": "https://doi.org/10.33327/ajee-18-7.4-a000103",
    "venue": "Access to Justice in Eastern Europe",
    "citation_count": 8,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424542"
  },
  {
    "source": "semantic_scholar",
    "source_id": "b30afed03d20e42a9239094b8218831098b7a05e",
    "title": "Artificial Intelligence in Governance: Opportunities, Challenges, and Ethical Implications for Public Administration",
    "authors": [
      "SantoshKumar Pulijala"
    ],
    "year": 2024,
    "abstract": "The integration of Artificial Intelligence (AI) in the public sector presents both unprecedented opportunities and significant challenges for governments worldwide. This article examines the multifaceted impact of AI on public administration, exploring its applications in service delivery, urban planning, public safety, and administrative efficiency. While AI offers substantial benefits, including enhanced decision-making, cost savings, and improved citizen services, it also raises critical concerns regarding bias, privacy, accountability, and workforce displacement. This article provides a comprehensive analysis of the ethical considerations surrounding AI deployment in governance,\nemphasizing the need for transparency, inclusivity, and human oversight. By critically evaluating both the promises and perils of AI in public sector operations, this article contributes to the ongoing discourse on responsible AI adoption in government. The findings underscore the importance of developing robust\ngovernance frameworks that can harness AI's potential while safeguarding citizens' rights and ensuring equitable service delivery. As governments navigate the AI revolution, this article offers insights into strategies for balancing technological advancement with ethical governance, paving the way for a more\nefficient, fair, and responsive public sector.",
    "doi": "10.36948/ijfmr.2024.v06i06.29990",
    "url": "https://www.semanticscholar.org/paper/b30afed03d20e42a9239094b8218831098b7a05e",
    "pdf_url": "https://www.ijfmr.com/papers/2024/6/29990.pdf",
    "venue": "International Journal For Multidisciplinary Research",
    "citation_count": 6,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424545"
  },
  {
    "source": "semantic_scholar",
    "source_id": "36554571bd688b62db21000c659db8bf238b94a2",
    "title": "Artificial Intelligence and Surgery: Ethical Dilemmas and Open Issues.",
    "authors": [
      "L. Cobianchi",
      "J. Verde",
      "T. Loftus",
      "Daniele Piccolo",
      "F. Dal Mas",
      "P. Mascagni",
      "A. Garc\u00eda V\u00e1zquez",
      "L. Ansaloni",
      "G. R. Marseglia",
      "M. Massaro",
      "Benoit Gallix",
      "N. Padoy",
      "Angelos Peter",
      "H. Kaafarani"
    ],
    "year": 2022,
    "abstract": "BACKGROUND\nArtificial intelligence (AI) applications aiming to support surgical decision-making processes are generating novel threats to ethical surgical care. To understand and address these threats, we summarize the main ethical issues that may arise from applying AI to surgery, starting from the Ethics Guidelines for Trustworthy Artificial Intelligence framework recently promoted by the European Commission.\n\n\nSTUDY DESIGN\nA modified Delphi process has been employed to achieve expert consensus.\n\n\nRESULTS\nThe main ethical issues that arise from applying AI to surgery, described in detail here, relate to human agency, accountability for errors, technical robustness, privacy and data governance, transparency, diversity, non-discrimination, and fairness. It may be possible to address many of these ethical issues by expanding the breadth of surgical AI research to focus on implementation science. The potential for AI to disrupt surgical practice suggests that formal digital health education is becoming increasingly important for surgeons and surgical trainees.\n\n\nCONCLUSIONS\nA multidisciplinary focus on implementation science and digital health education is desirable to balance opportunities offered by emerging AI technologies and respect for the ethical principles of a patient-centric philosophy.",
    "doi": "10.1097/XCS.0000000000000242",
    "url": "https://www.semanticscholar.org/paper/36554571bd688b62db21000c659db8bf238b94a2",
    "pdf_url": "https://iris.unive.it/bitstream/10278/3758526/1/2022_13_Cobianchi%20et%20al_JACS%20preprint.pdf",
    "venue": "Journal of the American College of Surgeons",
    "citation_count": 58,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424550"
  },
  {
    "source": "semantic_scholar",
    "source_id": "fc4ec3cc1682b7e24058fd17441c7ab8529530ee",
    "title": "Artificial Intelligence to support ethical decision-making for incapacitated patients: a survey among German anesthesiologists and internists",
    "authors": [
      "Lasse Benzinger",
      "J. Epping",
      "F. Ursin",
      "S. Salloch"
    ],
    "year": 2024,
    "abstract": "Background Artificial intelligence (AI) has revolutionized various healthcare domains, where AI algorithms sometimes even outperform human specialists. However, the field of clinical ethics has remained largely untouched by AI advances. This study explores the attitudes of anesthesiologists and internists towards the use of AI-driven preference prediction tools to support ethical decision-making for incapacitated patients. Methods A questionnaire was developed and pretested among medical students. The questionnaire was distributed to 200 German anesthesiologists and 200 German internists, thereby focusing on physicians who often encounter patients lacking decision-making capacity. The questionnaire covered attitudes toward AI-driven preference prediction, availability and utilization of Clinical Ethics Support Services (CESS), and experiences with ethically challenging situations. Descriptive statistics and bivariate analysis was performed. Qualitative responses were analyzed using content analysis in a mixed inductive-deductive approach. Results Participants were predominantly male (69.3%), with ages ranging from 27 to 77. Most worked in nonacademic hospitals (82%). Physicians generally showed hesitance toward AI-driven preference prediction, citing concerns about the loss of individuality and humanity, lack of explicability in AI results, and doubts about AI\u2019s ability to encompass the ethical deliberation process. In contrast, physicians had a more positive opinion of CESS. Availability of CESS varied, with 81.8% of participants reporting access. Among those without access, 91.8% expressed a desire for CESS. Physicians' reluctance toward AI-driven preference prediction aligns with concerns about transparency, individuality, and human-machine interaction. While AI could enhance the accuracy of predictions and reduce surrogate burden, concerns about potential biases, de-humanisation, and lack of explicability persist. Conclusions German physicians frequently encountering incapacitated patients exhibit hesitance toward AI-driven preference prediction but hold a higher esteem for CESS. Addressing concerns about individuality, explicability, and human-machine roles may facilitate the acceptance of AI in clinical ethics. Further research into patient and surrogate perspectives is needed to ensure AI aligns with patient preferences and values in complex medical decisions.",
    "doi": "10.1186/s12910-024-01079-z",
    "url": "https://www.semanticscholar.org/paper/fc4ec3cc1682b7e24058fd17441c7ab8529530ee",
    "pdf_url": "https://bmcmedethics.biomedcentral.com/counter/pdf/10.1186/s12910-024-01079-z",
    "venue": "BMC Medical Ethics",
    "citation_count": 2,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424554"
  },
  {
    "source": "semantic_scholar",
    "source_id": "360be56f656f7aa4c13325966febbe888c401faf",
    "title": "Machine Ethics and African Identities: Perspectives of Artificial Intelligence in Africa",
    "authors": [
      "D. Kohnert"
    ],
    "year": 2022,
    "abstract": ": Artificial intelligence (AI) has been welcomed enthusiastically by Africans as a new resource for African development. AI could allow for improved well-being by facilitating innovations in the economic sector, education, health, ecology, urban planning, industries etc. Yet, the high expectations may be little more than pious wishes. There are still unsolved questions concerning the required transfer and choice of appropriate technology and its mastering. Given, that the concept of 'technology transfer' of the modernization theories of the 1960s utterly failed, because it was not adapted to the local needs (e.g. lack of resources, widespread poverty and gross socio-economic inequality, labour-intensive technology, low productivity), some scholars called for an endogenous concept of African AI. This, however, triggered heated controversies. Africa became a battleground for 'digital empires' of global powers because of its practically inexistent digital infrastructure. Yet, African solutions to African problems would be required. Moreover, the prevailing narratives and default settings of AI-related technologies have been denounced as male gender-biased, white, heteronormative, able-bodied, and Western. Also, the hitherto existing focus on the formal sector is questionable. Innovators in the informal sector and the agency of the civil society, embedded in the local socio-cultural setting, but closely linked to transnational social spaces, often outperform the states' development efforts. Also, UNESCO cautioned that the effective use of AI would require appropriate skills, the legal framework and infrastructure. As in the past, the call for the pooling of resources, a pan-African strategy, was probably in vain. Possibly, AI will develop most rapidly in the already established African technology hubs of South Africa, Nigeria and Kenya. Yet, promising AI-focused activities also have been recognized in Ethiopia and Uganda. For AI to improve socio-economic inclusion in African settings, rather than undermine it, also gender equality, cultural and linguistic diversity and shifts in the labour markets would be required. Furthermore, ethical questions linked with a specific African identity have been raised. How far African perceptions of personhood and humanity would have to be considered in developing an African AI remains an open question. In short, AI could be a double-edged",
    "doi": "10.2139/ssrn.4163096",
    "url": "https://www.semanticscholar.org/paper/360be56f656f7aa4c13325966febbe888c401faf",
    "pdf_url": "https://mpra.ub.uni-muenchen.de/113799/1/MPRA_paper_113799.pdf",
    "venue": "Social Science Research Network",
    "citation_count": 13,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424558"
  },
  {
    "source": "semantic_scholar",
    "source_id": "788fa6d21adf3933693b9e5618e216beafe94a41",
    "title": "Artificial Intelligence and Sustainable Decisions",
    "authors": [
      "Jingchen Zhao",
      "Beatriz G\u00f3mez Fari\u00f1as"
    ],
    "year": 2022,
    "abstract": "When addressing corporate sustainability challenges, artificial intelligence (AI) is a double-edged sword. AI can make significant progress on the most complicated environmental and social problems faced by humans. On the other hand, the efficiencies and innovations generated by AI may also bring new risks, such as automated bias and conflicts with human ethics. We argue that companies and governments should make collective efforts to address sustainability challenges and risks brought by AI. Accountable and sustainable AI can be achieved through a proactive regulatory framework supported by rigorous corporate policies and reports. Given the rapidly evolving nature of this technology, we propose a harmonised and risk-based regulatory approach that accommodates diverse AI solutions to achieve the common good. Ensuring an adequate level of technological neutrality and proportionality of the regulation is the key to mitigating the wide range of potential risks inherent to the use of AI. Instead of promoting sustainability, unregulated AI would be a threat since it would not be possible to effectively monitor its effects on the economy, society and environment. Such a suitable regulatory framework would not only create a consensus concerning the risks to avoid and how to do so but also include enforcement mechanisms to ensure a trustworthy and ethical use of AI in the boardroom. Once this objective is achieved, it will be possible to refer to this technological development as a common good in itself that constitutes an essential asset to human development.",
    "doi": "10.1007/s40804-022-00262-2",
    "url": "https://www.semanticscholar.org/paper/788fa6d21adf3933693b9e5618e216beafe94a41",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s40804-022-00262-2.pdf",
    "venue": "European Business Organization Law Review",
    "citation_count": 102,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424562"
  },
  {
    "source": "semantic_scholar",
    "source_id": "fee596406375592b29b2f051910e8247ea501c01",
    "title": "Introduction to The Special Section on Bias and Fairness in AI",
    "authors": [
      "T. Calders",
      "Eirini Ntoutsi",
      "Mykola Pechenizkiy",
      "B. Rosenhahn",
      "S. Ruggieri"
    ],
    "year": 2021,
    "abstract": "Fairness in Artificial Intelligence rightfully receives a lot of attention these days. Many life-impacting decisions are being partially automated, including health-care resource planning decisions, insurance and credit risk predictions, recidivism predictions, etc. Much of work appearing on this topic within the Data Mining, Machine Learning and Artificial Intelligence community is focused on technological aspects. Nevertheless, fairness is much wider than this as it lies at the intersection of philosophy, ethics, legislation, and practical perspectives. Therefore, to fill this gap and bring together scholars of these disciplines working on fairness, the first workshop on Bias and Fairness in AI was held online on September 18, 2020 at the ECML-PKDD 2020 conference. This special section includes six articles presenting different perspectives on bias and fairness from different angles.",
    "doi": "10.1145/3468507.3468509",
    "url": "https://www.semanticscholar.org/paper/fee596406375592b29b2f051910e8247ea501c01",
    "pdf_url": "https://repository.uantwerpen.be/docstore/d:irua:7358",
    "venue": "SIGKDD Explorations",
    "citation_count": 8,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424566"
  },
  {
    "source": "semantic_scholar",
    "source_id": "304e37f652c5ac7df3c2b45b2dc1e6d863cb3c0b",
    "title": "The Ethics of Artificial Intelligence: Sociopolitical and Legal Dimensions",
    "authors": [
      "Jingjing Wang",
      "Wenji Mao",
      "Wenjie Wenjie"
    ],
    "year": 2023,
    "abstract": "This study aims to explore the ethical dimensions of artificial intelligence (AI), focusing on its sociopolitical and legal implications. It seeks to identify and analyze the primary ethical concerns that arise from the development and deployment of AI technologies, with an emphasis on understanding how these concerns impact society and the legal frameworks that govern AI. Employing a qualitative research design, this study conducted semi-structured interviews with 22 participants from diverse professional backgrounds, including technology ethicists, legal scholars, AI developers, policymakers, and advocacy group representatives. The data collection aimed for theoretical saturation, with the interviews designed to uncover a broad range of perspectives on AI ethics. Thematic analysis was used to identify and categorize the main themes and sub-themes related to the ethical implications of AI. The analysis revealed two main themes: Sociopolitical Dimension and Legal Dimension. The Sociopolitical Dimension includes categories such as Privacy and Data Governance, Bias and Discrimination, AI and Employment, Digital Divide, and AI in Governance. The Legal Dimension encompasses Intellectual Property Rights, Liability and Accountability, Regulatory Frameworks, AI Ethics and Law Integration, and Human Rights and AI. Each category was further explored through specific concepts, highlighting the complexities and challenges inherent in the ethical considerations of AI technologies. The study underscores the intricate relationship between AI technologies and ethical considerations, emphasizing the necessity for comprehensive, multidisciplinary approaches to address the identified sociopolitical and legal challenges. It advocates for the development of inclusive, equitable, and responsive frameworks that not only mitigate risks but also promote the beneficial potential of AI, ensuring that technological advancements align with societal values and legal norms.",
    "doi": "10.61838/kman.isslp.2.2.6",
    "url": "https://www.semanticscholar.org/paper/304e37f652c5ac7df3c2b45b2dc1e6d863cb3c0b",
    "pdf_url": "https://journalisslp.com/index.php/isslp/article/download/27/24",
    "venue": "Interdisciplinary Studies in Society, Law, and Politics",
    "citation_count": 5,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424570"
  },
  {
    "source": "semantic_scholar",
    "source_id": "810730691b1bcfefbf7fe3b93c6d3e19a3448671",
    "title": "The Use of Responsible Artificial Intelligence Techniques in the Context of Loan Approval Processes",
    "authors": [
      "Erasmo Purificato",
      "F. Lorenzo",
      "Francesca Fallucchi",
      "Ernesto William De Luca"
    ],
    "year": 2022,
    "abstract": "Abstract Despite the existing skepticism about the use of automatic systems in contexts where human knowledge and experience are considered indispensable (e.g., the granting of a mortgage, the prediction of stock prices, or the detection of cancers), our work aims to show how the use of explainability and fairness techniques can lead to the growth of a domain expert\u2019s trust and reliance on an artificial intelligence (AI) system. This article presents a system, applied to the context of loan approval processes, focusing on the two aforementioned ethical principles out of the four defined by the High-Level Expert Group on AI in the document \u201cEthics Guidelines for Trustworthy AI,\u201d published in April 2019, in which the key requirements that AI systems should meet to be considered trustworthy are identified. The presented case study is realized within a proprietary framework composed of several components for supporting the user throughout the management of the whole life cycle of a machine learning model. The main approaches, consisting of providing an interpretation of the model\u2019s outputs and monitoring the model\u2019s decisions to detect and react to unfair behaviors, are described in more detail to compare our system within state-of-the-art related frameworks. Finally, a novel Trust & Reliance Scale is proposed for evaluating the system, and a usability test is performed to measure the user satisfaction with the effectiveness of the developed user interface; results are obtained, respectively, by the submission of the mentioned novel scale to bank domain experts and the usability questionnaire to a heterogeneous group composed of loan officers, data scientists, and researchers.",
    "doi": "10.1080/10447318.2022.2081284",
    "url": "https://www.semanticscholar.org/paper/810730691b1bcfefbf7fe3b93c6d3e19a3448671",
    "pdf_url": "",
    "venue": "International journal of human computer interactions",
    "citation_count": 52,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424574"
  },
  {
    "source": "semantic_scholar",
    "source_id": "71c02376b4aee7ae2b29da937742d95683fc8710",
    "title": "Benefits of using artificial intelligence in core HR processes",
    "authors": [
      "Iryna Vats",
      "O. Kyrylenko",
      "Valentyna Novak"
    ],
    "year": 2024,
    "abstract": "The paper examines the use of artificial intelligence (AI) in the main processes of human resource management. It is noted that in modern conditions, AI is considered an advanced tool that can optimize management processes in various sectors of the economy. The author discusses the new opportunities that AI opens up in human resource management, increasing the efficiency of actions at all levels and complementing human abilities. The main part of the paper is devoted to the advantages and potential opportunities of using AI at different stages of the employee's life cycle in a company. In particular, the author emphasizes the optimization of recruitment through analytical processing of large amounts of information rather than subjective judgment. The paper highlights such areas as operational efficiency, recruitment, onboarding, talent management, strategic planning, career development, and management changes where AI can make a significant contribution. The paper also highlights the issues related to the potential dangers of introducing AI technologies. The level of readiness and the degree of involvement of managers in the latest technologies in human resource management is indicated. The paper raises the issue of efficiency and solving various problems. In addition, examples of real software products are provided. The conclusions emphasize the general perspective of using AI in HR processes and identify areas for further research. In particular, there is a call for the development of mechanisms to protect employees from possible misuse of AI and the development of effective strategies for the implementation of technologies that would take into account ethical aspects. The final part of the paper sets the task for the business community and legislative bodies to actively work on standards for the use of AI in HR to create fair and effective HR management.",
    "doi": "10.37634/efp.2024.3.1",
    "url": "https://www.semanticscholar.org/paper/71c02376b4aee7ae2b29da937742d95683fc8710",
    "pdf_url": "https://doi.org/10.37634/efp.2024.3.1",
    "venue": "Economics. Finances. Law",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424578"
  },
  {
    "source": "semantic_scholar",
    "source_id": "8540e1664d017c4b6a46ca4064908e37f04f02bb",
    "title": "Bias and Fairness in AI-Based Employee Attrition Prediction Using Random Forest",
    "authors": [
      "Idowu Adesoji Oladipupo",
      "S. Folorunso",
      "Sadiq Olusegun Balogun",
      "Fatima Iganya Suleiman",
      "O. Olayemi",
      "Joseph Maugbe Jacob"
    ],
    "year": 2026,
    "abstract": "Artificial intelligence is increasingly employed to predict employee attrition, enabling organisations to improve talent retention and workforce planning. However, without explicit consideration of fairness, these models risk embedding and amplifying societal biases. This study examines bias in AI-based attrition prediction using a Random Forest classifier applied to the IBM HR Analytics employee attrition dataset. Although the model demonstrates high predictive performance (92.3 percent) and an area under the curve of 0.97, subgroup analysis reveals disparities in prediction performance across gender. Fairness assessments based on equal accuracy, demographic parity, and equality of opportunity show that predictions for female employees achieve higher precision and recall than those for male employees, suggesting differential predictive performance across gender groups. The findings highlight organisational risks associated with such disparities, including the risk of unjust decision-making, reduced employee trust, and hindered diversity and inclusion efforts. To mitigate these challenges, the study recommends fairness-aware strategies such as balanced sampling, established fairness metrics, post-processing approaches (e.g., equalised odds), and continuous model auditing. This research underscores the ethical importance of aligning AI systems in human resource management with principles of equity, transparency, and accountability.",
    "doi": "10.64389/icds.2026.02162",
    "url": "https://www.semanticscholar.org/paper/8540e1664d017c4b6a46ca4064908e37f04f02bb",
    "pdf_url": "",
    "venue": "Innovation in Computer and Data Sciences",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424582"
  },
  {
    "source": "semantic_scholar",
    "source_id": "0e4589a51731a7698e6300f2c8f477bf9bd80ad3",
    "title": "Moral consideration of nonhumans in the ethics of artificial intelligence",
    "authors": [
      "A. Owe",
      "S. Baum"
    ],
    "year": 2021,
    "abstract": null,
    "doi": "10.1007/s43681-021-00065-0",
    "url": "https://www.semanticscholar.org/paper/0e4589a51731a7698e6300f2c8f477bf9bd80ad3",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s43681-021-00065-0.pdf",
    "venue": "AI and Ethics",
    "citation_count": 56,
    "fields_of_study": [
      "Sociology",
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424587"
  },
  {
    "source": "semantic_scholar",
    "source_id": "660b94b3ee837a8898a307364a6ca29b23193e9e",
    "title": "Generative Artificial Intelligence and the Impact on Sustainability",
    "authors": [
      "Niklas Humble",
      "Peter Mozelius"
    ],
    "year": 2024,
    "abstract": "An increasingly popular subcategory of Artificial Intelligence (AI) is Generative AI (GAI), which encompasses technologies capable of creating new content, such as images, text, and music, often resembling outputs made by humans. The potential impact by GAI on sustainability is multifaceted. On the positive side, generative AI can aid in optimizing processes, developing innovative solutions, and identifying patterns in large datasets related to sustainability. This can lead to more efficient resource management, reduced energy consumption, and the creation of more sustainable products. However, there are also potential negative impacts, such as increased energy consumption associated with training and running generative AI models, as well as the potential for unintended consequences or biases in the generated content. Additionally, overreliance on generative AI may lead to reduced human oversight, which could undermine holistic, interdisciplinary, and collaborative approaches to sustainability. The aim of this paper is to explore the potential impacts on sustainability by generative artificial intelligence through a review of prior research on the topic.\nThe study was conducted with a scoping literature review approach to identify potential impacts by generative AI on sustainability. Data were collected through a search in the database Scopus during the spring semester of 2024. Keywords, relevant for the study, were combined with Boolean operators. Papers identified through the search underwent a manual screening process by the authors, in which papers were selected for inclusion or exclusion in the study based on a set of criteria. Included paper were then analyzed with thematic analysis, according to the guidelines by Braun and Clarke. A categorization matrix, based in prior research on sustainability, supported the analysis and deductive coding of collected data.\u00a0Results of the study highlight generative AI\u2019s potential impact on sustainability that relate to both environmental aspects, economic aspects, and social aspects of sustainability. These different aspects of sustainability impact make this research an important contribution for deepening the understanding of generative AI and its potential consequences for society. Findings of the study provide theoretical contribution, implications for practice, and recommendations for future research on generative AI and sustainability.",
    "doi": "10.34190/icair.4.1.3024",
    "url": "https://www.semanticscholar.org/paper/660b94b3ee837a8898a307364a6ca29b23193e9e",
    "pdf_url": "https://papers.academic-conferences.org/index.php/icair/article/download/3024/2906",
    "venue": "International Conference on AI Research",
    "citation_count": 3,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424590"
  },
  {
    "source": "semantic_scholar",
    "source_id": "ce59430833ecd08d90df9aebb584c514a8853bc2",
    "title": "Artificial Intelligence & Ethics Beyond engineering at the dawn of decision-making machines",
    "authors": [
      "J. Shaw"
    ],
    "year": 2018,
    "abstract": null,
    "doi": null,
    "url": "https://www.semanticscholar.org/paper/ce59430833ecd08d90df9aebb584c514a8853bc2",
    "pdf_url": "",
    "venue": "",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424631"
  },
  {
    "source": "semantic_scholar",
    "source_id": "51468ede905d33700a4ff10cb6b1e6de7279e74c",
    "title": "Artificial intelligence in radiology: a narrative review of current methods, clinical impact, and future directions",
    "authors": [
      "Amy Avakian",
      "Garrett Barfoot"
    ],
    "year": 2026,
    "abstract": null,
    "doi": "10.1186/s44398-025-00020-7",
    "url": "https://www.semanticscholar.org/paper/51468ede905d33700a4ff10cb6b1e6de7279e74c",
    "pdf_url": "",
    "venue": "BMC Artificial Intelligence",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424638"
  },
  {
    "source": "semantic_scholar",
    "source_id": "b7bc57950b1dc5434dde6120a367c60ad15c6710",
    "title": "Artificial Intelligence (AI) in Revolutionizing Sustainable Recruitment: A Framework for Inclusivity and Efficiency",
    "authors": [
      "SM Masudur Rahman",
      "Md. Amzad Hossain",
      "Md. Shelim Miah",
      "Mahabub Alom",
      "Maruf Islam"
    ],
    "year": 2025,
    "abstract": "This study explores the potential of Artificial Intelligence (AI) technologies to advance sustainable recruitment, focusing on both environmental and social sustainability. AI-driven systems, including machine learning (ML) and natural language processing (NLP), offer significant improvements by automating tasks such as resume screening, candidate profiling, and interview scheduling. These technologies reduce resource consumption, eliminate the need for physical interviews and paperwork, and lower the carbon footprint of recruitment processes. Adopting a theoretical and conceptual analysis methodology, this research draws on a comprehensive review of AI applications in recruitment and sustainability frameworks. No primary data was collected; instead, the study utilizes secondary data from academic literature, industry reports, and expert insights. A conceptual framework is developed to illustrate how AI can be systematically integrated into recruitment processes to enhance sustainability, highlighting stages such as data collection, decision-making, and feedback loops to improve AI algorithms over time. The findings suggest that AI can contribute significantly to resource efficiency by digitizing recruitment processes and reducing environmental impacts like travel-related emissions. Moreover, AI enhances social sustainability by promoting diversity and inclusion in hiring, as automated systems reduce biases in candidate selection. Key strategies include adopting energy-efficient AI technologies, ensuring ethical use through algorithm audits, and leveraging feedback mechanisms to optimize AI performance. Policymakers are encouraged to develop regulations promoting transparency and accountability in AI use. Future research should explore AI\u2019s broader role in human resource management, ensuring its sustainability potential is fully realized.",
    "doi": "10.47857/irjms.2025.v06i01.02698",
    "url": "https://www.semanticscholar.org/paper/b7bc57950b1dc5434dde6120a367c60ad15c6710",
    "pdf_url": "",
    "venue": "International Research Journal of Multidisciplinary Scope",
    "citation_count": 9,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424644"
  },
  {
    "source": "semantic_scholar",
    "source_id": "05579a5181496cae4b0772cd044392044f81ee47",
    "title": "Exposing implicit biases and stereotypes in human and artificial intelligence: state of the art and challenges with a focus on gender",
    "authors": [
      "Ludovica Marinucci",
      "C. Mazzuca",
      "Aldo Gangemi"
    ],
    "year": 2022,
    "abstract": "Biases in cognition are ubiquitous. Social psychologists suggested biases and stereotypes serve a multifarious set of cognitive goals, while at the same time stressing their potential harmfulness. Recently, biases and stereotypes became the purview of heated debates in the machine learning community too. Researchers and developers are becoming increasingly aware of the fact that some biases, like gender and race biases, are entrenched in the algorithms some AI applications rely upon. Here, taking into account several existing approaches that address the problem of implicit biases and stereotypes, we propose that a strategy to cope with this phenomenon is to unmask those found in AI systems by understanding their cognitive dimension, rather than simply trying to correct algorithms. To this extent, we present a discussion bridging together findings from cognitive science and insights from machine learning that can be integrated in a state-of-the-art semantic network. Remarkably, this resource can be of assistance to scholars (e.g., cognitive and computer scientists) while at the same time contributing to refine AI regulations affecting social life. We show how only through a thorough understanding of the cognitive processes leading to biases, and through an interdisciplinary effort, we can make the best of AI technology.",
    "doi": "10.1007/s00146-022-01474-3",
    "url": "https://www.semanticscholar.org/paper/05579a5181496cae4b0772cd044392044f81ee47",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s00146-022-01474-3.pdf",
    "venue": "Ai & Society",
    "citation_count": 49,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424656"
  },
  {
    "source": "semantic_scholar",
    "source_id": "84870e2c569a603c9b3cb0566cbc23b43df4a5bf",
    "title": "A practical guide for nephrologist peer reviewers: evaluating artificial intelligence and machine learning research in nephrology",
    "authors": [
      "Yanni Wang",
      "W. Cheungpasitporn",
      "Hatem Ali",
      "Jianbo Qing",
      "C. Thongprayoon",
      "W. Kaewput",
      "K. Soliman",
      "Zhengxing Huang",
      "Min Yang",
      "Zhongheng Zhang"
    ],
    "year": 2025,
    "abstract": "Abstract Artificial intelligence (AI) and machine learning (ML) are transforming nephrology by enhancing diagnosis, risk prediction, and treatment optimization for conditions such as acute kidney injury (AKI) and chronic kidney disease (CKD). AI-driven models utilize diverse datasets\u2014including electronic health records, imaging, and biomarkers\u2014to improve clinical decision-making. Applications such as convolutional neural networks for kidney biopsy interpretation, and predictive modeling for renal replacement therapies underscore AI\u2019s potential. Nonetheless, challenges including data quality, limited external validation, algorithmic bias, and poor interpretability constrain the clinical reliability of AI/ML models. To address these issues, this article offers a structured framework for nephrologist peer reviewers, integrating the TRIPOD-AI (Transparent Reporting of a Multivariable Prediction Model for Individual Prognosis or Diagnosis\u2013AI Extension) checklist. Key evaluation criteria include dataset integrity, feature selection, model validation, reporting transparency, ethics, and real-world applicability. This framework promotes rigorous peer review and enhances the reproducibility, clinical relevance, and fairness of AI research in nephrology. Moreover, AI/ML studies must confront biases\u2014data, selection, and algorithmic\u2014that adversely affect model performance. Mitigation strategies such as data diversification, multi-center validation, and fairness-aware algorithms are essential. Overfitting in AI is driven by small patient cohorts faced with thousands of candidate features; our framework spotlights this imbalance and offers concrete remedies. Future directions in AI-driven nephrology include multimodal data fusion for improved predictive modeling, deep learning for automated imaging analysis, wearable-based monitoring, and clinical decision support systems (CDSS) that integrate comprehensive patient data. A visual summary of key manuscript sections is included.",
    "doi": "10.1080/0886022X.2025.2513002",
    "url": "https://www.semanticscholar.org/paper/84870e2c569a603c9b3cb0566cbc23b43df4a5bf",
    "pdf_url": "",
    "venue": "Renal Failure",
    "citation_count": 6,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424663"
  },
  {
    "source": "semantic_scholar",
    "source_id": "e4db1b35d721681358aaf084474138771492569d",
    "title": "Human-AI Interaction in Human Resource Management: Understanding Why Employees Resist Algorithmic Evaluation at Workplaces and How to Mitigate Burdens",
    "authors": [
      "Hyanghee Park",
      "Daehwan Ahn",
      "K. Hosanagar",
      "Joonhwan Lee"
    ],
    "year": 2021,
    "abstract": "Recently, Artificial Intelligence (AI) has been used to enable efficient decision-making in managerial and organizational contexts, ranging from employment to dismissal. However, to avoid employees\u2019 antipathy toward AI, it is important to understand what aspects of AI employees like and/or dislike. In this paper, we aim to identify how employees perceive current human resource (HR) teams and future algorithmic management. Specifically, we explored what factors negatively influence employees\u2019 perceptions of AI making work performance evaluations. Through in-depth interviews with 21 workers, we found that 1) employees feel six types of burdens (i.e., emotional, mental, bias, manipulation, privacy, and social) toward AI's introduction to human resource management (HRM), and that 2) these burdens could be mitigated by incorporating transparency, interpretability, and human intervention to algorithmic decision-making. Based on our findings, we present design efforts to alleviate employees\u2019 burdens. To leverage AI for HRM in fair and trustworthy ways, we call for the HCI community to design human-AI collaboration systems with various HR stakeholders.",
    "doi": "10.1145/3411764.3445304",
    "url": "https://www.semanticscholar.org/paper/e4db1b35d721681358aaf084474138771492569d",
    "pdf_url": "",
    "venue": "International Conference on Human Factors in Computing Systems",
    "citation_count": 101,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424667"
  },
  {
    "source": "semantic_scholar",
    "source_id": "597f3c3cb1bebfc9043ff0fc002c01d695e69cd9",
    "title": "Creative data justice: a decolonial and indigenous framework to assess creativity and artificial intelligence",
    "authors": [
      "Payal Arora"
    ],
    "year": 2024,
    "abstract": "ABSTRACT In the last decade, the Global South has emerged as a significant player in the data economy due to their majority user base, and studying its role is crucial to comprehend the future of AI. As societies grapple with the implications of AI on creative life, there is an opportunity to reevaluate the creative contributions of Global South cultures, ensuring they are acknowledged and foregrounded in the evolving landscape of human and machine creativity. This paper calls for reimagining and restructuring creative value with the emergence of AI enabled technologies by broadening who and what counts as creative in this data-driven era. To democratize creativity, a decolonial and indigenous framework of cross-cultural creative value is needed which critically intersects and examines the relations between creative labor, rights, and learning. The study of the Global South\u2019s data economies is important not only to harness its potential but also to address the cross-cultural ethics of building Creative AI tools with data from their underrepresented communities. At its core, the creative data justice framework emphasizes the need to challenge the existing power imbalances in global data governance. This paper proposes that fair creative value can be achieved by drawing inspiration from indigenous systems of care as a counterforce to neoliberal values of efficiency and utility. This framework will help scholars, policymakers and designers in their inclusive approaches to creativity in the age of AI.",
    "doi": "10.1080/1369118X.2024.2420041",
    "url": "https://www.semanticscholar.org/paper/597f3c3cb1bebfc9043ff0fc002c01d695e69cd9",
    "pdf_url": "https://doi.org/10.1080/1369118x.2024.2420041",
    "venue": "Information, Communication &amp; Society",
    "citation_count": 11,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424671"
  },
  {
    "source": "semantic_scholar",
    "source_id": "1013a3e5b2352d2cbe9d8c6291c6406ac504d8e7",
    "title": "How artificial intelligence will change the future of marketing",
    "authors": [
      "T. Davenport",
      "Abhijit Guha",
      "Dhruv Grewal",
      "Timna Bre\u00dfgott"
    ],
    "year": 2019,
    "abstract": "In the future, artificial intelligence (AI) is likely to substantially change both marketing strategies and customer behaviors. Building from not only extant research but also extensive interactions with practice, the authors propose a multidimensional framework for understanding the impact of AI involving intelligence levels, task types, and whether AI is embedded in a robot. Prior research typically addresses a subset of these dimensions; this paper integrates all three into a single framework. Next, the authors propose a research agenda that addresses not only how marketing strategies and customer behaviors will change in the future, but also highlights important policy questions relating to privacy, bias and ethics. Finally, the authors suggest AI will be more effective if it augments (rather than replaces) human managers.",
    "doi": "10.1007/s11747-019-00696-0",
    "url": "https://www.semanticscholar.org/paper/1013a3e5b2352d2cbe9d8c6291c6406ac504d8e7",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s11747-019-00696-0.pdf",
    "venue": "Journal of the Academy of Marketing Science",
    "citation_count": 1551,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424676"
  },
  {
    "source": "semantic_scholar",
    "source_id": "b24d47d2319b0a143280dbc1edaf143f48720f0b",
    "title": "Artificial Intelligence in Psychiatric Inpatient Care: Advancing Diagnostics, Personalized Treatment, and Ethical Integration",
    "authors": [
      "Khadija Jahan Mukta",
      "Md Anamul Islam"
    ],
    "year": 2025,
    "abstract": "Artificial intelligence (AI) is transforming mental inpatient care by improving diagnostic precision, facilitating individualized therapy, and optimizing hospital operations. This scoping review aggregated findings from 24 empirical studies published between 2015 and 2025 to assess the application of AI technologies\u2014such as machine learning, natural language processing, deep learning, digital phenotyping, and conversational agents\u2014in inpatient psychiatric environments. Findings demonstrate that AI enhances the early identification of relapse and suicide risk, facilitates personalized therapy via decision-support systems and chatbots, and bolsters patient monitoring using sensor-based technology. AI enhances operational efficiency by optimizing bed allocation, personnel scheduling, and clinical documentation, hence alleviating administrative burdens. Nonetheless, considerable obstacles persist, including algorithmic bias, privacy issues, clinical opposition, and legal uncertainty. This study offers the Three-Pillar Model for Responsible AI Integration, highlighting therapeutic augmentation, ethical safeguards, and operational governance as fundamental concepts. The analysis highlights the dual nature of AI in psychiatry: its revolutionary promise alongside ethical and implementation challenges. Future investigations should prioritize longitudinal validation, resource-constrained environments, interpretability, and the creation of inclusive datasets. By incorporating transparency, fairness, and human-centered design, AI can enhance mental inpatient treatment to be technologically advanced, equitable, trustworthy, and compassionate.",
    "doi": "10.32996/jpbs.2025.5.3.1",
    "url": "https://www.semanticscholar.org/paper/b24d47d2319b0a143280dbc1edaf143f48720f0b",
    "pdf_url": "",
    "venue": "Journal of psychology & behavioral studies",
    "citation_count": 3,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424693"
  },
  {
    "source": "semantic_scholar",
    "source_id": "966868f68ed4e66cc0c6a2a65a32ddda5065c7bb",
    "title": "Artificial Intelligence in Human Resources in the Era of Society 5.0",
    "authors": [
      "Khansa Islami",
      "Dan Sopiah"
    ],
    "year": 2022,
    "abstract": "Humans and robots must be able to cooperate and work together to complete their roles and activities in the age of Society 5.0, which is a challenge for scholars and professionals of HRM. The company\u2019s HR management operations, including the hiring process, interviews, coaching, advancement, salary, and staff effectiveness reviews, have widely used artificial intelligence (AI). Algorithm-based technology is thought to produce more productive and profitable outcomes, as well as reducing conventional biases. The purpose of this Systematic Literature Review (SLR) is to examine prior research on the application of artificial intelligence to human resource management (HRM), and examine the extent to which the use of artificial intelligence (AI) has affected businesses and employees.",
    "doi": "10.47772/ijriss.2022.61131",
    "url": "https://www.semanticscholar.org/paper/966868f68ed4e66cc0c6a2a65a32ddda5065c7bb",
    "pdf_url": "https://doi.org/10.47772/ijriss.2022.61131",
    "venue": "International journal of research and innovation in social science",
    "citation_count": 3,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424705"
  },
  {
    "source": "semantic_scholar",
    "source_id": "3080807300183fa33c4cc5399ecfc771ed53141e",
    "title": "Medical, dental, and nursing students\u2019 attitudes and knowledge towards artificial intelligence: a systematic review and meta-analysis",
    "authors": [
      "Hamidreza. Amiri",
      "Samira Peiravi",
      "Seyedeh sara rezazadeh shojaee",
      "Motahare Rouhparvarzamin",
      "Mohammad Naser Nateghi",
      "Mohammad Hossein Etemadi",
      "Mahdie ShojaeiBaghini",
      "Farhan Musaie",
      "Mohammad Hossein Anvari",
      "Mahsa Asadi Anar"
    ],
    "year": 2024,
    "abstract": "Nowadays, Artificial intelligence (AI) is one of the most popular topics that can be integrated into healthcare activities. Currently, AI is used in specialized fields such as radiology, pathology, and ophthalmology. Despite the advantages of AI, the fear of human labor being replaced by this technology makes some students reluctant to choose specific fields. This meta-analysis aims to investigate the knowledge and attitude of medical, dental, and nursing students and experts in this field about AI and its application. This study was designed based on PRISMA guidelines. PubMed, Scopus, and Google Scholar databases were searched with relevant keywords. After study selection according to inclusion criteria, data of knowledge and attitude were extracted for meta-analysis. Twenty-two studies included 8491 participants were included in this meta-analysis. The pooled analysis revealed a proportion of 0.44 (95%CI\u2009=\u2009[0.34, 0.54], P\u2009<\u20090.01, I2\u2009=\u200998.95%) for knowledge. Moreover, the proportion of attitude was 0.65 (95%CI\u2009=\u2009[0.55, 0.75], P\u2009<\u20090.01, I2\u2009=\u200999.47%). The studies did not show any publication bias with a symmetrical funnel plot. Average levels of knowledge indicate the necessity of including relevant educational programs in the student\u2019s academic curriculum. The positive attitude of students promises the acceptance of AI technology. However, dealing with ethics education in AI and the aspects of human-AI cooperation are discussed. Future longitudinal studies could follow students to provide more data to guide how AI can be incorporated into education.",
    "doi": "10.1186/s12909-024-05406-1",
    "url": "https://www.semanticscholar.org/paper/3080807300183fa33c4cc5399ecfc771ed53141e",
    "pdf_url": "https://bmcmededuc.biomedcentral.com/counter/pdf/10.1186/s12909-024-05406-1",
    "venue": "BMC Medical Education",
    "citation_count": 63,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424714"
  },
  {
    "source": "semantic_scholar",
    "source_id": "32c11fa96c469d936b67917d6bbc77ed8d6997ac",
    "title": "Incorporating the Concepts of Fairness and Bias into an Undergraduate Computer Science Course to Promote Fair Automated Decision Systems",
    "authors": [
      "Sheikh Rabiul Islam",
      "I. Russell",
      "W. Eberle",
      "D. Dicheva"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1145/3478432.3499043",
    "url": "https://www.semanticscholar.org/paper/32c11fa96c469d936b67917d6bbc77ed8d6997ac",
    "pdf_url": "",
    "venue": "Technical Symposium on Computer Science Education",
    "citation_count": 10,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424719"
  },
  {
    "source": "semantic_scholar",
    "source_id": "6f1d4761c4841be90b5274b26e92c235ff826b6a",
    "title": "Teaching with Artificial Intelligence in Architecture: Embedding Technical Skills and Ethical Reflection in a Core Design Studio",
    "authors": [
      "Jiaqi Wang",
      "Yu Shi",
      "Xiang Chen",
      "Yi Lan",
      "Shuying Liu"
    ],
    "year": 2025,
    "abstract": "This case study examines the integration of artificial intelligence (AI) into undergraduate architectural education through a 2024\u201325 core studio teaching experiment at Zhejiang University. A dual-module framework was implemented, comprising a 20 h AI skills training module and in-class ethics discussions, without altering the existing studio structure. The AI skills module introduced deep learning models, LLMs, AIGC image models, LoRA fine-tuning, and ComfyUI, supported by a dedicated technical instructor. Student feedback indicated phase-dependent and tool-sensitive engagement, and students expressed a preference for embedded ethical discussion within the design studio rather than separate formal instruction. The experiment demonstrated that modular AI education is both scalable and practical, highlighting the importance of phase-sensitive guidance, balanced technical and ethical framing, and institutional support such as cloud platforms and research-based AI tools. The integration enhanced students\u2019 digital adaptability and strategic thinking while prompting reflection on issues such as authorship, algorithmic bias, and accountability in human\u2013AI collaboration. These findings offer a replicable model for AI-integrated design pedagogy that balances technical training with critical awareness.",
    "doi": "10.3390/buildings15173069",
    "url": "https://www.semanticscholar.org/paper/6f1d4761c4841be90b5274b26e92c235ff826b6a",
    "pdf_url": "",
    "venue": "Buildings",
    "citation_count": 2,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424747"
  },
  {
    "source": "semantic_scholar",
    "source_id": "39d1f020a585d3f28cb4b4c14497649e6a469ef1",
    "title": "Artificial Intelligence (AI) Ethics: Ethics of AI and Ethical AI",
    "authors": [
      "K. Siau",
      "Weiyu Wang"
    ],
    "year": 2020,
    "abstract": "Artificial intelligence (AI)-based technology has achieved many great things, such as facial recognition, medical diagnosis, and self-driving cars. AI promises enormous benefits for economic growth, social development, as well as human well-being and safety improvement. However, the low-level of explainability, data biases, data security, data privacy, and ethical problems of AI-based technology pose significant risks for users, developers, humanity, and societies. As AI advances, one critical issue is how to address the ethical and moral challenges associated with AI. Even though the concept of \u201cmachine ethics\u201d was proposed around 2006, AI ethics is still in the infancy stage. AI ethics is the field related to the study of ethical issues in AI. To address AI ethics, one needs to consider the ethics of AI and how to build ethical AI. Ethics of AI studies the ethical principles, rules, guidelines, policies, and regulations that are related to AI. Ethical AI is an AI that performs and behaves ethically. One must recognize and understand the potential ethical and moral issues that may be caused by AI to formulate the necessary ethical principles, rules, guidelines, policies, and regulations for AI (i.e., Ethics of AI). With the appropriate ethics of AI, one can then build AI that exhibits ethical behavior (i.e., Ethical AI). This paper will discuss AI ethics by looking at the ethics of AI and ethical AI. What are the perceived ethical and moral issues with AI? What are the general and common ethical principles, rules, guidelines, policies, and regulations that can resolve or at least attenuate these ethical and moral issues with AI? What are some of the necessary features and characteristics of an ethical AI? How to adhere to the ethics of AI to build ethical AI?",
    "doi": "10.4018/jdm.2020040105",
    "url": "https://www.semanticscholar.org/paper/39d1f020a585d3f28cb4b4c14497649e6a469ef1",
    "pdf_url": "",
    "venue": "Journal of Database Management",
    "citation_count": 297,
    "fields_of_study": [
      "Psychology",
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424753"
  },
  {
    "source": "semantic_scholar",
    "source_id": "19940359f59ab2336780e5bd3b8e0cfa4da6f50f",
    "title": "Ethical Implication of Artificial Intelligence (AI) Adoption in Financial Decision Making",
    "authors": [
      "Omoshola S. Owolabi",
      "Prince C. Uche",
      "Nathaniel T. Adeniken",
      "Christopher Ihejirika",
      "Riyad Bin Islam",
      "Bishal Chhetri"
    ],
    "year": 2024,
    "abstract": "The integration of artificial intelligence (AI) into the financial sector has raised ethical concerns that need to be addressed. This paper analyzes the ethical implications of using AI in financial decision-making and emphasizes the importance of an ethical framework to ensure its fair and trustworthy deployment. The study explores various ethical considerations, including the need to address algorithmic bias, promote transparency and explainability in AI systems, and adhere to regulations that protect equity, accountability, and public trust. By synthesizing research and empirical evidence, the paper highlights the complex relationship between AI innovation and ethical integrity in finance. To tackle this issue, the paper proposes a comprehensive and actionable ethical framework that advocates for clear guidelines, governance structures, regular audits, and collaboration among stakeholders. This framework aims to maximize the potential of AI while minimizing negative impacts and unintended consequences. The study serves as a valuable resource for policymakers, industry professionals, researchers, and other stakeholders, facilitating informed discussions, evidence-based decision-making, and the development of best practices for responsible AI integration in the financial sector. The ultimate goal is to ensure fairness, transparency, and accountability while reaping the benefits of AI for both the financial sector and society.",
    "doi": "10.5539/cis.v17n1p49",
    "url": "https://www.semanticscholar.org/paper/19940359f59ab2336780e5bd3b8e0cfa4da6f50f",
    "pdf_url": "https://ccsenet.org/journal/index.php/cis/article/download/0/0/50148/54269",
    "venue": "Computer and Information Science",
    "citation_count": 25,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424758"
  },
  {
    "source": "semantic_scholar",
    "source_id": "a32baf8c6ba09f528fed3135514951331722a5fd",
    "title": "Artificial Intelligence in Farming: Challenges and opportunities for building trust",
    "authors": [
      "Maaz Gardezi",
      "Bhavna Joshi",
      "Donna M. Rizzo",
      "Mark Ryan",
      "Edward Prutzer",
      "Skye Brugler",
      "Ali Dadkhah"
    ],
    "year": 2023,
    "abstract": "Artificial intelligence (AI) represents technologies with human-like cognitive abilities to learn, perform, and make decisions. AI in precision agriculture (PA) enables farmers and farm managers to deploy highly targeted and precise farming practices based on site-specific agroclimatic field measurements. The foundational and applied development of AI has matured considerably over the last 30 years. The time is now right to engage seriously with the ethics and responsible practice of AI for the well-being of farmers and farm managers. In this paper, we identify and discuss both challenges and opportunities for improving farmers\u2019 trust in those providing AI solutions for PA. We highlight that farmers\u2019 trust can be moderated by how the benefits and risks of AI are perceived, shared, and distributed. We propose four recommendations for improving farmers\u2019 trust. First, AI developers should improve model transparency and explainability. Second, clear responsibility and accountability should be assigned to AI decisions. Third, concerns about the fairness of AI need to be overcome to improve human-machine partnerships in agriculture. Finally, regulation",
    "doi": "10.1002/agj2.21353",
    "url": "https://www.semanticscholar.org/paper/a32baf8c6ba09f528fed3135514951331722a5fd",
    "pdf_url": "https://doi.org/10.1002/agj2.21353",
    "venue": "Agronomy Journal",
    "citation_count": 63,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424773"
  },
  {
    "source": "semantic_scholar",
    "source_id": "3e3b2c41c916544fc06f332d9ae29341c02b9458",
    "title": "Toward Involving End-users in Interactive Human-in-the-loop AI Fairness",
    "authors": [
      "Yuri Nakao",
      "Simone Stumpf",
      "Subeida Ahmed",
      "A. Naseer",
      "Lorenzo Strappelli"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1145/3514258",
    "url": "https://www.semanticscholar.org/paper/3e3b2c41c916544fc06f332d9ae29341c02b9458",
    "pdf_url": "https://eprints.gla.ac.uk/269192/1/269192.pdf",
    "venue": "ACM Trans. Interact. Intell. Syst.",
    "citation_count": 37,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424778"
  },
  {
    "source": "semantic_scholar",
    "source_id": "1e7602967f5da0de3c7ea5592c24df90bc018994",
    "title": "A focused review of artificial intelligence in education: Evolution and challenges",
    "authors": [
      "Erkan Acar",
      "Youmna Deiri",
      "Fatih Yigit"
    ],
    "year": 2025,
    "abstract": "The given systematic analysis reviews 40 articles published in 2015-2025 to discuss the examine the evolution, applications, and challenges of artificial intelligence (AI) in education, specifically in the bi/multilingual learning settings. The review relies on empirical and theoretical study and provides identification of the three major domains, including personalized learning, intelligent tutoring systems and chatbots, and automated assessment. The research results demonstrate that AI improves student engagement and learning performance and teaching efficiency due to the adaptive feedback and real-time analytics, particularly when used to support multiliteracy language learning practices. There are, however, major issues of concern that data privacy, algorithmic bias, unequal access, and the disappearance of relational and cultural facets of teaching and learning. The review highlights the empathy gap in the AI tools and demands the incorporation of AI into the mainstream in an inclusive, ethically based and linguistically responsive manner. It promotes the change in automation to intelligence augmentation and places AI at the service of educators offloading them with fair, human-centered, and AI assistive tools in multilingual learning students in English-dominant settings. The implications refer to the imperative to provide strong governance structures, human centered training of teachers in which AI serves as an addition to intelligence and not intelligence, and inclusive design to provide equitable and effective AI integration and to provide a balanced innovation with a focus on human-centered learning.",
    "doi": "10.20897/jirais/17640",
    "url": "https://www.semanticscholar.org/paper/1e7602967f5da0de3c7ea5592c24df90bc018994",
    "pdf_url": "",
    "venue": "Journal of Interdisciplinary Research in Artificial Intelligence and Society",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424792"
  },
  {
    "source": "semantic_scholar",
    "source_id": "5ccc4284451d033c0a98986fc1544c1c0baa044d",
    "title": "Data and AI governance: Promoting equity, ethics, and fairness in large language models",
    "authors": [
      "Alok Abhishek",
      "Lisa Erickson",
      "Tushar Bandopadhyay"
    ],
    "year": 2025,
    "abstract": "In this paper, we cover approaches to systematically govern, assess and quantify bias across the complete life cycle of machine learning models, from initial development and validation to ongoing production monitoring and guardrail implementation. Building upon our foundational work on the Bias Evaluation and Assessment Test Suite (BEATS) for Large Language Models, the authors share prevalent bias and fairness related gaps in Large Language Models (LLMs) and discuss data and AI governance framework to address Bias, Ethics, Fairness, and Factuality within LLMs. The data and AI governance approach discussed in this paper is suitable for practical, real-world applications, enabling rigorous benchmarking of LLMs prior to production deployment, facilitating continuous real-time evaluation, and proactively governing LLM generated responses. By implementing the data and AI governance across the life cycle of AI development, organizations can significantly enhance the safety and responsibility of their GenAI systems, effectively mitigating risks of discrimination and protecting against potential reputational or brand-related harm. Ultimately, through this article, we aim to contribute to advancement of the creation and deployment of socially responsible and ethically aligned generative artificial intelligence powered applications.",
    "doi": "10.38105/spr.1sn574k4lp",
    "url": "https://www.semanticscholar.org/paper/5ccc4284451d033c0a98986fc1544c1c0baa044d",
    "pdf_url": "",
    "venue": "MIT Science Policy Review",
    "citation_count": 3,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424802"
  },
  {
    "source": "semantic_scholar",
    "source_id": "c3b8424b249bc46b97d1ebd49c441231f1ba0756",
    "title": "Reconceptualizing Gatekeeping in the Age of Artificial Intelligence: A Theoretical Exploration of Artificial Intelligence-Driven News Curation and Automated Journalism",
    "authors": [
      "D. Voinea"
    ],
    "year": 2025,
    "abstract": "Artificial intelligence (AI) is transforming how news is produced, curated, and consumed, challenging traditional gatekeeping theories rooted in human editorial control. We develop a robust theoretical framework to reconceptualize gatekeeping in the AI era. We integrate classic media theories\u2014gatekeeping, agenda-setting, and framing\u2014with contemporary insights from algorithmic news recommender systems, large language model (LLM)\u2013based news writing, and platform studies. Our review reveals that AI-driven content curation systems (e.g., social media feeds, news aggregators) increasingly mediate what news is visible, sometimes reinforcing mainstream agendas, according to Nechushtai & Lewis, while, at other times, introducing new biases or echo chambers. Simultaneously, automated news generation via LLMs raises questions about how training data and optimization goals (engagement vs. diversity) act as new \u201cgatekeepers\u201d in story selection and framing. We found pervasive Simon\u2019s theory that reliance on third-party AI platforms transfers authority from newsrooms, creating power dependencies that may undercut journalistic autonomy. Moreover, adaptive algorithms learn from user behavior, creating feedback loops that dynamically shape news diversity and bias over time. Drawing on communication studies, science & technology studies (STS), and AI ethics, we propose an updated theoretical framework of \u201calgorithmic gatekeeping\u201d that accounts for the hybrid human\u2013AI processes governing news flow. We outline key research gaps\u2014including opaque algorithmic decision-making and normative questions of accountability\u2014and suggest directions for future theory-building to ensure journalism\u2019s core values survive in the age of AI-driven news.",
    "doi": "10.3390/journalmedia6020068",
    "url": "https://www.semanticscholar.org/paper/c3b8424b249bc46b97d1ebd49c441231f1ba0756",
    "pdf_url": "https://doi.org/10.3390/journalmedia6020068",
    "venue": "Journalism and Media",
    "citation_count": 4,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424844"
  },
  {
    "source": "semantic_scholar",
    "source_id": "67bfc8d80a60b23bb1a8734df1b56c357a43ace0",
    "title": "Ethical Challenges in Data Science: Navigating the Complex Landscape of Responsibility and Fairness",
    "authors": [
      "Chiranjeevi Bura",
      "Srikanth Kamatala",
      "Praveen Kumar Myakala"
    ],
    "year": 2025,
    "abstract": "The rapid advancement of data science and artificial intelligence (AI) has revolutionized decision-making across multiple domains, including healthcare, finance, and law enforcement. However, these advancements come with pressing ethical challenges, such as algorithmic bias, data privacy risks, and lack of transparency. This paper systematically analyzes these ethical concerns, focusing on state-of-the-art methodologies for bias detection, explainable AI (XAI), and privacy-preserving techniques. We provide a comparative evaluation of ethical frameworks, including the ACM Code of Ethics, IEEE Ethically Aligned Design (EAD), and regulatory policies such as GDPR and CCPA. Through in-depth case studies examining biased hiring algorithms, risk assessment models in criminal justice, and data privacy concerns in smart technologies\u2014we highlight real-world implications of unethical AI. Furthermore, we propose a structured approach to bias mitigation, integrating fairness-aware machine learning, adversarial debiasing, and regulatory compliance measures. Our findings contribute to responsible AI governance by identifying best practices and technical solutions that promote fairness, accountability, and transparency in AI-driven systems.",
    "doi": "10.47191/ijcsrr/v8-i3-09",
    "url": "https://www.semanticscholar.org/paper/67bfc8d80a60b23bb1a8734df1b56c357a43ace0",
    "pdf_url": "",
    "venue": "International Journal of Current Science Research and Review",
    "citation_count": 3,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424850"
  },
  {
    "source": "semantic_scholar",
    "source_id": "f890916fd3f399dfdeb67ba8efc4b9a71e8029d0",
    "title": "The Algorithmic Hand: Investigating the Impact of Artificial Intelligence on Service Delivery, Customer Interactions, And Efficiency",
    "authors": [
      "Simon Suwanzy Dzreke",
      "Semefa Elikplim Dzreke"
    ],
    "year": 2025,
    "abstract": "Abstract: The study looks closely at the complicated, game-changing, and sometimes contradictory effects of Artificial Intelligence (AI) on modern service delivery. It looks at how AI changes the way businesses work, how customers interact with each other, and the moral limits of service ecosystems. Using a mixed-methods approach with multiple phases (interviews, experiments, case studies, and surveys), the results show that AI systems make tasks much more efficient, cutting transaction costs by up to 30% and response times by up to 40%. The paper makes the service quality seem better for standard tasks through calibrated anthropomorphic design (\u03b2=0.38, p<.001). But this \"algorithmic hand\" also causes serious social and emotional problems in complicated situations. Without real empathy and the ability to adapt to different situations, customers get frustrated and blame the company for AI failures; 82% of them blame the company for not being careful enough, which hurts trust more than anything else. The study shows that contingency factors\u2014task complexity, customer demographics, interface transparency, and agent skill polarization\u2014are important because they affect how well AI works. This leads to ethical issues like measurable algorithmic bias (0.75 SD lower satisfaction among elderly users; p < .01), growing privacy concerns, and widespread gaps in governance. We propose a new, multi-theoretical framework that integrates TAM, Social Presence Theory, and Attribution Theory. This framework explains how customers think and gives practical advice for hybrid human-AI systems. For professionals, its use means getting evidence-based advice on how to improve anthropomorphism, recover from failure, and reduce bias. It calls for regulatory frameworks that put fairness and human dignity at the top of the list. In the end, this work changes the definition of service innovation by saying that AI's real value is not in being able to work on its own, but in being ethically governed and sensitive to the situation. It also calls for more research into the new problems that generative AI is causing, with human flourishing as the main measure of progress.",
    "doi": "10.51583/ijltemas.2025.140600092",
    "url": "https://www.semanticscholar.org/paper/f890916fd3f399dfdeb67ba8efc4b9a71e8029d0",
    "pdf_url": "",
    "venue": "International Journal of Latest Technology in Engineering Management &amp; Applied Science",
    "citation_count": 10,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424854"
  },
  {
    "source": "semantic_scholar",
    "source_id": "1c79833e6442f627f7d136462fd1d036f75c5886",
    "title": "Artificial Intelligence and Deep Learning in Healthcare, Cyber security, and Food Systems: A Comprehensive Review of Applications, Challenges, and Future Directions",
    "authors": [
      "Ali Husnain"
    ],
    "year": 2025,
    "abstract": "The implementation of Artificial Intelligence in healthcare alongside cyber security and food systems produces enhanced efficiency and security functions together with automated processes. Healthcare organizations use AI-powered diagnostic instruments together with predictive data tools and individualized medical approaches to enhance therapeutic results while shortening drug development cycles. AI applications need proper solution to algorithmic biases while protecting data privacy and respecting ethical values for the sake of transparent and fair implementation. Security frameworks which are resilient to emerging exploitative AI techniques together with human oversight have become essential because AI-powered threat detection and automated responses enhance cyber security defenses against cyber-attacks. The upcoming stage of AI advancement will concentrate on three main areas which combine explain ability, trustworthy systems and knowledge transfer between different sectors. Global healthcare advancement along with improved cyber security protection and enhanced food system management are possible through interdisciplinary AI techniques and appropriate challenge management which ensures transparency, security and sustainable practices.",
    "doi": "10.70445/gjeac.1.2.2025.95-126",
    "url": "https://www.semanticscholar.org/paper/1c79833e6442f627f7d136462fd1d036f75c5886",
    "pdf_url": "",
    "venue": "Global Journal of Emerging AI and Computing",
    "citation_count": 2,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424858"
  },
  {
    "source": "semantic_scholar",
    "source_id": "d9c064ceac6f5f9fadc1a7f38ee96ad0faf6abbe",
    "title": "LEGAL CHALLENGES OF ARTIFICIAL INTELLIGENCE AND ROBOTICS: A COMPREHENSIVE REVIEW",
    "authors": [
      "Chidiogo Uzoamaka Akpuokwe",
      "Adekunle Oyeyemi Adeniyi",
      "Seun Solomon Bakare",
      "Nkechi Emmanuella Eneh"
    ],
    "year": 2024,
    "abstract": "The paper presents an insightful overview of the intricate legal challenges posed by the proliferation of Artificial Intelligence (AI) and Robotics. This comprehensive review explores the multifaceted dimensions of the evolving legal landscape, addressing issues at the intersection of technology and law. Key focal points include the accountability and liability frameworks for autonomous AI systems, ethical considerations in the deployment of intelligent machines, and the complex dynamics of data privacy in the age of pervasive automation. The review delves into the intricate legal nuances surrounding intellectual property rights, particularly as AI systems contribute to creative outputs and innovation. It navigates the blurred lines between human and machine authorship, raising fundamental questions about ownership and protection in this digital era. Moreover, the paper emphasizes the global nature of these challenges, highlighting the imperative for international cooperation to formulate harmonized legal standards. As AI and robotics revolutionize industries and societal frameworks, the analysis underscores the critical need for adaptive and anticipatory legal frameworks. It explores how existing legal paradigms are grappling with the unprecedented speed of technological advancements and the ethical dilemmas arising from the delegation of decision-making to intelligent algorithms. The paper sets the stage for a thorough examination of the legal intricacies surrounding AI and robotics. It advocates for a proactive and collaborative approach, involving legal experts, technologists, ethicists, and policymakers in crafting robust frameworks that balance innovation with ethical, privacy, and accountability considerations. This review serves as a foundational resource for understanding and addressing the legal challenges inherent in the transformative era of Artificial Intelligence and Robotics. \nKeywords: Artificial intelligence, Robotics, Legal, AI challenges, Ethics, Review.",
    "doi": "10.51594/csitrj.v5i3.860",
    "url": "https://www.semanticscholar.org/paper/d9c064ceac6f5f9fadc1a7f38ee96ad0faf6abbe",
    "pdf_url": "https://fepbl.com/index.php/csitrj/article/download/860/1061",
    "venue": "Computer Science &amp; IT Research Journal",
    "citation_count": 27,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424862"
  },
  {
    "source": "semantic_scholar",
    "source_id": "c81ba0ca7553f1e1c80437ebd8b34dd6ee55adf7",
    "title": "Using Artificial Intelligence for High-Volume Identification of Silicosis and Tuberculosis: A Bio-Ethics Approach",
    "authors": [
      "J. Spiegel",
      "R. Ehrlich",
      "A. Yassi",
      "F. Riera",
      "James Wilkinson",
      "K. Lockhart",
      "S. Barker",
      "B. Kistnasamy"
    ],
    "year": 2021,
    "abstract": "Although Artificial Intelligence (AI) is being increasingly applied, considerable distrust about introducing \u201cdisruptive\u201d technologies persists. Intrinsic and contextual factors influencing where and how such innovations are introduced therefore require careful scrutiny to ensure that health equity is promoted. To illustrate one such critical approach, we describe and appraise an AI application \u2013 the development of computer assisted diagnosis (CAD) to support more efficient adjudication of compensation claims from former gold miners with occupational lung disease in Southern Africa. In doing so, we apply a bio-ethical lens that considers the principles of beneficence, non-maleficence, autonomy and justice and add explicability as a core principle. We draw on the AI literature, our research on CAD validation and process efficiency, as well as apprehensions of users and stakeholders. Issues of concern included AI accuracy, biased training of AI systems, data privacy, impact on human skill development, transparency and accountability in AI use, as well as intellectual property ownership. We discuss ways in which each of these potential obstacles to successful use of CAD could be mitigated. We conclude that efforts to overcoming technical challenges in applying AI must be accompanied from the onset by attention to ensuring its ethical use.",
    "doi": "10.5334/aogh.3206",
    "url": "https://www.semanticscholar.org/paper/c81ba0ca7553f1e1c80437ebd8b34dd6ee55adf7",
    "pdf_url": "https://doi.org/10.5334/aogh.3206",
    "venue": "Annals of Global Health",
    "citation_count": 15,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424867"
  },
  {
    "source": "semantic_scholar",
    "source_id": "8eeacfa9fbf8ff903441f359411cb073921ebbd0",
    "title": "Cognitive Bias in AI Recommendations: Understanding and Mitigating Human-AI Decision-Making Errors",
    "authors": [
      "Prasasti Aich"
    ],
    "year": 2025,
    "abstract": "Artificial Intelligence (AI) systems increasingly influence human decision-making, from search engine suggestions to hiring recommendations. However, these systems often reinforce cognitive biases, leading to skewed perceptions and decision errors. This workshop will examine the intersection of cognitive biases and AI-generated recommendations, providing UX researchers, designers, and HCI practitioners with strategies to design transparent, fair, and bias-aware AI systems. Additionally, it will include people who use AI in their daily lives to help them realize the impact AI has on their choices. Through interactive discussions, usability studies, and real-world case analyses, participants will explore methods to identify and mitigate cognitive biases in AI recommendations. The workshop aims to foster collaboration and generate insights for a forthcoming publication on bias-aware AI design.",
    "doi": "10.1145/3765766.3765887",
    "url": "https://www.semanticscholar.org/paper/8eeacfa9fbf8ff903441f359411cb073921ebbd0",
    "pdf_url": "",
    "venue": "International Conference on Human-Agent Interaction",
    "citation_count": 1,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424871"
  },
  {
    "source": "semantic_scholar",
    "source_id": "d417065c6b62f57248166c2272cab7ea9191c153",
    "title": "Exploring the Role of Artificial Intelligence in Mental Healthcare: Progress, Pitfalls, and Promises",
    "authors": [
      "Gemma Espejo",
      "Wade Reiner",
      "Michael Wenzinger"
    ],
    "year": 2023,
    "abstract": "The rise of artificial intelligence (AI) heralds a significant revolution in healthcare, particularly in mental health. AI's potential spans diagnostic algorithms, data analysis from diverse sources, and real-time patient monitoring. It is essential for clinicians to remain informed about AI's progress and limitations. The inherent complexity of mental disorders, limited objective data, and retrospective studies pose challenges to the application of AI. Privacy concerns, bias, and the risk of AI replacing human care also loom. Regulatory oversight and physician involvement are needed for equitable AI implementation. AI integration and use in psychotherapy and other services are on the horizon. Patient trust, feasibility, clinical efficacy, and clinician acceptance are prerequisites. In the future, governing bodies must decide on AI ownership, governance, and integration approaches. While AI can enhance clinical decision-making and efficiency, it might also exacerbate moral dilemmas, autonomy loss, and issues regarding the scope of practice. Striking a balance between AI's strengths and limitations involves utilizing AI as a validated clinical supplement under medical supervision, necessitating active clinician involvement in AI research, ethics, and regulation. AI's trajectory must align with optimizing mental health treatment and upholding compassionate care.",
    "doi": "10.7759/cureus.44748",
    "url": "https://www.semanticscholar.org/paper/d417065c6b62f57248166c2272cab7ea9191c153",
    "pdf_url": "https://assets.cureus.com/uploads/editorial/pdf/169611/20230906-22464-vc3sfw.pdf",
    "venue": "Cureus",
    "citation_count": 35,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424875"
  },
  {
    "source": "semantic_scholar",
    "source_id": "9819447e44992a45463040d3ce57da761a303dfc",
    "title": "Integrating Artificial Intelligence into Medical Physics Practice: Promises and Ethical Considerations",
    "authors": [
      "Makoye John",
      "Rose Mina"
    ],
    "year": 2025,
    "abstract": "Artificial intelligence (AI) techniques such as deep learning show great potential to enhance medical physics practice by supporting diagnosis, treatment planning, and other clinical tasks. However, responsible integration of AI requires consideration of both promises and ethical risks to ensure technologies are developed and applied safely and for patient benefit. This research review examines opportunities and challenges of integrating AI across various domains of medical physics. Promising applications are discussed such as using large datasets to help radiologists interpret images more accurately and automating routine analyses to increase efficiency. AI may also expand access to care for rural populations through remote services. Potential ethical issues that could hamper responsible integration are also explored. Ensuring AI algorithms avoid human biases that unfairly impact patient outcomes is imperative. Other considerations include responsible oversight structures, ensuring privacy of patient data, and establishing regulatory and quality standards. This review proposes a framework for multidisciplinary collaboration and rigorous testing prior to clinical adoption of AI tools. It concludes that with ongoing research and development guided by principles of safety, accountability and fairness, AI can potentially enhance medical physics practice while avoiding unintended harms.\n",
    "doi": "10.11648/j.ajai.20250902.16",
    "url": "https://www.semanticscholar.org/paper/9819447e44992a45463040d3ce57da761a303dfc",
    "pdf_url": "",
    "venue": "American Journal of Artificial Intelligence",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424878"
  },
  {
    "source": "semantic_scholar",
    "source_id": "644723972382614555393a21e82014eea892a4eb",
    "title": "Artificial Intelligence in Image Analysis For Dermatology And Dermatopathology: Advancements And Challenges",
    "authors": [
      "R. Balachander",
      "G. Yohalakshmi",
      "A. R. Kavitha"
    ],
    "year": 2025,
    "abstract": "Emergence of Artificial Intelligence has evolved as a transformative tool for dermatology and dermatopathology, addressing significant hurdles such as high consultation costs, global dermatologist shortages, and diagnostic disparities. Therefore, this review delves into the progress that is being made in the areas related to AI applications with focus on its ability to diagnose high-resolution skin images towards better accuracy in diagnostics regarding melanoma, nevi, and inflammatory diseases. Using techniques like CNNs and deep learning, AI achieves sensitivity levels ranging from 58% to 96.1%, which is on par with human expertise. However, there are still many challenges, including dataset biases, underrepresentation of SOC, and reliance on outdated classification systems like the Fitzpatrick Skin Type (FST) scale. This paper will illustrate examples of solutions like Monk Skin Tone Scale, Fast Contrastive Unpaired Translation, (FastCUT) among others, to diminish this problem. Moreover, other ethical considerations like clarity and fairness and data confidentiality, among others, were observed. The review points toward multidisciplinary collaboration prospective clinical trials, and strict observance of regulatory compliance while dealing with AI models with great care for their trustworthiness and inclusivity. Thus, by overcoming these challenges, AI has the potential to revolutionize dermatological care with equity, accessibility, and effectiveness across diverse populations.",
    "doi": "10.1109/ICDSAAI65575.2025.11011788",
    "url": "https://www.semanticscholar.org/paper/644723972382614555393a21e82014eea892a4eb",
    "pdf_url": "",
    "venue": "2025 International Conference on Data Science, Agents & Artificial Intelligence (ICDSAAI)",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424882"
  },
  {
    "source": "semantic_scholar",
    "source_id": "57922a6310ae171f174b85527fc75bb1f9ceee50",
    "title": "Towards Involving End-users in Interactive Human-in-the-loop AI Fairness",
    "authors": [
      "Yuri Nakao",
      "Simone Stumpf",
      "Subeida Ahmed",
      "A. Naseer",
      "Lorenzo Strappelli"
    ],
    "year": 2022,
    "abstract": "Ensuring fairness in artificial intelligence (AI) is important to counteract bias and discrimination in far-reaching applications. Recent work has started to investigate how humans judge fairness and how to support machine learning (ML) experts in making their AI models fairer. Drawing inspiration from an Explainable AI (XAI) approach called \\emph{explanatory debugging} used in interactive machine learning, our work explores designing interpretable and interactive human-in-the-loop interfaces that allow ordinary end-users without any technical or domain background to identify potential fairness issues and possibly fix them in the context of loan decisions. Through workshops with end-users, we co-designed and implemented a prototype system that allowed end-users to see why predictions were made, and then to change weights on features to\"debug\"fairness issues. We evaluated the use of this prototype system through an online study. To investigate the implications of diverse human values about fairness around the globe, we also explored how cultural dimensions might play a role in using this prototype. Our results contribute to the design of interfaces to allow end-users to be involved in judging and addressing AI fairness through a human-in-the-loop approach.",
    "doi": "10.48550/arXiv.2204.10464",
    "url": "https://www.semanticscholar.org/paper/57922a6310ae171f174b85527fc75bb1f9ceee50",
    "pdf_url": "http://arxiv.org/pdf/2204.10464",
    "venue": "arXiv.org",
    "citation_count": 33,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424886"
  },
  {
    "source": "semantic_scholar",
    "source_id": "9721e79ac21e08a7b53ead33bbd1e675f84d1e6e",
    "title": "Balancing innovation and ethics: promote academic integrity through support and effective use of GenAI tools in higher education",
    "authors": [
      "Kangwa Daniel",
      "M. M. Msambwa",
      "A. Fute"
    ],
    "year": 2025,
    "abstract": null,
    "doi": "10.1007/s43681-025-00689-6",
    "url": "https://www.semanticscholar.org/paper/9721e79ac21e08a7b53ead33bbd1e675f84d1e6e",
    "pdf_url": "",
    "venue": "AI and Ethics",
    "citation_count": 4,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424889"
  },
  {
    "source": "semantic_scholar",
    "source_id": "9613a800142ec229cb888ce9b80efa8f78aab092",
    "title": "Artificial intelligence for telemedicine diabetic retinopathy screening: a review",
    "authors": [
      "L. Nakayama",
      "L. Zago Ribeiro",
      "Frederico Novaes",
      "I. Miyawaki",
      "Andresa Emy Miyawaki",
      "Juliana Ang\u00e9lica Estev\u00e3o de Oliveira",
      "Talita Oliveira",
      "F. Malerbi",
      "C. Regatieri",
      "L. Celi",
      "Paolo S. Silva"
    ],
    "year": 2023,
    "abstract": "Abstract Purpose This study aims to compare artificial intelligence (AI) systems applied in diabetic retinopathy (DR) teleophthalmology screening, currently deployed systems, fairness initiatives and the challenges for implementation. Methods The review included articles retrieved from PubMed/Medline/EMBASE literature search strategy regarding telemedicine, DR and AI. The screening criteria included human articles in English, Portuguese or Spanish and related to telemedicine and AI for DR screening. The author\u2019s affiliations and the study\u2019s population income group were classified according to the World Bank Country and Lending Groups. Results The literature search yielded a total of 132 articles, and nine were included after full-text assessment. The selected articles were published between 2004 and 2020 and were grouped as telemedicine systems, algorithms, economic analysis and image quality assessment. Four telemedicine systems that perform a quality assessment, image preprocessing and pathological screening were reviewed. A data and post-deployment bias assessment are not performed in any of the algorithms, and none of the studies evaluate the social impact implementations. There is a lack of representativeness in the reviewed articles, with most authors and target populations from high-income countries and no low-income country representation. Conclusions Telemedicine and AI hold great promise for augmenting decision-making in medical care, expanding patient access and enhancing cost-effectiveness. Economic studies and social science analysis are crucial to support the implementation of AI in teleophthalmology screening programs. Promoting fairness and generalizability in automated systems combined with telemedicine screening programs is not straightforward. Improving data representativeness, reducing biases and promoting equity in deployment and post-deployment studies are all critical steps in model development.",
    "doi": "10.1080/07853890.2023.2258149",
    "url": "https://www.semanticscholar.org/paper/9613a800142ec229cb888ce9b80efa8f78aab092",
    "pdf_url": "https://www.tandfonline.com/doi/pdf/10.1080/07853890.2023.2258149?needAccess=true",
    "venue": "Annals medicus",
    "citation_count": 29,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424894"
  },
  {
    "source": "semantic_scholar",
    "source_id": "df374be55da428c45891f1e09fe3eed81b758993",
    "title": "Ethical AI in Healthcare: A Comprehensive Review Addressing Privacy, Security, and Fairness",
    "authors": [
      "Ivy Payne Nkrumah",
      "Felicia Engmann",
      "Kofi Sarpong Adu-Manu"
    ],
    "year": 2025,
    "abstract": "The integration of Artificial Intelligence (AI) into healthcare presents both transformative potential and profound ethical challenges. This paper examines how ethical principles, such as transparency, fairness, accountability, and privacy, are applied and operationalised in healthcare AI. Using a structured narrative review approach, we analysed over 70 peer-reviewed empirical studies, policy documents, and regulatory frameworks that span applications in clinical decision support systems, diagnostics, mental health interventions and personalised medicine. Particular attention is given to the perspectives of diverse stakeholders, including patients, clinicians, data scientists and regulators. We assess fairness using demographic parity and equalised odds and evaluate transparency via explainability metrics and auditability practices. Our findings highlight the persistent issues of demographic bias, lack of stakeholder participation, and regulatory fragmentation. We propose a typology of responsible AI metrics, including data representativeness indices, fairness-accuracy trade-off scores, and human-AI oversight benchmarks, that can guide the ethical evaluation and deployment of AI models. By emphasising intersectionality, contextual equity, and co-designed governance, this study moves beyond generic ethical appeals to concrete implementation strategies. Our contribution offers a practical and interdisciplinary roadmap for aligning AI innovation with patient-centred values, institutional accountability, and evolving EU regulatory standards in the healthcare sector.",
    "doi": "10.14746/eip.2025.2.2",
    "url": "https://www.semanticscholar.org/paper/df374be55da428c45891f1e09fe3eed81b758993",
    "pdf_url": "",
    "venue": "ETHICS IN PROGRESS",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424898"
  },
  {
    "source": "semantic_scholar",
    "source_id": "a4113e31b39b72bb8f69479e52c339255b2606e7",
    "title": "Fairness in AI-Driven Recruitment: Challenges, Metrics, Methods, and Future Directions",
    "authors": [
      "Dena F. Mujtaba",
      "N. Mahapatra"
    ],
    "year": 2024,
    "abstract": "The recruitment process significantly impacts an organization's performance, productivity, and culture. Traditionally, human resource experts and industrial-organizational psychologists have developed systematic hiring methods, including job advertising, candidate skill assessments, and structured interviews to ensure candidate-organization fit. Recently, recruitment practices have shifted dramatically toward artificial intelligence (AI)-based methods, driven by the need to efficiently manage large applicant pools. However, reliance on AI raises concerns about the amplification and propagation of human biases embedded within hiring algorithms, as empirically demonstrated by biases in candidate ranking systems and automated interview assessments. Consequently, algorithmic fairness has emerged as a critical consideration in AI-driven recruitment, aimed at rigorously addressing and mitigating these biases. This paper systematically reviews biases identified in AI-driven recruitment systems, categorizes fairness metrics and bias mitigation techniques, and highlights auditing approaches used in practice. We emphasize critical gaps and current limitations, proposing future directions to guide researchers and practitioners toward more equitable AI recruitment practices, promoting fair candidate treatment and enhancing organizational outcomes.",
    "doi": "10.48550/arXiv.2405.19699",
    "url": "https://www.semanticscholar.org/paper/a4113e31b39b72bb8f69479e52c339255b2606e7",
    "pdf_url": "",
    "venue": "arXiv.org",
    "citation_count": 12,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424902"
  },
  {
    "source": "semantic_scholar",
    "source_id": "1f7b6e2be404f16a0d2a88eef169961220d5751f",
    "title": "Call for the responsible artificial intelligence in the healthcare",
    "authors": [
      "Umashankar Upadhyay",
      "Anton Gradisek",
      "Usman Iqbal",
      "Eshita Dhar",
      "Y. Li",
      "S. Syed-Abdul"
    ],
    "year": 2023,
    "abstract": "The integration of artificial intelligence (AI) into healthcare is progressively becoming pivotal, especially with its potential to enhance patient care and operational workflows. This paper navigates through the complexities and potentials of AI in healthcare, emphasising the necessity of explainability, trustworthiness, usability, transparency and fairness in developing and implementing AI models. It underscores the \u2018black box\u2019 challenge, highlighting the gap between algorithmic outputs and human interpretability, and articulates the pivotal role of explainable AI in enhancing the transparency and accountability of AI applications in healthcare. The discourse extends to ethical considerations, exploring the potential biases and ethical dilemmas that may arise in AI application, with a keen focus on ensuring equitable and ethical AI use across diverse global regions. Furthermore, the paper explores the concept of responsible AI in healthcare, advocating for a balanced approach that leverages AI\u2019s capabilities for enhanced healthcare delivery and ensures ethical, transparent and accountable use of technology, particularly in clinical decision-making and patient care.",
    "doi": "10.1136/bmjhci-2023-100920",
    "url": "https://www.semanticscholar.org/paper/1f7b6e2be404f16a0d2a88eef169961220d5751f",
    "pdf_url": "https://informatics.bmj.com/content/bmjhci/30/1/e100920.full.pdf",
    "venue": "BMJ Health & Care Informatics",
    "citation_count": 26,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424906"
  },
  {
    "source": "semantic_scholar",
    "source_id": "c1899167f19ff3cb30e59e674bd960d042287e82",
    "title": "Artificial intelligence: a new field of knowledge for nephrologists?",
    "authors": [
      "L. Fayos de Ariz\u00f3n",
      "E. R. Viera",
      "M. Pilco",
      "A. Perera",
      "G. de Maeztu",
      "A. Nicolau",
      "M. Furlano",
      "R. Torra"
    ],
    "year": 2023,
    "abstract": "\n Artificial Intelligence (AI) is a science that involves creating machines that can imitate human intelligence and learn. AI is ubiquitous in our daily lives, from search engines like Google to home assistants like Alexa and, more recently, OpenAI with its chatbot. AI can improve clinical care and research, but its use requires a solid understanding of its fundamentals, the promises and perils of algorithmic fairness, the barriers and solutions to its clinical implementation, and the pathways to developing an AI-competent workforce.\n The potential of AI in the field of nephrology is vast, particularly in the areas of diagnosis, treatment, and prediction. One of the most significant advantages of AI is the ability to improve diagnostic accuracy. Machine learning algorithms can be trained to recognize patterns in patient data, including lab results, imaging, and medical history, in order to identify early signs of kidney disease and thereby allow timely diagnoses and prompt initiation of treatment plans that can improve outcomes for patients. In short, AI holds the promise of advancing personalized medicine to new levels.\n While AI has tremendous potential, there are also significant challenges to its implementation, including data access and quality, data privacy and security, bias, trustworthiness, computing power, AI integration, and legal issues. The European Commission's proposed regulatory framework for AI technology will play a significant role in ensuring the safe and ethical implementation of these technologies in the healthcare industry.\n Training nephrologists in the fundamentals of AI is imperative because traditionally, decision-making pertaining to the diagnosis, prognosis, and treatment of renal patients has relied on ingrained practices, whereas AI serves as a powerful tool for swiftly and confidently synthesizing this information.",
    "doi": "10.1093/ckj/sfad182",
    "url": "https://www.semanticscholar.org/paper/c1899167f19ff3cb30e59e674bd960d042287e82",
    "pdf_url": "https://academic.oup.com/ckj/advance-article-pdf/doi/10.1093/ckj/sfad182/51005865/sfad182.pdf",
    "venue": "Clinical Kidney Journal",
    "citation_count": 22,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424910"
  },
  {
    "source": "semantic_scholar",
    "source_id": "ced30db981dc74704c9bd3cf04876c8540cf2f66",
    "title": "Augmented intelligence should be good for medicine, if medicine is to remain good for us",
    "authors": [
      "Daphna Idan",
      "L. Celi",
      "Sharon Einav",
      "Amit Frenkel"
    ],
    "year": 2025,
    "abstract": null,
    "doi": "10.1007/s44163-025-00256-2",
    "url": "https://www.semanticscholar.org/paper/ced30db981dc74704c9bd3cf04876c8540cf2f66",
    "pdf_url": "",
    "venue": "Discover Artificial Intelligence",
    "citation_count": 0,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424913"
  },
  {
    "source": "semantic_scholar",
    "source_id": "1d7799a5e056cce4ff48330fee77552d824e3be1",
    "title": "Artificial Intelligence Can\u2019t Be Charmed: The Effects of Impartiality on Laypeople\u2019s Algorithmic Preferences",
    "authors": [
      "Marius Claudy",
      "Karl Aquino",
      "Maja Graso"
    ],
    "year": 2022,
    "abstract": "Over the coming years, AI could increasingly replace humans for making complex decisions because of the promise it holds for standardizing and debiasing decision-making procedures. Despite intense debates regarding algorithmic fairness, little research has examined how laypeople react when resource-allocation decisions are turned over to AI. We address this question by examining the role of perceived impartiality as a factor that can influence the acceptance of AI as a replacement for human decision-makers. We posit that laypeople attribute greater impartiality to AI than human decision-makers. Our investigation shows that people value impartiality in decision procedures that concern the allocation of scarce resources and that people perceive AI as more capable of impartiality than humans. Yet, paradoxically, laypeople prefer human decision-makers in allocation decisions. This preference reverses when potential human biases are made salient. The findings highlight the importance of impartiality in AI and thus hold implications for the design of policy measures.",
    "doi": "10.3389/fpsyg.2022.898027",
    "url": "https://www.semanticscholar.org/paper/1d7799a5e056cce4ff48330fee77552d824e3be1",
    "pdf_url": "https://www.frontiersin.org/articles/10.3389/fpsyg.2022.898027/pdf",
    "venue": "Frontiers in Psychology",
    "citation_count": 15,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424917"
  },
  {
    "source": "semantic_scholar",
    "source_id": "5705095c8a342fc068f1f8487fb2706c669d1bfc",
    "title": "AI Ethics and Regulations: Ensuring Trustworthy AI",
    "authors": [
      "Pericles 'Asher' Rospigliosi"
    ],
    "year": 2025,
    "abstract": "As Artificial Intelligence (AI) technologies become increasingly embedded in critical aspects of modern life\u2014ranging from healthcare diagnostics and financial forecasting to autonomous vehicles, law enforcement, education, and national security\u2014the urgency of addressing their ethical implications has grown exponentially. While AI systems offer unprecedented efficiencies and capabilities, they also present significant risks, including algorithmic bias, opaque decisionmaking processes, data exploitation, invasion of privacy, digital surveillance, job displacement, and the amplification of societal inequalities. These risks are particularly acute in high-stakes domains where errors or unchecked use can result in irreversible harm or systemic injustice. This paper offers a comprehensive examination of the evolving ethical landscape surrounding AI development and deployment. It explores foundational ethical principles such as fairness, accountability, transparency, and human-centered design, alongside contemporary challenges introduced by machine learning models, deep learning algorithms, and autonomous decision systems. Special attention is given to the global regulatory landscape, comparing initiatives such as the European Union\u2019s AI Act, the U.S. Blueprint for an AI Bill of Rights, and guidelines from organizations like UNESCO and the OECD. The paper also examines the growing role of interdisciplinary AI ethics teams, algorithmic auditing, and impact assessments. Ultimately, the paper proposes a strategic roadmap for building ethical AI ecosystems grounded in inclusivity, explainability, legal compliance, and social well-being. It emphasizes that aligning AI development with democratic values, human dignity, and global equity is not merely desirable\u2014 but essential\u2014for ensuring that the future of AI serves humanity as a whole, rather than a privileged few.\u00a0",
    "doi": "10.63619/ijai4s.v1i2.004",
    "url": "https://www.semanticscholar.org/paper/5705095c8a342fc068f1f8487fb2706c669d1bfc",
    "pdf_url": "",
    "venue": "International Journal of Artificial Intelligence for Science (IJAI4S)",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424920"
  },
  {
    "source": "semantic_scholar",
    "source_id": "e3a579dae809624b78bc4029c44bb7b2a9d42f5b",
    "title": "A Process for Human Resource Performance Evaluation Using Computational Intelligence: An Approach Using a Combination of Rule-Based Classifiers and Supervised Learning Algorithms",
    "authors": [
      "Anderson Silva De Oliveira G\u00f3es",
      "Roberto C\u00e9lio Lim\u00e3o de Oliveira"
    ],
    "year": 2020,
    "abstract": "This paper proposes a process for human resource performance evaluation using computational intelligence techniques. The human resource (or employee\u2019s) performance evaluation is essentially a regular assessment and review of an employee\u2019s performance on the job. This evaluation can be performed in different ways, depending on the kind of job of the employee and on the company\u2019s politics or business area. The process proposed on this research combines Fuzzy logic, text sentiment analysis and supervised learning classification techniques, such as a multi layer perceptron artificial neural network, decision tree algorithms and na\u00efve bayes into ensemble classifiers, in an attempt to provide a fair evaluation process, minimizing or even eliminating common problems caused by simple objective or subjective approaches. The data provided for this research was originated from several evaluations applied in two Brazilians institutions. Simulation results shows consistence on the data generated by this proposed process, indicating a good perspective for applications on companies of most business areas.",
    "doi": "10.1109/ACCESS.2020.2975485",
    "url": "https://www.semanticscholar.org/paper/e3a579dae809624b78bc4029c44bb7b2a9d42f5b",
    "pdf_url": "https://ieeexplore.ieee.org/ielx7/6287639/8948470/09004612.pdf",
    "venue": "IEEE Access",
    "citation_count": 26,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424924"
  },
  {
    "source": "semantic_scholar",
    "source_id": "28d9b673f0f1df50e44e7f3e27c22580d5b7bc99",
    "title": "Integrating Behavioral, Economic, and Technical Insights to Understand and Address Algorithmic Bias: A Human-Centric Perspective",
    "authors": [
      "G. Adomavicius",
      "Mochen Yang"
    ],
    "year": 2022,
    "abstract": "Many important decisions are increasingly being made with the help of information systems that use artificial intelligence and machine learning models. These computational models are designed to discover useful patterns from large amounts of data, which augment human capabilities to make decisions in various application domains. However, there are growing concerns regarding the ethics challenges faced by these automated decision-making (ADM) models, most notably on the issue of algorithmic bias, in which the models systematically produce less favorable (i.e., unfair) decisions for certain groups of people. In this commentary, we argue that algorithmic bias is not just a technical (e.g., computational or statistical) problem, and its successful resolution requires deep insights into individual and organizational behavior, economic incentives, as well as complex dynamics of the sociotechnical systems in which the ADM models are embedded. We discuss a human-centric, fairness-aware ADM framework that highlights the holistic involvement of human decision makers in each step of ADM. We review the emerging literature on fairness-aware machine learning and then discuss various strategic decisions that humans need to make, such as formulating proper fairness objectives, recognizing fairness-induced trade-offs and implications, utilizing machine learning model outputs, and managing/governing the decisions of ADM models. We further illustrate how these strategic decisions are jointly informed by behavioral, economic, and design sciences. Our discussions reveal a number of future research opportunities uniquely suitable for Management Information Systems (MIS) researchers to pursue.",
    "doi": "10.1145/3519420",
    "url": "https://www.semanticscholar.org/paper/28d9b673f0f1df50e44e7f3e27c22580d5b7bc99",
    "pdf_url": "",
    "venue": "ACM Transactions on Management Information Systems",
    "citation_count": 16,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424927"
  },
  {
    "source": "semantic_scholar",
    "source_id": "5a0e9ae236ba51b423dcde3cdb207d1b3568f206",
    "title": "Exploring prospects, hurdles, and road ahead for generative artificial intelligence in orthopedic education and training",
    "authors": [
      "Nikhil Gupta",
      "Kavin Khatri",
      "Yogender Malik",
      "Amit Lakhani",
      "Abhinav Kanwal",
      "Sameer Aggarwal",
      "A. Dahuja"
    ],
    "year": 2024,
    "abstract": "Generative Artificial Intelligence (AI), characterized by its ability to generate diverse forms of content including text, images, video and audio, has revolutionized many fields, including medical education. Generative AI leverages machine learning to create diverse content, enabling personalized learning, enhancing resource accessibility, and facilitating interactive case studies. This narrative review explores the integration of generative artificial intelligence (AI) into orthopedic education and training, highlighting its potential, current challenges, and future trajectory. A review of recent literature was conducted to evaluate the current applications, identify potential benefits, and outline limitations of integrating generative AI in orthopedic education. Key findings indicate that generative AI holds substantial promise in enhancing orthopedic training through its various applications such as providing real-time explanations, adaptive learning materials tailored to individual student\u2019s specific needs, and immersive virtual simulations. However, despite its potential, the integration of generative AI into orthopedic education faces significant issues such as accuracy, bias, inconsistent outputs, ethical and regulatory concerns and the critical need for human oversight. Although generative AI models such as ChatGPT and others have shown impressive capabilities, their current performance on orthopedic exams remains suboptimal, highlighting the need for further development to match the complexity of clinical reasoning and knowledge application. Future research should focus on addressing these challenges through ongoing research, optimizing generative AI models for medical content, exploring best practices for ethical AI usage, curriculum integration and evaluating the long-term impact of these technologies on learning outcomes. By expanding AI\u2019s knowledge base, refining its ability to interpret clinical images, and ensuring reliable, unbiased outputs, generative AI holds the potential to revolutionize orthopedic education. This work aims to provides a framework for incorporating generative AI into orthopedic curricula to create a more effective, engaging, and adaptive learning environment for future orthopedic practitioners.",
    "doi": "10.1186/s12909-024-06592-8",
    "url": "https://www.semanticscholar.org/paper/5a0e9ae236ba51b423dcde3cdb207d1b3568f206",
    "pdf_url": "https://doi.org/10.1186/s12909-024-06592-8",
    "venue": "BMC Medical Education",
    "citation_count": 19,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424931"
  },
  {
    "source": "semantic_scholar",
    "source_id": "c2400d09993319898ecec666f41d61dfa896b1d0",
    "title": "Revolutionizing Medical Practice: The Impact of Artificial Intelligence (AI) on Healthcare",
    "authors": [],
    "year": 2024,
    "abstract": "The twenty-first century has witnessed significant advancements in informatics, reshaping our understanding of data processing and accessibility. Artificial intelligence (AI), encompassing techniques such as machine learning (ML), deep learning (DP), and neural networks (NN), is poised to revolutionize medicine. AI holds the capability of analyzing vast amounts of data, extracting meaningful insights, and making accurate predictions, thereby empowering industries to make informed decisions, drive innovation, and enhance efficiency. The landscape of medical AI has evolved significantly, demonstrating expert-level disease detection from medical images and promising breakthroughs across various industries. AI revolutionizes medical practice by leveraging advanced algorithms and machine learning capabilities to improve diagnostics, treatment planning, and overall patient care. However, the deployment of medical AI systems in regular clinical practice still needs to be tapped, presenting complex ethical, technical, and human-centered challenges that must be addressed for successful implementation. While AI algorithms have shown efficacy in retrospective medical investigations, their translation into practical medical settings has been limited, raising concerns about their usability and interaction with healthcare professionals. Moreover, the representativeness of retrospective datasets in real-world medical practice is subject to filtering and cleaning biases. Integrating AI into clinical medicine holds great promise for transforming healthcare delivery, improving patient care, and revolutionizing aspects such as diagnosis, treatment planning, drug discovery, personalized treatment, and medical imaging. With advanced algorithms and machine learning capabilities, AI and robotics in Healthcare can analyze large volumes of medical data, extract meaningful insights, and provide accurate predictions, empowering healthcare professionals to make informed decisions and optimize resource allocation. The availability of extensive clinical, genomics, and digital imaging data, coupled with investments from healthcare institutions and technology giants, underscores the potential of AI in healthcare. This review article explores AI's powerful potential to revolutionize healthcare delivery across multiple domains, emphasizing the need to overcome challenges and harness its transformative capabilities in clinical practice.",
    "doi": "10.33140/oajast.02.01.07",
    "url": "https://www.semanticscholar.org/paper/c2400d09993319898ecec666f41d61dfa896b1d0",
    "pdf_url": "https://doi.org/10.33140/oajast.02.01.07",
    "venue": "Open Access Journal of Applied Science and Technology",
    "citation_count": 16,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424935"
  },
  {
    "source": "semantic_scholar",
    "source_id": "989fc6de20cc98117eaf21e607019ca3513832c2",
    "title": "Advancing AI Data Ethics in Nursing: Future Directions for Nursing Practice, Research, and Education",
    "authors": [
      "Patricia A Ball Dunlap",
      "Martin Michalowski"
    ],
    "year": 2024,
    "abstract": "Abstract The ethics of artificial intelligence (AI) are increasingly recognized due to concerns such as algorithmic bias, opacity, trust issues, data security, and fairness. Specifically, machine learning algorithms, central to AI technologies, are essential in striving for ethically sound systems that mimic human intelligence. These technologies rely heavily on data, which often remain obscured within complex systems and must be prioritized for ethical collection, processing, and usage. The significance of data ethics in achieving responsible AI was first highlighted in the broader context of health care and subsequently in nursing. This viewpoint explores the principles of data ethics, drawing on relevant frameworks and strategies identified through a formal literature review. These principles apply to real-world and synthetic data in AI and machine-learning contexts. Additionally, the data-centric AI paradigm is briefly examined, emphasizing its focus on data quality and the ethical development of AI solutions that integrate human-centered domain expertise. The ethical considerations specific to nursing are addressed, including 4 recommendations for future directions in nursing practice, research, and education and 2 hypothetical nurse-focused ethical case studies. The primary objectives are to position nurses to actively participate in AI and data ethics, thereby contributing to creating high-quality and relevant data for machine learning applications.",
    "doi": "10.2196/62678",
    "url": "https://www.semanticscholar.org/paper/989fc6de20cc98117eaf21e607019ca3513832c2",
    "pdf_url": "",
    "venue": "JMIR Nursing",
    "citation_count": 23,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424938"
  },
  {
    "source": "semantic_scholar",
    "source_id": "e2e78a9066a5e8082d78e1b0880838025b31a7cc",
    "title": "Artificial Intelligence and unintended bias: A call for responsible innovation",
    "authors": [
      "Dhruvitkumar V. Talati"
    ],
    "year": 2021,
    "abstract": "This essay discusses the intricate and multifaceted problem of algorithmic bias in artificial intelligence (AI) systems, and emphasizes its human rights, social, and ethical implications. As AI technologies become increasingly embedded in high-stakes areas of medicine, finance, employment, law enforcement, and social services, risks of discriminatory decision-making remain on the rise. Algorithmic bias may perpetuate existing social biases, adversely affect disadvantaged populations disproportionately, and perpetuate institutional discrimination, and thereby pose serious ethical issues.\nThe research endeavors to present an extensive comprehension of algorithmic bias through exploration of its cause, mechanism, and societal aspects. It exhaustively analyzes the presence of bias in AI systems, its cause-running from biased input data to defective algorithmic development, as well as the ethical aspects brought by having AI-based decisions influence real-world repercussions. In addition, the study analyzes material and immaterial effects of AI bias on persons and groups and aims at fairness, transparency, and accountability of AI in particular.\nIn its attempt to deal with these issues, this paper analyzes some measures to mitigate against bias, for instance, technical measures such as bias-aware algorithms, fairness-aware machine learning algorithms, and explainable AI methodologies. Furthermore, it speaks to normative and regulatory regimes that enable responsible AI deployment, as well as grass-roots strategies that enable affected communities to participate in AI stewardship. Through the use of the best of an interdisciplinary approach, the study integrates findings from peer-reviewed literature, international case studies, government policy, and industry standards to provide a comprehensive perspective on the issue.\nFinally, the paper emphasizes the need for active, multi-stakeholder responses that make sure AI technologies conform to basic human rights and moral principles. In incorporating technical, ethical, legal, and social considerations into AI, the research demands more inclusive and accountable AI system that maximizes fairness, minimizes disparities, and secures human dignity in the modern fast-changing world of artificial intelligence.",
    "doi": "10.30574/ijsra.2021.2.2.0110",
    "url": "https://www.semanticscholar.org/paper/e2e78a9066a5e8082d78e1b0880838025b31a7cc",
    "pdf_url": "",
    "venue": "International Journal of Science and Research Archive",
    "citation_count": 3,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424941"
  },
  {
    "source": "semantic_scholar",
    "source_id": "c187a6b6a31d7357f1e92d5f4a1bc7b6ca7542ae",
    "title": "Perceptions, Strategies, and Challenges of Teachers in the Integration of Artificial Intelligence in Primary Education: A Systematic Review",
    "authors": [
      "Olga Arranz Garcia",
      "Mar\u00eda del Carmen Romero Garc\u00eda",
      "Vidal Alonso-Secades"
    ],
    "year": 2025,
    "abstract": "Aim/Purpose: Evaluate teachers\u2019 perceptions, strategies, and challenges in integrating artificial intelligence (AI) into K-12 education and identify patterns and trends in the data from the reviewed studies.\n\nBackground: This systematic review examines a decade of innovation to explore the transformative impact of AI on education (2014\u20132024). Adhering to PRISMA 2020 guidelines, the study uncovers key trends, challenges, and breakthroughs in AI-driven teaching and learning, offering a comprehensive perspective on how AI reshapes educational practices and methodologies. \n\nMethodology: The study employs a systematic review to analyze the implementation of AI techniques and tools in primary education, following the PRISMA 2020 guidelines to ensure the reliability and effectiveness of the findings. To achieve this, an extensive search was conducted in academic databases such as Web of Science, Scopus, and ERIC, focusing on empirical studies and peer-reviewed articles published between 2014 and 2024. Only accessible, peer-reviewed articles classified under Education and Educational Research and published in English or Spanish were selected.\n\nThe search strategy was structured into five categories aligned with the research questions to identify relevant studies accurately. The selection process was carried out in three phases \u2013 Identification, Screening, and Inclusion \u2013 applying predefined criteria to guarantee the quality and relevance of the selected studies. Of an initial total of 514,919 articles, 488,940 were excluded for not meeting the inclusion criteria. After removing duplicates and evaluating titles, abstracts, and full texts, a final set of 28 studies was included.\n\n\nContribution: The study explores the integration of AI in primary education, revealing both teachers\u2019 enthusiasm and the challenges they face. While AI is perceived as a tool to enhance critical thinking, problem-solving, and student engagement, its implementation is limited by insufficient training, resources, and institutional support.\n\nDespite these obstacles, teachers show confidence in designing AI-integrated curricula, though this is weakened by inadequate infrastructure and technical support, highlighting the need for continuous professional development. The study also stresses the importance of establishing a competency framework for AI literacy and adopting a systemic approach to AI education.\n\nAdditionally, ensuring safe learning environments by addressing data privacy and AI biases remains a key challenge. Overcoming these issues is essential for the ethical and effective integration of AI, maximizing its benefits while safeguarding student equity and security.\n\n\nFindings: - Educators see the potential of AI to personalize learning.\n- Barriers are lack of training and resources for teachers.\n- Importance of continuous training in digital skills.\n- Need for policies that promote AI literacy.\n- Collaboration with experts to optimize AI in the classroom.\n\nRecommendations for Practitioners: Teachers are encouraged to collaborate in using AI tools to enhance educational outcomes, supported by continuous professional development programs, clear policies that safeguard privacy and promote equality, and a framework that preserves human autonomy in integrating AI technologies.\n\nRecommendation for Researchers: The lack of empirical research on AI interventions in education limits understanding of its true impact, highlighting the need for future studies to fill this gap and optimize its application for greater educational benefits.\n\nImpact on Society: The integration of AI in K-12 education is not just an opportunity; it is a necessity to prepare future generations for an increasingly digital world. While AI has the potential to revolutionize learning by fostering critical thinking, personalization, and engagement, its impact depends on how effectively it is implemented. To ensure its benefits, it is essential to empower educators and students with AI literacy, address issues like bias and data privacy, and establish robust legal frameworks for fair and transparent use. Without proactive policies, AI could widen educational inequalities instead of reducing them. A responsible, human-centered approach is needed to create an inclusive, ethical, and effective AI-powered education system.\n\nFuture Research: The article highlights the urgency of future empirical research to better understand the real impact of AI in education, as the lack of intervention studies limits its optimal application. Analyzing how AI influences learning outcomes, teaching dynamics, equity, and accessibility is essential, along with investigating the pedagogical competencies and technological conditions that affect its adoption. To this end, expanding the scope of studies is recommended by incorporating multicultural and multilingual perspectives, exploring AI applications across various disciplines and educational levels, and promoting interdisciplinary approaches that address ethical, social, and pedagogical dimensions.\n\n",
    "doi": "10.28945/5458",
    "url": "https://www.semanticscholar.org/paper/c187a6b6a31d7357f1e92d5f4a1bc7b6ca7542ae",
    "pdf_url": "",
    "venue": "J. Inf. Technol. Educ. Res.",
    "citation_count": 12,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424945"
  },
  {
    "source": "semantic_scholar",
    "source_id": "06931b57128240d8b859492a689064c6d453653b",
    "title": "Algorithmic Fairness in Recruitment: Designing AI-Powered Hiring Tools to Identify and Reduce Biases in Candidate Selection",
    "authors": [
      "C. Agbasiere",
      "Goodness Rex Nze-Igwe"
    ],
    "year": 2025,
    "abstract": "The study looks into how artificial intelligence (AI) affects hiring procedures, focusing on the fairness of the algorithms that drive these tools. AI has improved the efficiency of the hiring process, yet its use results in institutionalised discrimination. The AI systems used for recruitment, which base evaluations on past performance data, have the potential to discriminate against minority candidates as well as women through unintentional actions. The ability of AI systems to decrease human biases during recruitment encounters major challenges, as Amazon's discriminatory resume screening demonstrates the issues in systemic bias maintenance. This paper discusses the origins of algorithmic bias, including biased training records, defining labels, and choosing features, and suggests debiasing methods. Methods such as reweighting, adversarial debiasing, and fairness-aware algorithms are assessed for suitability in developing unbiased AI hiring systems. A quantitative approach is used in the research, web scraping data from extensive secondary sources to assess these biases and their mitigation measures. A Fair Machine Learning (FML) theoretical framework is utilised, which introduces fairness constraints into machine learning models so that hiring models do not perpetuate present discrimination. The ethical, legal, and organisational ramifications of using AI for recruitment are further examined under GDPR and Equal Employment Opportunity law provisions. By investigating HR practitioners' experiences and AI-based recruitment data, the study aims to develop guidelines for designing open, accountable, and equitable AI-based hiring processes. The findings emphasise the value of human oversight and the necessity of regular audits to guarantee equity in AI hiring software and, consequently, encourage diversity and equal opportunity during employment.",
    "doi": "10.22178/pos.116-10",
    "url": "https://www.semanticscholar.org/paper/06931b57128240d8b859492a689064c6d453653b",
    "pdf_url": "https://doi.org/10.22178/pos.116-10",
    "venue": "Path of Science",
    "citation_count": 2,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424949"
  },
  {
    "source": "semantic_scholar",
    "source_id": "3eae656fa8f9a658000c2e6bc8023f20533448fd",
    "title": "Guest editorial: Artificial intelligence and machine learning in business and management",
    "authors": [
      "Fouad Ben Abdelaziz",
      "H. Kunze",
      "Davide La Torre",
      "Bernard Sinclair-Desgagn\u00e9"
    ],
    "year": 2022,
    "abstract": "\ufb01 personalized sentiment and team human resource management, motivation, job design, training, knowledge management, leadership and business ethics. the for further insightful and useful inquiries.",
    "doi": "10.1108/jm2-08-2022-325",
    "url": "https://www.semanticscholar.org/paper/3eae656fa8f9a658000c2e6bc8023f20533448fd",
    "pdf_url": "https://doi.org/10.1108/jm2-08-2022-325",
    "venue": "Journal of Modelling in Management",
    "citation_count": 4,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424952"
  },
  {
    "source": "semantic_scholar",
    "source_id": "b39f1792e30bcb39b2363c7b30d4dde2c5515577",
    "title": "Reducing AI bias in recruitment and selection: an integrative grounded approach",
    "authors": [
      "M. Soleimani",
      "A. Intezari",
      "Jim Arrowsmith",
      "David Pauleen",
      "Naz\u0131m Ta\u015fk\u0131n"
    ],
    "year": 2025,
    "abstract": "Abstract Artificial Intelligence (AI) is transforming business domains such as operations, marketing, risk, and financial management. However, its integration into Human Resource Management (HRM) poses challenges, particularly in recruitment, where AI influences work dynamics and decision-making. This study, using a grounded theory approach, interviewed 39 HR professionals and AI developers to explore potential biases in AI-Recruitment Systems (AIRS) and identify mitigation techniques. Findings highlight a critical gap: the HR profession\u2019s need to embrace both technical skills and nuanced people-focused competencies to collaborate effectively with AI developers and drive informed discussions on the scope of AI\u2019s role in recruitment and selection. This research integrates Gibson\u2019s direct perception theory and Gregory\u2019s indirect perception theory, combining psychological, information systems, and HRM perspectives to offer insights into decision-making biases in AI. A framework is proposed to clarify decision-making biases and guide the development of robust protocols for AI in HR, with a focus on ethical oversight and regulatory needs. This research contributes to AI-based HR decision-making literature by exploring the intersection of cognitive bias and AI-augmented decisions in recruitment and selection. It offers practical insights for HR professionals and AI developers on how collaboration and perception can improve the fairness and effectiveness of AIRS-aided decisions.",
    "doi": "10.1080/09585192.2025.2480617",
    "url": "https://www.semanticscholar.org/paper/b39f1792e30bcb39b2363c7b30d4dde2c5515577",
    "pdf_url": "https://doi.org/10.1080/09585192.2025.2480617",
    "venue": "International journal of human resources management",
    "citation_count": 12,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424956"
  },
  {
    "source": "semantic_scholar",
    "source_id": "61ec76bfc24131088f264861e059fdd2acc49fe1",
    "title": "Evaluating and mitigating bias in AI-based medical text generation",
    "authors": [
      "Xiuying Chen",
      "Tairan Wang",
      "Juexiao Zhou",
      "Zirui Song",
      "Xin Gao",
      "Xiangliang Zhang"
    ],
    "year": 2025,
    "abstract": "Artificial intelligence (AI) systems, particularly those based on deep learning models, have increasingly achieved expert-level performance in medical applications. However, there is growing concern that such AI systems may reflect and amplify human bias, reducing the quality of their performance in historically underserved populations. The fairness issue has attracted considerable research interest in the medical imaging classification field, yet it remains understudied in the text-generation domain. In this study, we investigate the fairness problem in text generation within the medical field and observe substantial performance discrepancies across different races, sexes and age groups, including intersectional groups, various model scales and different evaluation metrics. To mitigate this fairness issue, we propose an algorithm that selectively optimizes those underserved groups to reduce bias. Our evaluations across multiple backbones, datasets and modalities demonstrate that our proposed algorithm enhances fairness in text generation without compromising overall performance. This study evaluates bias in AI-generated medical text, revealing disparities across race, sex and age. An optimization method is proposed to enhance fairness without compromising performance, offering a step toward more equitable AI in healthcare.",
    "doi": "10.1038/s43588-025-00789-7",
    "url": "https://www.semanticscholar.org/paper/61ec76bfc24131088f264861e059fdd2acc49fe1",
    "pdf_url": "",
    "venue": "Nature Computational Science",
    "citation_count": 10,
    "fields_of_study": [
      "Computer Science",
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424960"
  },
  {
    "source": "semantic_scholar",
    "source_id": "50bee65826dacb9604d8008327d67ac8637c4a4a",
    "title": "The Impact of Artificial Intelligence on Health Equity in Oncology: A Scoping Review",
    "authors": [
      "Paul Istasy",
      "Wen Shen Lee",
      "Alla Iansavitchene",
      "Ross E. G. Upshur",
      "B. Sadikovic",
      "A. Lazo-Langner",
      "B. Chin\u2010Yee"
    ],
    "year": 2021,
    "abstract": "\n Introduction: The expanding use of Artificial Intelligence (AI) in hematology and oncology research and practice creates an urgent need to consider the potential impact of these technologies on health equity at both local and global levels. Fairness and equity are issues of growing concern in AI ethics, raising problems ranging from bias in datasets and algorithms to disparities in access to technology. The impact of AI on health equity in oncology, however, remains underexplored. We conducted a scoping review to characterize, evaluate, and identify gaps in the existing literature on AI applications in oncology and their implications for health equity in cancer care.\n Methodology: We performed a systematic literature search of MEDLINE (Ovid) and EMBASE from January 1, 2000 to March 28, 2021 using key terms for AI, health equity, and cancer. Our search was restricted to English language abstracts with no restrictions by publication type. Two reviewers screened a total of 9519 abstracts, and 321 met inclusion criteria for full-text review. 247 were included in the final analysis after assessment by three reviewers. Studies were analysed descriptively, by location, type of cancer and AI application, as well as thematically, based on issues pertaining to health equity in oncology.\n Results: Of the 247 studies included in our analysis, 150 (60.7%) were based in North America, 57 (23.0%) in Asia, 29 (11.7%) in Europe, 5 (2.1%) in Central/South America, 4 (1.6%) in Oceania, and 2 (0.9%) in Africa. 71 (28.6%) were reviews and commentaries, and 176 were (71.3%) clinical studies. 25 (10.1%) focused on AI applications in screening, 42 (17.0%) in diagnostics, 46 (18.6%) in prognostication, and 7 (2.9%) in treatment. 40 (16.3%) used AI as a tool for clinical/epidemiological research and 87 (35.2%) discussed multiple applications of AI. A diverse range of cancers were represented in the studies, including hematologic malignancies. Our scoping review identified three overarching themes in the literature, which largely focused on how AI might improve health equity in oncology. These included: (1) the potential for AI reduce disparities by improving access to health services in resource-limited settings through applications such as low-cost cancer screening technologies and decision support systems; (2) the ability of AI to mitigate bias in clinical decision-making through algorithms that alert clinicians to potential sources of bias thereby allowing for more equitable and individualized care; (3) the use of AI as a research tool to identify disparities in cancer outcomes based on factors such as race, gender and socioeconomic status, and thus inform health policy. While most of the literature emphasized the positive impact of AI in oncology, there was only limited discussion of AI's potential adverse effects on health equity . Despite engaging with the use of AI in resource-limited settings, ethical issues surrounding data extraction and AI trials in low-resource settings were infrequently raised. Similarly, AI's potential to reinforce bias and widen disparities in cancer care was under-examined despite engagement with related topics of bias in clinical decision-making.\n Conclusion: The overwhelming majority of the literature identified by our scoping review highlights the benefits of AI applications in oncology, including its potential to improve access to care in low-resource settings, mitigate bias in clinical decision-making, and identify disparities in cancer outcomes. However, AI's potential negative impacts on health equity in oncology remain underexplored: ethical issues arising from deploying AI technologies in low-resources settings, and issues of bias in datasets and algorithms were infrequently discussed in articles dealing with related themes.\n \n \n No relevant conflicts of interest to declare.\n",
    "doi": "10.1182/blood-2021-149264",
    "url": "https://www.semanticscholar.org/paper/50bee65826dacb9604d8008327d67ac8637c4a4a",
    "pdf_url": "https://doi.org/10.1182/blood-2021-149264",
    "venue": "Blood",
    "citation_count": 11,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424963"
  },
  {
    "source": "semantic_scholar",
    "source_id": "fa56200090dc8db644461759075cf473c6c0d8b0",
    "title": "The Role of Artificial Intelligence in Recruitment Process Decision-Making",
    "authors": [
      "A. Al-Alawi",
      "Misbah Naureen",
      "Ebtesam Ismaeel AlAlawi",
      "Ahmed Abdulla Naser Al-Hadad"
    ],
    "year": 2021,
    "abstract": "Artificial Intelligence (AI) can playa pivotal role in the firm's recruiting process, facilitating excellence. This study investigates the challenges AI faces in the hiring process and the outcomes/ results of using AI in the hiring process. The benefits of using AI in the hiring process include identifying AI vendors and firms that have adopted AI in the hiring process, analyzing the present state of AI to facilitate the hiring process, and the impact of adopting AI in the hiring process. Through this study, different perceptions, theories, ideas, and opinions are presented to modulate the use of AI in human resource management utilizing papers from 1988 to 2020. The findings indicate that AI is adopted mainly in high-tech or large companies. The reports presented by these companies on the use of AI thus do not provide an actual picture of the usage and step by step evaluation as interviews are still a part of the recruitment process providing space for human bias. Future research may include aligning the AI with the mission and vision of the company and the rules and regulations of the country that they have been adopted. The aspect of AI to support human resources in decision making, not a threat as AI is considered to take over the human roles in human resource management, should also be studied in detail.",
    "doi": "10.1109/DASA53625.2021.9682320",
    "url": "https://www.semanticscholar.org/paper/fa56200090dc8db644461759075cf473c6c0d8b0",
    "pdf_url": "",
    "venue": "2021 International Conference on Decision Aid Sciences and Application (DASA)",
    "citation_count": 27,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424967"
  },
  {
    "source": "semantic_scholar",
    "source_id": "9cf847bebe4df29a0ecbb66d2ad55641be51bc1d",
    "title": "AI-ENABLED INTERVIEW ANALYSIS: UNVEILING INSIGHTS AND ENHANCING DECISION-MAKING IN HUMAN RESOURCE MANAGEMENT",
    "authors": [
      "Rajneesh Panwar"
    ],
    "year": 2023,
    "abstract": "The process of conducting interviews plays a pivotal role in human resource management, as it directly influences the selection of candidates and ultimately shapes the composition of an organization's workforce. However, traditional interview methods are often subjective and prone to biases, leading to suboptimal decision-making. In recent years, the emergence of artificial intelligence (AI) technologies has provided new opportunities to revolutionize interview analysis and improve decision-making in the hiring process.This research paper explores the application of AI-enabled interview analysis in human resource management, aiming to unveil insights and enhance decision-making. The study focuses on three main areas: interview data collection, analysis, and decision-making support. AI technologies, including natural language processing (NLP) and machine learning algorithms, are leveraged to analyze interview transcripts, audio recordings, and other relevant data sources.By analyzing interview data using AI, this research uncovers hidden patterns, linguistic cues, and behavioural indicators that may be missed by human interviewers. These insights provide a deeper understanding of candidate suitability, skills, and competencies, enabling HR professionals to make more informed and objective decisions. Moreover, AI algorithms can be trained to identify biases and mitigate their impact, leading to fairer and more inclusive hiring practices. The research also investigates the potential challenges and ethical considerations associated with AI- enabled interview analysis. Concerns related to privacy, data security, algorithmic biases, and the role of human judgment in decision-making are examined, highlighting the need for responsible implementation and ongoing monitoring.To validate the effectiveness of AI-enabled interview analysis, a mixed-methods approach is employed, combining quantitative data analysis and qualitative feedback from HR professionals. The study presents empirical evidence demonstrating the benefits of AI technologies in improving decision-making accuracy, efficiency, and fairness. Key Index Terms: Digital AI-enabled interview analysis, Hiring process, Decision-making, Interview data analysis, Natural language processing (NLP), Machine learning algorithms, Candidate selection, Workforce composition, Objective decision-making, Hidden patterns, Linguistic cues.",
    "doi": "10.55041/ijsrem24357",
    "url": "https://www.semanticscholar.org/paper/9cf847bebe4df29a0ecbb66d2ad55641be51bc1d",
    "pdf_url": "https://ijsrem.com/download/ai-enabled-interview-analysis-unveiling-insights-and-enhancing-decision-making-in-human-resource-management/?wpdmdl=22150&refresh=65645571a76171701074289",
    "venue": "INTERANTIONAL JOURNAL OF SCIENTIFIC RESEARCH IN ENGINEERING AND MANAGEMENT",
    "citation_count": 2,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424970"
  },
  {
    "source": "semantic_scholar",
    "source_id": "243288f6e1040bd45c539010754d0eb21a231642",
    "title": "The Impact of Big Data and Artificial Intelligence (AI) in the Insurance Sector",
    "authors": [],
    "year": 2020,
    "abstract": "The other guideline comes from the European Commission\u2019s Independent High-Level Expert Group on Artificial Intelligence (HLAG AI), Ethics Guidelines for Trustworthy AI (High-Level Expert Group on Artificial Intelligence, 2019 [39] ). The assessment list included in the Guidelines is undergoing a pilot phase. The HLEG AI\u2019s Guidelines are more focussed on ethics related issues, and due to this is more specific on the nature of AI and how it should be developed. It is in fact derived from four ethical principles, which are rooted in fundamental rights: respect for human autonomy, prevention of harm, fairness and explicability (High-Level Expert Group on Artificial Intelligence, 2019 [39] ).",
    "doi": "10.1787/c822ee53-en",
    "url": "https://www.semanticscholar.org/paper/243288f6e1040bd45c539010754d0eb21a231642",
    "pdf_url": "",
    "venue": "",
    "citation_count": 34,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.424974"
  },
  {
    "source": "semantic_scholar",
    "source_id": "1c3a17f0729e3a37c876a54493f3d9a202a62cec",
    "title": "Dataset-centric AI ethics classification",
    "authors": [
      "Aditya Kartik",
      "Surya Raj",
      "Akash Rattan",
      "Deepti Sahu"
    ],
    "year": 2025,
    "abstract": null,
    "doi": "10.1007/s43681-025-00904-4",
    "url": "https://www.semanticscholar.org/paper/1c3a17f0729e3a37c876a54493f3d9a202a62cec",
    "pdf_url": "",
    "venue": "AI and Ethics",
    "citation_count": 0,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424984"
  },
  {
    "source": "semantic_scholar",
    "source_id": "f3d70d31b306ccb32564efde379701be7f43e12e",
    "title": "How to Make an Artificial Intelligence Algorithm \u201cEcological\u201d? Insights from a holistic perspective",
    "authors": [
      "Tania Di Mascio",
      "Federica Caruso",
      "Sara Peretti"
    ],
    "year": 2023,
    "abstract": "Nowadays, Artificial Intelligence is growing in many daily activities. On the one hand, it has many positive effects and produces social benefits. On the other hand, its development and deployment raise issues related to biases, such as gender, disability, and culture. Moreover, Artificial Intelligence\u2019s growing autonomy in decision-making could lead to decisions that conflict with human values or harm individuals and society. These issues stem from biased or incomplete datasets and a lack of transparency and accountability in the algorithms. Consequently, paying increasing attention to the ongoing discourse on Artificial Intelligence ethics: its autonomy in decision-making, and biases is necessary. A human-centric approach is a minimum requirement for designing algorithms since this approach is aligned with human values, dignity, and goals. Notwithstanding, its application does not guarantee a deep understanding of the context of use. According to recent theoretical perspectives, a deep interpretation of the context of use (i.e., a holistic perspective) could better regulate ethical aspects. This paper goes in this direction, presenting a human-centric and ecological approach as a design methodology. It has been experienced within Use Case 6 of the European FRACTAL project, which aims to develop intelligent totems for advertising and customer assistance in sentient shopping malls. The intelligence is realized by several artificial intelligent algorithms (e.g., gender recognition algorithms). By adopting Bronfenbrenner\u2019s ecological approach, algorithms were made free from gender bias, mirroring the context of men\u2019s and women\u2019s use at shopping malls as it is currently, i.e., characterized by gender balance. This proposal contributes to the ongoing discourse on Artificial Intelligence ethics and the development of its ethical algorithms.",
    "doi": "10.1145/3605390.3605398",
    "url": "https://www.semanticscholar.org/paper/f3d70d31b306ccb32564efde379701be7f43e12e",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3605390.3605398",
    "venue": "ACM SIGCHI Italian Chapter International Conference on Computer-Human Interaction",
    "citation_count": 2,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:02.424988"
  },
  {
    "source": "semantic_scholar",
    "source_id": "e7571ee537d3aa0906737666affc24b81583931e",
    "title": "Algorithmic Human Resource Management: Characteristics, Possibilities and Challenges",
    "authors": [
      "Goran Pavlovi\u0107"
    ],
    "year": 2023,
    "abstract": "In the field of human resources, algorithmic management refers to the utilization of digital technology, artificial intelligence, and big data to de\u00advelop rules and procedures that enable the automated management of hu\u00adman resources. Algorithmic human resource management can potentially re\u00adplace human resource managers in all stages and activities of staffing, there\u00adby significantly expediting the management process and enhancing cost-ef\u00adfectiveness. Through the use of artificial intelligence, algorithms develop pat\u00adterns and models from which they can autonomously learn and improve the quality of decision-making in employee management. However, relying ex\u00adclusively on algorithmic human resource management can lead to the emer\u00adgence of discriminatory management practices, particularly when the algo\u00adrithms are based on unrepresentative or biased data. Considering these fac\u00adtors, this paper aims to examine the fundamental characteristics, princi\u00adples, application possibilities, and challenges of algorithmic human resource management.",
    "doi": "10.31410/eraz.s.p.2023.147",
    "url": "https://www.semanticscholar.org/paper/e7571ee537d3aa0906737666affc24b81583931e",
    "pdf_url": "https://doi.org/10.31410/eraz.s.p.2023.147",
    "venue": "ERAZ Conference \u2013 Knowlegde Based Sustainable Development: Vol 9. Selected Papers",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.425015"
  },
  {
    "source": "semantic_scholar",
    "source_id": "1cb8f64757de8dd6a608271890a754a12fccb1ff",
    "title": "Legal and ethical principles governing the use of artificial intelligence in radiology services in South Africa",
    "authors": [
      "Irvine Sihlahla",
      "D. Donnelly",
      "B. Townsend",
      "D. Thaldar"
    ],
    "year": 2023,
    "abstract": "Abstract Artificial intelligence (AI) will drastically change the healthcare system. Radiology is one speciality that is most affected as AI algorithms are increasingly used in diagnostic imaging. AI\u2010enhanced health technologies will, inter alia, increase workflow efficiency, improve diagnostic accuracy, reduce healthcare\u2010related costs, and help alleviate medical personnel shortages in under\u2010resourced settings. However, the development of AI\u2010enhanced technologies in healthcare is fraught with legal, ethical, and human rights concerns. Currently, the use of AI in South African healthcare is not governed by sui generis legislation or ethical guidance focused exclusively and specifically on AI, although various provisions and principles from law and ethics find application. This article outlines these normative principles and explains their relationship with the extant legal obligations and regulatory framework as applied to the use of AI in radiology services in South Africa. The article concludes with three key recommendations for radiology practitioners using AI in South Africa. These are the need for: vigilant monitoring of AI use in practice, reforms to the liability framework, and appropriate guidance from local regulators and the Health Professions Council of South Africa on the ethical use of AI.",
    "doi": "10.1111/dewb.12436",
    "url": "https://www.semanticscholar.org/paper/1cb8f64757de8dd6a608271890a754a12fccb1ff",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/dewb.12436",
    "venue": "Developing World Bioethics",
    "citation_count": 10,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:02.425019"
  },
  {
    "source": "semantic_scholar",
    "source_id": "ce57a21482fb66664fe89420d5396c2a13c704f3",
    "title": "A theoretical model of AI bias mitigation: incentives, regulation and equilibrium",
    "authors": [
      "Subhasis Bera",
      "Ishita Bera"
    ],
    "year": 2025,
    "abstract": "\n \n This study aims to develop a conceptual economic model to analyse bias in artificial intelligence (AI), decomposing it into functionality bias (arising from data and algorithms) and usage bias (stemming from user incentives). It explores how these biases interact and emerge endogenously in economic systems, proposing a cost-constrained optimisation framework for mitigation.\n \n \n \n A mathematical optimisation model is formulated to minimise total bias, accounting for data curation costs, regulatory penalties and audit expenses. The model derives equilibrium conditions under which bias mitigation is cost-effective and identifies thresholds beyond which interventions fail.\n \n \n \n Reducing usage bias enhances the effectiveness of functionality bias mitigation, creating a cascading fairness effect. High regulatory costs without incentive alignment can discourage mitigation, emphasising the need for balanced interventions. The model highlights the cost-fairness trade-offs and suggests critical thresholds for policy action.\n \n \n \n The theoretical conceptual model is static; future work should explore dynamic extensions and conduct empirical validation to enhance its applicability. Nonetheless, it provides a quantitative foundation linking AI ethics with economic policymaking.\n \n \n \n Firms and policymakers can use the conceptual model to evaluate cost-efficient strategies for mitigating bias, particularly through early-stage interventions and the design of usage incentives.\n \n \n \n The study emphasises the importance of fairness in AI as both a technical and socioeconomic objective, essential for achieving equitable outcomes in areas such as finance, employment and public services.\n \n \n \n Unlike prior approaches that treat fairness as exogenous, this study endogenises bias within an economic decision framework, presenting a novel lens to address AI fairness as a constrained optimisation problem.\n",
    "doi": "10.1108/jices-06-2025-0138",
    "url": "https://www.semanticscholar.org/paper/ce57a21482fb66664fe89420d5396c2a13c704f3",
    "pdf_url": "",
    "venue": "Journal of Information, Communication and Ethics in Society",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.425023"
  },
  {
    "source": "semantic_scholar",
    "source_id": "7022dabf81143d3cb6e2eb538373694870400c28",
    "title": "Impact of Artificial Intelligence on Decision-making in Organisations",
    "authors": [
      "Chandana Charitha",
      "B. Hemaraju"
    ],
    "year": 2023,
    "abstract": "The use of artificial intelligence (AI) in decision-making processes has emerged as a key organizational development driver in the modern, dynamic commercial environment. This case study investigates the broad implications, difficulties, and transformative possibilities of intelligence in corporate decision-making.\nWe discover how applying data analysis, pattern recognition, and artificial intelligence can increase decision-making and accuracy using an integrated strategy. Real-world examples from a variety of industries demonstrate how AI-driven decision-making can boost productivity, lower risk, and encourage innovation.\nHowever, as businesses use AI to its full potential, ethical issues become more crucial.\nThese days, factors including algorithmic bias, data privacy worries, and the demand for human attention must be carefully considered. This paper discusses this intricacy and emphasizes the significance of integrating ethical AI.\ngot an endorsement from 250 workers utilizing a Google Docs study paper. The results illustrated the advantages and difficulties experienced by professionals directly involved in AI-driven decision-making.\nFinally, this study shows how AI has advanced beyond efficiency to develop models for business decision-making.\nOrganizations may overcome obstacles and maximize their potential to advance to a time when AI and people will share a common intelligence in decision-making by understanding the function and ethics of AI.",
    "doi": "10.36948/ijfmr.2023.v05i04.5172",
    "url": "https://www.semanticscholar.org/paper/7022dabf81143d3cb6e2eb538373694870400c28",
    "pdf_url": "https://www.ijfmr.com/papers/2023/4/5172.pdf",
    "venue": "International Journal For Multidisciplinary Research",
    "citation_count": 8,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.425026"
  },
  {
    "source": "semantic_scholar",
    "source_id": "e463c3f4c0a60de71bb1791f1877cfc81cf1dfb6",
    "title": "Artificial Intelligence and the Rule of Law",
    "authors": [
      "Aziz Z Huq"
    ],
    "year": 2021,
    "abstract": "This book chapter examines an interaction between technological shocks and the \u201crule of law.\u201d It does so by analyzing the implications of a class of loosely related computational technologies termed \u201cmachine learning\u201d (ML) or, rather less precisely \u201cartificial intelligence\u201d (AI). These tools are presently employed in the pre-adjudicative phase of enforcing of the laws, for example facilitating the selection of targets for tax and regulatory investigations. \n \nTwo general questions respecting the rule of law arise from these developments. The more immediately apparent one is whether these technologies, when integrated into the legal system, are themselves compatible or in conflict with the rule of law. Depending on which conception of the rule of law is deployed, the substitution of machine decision-making for human judgment can kindle objections based on transparency, predictability, bias, and procedural fairness. A first purpose of this chapter is to examine ways in which this technological shock poses such challenges. The interaction between the normative ambitions of the rule of law and ML technologies, I will suggest, is complex and ambiguous. In many cases, moreover, the more powerful normative objection to technology arises less from the bare fact of its objection, and more from the socio-political context in which that adoption occurred and the dynamic effect of technology on background disparities of power and resources. ML\u2019s adoption likely exacerbates differences of social power and status in ways that place the rule of law under strain. \n \nThe second question posed by new AI and ML technologies has also not been extensively discussed. Yet it is perhaps of more profound significance. Rather than focusing on the compliance of new technologies with rule-of-law values, it hinges on the implications of ML and AI technologies for how the rule of law itself is conceived or implemented. Many of the canonical discussions of the rule of law\u2014including Dicey\u2019s and Waldron\u2019s\u2014entangle a conceptual definition and a series of institutional entailments. Many assume that the rule of law requires the specific institutional form of courts. They presumably also posit human judges exercising discretion and making judgments as necessary rather than optional. For these institutional entailments of the rule of law, a substitution of human for ML technologies likely has destabilizing implications. It sharpens the question whether the abstract concept of the rule of law needs to be realized by a particular institutional form. It raises a question whether instead technological change might demand amendments to relationship between the concept(s) and the practice of the rule of law. For pre-existing normative concepts and their practical, institutional correlates may no longer hold under conditions of technological change. At the very least then, specification of institutional forms of the rule of law under such conditions raises challenges not just as a practical matter but also in terms of legal theory",
    "doi": "10.2139/SSRN.3794777",
    "url": "https://www.semanticscholar.org/paper/e463c3f4c0a60de71bb1791f1877cfc81cf1dfb6",
    "pdf_url": "https://chicagounbound.uchicago.edu/cgi/viewcontent.cgi?article=2194&context=public_law_and_legal_theory",
    "venue": "Social Science Research Network",
    "citation_count": 15,
    "fields_of_study": [
      "Economics"
    ],
    "retrieved_at": "2026-02-02T16:58:02.425030"
  },
  {
    "source": "semantic_scholar",
    "source_id": "5049ef4ba5d8c373580f3f9cb5f3bbc725d617a6",
    "title": "A Vision for Digitizing Judicial Processes and Integrating Artificial Intelligence in Pakistan\u2019s Judiciary: Enhancing Efficiency and Upholding Judicial Integrity",
    "authors": [
      "Faiza Khalil"
    ],
    "year": 2024,
    "abstract": "The judiciary, as the cornerstone of justice and the rule of law, is at a pivotal juncture to harness the transformative power of digital technology and artificial intelligence (AI) to enhance its operations. This essay outlines a comprehensive approach for digitizing judicial processes in Pakistan, incorporating AI integration by drawing parallels with successful international model. The focus is on the need for systemic change to ensure efficiency, transparency, and accessibility in the legal system. Current challenges include a lack of proper implementation of the rule of law, prolonged trials, and low public confidence. Traditional methods of case filing are manual and paper-based, leading to inefficiencies. The essay proposes a step-by-step transformation starting from e-filing to the digitization of the entire lifecycle of a case, aiming to modernize Pakistan\u2019s judiciary. AI can aid in legal research, evidence standards, and sentencing, offering predictive capabilities and streamlining routine case management. Ethical considerations and the need for human judicial discretion are emphasized to balance AI\u2019s assistance with maintaining judicial integrity and fairness. This digital transformation can restore public trust and efficiency in Pakistan\u2019s judiciary, paving the way for a modern, digital legal system. Keywords: Technological Integration in Courts, Predictive Analytics in Law, Transparency in Judicial Processes, Judicial Modernization, Artificial Intelligence in Judiciary, Digital transformation, AI and Legal Ethics, Case Management Systems, E-Filing, Legal Tech Innovation, AI in Legal Research, Efficiency in Judiciary, AI and Evidence Standards, AI in Sentencing, Legal Information Systems",
    "doi": "10.55574/rzhl8875",
    "url": "https://www.semanticscholar.org/paper/5049ef4ba5d8c373580f3f9cb5f3bbc725d617a6",
    "pdf_url": "",
    "venue": "International Journal of Law, Ethics, and Technology",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.425033"
  },
  {
    "source": "semantic_scholar",
    "source_id": "970069616c73a86c10b328c04a43644132cad22f",
    "title": "We\u2019re Missing a Moral Framework of Justice in Artificial Intelligence",
    "authors": [
      "Matthew Le Bui",
      "S. Noble"
    ],
    "year": 2020,
    "abstract": "This chapter assesses the concepts of fairness and bias in artificial intelligence research and interventions. In considering the explosive growth, emergence of, and investment in high-profile AI fairness and ethics interventions within both the academy and industry\u2014alongside the mounting and proliferating calls for the interrogation, regulation, and, in some cases, dismantling and prohibition of AI\u2014it contests and questions the extent to which such remedies can address the original concerns and problems they are designed to address. Indeed, many community organizations are organizing responses and challenging AI used in predictive technologies\u2014facial-recognition software and biometrics technologies\u2014with increasing success. Ultimately, the canon of AI ethics must interrogate and deeply engage with intersectional power structures that work to further consolidate capital in the hands of the elites and that will undergird digital informational systems of inequality: there is no neutral or objective state through which the flows and mechanics of data can be articulated as unbiased or fair.",
    "doi": "10.1093/oxfordhb/9780190067397.013.9",
    "url": "https://www.semanticscholar.org/paper/970069616c73a86c10b328c04a43644132cad22f",
    "pdf_url": "",
    "venue": "",
    "citation_count": 41,
    "fields_of_study": [
      "Sociology"
    ],
    "retrieved_at": "2026-02-02T16:58:02.425037"
  },
  {
    "source": "semantic_scholar",
    "source_id": "ebcc6034b8b561964b5a047dd4bee1483047d6e7",
    "title": "ARTIFICIAL INTELLIGENCE AND THE RULE OF LAW: A CRITICAL APPRAISAL OF A DEVELOPING SECTOR",
    "authors": [
      "Syed Hassan Gilani",
      "Nabila Rauf",
      "Shehla Zahoor"
    ],
    "year": 2023,
    "abstract": "Artificial intelligence has become increasingly prevalent in our daily lives and has the potential to transform many areas of society, including the legal system. While AI has the potential to support the rule of law, it also poses significant challenges and risks, particularly around bias and discrimination. To ensure that AI is compatible with the rule of law, it is essential to take a holistic and interdisciplinary approach that considers the legal, ethical, social, and technical dimensions of AI. This involves designing and using AI systems in a way that is transparent, accountable, fair, and compliant with the law, as well as engaging with diverse stakeholders. Ensuring that AI is compatible with the rule of law is critical for promoting the values of justice, equality, and human rights in the digital age and for building a more just and equitable society. Keywords: Rule of Law, Artificial intelligence, Law enforcement.",
    "doi": "10.52567/pjsr.v5i02.1156",
    "url": "https://www.semanticscholar.org/paper/ebcc6034b8b561964b5a047dd4bee1483047d6e7",
    "pdf_url": "https://ojs.pjsr.com.pk/index.php/PJSR/article/download/1156/805",
    "venue": "Pakistan Journal of Social Research",
    "citation_count": 4,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.425041"
  },
  {
    "source": "semantic_scholar",
    "source_id": "c2e910f50e22be234152f633a94a11c7e93f8f89",
    "title": "Legal aspects of artificial intelligence in the employment process",
    "authors": [
      "Helga \u0160padina"
    ],
    "year": 2023,
    "abstract": "The introduction of artificial intelligence in all domains of life is the most transformative process in recent history. It is also a highly dynamic process, and due to the pace of technological development, a very limited legal framework is available to address issues of human rights, ethics, transparency, privacy, safety and accountability. During the last few years, artificial intelligence started to reshape employment processes. Positive aspects of the introduction of AI in the employment process are efficiency and quality in job matching, digitalisation and acceleration of the process, ability to process large data and match job seekers to available vacancy announcements, the alleviation of administrative burdens of employees of employment agencies and giving them strategic and innovative roles. All these are indispensable in present times when demographic challenges in European countries are leading to increased labour migrations and require changes in the recruitment process. The paper explores the current challenges of AI, i.e. how to achieve human-centred values and fairness of AI use during the employment process, preventing algorithmic bias and discriminatory application of AI tools. In order to harness the maximum benefits of AI, we need to develop a regulatory framework that would be enforceable, inclusive and adaptive (OECD), particularly knowing that most AI solutions are privately owned and developed for commercial purposes.\u00a0\u00a0\u00a0",
    "doi": "10.59954/stnv.546",
    "url": "https://www.semanticscholar.org/paper/c2e910f50e22be234152f633a94a11c7e93f8f89",
    "pdf_url": "https://stnv.idn.org.rs/STNV/article/download/546/518",
    "venue": "Stanovni\u0161tvo",
    "citation_count": 4,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:02.425044"
  },
  {
    "source": "semantic_scholar",
    "source_id": "746dd0ed2004e8ac6d7084e1e671eccefec3fb85",
    "title": "Evaluating the prospects for university-based ethical governance in artificial intelligence and data-driven innovation",
    "authors": [
      "C. Hine"
    ],
    "year": 2021,
    "abstract": "There has been considerable debate around the ethical issues raised by data-driven technologies such as artificial intelligence. Ethical principles for the field have focused on the need to ensure that such technologies are used for good rather than harm, that they enshrine principles of social justice and fairness, that they protect privacy, respect human autonomy and are open to scrutiny. While development of such principles is well advanced, there is as yet little consensus on the mechanisms appropriate for ethical governance in this field. This paper examines the prospects for the university ethics committee to undertake effective review of research conducted on data-driven technologies in the university context. Challenges identified include: the relatively narrow focus of university-based ethical review on the human subjects research process and lack of capacity to anticipate downstream impacts; the difficulties of accommodating the complex interplay of academic and commercial interests in the field; and the need to ensure appropriate expertise from both specialists and lay voices. Overall, the challenges identified sharpen appreciation of the need to encourage a joined-up and effective system of ethical governance that fosters an ethical culture rather than replacing ethical reflection with bureaucracy.",
    "doi": "10.1177/17470161211022790",
    "url": "https://www.semanticscholar.org/paper/746dd0ed2004e8ac6d7084e1e671eccefec3fb85",
    "pdf_url": "https://journals.sagepub.com/doi/pdf/10.1177/17470161211022790",
    "venue": "Research Ethics",
    "citation_count": 13,
    "fields_of_study": [
      "Political Science"
    ],
    "retrieved_at": "2026-02-02T16:58:02.425048"
  },
  {
    "source": "semantic_scholar",
    "source_id": "bbdad642a48f66f3216a79987c385d5daf2de95e",
    "title": "Ethical Implications of Artificial Intelligence in the Healthcare Sector",
    "authors": [
      "Nutifafa Cudjoe Amedior"
    ],
    "year": 2023,
    "abstract": "This research paper examines the ethical implications of AI in healthcare, covering the benefits and risks of using AI in healthcare services and provision. The paper highlights the applications of AI in healthcare, which can improve efficiency and accuracy of providing healthcare services by health professionals. The benefits of AI cover reducing the need for human intervention and increasing productivity through automation, delivering personalised experiences by recommendations, assisting with informed decision-making by providing real-time data analysis and insights, predicting outcomes or identifying potential threats, improving healthcare and overall customer satisfaction. The paper highlights the ethical implications of the use of AI in healthcare, including privacy and security, bias and discrimination, transparency and explainability, responsibility and accountability, informed consent and human interaction and empathy. The paper recommends that as AI becomes more prevalent in healthcare, establishing clear guidelines for responsible use, and maintaining the importance of human interaction and empathy in patient care, enhances healthcare outcomes while safeguarding patient rights and welfare. Continued research and development of the ethical implications of AI in healthcare for low-income countries as further work can promote the ethical use of AI in healthcare worldwide. Keywords: Artificial Intelligence, Ethics, Ethical Implication, Healthcare, Privacy Proceedings Citation Format Amedior, N.C. Nutifafa Cudjoe Amedior (2022): Ethical Implications of Artificial Intelligence in the Healthcare Sector. Proceedings of the 36th iSTEAMS Accra Bespoke Multidisciplinary Innovations Conference. University of Ghana/Academic City University College, Accra, Ghana. 31st May \u2013 2nd June, 2023. Pp 1-12 www.isteams.net/ecowasetech2022. dx.doi.org/10.22624/AIMS-/ACCRABESPOKE2023P1",
    "doi": "10.22624/aims-/accrabespoke2023p1",
    "url": "https://www.semanticscholar.org/paper/bbdad642a48f66f3216a79987c385d5daf2de95e",
    "pdf_url": "",
    "venue": "Advances in Multidisciplinary & Scientific Research Journal Publication",
    "citation_count": 16,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586654"
  },
  {
    "source": "semantic_scholar",
    "source_id": "d1d7e2acf6f1ee6054b02f0aafbe17dd076b9032",
    "title": "Artificial intelligence for diagnosing exudative age-related macular degeneration.",
    "authors": [
      "Chae-Yeong Kang",
      "John C. Lin",
      "Helen Zhang",
      "I. Scott",
      "Jayashree Kalpathy-Cramer",
      "Su-Hsun Liu",
      "P. Greenberg"
    ],
    "year": 2024,
    "abstract": "BACKGROUND\nAge-related macular degeneration (AMD) is a retinal disorder characterized by central retinal (macular) damage. Approximately 10% to 20% of non-exudative AMD cases progress to the exudative form, which may result in rapid deterioration of central vision. Individuals with exudative AMD (eAMD) need prompt consultation with retinal specialists to minimize the risk and extent of vision loss. Traditional methods of diagnosing ophthalmic disease rely on clinical evaluation and multiple imaging techniques, which can be resource-consuming. Tests leveraging artificial intelligence (AI) hold the promise of automatically identifying and categorizing pathological features, enabling the timely diagnosis and treatment of eAMD.\n\n\nOBJECTIVES\nTo determine the diagnostic accuracy of artificial intelligence (AI) as a triaging tool for exudative age-related macular degeneration (eAMD).\n\n\nSEARCH METHODS\nWe searched CENTRAL, MEDLINE, Embase, three clinical trials registries, and Data Archiving and Networked Services (DANS) for gray literature. We did not restrict searches by language or publication date. The date of the last search was April 2024.\n\n\nSELECTION CRITERIA\nIncluded studies compared the test performance of algorithms with that of human readers to detect eAMD on retinal images collected from people with AMD who were evaluated at eye clinics in community or academic medical centers, and who were not receiving treatment for eAMD when the images were taken. We included algorithms that were either internally or externally validated or both.\n\n\nDATA COLLECTION AND ANALYSIS\nPairs of review authors independently extracted data and assessed study quality using the Quality Assessment of Diagnostic Accuracy Studies-2 (QUADAS-2) tool with revised signaling questions. For studies that reported more than one set of performance results, we extracted only one set of diagnostic accuracy data per study based on the last development stage or the optimal algorithm as indicated by the study authors. For two-class algorithms, we collected data from the 2x2 table whenever feasible. For multi-class algorithms, we first consolidated data from all classes other than eAMD before constructing the corresponding 2x2 tables. Assuming a common positivity threshold applied by the included studies, we chose random-effects, bivariate logistic models to estimate summary sensitivity and specificity as the primary performance metrics.\n\n\nMAIN RESULTS\nWe identified 36 eligible studies that reported 40 sets of algorithm performance data, encompassing over 16,000 participants and 62,000 images. We included 28 studies (78%) that reported 31 algorithms with performance data in the meta-analysis. The remaining nine studies (25%) reported eight algorithms that lacked usable performance data; we reported them in the qualitative synthesis. Study characteristics and risk of bias Most studies were conducted in Asia, followed by Europe, the USA, and collaborative efforts spanning multiple countries. Most studies identified study participants from the hospital setting, while others used retinal images from public repositories; a few studies did not specify image sources. Based on four of the 36 studies reporting demographic information, the age of the study participants ranged from 62 to 82 years. The included algorithms used various retinal image types as model input, such as optical coherence tomography (OCT) images (N = 15), fundus images (N = 6), and multi-modal imaging (N = 7). The predominant core method used was deep neural networks. All studies that reported externally validated algorithms were at high risk of bias mainly due to potential selection bias from either a two-gate design or the inappropriate exclusion of potentially eligible retinal images (or participants). Findings Only three of the 40 included algorithms were externally validated (7.5%, 3/40). The summary sensitivity and specificity were 0.94 (95% confidence interval (CI) 0.90 to 0.97) and 0.99 (95% CI 0.76 to 1.00), respectively, when compared to human graders (3 studies; 27,872 images; low-certainty evidence). The prevalence of images with eAMD ranged from 0.3% to 49%. Twenty-eight algorithms were reportedly either internally validated (20%, 8/40) or tested on a development set (50%, 20/40); the pooled sensitivity and specificity were 0.93 (95% CI 0.89 to 0.96) and 0.96 (95% CI 0.94 to 0.98), respectively, when compared to human graders (28 studies; 33,409 images; low-certainty evidence). We did not identify significant sources of heterogeneity among these 28 algorithms. Although algorithms using OCT images appeared more homogeneous and had the highest summary specificity (0.97, 95% CI 0.93 to 0.98), they were not superior to algorithms using fundus images alone (0.94, 95% CI 0.89 to 0.97) or multimodal imaging (0.96, 95% CI 0.88 to 0.99; P for meta-regression = 0.239). The median prevalence of images with eAMD was 30% (interquartile range [IQR] 22% to 39%). We did not include eight studies that described nine algorithms (one study reported two sets of algorithm results) to distinguish eAMD from normal images, images of other AMD, or other non-AMD retinal lesions in the meta-analysis. Five of these algorithms were generally based on smaller datasets (range 21 to 218 participants per study) yet with a higher prevalence of eAMD images (range 33% to 66%). Relative to human graders, the reported sensitivity in these studies ranged from 0.95 and 0.97, while the specificity ranged from 0.94 to 0.99. Similarly, using small datasets (range 46 to 106), an additional four algorithms for detecting eAMD from other retinal lesions showed high sensitivity (range 0.96 to 1.00) and specificity (range 0.77 to 1.00).\n\n\nAUTHORS' CONCLUSIONS\nLow- to very low-certainty evidence suggests that an algorithm-based test may correctly identify most individuals with eAMD without increasing unnecessary referrals (false positives) in either the primary or the specialty care settings. There were significant concerns for applying the review findings due to variations in the eAMD prevalence in the included studies. In addition, among the included algorithm-based tests, diagnostic accuracy estimates were at risk of bias due to study participants not reflecting real-world characteristics, inadequate model validation, and the likelihood of selective results reporting. Limited quality and quantity of externally validated algorithms highlighted the need for high-certainty evidence. This evidence will require a standardized definition for eAMD on different imaging modalities and external validation of the algorithm to assess generalizability.",
    "doi": "10.1002/14651858.CD015522.pub2",
    "url": "https://www.semanticscholar.org/paper/d1d7e2acf6f1ee6054b02f0aafbe17dd076b9032",
    "pdf_url": "",
    "venue": "Cochrane Database of Systematic Reviews",
    "citation_count": 9,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586671"
  },
  {
    "source": "semantic_scholar",
    "source_id": "a34d13f8ed40eea6de541c7198729a73ae871106",
    "title": "Investigating Fairness with FanFAIR: is Pre-Processing Useful Only for Performances?",
    "authors": [
      "Michele Rispoli",
      "M. S. Nobile",
      "L. Manzoni",
      "Alberto d'Onofrio",
      "M. Confalonieri",
      "F. Salton",
      "P. Confalonieri",
      "B. Ruaro",
      "Chiara Gallese"
    ],
    "year": 2025,
    "abstract": "Artificial Intelligence, and Machine Learning systems in general, are becoming pervasive in our society, from the industry to the public administration. AI can often provide a very efficient means to support decision-making, but it can represent a danger for high-risk applications such as bio-medicine and healthcare. In particular, biased datasets might lead to inaccurate or discriminatory ML systems, undermining the accuracy of their predictions and putting patients' health at risk. FanFAIR is a python tool that provides the community with a semi-automatic tool for datasets' fairness assessment. FanFAIR is designed to integrate qualitative considerations - such as ethics, human rights assessment, and data protection - with quantitative indicators of dataset's fairness, such as balance, the presence of invalid entries, or outliers. In this work, we extend FanFAIR to deal with categorical data, and introduce a new algorithm for outlier detection in the presence of missing values. We then provide a case study on the data collected from COVID patients admitted to pneumology departments in Italy. We show how the successive steps of data cleaning and variable selection improve the indicators provided by FanFAIR. This shows that data cleaning procedures are not only necessary to improve the performance of the machine learning algorithm using the data for learning, but are also a way to improve (a measure of) fairness. Hence, the proposed case study provides an example in which performance and fairness are not in contrast, like it is commonly believed to be, but they improve together.",
    "doi": "10.1109/CIHM64979.2025.10969477",
    "url": "https://www.semanticscholar.org/paper/a34d13f8ed40eea6de541c7198729a73ae871106",
    "pdf_url": "",
    "venue": "2025 IEEE Symposium on Computational Intelligence in Health and Medicine (CIHM)",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586677"
  },
  {
    "source": "semantic_scholar",
    "source_id": "b919566c424d2f2d342366f63a87b89c3ea590bd",
    "title": "The role of artificial intelligence in higher medical education and the ethical challenges of its implementation",
    "authors": [
      "Mark Perkins",
      "A. Pregowska"
    ],
    "year": 2024,
    "abstract": "Artificial intelligence (AI) is penetrating higher medical education; however, its adoption remains low. A PRISMA-S search of the Web of Science database from 2020 to 2024, utilizing the search terms \u201cartificial intelligence,\u201d \u201cmedicine,\u201d \u201ceducation,\u201d and \u201cethics,\u201d reveals this trend. Four key areas of AI application in medical education are examined for their potential benefits: Educational support (such as personalized distance education), radiology (diagnostics), virtual reality (VR) (visualization and simulations), and generative text engines (GenText), such as ChatGPT (from the production of notes to syllabus design). However, significant ethical risks accompany AI adoption, and specific concerns are linked to each of these four areas. While AI is recognized as an important support tool in medical education, its slow integration hampers learning and diminishes student motivation, as evidenced by the challenges in implementing VR. In radiology, data-intensive training is hindered by poor connectivity, particularly affecting learners in developing countries. Ethical risks, such as bias in datasets (whether intentional or unintentional), need to be highlighted within educational programs. Students must be informed of the possible motivation behind the introduction of social and political bias in datasets, as well as the profit motive. Finally, the ethical risks accompanying the use of GenText are discussed, ranging from student reliance on instant text generation for assignments, which can hinder the development of critical thinking skills, to the potential danger of relying on AI-generated learning and treatment plans without sufficient human moderation.",
    "doi": "10.36922/aih.3276",
    "url": "https://www.semanticscholar.org/paper/b919566c424d2f2d342366f63a87b89c3ea590bd",
    "pdf_url": "https://doi.org/10.36922/aih.3276",
    "venue": "Artificial Intelligence in Health",
    "citation_count": 7,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586681"
  },
  {
    "source": "semantic_scholar",
    "source_id": "aa6fb2528d5fa16e11b885926136985d9ad9adc4",
    "title": "Ethics methods are required as part of reporting guidelines for artificial intelligence in healthcare",
    "authors": [
      "V. Sounderajah",
      "Melissa McCradden",
      "Xiaoxuan Liu",
      "S. Rose",
      "H. Ashrafian",
      "G. Collins",
      "James A. Anderson",
      "P. Bossuyt",
      "D. Moher",
      "A. Darzi"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1038/s42256-022-00479-3",
    "url": "https://www.semanticscholar.org/paper/aa6fb2528d5fa16e11b885926136985d9ad9adc4",
    "pdf_url": "",
    "venue": "Nature Machine Intelligence",
    "citation_count": 12,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586686"
  },
  {
    "source": "semantic_scholar",
    "source_id": "52a7ba5d2ea652ad99efe7ee89a0e168e3d80acc",
    "title": "Artificial Intelligence in Education Management: Opportunities, Challenges, and Solutions",
    "authors": [
      "Tong Feng",
      "Qinglun Li"
    ],
    "year": 2024,
    "abstract": "Education management, as an integral part of management science, encompasses core functions such as organizing, planning, coordinating, and controlling educational resources, which closely align with the management concepts used in business administration. Whether in the field of education or business, managers need to improve organizational performance through effective strategy development, resource allocation, and decision-making support. The emergence of Artificial Intelligence (AI) has profoundly transformed several industries, and its impact on education is progressively gaining prominence.This paper explores the opportunities, challenges, and solutions associated with the integration of AI in the education sector. AI offers substantial benefits such as personalized learning experiences, automated educational management, and global access to shared educational resources, revolutionizing the traditional educational landscape. However, its application also presents significant challenges, including concerns over data privacy, the widening of the digital divide, and the evolving role of teachers.Through an analysis of both opportunities and challenges, this paper emphasizes the need for strategic measures to ensure the ethical and equitable use of AI in education. These measures include stronger policy frameworks for data protection, comprehensive teacher training programs for AI integration, and the promotion of global cooperation to bridge technological gaps in underdeveloped regions. Furthermore, the paper projects the potential future developments in AI-driven education, highlighting the importance of balancing technology with human interaction in the learning environment.By addressing both the benefits and risks associated with AI, this paper provides actionable insights for educators, policymakers, and technologists, aimed at creating a more inclusive, efficient, and innovative educational system. Future research should continue to examine AI's ethical implications and strive for solutions that ensure education remains accessible and fair in an increasingly AI-driven world.",
    "doi": "10.54097/raxsbp45",
    "url": "https://www.semanticscholar.org/paper/52a7ba5d2ea652ad99efe7ee89a0e168e3d80acc",
    "pdf_url": "",
    "venue": "Frontiers in Business, Economics and Management",
    "citation_count": 4,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586690"
  },
  {
    "source": "semantic_scholar",
    "source_id": "36471e7feabbe035c94d0a263444f3b76e5774b2",
    "title": "A Comprehensive Study on Bias in Artificial Intelligence Systems: Biased or Unbiased AI, That's the Question!",
    "authors": [
      "Elif Kartal Karatas"
    ],
    "year": 2022,
    "abstract": "Humans are social beings. Emotions, like their thoughts, play an essential role in decision-making. Today, artificial intelligence (AI) raises expectations for faster, more accurate, more rational, and fairer decisions with technological advancements. As a result, AI systems have often been seen as an ideal decision-making mechanism. But what if these systems decide against you based on gender, race, or other characteristics? Biased or unbiased AI, that's the question! The motivation of this study is to raise awareness among researchers about bias in AI and contribute to the advancement of AI studies and systems. As the primary purpose of this study is to examine bias in the decision-making process of AI systems, this paper focused on (1) bias in humans and AI, (2) the factors that lead to bias in AI systems, (3) current examples of bias in AI systems, and (4) various methods and recommendations to mitigate bias in AI systems.",
    "doi": "10.4018/ijiit.309582",
    "url": "https://www.semanticscholar.org/paper/36471e7feabbe035c94d0a263444f3b76e5774b2",
    "pdf_url": "https://doi.org/10.4018/ijiit.309582",
    "venue": "International Journal of Intelligent Information Technologies",
    "citation_count": 10,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586694"
  },
  {
    "source": "semantic_scholar",
    "source_id": "38fa4ae849033386b515bc14ccbdcc39afcf5bfd",
    "title": "The comparative ethics of artificial-intelligence methods for military applications",
    "authors": [
      "N. Rowe"
    ],
    "year": 2022,
    "abstract": "Concerns about the ethics of the use of artificial intelligence by militaries have insufficiently addressed the differences between the methods (algorithms) that such software provides. These methods are discussed and key differences are identified that affect their ethical military use, most notably for lethal autonomous systems. Possible mitigations of ethical problems are discussed such as sharing decision-making with humans, better testing of the software, providing explanations of what is being done, looking for biases, and putting explicit ethics into the software. The best mitigation in many cases is explaining reasoning and calculations to aid transparency.",
    "doi": "10.3389/fdata.2022.991759",
    "url": "https://www.semanticscholar.org/paper/38fa4ae849033386b515bc14ccbdcc39afcf5bfd",
    "pdf_url": "https://www.frontiersin.org/articles/10.3389/fdata.2022.991759/pdf",
    "venue": "Frontiers in Big Data",
    "citation_count": 10,
    "fields_of_study": [
      "Medicine",
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586698"
  },
  {
    "source": "semantic_scholar",
    "source_id": "99eb2faf2629e22717de14eb8210811f9f6d367f",
    "title": "A Narrative Review in Application of Artificial Intelligence in Forensic Science: Enhancing Accuracy in Crime Scene Analysis and Evidence Interpretation",
    "authors": [
      "Abirami Arthanari",
      "S. Raj",
      "Vignesh Ravindran"
    ],
    "year": 2025,
    "abstract": "\n \n \n This review examines the transformative potential of artificial intelligence (AI) in forensic science, emphasizing its applications in crime scene analysis, evidence interpretation, digital forensics, and forensic odontology. It highlights AI\u2019s ability to enhance accuracy, efficiency, and reliability while addressing ethical and practical challenges.\n \n \n \n A systematic search was conducted across PubMed, Web of Science, Scopus, and Google Scholar, complemented by manual reviews of key forensic journals and grey literature. The review included studies on AI applications in forensic odontology and other forensic domains published in the past decade. Predefined inclusion and exclusion criteria were applied, and duplicates were removed. Full-text reviews were conducted to ensure relevance, with disagreements resolved through consensus by a third reviewer to ensure rigor.\n \n \n \n AI has significantly enhanced forensic practices by automating evidence analysis and improving accuracy. It streamlines crime scene reconstruction, accelerates digital forensic processes by analyzing large datasets, and advances dental forensics through rapid victim identification and bite mark analysis. AI-powered biometric systems enhance suspect and victim identification through facial recognition and pattern-matching technologies. However, limitations such as algorithmic bias, data privacy issues, and resource disparities pose challenges to its widespread adoption.\n \n \n \n AI is revolutionizing forensic science by providing enhanced precision, efficiency, and reliability in investigations. Addressing ethical concerns such as transparency, fairness, and algorithmic accountability is crucial for its responsible implementation. Future advancements should prioritize the development of explainable and unbiased algorithms, privacy-preserving techniques, and ethical frameworks. Interdisciplinary collaborations and global policy guidelines are essential to ensure the equitable and responsible integration of AI in forensic science, ultimately advancing justice and equity in the criminal justice system.\n",
    "doi": "10.4103/jioh.jioh_162_24",
    "url": "https://www.semanticscholar.org/paper/99eb2faf2629e22717de14eb8210811f9f6d367f",
    "pdf_url": "",
    "venue": "Journal of International Oral Health",
    "citation_count": 6,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586702"
  },
  {
    "source": "semantic_scholar",
    "source_id": "edf7e51ec5cb32b47c9b11cede8308b252dd8eb3",
    "title": "Safely advancing a spacefaring humanity with artificial intelligence",
    "authors": [
      "C. Richards",
      "Tom Cernev",
      "A. Tzachor",
      "G. Zilgalvis",
      "Bartu Kaleagasi"
    ],
    "year": 2023,
    "abstract": "A \u201cSpace Renaissance\u201d is underway. As our efforts to understand, utilize and settle space rapidly take new form, three distinct human-space interfaces are emerging, defined here as the \u201cEarth-for-space,\u201d \u201cspace-for-Earth\u201d and \u201cspace-for-space\u201d economies. Each engenders unprecedented opportunities, and artificial intelligence (AI) will play an essential role in facilitating innovative, accurate and responsive endeavors given the hostile, expansive and uncertain nature of extraterrestrial environments. However, the proliferation of, and reliance on, AI in this context is poised to aggravate existing threats and give rise to new risks, which are largely underappreciated, especially given the potential for great power competition and arms-race-type dynamics. Here, we examine possible beneficial applications of AI through the systematic prism of the three economies, including advancing the astronomical sciences, resource efficiency, technological innovation, telecommunications, Earth observation, planetary defense, mission strategy, human life support systems and artificial astronauts. Then we consider unintended and malicious risks arising from AI in space, which could have catastrophic consequences for life on Earth, space stations and space settlements. As a response to mitigate these risks, we call for urgent expansion of existing \u201cresponsible use of AI in space\u201d frameworks to address \u201cethical limits\u201d in both civilian and non-civilian space economy ventures, alongside national, bilateral and international cooperation to enforce mechanisms for robust, explainable, secure, accountable, fair and societally beneficial AI in space.",
    "doi": "10.3389/frspt.2023.1199547",
    "url": "https://www.semanticscholar.org/paper/edf7e51ec5cb32b47c9b11cede8308b252dd8eb3",
    "pdf_url": "https://www.frontiersin.org/articles/10.3389/frspt.2023.1199547/pdf",
    "venue": "Frontiers in Space Technologies",
    "citation_count": 4,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586706"
  },
  {
    "source": "semantic_scholar",
    "source_id": "4e23bd86b40234a6bd4dba209245b0f6bb501b01",
    "title": "Role of Artificial Intelligence and Big Data in Sustainable Entrepreneurship",
    "authors": [
      "Rula Abu Shanab"
    ],
    "year": 2024,
    "abstract": "There is a pressing necessity to shift our economy, society, and culture to systems and actions that promote ecological sustainability. This radical transformation necessitates an equally radical transformation of resource utilization and decision-making strategies. Sustainable entrepreneurship (SE) is frequently touted as the solution to the triple-bottom-line challenges that businesses encounter; however, there are tangible constraints on its potential. SE is currently in the first phase of implementing technological frontier tools that provide empirical guidance throughout the entrepreneurial decision-making process. The potential for artificial intelligence (AI) to inform decision-making is advanced by Big Data (BD), which also establishes pathways to attain desired outcomes. The interactions between AI, BD, and SE have been generally under-studied thus far. The absence of work that consolidates and synthesizes this literature is the primary focus of this conceptual paper. We propose that AI and BD are capable of rapidly contributing to the continued sustainable development of the weak form, but they also hold significant potential for attaining the strong sustainability ideal. We present two proposals for the integration of AI and BD to inform and facilitate SE. Finally, we outline potential areas for future research. \nThe core of human cosmology and ethics has always been the definition of his uniqueness. He ceased to be the species situated at the center of the universe, accompanied by the sun and stars, with the arrival of Copernicus and Galileo. He ceased to be the species that was created and specially endowed by God with soul and reason with the arrival of Darwin. With Freud, he ceased to be the species whose behavior could potentially be regulated by the rational mind. He has ceased to be the species that is uniquely capable of complex, intelligent manipulation of his environment as we begin to produce mechanisms that think and learn.",
    "doi": "10.60087/jaigs.v5i1.199",
    "url": "https://www.semanticscholar.org/paper/4e23bd86b40234a6bd4dba209245b0f6bb501b01",
    "pdf_url": "https://ojs.boulibrary.com/index.php/JAIGS/article/download/199/149",
    "venue": "Journal of Artificial Intelligence General science (JAIGS) ISSN:3006-4023",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586710"
  },
  {
    "source": "semantic_scholar",
    "source_id": "34449d3d462666f17ae9082242c1b1f491b02edb",
    "title": "Unmasking AI Bias in Traditional Prognosis Models",
    "authors": [
      "Md. Rayhan Hasan",
      "Sabrina Akter Setu",
      "Shinthi Tasnim Himi",
      "Shirin Sultana",
      "Anika Afrin",
      "Mohammad Nasif Sadique Khan",
      "Shrebash Paul",
      "Natasha Tanzila Monalisa"
    ],
    "year": 2025,
    "abstract": "Artificial Intelligence (AI) in healthcare is on the rise, assisting with early disease prognosis and decision-making processes. However, A\u0130 models exhibit a propensity for bias, which can lead to unequal performance across various demographic and regional subgroups. Recent advancements in metalearning aim to enhance the generalisation of these models when faced with limited data scenarios. Yet, there is a paucity of studies investigating the behaviour of such models within low-resource clinical datasets, particularly when factoring in fairness constraints. This research employs sophisticated metalearning methodologies to assess and quantify bias in predicting rabies outcomes by implementing ProtoNet, Model-Agnostic Meta-Learning (MAML), and a Hybrid ProtoMAML model to a custom-annotated rabies dataset that has been stratified by age, gender, and district. The results demonstrate that the ProtoMAML model achieves superior fairness; however, bias remains evident across subgroups. This study underscores the importance of addressing algorithmic bias within clinical AI applications and advocates for developing equitable and inclusive medical decision-making systems.",
    "doi": "10.1109/QPAIN66474.2025.11171992",
    "url": "https://www.semanticscholar.org/paper/34449d3d462666f17ae9082242c1b1f491b02edb",
    "pdf_url": "",
    "venue": "2025 International Conference on Quantum Photonics, Artificial Intelligence, and Networking (QPAIN)",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586715"
  },
  {
    "source": "semantic_scholar",
    "source_id": "6b12bbdb9d3b5a6b1b8309595014f3398d0f0360",
    "title": "Interview Bot for Improving Human Resource Management",
    "authors": [
      "Sinung Suakanto",
      "J. Siswanto",
      "Tien Febrianti Kusumasari",
      "Ilham Reza Prasetyo",
      "Margareta Hardiyanti"
    ],
    "year": 2021,
    "abstract": "This study aims to explore the feasibility of implementing a chatbot for an interview process. The development of chatbots evolved rapidly to efficiently collect information in numerous fields, including customer service, health care, and etc. However, there was limited discussion of how chatbots are used to conduct an interview process autonomously. A human-driven interview also has some major limitations, e.g., it may only be conducted on a small-scale and is susceptible to bias. Hence, this study provides the design of a chatbot to conduct an interview, as well as processing the interview result by using Artificial Intelligence (AI) or machine learning. We have identified the difference between the typical chatbot communication method and the interview bot. This finding can be an opportunity to make a new interview bot or improve the implementation of a chatbot. In the end, we also discuss the challenges and benefits of the development of an interview bot.",
    "doi": "10.1109/ICISS53185.2021.9533248",
    "url": "https://www.semanticscholar.org/paper/6b12bbdb9d3b5a6b1b8309595014f3398d0f0360",
    "pdf_url": "",
    "venue": "International Conferences on Information Science and System",
    "citation_count": 10,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586719"
  },
  {
    "source": "semantic_scholar",
    "source_id": "f1b53dddd8bb243a43f697139a71c40903e79470",
    "title": "AI Decision Making with Dignity? Contrasting Workers\u2019 Justice Perceptions of Human and AI Decision Making in a Human Resource Management Context",
    "authors": [
      "Sarah Bankins",
      "Paul Formosa",
      "Yannick Griep",
      "Deborah Richards"
    ],
    "year": 2022,
    "abstract": "Using artificial intelligence (AI) to make decisions in human resource management (HRM) raises questions of how fair employees perceive these decisions to be and whether they experience respectful treatment (i.e., interactional justice). In this experimental survey study with open-ended qualitative questions, we examine decision making in six HRM functions and manipulate the decision maker (AI or human) and decision valence (positive or negative) to determine their impact on individuals\u2019 experiences of interactional justice, trust, dehumanization, and perceptions of decision-maker role appropriateness. In terms of decision makers, the use of human decision makers over AIs generally resulted in better perceptions of respectful treatment. In terms of decision valence, people experiencing positive over negative decisions generally resulted in better perceptions of respectful treatment. In instances where these cases conflict, on some indicators people preferred positive AI decisions over negative human decisions. Qualitative responses show how people identify justice concerns with both AI and human decision making. We outline implications for theory, practice, and future research.",
    "doi": "10.1007/s10796-021-10223-8",
    "url": "https://www.semanticscholar.org/paper/f1b53dddd8bb243a43f697139a71c40903e79470",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10796-021-10223-8.pdf",
    "venue": "Information Systems Frontiers",
    "citation_count": 123,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586723"
  },
  {
    "source": "semantic_scholar",
    "source_id": "9c5b0956d5acbdaf9da938a61d22c3c322c71262",
    "title": "Strategies and Practices for Enhancing Higher Education Faculty Teaching Capabilities through Artificial Intelligence",
    "authors": [
      "Yangpeng Zhu",
      "Linjie Zhang",
      "Nuonan Chen"
    ],
    "year": 2025,
    "abstract": "A new wave of technologies\u2014represented by generative AI, multimodal learning analytics, and human-machine collaborative systems\u2014is driving a three-dimensional transformation of higher education faculty roles. Educators are evolving from \u201cknowledge transmitters\u201d into integrated \u201clearning designers\u2014value shapers\u2014data decision-makers.\u201d Guided by the Ministry of Education's policy framework \u201cDigital Empowerment for Teacher Development,\u201d this study employs field research across over 30 universities and fuzzy set qualitative comparative analysis (fsQCA) of 280 secondary colleges. Through in-depth comparative case studies across three disciplines (STEM, humanities, arts/sports), it systematically elucidates the theoretical mechanisms, core technical architectures, and differentiated implementation pathways for AI-enhanced teaching capabilities. (fsQCA) across 280 secondary colleges, and in-depth comparative case studies across three disciplinary categories (science/engineering, humanities, physical education/arts). It systematically elucidates the theoretical mechanisms, core technological architecture, and differentiated implementation pathways for AI-empowered teaching capabilities, establishing a new triadic paradigm of \u201ctechnology-institutional-humanistic\u201d synergy. Key findings include: (1) The multimodal classroom evidence-based system can enhance the precision of teaching diagnostics, but require edge computing and federated learning to safeguard data sovereignty; (2) Enhancements in teachers' teaching efficacy exhibit disciplinary heterogeneity: STEM disciplines rely on a closed-loop system of \u201cteaching behaviors \u00d7 student feedback\u201d experimental data, while humanities disciplines depend on a dual-drive model of \u201cteaching ethics \u00d7 emotional interaction\u201d; (3) Absent ethical governance poses the primary risk for deep AI application, necessitating a three-tier firewall comprising \u201cdata classification and grading + algorithmic ethics review + teacher digital rights catalog.\u201d Based on these findings, the paper proposes an integrated teacher development model encompassing \u201cAI tools\u2014organizational support\u2014humanistic reflection\u201d and offers actionable policy recommendations for national resource repository development, discipline-differentiated training, and cross-border digital governance collaboration.",
    "doi": "10.1145/3785987.3786014",
    "url": "https://www.semanticscholar.org/paper/9c5b0956d5acbdaf9da938a61d22c3c322c71262",
    "pdf_url": "",
    "venue": "Proceedings of the 2025 2nd International Conference on Artificial Intelligence and Future Education",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586727"
  },
  {
    "source": "semantic_scholar",
    "source_id": "860190a1f02e08573bedcf82f0d45dad8653ae0e",
    "title": "Harmonizing creativity and ethics in AI systems",
    "authors": [
      "Joffrey Baeyaert"
    ],
    "year": 2025,
    "abstract": null,
    "doi": "10.1007/s43681-025-00766-w",
    "url": "https://www.semanticscholar.org/paper/860190a1f02e08573bedcf82f0d45dad8653ae0e",
    "pdf_url": "",
    "venue": "AI and Ethics",
    "citation_count": 2,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586731"
  },
  {
    "source": "semantic_scholar",
    "source_id": "5f70393e599bf3bc777339acf5b6986884bd1fb2",
    "title": "AI ethics in banking services: a systematic and bibliometric review of regulatory and consumer perspectives",
    "authors": [
      "McArthur Fundira",
      "Charles Mbohwa"
    ],
    "year": 2025,
    "abstract": null,
    "doi": "10.1007/s44163-025-00432-4",
    "url": "https://www.semanticscholar.org/paper/5f70393e599bf3bc777339acf5b6986884bd1fb2",
    "pdf_url": "",
    "venue": "Discover Artificial Intelligence",
    "citation_count": 2,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586735"
  },
  {
    "source": "semantic_scholar",
    "source_id": "027c01ee260e498c5e8450304a00209e40c067bc",
    "title": "The Study on Ethics and Biases in AI-Powered Education",
    "authors": [
      "V.G. Suchithra",
      "C.S. Arya"
    ],
    "year": 2025,
    "abstract": "Artificial Intelligence (AI) is transforming education by tailoring learning experiences, streamlining administrative tasks, and increasing student engagement. AI-powered platforms are developing personalised learning plans, automating grading processes and improving accessibility, making education more effective and inclusive. However, these innovations also pose ethical challenges, such as privacy concerns, the need for transparency in algorithms, and potential biases in AI systems. If left unaddressed, biases in AI-assisted education could increase inequalities, misrepresent students' abilities, and compromise the fairness of learning outcomes. This research explores the ethical implications of AI in education, identifying sources of bias and evaluating strategies to promote fairness and inclusivity. It highlights the need for ethical AI frameworks, transparency in algorithmic choices, and ongoing monitoring to reduce bias. The study also explores future opportunities in AI-driven education, including adaptive learning environments and improved accessibility tools. By balancing technological advancement with ethical considerations, AI can become a powerful catalyst for change in education while maintaining fairness, equity and accountability.",
    "doi": "10.59324/ejceel.2025.3(2).04",
    "url": "https://www.semanticscholar.org/paper/027c01ee260e498c5e8450304a00209e40c067bc",
    "pdf_url": "",
    "venue": "European Journal of Contemporary Education and E-Learning",
    "citation_count": 2,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586739"
  },
  {
    "source": "semantic_scholar",
    "source_id": "c62f0fb9c6ac503bf73c3b6a2cc0a61af6d64f26",
    "title": "Ethical recommendations for Artificial Intelligence technology in the Geological Sciences - with a focus on Language Models",
    "authors": [
      "Paul H. Cleverley"
    ],
    "year": 2024,
    "abstract": "Artificial Intelligence (AI) offers many opportunities for the geosciences to improve productivity, reduce uncertainty in models and stimulate discovery of new knowledge. There are also risks to geoscience, from the spread of obsolete, inaccurate and misinformation, to threats on fundamental human rights. Whilst ethical AI frameworks exist from numerous institutions such as UNESCO, they are high level and lack practical detail in the geosciences particularly for Large Language Models (LLM). This is evidenced by the misalignment between the way current geoscience AI/LLMs are being designed, trained and deployed, with core ethical principles. Using principles and frameworks from UNESCO and the International Science Council (ISC), a set of ten recommendations are proposed to bridge the gap between practice and these ethical frameworks. Critical Realism is used as an underlying philosophy which allows the potential to provide justifiable recommendations to ethical and moral questions using judgemental rationality. These recommendations may help stakeholders in the international community reach conclusions on what \u2018good looks like\u2019 for ethical AI in the geological sciences focusing on Language Models and their applications. This may inform developers, regulators, policy advisors, journal editors, geological surveys, societies, institutions and unions, publishers, funding bodies, geoscientists and decision makers. This is believed to be the first research paper on AI ethics in the geological sciences with a focus on Generative AI. Understanding the nuances of our ethical choices for both the development and use of LLMs and other AI tools in the geosciences, has the potential to positively impact science integrity, and critically, ensure fairness, personal privacy, democratic norms and human rights are safeguarded.",
    "doi": "10.4401/jgsg-63",
    "url": "https://www.semanticscholar.org/paper/c62f0fb9c6ac503bf73c3b6a2cc0a61af6d64f26",
    "pdf_url": "",
    "venue": "JOURNAL OF GEOETHICS AND SOCIAL GEOSCIENCES",
    "citation_count": 4,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586743"
  },
  {
    "source": "semantic_scholar",
    "source_id": "fe30c02ed5f26e7dcb96857811b425b41856a6e0",
    "title": "Accountability in Human and Artificial Intelligence Decision-Making as the Basis for Diversity and Educational Inclusion",
    "authors": [
      "K. Porayska-Pomsta",
      "Gnanathusharan Rajendran"
    ],
    "year": 2019,
    "abstract": null,
    "doi": "10.1007/978-981-13-8161-4_3",
    "url": "https://www.semanticscholar.org/paper/fe30c02ed5f26e7dcb96857811b425b41856a6e0",
    "pdf_url": "",
    "venue": "Artificial Intelligence and Inclusive Education",
    "citation_count": 36,
    "fields_of_study": [
      "Psychology"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586747"
  },
  {
    "source": "semantic_scholar",
    "source_id": "e9e961b64186c9d11ad3625eb9128b994ab45a21",
    "title": "Artificial Intelligence Ethik (Artificial Intelligence Ethics)",
    "authors": [
      "Julia M. Puaschunder"
    ],
    "year": 2018,
    "abstract": null,
    "doi": "10.2139/SSRN.3137926",
    "url": "https://www.semanticscholar.org/paper/e9e961b64186c9d11ad3625eb9128b994ab45a21",
    "pdf_url": "",
    "venue": "",
    "citation_count": 5,
    "fields_of_study": [
      "Political Science"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586750"
  },
  {
    "source": "semantic_scholar",
    "source_id": "10121233fc2d3ca0741945b8493596c3e1148c0b",
    "title": "Ethical Leadership and Decision-Making in AI: Navigating Educational Management Ethics in the Digital Age",
    "authors": [
      "Sippiya Chayanusasanee Jundon",
      "Busara Niyomves",
      "Somboon Kaewlamai",
      "Thanyachanok Pawala"
    ],
    "year": 2025,
    "abstract": "Background and Aims: Management ethics in the digital age is critical for maintaining trust because leaders must ensure responsible technology use, data privacy, and fairness in AI decisions. Ethical management promotes transparency, prevents the misuse of digital tools, and ensures accountability in a rapidly changing technological landscape. This paper aims to investigate Ethical Leadership and Decision-Making in AI\nMethodology: This paper used peer-reviewed literature, industry reports, and authoritative sources to conduct a systematic investigation into the intersection of ethical leadership and artificial intelligence in the digital age. It identified key trends and gaps through structured data collection and thematic analysis, and then made recommendations for promoting ethical leadership in AI decision-making.\nResults: The finding found that addressing critical ethical issues such as bias, transparency, privacy, and employment impact is critical for responsible AI management. Bias in AI algorithms can perpetuate societal inequalities, transparency issues can impede accountability, extensive data collection raises privacy concerns, and automation has the potential to disrupt labor markets. Effective management necessitates the implementation of fairness-aware algorithms, strong data security, and proactive workforce transition strategies. Leaders must establish ethical guidelines, foster an ethical AI culture, and adhere to global standards to navigate these challenges and promote responsible AI development.\nConclusion: The findings emphasize the importance of dealing with ethical issues such as bias, transparency, privacy, and employment impact to manage AI responsibly. To foster accountability and promote responsible AI development, leaders must implement algorithms that prioritize fairness, ensure data security, and establish ethical guidelines.",
    "doi": "10.60027/jelr.2025.1458",
    "url": "https://www.semanticscholar.org/paper/10121233fc2d3ca0741945b8493596c3e1148c0b",
    "pdf_url": "",
    "venue": "Journal of Education and Learning Reviews",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586754"
  },
  {
    "source": "semantic_scholar",
    "source_id": "b873498140cee0442abe8a1daab4cd60416dbd48",
    "title": "Macy Foundation Innovation Report Part I: Current Landscape of Artificial Intelligence in Medical Education.",
    "authors": [
      "Christy K Boscardin",
      "Raja-Elie E. Abdulnour",
      "Brian C. Gin"
    ],
    "year": 2025,
    "abstract": "ABSTRACT\nThe rapid emergence of artificial intelligence (AI), including generative large language models, offers transformative opportunities in medical education. This proliferation has generated numerous speculative discussions about AI's promise but has been limited in delivering a comprehensive analysis to distinguish evidence-based utility from hype while identifying context-specific limitations.In this first part of a two-part innovation report, commissioned by the Josiah Macy Jr. Foundation to inform the discussions at a conference on AI in medical education, the authors synthesize the landscape of AI in medical education, underscoring both its potential advantages and inherent challenges. To map the AI landscape, they reviewed 455 articles that targeted five medical education domains: (1) Admissions, (2) Classroom-Based Learning and Teaching, (3) Workplace-Based Learning and Teaching, (4) Assessment, Feedback, and Certification, and (5) Program Evaluation and Research.In admissions, AI-driven strategies facilitated holistic applicant reviews through predictive modeling, natural language processing, and large language model-based chatbots. Preclinical learning benefited from AI-powered virtual patients and curriculum design tools that managed expanding medical knowledge and supported robust student practice. Within clinical learning, AI aided diagnostic and interpretive processes, prompting medical education curricula to demand relevant AI competency and literacy frameworks. A few studies reported that assessment and feedback processes became more efficient through automated grading and advanced analytics, which reduced faculty workload and offered timely, targeted feedback. Program evaluation and research gained additional insights using AI on careers, diversity, and performance metrics of faculty and learners, improving resource allocations and guiding evidence-based approaches.Despite these possibilities, bias in AI algorithms, concerns about transparency, inadequate ethical guidelines, and risks of over-reliance highlighted the need for cautious, informed AI implementation. By mapping AI tasks to medical education applications, the authors provide a framework for understanding and leveraging AI's potential while addressing technical, ethical, and human-factor complexities in this evolving field.",
    "doi": "10.1097/ACM.0000000000006107",
    "url": "https://www.semanticscholar.org/paper/b873498140cee0442abe8a1daab4cd60416dbd48",
    "pdf_url": "",
    "venue": "Academic medicine : journal of the Association of American Medical Colleges",
    "citation_count": 5,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586758"
  },
  {
    "source": "semantic_scholar",
    "source_id": "c863d9e40b2c1606c1c51b9d26689f42d32b776a",
    "title": "How Copyright Law Can Fix Artificial Intelligence's Implicit Bias Problem",
    "authors": [
      "Amanda Levendowski"
    ],
    "year": 2017,
    "abstract": null,
    "doi": null,
    "url": "https://www.semanticscholar.org/paper/c863d9e40b2c1606c1c51b9d26689f42d32b776a",
    "pdf_url": "",
    "venue": "",
    "citation_count": 66,
    "fields_of_study": [
      "Engineering"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586762"
  },
  {
    "source": "semantic_scholar",
    "source_id": "ae41c7c5b2dcb76f4044dd88386b3bafe71e0c90",
    "title": "AI and ethics in business: A comprehensive review of responsible AI practices and corporate responsibility",
    "authors": [
      "Chidera Victoria",
      "Ibeh",
      "Funmilola Olatundun Olatoye",
      "Kehinde Feranmi Awonuga",
      "Noluthando Zamanjomane Mhlongo",
      "Oluwafunmi Adijat Elufioye",
      "Ndubuisi Leonard Ndubuisi"
    ],
    "year": 2024,
    "abstract": "As artificial intelligence (AI) continues to revolutionize business landscapes, the ethical implications of its deployment have garnered significant attention. This paper presents a comprehensive review of the intersection between AI and ethics in the context of corporate responsibility. The integration of AI into business processes necessitates a thorough understanding of responsible AI practices to ensure that technological advancements align with ethical standards and societal values. The first dimension explored in this review is the critical importance of transparency in AI algorithms and decision-making processes. Businesses adopting AI technologies must prioritize transparency to build trust among stakeholders, ensuring that the decision-making processes are understandable and accountable. Ethical considerations also extend to issues of bias and fairness, prompting the need for diverse and inclusive datasets to prevent discriminatory outcomes. Corporate responsibility in the realm of AI extends beyond technical aspects, encompassing the broader socio-economic impact of AI implementation. The review highlights the significance of considering the effects of AI on employment, inequality, and accessibility. Businesses are urged to adopt ethical guidelines that prioritize the well-being of employees and society at large, mitigating the potential negative consequences of AI on employment dynamics and social structures. Furthermore, the paper delves into the ethical considerations surrounding data privacy and security, emphasizing the importance of responsible data handling practices. As businesses accumulate vast amounts of data, it becomes imperative to prioritize the protection of individuals' privacy rights, reinforcing the ethical foundation of AI applications. This comprehensive review underscores the need for businesses to integrate responsible AI practices within the framework of corporate responsibility. By prioritizing transparency, fairness, and ethical data practices, organizations can navigate the complex terrain of AI implementation while ensuring alignment with societal values and ethical standards. This synthesis of AI and ethics in business is essential for fostering a sustainable and responsible technological future.",
    "doi": "10.30574/ijsra.2024.11.1.0235",
    "url": "https://www.semanticscholar.org/paper/ae41c7c5b2dcb76f4044dd88386b3bafe71e0c90",
    "pdf_url": "https://ijsra.net/sites/default/files/IJSRA-2024-0235.pdf",
    "venue": "International Journal of Science and Research Archive",
    "citation_count": 41,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586767"
  },
  {
    "source": "semantic_scholar",
    "source_id": "09c2ad9f972ef214d016d98744437dc2225ed106",
    "title": "Artificial Intelligence-Powered Robotic Technology for Transforming Palliative Care",
    "authors": [
      "Adebo Thomas",
      "Asiku Denis",
      "Wamusi Robert",
      "Simon Peter Kabiito",
      "Zaward Morish",
      "Aziku Samuel",
      "Malik Sallam",
      "Ioannis Adamopoulos"
    ],
    "year": 2025,
    "abstract": "Palliative care seeks to improve the quality of life of patients with life-threatening illnesses by addressing their physical, emotional, and psychological needs. However, global challenges such as workforce shortages, limited access to specialized care, and inconsistent care quality demand innovative solutions. Advances in artificial intelligence (AI)-powered robotics offer transformative potential to overcome these barriers and strengthen palliative care delivery. This study explores how AI-driven robotic technologies support palliative care through applications in symptom monitoring, clinical decision-making, emotional companionship, and personalized care planning. It reviews cutting-edge robotic systems, including assistive, companion, diagnostic, nursing, procedural, service, and rehabilitation robots. Enabled by machine learning, deep learning, natural language processing, and computer vision breakthroughs, these systems help monitor vital signs, manage symptoms, plan end-of-life care, deliver medication, alleviate pain, and support mobility through robotic exoskeletons. They also assist patients with daily activities and offer respite to caregivers. Despite their promise, AI-powered robotics face significant challenges, including ethical concerns, algorithmic bias, data privacy risks, cultural resistance, and resource limitations. When integrated ethically and thoughtfully, AI-powered robotics can extend the reach of palliative services, support human caregivers, and enhance outcomes for patients and families. Collaboration among healthcare professionals, AI researchers, engineers, and policymakers is crucial to ensure that robotic technologies remain patient-centered, safe, and accessible. By merging technological innovation with compassionate care, AI and robotics can redefine the future of palliative care globally.",
    "doi": "10.58496/mjaih/2025/007",
    "url": "https://www.semanticscholar.org/paper/09c2ad9f972ef214d016d98744437dc2225ed106",
    "pdf_url": "",
    "venue": "Mesopotamian Journal of Artificial Intelligence in Healthcare",
    "citation_count": 3,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586771"
  },
  {
    "source": "semantic_scholar",
    "source_id": "8725127c0bdba837fbf286982be34416798245c4",
    "title": "Ethics in AI: Balancing innovation and responsibility",
    "authors": [
      "Rishi Kumar Sharma"
    ],
    "year": 2025,
    "abstract": "The rapid advancement of artificial intelligence technologies has created unprecedented opportunities while raising significant ethical concerns across various sectors. This comprehensive article examines the challenges and strategies in implementing ethical AI frameworks, focusing on algorithmic bias, transparency, and accountability. The article investigates industry-specific applications in healthcare, financial services, and law enforcement, revealing ethical implementation and governance patterns. Through extensive research across multiple organizations, the article demonstrates the critical importance of structured ethical frameworks, stakeholder engagement, and comprehensive monitoring systems in ensuring responsible AI development. The findings highlight the need for balanced approaches that maintain technological innovation while adhering to ethical principles and human values.",
    "doi": "10.30574/ijsra.2025.14.1.0122",
    "url": "https://www.semanticscholar.org/paper/8725127c0bdba837fbf286982be34416798245c4",
    "pdf_url": "",
    "venue": "International Journal of Science and Research Archive",
    "citation_count": 9,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586775"
  },
  {
    "source": "semantic_scholar",
    "source_id": "8fabf24a07f006bd2097584770afd3953aadc4a6",
    "title": "Shaping the future of AI in healthcare through ethics and governance",
    "authors": [
      "Rabai Bouderhem"
    ],
    "year": 2024,
    "abstract": "The purpose of this research is to identify and evaluate the technical, ethical and regulatory challenges related to the use of Artificial Intelligence (AI) in healthcare. The potential applications of AI in healthcare seem limitless and vary in their nature and scope, ranging from privacy, research, informed consent, patient autonomy, accountability, health equity, fairness, AI-based diagnostic algorithms to care management through automation for specific manual activities to reduce paperwork and human error. The main challenges faced by states in regulating the use of AI in healthcare were identified, especially the legal voids and complexities for adequate regulation and better transparency. A few recommendations were made to protect health data, mitigate risks and regulate more efficiently the use of AI in healthcare through international cooperation and the adoption of harmonized standards under the World Health Organization (WHO) in line with its constitutional mandate to regulate digital and public health. European Union (EU) law can serve as a model and guidance for the WHO for a reform of the International Health Regulations (IHR).",
    "doi": "10.1057/s41599-024-02894-w",
    "url": "https://www.semanticscholar.org/paper/8fabf24a07f006bd2097584770afd3953aadc4a6",
    "pdf_url": "https://www.nature.com/articles/s41599-024-02894-w.pdf",
    "venue": "Humanities and Social Sciences Communications",
    "citation_count": 86,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586778"
  },
  {
    "source": "semantic_scholar",
    "source_id": "5821c044982322e2aebfbadbf319cdf7f6e576bf",
    "title": "Higher Education\u2019s Generative Artificial Intelligence Paradox: The Meaning of Chatbot Mania",
    "authors": [
      "Juergen Rudolph",
      "Fadhil Mohamed Mohamed Ismail",
      "Stefan Popenici"
    ],
    "year": 2024,
    "abstract": "Higher education is currently under a significant transformation due to the emergence of generative artificial intelligence (GenAI) technologies, the hype surrounding GenAI and the increasing influence of educational technology business groups over tertiary education. This commentary, prepared for the Special Issue of the Journal of University Teaching & Learning Practice (JUTLP) on \u201cEnhancing student engagement using Artificial Intelligence (AI) and chatbots,\u201d delves into the complex landscape of opportunities and threats that AI chatbots, including ChatGPT, introduce to the realm of higher education. We argue that while GenAI offers promise in enhancing pedagogy, research, administration, and student support, concerns around academic integrity, labour displacement, embedded biases, environmental sustainability, increased commercialisation, and regulatory gaps necessitate a critical approach. Our commentary advocates for the development of critical AI literacy among educators and students, emphasising the necessity to foster an environment of responsible innovation and informed use of AI. We posit that the successful integration of AI in higher education must be grounded in the principles of ethics, equity, and the prioritisation of educational aims and human values. By offering a critical and nuanced exploration of these issues, our commentary aims to contribute to the ongoing discourse on how higher education institutions can navigate the rise of GenAI, ensuring that technological advancements benefit all stakeholders while upholding core academic values.",
    "doi": "10.53761/54fs5e77",
    "url": "https://www.semanticscholar.org/paper/5821c044982322e2aebfbadbf319cdf7f6e576bf",
    "pdf_url": "https://open-publishing.org/journals/index.php/jutlp/article/download/744/754",
    "venue": "Journal of University Teaching and Learning Practice",
    "citation_count": 59,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586782"
  },
  {
    "source": "semantic_scholar",
    "source_id": "b9d6757b0170523916353062f96ee075ac915c4d",
    "title": "Demographic bias of expert-level vision-language foundation models in medical imaging",
    "authors": [
      "Yuzhe Yang",
      "Yujia Liu",
      "Xin Liu",
      "Avanti V Gulhane",
      "Domenico Mastrodicasa",
      "Wei Wu",
      "E. J. Wang",
      "Dushyant W. Sahani",
      "Shwetak N. Patel"
    ],
    "year": 2024,
    "abstract": "Advances in artificial intelligence (AI) have achieved expert-level performance in medical imaging applications. Notably, self-supervised vision-language foundation models can detect a broad spectrum of pathologies without relying on explicit training annotations. However, it is crucial to ensure that these AI models do not mirror or amplify human biases, disadvantaging historically marginalized groups such as females or Black patients. In this study, we investigate the algorithmic fairness of state-of-the-art vision-language foundation models in chest x-ray diagnosis across five globally sourced datasets. Our findings reveal that compared to board-certified radiologists, these foundation models consistently underdiagnose marginalized groups, with even higher rates seen in intersectional subgroups such as Black female patients. Such biases present over a wide range of pathologies and demographic attributes. Further analysis of the model embedding uncovers its substantial encoding of demographic information. Deploying medical AI systems with biases can intensify preexisting care disparities, posing potential challenges to equitable healthcare access and raising ethical questions about their clinical applications.",
    "doi": "10.1126/sciadv.adq0305",
    "url": "https://www.semanticscholar.org/paper/b9d6757b0170523916353062f96ee075ac915c4d",
    "pdf_url": "http://arxiv.org/pdf/2402.14815",
    "venue": "Science Advances",
    "citation_count": 43,
    "fields_of_study": [
      "Medicine",
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586787"
  },
  {
    "source": "semantic_scholar",
    "source_id": "6b8323c615566aa4d464b0d257d6e21bf0b2904c",
    "title": "Responsible AI for AI Sustainable Future: Governance, Ethics, and The Reality Behind\u00a0the\u00a0Promise",
    "authors": [
      "Miracle Atianashie",
      "Mark K. Kuffour",
      "Bernard Kyiewu",
      "Philipa Serwaa"
    ],
    "year": 2025,
    "abstract": "Artificial intelligence has emerged as a powerful force shaping global development, offering promising solutions across health, education, climate change, and governance. However, its rapid integration into critical sectors raises urgent questions about ethics, governance, and sustainability. This systematic review explores the promise and practice of responsible AI through the lens of three core objectives: the governance mechanisms guiding AI implementation, the ethical frameworks shaping its design, and the practical realities influencing its deployment across contexts. Drawing from sixty peer-reviewed articles published between 2017 and 2024, the review identifies strong global consensus on foundational principles such as fairness, accountability, and transparency. Nonetheless, a significant implementation gap persists, particularly in low-resource settings, where enforcement mechanisms and institutional readiness are often lacking. The findings also reveal that ethical commitments are frequently undermined by organizational constraints and commercial interests, leading to surface-level adherence without substantive change. Environmental sustainability, a critical dimension of responsible AI, remains underrepresented in current governance discussions despite mounting evidence of AI\u2019s carbon footprint. This review contributes to the growing body of scholarship advocating for inclusive, enforceable, and context-sensitive approaches to responsible AI. It underscores the need for deeper engagement with the political, social, and environmental realities that shape AI\u2019s impact on sustainable development. Ultimately, bridging the gap between AI\u2019s ethical aspirations and real-world outcomes requires not only technical innovation but also strong institutional leadership, interdisciplinary collaboration, and meaningful stakeholder participation.",
    "doi": "10.70715/jitcai.2025.v2.i2.012",
    "url": "https://www.semanticscholar.org/paper/6b8323c615566aa4d464b0d257d6e21bf0b2904c",
    "pdf_url": "",
    "venue": "Journal of Information Technology, Cybersecurity, and Artificial Intelligence",
    "citation_count": 2,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586791"
  },
  {
    "source": "semantic_scholar",
    "source_id": "baacd51e725c849bbc7a7ea78e9fe07d3e81dd64",
    "title": "The Ethics of Artificial Intelligence",
    "authors": [
      "Chris Rees"
    ],
    "year": 2020,
    "abstract": "This chapter focuses on the ethics of narrow, as opposed to general AI. It makes the practical as well as the philosophical case for discussion of AI ethics. It considers ethical charters, then discusses the principal ethical issues: bias, explainability, liability for failure, harmlessness, the ethical use of data, whether AIs should have legal personality, the effects on employment and society, and AIs impersonating humans. A case study is presented of AI in personal insurance. It makes the case for regulation of AI and discusses the challenges of enacting regulation. It draws conclusions, that the benefits of AI are so valuable that the ethical risks must be managed, or the benefits may be lost because of the loss of public trust. There are grounds for optimism, notably the public consciousness of the issues, the engagement of governments and the amount of private and public investment in ethical research.",
    "doi": "10.1007/978-3-030-64246-4_5",
    "url": "https://www.semanticscholar.org/paper/baacd51e725c849bbc7a7ea78e9fe07d3e81dd64",
    "pdf_url": "",
    "venue": "Unimagined Futures",
    "citation_count": 6,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586795"
  },
  {
    "source": "semantic_scholar",
    "source_id": "37ef7632480b672100aa0305addbdb4f743b5b7b",
    "title": "Artificial Intelligence and Inequality: Challenges and Opportunities",
    "authors": [
      "Milad Shahvaroughi Farahani",
      "Ghazal Ghasemi"
    ],
    "year": 2024,
    "abstract": "Integrating artificial intelligence (AI) technologies into various aspects of society has sparked both excitement and concern regarding its potential impact on inequality. This abstract provides an overview of the key issues surrounding AI and inequality, exploring the challenges and opportunities arising from the widespread adoption of AI systems.\n\nFirstly, we examine how AI technologies have the potential to exacerbate existing inequalities across various domains, including labor markets, education, healthcare, and access to services. AI-driven automation may lead to job displacement and wage polarization, widening the gap between high-skilled and low-skilled workers. Moreover, algorithmic biases embedded in AI systems can perpetuate discrimination and inequity, particularly against marginalized communities.\n\nHowever, alongside these challenges, AI also presents opportunities to address inequality and promote inclusivity. AI-powered innovations have the potential to enhance efficiency, accessibility, and affordability in sectors such as healthcare, education, and financial services, thereby reducing disparities in access to essential resources and opportunities. Additionally, initiatives focused on ethical AI development and responsible AI governance can mitigate the negative impacts of AI on inequality by promoting fairness, transparency, and accountability in algorithmic decision-making processes.\n\nIn conclusion, while AI has the potential to both exacerbate and mitigate inequality, its ultimate impact depends on the choices we make in designing, deploying, and governing AI systems. By prioritizing equity, social justice, and human welfare in AI development and implementation, we can harness the transformative power of AI to create a more equitable and inclusive society.\n",
    "doi": "10.32388/7hwuz2",
    "url": "https://www.semanticscholar.org/paper/37ef7632480b672100aa0305addbdb4f743b5b7b",
    "pdf_url": "",
    "venue": "Qeios",
    "citation_count": 32,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586799"
  },
  {
    "source": "semantic_scholar",
    "source_id": "1366dd0cf93e9e4ba85e7683fe45869e225d336e",
    "title": "Predictive Analytics in Human Resources Management: Evaluating AIHR\u2019s Role in Talent Retention",
    "authors": [
      "Ana Maria C\u0103vescu",
      "Nirvana Popescu"
    ],
    "year": 2025,
    "abstract": "This study explores the role of artificial intelligence (AI) in human resource management (HRM), with a focus on recruitment, employee retention, and performance optimization. Through a PRISMA-based systematic literature review, the paper examines many machine learning algorithms including XGBoost, SVM, random forest, and linear regression in decision-making related to employee-attrition prediction and talent management. The findings suggest that these technologies can automate HR processes, reduce bias, and personalize employee experiences. However, the implementation of AI in HRM also presents challenges, including data privacy concerns, algorithmic bias, and organizational resistance. To address these obstacles, the study highlights the importance of adopting ethical AI frameworks, ensuring transparency in decision-making, and developing effective integration strategies. Future research should focus on improving explainability, minimizing algorithmic bias, and promoting fairness in AI-driven HR practices.",
    "doi": "10.3390/appliedmath5030099",
    "url": "https://www.semanticscholar.org/paper/1366dd0cf93e9e4ba85e7683fe45869e225d336e",
    "pdf_url": "",
    "venue": "AppliedMath",
    "citation_count": 7,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586802"
  },
  {
    "source": "semantic_scholar",
    "source_id": "e8b8647f4b2a4b14fc791d1ba57edb77f21d9c19",
    "title": "Factors influencing human trust in intelligent built environment systems",
    "authors": [
      "Amir Behzadan",
      "Armita Dabiri"
    ],
    "year": 2025,
    "abstract": null,
    "doi": "10.1007/s43681-025-00813-6",
    "url": "https://www.semanticscholar.org/paper/e8b8647f4b2a4b14fc791d1ba57edb77f21d9c19",
    "pdf_url": "",
    "venue": "AI and Ethics",
    "citation_count": 1,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586806"
  },
  {
    "source": "semantic_scholar",
    "source_id": "bc95c1c9f64b40eec29592229a81d51419383ab1",
    "title": "Should Artificial Intelligence be used to support clinical ethical decision-making? A systematic review of reasons",
    "authors": [
      "Lasse Benzinger",
      "F. Ursin",
      "Wolf-Tilo Balke",
      "T. Kacprowski",
      "Sabine Salloch"
    ],
    "year": 2023,
    "abstract": "Background Healthcare providers have to make ethically complex clinical decisions which may be a source of stress. Researchers have recently introduced Artificial Intelligence (AI)-based applications to assist in clinical ethical decision-making. However, the use of such tools is controversial. This review aims to provide a comprehensive overview of the reasons given in the academic literature for and against their use. Methods PubMed, Web of Science, Philpapers.org and Google Scholar were searched for all relevant publications. The resulting set of publications was title and abstract screened according to defined inclusion and exclusion criteria, resulting in 44 papers whose full texts were analysed using the Kuckartz method of qualitative text analysis. Results Artificial Intelligence might increase patient autonomy by improving the accuracy of predictions and allowing patients to receive their preferred treatment. It is thought to increase beneficence by providing reliable information, thereby, supporting surrogate decision-making. Some authors fear that reducing ethical decision-making to statistical correlations may limit autonomy. Others argue that AI may not be able to replicate the process of ethical deliberation because it lacks human characteristics. Concerns have been raised about issues of justice, as AI may replicate existing biases in the decision-making process. Conclusions The prospective benefits of using AI in clinical ethical decision-making are manifold, but its development and use should be undertaken carefully to avoid ethical pitfalls. Several issues that are central to the discussion of Clinical Decision Support Systems, such as justice, explicability or human\u2013machine interaction, have been neglected in the debate on AI for clinical ethics so far. Trial registration This review is registered at Open Science Framework ( https://osf.io/wvcs9 ).",
    "doi": "10.1186/s12910-023-00929-6",
    "url": "https://www.semanticscholar.org/paper/bc95c1c9f64b40eec29592229a81d51419383ab1",
    "pdf_url": "https://bmcmedethics.biomedcentral.com/counter/pdf/10.1186/s12910-023-00929-6",
    "venue": "BMC Medical Ethics",
    "citation_count": 49,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586810"
  },
  {
    "source": "semantic_scholar",
    "source_id": "baee16e76433605cdd093b939e5915a0e902bcef",
    "title": "Environmentally sustainable development and use of artificial intelligence in health care",
    "authors": [
      "C. Richie"
    ],
    "year": 2022,
    "abstract": "Abstract Artificial intelligence (AI) can transform health care by delivering medical services to underserved areas, while also filling gaps in health care provider availability. However, AI may also lead to patient harm due to fatal glitches in robotic surgery, bias in diagnosis, or dangerous recommendations. Despite concerns ethicists have identified in the use of AI in health care, the most significant consideration ought not be vulnerabilities in the software, but the environmental impact of AI. Health care emits a significant amount of carbon in many countries. As AI becomes an essential part of health care, ethical reflection must include the potential to negatively impact the environment. As such, this article will first overview the carbon emissions in health care. It will, second, offer five reasons why carbon calculations are insufficient to address sustainability in health care. Third, the article will derive normative concepts from the goals of medicine, the principles of biomedical ethics, and green bioethics\u2014the very locus in which AI in health care sits\u2014to propose health, justice, and resource conservation as criteria for sustainable AI in health care. In the fourth and final part of the article, examples of sustainable and unsustainable development and use of AI in health care will be evaluated through the three\u2010fold lens of health, justice, and resource conservation. With various ethical approaches to AI in health care, the imperative for environmental sustainability must be underscored, lest carbon emissions continue to increase, harming people and planet alike.",
    "doi": "10.1111/bioe.13018",
    "url": "https://www.semanticscholar.org/paper/baee16e76433605cdd093b939e5915a0e902bcef",
    "pdf_url": "https://repository.tudelft.nl/file/File_8339643d-3753-4ac5-8131-3cc562ebf948",
    "venue": "Bioethics",
    "citation_count": 54,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586813"
  },
  {
    "source": "semantic_scholar",
    "source_id": "2cc5941e5effff3243702f5ab318ee1336442eed",
    "title": "Feeling Machines: Ethics, Culture, and the Rise of Emotional AI",
    "authors": [
      "Vivek Chavan",
      "Arsen Cenaj",
      "Shuyuan Shen",
      "A. Bar",
      "Srishti Binwani",
      "Tommaso Del Becaro",
      "Marius Funk",
      "Lynn Greschner",
      "Roberto Hung",
      "Stina Klein",
      "Romina Kleiner",
      "Stefanie Krause",
      "Sylwia Olbrych",
      "Vishvapalsinhji Ramsinh Parmar",
      "Jaleh Sarafraz",
      "Daria Soroko",
      "Daksitha Withanage Don",
      "Chang Zhou",
      "Hoang Thuy Duong Vu",
      "Parastoo Semnani",
      "Daniel Weinhardt",
      "Elisabeth Andr\u00e9",
      "Jorg Kruger",
      "Xavier Fresquet"
    ],
    "year": 2025,
    "abstract": "This paper explores the growing presence of emotionally responsive artificial intelligence through a critical and interdisciplinary lens. Bringing together the voices of early-career researchers from multiple fields, it explores how AI systems that simulate or interpret human emotions are reshaping our interactions in areas such as education, healthcare, mental health, caregiving, and digital life. The analysis is structured around four central themes: the ethical implications of emotional AI, the cultural dynamics of human-machine interaction, the risks and opportunities for vulnerable populations, and the emerging regulatory, design, and technical considerations. The authors highlight the potential of affective AI to support mental well-being, enhance learning, and reduce loneliness, as well as the risks of emotional manipulation, over-reliance, misrepresentation, and cultural bias. Key challenges include simulating empathy without genuine understanding, encoding dominant sociocultural norms into AI systems, and insufficient safeguards for individuals in sensitive or high-risk contexts. Special attention is given to children, elderly users, and individuals with mental health challenges, who may interact with AI in emotionally significant ways. However, there remains a lack of cognitive or legal protections which are necessary to navigate such engagements safely. The report concludes with ten recommendations, including the need for transparency, certification frameworks, region-specific fine-tuning, human oversight, and longitudinal research. A curated supplementary section provides practical tools, models, and datasets to support further work in this domain.",
    "doi": "10.48550/arXiv.2506.12437",
    "url": "https://www.semanticscholar.org/paper/2cc5941e5effff3243702f5ab318ee1336442eed",
    "pdf_url": "",
    "venue": "arXiv.org",
    "citation_count": 3,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586819"
  },
  {
    "source": "semantic_scholar",
    "source_id": "f5ecc97c1bdaa2a4bce0efe2fb029482150be1a4",
    "title": "Explainable AI-Driven Decision Support for Social Benefit Optimization: Improving Fairness, Reliability, and Managerial Oversight",
    "authors": [
      "Shakun Garg",
      "Amit Verma"
    ],
    "year": 2026,
    "abstract": "It has become more necessary to have fair and transparent distribution of social benefits due to the increasing dependence of governments and organizations on data-driven decision systems. However, traditional AI platforms tend to be black-box, so interpretability is usually limited, and it allows biases to exist that compromise trust and undermine managerial control. To overcome these issues, the present paper introduces a proposal of an explainable artificial intelligence-based decision support system to improve fairness, reliability, and policy compliance in the workflow of social-benefit distribution. Its approach combines interpretable prediction modelling, equity-sensitive modifications, uncertainty estimation, and human-in-the-loop oversight and places it into one pipeline. Quantitative analysis of synthetic and real-world welfare data demonstrates that the proposed structure removes demographic bias by 22.7% and decision under perturbations by 18.4 and greater explanation fidelity by 31.2 than non-explainable bases do. The system further enhances the consistency of the allocation by 17.5% and reduces the risk of policy-violation by 14.9 %, and at the same time, it sustains the competitive predictive accuracy. As experimental findings indicate, there might be not only the higher quality of generated balance and credible recommendations of benefits but the enhanced managerial control due to the transparency of decision rationales and audit-traceable procedures. The results emphasize the usefulness of explainable and decision-aware AI systems in facilitating socially responsible and accountable decision making towards the administration of the public good.",
    "doi": "10.63503/j.ijaimd.2025.195",
    "url": "https://www.semanticscholar.org/paper/f5ecc97c1bdaa2a4bce0efe2fb029482150be1a4",
    "pdf_url": "",
    "venue": "International Journal on Engineering Artificial Intelligence Management, Decision Support, and Policies",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586823"
  },
  {
    "source": "semantic_scholar",
    "source_id": "686b225718e76544cbf8472dcf85a587088b66c8",
    "title": "Navigating Ethical Challenges and Biases in Generative AI: Ensuring Trust and Fairness in B2B Sales Interactions and Decision-Making",
    "authors": [
      "Venkata Tadi"
    ],
    "year": 2024,
    "abstract": "The integration of generative artificial intelligence (AI) in business-to-business (B2B) sales processes offers significant opportunities for enhanced efficiency, personalization, and predictive capabilities. However, these advancements come with substantial ethical challenges and risks of biases that can undermine trust and fairness in AI-driven interactions. This paper explores the ethical landscape of generative AI in B2B sales, focusing on data privacy, security, transparency, accountability, and informed consent. It examines the sources of bias in AI algorithms, their impact on customer engagement and satisfaction, and the strategies to mitigate these biases. Through a comprehensive review of current literature and case studies, this research highlights the importance of building and maintaining trust in AI systems and ensuring fair treatment of all customers. Insights from industry leaders and proposed future research directions emphasize the need for continuous adaptation and learning in AI ethics. The findings underscore the critical role of ethical AI practices in fostering sustainable and trustworthy B2B sales environments. This paper aims to contribute to the development of ethical frameworks and guidelines that support fair and transparent AI systems, ensuring that the benefits of AI are realized without compromising ethical standards.",
    "doi": "10.47363/jaicc/2024(3)e104",
    "url": "https://www.semanticscholar.org/paper/686b225718e76544cbf8472dcf85a587088b66c8",
    "pdf_url": "",
    "venue": "Journal of Artificial Intelligence &amp; Cloud Computing",
    "citation_count": 3,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586827"
  },
  {
    "source": "semantic_scholar",
    "source_id": "be10e806afc9f0fd1fddaae855e7e503b1eaca89",
    "title": "The cyclical ethical effects of using artificial intelligence in education",
    "authors": [
      "E. Dieterle",
      "C. Dede",
      "Michael Walker"
    ],
    "year": 2022,
    "abstract": "Our synthetic review of the relevant and related literatures on the ethics and effects of using AI in education reveals five qualitatively distinct and interrelated divides associated with access, representation, algorithms, interpretations, and citizenship. We open our analysis by probing the ethical effects of algorithms and how teams of humans can plan for and mitigate bias when using AI tools and techniques to model and inform instructional decisions and predict learning outcomes. We then analyze the upstream divides that feed into and fuel the algorithmic divide, first investigating access (who does and does not have access to the hardware, software, and connectivity necessary to engage with AI-enhanced digital learning tools and platforms) and then representation (the factors making data either representative of the total population or over-representative of a subpopulation\u2019s preferences, thereby preventing objectivity and biasing understandings and outcomes). After that, we analyze the divides that are downstream of the algorithmic divide associated with interpretation (how learners, educators, and others understand the outputs of algorithms and use them to make decisions) and citizenship (how the other divides accumulate to impact interpretations of data by learners, educators, and others, in turn influencing behaviors and, over time, skills, culture, economic, health, and civic outcomes). At present, lacking ongoing reflection and action by learners, educators, educational leaders, designers, scholars, and policymakers, the five divides collectively create a vicious cycle and perpetuate structural biases in teaching and learning. However, increasing human responsibility and control over these divides can create a virtuous cycle that improves diversity, equity, and inclusion in education. We conclude the article by looking forward and discussing ways to increase educational opportunity and effectiveness for all by mitigating bias through a cycle of progressive improvement.",
    "doi": "10.1007/s00146-022-01497-w",
    "url": "https://www.semanticscholar.org/paper/be10e806afc9f0fd1fddaae855e7e503b1eaca89",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s00146-022-01497-w.pdf",
    "venue": "Ai & Society",
    "citation_count": 78,
    "fields_of_study": [
      "Computer Science",
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586831"
  },
  {
    "source": "semantic_scholar",
    "source_id": "87e67360dd19d2ce61af795efed9547c791fd7dd",
    "title": "Improving Fairness of Automated Chest Radiograph Diagnosis by Contrastive Learning.",
    "authors": [
      "Mingquan Lin",
      "Tianhao Li",
      "Zhaoyi Sun",
      "G. Holste",
      "Ying Ding",
      "Fei Wang",
      "George Shih",
      "Yifan Peng"
    ],
    "year": 2024,
    "abstract": "\"Just Accepted\" papers have undergone full peer review and have been accepted for publication in Radiology: Artificial Intelligence. This article will undergo copyediting, layout, and proof review before it is published in its final version. Please note that during production of the final copyedited article, errors may be discovered which could affect the content. Purpose To develop an artificial intelligence model that utilizes supervised contrastive learning to minimize bias in chest radiograph (CXR) diagnosis. Materials and Methods In this retrospective study, the proposed method was evaluated on two datasets: the Medical Imaging and Data Resource Center (MIDRC) dataset with 77,887 CXRs from 27,796 patients collected as of April 20, 2023 for COVID-19 diagnosis, and the NIH Chest x-ray 14 (NIH-CXR) dataset with 112,120 CXRs from 30,805 patients collected between 1992 and 2015. In the NIH-CXR dataset, thoracic abnormalities included atelectasis, cardiomegaly, effusion, infiltration, mass, nodule, pneumonia, pneumothorax, consolidation, edema, emphysema, fibrosis, pleural thickening, or hernia. The proposed method utilized supervised contrastive learning with carefully selected positive and negative samples to generate fair image embeddings, which were fine-tuned for subsequent tasks to reduce bias in CXR diagnosis. The method was evaluated using the marginal area under the receiver operating characteristic curve (AUC) difference (\u0394mAUC). Results The proposed model showed a significant decrease in bias across all subgroups compared with the baseline models, as evidenced by a paired T-test (P < .001). The \u0394mAUCs obtained by the proposed method were 0.01 (95% CI, 0.01-0.01), 0.21 (95% CI, 0.21-0.21), and 0.10 (95% CI, 0.10-0.10) for sex, race, and age subgroups, respectively, on MIDRC, and 0.01 (95% CI, 0.01-0.01) and 0.05 (95% CI, 0.05-0.05) for sex and age subgroups, respectively, on NIH-CXR. Conclusion Employing supervised contrastive learning can mitigate bias in CXR diagnosis, addressing concerns of fairness and reliability in deep learning-based diagnostic methods. \u00a9RSNA, 2024.",
    "doi": "10.1148/ryai.230342",
    "url": "https://www.semanticscholar.org/paper/87e67360dd19d2ce61af795efed9547c791fd7dd",
    "pdf_url": "",
    "venue": "Radiology: Artificial Intelligence",
    "citation_count": 6,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586836"
  },
  {
    "source": "semantic_scholar",
    "source_id": "0ecd310576a096e494af572ed607ecce8fa41d65",
    "title": "Implementing ethics into artificial intelligence: a contribution, from a legal perspective, to the development of an AI governance regime",
    "authors": [
      "A. Walz",
      "Kay Firth-Butterfield"
    ],
    "year": 2019,
    "abstract": null,
    "doi": null,
    "url": "https://www.semanticscholar.org/paper/0ecd310576a096e494af572ed607ecce8fa41d65",
    "pdf_url": "",
    "venue": "",
    "citation_count": 27,
    "fields_of_study": [
      "Political Science"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586840"
  },
  {
    "source": "semantic_scholar",
    "source_id": "2a18c5b720906b39133f3ef2503c6695be4e3f9a",
    "title": "Towards Risk-Free Trustworthy Artificial Intelligence: Significance and Requirements",
    "authors": [
      "Laith Alzubaidi",
      "Aiman Al-Sabaawi",
      "Jinshuai Bai",
      "Ammar Dukhan",
      "Ahmed H. Alkenani",
      "Ahmed Al-Asadi",
      "Haider A. Alwzwazy",
      "M. Manoufali",
      "M. Fadhel",
      "A. Albahri",
      "Catarina Moreira",
      "Chun Ouyang",
      "Jinglan Zhang",
      "Jos\u00e9 I. Santamar\u00eda",
      "Asma Salhi",
      "Freek Hollman",
      "Ashish Gupta",
      "Ye Duan",
      "T. Rabczuk",
      "Amin Abbosh",
      "Yuantong Gu"
    ],
    "year": 2023,
    "abstract": "Given the tremendous potential and influence of artificial intelligence (AI) and algorithmic decision-making (DM), these systems have found wide-ranging applications across diverse fields, including education, business, healthcare industries, government, and justice sectors. While AI and DM offer significant benefits, they also carry the risk of unfavourable outcomes for users and society. As a result, ensuring the safety, reliability, and trustworthiness of these systems becomes crucial. This article aims to provide a comprehensive review of the synergy between AI and DM, focussing on the importance of trustworthiness. The review addresses the following four key questions, guiding readers towards a deeper understanding of this topic: (i) why do we need trustworthy AI? (ii) what are the requirements for trustworthy AI? In line with this second question, the key requirements that establish the trustworthiness of these systems have been explained, including explainability, accountability, robustness, fairness, acceptance of AI, privacy, accuracy, reproducibility, and human agency, and oversight. (iii) how can we have trustworthy data? and (iv) what are the priorities in terms of trustworthy requirements for challenging applications? Regarding this last question, six different applications have been discussed, including trustworthy AI in education, environmental science, 5G-based IoT networks, robotics for architecture, engineering and construction, financial technology, and healthcare. The review emphasises the need to address trustworthiness in AI systems before their deployment in order to achieve the AI goal for good. An example is provided that demonstrates how trustworthy AI can be employed to eliminate bias in human resources management systems. The insights and recommendations presented in this paper will serve as a valuable guide for AI researchers seeking to achieve trustworthiness in their applications.",
    "doi": "10.1155/2023/4459198",
    "url": "https://www.semanticscholar.org/paper/2a18c5b720906b39133f3ef2503c6695be4e3f9a",
    "pdf_url": "https://downloads.hindawi.com/journals/ijis/2023/4459198.pdf",
    "venue": "International Journal of Intelligent Systems",
    "citation_count": 60,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586845"
  },
  {
    "source": "semantic_scholar",
    "source_id": "fda514d275ca73a51d72c325ab2108564bbc502f",
    "title": "Ethics of artificial intelligence in radiology: summary of the joint European and North American multisociety statement",
    "authors": [
      "J. R. Geis",
      "A. Brady",
      "Carol C. Wu",
      "Jack Spencer",
      "E. Ranschaert",
      "J. Jaremko",
      "S. Langer",
      "A. B. Kitts",
      "J. Birch",
      "William F. Shields",
      "R. V. D. H. V. Genderen",
      "E. Kotter",
      "J. W. Gichoya",
      "J. W. Gichoya",
      "T. Cook",
      "Matthew B. Morgan",
      "A. Tang",
      "Nabile M. Safdar",
      "M. Kohli"
    ],
    "year": 2019,
    "abstract": "This is a condensed summary of an international multisociety statement on ethics of artificial intelligence (AI) in radiology produced by the ACR, European Society of Radiology, RSNA, Society for Imaging Informatics in Medicine, European Society of Medical Imaging Informatics, Canadian Association of Radiologists, and American Association of Physicists in Medicine.AI has great potential to increase efficiency and accuracy throughout radiology, but also carries inherent pitfalls and biases. Widespread use of AI-based intelligent and autonomous systems in radiology can increase the risk of systemic errors with high consequence, and highlights complex ethical and societal issues. Currently, there is little experience using AI for patient care in diverse clinical settings. Extensive research is needed to understand how to best deploy AI in clinical practice.This statement highlights our consensus that ethical use of AI in radiology should promote well-being, minimize harm, and ensure that the benefits and harms are distributed among stakeholders in a just manner. We believe AI should respect human rights and freedoms, including dignity and privacy. It should be designed for maximum transparency and dependability. Ultimate responsibility and accountability for AI remains with its human designers and operators for the foreseeable future.The radiology community should start now to develop codes of ethics and practice for AI which promote any use that helps patients and the common good and should block use of radiology data and algorithms for financial gain without those two attributes.",
    "doi": "10.1186/s13244-019-0785-8",
    "url": "https://www.semanticscholar.org/paper/fda514d275ca73a51d72c325ab2108564bbc502f",
    "pdf_url": "https://insightsimaging.springeropen.com/track/pdf/10.1186/s13244-019-0785-8",
    "venue": "Insights into Imaging",
    "citation_count": 245,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586851"
  },
  {
    "source": "semantic_scholar",
    "source_id": "5bc0d85f950bb2b9126f431acf84a07ba598da9b",
    "title": "Artificial Intelligence of Internet of Things (AIoT) Technology-based Law Enforcement Process",
    "authors": [
      "Muhammad Iqbal Tarigan",
      "Noviyanti Wulandari Sitepu"
    ],
    "year": 2023,
    "abstract": "Technological developments are increasingly developing in all fields, unstoppable in the area of law and the role of this IoT technology in solving legal problems, considering Society 5.0, which focuses on building a humane and prosperous society, especially people in Indonesia. And the role of IoT on the legal side is expected to be the answer for an appropriate and fair law enforcement process. IoT Technology collaboration with all sectors of human life, for example, legal, social and economic, as well as natural resource factors and human resources, are still needed. IoT is expected to be a tool to achieve a level of accuracy, real-time, fast, and stability. In the era of Society 5.0, all aspects were asked to be fast so as not to be left behind in any sector; the ability factor of the human being, namely human resources, also determines whether a matter or case can be appropriately resolved. This article is one of the review articles on the role of IoT in law enforcement. Some parameters within the Internet of Things form Artificial Intelligence, Deep Learning, Big Data, and Machine Learning. Solutions with AI can be seen in the lie detection system.",
    "doi": "10.31763/iota.v3i1.577",
    "url": "https://www.semanticscholar.org/paper/5bc0d85f950bb2b9126f431acf84a07ba598da9b",
    "pdf_url": "https://pubs.ascee.org/index.php/iota/article/download/577/172",
    "venue": "Internet of Things and Artificial Intelligence Journal",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586855"
  },
  {
    "source": "semantic_scholar",
    "source_id": "a328514f922f3bec2ad163218985cbe3cc532d88",
    "title": "Legal Framework for Regulating AI in Smart Cities: Privacy, Surveillance, and Ethics",
    "authors": [
      "Muath Mohammed Alashqar",
      "Ahmed F. S. Abulehia",
      "Ahmad Ali Atieh",
      "Mo\u2019men Hani Mahmoud",
      "M. Alzubi"
    ],
    "year": 2025,
    "abstract": "The swift incorporation of Artificial Intelligence (AI) in smart cities markedly improves urban administration, enriches public services, and optimizes resource distribution. This technology-driven progress presents significant legal and ethical challenges, especially around data privacy, surveillance, and liability. This article assesses existing legal frameworks regulating AI in smart cities, highlighting data protection laws like GDPR, ethical implications in automated public services, as well as liability for AI-related malfunctions. The results emphasize the necessity of governmental supervision, transparency, and community involvement to guarantee that AI is utilized responsibly and conforms to human rights standards while promoting innovation. Practical recommendations are offered for policymakers to develop balanced frameworks that both enhance technical progress and protect the public's trust.",
    "doi": "10.1109/AI2E64943.2025.10983107",
    "url": "https://www.semanticscholar.org/paper/a328514f922f3bec2ad163218985cbe3cc532d88",
    "pdf_url": "",
    "venue": "2025 International Conference for Artificial Intelligence, Applications, Innovation and Ethics (AI2E)",
    "citation_count": 6,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586859"
  },
  {
    "source": "semantic_scholar",
    "source_id": "bf823a8b26bba29ff976ee85167ec113f1cdf93b",
    "title": "Ethical review of AI health research: An exploratory qualitative study on experiences and challenges of research ethics committees in Uganda",
    "authors": [
      "Sylvia Nabukenya",
      "William Wasswa",
      "Adelline Twimukye",
      "E. Mwaka"
    ],
    "year": 2025,
    "abstract": "The use of artificial intelligence (AI) in health research of both communicable and non-communicable diseases has shown an improvement in diagnosis, reduced researchers\u2019 workload, and facilitated real-time data analysis. However, several ethical concerns on public trust, privacy, accountability and fairness regarding access to AI have been pointed out to expose the users of AI to harm. Whereas AI technologies continue to grow rapidly in health research, there is limited knowledge on research ethics committees\u2019 (REC) current practices and challenges experienced when reviewing AI health research in low resource settings like Uganda. This study examined the current practices and challenges experienced by ethics committees during the review of AI health research. We adopted a qualitative exploratory approach, where in-depth interviews were conducted with 12 REC members and 6 REC administrators between May and September 2024. A thematic approach was used to analyze the results. Three themes merged from this data including current practices of RECs, challenges experienced by REC members when reviewing AI health research proposals, and the proposed solutions to the mentioned challenges. Of interest, respondents expressed concerns of limited training and expertise in field of AI, inadequate guiding and reference tools, and unreasonable demands from researchers. Therefore, it is essential to build capacity for REC members and develop comprehensive guidelines, and standard operating procedures for efficient and constructive feedback to researchers.",
    "doi": "10.1177/17470161251370400",
    "url": "https://www.semanticscholar.org/paper/bf823a8b26bba29ff976ee85167ec113f1cdf93b",
    "pdf_url": "",
    "venue": "Research Ethics",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586862"
  },
  {
    "source": "semantic_scholar",
    "source_id": "85a2a958cb6992445fab7dc3f76dc29ca1238843",
    "title": "Trust in Artificial Intelligence\u2013Based Clinical Decision Support Systems Among Health Care Workers: Systematic Review",
    "authors": [
      "H. Tun",
      "H. Rahman",
      "Lin Naing",
      "O. A. Malik"
    ],
    "year": 2024,
    "abstract": "Abstract Background Artificial intelligence\u2013based clinical decision support systems (AI-CDSSs) have enhanced personalized medicine and improved the efficiency of health care workers. Despite these opportunities, trust in these tools remains a critical factor for their successful integration into practice. Existing research lacks synthesized insights and actionable recommendations to guide the development of AI-CDSSs that foster trust among health care workers. Objective This systematic review aims to identify and synthesize key factors that influence health care workers\u2019 trust in AI-CDSSs and to provide actionable recommendations for enhancing their trust in these systems. Methods We conducted a systematic review of published studies from January 2020 to November 2024, retrieved from PubMed, Scopus, and Google Scholar. Inclusion criteria focused on studies that examined health care workers\u2019 perceptions, experiences, and trust in AI-CDSSs. Studies in non\u2013English languages and those unrelated to health care settings were excluded. Two independent reviewers followed the Cochrane Collaboration Handbook and PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) 2020 guidelines. Analysis was conducted using a developed data charter. The Critical Appraisal Skills Programme tool was applied to assess the quality of the included studies and to evaluate the risk of bias, ensuring a rigorous and systematic review process. Results A total of 27 studies met the inclusion criteria, involving diverse health care workers, predominantly in hospitalized settings. Qualitative methods were the most common (n=16, 59%), with sample sizes ranging from small focus groups to cohorts of over 1000 participants. Eight key themes emerged as pivotal in improving health care workers\u2019 trust in AI-CDSSs: (1) System Transparency, emphasizing the need for clear and interpretable AI; (2) Training and Familiarity, highlighting the importance of knowledge sharing and user education; (3) System Usability, focusing on effective integration into clinical workflows; (4) Clinical Reliability, addressing the consistency and accuracy of system performance; (5) Credibility and Validation, referring to how well the system performs across diverse clinical contexts; (6) Ethical Consideration, examining medicolegal liability, fairness, and adherence to ethical standards;(7) Human Centric Design, pioritizing patient centered approaches; (8) Customization and Control, highlighting the need to tailor tools to specific clinical needs while preserving health care providers\u2019 decision-making autonomy. Barriers to trust included algorithmic opacity, insufficient training, and ethical challenges, while enabling factors for health care workers\u2019 trust in AI-CDSS tools were transparency, usability, and clinical reliability. Conclusions The findings highlight the need for explainable AI models, comprehensive training, stakeholder involvement, and human-centered design to foster health care workers\u2019 trust in AI-CDSSs. Although the heterogeneity of study designs and lack of specific data limit further analysis, this review bridges existing gaps by identifying key themes that support trust in AI-CDSSs. It also recommends that future research include diverse demographics, cross-cultural perspectives, and contextual differences in trust across various health care professions.",
    "doi": "10.2196/69678",
    "url": "https://www.semanticscholar.org/paper/85a2a958cb6992445fab7dc3f76dc29ca1238843",
    "pdf_url": "https://doi.org/10.2196/69678",
    "venue": "Journal of Medical Internet Research",
    "citation_count": 20,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586866"
  },
  {
    "source": "semantic_scholar",
    "source_id": "3ec72020d88f68fa9102192502b80d964678eea8",
    "title": "Ethics of Artificial Intelligence in Radiology: Summary of the Joint European and North American Multisociety Statement.",
    "authors": [
      "MD \u2022 J. Raymond Geis",
      "M. F. \u2022. Adrian P. Brady",
      "MD \u2022 Carol C. Wu",
      "PhD \u2022 Jack Spencer",
      "MD Erik Ranschaert",
      "PhD \u2022 Jacob L. Jaremko",
      "P. \u2022. S. G. Md",
      "PhD \u2022 Andrea Borondy Kitts",
      "M. Ms",
      "M. M. M. \u2022. Elmar Kotter",
      "MBChB Judy Wawira Gichoya",
      "MS \u2022 Tessa S. Cook",
      "PhD \u2022 Matthew B. Morgan",
      "M. \u2022. A. Md",
      "M. \u2022. N. M. Md",
      "M. \u2022. M. Md"
    ],
    "year": 2019,
    "abstract": "This is a condensed summary of an international multisociety statement on ethics of artificial intelligence (AI) in radiology produced by the ACR, European Society of Radiology, RSNA, Society for Imaging Informatics in Medicine, European Society of Medical Imaging Informatics, Canadian Association of Radiologists, and American Association of Physicists in Medicine. AI has great potential to increase efficiency and accuracy throughout radiology, but it also carries inherent pitfalls and biases. Widespread use of AI-based intelligent and autonomous systems in radiology can increase the risk of systemic errors with high consequence and highlights complex ethical and societal issues. Currently, there is little experience using AI for patient care in diverse clinical settings. Extensive research is needed to understand how to best deploy AI in clinical practice. This statement highlights our consensus that ethical use of AI in radiology should promote well-being, minimize harm, and ensure that the benefits and harms are distributed among stakeholders in a just manner. We believe AI should respect human rights and freedoms, including dignity and privacy. It should be designed for maximum transparency and dependability. Ultimate responsibility and accountability for AI remains with its human designers and operators for the foreseeable future. The radiology community should start now to develop codes of ethics and practice for AI that promote any use that helps patients and the common good and should block use of radiology data and algorithms for financial gain without those two attributes. This article is a simultaneous joint publication in Radiology, Journal of the American College of Radiology, Canadian Association of Radiologists Journal, and Insights into Imaging. Published under a CC BY-NC-ND 4.0 license. Online supplemental material is available for this article.",
    "doi": "10.1148/radiol.2019191586",
    "url": "https://www.semanticscholar.org/paper/3ec72020d88f68fa9102192502b80d964678eea8",
    "pdf_url": "https://pubs.rsna.org/doi/pdf/10.1148/radiol.2019191586",
    "venue": "Radiology",
    "citation_count": 196,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586870"
  },
  {
    "source": "semantic_scholar",
    "source_id": "40c8d2478a3ec125b85e6d19296eab0f9d05feb7",
    "title": "Societal Issues Concerning the Application of Artificial Intelligence in Medicine",
    "authors": [
      "A. Vellido"
    ],
    "year": 2018,
    "abstract": "Background: Medicine is becoming an increasingly data-centred discipline and, beyond classical statistical approaches, artificial intelligence (AI) and, in particular, machine learning (ML) are attracting much interest for the analysis of medical data. It has been argued that AI is experiencing a fast process of commodification. This characterization correctly reflects the current process of industrialization of AI and its reach into society. Therefore, societal issues related to the use of AI and ML should not be ignored any longer and certainly not in the medical domain. These societal issues may take many forms, but they all entail the design of models from a human-centred perspective, incorporating human-relevant requirements and constraints. In this brief paper, we discuss a number of specific issues affecting the use of AI and ML in medicine, such as fairness, privacy and anonymity, explainability and interpretability, but also some broader societal issues, such as ethics and legislation. We reckon that all of these are relevant aspects to consider in order to achieve the objective of fostering acceptance of AI- and ML-based technologies, as well as to comply with an evolving legislation concerning the impact of digital technologies on ethically and privacy sensitive matters. Our specific goal here is to reflect on how all these topics affect medical applications of AI and ML. This paper includes some of the contents of the \u201c2nd Meeting of Science and Dialysis: Artificial Intelligence,\u201d organized in the Bellvitge University Hospital, Barcelona, Spain. Summary and Key Messages: AI and ML are attracting much interest from the medical community as key approaches to knowledge extraction from data. These approaches are increasingly colonizing ambits of social impact, such as medicine and healthcare. Issues of social relevance with an impact on medicine and healthcare include (although they are not limited to) fairness, explainability, privacy, ethics and legislation.",
    "doi": "10.1159/000492428",
    "url": "https://www.semanticscholar.org/paper/40c8d2478a3ec125b85e6d19296eab0f9d05feb7",
    "pdf_url": "https://www.karger.com/Article/Pdf/492428",
    "venue": "Kidney Diseases",
    "citation_count": 97,
    "fields_of_study": [
      "Sociology",
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586874"
  },
  {
    "source": "semantic_scholar",
    "source_id": "2275d507e38f03c2147983b20be75f69950c5340",
    "title": "Ethics in international HRD: examining conversational AI and HR chatbots",
    "authors": [
      "Natalie Bidnick Andreas"
    ],
    "year": 2024,
    "abstract": "\nPurpose\nThe integration of artificial intelligence (AI) technologies like conversational AI and HR chatbots in international human resource development (HRD) presents both productivity benefits and ethical challenges. This study aims to examine the ethical dimensions of AI-driven HR chatbots, emphasizing the need for fairness, autonomy and nondiscrimination. It discusses inherent biases in AI systems and addresses linguistic, cultural and accessibility issues. The paper advocates for a comprehensive risk assessment approach to guide ethical integration, proposing a \u201crisk management by design\u201d framework. By embracing ethical principles and robust risk management strategies, organizations can navigate AI-driven HR technologies while upholding fairness and equity in global workforce management.\n\n\nDesign/methodology/approach\nSystematic literature review.\n\n\nFindings\nThe paper advocates for a comprehensive risk assessment approach to guide ethical integration, proposing a \u201crisk management by design\u201d framework.\n\n\nPractical implications\nBy embracing ethical principles and robust risk management strategies, organizations can navigate AI-driven HR technologies while upholding fairness and equity in global workforce management.\n\n\nOriginality/value\nThis study explores the intricate ethical landscape surrounding AI-driven HR chatbots, spotlighting the imperatives of fairness, autonomy, and nondiscrimination. Uncovering biases inherent in AI systems, it addresses linguistic, cultural, and accessibility concerns. Proposing a pioneering \u201crisk management by design\u201d framework, the study advocates for a holistic approach to ethical integration, ensuring organizations navigate the complexities of AI-driven HR technologies while prioritizing fairness and equity in global workforce management.\n",
    "doi": "10.1108/shr-03-2024-0018",
    "url": "https://www.semanticscholar.org/paper/2275d507e38f03c2147983b20be75f69950c5340",
    "pdf_url": "",
    "venue": "Strategic HR Review",
    "citation_count": 5,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586877"
  },
  {
    "source": "semantic_scholar",
    "source_id": "653ddda1db304633a1ad4f7ac062e2295a077b59",
    "title": "Embryo selection through artificial intelligence versus embryologists: a systematic review",
    "authors": [
      "M. Salih",
      "C. Austin",
      "R. Warty",
      "C. Tiktin",
      "D. Rolnik",
      "M. Momeni",
      "H. Rezatofighi",
      "S. Reddy",
      "V. Smith",
      "B. Vollenhoven",
      "F. Horta"
    ],
    "year": 2023,
    "abstract": "Abstract STUDY QUESTION What is the present performance of artificial intelligence (AI) decision support during embryo selection compared to the standard embryo selection by embryologists? SUMMARY ANSWER AI consistently outperformed the clinical teams in all the studies focused on embryo morphology and clinical outcome prediction during embryo selection assessment. WHAT IS KNOWN ALREADY The ART success rate is \u223c30%, with a worrying trend of increasing female age correlating with considerably worse results. As such, there have been ongoing efforts to address this low success rate through the development of new technologies. With the advent of AI, there is potential for machine learning to be applied in such a manner that areas limited by human subjectivity, such as embryo selection, can be enhanced through increased objectivity. Given the potential of AI to improve IVF success rates, it remains crucial to review the performance between AI and embryologists during embryo selection. STUDY DESIGN, SIZE, DURATION The search was done across PubMed, EMBASE, Ovid Medline, and IEEE Xplore from 1 June 2005 up to and including 7 January 2022. Included articles were also restricted to those written in English. Search terms utilized across all databases for the study were: (\u2018Artificial intelligence\u2019 OR \u2018Machine Learning\u2019 OR \u2018Deep learning\u2019 OR \u2018Neural network\u2019) AND (\u2018IVF\u2019 OR \u2018in vitro fertili*\u2019 OR \u2018assisted reproductive techn*\u2019 OR \u2018embryo\u2019), where the character \u2018*\u2019 refers the search engine to include any auto completion of the search term. PARTICIPANTS/MATERIALS, SETTING, METHODS A literature search was conducted for literature relating to AI applications to IVF. Primary outcomes of interest were accuracy, sensitivity, and specificity of the embryo morphology grade assessments and the likelihood of clinical outcomes, such as clinical pregnancy after IVF treatments. Risk of bias was assessed using the Modified Down and Black Checklist. MAIN RESULTS AND THE ROLE OF CHANCE Twenty articles were included in this review. There was no specific embryo assessment day across the studies\u2014Day 1 until Day 5/6 of embryo development was investigated. The types of input for training AI algorithms were images and time-lapse (10/20), clinical information (6/20), and both images and clinical information (4/20). Each AI model demonstrated promise when compared to an embryologist\u2019s visual assessment. On average, the models predicted the likelihood of successful clinical pregnancy with greater accuracy than clinical embryologists, signifying greater reliability when compared to human prediction. The AI models performed at a median accuracy of 75.5% (range 59\u201394%) on predicting embryo morphology grade. The correct prediction (Ground Truth) was defined through the use of embryo images according to post embryologists\u2019 assessment following local respective guidelines. Using blind test datasets, the embryologists\u2019 accuracy prediction was 65.4% (range 47\u201375%) with the same ground truth provided by the original local respective assessment. Similarly, AI models had a median accuracy of 77.8% (range 68\u201390%) in predicting clinical pregnancy through the use of patient clinical treatment information compared to 64% (range 58\u201376%) when performed by embryologists. When both images/time-lapse and clinical information inputs were combined, the median accuracy by the AI models was higher at 81.5% (range 67\u201398%), while clinical embryologists had a median accuracy of 51% (range 43\u201359%). LIMITATIONS, REASONS FOR CAUTION The findings of this review are based on studies that have not been prospectively evaluated in a clinical setting. Additionally, a fair comparison of all the studies were deemed unfeasible owing to the heterogeneity of the studies, development of the AI models, database employed and the study design and quality. WIDER IMPLICATIONS OF THE FINDINGS AI provides considerable promise to the IVF field and embryo selection. However, there needs to be a shift in developers\u2019 perception of the clinical outcome from successful implantation towards ongoing pregnancy or live birth. Additionally, existing models focus on locally generated databases and many lack external validation. STUDY FUNDING/COMPETING INTERESTS This study was funded by Monash Data Future Institute. All authors have no conflicts of interest to declare. REGISTRATION NUMBER CRD42021256333",
    "doi": "10.1093/hropen/hoad031",
    "url": "https://www.semanticscholar.org/paper/653ddda1db304633a1ad4f7ac062e2295a077b59",
    "pdf_url": "https://academic.oup.com/hropen/article-pdf/2023/3/hoad031/51112668/hoad031.pdf",
    "venue": "Human Reproduction Open",
    "citation_count": 75,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586882"
  },
  {
    "source": "semantic_scholar",
    "source_id": "d3f67f5d1d8511446e61601084ee3c32bbf3a713",
    "title": "A Catalog of Fairness-Aware Practices in Machine Learning Engineering",
    "authors": [
      "Gianmario Voria",
      "Giulia Sellitto",
      "Carmine Ferrara",
      "Francesco Abate",
      "Andrea De Lucia",
      "F. Ferrucci",
      "Gemma Catolino",
      "Fabio Palomba"
    ],
    "year": 2024,
    "abstract": "Artificial Intelligence (AI)\u2019s widespread adoption in decision-making processes, particularly with the introduction of AI-based assistants, raises concerns about ethics and fairness, particularly regarding the treatment of sensitive features and potential discrimination against underrepresented groups. The software engineering community has responded by developing fairness-oriented metrics, empirical studies, and mitigation approaches. However, there remains a gap in understanding and categorizing practices for engineering fairness throughout the development lifecycle of AI-based solutions. This paper presents a catalog of practices for addressing fairness derived from a systematic mapping study. The study identifies and categorizes 28 practices from existing literature, mapping them onto different stages of the development lifecycle. From this catalog, actionable items and implications for both researchers and practitioners in software engineering were extracted. This work aims to provide a comprehensive resource for integrating fairness considerations into the development and deployment of AI systems, enhancing their reliability, accountability, and credibility.",
    "doi": "10.1145/3727967.3756824",
    "url": "https://www.semanticscholar.org/paper/d3f67f5d1d8511446e61601084ee3c32bbf3a713",
    "pdf_url": "",
    "venue": "EASE Companion",
    "citation_count": 5,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586886"
  },
  {
    "source": "semantic_scholar",
    "source_id": "cf0709674031ca3b2e3d514b7b1205df220edddf",
    "title": "Artificial Intelligence Applications to Measure Food and Nutrient Intakes: Scoping Review",
    "authors": [
      "Jiakun Zheng",
      "Junjie Wang",
      "Jing Shen",
      "R. An"
    ],
    "year": 2023,
    "abstract": "Background Accurate measurement of food and nutrient intake is crucial for nutrition research, dietary surveillance, and disease management, but traditional methods such as 24-hour dietary recalls, food diaries, and food frequency questionnaires are often prone to recall error and social desirability bias, limiting their reliability. With the advancement of artificial intelligence (AI), there is potential to overcome these limitations through automated, objective, and scalable dietary assessment techniques. However, the effectiveness and challenges of AI applications in this domain remain inadequately explored. Objective This study aimed to conduct a scoping review to synthesize existing literature on the efficacy, accuracy, and challenges of using AI tools in assessing food and nutrient intakes, offering insights into their current advantages and areas of improvement. Methods This review followed the PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses extension for Scoping Reviews) guidelines. A comprehensive literature search was conducted in 4 databases\u2014PubMed, Web of Science, Cochrane Library, and EBSCO\u2014covering publications from the databases\u2019 inception to June 30, 2023. Studies were included if they used modern AI approaches to assess food and nutrient intakes in human subjects. Results The 25 included studies, published between 2010 and 2023, involved sample sizes ranging from 10 to 38,415 participants. These studies used a variety of input data types, including food images (n=10), sound and jaw motion data from wearable devices (n=9), and text data (n=4), with 2 studies combining multiple input types. AI models applied included deep learning (eg, convolutional neural networks), machine learning (eg, support vector machines), and hybrid approaches. Applications were categorized into dietary intake assessment, food detection, nutrient estimation, and food intake prediction. Food detection accuracies ranged from 74% to 99.85%, and nutrient estimation errors varied between 10% and 15%. For instance, the RGB-D (Red, Green, Blue-Depth) fusion network achieved a mean absolute error of 15% in calorie estimation, and a sound-based classification model reached up to 94% accuracy in detecting food intake based on jaw motion and chewing patterns. In addition, AI-based systems provided real-time monitoring capabilities, improving the precision of dietary assessments and demonstrating the potential to reduce recall bias typically associated with traditional self-report methods. Conclusions While AI demonstrated significant advantages in improving accuracy, reducing labor, and enabling real-time monitoring, challenges remain in adapting to diverse food types, ensuring algorithmic fairness, and addressing data privacy concerns. The findings suggest that AI has transformative potential for dietary assessment at both individual and population levels, supporting precision nutrition and chronic disease management. Future research should focus on enhancing the robustness of AI models across diverse dietary contexts and integrating biological sensors for a holistic dietary assessment approach.",
    "doi": "10.2196/54557",
    "url": "https://www.semanticscholar.org/paper/cf0709674031ca3b2e3d514b7b1205df220edddf",
    "pdf_url": "https://doi.org/10.2196/54557",
    "venue": "Journal of Medical Internet Research",
    "citation_count": 31,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586889"
  },
  {
    "source": "semantic_scholar",
    "source_id": "f17bd30d769369c2dfc1e663adb6c2d8ccde4119",
    "title": "Redefining Architectural Ethics in the Age of AI: A Framework for Responsible Innovation",
    "authors": [
      "Walaa Hussien",
      "Amir El-Ghamry",
      "Noha Elfliky",
      "Safwat Hamad"
    ],
    "year": 2025,
    "abstract": "The combination of Artificial Intelligence (AI) and architecture is transforming how we design and build spaces, opening new possibilities for creativity, efficiency, and problem solving. Architects can now address complex challenges in ways that were previously unimaginable, thanks to AI tools that offer smarter, faster solutions. But alongside these advancements come important ethical questions, how do we ensure that these technologies are used in ways that align with human values, uphold professional integrity, and promote sustainability? This paper presents a fresh framework for integrating AI ethically in architecture, focusing on core principles such as transparency, accountability, fairness, privacy, and environmental responsibility. By exploring real world examples and potential future scenarios, we offer practical guidance to architects, AI developers, policymakers, and educators. The goal is to help them use AI not just as a tool for innovation, but to create more inclusive, sustainable, and ethically responsible built environments that truly serve communities.",
    "doi": "10.1109/GCAIoT68269.2025.11275538",
    "url": "https://www.semanticscholar.org/paper/f17bd30d769369c2dfc1e663adb6c2d8ccde4119",
    "pdf_url": "",
    "venue": "Global Conference on Artificial Intelligence and Internet of Things",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586893"
  },
  {
    "source": "semantic_scholar",
    "source_id": "3060d714cb70857530c6d366bd2276596bd9a3bd",
    "title": "A multi-institutional study using artificial intelligence to provide reliable and fair feedback to surgeons",
    "authors": [
      "Dani Kiyasseh",
      "Jasper A. Laca",
      "Taseen F. Haque",
      "B. Miles",
      "C. Wagner",
      "D. Donoho",
      "Anima Anandkumar",
      "Andrew J. Hung"
    ],
    "year": 2023,
    "abstract": "Surgeons who receive reliable feedback on their performance quickly master the skills necessary for surgery. Such performance-based feedback can be provided by a recently-developed artificial intelligence (AI) system that assesses a surgeon\u2019s skills based on a surgical video while simultaneously highlighting aspects of the video most pertinent to the assessment. However, it remains an open question whether these highlights, or explanations, are equally reliable for all surgeons. Here, we systematically quantify the reliability of AI-based explanations on surgical videos from three hospitals across two continents by comparing them to explanations generated by humans experts. To improve the reliability of AI-based explanations, we propose the strategy of training with explanations \u2013TWIX \u2013which uses human explanations as supervision to explicitly teach an AI system to highlight important video frames. We show that while AI-based explanations often align with human explanations, they are not equally reliable for different sub-cohorts of surgeons (e.g., novices vs. experts), a phenomenon we refer to as an explanation bias. We also show that TWIX enhances the reliability of AI-based explanations, mitigates the explanation bias, and improves the performance of AI systems across hospitals. These findings extend to a training environment where medical students can be provided with feedback today. Our study informs the impending implementation of AI-augmented surgical training and surgeon credentialing programs, and contributes to the safe and fair democratization of surgery. Surgeons aim to master skills necessary for surgery. One such skill is suturing which involves connecting objects together through a series of stitches. Mastering these surgical skills can be improved by providing surgeons with feedback on the quality of their performance. However, such feedback is often absent from surgical practice. Although performance-based feedback can be provided, in theory, by recently-developed artificial intelligence (AI) systems that use a computational model to assess a surgeon\u2019s skill, the reliability of this feedback remains unknown. Here, we compare AI-based feedback to that provided by human experts and demonstrate that they often overlap with one another. We also show that explicitly teaching an AI system to align with human feedback further improves the reliability of AI-based feedback on new videos of surgery. Our findings outline the potential of AI systems to support the training of surgeons by providing feedback that is reliable and focused on a particular skill, and guide programs that give surgeons qualifications by complementing skill assessments with explanations that increase the trustworthiness of such assessments. Kiyasseh et al. compare the quality of feedback provided to surgeons by artificial intelligence (AI) to that provided by human experts. Teaching an AI system to explicitly follow human explanations improves the reliability and reduces the bias of AI-based feedback.",
    "doi": "10.1038/s43856-023-00263-3",
    "url": "https://www.semanticscholar.org/paper/3060d714cb70857530c6d366bd2276596bd9a3bd",
    "pdf_url": "https://www.nature.com/articles/s43856-023-00263-3.pdf",
    "venue": "Communications Medicine",
    "citation_count": 52,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586896"
  },
  {
    "source": "semantic_scholar",
    "source_id": "2288d1bd124febc26d37828b1dfa7699cd88f1f4",
    "title": "Representation of intensivists\u2019 race/ethnicity, sex, and age by artificial intelligence: a cross-sectional study of two text-to-image models",
    "authors": [
      "M. Gisselbaek",
      "M\u00e9lanie Suppan",
      "Laurens Minsart",
      "Ekin K\u00f6selerli",
      "S. Nainan Myatra",
      "Idit Matot",
      "Odmara L. Barreto Chang",
      "Sarah Saxena",
      "J. Berger-Estilita"
    ],
    "year": 2024,
    "abstract": "Integrating artificial intelligence (AI) into intensive care practices can enhance patient care by providing real-time predictions and aiding clinical decisions. However, biases in AI models can undermine diversity, equity, and inclusion (DEI) efforts, particularly in visual representations of healthcare professionals. This work aims to examine the demographic representation of two AI text-to-image models, Midjourney and ChatGPT DALL-E 2, and assess their accuracy in depicting the demographic characteristics of intensivists. This cross-sectional study, conducted from May to July 2024, used demographic data from the USA workforce report (2022) and intensive care trainees (2021) to compare real-world intensivist demographics with images generated by two AI models, Midjourney v6.0 and ChatGPT 4.0 DALL-E 2. A total of 1,400 images were generated across ICU subspecialties, with outcomes being the comparison of sex, race/ethnicity, and age representation in AI-generated images to the actual workforce demographics. The AI models demonstrated noticeable biases when compared to the actual U.S. intensive care workforce data, notably overrepresenting White and young doctors. ChatGPT-DALL-E2 produced less female (17.3% vs 32.2%, p\u2009<\u20090.0001), more White (61% vs 55.1%, p\u2009=\u20090.002) and younger (53.3% vs 23.9%, p\u2009<\u20090.001) individuals. While Midjourney depicted more female (47.6% vs 32.2%, p\u2009<\u20090.001), more White (60.9% vs 55.1%, p\u2009=\u20090.003) and younger intensivist (49.3% vs 23.9%, p\u2009<\u20090.001). Substantial differences between the specialties within both models were observed. Finally when compared together, both models showed significant differences in the Portrayal of intensivists. Significant biases in AI images of intensivists generated by ChatGPT DALL-E 2 and Midjourney reflect broader cultural issues, potentially perpetuating stereotypes of healthcare worker within the society. This study highlights the need for an approach that ensures fairness, accountability, transparency, and ethics in AI applications for healthcare.",
    "doi": "10.1186/s13054-024-05134-4",
    "url": "https://www.semanticscholar.org/paper/2288d1bd124febc26d37828b1dfa7699cd88f1f4",
    "pdf_url": "",
    "venue": "Critical Care",
    "citation_count": 15,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586901"
  },
  {
    "source": "semantic_scholar",
    "source_id": "43f1d604433d20000db637f5ce57301d947adc76",
    "title": "Uncovering Creative Accounting Practices in MSMEs from the Perspective of Ethics and Professional Compliance",
    "authors": [
      "Joanna Azmi Alyssa Dewi",
      "Elga Yulindisti",
      "Rusliyawati Rusliyawati",
      "Marjono Marjono"
    ],
    "year": 2025,
    "abstract": "This study explores how leaders adapt to institutional changes driven by artificial intelligence (AI), focusing on leadership strategies, managerial flexibility, and their impact on human resource engagement. Using a qualitative case study with 12 key informants from a higher education institution in Riau, data were collected through in-depth interviews and analyzed thematically. Findings show that effective leadership adaptation relies on articulating a clear AI transformation vision, developing human resource capacity through continuous training, and implementing participatory communication to reduce resistance. The study concludes that leadership adaptation is crucial for sustaining AI-based transformation and contributes both theoretically and practically to adaptive leadership and HR management in the digital era.",
    "doi": "10.55927/fjst.v4i9.247",
    "url": "https://www.semanticscholar.org/paper/43f1d604433d20000db637f5ce57301d947adc76",
    "pdf_url": "",
    "venue": "Formosa Journal of Science and Technology",
    "citation_count": 0,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586905"
  },
  {
    "source": "semantic_scholar",
    "source_id": "4541dc6e4200df5ed9cf28e529ac56d73c8017ab",
    "title": "Integrating AI Into Arbitration: Balancing Efficiency With Fairness and Legal Compliance",
    "authors": [
      "T. Alhasan"
    ],
    "year": 2025,
    "abstract": "The integration of artificial intelligence (AI) into arbitration marks a significant transformation in alternative dispute resolution, aiming to enhance efficiency, objectivity, and accessibility. Advanced AI systems now extend beyond administrative tasks to analyze complex legal data, predict case outcomes, and even generate arbitral awards. This evolution addresses the growing volume and complexity of international disputes, particularly in commercial and investment arbitration. However, the adoption of AI introduces profound legal and ethical challenges. Key concerns include the absence of human judgment, potential biases embedded in AI algorithms, and the opacity of their decision\u2010making processes, accountability issues, and data privacy risks. Critically, current legal frameworks such as the New York Convention were not designed to accommodate AI\u2010generated awards, raising questions about their legitimacy, procedural fairness, and enforceability. This article explores these intersections, focusing on how AI impacts arbitration's efficiency and objectivity, the legal and ethical challenges arising from AI integration, and the extent to which existing legal frameworks accommodate AI\u2010generated awards. Employing a multidisciplinary approach that includes legal scholarship, case studies, and technological research, the analysis examines the practical implications of AI in arbitration and the specific enforcement challenges of AI\u2010generated awards. The article concludes with recommendations for regulatory reforms and the adoption of hybrid AI\u2010human models to balance technological benefits with the necessity for human oversight and ethical accountability.",
    "doi": "10.1002/crq.21470",
    "url": "https://www.semanticscholar.org/paper/4541dc6e4200df5ed9cf28e529ac56d73c8017ab",
    "pdf_url": "",
    "venue": "Conflict Resolution Quarterly",
    "citation_count": 34,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586908"
  },
  {
    "source": "semantic_scholar",
    "source_id": "d1d173f73e6ce917000391a22745b166c6825990",
    "title": "Evaluation of Explainable Artificial Intelligence using TOPSIS Method",
    "authors": [],
    "year": 2024,
    "abstract": "Explainable Artificial Intelligence (XAI) refers to the development of AI systems are transparent, explainable and their comprehensible for results can provide explanations or predictions. As AI technologies, particularly machine learning models, become more complex and sophisticated, there is a growing need to ensure that their decisions can be comprehended and trusted by humans, especially health, Finance and such as criminal justice in important domains. Evaluating Explainable Artificial Intelligence (XAI) is essential to ensure transparency, accountability, and user trust in AI systems. Interpretability is a key factor, examining how easily the model's internal mechanisms can be understood. Model transparency, feature importance, and the clarity of visualizations contribute to this aspect. Differentiate between post-hoc and intrinsic explanations, considering whether the model inherently provides interpretable insights. The distinction between local and global explanations is crucial, as it determines whether explanations focus on individual predictions or the overall model behavior. Robustness and consistency are assessed through stability and sensitivity analysis, ensuring that explanations remain reliable across similar instances. Additionally, ethical considerations, such as fairness and transparency in decision-making, must be addressed to uncover and mitigate biases. User feedback and the relevance of explanations to the specific use case contribute to a comprehensive evaluation, fostering the development of XAI systems that are not only technically robust but also ethically sound and user-friendly. The significance of research in Explainable Artificial Intelligence (XAI) lies in addressing critical challenges associated with the adoption and deployment of AI systems in various domains. As AI technologies, particularly complex machine learning models, become integral to decision-making processes in areas such as healthcare, finance, and criminal justice, the need for transparency and interpretability becomes paramount. Topsis involves optimizing from an advantageous standpoint by simultaneously minimizing the distance to and maximizing the distance from a reference point, which is defined in relation to solutions within a set of alternative options and numerous identification criteria. The importance of Topsis criteria lies in the potential to integrate comparative weights. This study conducts a comprehensive review of Topsis, exploring various weighing schemes and employing different distance measurements. Numerous applications of Topsis are examined, particularly its utilization in comparing results for a diverse set of multiple criteria data with varying weights. Interpretable Machine Learning Models, Human-Centric Design in XAI, Ethical Implications of XAI, Industry-specific Applications of XAI and Hybrid Approaches for Model Interpretability. Interpretability Metrics, Human-Subjective Evaluation, Algorithmic Robustness and Real-world Impact. the Ranking of Evaluation Explainable Artificial Intelligence. Industry-specific Applications of XAI is got the first rank whereas is the Ethical Implications of XAI is having the Lowest rank.",
    "doi": "10.46632/cset/2/2/2",
    "url": "https://www.semanticscholar.org/paper/d1d173f73e6ce917000391a22745b166c6825990",
    "pdf_url": "",
    "venue": "Computer Science, Engineering and Technology",
    "citation_count": 4,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586911"
  },
  {
    "source": "semantic_scholar",
    "source_id": "37b8605f350501ca4b7655627dbfbcd939f2a9eb",
    "title": "Engineering a social contract: Rawlsian distributive justice through algorithmic game theory and artificial intelligence",
    "authors": [
      "H. Ashrafian"
    ],
    "year": 2022,
    "abstract": "The potential for artificial intelligence algorithms and game theory concepts\u00a0to offer prescriptive and decision-making capability for humankind is increasingly recognized. This derives from the increasing availability of granular, multivariable, well-curated data offering analytical insights for necessarily complex human behaviors and activities. Of the multitude of situations that this decision-making aptitude presents, the application to governmental policy offers a commanding case. This would allow decisions to be made for the benefit of societies and citizens based on rigorous objective information devoid of the traditional approach of choosing policies and societal values based on the opinion of a handful of selected representatives who may be exposed to a lack of comprehensive data analysis capacity and subject to personal biases. There would need to be a critical requirement of wider socially responsible data practices here, beyond those of technical considerations and the incorporation of wider societal fairness approaches. Amongst the schools of political thought particularly acquiescent to the application by this approach would be the egalitarian approach of John Rawls. Here an Original Position\u2019s pre-determination tool of Veil of Ignorance and ensuing Difference Principal presents a method of distributive justice that can be clearly mathematically defined in economics theory through Wald\u2019s Maximin principle. This offers an opportunity to apply algorithmic game theory and artificial intelligence computational approaches to implement Rawlsian distributive justice that are presented and discussed. The outputs from the algorithmic acquaintance of Rawlsian egalitarianism with applicable state data, protected with appropriate privacy, security, legal, ethical and social governance could in turn lead to automated direct governmental choices and an objective Social Contract for citizens of digitally literate nations.",
    "doi": "10.1007/s43681-022-00253-6",
    "url": "https://www.semanticscholar.org/paper/37b8605f350501ca4b7655627dbfbcd939f2a9eb",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s43681-022-00253-6.pdf",
    "venue": "AI and Ethics",
    "citation_count": 8,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586915"
  },
  {
    "source": "semantic_scholar",
    "source_id": "c0df896966a7e4bb237bf39763e27b7f0c34704c",
    "title": "Introduction to the Special Issue on AI Fairness, Trust, and Ethics",
    "authors": [
      "L. Robert",
      "G. Bansal",
      "Nigel P. Melville",
      "Thomas F. Stafford"
    ],
    "year": 2020,
    "abstract": "It is our pleasure to welcome you to this AIS Transactions on Human Computer Interaction special issue on artificial intelligence (AI) fairness, trust, and ethics. This special issue received research papers that unpacked the potential, challenges, impacts, and theoretical implications of AI. This special issue contains four papers that integrate research across diverse fields of study, such as social science, computer science, engineering, design, values, and other diverse topics related to AI fairness, trust, and ethics broadly conceptualized. This issue contains three of the four papers (along with a regular paper of the journal). The fourth or last paper of this special issue is forthcoming in March 2021. We hope that you enjoy these papers and, like us, look forward to similar research published in AIS Transactions on Human Computer Interaction.",
    "doi": "10.17705/1thci.00134",
    "url": "https://www.semanticscholar.org/paper/c0df896966a7e4bb237bf39763e27b7f0c34704c",
    "pdf_url": "https://aisel.aisnet.org/cgi/viewcontent.cgi?article=1139&context=thci",
    "venue": "AIS Trans. Hum. Comput. Interact.",
    "citation_count": 14,
    "fields_of_study": [
      "Psychology",
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586919"
  },
  {
    "source": "semantic_scholar",
    "source_id": "ce04f60c9e019ce32e564a3d9465790efd43961c",
    "title": "Exploring Gender Bias and Algorithm Transparency: Ethical Considerations of AI in HRM",
    "authors": [
      "Jiaxing Du"
    ],
    "year": 2024,
    "abstract": "Opportunities and challenges are introduced by the integration of Artificial Intelligence (AI) into Human Resource Management (HRM). The paragraph discusses the ethical implications of AI applications in HRM, focusing on gender bias and algorithm transparency. It explores how AI-driven decision-making in HRM perpetuates gender bias, the importance of transparent algorithms for trust and accountability, and the role of regulatory frameworks in safeguarding ethical standards. The paper aims to provide a comprehensive analysis of the ethical landscape of AI in HRM and offers policy recommendations to mitigate bias and enhance transparency.",
    "doi": "10.53469/jtpms.2024.04(03).06",
    "url": "https://www.semanticscholar.org/paper/ce04f60c9e019ce32e564a3d9465790efd43961c",
    "pdf_url": "https://centuryscipub.com/index.php/JTPMS/article/download/539/461",
    "venue": "Journal of Theory and Practice of Management Science",
    "citation_count": 14,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586922"
  },
  {
    "source": "semantic_scholar",
    "source_id": "f820dc201869376d29da935d9c9dab7b892ac18b",
    "title": "AI and ML ethics, Law, Diversity, and Global Impact.",
    "authors": [
      "Katherine Drabiak",
      "Skylar Kyzer",
      "Valerie Nemov",
      "I. E. El Naqa"
    ],
    "year": 2023,
    "abstract": "Artificial intelligence (AI) and its machine learning (ML) algorithms are offering new promise for personalized biomedicine and more cost-effective healthcare with impressive technical capability to mimic human cognitive capabilities. However, widespread application of this promising technology has been limited in the medical domain and expectations have been tampered by ethical challenges and concerns regarding patient privacy, legal responsibility, trustworthiness, and fairness. To balance technical innovation with ethical applications of AI/ML, developers must demonstrate the AI functions as intended and adopt strategies to minimize the risks for failure or bias. This review describes the new ethical challenges created by AI/ML for clinical care and identifies specific considerations for its practice in medicine. We provide an overview of regulatory and legal issues applicable in Europe and the United States, a description of technical aspects to consider, and present recommendations for trustworthy AI/ML that promote transparency, minimize risks of bias or error, and protect the patient well-being.",
    "doi": "10.1259/bjr.20220934",
    "url": "https://www.semanticscholar.org/paper/f820dc201869376d29da935d9c9dab7b892ac18b",
    "pdf_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10546451",
    "venue": "British Journal of Radiology",
    "citation_count": 45,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586926"
  },
  {
    "source": "semantic_scholar",
    "source_id": "bf59075b7fd5e28d7f87f6302d2537b3b37549a5",
    "title": "The Artificial Intelligence application in Aesthetic Medicine: How ChatGPT can Revolutionize the Aesthetic World",
    "authors": [
      "G. Buzzaccarini",
      "R. Degliuomini",
      "M. Borin"
    ],
    "year": 2023,
    "abstract": null,
    "doi": "10.1007/s00266-023-03416-w",
    "url": "https://www.semanticscholar.org/paper/bf59075b7fd5e28d7f87f6302d2537b3b37549a5",
    "pdf_url": "",
    "venue": "Aesthetic Plastic Surgery",
    "citation_count": 29,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586929"
  },
  {
    "source": "semantic_scholar",
    "source_id": "818f557ca8283b054d9a812112788efb198b3704",
    "title": "Ethical Concerns While Using Artificial Intelligence in Recruitment of Employees",
    "authors": [
      "Aashima Gupta",
      "Mridula Mishra"
    ],
    "year": 2022,
    "abstract": "Artificial Intelligence has evolved as an alternative to human intelligence. It affects the lives of billions of people. It mimics humans by solving problems and understanding the task. These Artificial Intelligence technologies must have some moral values and ethics incorporated within itself. The usage of AI is growing worldwide, posing more ethical issues to consider. In recent years, many companies have used various Artificial Intelligence tools such as chatbots and face recognition software for fulfilling their hiring needs. This research work will focus on such devices that help manage one of the important functions of human resources: recruitment. It will identify various challenges and ethical issues that a firm faces while assimilating Artificial Intelligence tools in the process of Recruitment. The hiring companies need to make the job seekers realize that AI-powered tools would be free from discrimination and safeguard privacy. The purpose of the study is to identify the ethical issues while incorporating Artificial Intelligence into hiring needs. The study will be based on reviews and features of applications. The study mentions various applications whose features might be unethical for job seekers. Findings reveal that the significant unethical issues faced by the hiring companies are Data privacy and unconscious biasness. The biasness is due to the algorithm that works according to the inputs fed to build it, and the programmer might have subconscious biasness in his mind. AI has restored concerns regarding privacy and data protection. According to a report by UNESCO, Women make up only 22% of all AI professionals. Gender prejudices and stereotyping are perpetuated in AI technologies due to their underrepresentation in the sector. Virtual personal assistants like Siri, Alexa, and Cortana are \u201cfemale\u201d by default, which is no accident. The submissiveness they display is an illustration of how Artificial Intelligence (AI) might continue to support and extend gender bias in our society.",
    "doi": "10.21272/bel.6(2).6-11.2022",
    "url": "https://www.semanticscholar.org/paper/818f557ca8283b054d9a812112788efb198b3704",
    "pdf_url": "https://armgpublishing.sumdu.edu.ua/wp-content/uploads/2022/07/BEL_2_2022_1.pdf",
    "venue": "Business Ethics and Leadership",
    "citation_count": 18,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586933"
  },
  {
    "source": "semantic_scholar",
    "source_id": "3229e05e2b8e2514b34973109b6bf8268c7db758",
    "title": "Auditing Fairness and Explainability in Chest X-Ray Image Classifiers",
    "authors": [
      "Gemma Bordes",
      "Alan Perotti"
    ],
    "year": 2024,
    "abstract": ": Advancements in Artificial Intelligence have produced several tools that can be used in medical decision support systems. However, these models often exhibit the so-called \u2019black-box problem\u2019: an algorithmic diagnosis is produced, but no human-understandable details about the decision process can be obtained. This raises critical questions about fairness and explainability, crucial for equitable healthcare. In this paper we focus on chest X-ray image classification, auditing the reproducibility of previous results in terms of model bias, exploring the applicability of Explainable AI (XAI) techniques, and auditing the fairness of the produced explanations. We highlight the challenges in assessing the quality of explanations provided by XAI methods, particularly in the absence of ground truth. In turn, this strongly hampers the possibility of comparing explanation quality across patients sub-groups, which is a cornerstone in fairness audits. Our experiments illustrate the complexities in achieving transparent AI interpretations in medical diagnostics, underscoring the need both for reliable XAI techniques and more robust fairness auditing methods.",
    "doi": "10.5220/0012472400003636",
    "url": "https://www.semanticscholar.org/paper/3229e05e2b8e2514b34973109b6bf8268c7db758",
    "pdf_url": "https://doi.org/10.5220/0012472400003636",
    "venue": "International Conference on Agents and Artificial Intelligence",
    "citation_count": 2,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586936"
  },
  {
    "source": "semantic_scholar",
    "source_id": "4a79f1acaee07814b54f0eb1f2eba2c909606e7a",
    "title": "Who is responsible? US Public perceptions of AI governance through the lenses of trust and ethics",
    "authors": [
      "Prabu David",
      "Hyesun Choung",
      "John S. Seberger"
    ],
    "year": 2024,
    "abstract": "The governance of artificial intelligence (AI) is an urgent challenge that requires actions from three interdependent stakeholders: individual citizens, technology corporations, and governments. We conducted an online survey (N = 525) of US adults to examine their beliefs about the governance responsibility of these stakeholders as a function of trust and AI ethics. Different dimensions of trust and different ethical concerns were associated with beliefs in governance responsibility of the three stakeholders. Specifically, belief in the governance responsibility of the government was associated with ethical concerns about AI, whereas belief in governance responsibility of corporations was related to both ethical concerns and trust in AI. Belief in governance responsibility of individuals was related to human-centered values of trust in AI and fairness. Overall, the findings point to the need for an interdependent framework in which citizens, corporations, and governments share governance responsibilities, guided by trust and ethics as the guardrails.",
    "doi": "10.1177/09636625231224592",
    "url": "https://www.semanticscholar.org/paper/4a79f1acaee07814b54f0eb1f2eba2c909606e7a",
    "pdf_url": "",
    "venue": "Public Understanding of Science",
    "citation_count": 20,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586939"
  },
  {
    "source": "semantic_scholar",
    "source_id": "360c5a973329b5ce289da96864ce2106ae83e6e3",
    "title": "Enhancing the Fairness and Performance of Edge Cameras with Explainable AI",
    "authors": [
      "Truong Thanh Hung Nguyen",
      "V. Nguyen",
      "Quoc Hung Cao",
      "Van Binh Truong",
      "Quoc Khanh Nguyen",
      "Hung Cao"
    ],
    "year": 2024,
    "abstract": "The rising use of Artificial Intelligence (AI) in human detection on Edge camera systems has led to accurate but complex models, challenging to interpret and debug. Our research presents a diagnostic method using XAI for model debugging, with expert-driven problem identification and solution creation. Validated on the Bytetrack model in a real-world office Edge network, we found the training dataset as the main bias source and suggested model augmentation as a solution. Our approach helps identify model biases, essential for achieving fair and trustworthy models.",
    "doi": "10.1109/ICCE59016.2024.10444383",
    "url": "https://www.semanticscholar.org/paper/360c5a973329b5ce289da96864ce2106ae83e6e3",
    "pdf_url": "https://arxiv.org/pdf/2401.09852",
    "venue": "IEEE International Conference on Consumer Electronics",
    "citation_count": 2,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586943"
  },
  {
    "source": "semantic_scholar",
    "source_id": "59b3cf509ae22db9f1ac8a62426e6d8040625c86",
    "title": "Algor-ethics: charting the ethical path for AI in critical care",
    "authors": [
      "J. Montomoli",
      "M. M. Bitondo",
      "M. Cascella",
      "Emanuele Rezoagli",
      "L. Romeo",
      "Valentina Bellini",
      "Federico Semeraro",
      "E. Gamberini",
      "Emanuele Frontoni",
      "V. Agnoletti",
      "Mattia Altini",
      "Paolo Benanti",
      "E. Bignami"
    ],
    "year": 2024,
    "abstract": "The integration of Clinical Decision Support Systems (CDSS) based on artificial intelligence (AI) in healthcare is groundbreaking evolution with enormous potential, but its development and ethical implementation, presents unique challenges, particularly in critical care, where physicians often deal with life-threating conditions requiring rapid actions and patients unable to participate in the decisional process. Moreover, development of AI-based CDSS is complex and should address different sources of bias, including data acquisition, health disparities, domain shifts during clinical use, and cognitive biases in decision-making. In this scenario algor-ethics is mandatory and emphasizes the integration of \u2018Human-in-the-Loop\u2019 and \u2018Algorithmic Stewardship\u2019 principles, and the benefits of advanced data engineering. The establishment of Clinical AI Departments (CAID) is necessary to lead AI innovation in healthcare, ensuring ethical integrity and human-centered development in this rapidly evolving field.",
    "doi": "10.1007/s10877-024-01157-y",
    "url": "https://www.semanticscholar.org/paper/59b3cf509ae22db9f1ac8a62426e6d8040625c86",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10877-024-01157-y.pdf",
    "venue": "Journal of clinical monitoring and computing",
    "citation_count": 21,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586947"
  },
  {
    "source": "semantic_scholar",
    "source_id": "f64670a5f54fcce339a916497a001cbf02a9a04f",
    "title": "A Review on Fairness in Machine Learning",
    "authors": [
      "Dana Pessach",
      "E. Shmueli"
    ],
    "year": 2022,
    "abstract": "An increasing number of decisions regarding the daily lives of human beings are being controlled by artificial intelligence and machine learning (ML) algorithms in spheres ranging from healthcare, transportation, and education to college admissions, recruitment, provision of loans, and many more realms. Since they now touch on many aspects of our lives, it is crucial to develop ML algorithms that are not only accurate but also objective and fair. Recent studies have shown that algorithmic decision making may be inherently prone to unfairness, even when there is no intention for it. This article presents an overview of the main concepts of identifying, measuring, and improving algorithmic fairness when using ML algorithms, focusing primarily on classification tasks. The article begins by discussing the causes of algorithmic bias and unfairness and the common definitions and measures for fairness. Fairness-enhancing mechanisms are then reviewed and divided into pre-process, in-process, and post-process mechanisms. A comprehensive comparison of the mechanisms is then conducted, toward a better understanding of which mechanisms should be used in different scenarios. The article ends by reviewing several emerging research sub-fields of algorithmic fairness, beyond classification.",
    "doi": "10.1145/3494672",
    "url": "https://www.semanticscholar.org/paper/f64670a5f54fcce339a916497a001cbf02a9a04f",
    "pdf_url": "",
    "venue": "ACM Computing Surveys",
    "citation_count": 609,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586951"
  },
  {
    "source": "semantic_scholar",
    "source_id": "45d129e9ef09133d07c4ee7bd067e78ff88370ba",
    "title": "When Artificial Intelligence and Big Data Collide\u2014How Data Aggregation and Predictive Machines Threaten our Privacy and Autonomy",
    "authors": [
      "Alex Alben"
    ],
    "year": 2020,
    "abstract": "Artificial Intelligence and Big Data represent two profound technology trends. Professor Alben\u2019s article explores how Big Data feeds AI applications and makes the case that necessity to monitor such applications has become more immediate and consequential to protect our civil discourse and personal autonomy, especially as they are expressed on social media. Like many of the revolutionary technologies that preceded it, ranging from broadcast radio to atomic power, AI can be used for purposes that benefit human beings and purposes that threaten our very existence. The challenge for the next decade is to make sure that we harness AI with appropriate safeguards and limitations. With a perspective on previous \u201crevolutionary\u201d technologies, the article explains how personal data became profiled and marketed by data brokers over the past two decades with an emphasis on dangers to privacy rights. The article observes that it is critical to adopt an approach in the public policy realm that addresses the bias dangers of a technology, while enabling a fair and transparent implementation that allows our society to reap the benefits of adoption. It advocates solutions to improve the technology and adopt the best versions, not cut off development in early stages of the new technology\u2019s evolution. Drawing on the author\u2019s work as a state-level Chief Privacy Officer and a high-tech executive, the article concludes with four policy recommendations for curbing the flow of personal information into the Big Data economy: 1. Regulating data brokers; 2. Minimizing data by default; 3. Public Records Reform and 4. Improving personal data hygiene. _______________",
    "doi": "10.47289/aiej20201106",
    "url": "https://www.semanticscholar.org/paper/45d129e9ef09133d07c4ee7bd067e78ff88370ba",
    "pdf_url": "https://42bade24-c7d1-4b33-a885-3579694f405d.filesusr.com/ugd/c57e34_26064532afa64c72a70e5084dba7ab3c.pdf",
    "venue": "AI Ethics Journal",
    "citation_count": 1,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586954"
  },
  {
    "source": "semantic_scholar",
    "source_id": "7e1f70a74429e1804c602fdab2bb1a45adb1e100",
    "title": "Navigating ethical dimensions in algorithmic radiology: A call for action to ensure representation of low-resource contexts.",
    "authors": [
      "H. Shafeeq",
      "Ahmed",
      "Shafeeq Ahmed"
    ],
    "year": 2025,
    "abstract": "Artificial intelligence (AI) has revolutionised medicine, particularly radiology, transforming our ability to interpret complex imaging data. While traditional methods rely on subjective visual assessments, AI excels at recognising intricate patterns and providing quantitative and automated evaluations. In this commentary, I delve into the various ethical considerations in algorithmic radiology, beyond the conventional concerns. Focusing on utilitarianism, patient understanding, virtue ethics, and social contract theory, the paper contributes to a comprehensive understanding of the ethical landscape surrounding AI technologies. The challenges in the use of algorithmic AI in radiology underscore the significance of the ethics of care, responsiveness to context, and the role of human emotion, whether pertaining to the practitioner, the patient, or both. The social contract theory guides the responsibilities of healthcare professionals, urging action to address biases in AI algorithms and ensuring equitable representation of various ethnic and racial populations. Diversity in data must be prioritised to avoid disparities in administering healthcare and uphold patient rights in the adoption of AI. In terms of virtue ethics, professionalism and responsibility are crucial for radiologists adopting AI. Also, an absence of explicit guidelines on the use of AI in healthcare poses challenges, necessitating further discourse. Finally, a utilitarian perspective on public health mandates a fair distribution of imaging technologies to address prevalent health issues in a given population. In conclusion, this paper advocates for an ethical approach to AI integration, which aligns technology with human values and wellbeing, as we shape the future of healthcare.",
    "doi": "10.20529/ijme.2024.089",
    "url": "https://www.semanticscholar.org/paper/7e1f70a74429e1804c602fdab2bb1a45adb1e100",
    "pdf_url": "",
    "venue": "Indian Journal of Medical Ethics",
    "citation_count": 0,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586958"
  },
  {
    "source": "semantic_scholar",
    "source_id": "585d6882524e7b8cb4ea79c2852810673151db4d",
    "title": "Corporate digital responsibility (CDR) in construction engineering\u2014ethical guidelines for the application of digital transformation and artificial intelligence (AI) in user practice",
    "authors": [
      "B. Weber-Lewerenz"
    ],
    "year": 2021,
    "abstract": "Digitization is developing fast and has become a powerful tool for digital planning, construction and operations, for instance digital twins. Now is the right time for constructive approaches and to apply ethics-by-design in order to develop and implement a safe and efficient artificial intelligence (AI) application. So far, no study has addressed the key research question: Where can corporate digital responsibility (CDR) be allocated, and how shall an adequate ethical framework be designed to support digital innovations in order to make full use of the potentials of digitization and AI? Therefore, the research on how best practices meet their corporate responsibility in the digital transformation process and the requirements of the EU for trustworthy AI and its human-friendly use is essential. Its transformation bears a high potential for companies, is critical for success and thus, requires responsible handling. This study generates data by conducting case studies and interviewing experts as part of the qualitative method to win profound insights into applied practice. It provides an assessment of demands stated in the Sustainable Development Goals by the United Nations (SDGs), White Papers on AI by international institutions, European Commission and German Government requesting the consideration and protection of values and fundamental rights, the careful demarcation between machine (artificial) and human intelligence and the careful use of such technologies. The study discusses digitization and the impacts of AI in construction engineering from an ethical perspective. This research critically evaluates opportunities and risks concerning CDR in construction industry. To the author\u2019s knowledge, no study has set out to investigate how CDR in construction could be conceptualized, especially in relation to digitization and AI, to mitigate digital transformation both in large, medium- and small-sized companies. This study applies a holistic, interdisciplinary, inclusive approach to provide guidelines for orientation and examine benefits as well as risks of AI. Furthermore, the goal is to define ethical principles which are key for success, resource-cost-time efficiency and sustainability using digital technologies and AI in construction engineering to enhance digital transformation. This study concludes that innovative corporate organizations starting new business models are more likely to succeed than those dominated by a more conservative, traditional attitude. Highlights the role model function of construction engineering in human-led and value-based AI for other sectors, creates awareness of the potential of digital transformation and offers constructive solutions to shape this process for the benefit of companies and society. Fill in the construction engineering niche in the ongoing interdisciplinary debate \u201cEthics in AI\u201d and engage nationally and internationally recognized institutes as supporters and mentors. Identify CDR with ethical principles as the key driver for success, resources-cost-time efficiency and sustainability using digital technologies and AI in construction engineering. Highlights the role model function of construction engineering in human-led and value-based AI for other sectors, creates awareness of the potential of digital transformation and offers constructive solutions to shape this process for the benefit of companies and society. Fill in the construction engineering niche in the ongoing interdisciplinary debate \u201cEthics in AI\u201d and engage nationally and internationally recognized institutes as supporters and mentors. Identify CDR with ethical principles as the key driver for success, resources-cost-time efficiency and sustainability using digital technologies and AI in construction engineering.",
    "doi": "10.1007/s42452-021-04776-1",
    "url": "https://www.semanticscholar.org/paper/585d6882524e7b8cb4ea79c2852810673151db4d",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s42452-021-04776-1.pdf",
    "venue": "SN Applied Sciences",
    "citation_count": 77,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586961"
  },
  {
    "source": "semantic_scholar",
    "source_id": "0e8e3b2828235f4372d65a7e840d88b8162c62c7",
    "title": "Applications and implementation of Generative Artificial Intelligence in cardiovascular imaging with a focus on ethical and legal considerations: what cardiovascular imagers need to know!",
    "authors": [
      "Ahmed Marey",
      "Kevin Christopher Serdysnki",
      "Benjamin Killeen",
      "Mathias Unberath",
      "Muhammad Umair"
    ],
    "year": 2024,
    "abstract": "\n Artificial intelligence (AI) has emerged as a prominent field in computer science. Machine learning (ML) and deep learning (DL) have potential applications in medicine. This overview explores the applications of artificial intelligence (AI) in cardiovascular imaging, focusing on echocardiography, cardiac magnetic resonance imaging (CMR), coronary CT angiography (CCTA), and CT morphology and function. AI, particularly deep learning (DL) approaches like convolutional neural networks (CNNs), enhances standardization and reduces operator-dependent variations in echocardiography. In CMR, undersampling techniques and DL-based reconstruction methods, such as variational neural networks (VNNs), improve efficiency and accuracy. ML in CCTA aids in diagnosing coronary artery disease, assessing stenosis severity, and analyzing plaque characteristics. Automatic segmentation of cardiac structures and vessels using AI is discussed, along with its potential in congenital heart disease diagnosis and 3D printing applications. Overall, AI integration in cardiovascular imaging shows promise for enhancing diagnostic accuracy and efficiency across modalities. The growing use of Generative Adversarial Networks in cardiovascular imaging brings substantial advancements but raises ethical concerns. The \"black box\" problem in deep learning models poses challenges for interpretability crucial in clinical practice. Evaluation metrics like ROC curves, image quality, clinical relevance, diversity, and quantitative performance assess GAI models. Automation bias highlights the risk of unquestioned reliance on AI outputs, demanding careful implementation and ethical frameworks. Ethical considerations involve transparency, respect for persons, beneficence, and justice, necessitating standardized evaluation protocols. Health disparities emerge if AI training lacks diversity, impacting diagnostic accuracy. AI language models, like GPT-4, face hallucination issues, posing ethical and legal challenges in healthcare. Regulatory frameworks and ethical governance are crucial for fair and accountable AI, addressing discrimination while preserving privacy. Ongoing research and development are vital to evolving AI ethics and ensuring ethical data handling in healthcare.",
    "doi": "10.1093/bjrai/ubae008",
    "url": "https://www.semanticscholar.org/paper/0e8e3b2828235f4372d65a7e840d88b8162c62c7",
    "pdf_url": "https://academic.oup.com/bjrai/advance-article-pdf/doi/10.1093/bjrai/ubae008/58011240/ubae008.pdf",
    "venue": "BJR|Artificial Intelligence",
    "citation_count": 6,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586965"
  },
  {
    "source": "semantic_scholar",
    "source_id": "3eb9c847fe8742a69615ba3d11b1cff57cf9f4a0",
    "title": "\u201cThe Impact of Artificial Intelligence on Modern Recruitment Practices: A Multi-Company Case Study Analysis\u201d",
    "authors": [
      "Arati Biradar",
      "Jyoti Ainapur",
      "K. K",
      "Aishwarya Aishwarya",
      "Sudharani Sudharani",
      "Shivaleela Shivaleela",
      "Monika Monika"
    ],
    "year": 2024,
    "abstract": "This study examines the impact of Artificial Intelligence (AI) on modern recruitment practices through a multi-company case study analysis. We investigate the implementation and outcomes of AI-driven recruitment tools at five major corporations: Unilever, IBM, Hilton Hotels, Siemens, and Google. The research focuses on how AI technologies, including machine learning, natural language processing, and predictive analytics, are being utilized to streamline hiring processes, reduce costs, and improve candidate selection. Through analysis of these case studies, we find that AI significantly reduces time-to-hire, with some companies reporting up to 85% reduction in recruitment time. Cost savings are substantial, with decreases in recruitment expenses of up to 30%. Moreover, AI implementation has led to improved hiring accuracy and retention rates, with one company noting a 16% improvement in retention. The study also reveals enhanced diversity in hiring outcomes and improved candidate experiences. However, challenges persist, including concerns about data privacy and potential algorithmic bias. The research concludes that while AI offers significant benefits in recruitment, a balance between technological efficiency and human judgment remains crucial for fair and effective hiring practices. These findings provide valuable insights for HR professionals, business leaders, and job seekers navigating the evolving landscape of AI-driven recruitment.",
    "doi": "10.35629/8028-1309143150",
    "url": "https://www.semanticscholar.org/paper/3eb9c847fe8742a69615ba3d11b1cff57cf9f4a0",
    "pdf_url": "",
    "venue": "International journal of business and management invention",
    "citation_count": 6,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586968"
  },
  {
    "source": "semantic_scholar",
    "source_id": "c0d410770801bf0411859c5f4d9de00c2d7ecb56",
    "title": "Responsible Artificial Intelligence (AI) for Digital Health and Medical Analytics",
    "authors": [
      "U. Sivarajah",
      "Yichuan Wang",
      "Hossein Olya",
      "Sherin Mathew"
    ],
    "year": 2023,
    "abstract": "AI could pose potential risks to care delivery by devaluing physicians\u2019 skills, failing to meet transparency standards, underestimating algorithmic biases, and neglecting the fairness of clinical deployment (Vayena et al., 2018). Such ethical dilemmas and concerns, if not adequately addressed when implementing AI for digital health and medical analytics, can not only negatively impact patients but may also tarnish the reputation of healthcare organisations (Wang et al., 2018). In response to these ethical challenges, many countries have implemented data protection regulations, such as the UK\u2019s Data Protection Act 2018, which is in line with the General Data Protection Regulation (GDPR) formulated by the European Union. These regulations aim to improve individuals\u2019 confidence in sharing personal information with healthcare organisations, leading to a scholarly and practical focus on the responsible use of AI. Responsible AI refers to the integration of ethical and responsible AI use into strategic implementation and organisational planning processes (Wang et al., 2023). It aims to design and implement ethical, transparent, and accountable AI solutions that help organizations maintain trust and minimise privacy invasion. Responsible AI places humans (e.g., patients) at the centre and aligns with stakeholder expectations as well as applicable regulations and laws. The ultimate goal of responsible AI is to strike a balance between satisfying patient needs through responsible AI use and attaining long-term economic value for healthcare organisations. Despite its importance for organisational prosperity and the significant attention devoted to it, responsible AI use in healthcare is still in its nascent stages.",
    "doi": "10.1007/s10796-023-10412-7",
    "url": "https://www.semanticscholar.org/paper/c0d410770801bf0411859c5f4d9de00c2d7ecb56",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10796-023-10412-7.pdf",
    "venue": "Information Systems Frontiers",
    "citation_count": 21,
    "fields_of_study": [
      "Medicine",
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586972"
  },
  {
    "source": "semantic_scholar",
    "source_id": "13300b6a96eba2af4b738c846787bcd2d06aa75b",
    "title": "Health Economic Implications of Artificial Intelligence Implementation for Ophthalmology in Australia: A Systematic Review",
    "authors": [
      "James Pietris",
      "Antoinette Lam",
      "Stephen Bacchi",
      "Aashray K. Gupta",
      "J. Kovoor",
      "W. Chan"
    ],
    "year": 2022,
    "abstract": "Purpose: The health care industry is an inherently resource-intense sector. Emerging technologies such as artificial intelligence (AI) are at the forefront of advancements in health care. The health economic implications of this technology have not been clearly established and represent a substantial barrier to adoption both in Australia and globally. This review aims to determine the health economic impact of implementing AI to ophthalmology in Australia. Methods: A systematic search of the databases PubMed/MEDLINE, EMBASE, and CENTRAL was conducted to March 2022, before data collection and risk of bias analysis in accordance with preferred reporting items for systematic ceviews and meta-analyses 2020 guidelines (PROSPERO number CRD42022325511). Included were full-text primary research articles analyzing a population of patients who have or are being evaluated for an ophthalmological diagnosis, using a health economic assessment system to assess the cost-effectiveness of AI. Results: Seven articles were identified for inclusion. Economic viability was defined as direct cost to the patient that is equal to or less than costs incurred with human clinician assessment. Despite the lack of Australia-specific data, foreign analyses overwhelmingly showed that AI is just as economically viable, if not more so, than traditional human screening programs while maintaining comparable clinical effectiveness. This evidence was largely in the setting of diabetic retinopathy screening. Conclusions: Primary Australian research is needed to accurately analyze the health economic implications of implementing AI on a large scale. Further research is also required to analyze the economic feasibility of adoption of AI technology in other areas of ophthalmology, such as glaucoma and cataract screening.",
    "doi": "10.1097/APO.0000000000000565",
    "url": "https://www.semanticscholar.org/paper/13300b6a96eba2af4b738c846787bcd2d06aa75b",
    "pdf_url": "https://doi.org/10.1097/apo.0000000000000565",
    "venue": "Asia - Pacific Journal of Ophthalmology",
    "citation_count": 9,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586976"
  },
  {
    "source": "semantic_scholar",
    "source_id": "36cefd885af98589472473d386507be57ed72298",
    "title": "Artificial Intelligence Needs Human Rights: How the Focus on Ethical AI Fails to Address Privacy, Discrimination and Other Concerns",
    "authors": [
      "Kate Saslow",
      "Philippe Lorenz"
    ],
    "year": 2019,
    "abstract": "AI has been a catalyst for automation and efficiency in numerous ways, but has also had harmful consequences, including: unforeseen algorithmic bias that affects already marginalized communities, as with Amazon\u2019s AI recruiting algorithm that showed bias against women; accountability and liability coming into question if an autonomous vehicle injures or kills, as seen with Uber\u2019s self-driving car casualties; even the notion of democracy is being challenged as the technology enables authoritarian and democratic states like China and the United States to practice surveillance at an unprecedented scale.<br><br>The risks as well as the need for some form of basic rules have not gone unnoticed and governments, tech companies, research consortiums or advocacy groups have broached the issue. In fact, this has been the topic of local, national, and supranational discussion for some years now, as can be seen with new legislation popping up to ban facial recognition software in public spaces. The problem with these discussions, however, is that they have been heavily dominated by how we can make AI more \u201cethical\u201d. Companies, states, and even international organizations discuss ethical principles, such as fair, accountable, responsible, or safe AI in numerous expert groups or ad hoc committees, such as the High-Level Expert Group on AI in the European Commission, the group on AI in Society of the Organization for Economic Co-operation and Development (OECD), or the select committee on Artificial Intelligence of the United Kingdom House of Lords.<br><br>This may sound like a solid approach to tackling the dangers that AI poses, but to actually be impactful, these discussions must be grounded in rhetoric that is focused and actionable. Not only may the principles be defined differently depending on the stakeholders, but there are overwhelming differences in how principles are interpreted and what requirements are necessary for them to materialize. In addition, ethical debates on AI are often dominated by American or Chinese companies, which are both propagating their own idea of ethical AI, but which may in many cases stand in conflict with the values of other cultures and nations. Not only do different countries have different ideas of which \u201cethics\u201d principles need to be protected, but different countries play starkly different roles in developing AI. Another problem is when ethical guidelines are discussed, suggestions often come from tech companies themselves, while voices from citizens or even governments are marginalized.<br><br>Self-regulation around ethical principles is too weak to address the spreading implications that AI technologies have had. Ethical principles lack clarity and enforcement capabilities. We must stop focusing the discourse on ethical principles, and instead shift the debate to human rights. Debates must be louder at the supranational level. International pressure must be put on states and companies who fail to protect individuals by propagating AI technologies that carry risks. Leadership must be defined not by actors who come up with new iterations of ethical guidelines, but by those who develop legal obligations regarding AI, which are anchored in and derived from a human rights perspective.<br><br>A way to do this would be to reaffirm the human-centric nature of AI development and deployment that follows actionable standards of human rights law. The human rights legal framework has been around for decades and has been instrumental in fighting and pressuring states to change domestic laws. Nelson Mandela referred to the duties spelled out in the Universal Declaration of Human Rights while fighting to end apartheid in South Africa; in 1973 with Roe v. Wade the United States Supreme Court followed a larger global trend of recognizing women\u2019s human rights by protecting individuals from undue governmental interference in private affairs and giving women the ability to participate fully and equally in society; more recently, open access to the Internet has been recognized as a human right essential to not only freedom of opinion, expression, association, and assembly, but also instrumental in mobilizing the population to call for equality, justice, and accountability in order to advance global respect for human rights. These examples show how human rights standards have been applied to a diverse set of domestic and international rules. That these standards are actionable and enforceable show that they are well-suited to regulate the cross-border nature of AI technologies. AI systems must be scrutinized through a human rights perspective to analyze current and future harms either created or exacerbated by AI, and take action to avoid any harm.<br><br>The adoption of AI technologies has spread across borders and has had diverse effects on societies all over the world. A globalized technology needs international obligations to mitigate the societal problems being faced at an accelerated and larger scale. Companies and states should strive for the development of AI technologies that uphold human rights. Centering the AI discourse around human rights rather than simply ethics can be one way of providing a clearer legal basis for development and deployment of AI technologies. The international community must raise awareness, build consensus, and analyze thoroughly how AI technologies violate human rights in different contexts and develop paths for effective legal remedies. Focusing the discourse on human rights rather than ethical principles can provide more accountability measures, more obligations for state and private actors, and can redirect the debate to rely on consistent and widely accepted legal principles developed over decades.",
    "doi": "10.2139/ssrn.3589473",
    "url": "https://www.semanticscholar.org/paper/36cefd885af98589472473d386507be57ed72298",
    "pdf_url": "",
    "venue": "Social Science Research Network",
    "citation_count": 4,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586979"
  },
  {
    "source": "semantic_scholar",
    "source_id": "d53093a2a4fdbaee337a2d90f243e7a8378c9c68",
    "title": "Trustworthy Artificial Intelligence and its use by Law Enforcement Authorities: where do we stand?",
    "authors": [
      "Suncana Roksandic",
      "N. Protrka",
      "M. Engelhart"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.23919/MIPRO55190.2022.9803606",
    "url": "https://www.semanticscholar.org/paper/d53093a2a4fdbaee337a2d90f243e7a8378c9c68",
    "pdf_url": "",
    "venue": "International Convention on Information and Communication Technology, Electronics and Microelectronics",
    "citation_count": 13,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586983"
  },
  {
    "source": "semantic_scholar",
    "source_id": "e9cccc30b9fb6526792691b26bbd9db4c05342f5",
    "title": "Senior High School Students Perceptions and Awareness on the Ethical Implications of Artificial Intelligence",
    "authors": [
      "Cataga Chj",
      "Cator Ta",
      "Fabrique KS*",
      "Nudalo Bja",
      "Priol Js",
      "Tabon Ja"
    ],
    "year": 2024,
    "abstract": "Artificial Intelligence aims to create intelligent devices that resemble humans by inducing intelligent behavior. This study aims\nto examine the senior high school students\u2019 perceptions and awareness on the ethical implications of artificial intelligence\nin terms of age, sex, and grade level. The study utilized a quantitative cross-sectional research design. The respondents of\nthe study were 142 senior high school students currently enrolled in a public secondary high school in Eastern Philippines\nof the school year 2024-2025 and selected using stratified and systematic random sampling techniques. The study used\nan adapted survey questionnaire. Results revealed that senior high school students have a high perception and awareness\ntowards ethical implications of artificial intelligence. Furthermore, result showed that there is a significant difference in terms\nof age of senior high school towards perceptions and attitudes on the ethical implications of artificial intelligence and there\nis no significant difference between perceptions and awareness in terms of sex and grade level. The study concludes that\nwhile students are largely optimistic about AI in education, proactive measures are crucial to ensure responsible and fair use\nof this technology. Further research should focus on addressing resource inequalities and translating ethical concerns into\nconcrete policies and practices. The study emphasizes how urgently proactive steps must be taken to guarantee the ethical and\nresponsible application of artificial intelligence in education, including addressing resource disparities and converting moral\nconsiderations into tangible rules and procedures. This highlighted a potential access to AI resources and training, raising\nconcerns about equitable implementation.",
    "doi": "10.23880/oajda-16000155",
    "url": "https://www.semanticscholar.org/paper/e9cccc30b9fb6526792691b26bbd9db4c05342f5",
    "pdf_url": "",
    "venue": "Open Access Journal of Data Science and Artificial Intelligence",
    "citation_count": 1,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586987"
  },
  {
    "source": "semantic_scholar",
    "source_id": "171d499744efcdd871c72757714f002af5d5e5df",
    "title": "Ethical Reflections on Artificial Intelligence",
    "authors": [
      "B. Green"
    ],
    "year": 2018,
    "abstract": "Artificial Intelligence (AI) technology presents a multitude of ethical concerns, many of which are being actively considered by organizations ranging from small groups in civil society to large corporations and governments. However, it also presents ethical concerns which are not being actively considered. This paper presents a broad overview of twelve topics in ethics in AI, including function, transparency, evil use, good use, bias, unemployment, socio-economic inequality, moral automation and human de-skilling, robot consciousness and rights, dependency, social-psychological effects, and spiritual effects. Each of these topics will be given a brief discussion, though each deserves much deeper consideration.",
    "doi": "10.12775/SETF.2018.015",
    "url": "https://www.semanticscholar.org/paper/171d499744efcdd871c72757714f002af5d5e5df",
    "pdf_url": "https://apcz.umk.pl/czasopisma/index.php/SetF/article/download/SetF.2018.015/15729",
    "venue": "Scientia et Fides",
    "citation_count": 42,
    "fields_of_study": [
      "Sociology"
    ],
    "retrieved_at": "2026-02-02T16:58:06.586990"
  },
  {
    "source": "semantic_scholar",
    "source_id": "9b688157f467a83b7f4f6ac4eae7754241018aef",
    "title": "Examining Ethical Aspects of AI: Addressing Bias and Equity in the Discipline",
    "authors": [
      "Jeff Shuford"
    ],
    "year": 2024,
    "abstract": "he rapid progress in implementing Artificial Intelligence (AI) across various domains such as healthcare decision-making, medical diagnosis, and others has raised significant concerns regarding the fairness and bias embedded within AI systems. This is particularly crucial in sectors like healthcare, employment, criminal justice, credit scoring, and the emerging field of generative AI models (GenAI) producing synthetic media. Such systems can lead to unfair outcomes and perpetuate existing inequalities, including biases ingrained in the synthetic data representation of individuals.This survey paper provides a concise yet comprehensive examination of fairness and bias in AI, encompassing their origins, ramifications, and potential mitigation strategies. We scrutinize sources of bias, including data, algorithmic, and human decision biases, shedding light on the emergent issue of generative AI bias where models may replicate and amplify societal stereotypes. Assessing the societal impact of biased AI systems, we spotlight the perpetuation of inequalities and the reinforcement of harmful stereotypes, especially as generative AI gains traction in shaping public perception through generated content.Various proposed mitigation strategies are explored, with an emphasis on the ethical considerations surrounding their implementation. We stress the necessity of interdisciplinary collaboration to ensure the effectiveness of these strategies. Through a systematic literature review spanning multiple academic disciplines, we define AI bias and its various types, delving into the nuances of generative AI bias. We discuss the adverse effects of AI bias on individuals and society, providing an overview of current approaches to mitigate bias, including data preprocessing, model selection, and post-processing. Unique challenges posed by generative AI models are highlighted, underscoring the importance of tailored strategies to address them effectively.Addressing bias in AI necessitates a holistic approach, involving diverse and representative datasets, enhanced transparency, and accountability in AI systems, and exploration of alternative AI paradigms prioritizing fairness and ethical considerations. This survey contributes to the ongoing discourse on developing fair and unbiased AI systems by outlining the sources, impacts, and mitigation strategies related to AI bias, with a particular focus on the burgeoning field of generative AI.",
    "doi": "10.60087/jaigs.v3i1.119",
    "url": "https://www.semanticscholar.org/paper/9b688157f467a83b7f4f6ac4eae7754241018aef",
    "pdf_url": "https://ojs.boulibrary.com/index.php/JAIGS/article/download/119/87",
    "venue": "Journal of Artificial Intelligence General science (JAIGS) ISSN:3006-4023",
    "citation_count": 10,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586993"
  },
  {
    "source": "semantic_scholar",
    "source_id": "b4d21b18308b6b6786c00c303bb49327934d60fd",
    "title": "How to survive in the age of artificial intelligence? Exploring the intelligent transformations of SMEs in central China",
    "authors": [
      "Jinqiang Wang",
      "Yao-bin Lu",
      "S. Fan",
      "Peng Hu",
      "Bin Wang"
    ],
    "year": 2021,
    "abstract": "PurposeThe purpose of the research is to explore how small and medium enterprises (SMEs) in central China achieve intelligent transformation through the use of artificial intelligence (AI). Because of unequal resource allocation, constraints on the intelligent transformation of SMEs in central China are different from those in economically and technologically well-developed coastal provinces. Hence, the authors focus on SMEs in central China to identify drivers of and barriers to intelligent transformation.Design/methodology/approachThe interview data were collected from 66 SMEs across 20 industries in central China. To verify the validity of the data collection method, the authors used two methods to control for retrospective bias: multi-level informants and enterprises' AI project application materials (Wei and Clegg, 2020). The final data were validated without conflicts. Next, the authors cautiously followed a two-step approach recommended by Venkatesh et\u00a0al. (2010) and used NVivo 11.0 to analyze the collected text data.FindingsSMEs in central China are enthusiastic about intelligent transformation while facing both internal and external pressures. SMEs need to pay attention to both internal (enterprise development needs, implementation cost, human resources and top management involvement) and external factors (external market pressure, convenience of AI technology and policy support) and their different impacts on intelligent transformation. However, constrained by limited resources, SMEs in central China have been forced to take a step-by-step intelligent transformation strategy based on their actual needs with the technological flexibility method in the short term.Originality/valueConsidering the large number of SMEs and their importance in promoting China's economic development and job creation (SME Bureau of MIIT, 2020), more research on SMEs with limited resources is needed. In the study, the authors confirmed that enterprises should handle \u201csocial responsibility\u201d carefully because over-emphasizing it will hinder intelligent transformation. However, firms should pay attention to the role of executives in promoting intelligent transformation and make full use of policy support to access more resources.",
    "doi": "10.1108/ijoem-06-2021-0985",
    "url": "https://www.semanticscholar.org/paper/b4d21b18308b6b6786c00c303bb49327934d60fd",
    "pdf_url": "",
    "venue": "International Journal of Emerging Markets",
    "citation_count": 43,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.586997"
  },
  {
    "source": "semantic_scholar",
    "source_id": "8c32d5141b0fd8b88366550ffe17a70a8c8a8167",
    "title": "Evaluating accountability, transparency, and bias in AI-assisted healthcare decision- making: a qualitative study of healthcare professionals\u2019 perspectives in the UK",
    "authors": [
      "Saoudi CE Nouis",
      "Victoria Uren",
      "Srushti Jariwala"
    ],
    "year": 2025,
    "abstract": "While artificial intelligence (AI) has emerged as a powerful tool for enhancing diagnostic accuracy and streamlining workflows, key ethical questions remain insufficiently explored\u2014particularly around accountability, transparency, and bias. These challenges become especially critical in domains such as pathology and blood sciences, where opaque AI algorithms and non-representative datasets can impact clinical outcomes. The present work focuses on a single NHS context and does not claim broader generalization. We conducted a local qualitative study across multiple healthcare facilities in a single NHS Trust in the West Midlands, United Kingdom, to investigate healthcare professionals\u2019 experiences and perceptions of AI-assisted decision-making. Forty participants\u2014including clinicians, healthcare administrators, and AI developers\u2014took part in semi-structured interviews or focus groups. Transcribed data were analyzed using Braun and Clarke\u2019s thematic analysis framework, allowing us to identify core themes relating to the benefits of AI, ethical challenges, and potential mitigation strategies. Participants reported notable gains in diagnostic efficiency and resource allocation, underscoring AI\u2019s potential to reduce turnaround times for routine tests and enhance detection of abnormalities. Nevertheless, accountability surfaced as a pervasive concern: while clinicians felt ultimately liable for patient outcomes, they also relied on AI-generated insights, prompting questions about liability if systems malfunctioned. Transparency emerged as another major theme, with clinicians emphasizing the difficulty of trusting \u201cblack box\u201d models that lack clear rationale or interpretability\u2014particularly for rare or complex cases. Bias was repeatedly cited, especially when algorithms underperformed in minority patient groups or in identifying atypical presentations. These issues raised doubts about the fairness and reliability of AIassisted diagnoses. Although AI demonstrates promise for improving efficiency and patient care, unresolved ethical complexities around accountability, transparency, and bias may erode stakeholder confidence and compromise patient safety. Participants called for clearer regulatory frameworks, inclusive training datasets, and stronger clinician\u2013developer collaboration. Future research should incorporate patient perspectives, investigate long-term impacts of AI-driven clinical decisions, and refine ethical guidelines to ensure equitable, responsible AI deployment. : Not applicable.",
    "doi": "10.1186/s12910-025-01243-z",
    "url": "https://www.semanticscholar.org/paper/8c32d5141b0fd8b88366550ffe17a70a8c8a8167",
    "pdf_url": "",
    "venue": "BMC Medical Ethics",
    "citation_count": 16,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:06.587000"
  },
  {
    "source": "semantic_scholar",
    "source_id": "493050e590e4b8845b95c57c7d87932d432f2c28",
    "title": "Evaluating Generalization, Bias, and Fairness in Deep Learning for Metal Surface Defect Detection: A Comparative Study",
    "authors": [
      "Singharat Rattanaphan",
      "Alexia Briassouli"
    ],
    "year": 2024,
    "abstract": "In recent years, deep learning models have led to improved accuracy in industrial defect detection, often using variants of YOLO (You Only Look Once), due to its high performance at a low cost. However, the generalizability, fairness and bias of their outcomes have not been examined, which may lead to overconfident predictions. Additionally, the complexity added by co-occurring defects, single and multi-class defects, and the effect on training, is not taken into consideration. This study addresses these critical gaps by introducing new methodologies for analyzing dataset complexity and evaluating model fairness. It introduces the novel approach of co-occurrence impact analysis, examining how the co-occurrence of defects in sample images affects performance, and introducing new dimensions to dataset preparation and training. Its aim is to increase model robustness in the face of real-world scenarios where multiple defects often appear together. Our study also innovates in the evaluation of model fairness by adapting the disparate impact ratio (DIR) to consider the true positive rate (TPR) across different groups and modifying the predictive parity difference (PPD) metric to focus on biases present in industrial quality control. Experiments demonstrate by cross-validation that the model trained on combined datasets significantly outperforms others in accuracy without overfitting and results in increased fairness, as validated by our novel fairness metrics. Explainability also provides valuable insights on the effects of different training regimes, notably absent in prior works. This work not only advances the field of deep learning for defect detection but also provides a strategic framework for future advancements, emphasizing the need for balanced datasets and considerations of ethics, fairness, bias and generalizability in the deployment of artificial intelligence in industry.",
    "doi": "10.3390/pr12030456",
    "url": "https://www.semanticscholar.org/paper/493050e590e4b8845b95c57c7d87932d432f2c28",
    "pdf_url": "https://www.mdpi.com/2227-9717/12/3/456/pdf?version=1708701741",
    "venue": "Processes",
    "citation_count": 5,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.587003"
  },
  {
    "source": "semantic_scholar",
    "source_id": "5816b7cbdc7793c3447c854e0d543fed96b55988",
    "title": "Automated Decision Making in Airport Checkpoints: Bias Detection Toward Smarter Security and Fairness",
    "authors": [
      "D. Kyriazanos",
      "K. Thanos",
      "S. Thomopoulos"
    ],
    "year": 2019,
    "abstract": "Automated decision making emerges as the enabler for risk-based and smarter security. However, ethics, privacy, and the General Data Protection Regulation (GDPR) provide a very challenging setting along with monitoring fairness and bias detection when applying artificial intelligence (AI) security solutions.",
    "doi": "10.1109/MSEC.2018.2888777",
    "url": "https://www.semanticscholar.org/paper/5816b7cbdc7793c3447c854e0d543fed96b55988",
    "pdf_url": "",
    "venue": "IEEE Security and Privacy",
    "citation_count": 11,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:06.587007"
  },
  {
    "source": "semantic_scholar",
    "source_id": "150769b73fda6c0f1aeedb91dc4567ca28893bdc",
    "title": "Policies for Artificial Intelligence in Science and Innovation",
    "authors": [
      "A. Paic"
    ],
    "year": 2020,
    "abstract": "This contribution synthesizes the discussions of the special session on policies for Artificial Intelligence in Science and Innovation, organized by the OECD\u2019s Directorate for Science, Technology and Innovation. The session was opened by Dr Judith Arrieta, Minister of the Foreign Service at the Chief of Staff\u2019s Office of the Secretary of Foreign Affairs of Mexico, and the two panels included speakers from governments, industry and civil society from European countries, USA,Canada China and Australia. Participants discussed the disruptive nature of AI and the formidable challenges it poses. Most of the discussion focused under the umbrella title of ethics, but they span very different issues of human-centered values, fairness, transparency, explainability, and many more. Other challenges include employment, education, SME policy, enabling environment, access to data and computing technology. Responses by governments were also discussed with a particular focus on national strategies, whose main pillars are oriented toward knowledge creation through AI research, knowledge diffusion through linkages to the private sector, development of human capital which will underpin the development of the sector, and a strong values, ethical and regulatory framework to create the conditions for the development of trustworthy AI. \nIn a world of finite resources, discussants concluded that one cannot apply very stringent requirements to all AI decisions, and there is clearly a need to require more transparency, explainability and robustness from systems which have the greatest impact on human lives. Therefore an approach based on algorithmic impact assessment seems reasonable. Such an approach needs to be further developed and standardized.",
    "doi": "10.22323/1.372.0045",
    "url": "https://www.semanticscholar.org/paper/150769b73fda6c0f1aeedb91dc4567ca28893bdc",
    "pdf_url": "https://pos.sissa.it/372/045/pdf",
    "venue": "Proceedings of Artificial Intelligence for Science, Industry and Society \u2014 PoS(AISIS2019)",
    "citation_count": 0,
    "fields_of_study": [
      "Political Science"
    ],
    "retrieved_at": "2026-02-02T16:58:06.587010"
  },
  {
    "source": "semantic_scholar",
    "source_id": "f0340c3932c4dcc9f505f06390540f16c7ee7905",
    "title": "Towards Responsible AI in Banking: Addressing Bias for Fair Decision-Making",
    "authors": [
      "Alessandro Castelnovo"
    ],
    "year": 2024,
    "abstract": "In an era characterized by the pervasive integration of artificial intelligence into decision-making processes across diverse industries, the demand for trust has never been more pronounced. This thesis embarks on a comprehensive exploration of bias and fairness, with a particular emphasis on their ramifications within the banking sector, where AI-driven decisions bear substantial societal consequences. In this context, the seamless integration of fairness, explainability, and human oversight is of utmost importance, culminating in the establishment of what is commonly referred to as\"Responsible AI\". This emphasizes the critical nature of addressing biases within the development of a corporate culture that aligns seamlessly with both AI regulations and universal human rights standards, particularly in the realm of automated decision-making systems. Nowadays, embedding ethical principles into the development, training, and deployment of AI models is crucial for compliance with forthcoming European regulations and for promoting societal good. This thesis is structured around three fundamental pillars: understanding bias, mitigating bias, and accounting for bias. These contributions are validated through their practical application in real-world scenarios, in collaboration with Intesa Sanpaolo. This collaborative effort not only contributes to our understanding of fairness but also provides practical tools for the responsible implementation of AI-based decision-making systems. In line with open-source principles, we have released Bias On Demand and FairView as accessible Python packages, further promoting progress in the field of AI fairness.",
    "doi": "10.48550/arXiv.2401.08691",
    "url": "https://www.semanticscholar.org/paper/f0340c3932c4dcc9f505f06390540f16c7ee7905",
    "pdf_url": "",
    "venue": "arXiv.org",
    "citation_count": 8,
    "fields_of_study": [
      "Mathematics",
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:06.587014"
  },
  {
    "source": "semantic_scholar",
    "source_id": "e8b3b7510ab2b9381573b89270d5582df5645e3e",
    "title": "Toward Urban Artificial Intelligence for Developing Justice-Oriented Smart Cities",
    "authors": [
      "Xinyue Ye",
      "Galen Newman",
      "Chanam Lee",
      "Shannon Van Zandt",
      "D. Jourdan"
    ],
    "year": 2023,
    "abstract": "Urban artificial intelligence (UAI) refers to the development and deployment of artificial intelligence (AI) technologies and solutions in urban settings such as energy management, environmental monitoring, public safety, transportation, and predictive maintenance. Urban research has shifted from a data-scarce to a data-rich environment in recent years. Big data and computational algorithms have become continually integrated into the built environment and within human\u2019s daily lives, leading to a significant rise in digital twin research. Heterogeneous real-time data can be synthesized from a wide range of sources such as sensors and cameras connected to buildings, factories, green spaces, roads, sidewalks, and other urban elements. Defined as a virtual representation of a physical urban environment, digital twins can be employed to analyze, model, and simulate various aspects of urban phenomena in the fine scale. The UAI will take the source data from sensors, satellite imagery, and social media over space, time, and scale as inputs, and generate outputs that typically include predictions or simulations of how urban elements or systems will be affected by these inputs. Powered by UAI, the bi-directional flow of data between a digital twin and the physical urban environment further allows the digital twin to both reflect the current state of the city and make more informed decisions about how to optimize the urban operation (Ye et al. 2022). Furthermore, the revolution of computing power and information technology has blurred the boundary across disciplines and urban applications. Linked with immersive technologies such as virtual reality (VR) and augmented reality (AR), UAI helps people to visualize cities as they change by showing how planning and infrastructure design can alter the urban environment reflecting the diverse perspectives and needs of the community, either positively or negatively. Collaboration across disciplines and stakeholders is often essential for addressing complex urban problems. UAI has the potential to help bridge the silos within design, social, and engineering sciences as well as growing gaps between research and practice, through activities such as citizen science, community-based research, and participatory research. UAI is revolutionizing urban planning education and practice by providing new tools for planners to automate certain tasks and make informed decisions (Sanchez et al. 2022). This allows planners to focus on more creative aspects of their work and efficiently evaluate large amounts of design options, ensuring that the final delivery is an optimized solution. Simultaneously, UAI enables a collective understanding of existing urban conditions and demonstrates innovative capabilities for how to increase cyber, social, and physical resilience and efficacy beyond simple technology integration. However, UAI could possibly exacerbate existing socioeconomic inequities in the built environment if such technical strength is not designed and used by researchers and practitioners in an ethical and responsible manner. Hence, UAI needs to be used to promote knowledge co-production, which refers to the inclusive process in which knowledge is created, shared, and used through active collaboration among people with different backgrounds, experiences, and perspectives (Shrestha et al. 2017). Driven by UAI, knowledge co-production can engage a variety of relevant parties to identify research questions and co-design/ implement research projects through the process of data collection, analysis, and dissemination. In addition, UAI-based knowledge co-production can help cultivate the trust between researchers and the local residents, and increase confidence in its decision-making abilities, leading to a more comprehensive and inclusive understanding of the needs and priorities of the communities they serve. In terms of data shortage issue especially in lower-income or under-resourced communities, UAI techniques can be used to augment existing data with additional sources of information, such as public data sets or data from citizen science. UAI is highly affected by its training data and the adopted algorithms. As a result, it inherits the built-in biases embedded in these data and algorithms. The potential unfair or discriminatory outcomes may result in serious consequences for individuals or society if such biased UAI is deployed in decision-making processes. Hence, planners need to mitigate the bias by using representative training data, documenting the training process in an open-source manner, and consistently assessing the AI functions. We need to be transparent about the data employed to train UAI and the algorithms used to develop it. It is also important for developers to be aware of data ethics involved in the procedure of collecting, managing, and using sensitive data. It is vital to ensure that the data collection is with the consent of the involved individuals and that it is used in a responsible manner. In addition, the AI 1154002 JPEXXX10.1177/0739456X231154002Journal of Planning Education and ResearchEditorial editorial2023",
    "doi": "10.1177/0739456X231154002",
    "url": "https://www.semanticscholar.org/paper/e8b3b7510ab2b9381573b89270d5582df5645e3e",
    "pdf_url": "https://journals.sagepub.com/doi/pdf/10.1177/0739456X231154002",
    "venue": "Journal of planning education and research",
    "citation_count": 12,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.587017"
  },
  {
    "source": "semantic_scholar",
    "source_id": "de9289d2ed7408457d34330eda07457d252f0e14",
    "title": "Impact of Artificial Intelligence on Recruitment and Selection of Information Technology Companies",
    "authors": [
      "A. Hemalatha",
      "P. Kumari",
      "N. Nawaz",
      "Vijayakumar Gajenderan"
    ],
    "year": 2021,
    "abstract": "Artificial Intelligence (AI) is one of the promising and compelling technologies nowadays which continuously transforms human lives and massively impacts almost all spheres of the business world. While AI is constructively indiscriminately flourishing in all fields, workforce management is not an exception to the rule. The primary purpose of this research is to critically analyze the impact that Artificial Intelligence (AI) is having on Human Resource management practices, more specifically on recruitment and Selection in organizations. The researcher has concentrated on four AI capabilities, namely Natural Language Processing, Machine Vision, Automation, and Augmentation, and their impact on the Recruitment and selection process. The researcher has collected primary data through an online survey from 141 IT employees regarding Chennai city. The researcher has also focused on external secondary data (articles and reports) to demonstrate some of the findings of the impact of AI capabilities on Recruitment and Selection. The study finds that AI technologies capabilities namely NLP, Machine Vision, Automation, and Augmentation have a significant impact on the Recruitment and Selection Process with potential positive outcomes such as time & cost-saving, accuracy, removes bias, reduced workload, increased efficiency, and candidate experience.",
    "doi": "10.1109/ICAIS50930.2021.9396036",
    "url": "https://www.semanticscholar.org/paper/de9289d2ed7408457d34330eda07457d252f0e14",
    "pdf_url": "",
    "venue": "International Conference on Adaptive and Intelligent Systems",
    "citation_count": 39,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.587021"
  },
  {
    "source": "semantic_scholar",
    "source_id": "f989e1c7738a3396e5225f4f506dcbdba13dbbf1",
    "title": "Artificial Intelligence in Supply Chain Management: A Systematic Review of Emerging Trends and Evidence in Healthcare Operations",
    "authors": [
      "Akande Sodiq Adedunjoye",
      "Joy Onma Enyejo"
    ],
    "year": 2023,
    "abstract": "The increasing complexity of healthcare supply chains characterized by fluctuating demand, stringent regulatory requirements, globalized procurement networks, and the critical need for real-time resource availability has accelerated the adoption of Artificial Intelligence (AI) as a transformative operational tool. This systematic review synthesizes emerging trends, empirical findings, and technological innovations in AI-enabled supply chain management within healthcare systems. Drawing on peer-reviewed literature from the past decade, the study examines how AI-driven techniques such as machine learning, predictive analytics, natural language processing, optimization algorithms, and intelligent automation enhance procurement forecasting, inventory management, logistics optimization, clinical resource allocation, and risk mitigation.\nThe review highlights the growing integration of AI with enabling technologies such as digital twins, Internet of Medical Things (IoMT), blockchain, and cloud-based analytics to strengthen supply chain visibility, traceability, and resilience. Evidence shows that AI significantly reduces stock-outs, improves demand prediction accuracy, enhances cold-chain monitoring, and supports decision-making in critical service lines such as pharmaceuticals, surgical supplies, and emergency care. Despite these advancements, major challenges remain, including data fragmentation, interoperability limitations, model transparency concerns, workforce capacity gaps, and ethical issues relating to bias, privacy, and automation risks. The review concludes by outlining future research directions, emphasizing the need for explainable AI (XAI), scalable real-time analytics, integrated data governance frameworks, and hybrid human-AI decision architectures. This study provides a consolidated knowledge base for policymakers, healthcare administrators, and supply chain professionals seeking evidence-based pathways for AI adoption in healthcare operations.",
    "doi": "10.38124/ijsrmt.v3i12.1055",
    "url": "https://www.semanticscholar.org/paper/f989e1c7738a3396e5225f4f506dcbdba13dbbf1",
    "pdf_url": "",
    "venue": "International Journal of Scientific Research and Modern Technology",
    "citation_count": 4,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.587024"
  },
  {
    "source": "semantic_scholar",
    "source_id": "42dcd0ae8e6a3dc294250d08949db1d6beb5f1c9",
    "title": "Human biases and remedies in AI safety and alignment contexts",
    "authors": [
      "Zo\u00e9 Roy-Stang",
      "Jim Davies"
    ],
    "year": 2025,
    "abstract": null,
    "doi": "10.1007/s43681-025-00698-5",
    "url": "https://www.semanticscholar.org/paper/42dcd0ae8e6a3dc294250d08949db1d6beb5f1c9",
    "pdf_url": "",
    "venue": "AI and Ethics",
    "citation_count": 2,
    "fields_of_study": [
      "Computer Science"
    ],
    "retrieved_at": "2026-02-02T16:58:06.587028"
  },
  {
    "source": "semantic_scholar",
    "source_id": "954f7412a37649eff89da3e84df0257aa63655e9",
    "title": "The dark side of generative artificial intelligence: A critical analysis of controversies and risks of ChatGPT",
    "authors": [
      "K. Wach",
      "Cong Doanh Duong",
      "J. Ejdys",
      "R\u016bta Kazlauskait\u0117",
      "P. Korzy\u0144ski",
      "G. Mazurek",
      "Joanna Paliszkiewicz",
      "E. Ziemba"
    ],
    "year": 2023,
    "abstract": "Objective: The objective of the article is to provide a comprehensive identification and understanding of the challenges and opportunities associated with the use of generative artificial intelligence (GAI) in business. This study sought to develop a conceptual framework that gathers the negative aspects of GAI development in management and economics, with a focus on ChatGPT. Research Design & Methods: The study employed a narrative and critical literature review and developed a conceptual framework based on prior literature. We used a line of deductive reasoning in formulating our theoretical framework to make the study\u2019s overall structure rational and productive. Therefore, this article should be viewed as a conceptual article that highlights the controversies and threats of GAI in management and economics, with ChatGPT as a case study. Findings: Based on the conducted deep and extensive query of academic literature on the subject as well as professional press and Internet portals, we identified various controversies, threats, defects, and disadvantages of GAI, in particular ChatGPT. Next, we grouped the identified threats into clusters to summarize the seven main threats we see. In our opinion they are as follows: (i) no regulation of the AI market and urgent need for regulation, (ii) poor quality, lack of quality control, disinformation, deepfake content, algorithmic bias, (iii) automation-spurred job losses, (iv) personal data violation, social surveillance, and privacy violation, (v) social manipulation, weakening ethics and goodwill, (vi) widening socio-economic inequalities, and (vii) AI technostress. Implications & Recommendations: It is important to regulate the AI/GAI market. Advocating for the regulation of the AI market is crucial to ensure a level playing field, promote fair competition, protect intellectual property rights and privacy, and prevent potential geopolitical risks. The changing job market requires workers to continuously acquire new (digital) skills through education and retraining. As the training of AI systems becomes a prominent job category, it is important to adapt and take advantage of new opportunities. To mitigate the risks related to personal data violation, social surveillance, and privacy violation, GAI developers must prioritize ethical considerations and work to develop systems that prioritize user privacy and security. To avoid social manipulation and weaken ethics and goodwill, it is important to implement responsible AI practices and ethical guidelines: transparency in data usage, bias mitigation techniques, and monitoring of generated content for harmful or misleading information. Contribution & Value Added: This article may aid in bringing attention to the significance of resolving the ethical and legal considerations that arise from the use of GAI and ChatGPT by drawing attention to the contro-versies and hazards associated with these technologies.",
    "doi": "10.15678/eber.2023.110201",
    "url": "https://www.semanticscholar.org/paper/954f7412a37649eff89da3e84df0257aa63655e9",
    "pdf_url": "https://eber.uek.krakow.pl/index.php/eber/article/view/2113/852",
    "venue": "Entrepreneurial Business and Economics Review",
    "citation_count": 348,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.587031"
  },
  {
    "source": "semantic_scholar",
    "source_id": "6a1f8f8247574b831f3f2ea97f8ca146415ed255",
    "title": "Navigating and reviewing ethical dilemmas in AI development: Strategies for transparency, fairness, and accountability",
    "authors": [
      "Olatunji Akinrinola",
      "Chinwe Chinazo Okoye",
      "Onyeka Chrisanctus Ofodile",
      "Chinonye Esther Ugochukwu"
    ],
    "year": 2024,
    "abstract": "As artificial intelligence (AI) continues to permeate various aspects of our lives, the ethical challenges associated with its development become increasingly apparent. This paper navigates and reviews the ethical dilemmas in AI development, focusing on strategies to promote transparency, fairness, and accountability. The rapid growth of AI technology has given rise to concerns related to bias, lack of transparency, and the need for clear accountability mechanisms. In this exploration, we delve into the intricate ethical landscape of AI, examining issues such as bias and fairness, lack of transparency, and the challenges associated with accountability. To address these concerns, we propose strategies for transparency, including the implementation of Explainable AI (XAI), advocating for open data sharing, and embracing ethical AI frameworks. Furthermore, we explore strategies to promote fairness in AI algorithms, emphasizing the importance of fairness metrics, diverse training data, and continuous monitoring for iterative improvement. Additionally, the paper delves into strategies to ensure accountability in AI development, considering regulatory measures, ethical AI governance, and the incorporation of human-in-the-loop approaches. To provide practical insights, case studies and real-world examples are analyzed to distill lessons learned and best practices. The paper concludes with a comprehensive overview of the proposed strategies, emphasizing the importance of balancing innovation with ethical responsibility in the evolving landscape of AI development. This work contributes to the ongoing discourse on AI ethics, offering a roadmap for navigating the challenges and fostering responsible AI development practices.",
    "doi": "10.30574/gscarr.2024.18.3.0088",
    "url": "https://www.semanticscholar.org/paper/6a1f8f8247574b831f3f2ea97f8ca146415ed255",
    "pdf_url": "https://gsconlinepress.com/journals/gscarr/sites/default/files/GSCARR-2024-0088.pdf",
    "venue": "GSC Advanced Research and Reviews",
    "citation_count": 97,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.587035"
  },
  {
    "source": "semantic_scholar",
    "source_id": "29ab6634af3a6772404b03bb00895d21a6416524",
    "title": "Exploring the potential of Claude 2 for risk of bias assessment: Using a large language model to assess randomized controlled trials with RoB 2",
    "authors": [
      "Angelika Eisele-Metzger",
      "Judith-Lisa Lieberum",
      "M. Toews",
      "Waldemar Siemens",
      "Felix Heilmeyer",
      "Christian Haverkamp",
      "D. Boehringer",
      "Joerg J. Meerpohl"
    ],
    "year": 2024,
    "abstract": "Systematic reviews are essential for evidence based healthcare, but conducting them is time and resource consuming. To date, efforts have been made to accelerate and (semi-) automate various steps of systematic reviews through the use of artificial intelligence and the emergence of large language models (LLMs) promises further opportunities. One crucial but complex task within systematic review conduct is assessing the risk of bias of included studies. Therefore, the aim of this study was to test the LLM Claude 2 for risk of bias assessment of 100 randomized controlled trials using the revised Cochrane risk of bias tool (\"RoB 2\"; involving judgements for five specific domains and an overall judgement). We assessed the agreement of risk of bias judgements by Claude with human judgements published in Cochrane Reviews. The observed agreement between Claude and Cochrane authors ranged from 41% for the overall judgement to 71% for domain 4 (\"outcome measurement\"). Cohen's Kappa was lowest for domain 5 (\"selective reporting\"; 0.10 (95% confidence interval (CI): -0.10-0.31)) and highest for domain 3 (\"missing data\"; 0.31 (95% CI: 0.10-0.52)), indicating slight to fair agreement. Fair agreement was found for the overall judgement (Cohen's Kappa: 0.22 (95% CI: 0.06-0.38)). Sensitivity analyses using alternative prompting techniques or the more recent version Claude 3 did not result in substantial changes. Currently, Claude's RoB 2 judgements cannot replace human risk of bias assessment. However, the potential of LLMs to support risk of bias assessment should be further explored.",
    "doi": "10.1017/rsm.2025.12",
    "url": "https://www.semanticscholar.org/paper/29ab6634af3a6772404b03bb00895d21a6416524",
    "pdf_url": "https://doi.org/10.1101/2024.07.16.24310483",
    "venue": "medRxiv",
    "citation_count": 9,
    "fields_of_study": [
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:06.587039"
  },
  {
    "source": "semantic_scholar",
    "source_id": "6c1441fbc440f0dcc1a94bdcf1cb61a2eb7738b2",
    "title": "Artificial Intelligence Involvement in Graphic Game Development",
    "authors": [
      "Safal Antony",
      "Sabari T",
      "R. I. Joshua",
      "N. Jayapandian"
    ],
    "year": 2023,
    "abstract": "Games have always been a popular form of entertainment and with the advancements in technology, the integration of Artificial Intelligence (AI) in gaming has revolutionized the gaming industry. This research article aims to explore the various applications of AI in gaming and its impact on the industry and player experience. Unlike the typical straightforward nature of AI, this research paper takes a more human approach to discussing the topic. It delves into the evolution of AI in games and the various types of AI used in game development. These include rule-based AI, learning- based AI, and evolutionary AI, which have all contributed to the development of increasingly immersive gaming experiences. The benefits and challenges of using AI in games are also explored, considering the impact on player experience. While AI-powered opponents can provide a greater challenge, balancing the difficulty level is critical to ensuring the game remains enjoyable. The potential ethical concerns of using AI in games are also discussed, such as data privacy, bias, and fairness. Furthermore, this research paper looks into the future of AI in games and how it may shape the gaming industry and player experience in the years to come. With the continued development of AI techniques such as reinforcement learning and GANs, the possibilities for more immersive and engaging gaming experiences are endless.",
    "doi": "10.1109/ICAISS58487.2023.10250553",
    "url": "https://www.semanticscholar.org/paper/6c1441fbc440f0dcc1a94bdcf1cb61a2eb7738b2",
    "pdf_url": "",
    "venue": "2023 Second International Conference on Augmented Intelligence and Sustainable Systems (ICAISS)",
    "citation_count": 3,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:06.587042"
  },
  {
    "source": "semantic_scholar",
    "source_id": "0bb7a2c972d341efe80e76a09beaa69b2efd38e3",
    "title": "Toward Fairness, Morality and Transparency in Artificial Intelligence through Experiential AI",
    "authors": [
      "D. Hemment",
      "Vaishak Belle",
      "R. Aylett",
      "Dave Murray-Rust",
      "Larissa Pschetz",
      "Frank Broz"
    ],
    "year": 2019,
    "abstract": "https://doi.org/10.1162/leon_a_01795 \u00a92019 ISAST The new research Theme experienTial ai, at Edin\u00ad burgh Futures Institute, responds to concerns around the societal impacts of artificial intelligence (AI) and proposes a cross\u00addisciplinary AI research and practice between art and science [1]. The last year has been a watershed for the conjunction of art and AI, reflected in Ars Electronica introducing a new category in their Prix [2]. Elsewhere, capabilities of AI were often overclaimed in reporting on the first artwork \u201ccreated by an algorithm\u201d to be sold at Christie\u2019s [3]. Increasingly, art\u00ad ists are experimenting with machine learning algorithms as subject and tool. Something of an emerging machine learning aesthetic reveals and manifests distortions in the ways algo\u00ad rithms interpret the world. The misshapen imagery that can result, named by one proponent the \u201cFrancis Bacon effect\u201d [4], arguably enables the character of machine reasoning and vision to be made explicit and its artifacts tangible [5]. Other artists have addressed the social and ethical conse\u00ad quences of algorithms. CV Dazzle by Adam Harvey presents hair styling and makeup as camouflage from face\u00addetection technology [6], and Mushon Zer\u00adAviv questions the con\u00ad struction of prejudice and normalcy in The Normalizing Machine [7]. The fairness and morality of AI systems, a topic so far little explored by the current generation of artists working with machine learning algorithms, is already under inves\u00ad tigation by AI scientists. Because most prediction systems look for frequent patterns, algorithms trained on data em\u00ad bodying specific historical and cultural biases produce, un\u00ad surprisingly, systems exhibiting these same biases. Thus, AI researchers are devising definitions that enable predictions to respect fairness constraints with respect to gender, race and other \u201cprotected attributes\u201d despite biases in data. Fairness is, however, one part of a larger picture. AI al\u00ad gorithms are frequently used for recruitment and trading stocks but also in self\u00addriving cars and domestic robots that act physically on the environment and with people. What biases might these robotic applications infer from long\u00adterm interactions with us? Conversely, what values would we like them to embody? Should we strive for a shared computa\u00ad tional framework enabling machines to reason about their actions and ethical implications? How can we make such systems sufficiently transparent that we can understand and critique their reasoning? The design of moral machines needs to account for the con\u00ad tingency of human value systems across contexts, cultures and demographic groups. The logic of computation shapes political and public discourse in its image, in ways that can be inimical to societal values. There are, therefore, longstanding concerns about translating morals from the domain of human ethics and politics into a framework using numeric repre\u00ad sentations. We must both consider machines that can engage in ethical reasoning and simultaneously recommend social domains that are not suited to automated decision\u00admaking. Fairness, morality and transparency will be the theme of the first program in Experiential AI. Participating artists will experiment with new ideas, data and technologies and engage both AI practitioners and publics in envisioning fu\u00ad tures for ethical and responsible AI. Their works can allow audiences to explore future scenarios and experience various aspects of the moral dimension, making algorithmic mecha\u00ad nisms vividly apparent. As a methodology and approach, experiential AI can ques\u00ad tion data harvesting, algorithms and the outcomes of their application, and how a system is understood. Art can create experiences around social impacts and consequences of tech\u00ad nology, giving audiences direct experience of philosophical and computational principles. It can challenge what the algo\u00ad rithms are and how they are used. This can lead to significant new works and create insights to feed into the design of these technologies.",
    "doi": "10.1162/leon_a_01795",
    "url": "https://www.semanticscholar.org/paper/0bb7a2c972d341efe80e76a09beaa69b2efd38e3",
    "pdf_url": "https://www.pure.ed.ac.uk/ws/files/106508348/Toward_Fairness_Morality_HEMMENT_DoA090719_AFV.pdf",
    "venue": "Leonardo: Journal of the International Society for the Arts, Sciences and Technology",
    "citation_count": 1,
    "fields_of_study": [
      "Psychology"
    ],
    "retrieved_at": "2026-02-02T16:58:06.587046"
  },
  {
    "source": "semantic_scholar",
    "source_id": "ae45f035d155b4001c53436fc7e7147c3d39eb39",
    "title": "Beyond fairness, accountability, and transparency in the ethics of algorithms: Contributions and perspectives from LIS",
    "authors": [
      "A. Hoffmann",
      "Sarah T. Roberts",
      "Christine T. Wolf",
      "Stacy Wood"
    ],
    "year": 2018,
    "abstract": null,
    "doi": "10.1002/PRA2.2018.14505501084",
    "url": "https://www.semanticscholar.org/paper/ae45f035d155b4001c53436fc7e7147c3d39eb39",
    "pdf_url": "",
    "venue": "ASIS&T Annual Meeting",
    "citation_count": 22,
    "fields_of_study": [
      "Computer Science",
      "Sociology"
    ],
    "retrieved_at": "2026-02-02T16:58:06.587049"
  },
  {
    "source": "openalex",
    "source_id": "W4206346145",
    "title": "Can HR adapt to the paradoxes of artificial intelligence?",
    "authors": [
      "Andy Charlwood",
      "Nigel Guenole"
    ],
    "year": 2022,
    "abstract": "Abstract Artificial intelligence (AI) is widely heralded as a new and revolutionary technology that will transform the world of work. While the impact of AI on human resource (HR) and people management is difficult to predict, the article considers potential scenarios for how AI will affect our field. We argue that although popular accounts of AI stress the risks of bias and unfairness, these problems are eminently solvable. However, the way that the AI industry is currently constituted and wider trends in the use of technology for organising work mean that there is a significant risk that AI use will degrade the quality of work. Viewing different scenarios through a paradox lens, we argue that both positive and negative visions of the future are likely to coexist. The HR profession has a degree of agency to shape the future if it chooses to use it; HR professionals need to develop the skills to ensure that ethics and fairness are at the centre of AI development for HR and people management.",
    "doi": "10.1111/1748-8583.12433",
    "url": "https://openalex.org/W4206346145",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/1748-8583.12433",
    "venue": "Human Resource Management Journal",
    "citation_count": 199,
    "fields_of_study": [
      "Vision",
      "Agency (philosophy)",
      "Work (physics)",
      "Field (mathematics)",
      "Quality (philosophy)"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768317"
  },
  {
    "source": "openalex",
    "source_id": "W4236357753",
    "title": "The ARRIVE guidelines 2.0: Updated guidelines for reporting animal research",
    "authors": [
      "Nathalie Percie du Sert",
      "Viki Hurst",
      "Amrita Ahluwalia",
      "Sabina Alam",
      "Marc T. Avey",
      "Monya Baker",
      "William J. Browne",
      "Alejandra Clark",
      "Innes C. Cuthill",
      "Ulrich Dirnagl",
      "Michael Emerson",
      "Paul Garner",
      "Stephen T. Holgate",
      "David W. Howells",
      "Natasha A. Karp",
      "Stanley E. Lazic",
      "Katie Lidster",
      "Catriona MacCallum",
      "Malcolm Macleod",
      "Esther J. Pearl",
      "Ole H. Petersen",
      "Frances Rawle",
      "Penny S. Reynolds",
      "Kieron Rooney",
      "Emily S. Sena",
      "Shai D. Silberberg",
      "Thomas Steckler",
      "Hanno W\u00fcrbel"
    ],
    "year": 2020,
    "abstract": "Reproducible science requires transparent reporting. The ARRIVE guidelines (Animal Research: Reporting of In Vivo Experiments) were originally developed in 2010 to improve the reporting of animal research. They consist of a checklist of information to include in publications describing in vivo experiments to enable others to scrutinise the work adequately, evaluate its methodological rigour, and reproduce the methods and results. Despite considerable levels of endorsement by funders and journals over the years, adherence to the guidelines has been inconsistent, and the anticipated improvements in the quality of reporting in animal research publications have not been achieved. Here, we introduce ARRIVE 2.0. The guidelines have been updated and information reorganised to facilitate their use in practice. We used a Delphi exercise to prioritise and divide the items of the guidelines into 2 sets, the \"ARRIVE Essential 10,\" which constitutes the minimum requirement, and the \"Recommended Set,\" which describes the research context. This division facilitates improved reporting of animal research by supporting a stepwise approach to implementation. This helps journal editors and reviewers verify that the most important items are being reported in manuscripts. We have also developed the accompanying Explanation and Elaboration (E&E) document, which serves (1) to explain the rationale behind each item in the guidelines, (2) to clarify key concepts, and (3) to provide illustrative examples. We aim, through these changes, to help ensure that researchers, reviewers, and journal editors are better equipped to improve the rigour and transparency of the scientific process and thus reproducibility.",
    "doi": "10.1371/journal.pbio.3000410",
    "url": "https://openalex.org/W4236357753",
    "pdf_url": "https://journals.plos.org/plosbiology/article/file?id=10.1371/journal.pbio.3000410&type=printable",
    "venue": "PLoS Biology",
    "citation_count": 5017,
    "fields_of_study": [
      "Rigour",
      "Checklist",
      "Context (archaeology)",
      "Transparency (behavior)",
      "Set (abstract data type)"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768356"
  },
  {
    "source": "openalex",
    "source_id": "W2902634493",
    "title": "AI4People\u2014An Ethical Framework for a Good AI Society: Opportunities, Risks, Principles, and Recommendations",
    "authors": [
      "Luciano Floridi",
      "Josh Cowls",
      "Monica Beltrametti",
      "Raja Chatila",
      "Patrice Chazerand",
      "Virginia Dignum",
      "Christoph Luetge",
      "Robert Madelin",
      "Ugo Pagallo",
      "Francesca Rossi",
      "Burkhard Sch\u00e4fer",
      "Peggy Valcke",
      "Effy Vayena"
    ],
    "year": 2018,
    "abstract": null,
    "doi": "10.1007/s11023-018-9482-5",
    "url": "https://openalex.org/W2902634493",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s11023-018-9482-5.pdf",
    "venue": "Minds and Machines",
    "citation_count": 2813,
    "fields_of_study": [
      "Philosophy of science",
      "Foundation (evidence)",
      "Engineering ethics",
      "Responsible Research and Innovation",
      "Philosophy of mind"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768382"
  },
  {
    "source": "openalex",
    "source_id": "W2969625533",
    "title": "Artificial Intelligence (AI): Multidisciplinary perspectives on emerging challenges, opportunities, and agenda for research, practice and policy",
    "authors": [
      "Yogesh K. Dwivedi",
      "Laurie Hughes",
      "Elvira Ismagilova",
      "Gert Aarts",
      "Crispin Coombs",
      "Tom Crick",
      "Yanqing Duan",
      "Rohita Dwivedi",
      "John S. Edwards",
      "Aled Eirug",
      "Vassilis Galanos",
      "P. Vigneswara Ilavarasan",
      "Marijn Janssen",
      "Paul Jones",
      "Arpan Kumar Kar",
      "Hatice Kizgin",
      "Bianca Kronemann",
      "Banita Lal",
      "Biagio Lucini",
      "Rony Medaglia",
      "Kenneth Le Meunier\u2010FitzHugh",
      "Leslie Caroline Le Meunier-FitzHugh",
      "Santosh K. Misra",
      "Emmanuel Mogaji",
      "Sujeet Kumar Sharma",
      "Jang Bahadur Singh",
      "Vishnupriya Raghavan",
      "Ramakrishnan Raman",
      "Nripendra P. Rana",
      "Spyridon Samothrakis",
      "Jak Spencer",
      "Kuttimani Tamilmani",
      "Annie Tubadji",
      "Paul Walton",
      "Michael D. Williams"
    ],
    "year": 2019,
    "abstract": "&lt;p&gt;As far back as the industrial revolution, significant development in technical innovation has succeeded in transforming numerous manual tasks and processes that had been in existence for decades where humans had reached the limits of physical capacity. Artificial Intelligence (AI) offers this same transformative potential for the augmentation and potential replacement of human tasks and activities within a wide range of industrial, intellectual and social applications. The pace of change for this new AI technological age is staggering, with new breakthroughs in algorithmic machine learning and autonomous decision-making, engendering new opportunities for continued innovation. The impact of AI could be significant, with industries ranging from: finance, healthcare, manufacturing, retail, supply chain, logistics and utilities, all potentially disrupted by the onset of AI technologies. The study brings together the collective insight from a number of leading expert contributors to highlight the significant opportunities, realistic assessment of impact, challenges and potential research agenda posed by the rapid emergence of AI within a number of domains: business and management, government, public sector, and science and technology. This research offers significant and timely insight to AI technology and its impact on the future of industry and society in general, whilst recognising the societal and industrial influence on pace and direction of AI development.&lt;/p&gt;",
    "doi": "10.1016/j.ijinfomgt.2019.08.002",
    "url": "https://openalex.org/W2969625533",
    "pdf_url": "https://www.sciencedirect.com/science/article/pii/S026840121930917X",
    "venue": "International Journal of Information Management",
    "citation_count": 3635,
    "fields_of_study": [
      "Pace",
      "Transformative learning",
      "Government (linguistics)",
      "Multidisciplinary approach",
      "Supply chain"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768388"
  },
  {
    "source": "openalex",
    "source_id": "W4360620450",
    "title": "Opinion Paper: \u201cSo what if ChatGPT wrote it?\u201d Multidisciplinary perspectives on opportunities, challenges and implications of generative conversational AI for research, practice and policy",
    "authors": [
      "Yogesh K. Dwivedi",
      "Nir Kshetri",
      "Laurie Hughes",
      "Emma Slade",
      "Anand Jeyaraj",
      "Arpan Kumar Kar",
      "Abdullah M. Baabdullah",
      "Alex Koohang",
      "Vishnupriya Raghavan",
      "Manju Ahuja",
      "Hanaa Albanna",
      "Mousa Ahmad Albashrawi",
      "Adil S. Al-Busaidi",
      "Janarthanan Balakrishnan",
      "Yves Barlette",
      "Sriparna Basu",
      "Indranil Bose",
      "Laurence Brooks",
      "Dimitrios Buhalis",
      "Lemuria Carter",
      "Soumyadeb Chowdhury",
      "Tom Crick",
      "Scott W. Cunningham",
      "Gareth H. Davies",
      "Robert M. Davison",
      "Rahul D\u00e9",
      "Denis Dennehy",
      "Yanqing Duan",
      "Rameshwar Dubey",
      "Rohita Dwivedi",
      "John S. Edwards",
      "Carlos Flavi\u00e1n",
      "Robin Gauld",
      "Varun Grover",
      "Mei\u2010Chih Hu",
      "Marijn Janssen",
      "Paul Jones",
      "Iris Junglas",
      "Sangeeta Khorana",
      "Sascha Kraus",
      "Kai R. Larsen",
      "Paul Latreille",
      "Sven Laumer",
      "Tegwen Malik",
      "Abbas Mardani",
      "Marcello Mariani",
      "Sunil Mithas",
      "Emmanuel Mogaji",
      "Jeretta Horn Nord",
      "Siobh\u00e1n O\u2019Connor",
      "Fevzi Okumus",
      "Margherita Pagani",
      "Neeraj Pandey",
      "Savvas Papagiannidis",
      "Ilias O. Pappas",
      "Nishith Pathak",
      "Jan Pries\u2010Heje",
      "Ramakrishnan Raman",
      "Nripendra P. Rana",
      "Sven\u2010Volker Rehm",
      "Samuel Ribeiro\u2010Navarrete",
      "Alexander Richter",
      "Frantz Rowe",
      "Suprateek Sarker",
      "Bernd Carsten Stahl",
      "Manoj Tiwari",
      "Wil van der Aalst",
      "Viswanath Venkatesh",
      "Giampaolo Viglia",
      "Michael Wade",
      "Paul Walton",
      "Jochen Wirtz",
      "Ryan Wright"
    ],
    "year": 2023,
    "abstract": "Transformative artificially intelligent tools, such as ChatGPT, designed to generate sophisticated text indistinguishable from that produced by a human, are applicable across a wide range of contexts. The technology presents opportunities as well as, often ethical and legal, challenges, and has the potential for both positive and negative impacts for organisations, society, and individuals. Offering multi-disciplinary insight into some of these, this article brings together 43 contributions from experts in fields such as computer science, marketing, information systems, education, policy, hospitality and tourism, management, publishing, and nursing. The contributors acknowledge ChatGPT's capabilities to enhance productivity and suggest that it is likely to offer significant gains in the banking, hospitality and tourism, and information technology industries, and enhance business activities, such as management and marketing. Nevertheless, they also consider its limitations, disruptions to practices, threats to privacy and security, and consequences of biases, misuse, and misinformation. However, opinion is split on whether ChatGPT's use should be restricted or legislated. Drawing on these contributions, the article identifies questions requiring further research across three thematic areas: knowledge, transparency, and ethics; digital transformation of organisations and societies; and teaching, learning, and scholarly research. The avenues for further research include: identifying skills, resources, and capabilities needed to handle generative AI; examining biases of generative AI attributable to training datasets and processes; exploring business and societal contexts best suited for generative AI implementation; determining optimal combinations of human and generative AI for various tasks; identifying ways to assess accuracy of text produced by generative AI; and uncovering the ethical and legal issues in using generative AI across different contexts. 2023 The Authors",
    "doi": "10.1016/j.ijinfomgt.2023.102642",
    "url": "https://openalex.org/W4360620450",
    "pdf_url": "https://linkinghub.elsevier.com/science/article/pii/S0268401223000233/pdfft?md5=492895056a2fa29b1cb81876a1c57544&pid=1-s2.0-S0268401223000233-main.pdf",
    "venue": "International Journal of Information Management",
    "citation_count": 3140,
    "fields_of_study": [
      "Transformative learning",
      "Generative grammar",
      "Knowledge management",
      "Hospitality",
      "Engineering ethics"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768414"
  },
  {
    "source": "openalex",
    "source_id": "W4205372944",
    "title": "Ethics Guidelines for Using AI-based Algorithms in Recruiting: Learnings from a Systematic Literature Review",
    "authors": [
      "Lennart Hofeditz",
      "Milad Mirbabaie",
      "Audrey Luther",
      "Riccarda Mauth",
      "Ina Rentemeister"
    ],
    "year": 2022,
    "abstract": "To reduce the workload of employees working in Human Resource departments and to avoid bias in pre-selection of applicants, an increasing number of companies deploy Artificial Intelligence (AI)-based algorithms. Some examples such as Amazon\u2019s discriminating recruiting algorithm showed that algorithms are not free of unethical decision making. Although there already exists a variety of ethics principles for AI-based systems, those are usually hardly being applicable to specific use cases such as using AI-based algorithms in recruiting processes. To address this issue and to provide guidance for researchers and practitioners, we conducted a systematic literature review (keyword and backwards search) on existing ethics guidelines and principles for AI and extracted aspects that seemed applicable to guide recruiting processed. Based on 28 relevant papers we derived actionable guidelines for using AI-based algorithms in recruiting processes. We categorized our guidelines into the aspects of fairness, avoidance of discrimination and avoidance of bias.",
    "doi": "10.24251/hicss.2022.018",
    "url": "https://openalex.org/W4205372944",
    "pdf_url": "https://doi.org/10.24251/hicss.2022.018",
    "venue": "Proceedings of the ... Annual Hawaii International Conference on System Sciences/Proceedings of the Annual Hawaii International Conference on System Sciences",
    "citation_count": 18,
    "fields_of_study": [
      "Computer science",
      "Algorithm",
      "Management science",
      "Engineering"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768437"
  },
  {
    "source": "openalex",
    "source_id": "W4384071683",
    "title": "Large language models encode clinical knowledge",
    "authors": [
      "Karan Singhal",
      "Shekoofeh Azizi",
      "Tao Tu",
      "S. Sara Mahdavi",
      "Jason Lee",
      "Hyung Won Chung",
      "Nathan Scales",
      "Ajay Kumar Tanwani",
      "Heather Cole-Lewis",
      "Stephen Pfohl",
      "Perry W. Payne",
      "Martin Seneviratne",
      "Paul Gamble",
      "Christopher Kelly",
      "Abubakr Babiker",
      "Nathanael Sch\u00e4rli",
      "Aakanksha Chowdhery",
      "P. Mansfield",
      "Dina Demner\u2010Fushman",
      "Blaise Ag\u00fcera y Arcas",
      "Dale R. Webster",
      "Greg S. Corrado",
      "Yossi Matias",
      "Katherine Chou",
      "Juraj Gottweis",
      "Nenad Toma\u0161ev",
      "Yun Liu",
      "Alvin Rajkomar",
      "Jo\u00eblle Barral",
      "Christopher Semturs",
      "Alan Karthikesalingam",
      "Vivek Natarajan"
    ],
    "year": 2023,
    "abstract": null,
    "doi": "10.1038/s41586-023-06291-2",
    "url": "https://openalex.org/W4384071683",
    "pdf_url": "https://www.nature.com/articles/s41586-023-06291-2.pdf",
    "venue": "Nature",
    "citation_count": 2503,
    "fields_of_study": [
      "Computer science",
      "Benchmark (surveying)",
      "Language model",
      "Comprehension",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768457"
  },
  {
    "source": "openalex",
    "source_id": "W4386958277",
    "title": "Revolutionizing healthcare: the role of artificial intelligence in clinical practice",
    "authors": [
      "Shuroug A. Alowais",
      "Sahar S. Alghamdi",
      "Nada Alsuhebany",
      "Tariq Alqahtani",
      "Abdulrahman Alshaya",
      "Sumaya N. Almohareb",
      "Atheer Aldairem",
      "Mohammed Alrashed",
      "Khalid Bin Saleh",
      "Hisham A. Badreldin",
      "Majed S. Al Yami",
      "Shmeylan Al Harbi",
      "Abdulkareem Albekairy"
    ],
    "year": 2023,
    "abstract": null,
    "doi": "10.1186/s12909-023-04698-z",
    "url": "https://openalex.org/W4386958277",
    "pdf_url": "https://bmcmededuc.biomedcentral.com/counter/pdf/10.1186/s12909-023-04698-z",
    "venue": "BMC Medical Education",
    "citation_count": 2386,
    "fields_of_study": [
      "Health care",
      "MEDLINE",
      "Applications of artificial intelligence",
      "Medicine",
      "Leverage (statistics)"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768461"
  },
  {
    "source": "openalex",
    "source_id": "W4247155454",
    "title": "Artificial Intelligence and Management: The Automation\u2013Augmentation Paradox",
    "authors": [
      "Sebastian Raisch",
      "Sebastian Krakowski"
    ],
    "year": 2021,
    "abstract": "Taking three recent business books on artificial intelligence (AI) as a starting point, we explore the automation and augmentation concepts in the management domain. Whereas automation implies that machines take over a human task, augmentation means that humans collaborate closely with machines to perform a task. Taking a normative stance, the three books advise organizations to prioritize augmentation, which they relate to superior performance. Using a more comprehensive paradox theory perspective, we argue that, in the management domain, augmentation cannot be neatly separated from automation. These dual AI applications are interdependent across time and space, creating a paradoxical tension. Overemphasizing either augmentation or automation fuels reinforcing cycles with negative organizational and societal outcomes. However, if organizations adopt a broader perspective comprising both automation and augmentation, they could deal with the tension and achieve complementarities that benefit business and society. Drawing on our insights, we conclude that management scholars need to be involved in research on the use of AI in organizations. We also argue that a substantial change is required in how AI research is currently conducted in order to develop meaningful theory and to provide practice with sound advice.",
    "doi": "10.5465/amr.2018.0072",
    "url": "https://openalex.org/W4247155454",
    "pdf_url": "https://journals.aom.org/doi/full/10.5465/amr.2018.0072",
    "venue": "Academy of Management Review",
    "citation_count": 1382,
    "fields_of_study": [
      "Automation",
      "Task (project management)",
      "Interdependence",
      "Normative",
      "Knowledge management"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768464"
  },
  {
    "source": "openalex",
    "source_id": "W4386142022",
    "title": "Interpreting Black-Box Models: A Review on Explainable Artificial Intelligence",
    "authors": [
      "Vikas Hassija",
      "Vinay Chamola",
      "A. Mahapatra",
      "Abhinandan Singal",
      "Divyansh Goel",
      "Kaizhu Huang",
      "Simone Scardapane",
      "Indro Spinelli",
      "Mufti Mahmud",
      "Amir Hussain"
    ],
    "year": 2023,
    "abstract": "Abstract Recent years have seen a tremendous growth in Artificial Intelligence (AI)-based methodological development in a broad range of domains. In this rapidly evolving field, large number of methods are being reported using machine learning (ML) and Deep Learning (DL) models. Majority of these models are inherently complex and lacks explanations of the decision making process causing these models to be termed as 'Black-Box'. One of the major bottlenecks to adopt such models in mission-critical application domains, such as banking, e-commerce, healthcare, and public services and safety, is the difficulty in interpreting them. Due to the rapid proleferation of these AI models, explaining their learning and decision making process are getting harder which require transparency and easy predictability. Aiming to collate the current state-of-the-art in interpreting the black-box models, this study provides a comprehensive analysis of the explainable AI (XAI) models. To reduce false negative and false positive outcomes of these back-box models, finding flaws in them is still difficult and inefficient. In this paper, the development of XAI is reviewed meticulously through careful selection and analysis of the current state-of-the-art of XAI research. It also provides a comprehensive and in-depth evaluation of the XAI frameworks and their efficacy to serve as a starting point of XAI for applied and theoretical researchers. Towards the end, it highlights emerging and critical issues pertaining to XAI research to showcase major, model-specific trends for better explanation, enhanced transparency, and improved prediction accuracy.",
    "doi": "10.1007/s12559-023-10179-8",
    "url": "https://openalex.org/W4386142022",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s12559-023-10179-8.pdf",
    "venue": "Cognitive Computation",
    "citation_count": 1280,
    "fields_of_study": [
      "Transparency (behavior)",
      "Computer science",
      "Black box",
      "Process (computing)",
      "Predictability"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768486"
  },
  {
    "source": "openalex",
    "source_id": "W3199189488",
    "title": "Artificial intelligence in education: Addressing ethical challenges in K-12 settings",
    "authors": [
      "Selin Akg\u00fcn",
      "Christine Greenhow"
    ],
    "year": 2021,
    "abstract": null,
    "doi": "10.1007/s43681-021-00096-7",
    "url": "https://openalex.org/W3199189488",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s43681-021-00096-7.pdf",
    "venue": "AI and Ethics",
    "citation_count": 1028,
    "fields_of_study": [
      "Artificial intelligence",
      "Variety (cybernetics)",
      "Computer science",
      "Field (mathematics)",
      "Mathematics"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768508"
  },
  {
    "source": "openalex",
    "source_id": "W4317910584",
    "title": "ChatGPT: Bullshit spewer or the end of traditional assessments in higher education?",
    "authors": [
      "J\u00fcrgen Rudolph",
      "Samson Tan",
      "Shannon Tan"
    ],
    "year": 2023,
    "abstract": "ChatGPT is the world\u2019s most advanced chatbot thus far. Unlike other chatbots, it can create impressive prose within seconds, and it has created much hype and doomsday predictions when it comes to student assessment in higher education and a host of other matters. ChatGPT is a state-of-the-art language model (a variant of OpenAI\u2019s Generative Pretrained Transformer (GPT) language model) designed to generate text that can be indistinguishable from text written by humans. It can engage in conversation with users in a seemingly natural and intuitive way. In this article, we briefly tell the story of OpenAI, the organisation behind ChatGPT. We highlight the fundamental change from a not-for-profit organisation to a commercial business model. In terms of our methods, we conducted an extensive literature review and experimented with this artificial intelligence (AI) software. Our literature review shows our review to be amongst the first peer-reviewed academic journal articles to explore ChatGPT and its relevance for higher education (especially assessment, learning and teaching). After a description of ChatGPT\u2019s functionality and a summary of its strengths and limitations, we focus on the technology\u2019s implications for higher education and discuss what is the future of learning, teaching and assessment in higher education in the context of AI chatbots such as ChatGPT. We position ChatGPT in the context of current Artificial Intelligence in Education (AIEd) research, discuss student-facing, teacher-facing and system-facing applications, and analyse opportunities and threats. We conclude the article with recommendations for students, teachers and higher education institutions. Many of them focus on assessment.",
    "doi": "10.37074/jalt.2023.6.1.9",
    "url": "https://openalex.org/W4317910584",
    "pdf_url": "https://journals.sfu.ca/jalt/index.php/jalt/article/download/689/539",
    "venue": "Journal of Applied Learning & Teaching",
    "citation_count": 1549,
    "fields_of_study": [
      "Chatbot",
      "Conversation",
      "Relevance (law)",
      "Context (archaeology)",
      "Higher education"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768511"
  },
  {
    "source": "openalex",
    "source_id": "W4304943299",
    "title": "Ethical principles for artificial intelligence in education",
    "authors": [
      "Andy Nguyen",
      "Ha Ngan Ngo",
      "Yvonne Hong",
      "Belle Dang",
      "Bich\u2010Phuong Thi Nguyen"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1007/s10639-022-11316-w",
    "url": "https://openalex.org/W4304943299",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10639-022-11316-w.pdf",
    "venue": "Education and Information Technologies",
    "citation_count": 861,
    "fields_of_study": [
      "Autonomy",
      "Engineering ethics",
      "Underpinning",
      "Trustworthiness",
      "Set (abstract data type)"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768538"
  },
  {
    "source": "openalex",
    "source_id": "W4383312437",
    "title": "A comprehensive AI policy education framework for university teaching and learning",
    "authors": [
      "Cecilia Ka Yuk Chan"
    ],
    "year": 2023,
    "abstract": "Abstract This study aims to develop an AI education policy for higher education by examining the perceptions and implications of text generative AI technologies. Data was collected from 457 students and 180 teachers and staff across various disciplines in Hong Kong universities, using both quantitative and qualitative research methods. Based on the findings, the study proposes an AI Ecological Education Policy Framework to address the multifaceted implications of AI integration in university teaching and learning. This framework is organized into three dimensions: Pedagogical, Governance, and Operational. The Pedagogical dimension concentrates on using AI to improve teaching and learning outcomes, while the Governance dimension tackles issues related to privacy, security, and accountability. The Operational dimension addresses matters concerning infrastructure and training. The framework fosters a nuanced understanding of the implications of AI integration in academic settings, ensuring that stakeholders are aware of their responsibilities and can take appropriate actions accordingly.",
    "doi": "10.1186/s41239-023-00408-3",
    "url": "https://openalex.org/W4383312437",
    "pdf_url": "https://educationaltechnologyjournal.springeropen.com/counter/pdf/10.1186/s41239-023-00408-3",
    "venue": "International Journal of Educational Technology in Higher Education",
    "citation_count": 976,
    "fields_of_study": [
      "Dimension (graph theory)",
      "Accountability",
      "Corporate governance",
      "Higher education",
      "Sociology"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768541"
  },
  {
    "source": "openalex",
    "source_id": "W3033511014",
    "title": "Secure, privacy-preserving and federated machine learning in medical imaging",
    "authors": [
      "Georgios Kaissis",
      "Marcus R. Makowski",
      "Daniel R\u00fcckert",
      "Rickmer Braren"
    ],
    "year": 2020,
    "abstract": null,
    "doi": "10.1038/s42256-020-0186-1",
    "url": "https://openalex.org/W3033511014",
    "pdf_url": "https://www.nature.com/articles/s42256-020-0186-1.pdf",
    "venue": "Nature Machine Intelligence",
    "citation_count": 1148,
    "fields_of_study": [
      "Compromise",
      "Computer science",
      "Information privacy",
      "Computer security",
      "Bridge (graph theory)"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768556"
  },
  {
    "source": "openalex",
    "source_id": "W3155263273",
    "title": "Ethics of AI in Education: Towards a Community-Wide Framework",
    "authors": [
      "W. Holmes",
      "Ka\u015bka Porayska\u2010Pomsta",
      "Ken Holstein",
      "Emma Sutherland",
      "Toby T. Baker",
      "Simon Buckingham Shum",
      "Olga C. Santos",
      "Ma. Mercedes T. Rodrigo",
      "Mutlu Cukurova",
      "Ig Ibert Bittencourt",
      "Kenneth R. Koedinger"
    ],
    "year": 2021,
    "abstract": "Abstract While Artificial Intelligence in Education (AIED) research has at its core the desire to support student learning, experience from other AI domains suggest that such ethical intentions are not by themselves sufficient. There is also the need to consider explicitly issues such as fairness, accountability, transparency, bias, autonomy, agency, and inclusion. At a more general level, there is also a need to differentiate between doing ethical things and doing things ethically , to understand and to make pedagogical choices that are ethical, and to account for the ever-present possibility of unintended consequences. However, addressing these and related questions is far from trivial. As a first step towards addressing this critical gap, we invited 60 of the AIED community\u2019s leading researchers to respond to a survey of questions about ethics and the application of AI in educational contexts. In this paper, we first introduce issues around the ethics of AI in education. Next, we summarise the contributions of the 17 respondents, and discuss the complex issues that they raised. Specific outcomes include the recognition that most AIED researchers are not trained to tackle the emerging ethical questions. A well-designed framework for engaging with ethics of AIED that combined a multidisciplinary approach and a set of robust guidelines seems vital in this context.",
    "doi": "10.1007/s40593-021-00239-1",
    "url": "https://openalex.org/W3155263273",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s40593-021-00239-1.pdf",
    "venue": "International Journal of Artificial Intelligence in Education",
    "citation_count": 840,
    "fields_of_study": [
      "Accountability",
      "Autonomy",
      "Transparency (behavior)",
      "Engineering ethics",
      "Information ethics"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768559"
  },
  {
    "source": "openalex",
    "source_id": "W4385878593",
    "title": "New Era of Artificial Intelligence in Education: Towards a Sustainable Multifaceted Revolution",
    "authors": [
      "Firuz Kamalov",
      "David Santandreu Calonge",
      "Ikhlaas Gurrib"
    ],
    "year": 2023,
    "abstract": "The recent high performance of ChatGPT on several standardized academic tests has thrust the topic of artificial intelligence (AI) into the mainstream conversation about the future of education. As deep learning is poised to shift the teaching paradigm, it is essential to have a clear understanding of its effects on the current education system to ensure sustainable development and deployment of AI-driven technologies at schools and universities. This research aims to investigate the potential impact of AI on education through review and analysis of the existing literature across three major axes: applications, advantages, and challenges. Our review focuses on the use of artificial intelligence in collaborative teacher\u2013student learning, intelligent tutoring systems, automated assessment, and personalized learning. We also report on the potential negative aspects, ethical issues, and possible future routes for AI implementation in education. Ultimately, we find that the only way forward is to embrace the new technology, while implementing guardrails to prevent its abuse.",
    "doi": "10.3390/su151612451",
    "url": "https://openalex.org/W4385878593",
    "pdf_url": "https://www.mdpi.com/2071-1050/15/16/12451/pdf?version=1692181759",
    "venue": "Sustainability",
    "citation_count": 771,
    "fields_of_study": [
      "Mainstream",
      "Software deployment",
      "Applications of artificial intelligence",
      "Computer science",
      "Conversation"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768578"
  },
  {
    "source": "openalex",
    "source_id": "W3001807593",
    "title": "Closing the AI accountability gap",
    "authors": [
      "Inioluwa Deborah Raji",
      "Andrew Smart",
      "Rebecca N. White",
      "Margaret Mitchell",
      "Timnit Gebru",
      "Ben Hutchinson",
      "Jamila Smith-Loud",
      "Daniel Theron",
      "Parker Barnes"
    ],
    "year": 2020,
    "abstract": "Rising concern for the societal implications of artificial intelligence systems has inspired a wave of academic and journalistic literature in which deployed systems are audited for harm by investigators from outside the organizations deploying the algorithms. However, it remains challenging for practitioners to identify the harmful repercussions of their own systems prior to deployment, and, once deployed, emergent issues can become difficult or impossible to trace back to their source.",
    "doi": "10.1145/3351095.3372873",
    "url": "https://openalex.org/W3001807593",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3351095.3372873",
    "venue": null,
    "citation_count": 773,
    "fields_of_study": [
      "Software deployment",
      "Closing (real estate)",
      "Accountability",
      "Harm",
      "TRACE (psycholinguistics)"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768594"
  },
  {
    "source": "openalex",
    "source_id": "W4242918116",
    "title": "Data Feminism",
    "authors": [
      "Catherine D\u2019Ignazio",
      "Lauren Klein"
    ],
    "year": 2020,
    "abstract": "A new way of thinking about data science and data ethics that is informed by the ideas of intersectional feminism. Today, data science is a form of power. It has been used to expose injustice, improve health outcomes, and topple governments. But it has also been used to discriminate, police, and surveil. This potential for good, on the one hand, and harm, on the other, makes it essential to ask: Data science by whom? Data science for whom? Data science with whose interests in mind? The narratives around big data and data science are overwhelmingly white, male, and techno-heroic. In Data Feminism, Catherine D'Ignazio and Lauren Klein present a new way of thinking about data science and data ethics\u2014one that is informed by intersectional feminist thought. Illustrating data feminism in action, D'Ignazio and Klein show how challenges to the male/female binary can help challenge other hierarchical (and empirically wrong) classification systems. They explain how, for example, an understanding of emotion can expand our ideas about effective data visualization, and how the concept of invisible labor can expose the significant human efforts required by our automated systems. And they show why the data never, ever \u201cspeak for themselves.\u201d Data Feminism offers strategies for data scientists seeking to learn how feminism can help them work toward justice, and for feminists who want to focus their efforts on the growing field of data science. But Data Feminism is about much more than gender. It is about power, about who has it and who doesn't, and about how those differentials of power can be challenged and changed. The open access edition of this book was made possible by generous funding from the MIT Libraries.",
    "doi": "10.7551/mitpress/11805.001.0001",
    "url": "https://openalex.org/W4242918116",
    "pdf_url": "https://direct.mit.edu/books/book-pdf/2390355/book_9780262358521.pdf",
    "venue": "The MIT Press eBooks",
    "citation_count": 1306,
    "fields_of_study": [
      "Feminism",
      "Big data",
      "Injustice",
      "Sociology",
      "Engineering ethics"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768603"
  },
  {
    "source": "openalex",
    "source_id": "W4221106857",
    "title": "Legal and Ethical Consideration in Artificial Intelligence in Healthcare: Who Takes Responsibility?",
    "authors": [
      "Nithesh Naik",
      "B. M. Zeeshan Hameed",
      "Dasharathraj K Shetty",
      "Dishant Swain",
      "Milap Shah",
      "Rahul Paul",
      "Kaivalya Aggarwal",
      "Sufyan Ibrahim",
      "Vathsala Patil",
      "Komal Smriti",
      "Suyog Shetty",
      "Bhavan Prasad",
      "P. Ch\u0142osta",
      "Bhaskar Somani"
    ],
    "year": 2022,
    "abstract": "The legal and ethical issues that confront society due to Artificial Intelligence (AI) include privacy and surveillance, bias or discrimination, and potentially the philosophical challenge is the role of human judgment. Concerns about newer digital technologies becoming a new source of inaccuracy and data breaches have arisen as a result of its use. Mistakes in the procedure or protocol in the field of healthcare can have devastating consequences for the patient who is the victim of the error. Because patients come into contact with physicians at moments in their lives when they are most vulnerable, it is crucial to remember this. Currently, there are no well-defined regulations in place to address the legal and ethical issues that may arise due to the use of artificial intelligence in healthcare settings. This review attempts to address these pertinent issues highlighting the need for algorithmic transparency, privacy, and protection of all the beneficiaries involved and cybersecurity of associated vulnerabilities.",
    "doi": "10.3389/fsurg.2022.862322",
    "url": "https://openalex.org/W4221106857",
    "pdf_url": "https://www.frontiersin.org/articles/10.3389/fsurg.2022.862322/pdf",
    "venue": "Frontiers in Surgery",
    "citation_count": 792,
    "fields_of_study": [
      "Transparency (behavior)",
      "Health care",
      "Ethical issues",
      "Internet privacy",
      "Engineering ethics"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768628"
  },
  {
    "source": "openalex",
    "source_id": "W1598829572",
    "title": "Social Science Research: Principles, Methods and Practices",
    "authors": [
      "Anol Bhattacherjee",
      "Toleman, Mark",
      "Rowling, Samara",
      "Frederiks, Anita",
      "Andersen, Nikki"
    ],
    "year": 2019,
    "abstract": "This book is designed to introduce doctoral and postgraduate students to the process of conducting scientific research in the social sciences, business, education, public health, and related disciplines. It is a one-stop, comprehensive, and compact source for foundational concepts in behavioural research, and can serve as a standalone text or as a supplement to research readings in any doctoral seminar or research methods class. This book is currently being used as a research text at universities in 216 countries, across six continents and has been translated into seven different languages. To receive updates on this book, including the translated versions, please follow the author on Facebook or Twitter @Anol_B.",
    "doi": "10.26192/q7w89",
    "url": "https://openalex.org/W1598829572",
    "pdf_url": "https://digitalcommons.usf.edu/oa_textbooks/3",
    "venue": "University of Southern Queensland ePrints (University of Southern Queensland)",
    "citation_count": 2049,
    "fields_of_study": [
      "Management science",
      "Sociology",
      "Engineering ethics",
      "Data science",
      "Social science"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768643"
  },
  {
    "source": "openalex",
    "source_id": "W3135539146",
    "title": "Sustainable AI: AI for sustainability and the sustainability of AI",
    "authors": [
      "Aimee van Wynsberghe"
    ],
    "year": 2021,
    "abstract": "Abstract While there is a growing effort towards AI for Sustainability (e.g. towards the sustainable development goals) it is time to move beyond that and to address the sustainability of developing and using AI systems. In this paper I propose a definition of Sustainable AI; Sustainable AI is a movement to foster change in the entire lifecycle of AI products (i.e. idea generation, training, re-tuning, implementation, governance) towards greater ecological integrity and social justice. As such, Sustainable AI is focused on more than AI applications; rather, it addresses the whole sociotechnical system of AI. I have suggested here that Sustainable AI is not about how to sustain the development of AI per say but it is about how to develop AI that is compatible with sustaining environmental resources for current and future generations; economic models for societies; and societal values that are fundamental to a given society. I have articulated that the phrase Sustainable AI be understood as having two branches; AI for sustainability and sustainability of AI (e.g. reduction of carbon emissions and computing power). I propose that Sustainable AI take sustainable development at the core of its definition with three accompanying tensions between AI innovation and equitable resource distribution; inter and intra-generational justice; and, between environment, society, and economy. This paper is not meant to engage with each of the three pillars of sustainability (i.e. social, economic, environment), and as such the pillars of sustainable AI. Rather, this paper is meant to inspire the reader, the policy maker, the AI ethicist, the AI developer to connect with the environment\u2014to remember that there are environmental costs to AI. Further, to direct funding towards sustainable methods of AI.",
    "doi": "10.1007/s43681-021-00043-6",
    "url": "https://openalex.org/W3135539146",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s43681-021-00043-6.pdf",
    "venue": "AI and Ethics",
    "citation_count": 717,
    "fields_of_study": [
      "Sustainability",
      "Sustainable development",
      "Social sustainability",
      "Corporate governance",
      "Business"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768656"
  },
  {
    "source": "openalex",
    "source_id": "W2954266614",
    "title": "A Unified Framework of Five Principles for AI in Society",
    "authors": [
      "Luciano Floridi",
      "Josh Cowls"
    ],
    "year": 2019,
    "abstract": "Artificial Intelligence (AI) is already having a major impact on society. As a result, many organizations have launched a wide range of initiatives to establish ethical principles for the adoption of socially beneficial AI. Unfortunately, the sheer volume of proposed principles threatens to overwhelm and confuse. How might this problem of 'principle proliferation' be solved? In this paper, we report the results of a fine-grained analysis of several of the highest-profile sets of ethical principles for AI. We assess whether these principles converge upon a set of agreed-upon principles, or diverge, with significant disagreement over what constitutes 'ethical AI.' Our analysis finds a high degree of overlap among the sets of principles we analyze. We then identify an overarching framework consisting of five core principles for ethical AI. Four of them are core principles commonly used in bioethics: beneficence, non-maleficence, autonomy, and justice. On the basis of our comparative analysis, we argue that a new principle is needed in addition: explicability, understood as incorporating both the epistemological sense of intelligibility (as an answer to the question 'how does it work?') and in the ethical sense of accountability (as an answer to the question: 'who is responsible for the way it works?'). In the ensuing discussion, we note the limitations and assess the implications of this ethical framework for future efforts to create laws, rules, technical standards, and best practices for ethical AI in a wide range of contexts.",
    "doi": "10.1162/99608f92.8cd550d1",
    "url": "https://openalex.org/W2954266614",
    "pdf_url": "https://assets.pubpub.org/ukqte8ry/c8d3cba5-8f10-4a00-894c-3a3b886ad844.pdf",
    "venue": "Harvard Data Science Review",
    "citation_count": 868,
    "fields_of_study": [
      "Management science",
      "Epistemology",
      "Computer science",
      "Philosophy",
      "Engineering"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768681"
  },
  {
    "source": "openalex",
    "source_id": "W4383913712",
    "title": "Human resource management in the age of generative artificial intelligence: Perspectives and research directions on ChatGPT",
    "authors": [
      "Pawan Budhwar",
      "Soumyadeb Chowdhury",
      "Geoffrey Wood",
      "Herman Aguinis",
      "Greg J. Bamber",
      "Jose R. Beltran",
      "Paul Boselie",
      "Fang Lee Cooke",
      "Stephanie Decker",
      "Angelo S. DeNisi",
      "Prasanta Kumar Dey",
      "David Guest",
      "Andrew J. Knoblich",
      "Ashish Malik",
      "Jaap Paauwe",
      "Savvas Papagiannidis",
      "Charmi Patel",
      "Vijay Pereira",
      "Shuang Ren",
      "Steven G. Rogelberg",
      "Mark N. K. Saunders",
      "Rosalie L. Tung",
      "Arup Varma"
    ],
    "year": 2023,
    "abstract": "Abstract ChatGPT and its variants that use generative artificial intelligence (AI) models have rapidly become a focal point in academic and media discussions about their potential benefits and drawbacks across various sectors of the economy, democracy, society, and environment. It remains unclear whether these technologies result in job displacement or creation, or if they merely shift human labour by generating new, potentially trivial or practically irrelevant, information and decisions. According to the CEO of ChatGPT, the potential impact of this new family of AI technology could be as big as \u201cthe printing press\u201d, with significant implications for employment, stakeholder relationships, business models, and academic research, and its full consequences are largely undiscovered and uncertain. The introduction of more advanced and potent generative AI tools in the AI market, following the launch of ChatGPT, has ramped up the \u201cAI arms race\u201d, creating continuing uncertainty for workers, expanding their business applications, while heightening risks related to well\u2010being, bias, misinformation, context insensitivity, privacy issues, ethical dilemmas, and security. Given these developments, this perspectives editorial offers a collection of perspectives and research pathways to extend HRM scholarship in the realm of generative AI. In doing so, the discussion synthesizes the literature on AI and generative AI, connecting it to various aspects of HRM processes, practices, relationships, and outcomes, thereby contributing to shaping the future of HRM research.",
    "doi": "10.1111/1748-8583.12524",
    "url": "https://openalex.org/W4383913712",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/1748-8583.12524",
    "venue": "Human Resource Management Journal",
    "citation_count": 652,
    "fields_of_study": [
      "Generative grammar",
      "Context (archaeology)",
      "Stakeholder",
      "Scholarship",
      "Realm"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768719"
  },
  {
    "source": "openalex",
    "source_id": "W4389681782",
    "title": "Assessment of the bias of artificial intelligence generated images and large language models on their depiction of a surgeon",
    "authors": [
      "Jevan Cevik",
      "Bryan Lim",
      "Ishith Seth",
      "Foti Sofiadellis",
      "Richard J. Ross",
      "Roberto Cuomo",
      "Warren M. Rozen"
    ],
    "year": 2023,
    "abstract": "The increasing integration of artificial intelligence (AI) into domains like medicine, surgery, and research, has brought unparalleled advancements, and changed how doctors, particularly surgeons, are perceived.1-9 The advent of AI-generated images using generative adversarial networks (GANs) and increased reliance on large language models (LLMs), have raised concerns regarding biases. Bias in AI models can be gender, racial, or cultural, which pertain to the systematic and unfair preferences or discrimination of certain demographics in the behaviour and outcomes of AI systems. For instance, AI-generated images may disproportionately represent surgeons of a specific gender or race.10 These biases often originate from their training data.10 The consequences of such biases include skewed public perception, discrimination, and potential loss of trust in healthcare professionals and AI systems. Certain demographics may also find greater difficulty in entering certain specialities of medicine or attaining promotions due to unconscious bias against them. The investigation of biases in AI-generated images and descriptions, of surgeons, provides insights into potential inaccuracies and emphasizes the ethical implications of technology's role in shaping public opinion. Understanding these biases is critical for developing more equitable and accurate AI models, for educational, clinical, and public usage. This paper systematically analyses AI-generated images and descriptions from various GANs and LLMs to identify and characterize biases in the representation of surgeons. We discuss the underlying factors contributing to these biases, examine their impact on public perception, and propose mitigation strategies. Four generative AI tools, comprising two LLMs (ChatGPT-3.5 and BARD) and two GANs (Dall-E2 and Midjourney), were prompted to describe and illustrate characteristics of eight types of surgeons. Twenty-four descriptions and 64 images were extracted from them, which were then independently analysed by three reviewers (J.C., I.S., and B.L.) for presumed skin tone (Massey Martin NIS Skin Scale Score), age, gender, and Body Silhouette Scale Score.11, 12 Light and dark-skin-toned surgeons were classified with Massey scores of 1-2 and 3-10, respectively. Any discrepancies were discussed by all authors until consensus was achieved. No ethics had to be acquired as all data was generated by the AI tools. DALL-E2 generated 71.9% male and 28.1% female representations. They showed a balanced age representation: 43.8% depicted surgeons under 50 years, while 56.2% showed over 50. Furthermore, DALL-E2 has a balanced skin tone distribution with 50% being light-skinned, and 50% dark-skinned. Regarding Body Silhouette Scale Scores, 73.1% scored between 1 and 5, whereas 26.9% scored 6 or above (Table 1; Figs. 1-8). Midjourney displayed more biased results, producing 87.5% male and 12.5% female images. Based on the Massey Martin NIS Skin Scale Score, 100% of the surgeons were of skin scale scores of 1 or 2 which were categorized as light skin colours. Most surgeons appeared to be above 50 years of age (71.9%), more than DALL-E2's representation. Moreover, 96.4% had smaller body silhouettes between 1 and 5 on the Body Silhouette Scale (Table 1; Figs. 1-8). BARD stresses that no single trait defines a surgeon despite acknowledging a trend of white male surgeons in their 50s, often possessing sufficient strength to endure the physically demanding work. It then discusses exceptions, especially women of colour across different ages with varying personalities. BARD also underscores qualities like intellect, intrinsic motivation, and compassion as typically desirable attributes. While it occasionally provides detailed surgeon exemplars, it concludes its responses by reiterating the diversity of surgeons beyond stereotypes (Figs. 1-8). ChatGPT-3.5 recurrently highlights the inconsequentiality of physical attributes in determining a surgeon's proficiency, instead stressing their competence and compassion. Three of its replies allude to the typically upper age range of surgeons due to the long medical training they undertake. ChatGPT-3.5 occasionally describes the characteristics of a surgeon, narrating their behaviours and attitudes within and outside the professional milieu (Figs. 1-8). The LLMs demonstrated a nuanced understanding of surgeons' diverse backgrounds without significant bias, indicating their quality design and equitable training. In contrast, the AI-generated images of surgeons from the GANs demonstrated notable gender and skin-tone biases. While the current data indicates a male-dominated surgical population in Australia, it raises the question of whether AI should reflect these disparities or present a more equal representation.13 Failure to address the underlying inequalities could perpetuate bias, and conflating the current proportions with aspirational goals of diversity and inclusivity can complicate the issue. It is crucial to recognize this difference, assess these proportions and work towards a fairer and more equitable representation of surgeons, representing both current and desired realities. Ultimately, we argue that AI models should depict medical personnel such as surgeons in a more equitable manner. Dall-E2 evenly represented light and dark skin tones, whereas Midjourney exclusively depicted lighter skin tones. This indicates Dall-E2's training data or data processing maintains diversity, while Midjourney's outputs reveal a clear bias. Such a pattern in Midjourney raises questions about its training data and possible post-training adjustments. The marked underrepresentation of surgeons presumed to be female, in the results from both GANs, stands out as a significant issue. This disparity may not be a random occurrence but perhaps has roots due to historical bias. As a result, the GANs' outputs, presenting more male surgeons, may reflect past imbalances in gender demographics within medical education and practice. The reason GANs might produce more male surgeons when prompted to create a 'surgeon' image ties back to their foundational reliance on training data. These systems learn from vast datasets of images, and if the majority of 'surgeon' images in their training data are of men, the GANs will learn the bias that a 'typical' surgeon appears as a male. This learning process lacks an innate moral compass, so it mirrors and perpetuates existing biases in data. For instance, if in the past few decades, 80% of surgeons were male, the dataset will likely contain more images of male surgeons, teaching the GANs that 'surgeon' equates more often to a male figure. This problem underscores the importance of curating diverse and balanced training datasets and continuously updating them to reflect current realities and aspirations for equality. It also highlights the need for interventions in the training of these AI models, such as introducing algorithms to detect and mitigate bias or employing fairness criteria, ensuring that the outputs do not continue historical biases but instead represent a more equitable vision of society. The consequences of such biases are multiple.14 Misrepresentation in AI outputs can reinforce stereotypes, skew perceptions, delay promotions, lead to poorer evaluations, and even influence decision-making processes in real-world clinical settings.15, 16 For instance, if an AI system associates surgical expertise with a specific gender or ethnicity, it may inadvertently influence hiring decisions or patient trust. These biases can erode trust in healthcare systems, as patients may develop preferences for certain surgeons based on AI-generated information, which can affect a surgeon's reputation and career development. For decades, certain professions, including surgery, have been associated predominantly with specific genders or backgrounds.17, 18 Age bias can skew representation of certain age groups, whilst body silhouette bias can perpetuate detrimental beauty standards. In this study, Midjourney mainly demonstrated surgeons as older individuals with narrower body silhouettes. DALL-E2 demonstrated less bias in its depictions than Midjourney but such bias was also present. Bias can manifest at various stages of AI model development, often stemming from their training data which might reflect real-world prejudices and inadvertently perpetuate these notions in its outputs.19 For example, an AI image generator's dataset predominantly comprising lighter-skinned individuals might underrepresent darker skin tones. Understanding biases in AI is essential. AI GANs and LLMs are trained on pre-existing online data. If this data underrepresents a certain demographic, the output will likely be skewed.20-24 Despite using unbiased algorithms, research shows gender biases persist.25, 26 Another concern is 'Programmer Bias', where non-representative developer demographics might introduce biases into software.27 The 'Black Box' issue further complicates matters, as AI algorithms' inner workings are often hard to interpret.20, 28 Some AI tools lack real-time internet connectivity, risking outdated references and potential reporting bias, especially in fields like healthcare. Machine biases often echoes their human developers'. However, without clear datasets information, current AI findings are mostly speculative based on observed outputs. Several strategies can help address these biases. Firstly, using diverse and representative sample data, incorporating images and descriptions of surgeons from various genders, ethnicities, and backgrounds ensures a holistic view of the profession.29, 30 Another strategy is adopting a continuous feedback loop, allowing users and experts to flag potential biases and identify nuances that might have been overlooked during the model's development phase. Moreover, incorporating expert reviews can provide a depth of analysis that general feedback might not capture.29 Iterative model improvements are crucial. In the fast-evolving world of AI, a model that remains static is one that will inevitably become obsolete or problematic. By incorporating feedback and continuously refining the model, developers ensure that the AI system remains relevant, accurate, and free from perpetuating harmful stereotypes. In addition to these strategies, transparency in model development, methodologies, and data sources can also foster trust.29 When users understand the mechanisms behind the AI outputs, they can engage more critically and constructively, further enhancing the model's credibility and performance. The primary constraint of this study stems from its dependence on a limited group of plastic surgery residents and plastic surgeons to assess the biases inherent in the GANs. This narrow scope may impede the broader applicability of the findings, potentially infusing the results with subjectivity and individual biases. However, this research represents, to the authors' understanding, an initial endeavour in exploring the biased representations of different surgical specialties within GAN outputs. Subsequent studies would benefit from extending this scrutiny to biases present in other AI systems, thereby offering a more holistic understanding of these pervasive limitations. This study sheds light on the biases present in some of the latest popular AI models. As AI models continue to permeate the medical field, it becomes imperative to assess these biases rigorously. Only through collective and informed action can we ensure that AI serves as an equitable, effective, and reliable resource in advancing global healthcare. The broader scientific community should engage in ongoing discourse on defining acceptable bias thresholds and establishing standardized bias evaluation metrics. Open access publishing facilitated by Monash University, as part of the Wiley - Monash University agreement via the Council of Australian University Librarians. Jevan Cevik: Conceptualization; writing \u2013 original draft; writing \u2013 review and editing. Bryan Lim: Conceptualization; writing \u2013 original draft; writing \u2013 review and editing. Ishith Seth: Conceptualization; writing \u2013 original draft; writing \u2013 review and editing. Foti Sofiadellis: Conceptualization; supervision. Richard J. Ross: Conceptualization; supervision. Roberto Cuomo: Supervision. Warren M. Rozen: Conceptualization; supervision.",
    "doi": "10.1111/ans.18792",
    "url": "https://openalex.org/W4389681782",
    "pdf_url": "https://doi.org/10.1111/ans.18792",
    "venue": "ANZ Journal of Surgery",
    "citation_count": 29,
    "fields_of_study": [
      "Perception",
      "Generative grammar",
      "Artificial intelligence",
      "Demographics",
      "Psychology"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768739"
  },
  {
    "source": "openalex",
    "source_id": "W3041968715",
    "title": "Decolonial AI: Decolonial Theory as Sociotechnical Foresight in Artificial Intelligence",
    "authors": [
      "Shakir Mohamed",
      "Marie-Th\u00e9r\u00e8se Png",
      "William Isaac"
    ],
    "year": 2020,
    "abstract": null,
    "doi": "10.1007/s13347-020-00405-8",
    "url": "https://openalex.org/W3041968715",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s13347-020-00405-8.pdf",
    "venue": "Philosophy & Technology",
    "citation_count": 589,
    "fields_of_study": [
      "Futures studies",
      "Philosophy of technology",
      "Sociotechnical system",
      "Sociology",
      "Politics"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768907"
  },
  {
    "source": "openalex",
    "source_id": "W2099531439",
    "title": "How Technology Is Changing Work and Organizations",
    "authors": [
      "Wayne F. Cascio",
      "Ramiro Montealegre"
    ],
    "year": 2016,
    "abstract": "Given the rapid advances and the increased reliance on technology, the question of how it is changing work and employment is highly salient for scholars of organizational psychology and organizational behavior (OP/OB). This article attempts to interpret the progress, direction, and purpose of current research on the effects of technology on work and organizations. After a review of key breakthroughs in the evolution of technology, we consider the disruptive effects of emerging information and communication technologies. We then examine numbers and types of jobs affected by developments in technology, and how this will lead to significant worker dislocation. To illustrate technology's impact on work, work systems, and organizations, we present four popular technologies: electronic monitoring systems, robots, teleconferencing, and wearable computing devices. To provide insights regarding what we know about the effects of technology for OP/OB scholars, we consider the results of research conducted from four different perspectives on the role of technology in management. We also examine how that role is changing in the emerging world of technology. We conclude by considering approaches to six human resources (HR) areas supported by traditional and emerging technologies, identifying related research questions that should have profound implications both for research and for practice, and providing guidance for future research.",
    "doi": "10.1146/annurev-orgpsych-041015-062352",
    "url": "https://openalex.org/W2099531439",
    "pdf_url": "https://www.annualreviews.org/doi/pdf/10.1146/annurev-orgpsych-041015-062352",
    "venue": "Annual Review of Organizational Psychology and Organizational Behavior",
    "citation_count": 1030,
    "fields_of_study": [
      "Salient",
      "Work (physics)",
      "Emerging technologies",
      "Knowledge management",
      "Information technology"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768910"
  },
  {
    "source": "openalex",
    "source_id": "W4380685454",
    "title": "Re-Thinking Data Strategy and Integration for Artificial Intelligence: Concepts, Opportunities, and Challenges",
    "authors": [
      "Abdulaziz Aldoseri",
      "Khalifa N. Al\u2010Khalifa",
      "A.M.S. Hamouda"
    ],
    "year": 2023,
    "abstract": "The use of artificial intelligence (AI) is becoming more prevalent across industries such as healthcare, finance, and transportation. Artificial intelligence is based on the analysis of large datasets and requires a continuous supply of high-quality data. However, using data for AI is not without challenges. This paper comprehensively reviews and critically examines the challenges of using data for AI, including data quality, data volume, privacy and security, bias and fairness, interpretability and explainability, ethical concerns, and technical expertise and skills. This paper examines these challenges in detail and offers recommendations on how companies and organizations can address them. By understanding and addressing these challenges, organizations can harness the power of AI to make smarter decisions and gain competitive advantage in the digital age. It is expected, since this review article provides and discusses various strategies for data challenges for AI over the last decade, that it will be very helpful to the scientific research community to create new and novel ideas to rethink our approaches to data strategies for AI.",
    "doi": "10.3390/app13127082",
    "url": "https://openalex.org/W4380685454",
    "pdf_url": "https://www.mdpi.com/2076-3417/13/12/7082/pdf?version=1686659661",
    "venue": "Applied Sciences",
    "citation_count": 522,
    "fields_of_study": [
      "Interpretability",
      "Big data",
      "Computer science",
      "Quality (philosophy)",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768929"
  },
  {
    "source": "openalex",
    "source_id": "W4393353064",
    "title": "The Role of AI in Hospitals and Clinics: Transforming Healthcare in the 21st Century",
    "authors": [
      "Shiva Maleki Varnosfaderani",
      "Mohamad Forouzanfar"
    ],
    "year": 2024,
    "abstract": "As healthcare systems around the world face challenges such as escalating costs, limited access, and growing demand for personalized care, artificial intelligence (AI) is emerging as a key force for transformation. This review is motivated by the urgent need to harness AI\u2019s potential to mitigate these issues and aims to critically assess AI\u2019s integration in different healthcare domains. We explore how AI empowers clinical decision-making, optimizes hospital operation and management, refines medical image analysis, and revolutionizes patient care and monitoring through AI-powered wearables. Through several case studies, we review how AI has transformed specific healthcare domains and discuss the remaining challenges and possible solutions. Additionally, we will discuss methodologies for assessing AI healthcare solutions, ethical challenges of AI deployment, and the importance of data privacy and bias mitigation for responsible technology use. By presenting a critical assessment of AI\u2019s transformative potential, this review equips researchers with a deeper understanding of AI\u2019s current and future impact on healthcare. It encourages an interdisciplinary dialogue between researchers, clinicians, and technologists to navigate the complexities of AI implementation, fostering the development of AI-driven solutions that prioritize ethical standards, equity, and a patient-centered approach.",
    "doi": "10.3390/bioengineering11040337",
    "url": "https://openalex.org/W4393353064",
    "pdf_url": "https://www.mdpi.com/2306-5354/11/4/337/pdf?version=1711712822",
    "venue": "Bioengineering",
    "citation_count": 607,
    "fields_of_study": [
      "Health care",
      "Medicine",
      "Computer science",
      "Political science",
      "Law"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768945"
  },
  {
    "source": "openalex",
    "source_id": "W4362581834",
    "title": "Revolutionizing education with AI: Exploring the transformative potential of ChatGPT",
    "authors": [
      "Tufan Ad\u0131g\u00fczel",
      "Mehmet Haldun Kaya",
      "Fatih K\u00fcr\u015fat Cansu"
    ],
    "year": 2023,
    "abstract": "Artificial intelligence (AI) introduces new tools to the educational environment with the potential to transform conventional teaching and learning processes. This study offers a comprehensive overview of AI technologies, their potential applications in education, and the difficulties involved. Chatbots and related algorithms that can simulate human interactions and generate human-like text based on input from natural language are discussed. In addition to the advantages of cutting-edge chatbots like ChatGPT, their use in education raises important ethical and practical challenges. The authors aim to provide insightful information on how AI may be successfully incorporated into the educational setting to benefit teachers and students, while promoting responsible and ethical use.",
    "doi": "10.30935/cedtech/13152",
    "url": "https://openalex.org/W4362581834",
    "pdf_url": "https://www.cedtech.net/download/revolutionizing-education-with-ai-exploring-the-transformative-potential-of-chatgpt-13152.pdf",
    "venue": "Contemporary Educational Technology",
    "citation_count": 755,
    "fields_of_study": [
      "Transformative learning",
      "Computer science",
      "Artificial intelligence",
      "Psychology",
      "Pedagogy"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768962"
  },
  {
    "source": "openalex",
    "source_id": "W3090117266",
    "title": "Trustworthy artificial intelligence",
    "authors": [
      "Scott Thiebes",
      "Sebastian Lins",
      "Ali Sunyaev"
    ],
    "year": 2020,
    "abstract": null,
    "doi": "10.1007/s12525-020-00441-4",
    "url": "https://openalex.org/W3090117266",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s12525-020-00441-4.pdf",
    "venue": "Electronic Markets",
    "citation_count": 505,
    "fields_of_study": [
      "Beneficence",
      "Variety (cybernetics)",
      "Autonomy",
      "Software deployment",
      "Economic Justice"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768977"
  },
  {
    "source": "openalex",
    "source_id": "W4386098991",
    "title": "Challenges and Opportunities of Generative AI for Higher Education as Explained by ChatGPT",
    "authors": [
      "Rosario Michel\u2010Villarreal",
      "Eliseo Luis Vilalta-perdomo",
      "David Ernesto Salinas-Navarro",
      "Ricardo Thierry-Aguilera",
      "Flor Silvestre Gerardou"
    ],
    "year": 2023,
    "abstract": "ChatGPT is revolutionizing the field of higher education by leveraging deep learning models to generate human-like content. However, its integration into academic settings raises concerns regarding academic integrity, plagiarism detection, and the potential impact on critical thinking skills. This article presents a study that adopts a thing ethnography approach to understand ChatGPT\u2019s perspective on the challenges and opportunities it represents for higher education. The research explores the potential benefits and limitations of ChatGPT, as well as mitigation strategies for addressing the identified challenges. Findings emphasize the urgent need for clear policies, guidelines, and frameworks to responsibly integrate ChatGPT in higher education. It also highlights the need for empirical research to understand user experiences and perceptions. The findings provide insights that can guide future research efforts in understanding the implications of ChatGPT and similar Artificial Intelligence (AI) systems in higher education. The study concludes by highlighting the importance of thing ethnography as an innovative approach for engaging with intelligent AI systems and calls for further research to explore best practices and strategies in utilizing Generative AI for educational purposes.",
    "doi": "10.3390/educsci13090856",
    "url": "https://openalex.org/W4386098991",
    "pdf_url": "https://www.mdpi.com/2227-7102/13/9/856/pdf?version=1692771591",
    "venue": "Education Sciences",
    "citation_count": 633,
    "fields_of_study": [
      "Generative grammar",
      "Engineering ethics",
      "Perspective (graphical)",
      "Higher education",
      "Field (mathematics)"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768980"
  },
  {
    "source": "openalex",
    "source_id": "W4385632485",
    "title": "Practical and ethical challenges of large language models in education: A systematic scoping review",
    "authors": [
      "Lixiang Yan",
      "Lele Sha",
      "Linxuan Zhao",
      "Yuheng Li",
      "Roberto Mart\u00ednez\u2010Maldonado",
      "Guanliang Chen",
      "Xinyu Li",
      "Yueqiao Jin",
      "Dragan Ga\u0161evi\u0107"
    ],
    "year": 2023,
    "abstract": "Abstract Educational technology innovations leveraging large language models (LLMs) have shown the potential to automate the laborious process of generating and analysing textual content. While various innovations have been developed to automate a range of educational tasks (eg, question generation, feedback provision, and essay grading), there are concerns regarding the practicality and ethicality of these innovations. Such concerns may hinder future research and the adoption of LLMs\u2010based innovations in authentic educational contexts. To address this, we conducted a systematic scoping review of 118 peer\u2010reviewed papers published since 2017 to pinpoint the current state of research on using LLMs to automate and support educational tasks. The findings revealed 53 use cases for LLMs in automating education tasks, categorised into nine main categories: profiling/labelling, detection, grading, teaching support, prediction, knowledge representation, feedback, content generation, and recommendation. Additionally, we also identified several practical and ethical challenges, including low technological readiness, lack of replicability and transparency and insufficient privacy and beneficence considerations. The findings were summarised into three recommendations for future studies, including updating existing innovations with state\u2010of\u2010the\u2010art models (eg, GPT\u20103/4), embracing the initiative of open\u2010sourcing models/systems, and adopting a human\u2010centred approach throughout the developmental process. As the intersection of AI and education is continuously evolving, the findings of this study can serve as an essential reference point for researchers, allowing them to leverage the strengths, learn from the limitations, and uncover potential research opportunities enabled by ChatGPT and other generative AI models. Practitioner notes What is currently known about this topic Generating and analysing text\u2010based content are time\u2010consuming and laborious tasks. Large language models are capable of efficiently analysing an unprecedented amount of textual content and completing complex natural language processing and generation tasks. Large language models have been increasingly used to develop educational technologies that aim to automate the generation and analysis of textual content, such as automated question generation and essay scoring. What this paper adds A comprehensive list of different educational tasks that could potentially benefit from LLMs\u2010based innovations through automation. A structured assessment of the practicality and ethicality of existing LLMs\u2010based innovations from seven important aspects using established frameworks. Three recommendations that could potentially support future studies to develop LLMs\u2010based innovations that are practical and ethical to implement in authentic educational contexts. Implications for practice and/or policy Updating existing innovations with state\u2010of\u2010the\u2010art models may further reduce the amount of manual effort required for adapting existing models to different educational tasks. The reporting standards of empirical research that aims to develop educational technologies using large language models need to be improved. Adopting a human\u2010centred approach throughout the developmental process could contribute to resolving the practical and ethical challenges of large language models in education.",
    "doi": "10.1111/bjet.13370",
    "url": "https://openalex.org/W4385632485",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/bjet.13370",
    "venue": "British Journal of Educational Technology",
    "citation_count": 523,
    "fields_of_study": [
      "Computer science",
      "Grading (engineering)",
      "Systematic review",
      "Engineering ethics",
      "Knowledge management"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769002"
  },
  {
    "source": "openalex",
    "source_id": "W3131457744",
    "title": "What do we want from Explainable Artificial Intelligence (XAI)? \u2013 A stakeholder perspective on XAI and a conceptual model guiding interdisciplinary XAI research",
    "authors": [
      "Markus Langer",
      "Daniel Oster",
      "Timo Speith",
      "Holger Hermanns",
      "Lena K\u00e4stner",
      "Eva Schmidt",
      "Andreas Sesing-Wagenpfeil",
      "Kevin Baum"
    ],
    "year": 2021,
    "abstract": null,
    "doi": "10.1016/j.artint.2021.103473",
    "url": "https://openalex.org/W3131457744",
    "pdf_url": "https://www.sciencedirect.com/science/article/pii/S0004370221000242",
    "venue": "Artificial Intelligence",
    "citation_count": 524,
    "fields_of_study": [
      "Perspective (graphical)",
      "Stakeholder",
      "Knowledge management",
      "Management science",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769043"
  },
  {
    "source": "openalex",
    "source_id": "W4381982883",
    "title": "ChatGPT for Education and Research: Opportunities, Threats, and Strategies",
    "authors": [
      "Md. Mostafizer Rahman",
      "Yutaka Watanobe"
    ],
    "year": 2023,
    "abstract": "In recent years, the rise of advanced artificial intelligence technologies has had a profound impact on many fields, including education and research. One such technology is ChatGPT, a powerful large language model developed by OpenAI. This technology offers exciting opportunities for students and educators, including personalized feedback, increased accessibility, interactive conversations, lesson preparation, evaluation, and new ways to teach complex concepts. However, ChatGPT poses different threats to the traditional education and research system, including the possibility of cheating on online exams, human-like text generation, diminished critical thinking skills, and difficulties in evaluating information generated by ChatGPT. This study explores the potential opportunities and threats that ChatGPT poses to overall education from the perspective of students and educators. Furthermore, for programming learning, we explore how ChatGPT helps students improve their programming skills. To demonstrate this, we conducted different coding-related experiments with ChatGPT, including code generation from problem descriptions, pseudocode generation of algorithms from texts, and code correction. The generated codes are validated with an online judge system to evaluate their accuracy. In addition, we conducted several surveys with students and teachers to find out how ChatGPT supports programming learning and teaching. Finally, we present the survey results and analysis.",
    "doi": "10.3390/app13095783",
    "url": "https://openalex.org/W4381982883",
    "pdf_url": "https://www.mdpi.com/2076-3417/13/9/5783/pdf?version=1683532719",
    "venue": "Applied Sciences",
    "citation_count": 820,
    "fields_of_study": [
      "Cheating",
      "Computer science",
      "Coding (social sciences)",
      "Perspective (graphical)",
      "Mathematics education"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769045"
  },
  {
    "source": "openalex",
    "source_id": "W3172362366",
    "title": "Current Challenges and Future Opportunities for XAI in Machine Learning-Based Clinical Decision Support Systems: A Systematic Review",
    "authors": [
      "Anna Markella Antoniadi",
      "Yuhan Du",
      "Yasmine Guendouz",
      "Lan Wei",
      "Claudia Mazo",
      "Brett A. Becker",
      "Catherine Mooney"
    ],
    "year": 2021,
    "abstract": "Machine Learning and Artificial Intelligence (AI) more broadly have great immediate and future potential for transforming almost all aspects of medicine. However, in many applications, even outside medicine, a lack of transparency in AI applications has become increasingly problematic. This is particularly pronounced where users need to interpret the output of AI systems. Explainable AI (XAI) provides a rationale that allows users to understand why a system has produced a given output. The output can then be interpreted within a given context. One area that is in great need of XAI is that of Clinical Decision Support Systems (CDSSs). These systems support medical practitioners in their clinic decision-making and in the absence of explainability may lead to issues of under or over-reliance. Providing explanations for how recommendations are arrived at will allow practitioners to make more nuanced, and in some cases, life-saving decisions. The need for XAI in CDSS, and the medical field in general, is amplified by the need for ethical and fair decision-making and the fact that AI trained with historical data can be a reinforcement agent of historical actions and biases that should be uncovered. We performed a systematic literature review of work to-date in the application of XAI in CDSS. Tabular data processing XAI-enabled systems are the most common, while XAI-enabled CDSS for text analysis are the least common in literature. There is more interest in developers for the provision of local explanations, while there was almost a balance between post-hoc and ante-hoc explanations, as well as between model-specific and model-agnostic techniques. Studies reported benefits of the use of XAI such as the fact that it could enhance decision confidence for clinicians, or generate the hypothesis about causality, which ultimately leads to increased trustworthiness and acceptability of the system and potential for its incorporation in the clinical workflow. However, we found an overall distinct lack of application of XAI in the context of CDSS and, in particular, a lack of user studies exploring the needs of clinicians. We propose some guidelines for the implementation of XAI in CDSS and explore some opportunities, challenges, and future research needs.",
    "doi": "10.3390/app11115088",
    "url": "https://openalex.org/W3172362366",
    "pdf_url": "https://www.mdpi.com/2076-3417/11/11/5088/pdf?version=1622439587",
    "venue": "Applied Sciences",
    "citation_count": 525,
    "fields_of_study": [
      "Transparency (behavior)",
      "Computer science",
      "Context (archaeology)",
      "Clinical decision support system",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769064"
  },
  {
    "source": "openalex",
    "source_id": "W4381716616",
    "title": "Bias in artificial intelligence algorithms and recommendations for mitigation",
    "authors": [
      "Lama Nazer",
      "Razan Zatarah",
      "Shai Waldrip",
      "Janny Xue Chen Ke",
      "Mira Moukheiber",
      "Ashish K. Khanna",
      "Rachel Hicklen",
      "Lama Moukheiber",
      "Dana Moukheiber",
      "Haobo Ma",
      "Piyush Mathur"
    ],
    "year": 2023,
    "abstract": "The adoption of artificial intelligence (AI) algorithms is rapidly increasing in healthcare. Such algorithms may be shaped by various factors such as social determinants of health that can influence health outcomes. While AI algorithms have been proposed as a tool to expand the reach of quality healthcare to underserved communities and improve health equity, recent literature has raised concerns about the propagation of biases and healthcare disparities through implementation of these algorithms. Thus, it is critical to understand the sources of bias inherent in AI-based algorithms. This review aims to highlight the potential sources of bias within each step of developing AI algorithms in healthcare, starting from framing the problem, data collection, preprocessing, development, and validation, as well as their full implementation. For each of these steps, we also discuss strategies to mitigate the bias and disparities. A checklist was developed with recommendations for reducing bias during the development and implementation stages. It is important for developers and users of AI-based algorithms to keep these important considerations in mind to advance health equity for all populations.",
    "doi": "10.1371/journal.pdig.0000278",
    "url": "https://openalex.org/W4381716616",
    "pdf_url": "https://journals.plos.org/digitalhealth/article/file?id=10.1371/journal.pdig.0000278&type=printable",
    "venue": "PLOS Digital Health",
    "citation_count": 468,
    "fields_of_study": [
      "Health care",
      "Computer science",
      "Preprocessor",
      "Artificial intelligence",
      "Data science"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769101"
  },
  {
    "source": "openalex",
    "source_id": "W4221045317",
    "title": "Towards a standard for identifying and managing bias in artificial intelligence",
    "authors": [
      "Reva Schwartz",
      "Apostol Vassilev",
      "Kristen Greene",
      "Lori Perine",
      "Andrew Burt",
      "Patrick Hall"
    ],
    "year": 2022,
    "abstract": "As individuals and communities interact in and with an environment that is increasingly virtual they are often vulnerable to the commodification of their digital exhaust. Concepts and behavior that are ambiguous in nature are captured in this environment, quantified, and used to categorize, sort, recommend, or make decisions about people's lives. While many organizations seek to utilize this information in a responsible manner, biases remain endemic across technology processes and can lead to harmful impacts regardless of intent. These harmful outcomes, even if inadvertent, create significant challenges for cultivating public trust in artificial intelligence (AI). SP 1270 is a NIST Artificial Intelligence publication and should be read in conjunction with all publications in the NIST AI Series, which was established in January 2023.",
    "doi": "10.6028/nist.sp.1270",
    "url": "https://openalex.org/W4221045317",
    "pdf_url": "https://doi.org/10.6028/nist.sp.1270",
    "venue": null,
    "citation_count": 455,
    "fields_of_study": [
      "Categorization",
      "NIST",
      "sort",
      "Computer science",
      "Data science"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769121"
  },
  {
    "source": "openalex",
    "source_id": "W4385484319",
    "title": "A multilevel review of artificial intelligence in organizations: Implications for organizational behavior research and practice",
    "authors": [
      "Sarah Bankins",
      "Anna Carmella Ocampo",
      "Mauricio Marrone",
      "Simon Lloyd D. Restubog",
      "Sang Eun Woo"
    ],
    "year": 2023,
    "abstract": "Summary The rising use of artificially intelligent (AI) technologies, including generative AI tools, in organizations is undeniable. As these systems become increasingly integrated into organizational practices and processes, understanding their impact on workers' experiences and job designs is critical. However, the ongoing discourse surrounding AI use in the workplace remains divided. Proponents of the technology extol its benefits for enhancing efficiency and productivity, while others voice concerns about the potential harm to human workers. To provide greater clarity on this pressing issue, this article presents a systematic review of empirical research that sheds light on the implications of AI use at work. Organized under five inductively generated themes within a multilevel framework, we uncover individual, group, and organizational factors that shape the interplay between humans and AI. Specifically, the themes are: (1) human\u2013AI collaboration; (2) perceptions of algorithmic and human capabilities; (3) worker attitudes towards AI; (4) AI as a control mechanism in algorithmic management of platform\u2010based work; and (5) labor market implications of AI use. Our review offers insights into these themes and identifies five pathways for future research. Finally, we provide practical recommendations for organizational leaders seeking to implement AI technologies while prioritizing their employees' well\u2010being.",
    "doi": "10.1002/job.2735",
    "url": "https://openalex.org/W4385484319",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/job.2735",
    "venue": "Journal of Organizational Behavior",
    "citation_count": 391,
    "fields_of_study": [
      "CLARITY",
      "Knowledge management",
      "Generative grammar",
      "Harm",
      "Perception"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769134"
  },
  {
    "source": "openalex",
    "source_id": "W3104128335",
    "title": "Challenges in Deploying Machine Learning: A Survey of Case Studies",
    "authors": [
      "Andrei Paleyes",
      "Raoul-Gabriel Urma",
      "Neil D. Lawrence"
    ],
    "year": 2022,
    "abstract": "In recent years, machine learning has transitioned from a field of academic research interest to a field capable of solving real-world business problems. However, the deployment of machine learning models in production systems can present a number of issues and concerns. This survey reviews published reports of deploying machine learning solutions in a variety of use cases, industries, and applications and extracts practical considerations corresponding to stages of the machine learning deployment workflow. By mapping found challenges to the steps of the machine learning deployment workflow, we show that practitioners face issues at each stage of the deployment process. The goal of this article is to lay out a research agenda to explore approaches addressing these challenges.",
    "doi": "10.1145/3533378",
    "url": "https://openalex.org/W3104128335",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3533378",
    "venue": "ACM Computing Surveys",
    "citation_count": 487,
    "fields_of_study": [
      "Software deployment",
      "Workflow",
      "Computer science",
      "Artificial intelligence",
      "Machine learning"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769153"
  },
  {
    "source": "openalex",
    "source_id": "W4383959108",
    "title": "The dark side of generative artificial intelligence: A critical analysis of controversies and risks of ChatGPT",
    "authors": [
      "Krzysztof Wach",
      "Cong Doanh Duong",
      "Joanna Ejdys",
      "R\u016bta Kazlauskait\u0117",
      "Pawe\u0142 Korzy\u0144ski",
      "Grzegorz Mazurek",
      "Joanna Paliszkiewicz",
      "Ewa Ziemba"
    ],
    "year": 2023,
    "abstract": "Objective: The objective of the article is to provide a comprehensive identification and understanding of the challenges and opportunities associated with the use of generative artificial intelligence (GAI) in business. This study sought to develop a conceptual framework that gathers the negative aspects of GAI development in management and economics, with a focus on ChatGPT. Research Design & Methods: The study employed a narrative and critical literature review and developed a conceptual framework based on prior literature. We used a line of deductive reasoning in formulating our theoretical framework to make the study's overall structure rational and productive. Therefore, this article should be viewed as a conceptual article that highlights the controversies and threats of GAI in management and economics, with ChatGPT as a case study. Findings: Based on the conducted deep and extensive query of academic literature on the subject as well as professional press and Internet portals, we identified various controversies, threats, defects, and disadvantages of GAI, in particular ChatGPT. Next, we grouped the identified threats into clusters to summarize the seven main threats we see. In our opinion they are as follows: (i) no regulation of the AI market and urgent need for regulation, (ii) poor quality, lack of quality control, disinformation, deepfake content, algorithmic bias, (iii) automation-spurred job losses, (iv) personal data violation, social surveillance, and privacy violation, (v) social manipulation, weakening ethics and goodwill, (vi) widening socio-economic inequalities, and (vii) AI technostress. Implications & Recommendations: It is important to regulate the AI/GAI market. Advocating for the regulation of the AI market is crucial to ensure a level playing field, promote fair competition, protect intellectual property rights and privacy, and prevent potential geopolitical risks. The changing job market requires workers to continuously acquire new (digital) skills through education and retraining. As the training of AI systems becomes a prominent job category, it is important to adapt and take advantage of new opportunities. To mitigate the risks related to personal data violation, social surveillance, and privacy violation, GAI developers must prioritize ethical considerations and work to develop systems that prioritize user privacy and security. To avoid social manipulation and weaken ethics and goodwill, it is important to implement responsible AI practices and ethical guidelines: transparency in data usage, bias mitigation techniques, and monitoring of generated content for harmful or misleading information. Contribution & Value Added: This article may aid in bringing attention to the significance of resolving the ethical and legal considerations that arise from the use of GAI and ChatGPT by drawing attention to the controversies and hazards associated with these technologies.",
    "doi": "10.15678/eber.2023.110201",
    "url": "https://openalex.org/W4383959108",
    "pdf_url": "https://eber.uek.krakow.pl/index.php/eber/article/view/2113/852",
    "venue": "Entrepreneurial Business and Economics Review",
    "citation_count": 438,
    "fields_of_study": [
      "Great Rift",
      "Generative grammar",
      "Psychology",
      "Artificial intelligence",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769165"
  },
  {
    "source": "openalex",
    "source_id": "W4385564466",
    "title": "Fairness of artificial intelligence in healthcare: review and recommendations",
    "authors": [
      "Daiju Ueda",
      "Taichi Kakinuma",
      "Shohei Fujita",
      "Koji Kamagata",
      "Yasutaka Fushimi",
      "Rintaro Ito",
      "Yusuke Matsui",
      "Taiki Nozaki",
      "Takeshi Nakaura",
      "Noriyuki Fujima",
      "Fuminari Tatsugami",
      "Masahiro Yanagawa",
      "Kenji Hirata",
      "Akira Yamada",
      "Takahiro Tsuboyama",
      "Mariko Kawamura",
      "Tomoyuki Fujioka",
      "Shinji Naganawa"
    ],
    "year": 2023,
    "abstract": "Abstract In this review, we address the issue of fairness in the clinical integration of artificial intelligence (AI) in the medical field. As the clinical adoption of deep learning algorithms, a subfield of AI, progresses, concerns have arisen regarding the impact of AI biases and discrimination on patient health. This review aims to provide a comprehensive overview of concerns associated with AI fairness; discuss strategies to mitigate AI biases; and emphasize the need for cooperation among physicians, AI researchers, AI developers, policymakers, and patients to ensure equitable AI integration. First, we define and introduce the concept of fairness in AI applications in healthcare and radiology, emphasizing the benefits and challenges of incorporating AI into clinical practice. Next, we delve into concerns regarding fairness in healthcare, addressing the various causes of biases in AI and potential concerns such as misdiagnosis, unequal access to treatment, and ethical considerations. We then outline strategies for addressing fairness, such as the importance of diverse and representative data and algorithm audits. Additionally, we discuss ethical and legal considerations such as data privacy, responsibility, accountability, transparency, and explainability in AI. Finally, we present the Fairness of Artificial Intelligence Recommendations in healthcare (FAIR) statement to offer best practices. Through these efforts, we aim to provide a foundation for discussing the responsible and equitable implementation and deployment of AI in healthcare.",
    "doi": "10.1007/s11604-023-01474-3",
    "url": "https://openalex.org/W4385564466",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s11604-023-01474-3.pdf",
    "venue": "Japanese Journal of Radiology",
    "citation_count": 430,
    "fields_of_study": [
      "Accountability",
      "Health care",
      "Transparency (behavior)",
      "Computer science",
      "Software deployment"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769204"
  },
  {
    "source": "openalex",
    "source_id": "W4233435953",
    "title": "The ARRIVE guidelines 2.0: Updated guidelines for reporting animal research",
    "authors": [
      "Nathalie Percie du Sert",
      "Viki Hurst",
      "Amrita Ahluwalia",
      "Sabina Alam",
      "Marc T. Avey",
      "Monya Baker",
      "William J. Browne",
      "Alejandra Clark",
      "Innes C. Cuthill",
      "Ulrich Dirnagl",
      "Michael Emerson",
      "Paul Garner",
      "Stephen T. Holgate",
      "David W. Howells",
      "Natasha A. Karp",
      "Stanley E. Lazic",
      "Katie Lidster",
      "Catriona MacCallum",
      "Malcolm Macleod",
      "Esther J. Pearl",
      "Ole H. Petersen",
      "Frances Rawle",
      "Penny S. Reynolds",
      "Kieron Rooney",
      "Emily S. Sena",
      "Shai D. Silberberg",
      "Thomas Steckler",
      "Hanno W\u00fcrbel"
    ],
    "year": 2020,
    "abstract": "Reproducible science requires transparent reporting. The ARRIVE guidelines (Animal Research: Reporting of In Vivo Experiments) were originally developed in 2010 to improve the reporting of animal research. They consist of a checklist of information to include in publications describing in vivo experiments to enable others to scrutinise the work adequately, evaluate its methodological rigour, and reproduce the methods and results. Despite considerable levels of endorsement by funders and journals over the years, adherence to the guidelines has been inconsistent, and the anticipated improvements in the quality of reporting in animal research publications have not been achieved. Here, we introduce ARRIVE 2.0. The guidelines have been updated and information reorganised to facilitate their use in practice. We used a Delphi exercise to prioritise and divide the items of the guidelines into 2 sets, the \u201cARRIVE Essential 10,\u201d which constitutes the minimum requirement, and the \u201cRecommended Set,\u201d which describes the research context. This division facilitates improved reporting of animal research by supporting a stepwise approach to implementation. This helps journal editors and reviewers verify that the most important items are being reported in manuscripts. We have also developed the accompanying Explanation and Elaboration (E&amp;E) document, which serves (1) to explain the rationale behind each item in the guidelines, (2) to clarify key concepts, and (3) to provide illustrative examples. We aim, through these changes, to help ensure that researchers, reviewers, and journal editors are better equipped to improve the rigour and transparency of the scientific process and thus reproducibility.",
    "doi": "10.1111/bph.15193",
    "url": "https://openalex.org/W4233435953",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/bph.15193",
    "venue": "British Journal of Pharmacology",
    "citation_count": 884,
    "fields_of_study": [
      "Rigour",
      "Checklist",
      "Context (archaeology)",
      "Transparency (behavior)",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769225"
  },
  {
    "source": "openalex",
    "source_id": "W4223430324",
    "title": "Machine learning for medical imaging: methodological failures and recommendations for the future",
    "authors": [
      "Ga\u00ebl Varoquaux",
      "Veronika Cheplygina"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1038/s41746-022-00592-y",
    "url": "https://openalex.org/W4223430324",
    "pdf_url": "https://www.nature.com/articles/s41746-022-00592-y.pdf",
    "venue": "npj Digital Medicine",
    "citation_count": 524,
    "fields_of_study": [
      "Medical imaging",
      "Psychology",
      "Computer science",
      "Data science",
      "Engineering ethics"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769248"
  },
  {
    "source": "openalex",
    "source_id": "W2786242872",
    "title": "Fairness and Accountability Design Needs for Algorithmic Support in High-Stakes Public Sector Decision-Making",
    "authors": [
      "Michael Veale",
      "Max Van Kleek",
      "Reuben Binns"
    ],
    "year": 2018,
    "abstract": "Calls for heightened consideration of fairness and accountability in\\nalgorithmically-informed public decisions---like taxation, justice, and child\\nprotection---are now commonplace. How might designers support such human\\nvalues? We interviewed 27 public sector machine learning practitioners across 5\\nOECD countries regarding challenges understanding and imbuing public values\\ninto their work. The results suggest a disconnect between organisational and\\ninstitutional realities, constraints and needs, and those addressed by current\\nresearch into usable, transparent and 'discrimination-aware' machine\\nlearning---absences likely to undermine practical initiatives unless addressed.\\nWe see design opportunities in this disconnect, such as in supporting the\\ntracking of concept drift in secondary data sources, and in building usable\\ntransparency tools to identify risks and incorporate domain knowledge, aimed\\nboth at managers and at the 'street-level bureaucrats' on the frontlines of\\npublic service. We conclude by outlining ethical challenges and future\\ndirections for collaboration in these high-stakes applications.\\n",
    "doi": "10.1145/3173574.3174014",
    "url": "https://openalex.org/W2786242872",
    "pdf_url": "http://dl.acm.org/ft_gateway.cfm?id=3174014&type=pdf",
    "venue": null,
    "citation_count": 418,
    "fields_of_study": [
      "Accountability",
      "USable",
      "Transparency (behavior)",
      "Public sector",
      "Public relations"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769251"
  },
  {
    "source": "openalex",
    "source_id": "W4392773210",
    "title": "Embracing the future of Artificial Intelligence in the classroom: the relevance of AI literacy, prompt engineering, and critical thinking in modern education",
    "authors": [
      "Yoshija Walter"
    ],
    "year": 2024,
    "abstract": "Abstract The present discussion examines the transformative impact of Artificial Intelligence (AI) in educational settings, focusing on the necessity for AI literacy, prompt engineering proficiency, and enhanced critical thinking skills. The introduction of AI into education marks a significant departure from conventional teaching methods, offering personalized learning and support for diverse educational requirements, including students with special needs. However, this integration presents challenges, including the need for comprehensive educator training and curriculum adaptation to align with societal structures. AI literacy is identified as crucial, encompassing an understanding of AI technologies and their broader societal impacts. Prompt engineering is highlighted as a key skill for eliciting specific responses from AI systems, thereby enriching educational experiences and promoting critical thinking. There is detailed analysis of strategies for embedding these skills within educational curricula and pedagogical practices. This is discussed through a case-study based on a Swiss university and a narrative literature review, followed by practical suggestions of how to implement AI in the classroom.",
    "doi": "10.1186/s41239-024-00448-3",
    "url": "https://openalex.org/W4392773210",
    "pdf_url": "https://educationaltechnologyjournal.springeropen.com/counter/pdf/10.1186/s41239-024-00448-3",
    "venue": "International Journal of Educational Technology in Higher Education",
    "citation_count": 576,
    "fields_of_study": [
      "Relevance (law)",
      "Critical thinking",
      "Literacy",
      "Higher education",
      "Mathematics education"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769264"
  },
  {
    "source": "openalex",
    "source_id": "W4386285839",
    "title": "Managing the Strategic Transformation of Higher Education through Artificial Intelligence",
    "authors": [
      "Babu George",
      "Ontario S. Wooden"
    ],
    "year": 2023,
    "abstract": "Considering the rapid advancements in artificial intelligence (AI) and their potential implications for the higher education sector, this article seeks to critically evaluate the strategic adoption of AI in the framework of \u201csmart universities\u201d. We envisage these innovative institutions as the imminent evolution in higher education, harnessing AI and quantum technologies to reshape academic and administrative processes. The core presumption is that through such integration, universities can achieve personalized learning trajectories, enhanced accessibility, economic efficiency, and a boost in overall operational performance. However, venturing into this new educational paradigm necessitates a thorough exploration of potential pitfalls, including questions surrounding educational quality, potential job losses, risks of bias, privacy breaches, and safety concerns. Our primary objective is to offer a balanced assessment to aid stakeholders in making informed strategic decisions about endorsing and advancing the smart university model. A pivotal factor in this discourse is the acceptance of qualifications from AI-enriched institutions by employers, a variable that may drastically redefine the education sector\u2019s trajectory. Within the context of a comprehensive analysis of its broader societal impact, this article also delves into the ramifications of AI-driven innovations for historically Black colleges and universities (HBCUs).",
    "doi": "10.3390/admsci13090196",
    "url": "https://openalex.org/W4386285839",
    "pdf_url": "https://www.mdpi.com/2076-3387/13/9/196/pdf?version=1693319334",
    "venue": "Administrative Sciences",
    "citation_count": 380,
    "fields_of_study": [
      "Presumption",
      "Context (archaeology)",
      "Higher education",
      "Strategic intelligence",
      "Quality (philosophy)"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769279"
  },
  {
    "source": "openalex",
    "source_id": "W4390829176",
    "title": "Balancing Privacy and Progress: A Review of Privacy Challenges, Systemic Oversight, and Patient Perceptions in AI-Driven Healthcare",
    "authors": [
      "S. Williamson",
      "Victor R. Prybutok"
    ],
    "year": 2024,
    "abstract": "Integrating Artificial Intelligence (AI) in healthcare represents a transformative shift with substantial potential for enhancing patient care. This paper critically examines this integration, confronting significant ethical, legal, and technological challenges, particularly in patient privacy, decision-making autonomy, and data integrity. A structured exploration of these issues focuses on Differential Privacy as a critical method for preserving patient confidentiality in AI-driven healthcare systems. We analyze the balance between privacy preservation and the practical utility of healthcare data, emphasizing the effectiveness of encryption, Differential Privacy, and mixed-model approaches. The paper navigates the complex ethical and legal frameworks essential for AI integration in healthcare. We comprehensively examine patient rights and the nuances of informed consent, along with the challenges of harmonizing advanced technologies like blockchain with the General Data Protection Regulation (GDPR). The issue of algorithmic bias in healthcare is also explored, underscoring the urgent need for effective bias detection and mitigation strategies to build patient trust. The evolving roles of decentralized data sharing, regulatory frameworks, and patient agency are discussed in depth. Advocating for an interdisciplinary, multi-stakeholder approach and responsive governance, the paper aims to align healthcare AI with ethical principles, prioritize patient-centered outcomes, and steer AI towards responsible and equitable enhancements in patient care.",
    "doi": "10.3390/app14020675",
    "url": "https://openalex.org/W4390829176",
    "pdf_url": "https://www.mdpi.com/2076-3417/14/2/675/pdf?version=1705396255",
    "venue": "Applied Sciences",
    "citation_count": 390,
    "fields_of_study": [
      "Health care",
      "Autonomy",
      "Confidentiality",
      "Transformative learning",
      "Information privacy"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769298"
  },
  {
    "source": "openalex",
    "source_id": "W4283170666",
    "title": "Taxonomy of Risks posed by Language Models",
    "authors": [
      "Laura Weidinger",
      "Jonathan Uesato",
      "Maribeth Rauh",
      "Conor Griffin",
      "Po-Sen Huang",
      "John Mellor",
      "Amelia Glaese",
      "Myra Cheng",
      "Borja Balle",
      "Atoosa Kasirzadeh",
      "Courtney Biles",
      "Sasha Brown",
      "Zac Kenton",
      "Will Hawkins",
      "Tom Stepleton",
      "Abeba Birhane",
      "Lisa Anne Hendricks",
      "Laura Rimell",
      "William Isaac",
      "Julia Haas",
      "Sean Legassick",
      "Geoffrey Irving",
      "Iason Gabriel"
    ],
    "year": 2022,
    "abstract": "Responsible innovation on large-scale Language Models (LMs) re- quires foresight into and in-depth understanding of the risks these models may pose. This paper develops a comprehensive taxon- omy of ethical and social risks associated with LMs. We identify twenty-one risks, drawing on expertise and literature from com- puter science, linguistics, and the social sciences. We situate these risks in our taxonomy of six risk areas: I. Discrimination, Hate speech and Exclusion, II. Information Hazards, III. Misinformation Harms, IV. Malicious Uses, V. Human-Computer Interaction Harms, and VI. Environmental and Socioeconomic harms. For risks that have already been observed in LMs, the causal mechanism leading to harm, evidence of the risk, and approaches to risk mitigation are discussed. We further describe and analyse risks that have not yet been observed but are anticipated based on assessments of other language technologies, and situate these in the same taxonomy. We underscore that it is the responsibility of organizations to engage with the mitigations we discuss throughout the paper. We close by highlighting challenges and directions for further research on risk evaluation and mitigation with the goal of ensuring that language models are developed responsibly.",
    "doi": "10.1145/3531146.3533088",
    "url": "https://openalex.org/W4283170666",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3531146.3533088",
    "venue": "2022 ACM Conference on Fairness, Accountability, and Transparency",
    "citation_count": 482,
    "fields_of_study": [
      "Misinformation",
      "Taxonomy (biology)",
      "Harm",
      "Risk analysis (engineering)",
      "Futures studies"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769322"
  },
  {
    "source": "openalex",
    "source_id": "W3101981467",
    "title": "A Survey on the Explainability of Supervised Machine Learning",
    "authors": [
      "Nadia Burkart",
      "Marco F. Huber"
    ],
    "year": 2021,
    "abstract": "Predictions obtained by, e.g., artificial neural networks have a high accuracy but humans often perceive the models as black boxes. Insights about the decision making are mostly opaque for humans. Particularly understanding the decision making in highly sensitive areas such as healthcare or finance, is of paramount importance. The decision-making behind the black boxes requires it to be more transparent, accountable, and understandable for humans. This survey paper provides essential definitions, an overview of the different principles and methodologies of explainable Supervised Machine Learning (SML). We conduct a state-of-the-art survey that reviews past and recent explainable SML approaches and classifies them according to the introduced definitions. Finally, we illustrate principles by means of an explanatory case study and discuss important future directions.",
    "doi": "10.1613/jair.1.12228",
    "url": "https://openalex.org/W3101981467",
    "pdf_url": "https://jair.org/index.php/jair/article/download/12228/26647",
    "venue": "Journal of Artificial Intelligence Research",
    "citation_count": 900,
    "fields_of_study": [
      "Computer science",
      "Machine learning",
      "Artificial intelligence",
      "Supervised learning",
      "Artificial neural network"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769339"
  },
  {
    "source": "openalex",
    "source_id": "W4392669753",
    "title": "A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity",
    "authors": [
      "Yejin Bang",
      "Samuel Cahyawijaya",
      "Nayeon Lee",
      "Wenliang Dai",
      "Dan Su",
      "Bryan Wilie",
      "Holy Lovenia",
      "Ziwei Ji",
      "Tiezheng Yu",
      "Willy Chung",
      "V. Quyet",
      "Yan Xu",
      "Pascale Fung"
    ],
    "year": 2023,
    "abstract": "Yejin Bang, Samuel Cahyawijaya, Nayeon Lee, Wenliang Dai, Dan Su, Bryan Wilie, Holy Lovenia, Ziwei Ji, Tiezheng Yu, Willy Chung, Quyet V. Do, Yan Xu, Pascale Fung. Proceedings of the 13th International Joint Conference on Natural Language Processing and the 3rd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics (Volume 1: Long Papers). 2023.",
    "doi": "10.18653/v1/2023.ijcnlp-main.45",
    "url": "https://openalex.org/W4392669753",
    "pdf_url": "https://aclanthology.org/2023.ijcnlp-main.45.pdf",
    "venue": null,
    "citation_count": 569,
    "fields_of_study": [
      "Interactivity",
      "Computer science",
      "Natural language processing",
      "Multimodal interaction",
      "Multimodal therapy"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769353"
  },
  {
    "source": "openalex",
    "source_id": "W4378574344",
    "title": "ChatGPT and Open-AI Models: A Preliminary Review",
    "authors": [
      "Konstantinos I. Roumeliotis",
      "Nikolaos D. Tselikas"
    ],
    "year": 2023,
    "abstract": "According to numerous reports, ChatGPT represents a significant breakthrough in the field of artificial intelligence. ChatGPT is a pre-trained AI model designed to engage in natural language conversations, utilizing sophisticated techniques from Natural Language Processing (NLP), Supervised Learning, and Reinforcement Learning to comprehend and generate text comparable to human-generated text. This article provides an overview of the training process and fundamental functionality of ChatGPT, accompanied by a preliminary review of the relevant literature. Notably, this article presents the first comprehensive literature review of this technology at the time of publication, aiming to aggregate all the available pertinent articles to facilitate further developments in the field. Ultimately, the authors aim to offer an appraisal of the technology\u2019s potential implications on existing knowledge and technology, along with potential challenges that must be addressed.",
    "doi": "10.3390/fi15060192",
    "url": "https://openalex.org/W4378574344",
    "pdf_url": "https://www.mdpi.com/1999-5903/15/6/192/pdf?version=1685089354",
    "venue": "Future Internet",
    "citation_count": 618,
    "fields_of_study": [
      "Computer science",
      "Field (mathematics)",
      "Artificial intelligence",
      "Process (computing)",
      "Reinforcement learning"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769362"
  },
  {
    "source": "openalex",
    "source_id": "W2162057064",
    "title": "Climate Clubs: Overcoming Free-riding in International Climate Policy",
    "authors": [
      "William D. Nordhaus"
    ],
    "year": 2015,
    "abstract": "Notwithstanding great progress in scientific and economic understanding of climate change, it has proven difficult to forge international agreements because of free-riding, as seen in the defunct Kyoto Protocol. This study examines the club as a model for international climate policy. Based on economic theory and empirical modeling, it finds that without sanctions against non-participants there are no stable coalitions other than those with minimal abatement. By contrast, a regime with small trade penalties on non-participants, a Climate Club, can induce a large stable coalition with high levels of abatement. (JEL Q54, Q58, K32, K33)",
    "doi": "10.1257/aer.15000001",
    "url": "https://openalex.org/W2162057064",
    "pdf_url": "https://www.aeaweb.org/articles/pdf/doi/10.1257/aer.15000001",
    "venue": "American Economic Review",
    "citation_count": 1275,
    "fields_of_study": [
      "Sanctions",
      "Club",
      "Climate change",
      "Climate policy",
      "Kyoto Protocol"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769378"
  },
  {
    "source": "openalex",
    "source_id": "W2991184684",
    "title": "Artificial Intelligence and its role in surgical care in low-income and middle-income countries",
    "authors": [
      "Ch\u00e9 L. Reddy",
      "Shivani Mitra",
      "John G. Meara",
      "Rifat Atun",
      "Salim Afshar"
    ],
    "year": 2019,
    "abstract": "The barriers that prevent access to safe, affordable, and timely surgical care for 5 billion people are myriad, including shortfalls in workforce, infrastructure, and financing. These barriers mainly affect health systems in low-income and middle-income countries.1Meara JG Leather AJM Hagander L et al.Global Surgery 2030: evidence and solutions for achieving health, welfare, and economic development.Lancet. 2015; 386: 569-624Summary Full Text Full Text PDF PubMed Scopus (1818) Google Scholar In many high-income countries, artificial intelligence (AI) is viewed as a promising tool for transforming health systems.2Panch T Pearson-Stuttard J Greaves F Atun R Artificial intelligence: opportunities and risks for public health.Lancet Digital Health. 2019; 1: e13-e14Summary Full Text Full Text PDF Scopus (39) Google Scholar AI has a role to play in optimising health systems and supporting clinical judgement, because it can be used to search for patterns and insights across a patient population when human cognition alone is limited. However, is AI a luxury in low-resourced settings, or a required tool? Low-income and middle-income countries are a heterogeneous group of countries when it comes to data and technological expertise. Countries such as Brazil, China, India, Turkey, and South Africa have large datasets at the institutional and national levels and have the technological capacity to implement the technology. Exploring the possible use of AI could be considered a distraction, especially when major barriers to health-care delivery exist, but we argue that precisely because of these barriers, AI presents an exciting opportunity for some low-income and middle-income countries. We believe that the potential of AI to build more robust surgical systems lies in appropriately applying it to health system processes, to augment clinical judgment. In 2015, WHO member states adopted a resolution that emphasised the crucial role of surgery in Universal Health Coverage.368th World Health AssemblyWHA 68.15 Strengthening emergency and essential surgical care and anaesthesia as a component of universal health coverage.https://apps.who.int/gb/ebwha/pdf_files/WHA68/A68_R15-en.pdfDate: 2015Date accessed: November 12, 2019Google Scholar Surgically treatable conditions contribute to more deaths each year than HIV, tuberculosis, and malaria combined (appendix)1Meara JG Leather AJM Hagander L et al.Global Surgery 2030: evidence and solutions for achieving health, welfare, and economic development.Lancet. 2015; 386: 569-624Summary Full Text Full Text PDF PubMed Scopus (1818) Google Scholar\u2014a burden inequitably borne by low-income and middle-income countries. AI tools could help augment clinical judgment regarding patients and will probably eventually improve surgical care through stronger surgical diagnostics, prognostics, and therapeutics.4Hashimoto DA Rosman G Rus D Meireles OR Artificial Intelligence in surgery: promises and perils.Real Estate Econ. 2010; 38: 57-90Google Scholar However, for low-income and middle-income countries, we believe that AI tools should be developed to target the most substantial factor limiting surgical care: weak health systems with severe resource shortages and operational challenges, all of which undermine patient-level surgical care. The core problems in many low-income and middle-income countries are operational, managerial, and process challenges that reflect faults in the surgical system, rather than poor decision making by clinicians. Faulty supply chains result in inadequate surgical supplies; poor infrastructure\u2014for example, electricity blackouts\u2014causes delays in operating theatre lists; insufficient workforce foments physician burnout, inattention, and clinical errors; and weak governance and management results in impaired service delivery and overall institutional decay. Ineffective management of processes can be made more efficient within this realm of system function through AI systematically applied to answer questions within the domains of the National Surgical, Obstetric, and Anesthesia Planning (NSOAP) framework.5WHOSurgical care systems strengthening: developing national surgical, obstetric and anaesthesia plans.http://apps.who.int/iris/bitstream/10665/255566/1/9789241512244-eng.pdf?ua=1Date: 2017Date accessed: November 5, 2019Google Scholar Low-income and middle-income countries have implemented NSOAPs to develop country-specific strategies to improve their surgical system within six functional domains of a health system\u2014governance, financing, workforce, infrastructure, service delivery, and information management. NSOAPs are integrated into country national health strategic plans and within the other strategic health objectives of the Ministry of Health. For each country, data drives strategic decisions within each NSOAP domain, to which AI can be applied to data to answer process-related questions and reveal inferences that help policy makers and administrators advance surgical systems. The application of AI could overcome bureaucratic inefficiency for more efficient surgical system development in these countries, helping to optimise the production, distribution, and use of the health workforce and infrastructure; allocate system resources more efficiently; and streamline care pathways and supply chains. However, how can the issue of low-quality data in low-income and middle-income countries be addressed? With regards to data, not all low-income and middle-income countries are the same. Many countries, including South Africa, have large sets of data that pertain to both the health system and the broader context that together influence health service delivery at the national and sub-national levels.6World BankCentral Data Catalog. Microdata Library.https://microdata.worldbank.org/index.php/catalogDate accessed: October 5, 2019Google Scholar Countries with targeted national programmes have rich datasets to which AI could be applied to help policy makers gain insights into the provinces and challenges that should be prioritised. In addition to government data, dedicated networks of health-care providers offer specialised surgical care with comprehensive data repositories in both the private and public sectors. With appropriate data cleaning, rigorous coding, and transfer from one format to another to produce reliable and interoperable databases, growing surgical systems can leverage the large datasets they already possess. Most data in low-income and middle-income countries are not of low quality\u2014they are more frequently asymmetric, asynchronous, varied in type, and spread across locations. These datasets are dormant and underutilised in these countries. Expert-driven AI using smaller data sets that are combined\u2014for example, at the institutional level\u2014can be equally as powerful as large amounts of data.7Wilson HJ Daugherty PR Davenport C The future of AI will be about less data, not more.https://hbr.org/2019/01/the-future-of-ai-will-be-about-less-data-not-moreDate: 2019Date accessed: October 6, 2019Google Scholar Data scientists working closely with clinicians have already applied this approach in AI to address specific clinical questions.8Cho J Lee K Shin E Choy G Do S How much data is needed to train a medical image deep learning system to achieve necessary high accuracy?.https://arxiv.org/abs/1511.06348Date: 2015Date accessed: November 5, 2019Google Scholar Experts in health service delivery in low-income and middle-income countries can navigate asynchronous and asymmetric data sets through different applications of AI instead of relying only on bottom-up methodologies, although this has not yet been applied to health systems to answer questions on the inputs and outputs that determine the state of their health system. Developing transparent AI is possible through leveraging a combination of small data sets. When developers and experts are aware of the algorithms, its biases, and the results produced at each step in the application process, the AI algorithm becomes explainable9Lee H Yune S Mansouri M et al.An explainable deep-learning algorithm for the detection of acute intracranial haemorrhage from small datasets.Nat Biomed Eng. 2019; 3: 173-182Crossref PubMed Scopus (211) Google Scholar and therefore minimises the ethical and functional issues caused by blind results. Although the method holds promise, AI is not a panacea for improved surgical care. Broader challenges affecting AI policy include concerns around employment; ethics; privacy; and whether countries ought to immediately invest in other proven, cost-effective interventions before seeking out AI solutions. More specifically, regulatory and ethics boards will be needed to uphold the principles of transparency, accountability, privacy, and fairness in the use of data. This will require a careful assessment of both the challenges and potential benefit at institutional and national levels. Although the return on investment is unclear, the magnitude of the potential impact warrants the development of a receptive environment for AI adoption. This entails evaluating the AI innovation itself (AI utilised via the NSOAP framework), the adoption system (including stakeholders), and the broader health system context (appendix). The adoption system must encompass individuals and institutions that implement AI within the health system and those entities that influence or create the AI technology itself, each of which is crucial for successful adoption and scale-up. The potential for AI to improve access to effective and efficient surgical care in low-income and middle-income countries could be substantial. Urgent action is needed to develop the required technical skills for appropriate AI technologies and to create a receptive environment to test and scale AI. These countries must nurture local talent, bringing together a triad of AI developers, policy makers and clinicians, to understand the potential of AI that leverages asynchronous data sets; improve the pooling of data; develop context-appropriate regulatory and ethical frameworks; and apply appropriate AI technologies to answer questions within the domains of a surgical system. Failing to do so will almost guarantee the passive transfer of clinical AI tools to low-income and middle-income countries not ready to adopt and implement them in the contextual reality of a weak health system. Through a fair and inclusive process and method of analysis framed by NSOAPs, these countries could make substantial improvements in the application of AI to help expand surgical services to those who require it the most. SA declares patents pending in relation to software unrelated to the submitted work. Download .pdf (.24 MB) Help with pdf files Supplementary appendix",
    "doi": "10.1016/s2589-7500(19)30200-6",
    "url": "https://openalex.org/W2991184684",
    "pdf_url": "http://www.thelancet.com/article/S2589750019302006/pdf",
    "venue": "The Lancet Digital Health",
    "citation_count": 23,
    "fields_of_study": [
      "Low and middle income countries",
      "Middle income",
      "Demographic economics",
      "Economics",
      "Business"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769392"
  },
  {
    "source": "openalex",
    "source_id": "W4288391568",
    "title": "An Overview of Artificial Intelligence Ethics",
    "authors": [
      "Changwu Huang",
      "Zeqi Zhang",
      "Bifei Mao",
      "Xin Yao"
    ],
    "year": 2022,
    "abstract": "Artificial intelligence (AI) has profoundly changed and will continue to change our lives. AI is being applied in more and more fields and scenarios such as autonomous driving, medical care, media, finance, industrial robots, and internet services. The widespread application of AI and its deep integration with the economy and society have improved efficiency and produced benefits. At the same time, it will inevitably impact the existing social order and raise ethical concerns. Ethical issues, such as privacy leakage, discrimination, unemployment, and security risks, brought about by AI systems have caused great trouble to people. Therefore, AI ethics, which is a field related to the study of ethical issues in AI, has become not only an important research topic in academia, but also an important topic of common concern for individuals, organizations, countries, and society. This paper will give a comprehensive overview of this field by summarizing and analyzing the ethical risks and issues raised by AI, ethical guidelines and principles issued by different organizations, approaches for addressing ethical issues in AI, methods for evaluating the ethics of AI. Additionally, challenges in implementing ethics in AI and some future perspectives are pointed out. We hope our work will provide a systematic and comprehensive overview of AI ethics for researchers and practitioners in this field, especially the beginners of this research discipline.",
    "doi": "10.1109/tai.2022.3194503",
    "url": "https://openalex.org/W4288391568",
    "pdf_url": "https://ieeexplore.ieee.org/ielx7/9078688/9184921/09844014.pdf",
    "venue": "IEEE Transactions on Artificial Intelligence",
    "citation_count": 354,
    "fields_of_study": [
      "Engineering ethics",
      "Ethical issues",
      "Field (mathematics)",
      "Ethics of technology",
      "Political science"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769513"
  },
  {
    "source": "openalex",
    "source_id": "W4206484811",
    "title": "A Metaverse: Taxonomy, Components, Applications, and Open Challenges",
    "authors": [
      "Sangmin Park",
      "Young\u2010Gab Kim"
    ],
    "year": 2022,
    "abstract": "Unlike previous studies on the Metaverse based on Second Life, the current Metaverse is based on the social value of Generation Z that online and offline selves are not different. With the technological development of deep learning-based high-precision recognition models and natural generation models, Metaverse is being strengthened with various factors, from mobile-based always-on access to connectivity with reality using virtual currency. The integration of enhanced social activities and neural-net methods requires a new definition of Metaverse suitable for the present, different from the previous Metaverse. This paper divides the concepts and essential techniques necessary for realizing the Metaverse into three components (i.e., hardware, software, and contents) and three approaches (i.e., user interaction, implementation, and application) rather than marketing or hardware approach to conduct a comprehensive analysis. Furthermore, we describe essential methods based on three components and techniques to Metaverse&#x2019;s representative Ready Player One, Roblox, and Facebook research in the domain of films, games, and studies. Finally, we summarize the limitations and directions for implementing the immersive Metaverse as social influences, constraints, and open challenges.",
    "doi": "10.1109/access.2021.3140175",
    "url": "https://openalex.org/W4206484811",
    "pdf_url": "https://ieeexplore.ieee.org/ielx7/6287639/9668973/09667507.pdf",
    "venue": "IEEE Access",
    "citation_count": 1664,
    "fields_of_study": [
      "Computer science",
      "Taxonomy (biology)",
      "Metaverse",
      "Data science",
      "World Wide Web"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769531"
  },
  {
    "source": "openalex",
    "source_id": "W3032875465",
    "title": "Re-examining Whether, Why, and How Human-AI Interaction Is Uniquely Difficult to Design",
    "authors": [
      "Qian Yang",
      "Aaron Steinfeld",
      "Carolyn Penstein Ros\u00e9",
      "John Zimmerman"
    ],
    "year": 2020,
    "abstract": "Artificial Intelligence (AI) plays an increasingly important role in improving HCI and user experience. Yet many challenges persist in designing and innovating valuable human-AI interactions. For example, AI systems can make unpredictable errors, and these errors damage UX and even lead to undesired societal impact. However, HCI routinely grapples with complex technologies and mitigates their unintended consequences. What makes AI different? What makes human-AI interaction appear particularly difficult to design? This paper investigates these questions. We synthesize prior research, our own design and research experience, and our observations when teaching human-AI interaction. We identify two sources of AI's distinctive design challenges: 1) uncertainty surrounding AI's capabilities, 2) AI's output complexity, spanning from simple to adaptive complex. We identify four levels of AI systems. On each level, designers encounter a different subset of the design challenges. We demonstrate how these findings reveal new insights for designers, researchers, and design tool makers in productively addressing the challenges of human-AI interaction going forward.",
    "doi": "10.1145/3313831.3376301",
    "url": "https://openalex.org/W3032875465",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3313831.3376301",
    "venue": null,
    "citation_count": 495,
    "fields_of_study": [
      "Computer science",
      "Unintended consequences",
      "Human\u2013computer interaction",
      "Data science",
      "Interaction design"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769547"
  },
  {
    "source": "openalex",
    "source_id": "W4292289324",
    "title": "Human-in-the-loop machine learning: a state of the art",
    "authors": [
      "Eduardo Mosqueira-Rey",
      "Elena Hern\u00e1ndez-Pereira",
      "David Alonso-R\u00edos",
      "Jos\u00e9 Bobes-Bascar\u00e1n",
      "\u00c1ngel Fern\u00e1ndez-Leal"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1007/s10462-022-10246-w",
    "url": "https://openalex.org/W4292289324",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10462-022-10246-w.pdf",
    "venue": "Artificial Intelligence Review",
    "citation_count": 666,
    "fields_of_study": [
      "Computer science",
      "Artificial intelligence",
      "Machine learning",
      "Process (computing)",
      "Active learning (machine learning)"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769560"
  },
  {
    "source": "openalex",
    "source_id": "W4391855109",
    "title": "A Review on Large Language Models: Architectures, Applications, Taxonomies, Open Issues and Challenges",
    "authors": [
      "Mohaimenul Azam Khan Raiaan",
      "Md. Saddam Hossain Mukta",
      "Kaniz Fatema",
      "Nur Mohammad Fahad",
      "Sadman Sakib",
      "Most. Marufatul Jannat Mim",
      "Jubaer Ahmad",
      "Mohammed Eunus Ali",
      "Sami Azam"
    ],
    "year": 2024,
    "abstract": "Large Language Models (LLMs) recently demonstrated extraordinary capability in various natural language processing (NLP) tasks including language translation, text generation, question answering, etc. Moreover, LLMs are new and essential part of computerized language processing, having the ability to understand complex verbal patterns and generate coherent and appropriate replies in a given context. Though this success of LLMs has prompted a substantial increase in research contributions, rapid growth has made it difficult to understand the overall impact of these improvements. Since a plethora of research on LLMs have been appeared within a short time, it is quite impossible to track all of these and get an overview of the current state of research in this area. Consequently, the research community would benefit from a short but thorough review of the recent changes in this area. This article thoroughly overviews LLMs, including their history, architectures, transformers, resources, training methods, applications, impacts, challenges, etc. This paper begins by discussing the fundamental concepts of LLMs with its traditional pipeline of the LLMs training phase. Then the paper provides an overview of the existing works, the history of LLMs, their evolution over time, the architecture of transformers in LLMs, the different resources of LLMs, and the different training methods that have been used to train them. The paper also demonstrates the datasets utilized in the studies. After that, the paper discusses the wide range of applications of LLMs, including biomedical and healthcare, education, social, business, and agriculture. The study also illustrates how LLMs create an impact on society and shape the future of AI and how they can be used to solve real-world problems. Finally, the paper also explores open issues and challenges to deploy LLMs in real-world scenario. Our review paper aims to help practitioners, researchers, and experts thoroughly understand the evolution of LLMs, pre-trained architectures, applications, challenges, and future goals.",
    "doi": "10.1109/access.2024.3365742",
    "url": "https://openalex.org/W4391855109",
    "pdf_url": "https://ieeexplore.ieee.org/ielx7/6287639/6514899/10433480.pdf",
    "venue": "IEEE Access",
    "citation_count": 517,
    "fields_of_study": [
      "Computer science",
      "Open research",
      "Data science",
      "Natural language processing",
      "World Wide Web"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769564"
  },
  {
    "source": "openalex",
    "source_id": "W3046653923",
    "title": "Federated Learning: A Survey on Enabling Technologies, Protocols, and Applications",
    "authors": [
      "Mohammed Aledhari",
      "Rehma Razzak",
      "Reza M. Parizi",
      "Fahad Saeed"
    ],
    "year": 2020,
    "abstract": "This paper provides a comprehensive study of Federated Learning (FL) with an emphasis on enabling software and hardware platforms, protocols, real-life applications and use-cases. FL can be applicable to multiple domains but applying it to different industries has its own set of obstacles. FL is known as collaborative learning, where algorithm(s) get trained across multiple devices or servers with decentralized data samples without having to exchange the actual data. This approach is radically different from other more established techniques such as getting the data samples uploaded to servers or having data in some form of distributed infrastructure. FL on the other hand generates more robust models without sharing data, leading to privacy-preserved solutions with higher security and access privileges to data. This paper starts by providing an overview of FL. Then, it gives an overview of technical details that pertain to FL enabling technologies, protocols, and applications. Compared to other survey papers in the field, our objective is to provide a more thorough summary of the most relevant protocols, platforms, and real-life use-cases of FL to enable data scientists to build better privacy-preserving solutions for industries in critical need of FL. We also provide an overview of key challenges presented in the recent literature and provide a summary of related research work. Moreover, we explore both the challenges and advantages of FL and present detailed service use-cases to illustrate how different architectures and protocols that use FL can fit together to deliver desired results.",
    "doi": "10.1109/access.2020.3013541",
    "url": "https://openalex.org/W3046653923",
    "pdf_url": "https://ieeexplore.ieee.org/ielx7/6287639/8948470/09153560.pdf",
    "venue": "IEEE Access",
    "citation_count": 666,
    "fields_of_study": [
      "Computer science",
      "Upload",
      "Server",
      "Field (mathematics)",
      "Key (lock)"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769587"
  },
  {
    "source": "openalex",
    "source_id": "W3200742808",
    "title": "Chatbot for Health Care and Oncology Applications Using Artificial Intelligence and Machine Learning: Systematic Review",
    "authors": [
      "Lu Xu",
      "Leslie Sanders",
      "Kay Li",
      "James C. L. Chow"
    ],
    "year": 2021,
    "abstract": "Background Chatbot is a timely topic applied in various fields, including medicine and health care, for human-like knowledge transfer and communication. Machine learning, a subset of artificial intelligence, has been proven particularly applicable in health care, with the ability for complex dialog management and conversational flexibility. Objective This review article aims to report on the recent advances and current trends in chatbot technology in medicine. A brief historical overview, along with the developmental progress and design characteristics, is first introduced. The focus will be on cancer therapy, with in-depth discussions and examples of diagnosis, treatment, monitoring, patient support, workflow efficiency, and health promotion. In addition, this paper will explore the limitations and areas of concern, highlighting ethical, moral, security, technical, and regulatory standards and evaluation issues to explain the hesitancy in implementation. Methods A search of the literature published in the past 20 years was conducted using the IEEE Xplore, PubMed, Web of Science, Scopus, and OVID databases. The screening of chatbots was guided by the open-access Botlist directory for health care components and further divided according to the following criteria: diagnosis, treatment, monitoring, support, workflow, and health promotion. Results Even after addressing these issues and establishing the safety or efficacy of chatbots, human elements in health care will not be replaceable. Therefore, chatbots have the potential to be integrated into clinical practice by working alongside health practitioners to reduce costs, refine workflow efficiencies, and improve patient outcomes. Other applications in pandemic support, global health, and education are yet to be fully explored. Conclusions Further research and interdisciplinary collaboration could advance this technology to dramatically improve the quality of care for patients, rebalance the workload for clinicians, and revolutionize the practice of medicine.",
    "doi": "10.2196/27850",
    "url": "https://openalex.org/W3200742808",
    "pdf_url": "https://cancer.jmir.org/2021/4/e27850/PDF",
    "venue": "JMIR Cancer",
    "citation_count": 474,
    "fields_of_study": [
      "Chatbot",
      "Workflow",
      "Health care",
      "Safeguarding",
      "Clinical decision support system"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769613"
  },
  {
    "source": "openalex",
    "source_id": "W3006754301",
    "title": "A future for the world's children? A WHO\u2013UNICEF\u2013Lancet Commission",
    "authors": [
      "Helen Clark",
      "Awa Marie Coll\u2010Seck",
      "Anshu Banerjee",
      "Stefan Peterson",
      "Sarah L Dalglish",
      "Shanthi Ameratunga",
      "Dina Balabanova",
      "Maharaj Kishan Bhan",
      "Zulfiqar A Bhutta",
      "John Borrazzo",
      "M Claeson",
      "Tanya Doherty",
      "Fadi El\u2010Jardali",
      "Asha George",
      "Angela Gichaga",
      "Lu Gram",
      "David Hipgrave",
      "Aku Kwamie",
      "Qingyue Meng",
      "Ra\u00fal Mercer",
      "Sunita Narain",
      "Jesca Nsungwa\u2010Sabiiti",
      "Adesola Olumide",
      "David Osrin",
      "Timothy Powell\u2010Jackson",
      "Kumanan Rasanathan",
      "Imran Rasul",
      "Papaarangi Reid",
      "Jennifer Requejo",
      "Sarah Rohde",
      "Nigel Rollins",
      "Magali Romedenne",
      "Harshpal Singh Sachdev",
      "Rana Saleh",
      "Yusra Ribhi Shawar",
      "Jeremy Shiffman",
      "Jonathon Simon",
      "Peter D. Sly",
      "Karin Stenberg",
      "Mark Tomlinson",
      "Rajani Ved",
      "Anthony Costello"
    ],
    "year": 2020,
    "abstract": "Despite dramatic improvements in survival, nutrition, and education over recent decades, today's children face an uncertain future. Climate change, ecological degradation, migrating populations, conflict, pervasive inequalities, and predatory commercial practices threaten the health and future of children in every country. In 2015, the world's countries agreed on the Sustainable Development Goals (SDGs), yet nearly 5 years later, few countries have recorded much progress towards achieving them. This Commission presents the case for placing children, aged 0\u201318 years, at the centre of the SDGs: at the heart of the concept of sustainability and our shared human endeavour. Governments must harness coalitions across sectors to overcome ecological and commercial pressures to ensure children receive their rights and entitlements now and a liveable planet in the years to come. The evidence is clear: early investments in children's health, education, and development have benefits that compound throughout the child's lifetime, for their future children, and society as a whole. Successful societies invest in their children and protect their rights, as is evident from countries that have done well on health and economic measures over the past few decades. Yet many politicians still do not prioritise investing in children, nor see it as the foundation for broader societal improvements. Even in rich countries, many children go hungry or live in conditions of absolute poverty, especially those belonging to marginalised social groups\u2014including indigenous populations and ethnic minorities. Too often, the potential of children with developmental disabilities is neglected, restricting their contributions to society. Additionally, many millions of children grow up scarred by war or insecurity, excluded from receiving the most basic health, educational, and developmental services. Decision makers need a long-term vision. Just as good health and nutrition in the prenatal period and early years lay the foundation for a healthy life course, the learning and social skills we acquire at a young age provide the basis for later development and support a strong national polity and economy. High-quality services with universal health-care coverage must be a top priority. The benefits of investing in children would be enormous, and the costs are not prohibitive: an analysis of the SDGs suggests a financing gap of US$195 per person. To ensure stronger economic and human development, each government must assess how to mobilise funding using instruments that help the poorest proportion of the population to meet this gap for children, and frame these as the most powerful investments a society can make. But investments are not just monetary: citizen participation and community action, including the voices of children themselves, are powerful forces for change that must be mobilised to reach the SDGs. Social movements must play a transformational role in demanding the rights that communities need to care for children and provide for families. Countries that support future generations put a high priority on ensuring all children's needs are met, by delivering entitlements, such as paid parental leave, free primary health care at the point of delivery, access to healthy\u2014and sufficient amounts of\u2014food, state-funded or subsidised education, and other social protection measures. These countries make sure children grow up in safe and healthy environments, with clean water and air and safe spaces to play. They respect the equal rights of girls, boys, and those with non-conforming gender identities. Policy makers in these countries are concerned with the effect of all policies on all children, but especially those in poorer families and marginalised populations, starting by ensuring birth registration so that the government can provide for children across the life course, and help them to become engaged and productive adult citizens. The rights and entitlements of children are enshrined within the UN Convention on the Rights of the Child (CRC) ratified by all countries, except the USA. Countries might provide these entitlements in different ways, but their realisation is the only pathway for countries to achieve the SDGs for children's health and wellbeing, and requires decisive and strong public action. Since threats to child health and wellbeing originate in all sectors, a deliberately multisectoral approach is needed to ensure children and adolescents survive and thrive from the ages of 0\u201318 years, today and in the future. Investment in sectors beyond health and education\u2014such as housing, agriculture, energy, and transport\u2014are needed to address the greatest threats to child health and wellbeing. Political commitment at executive level is needed to coordinate across sectors and leverage synergies across the life course, ensuring universal health coverage; good nutrition and food security for all; thoughtful urban planning; safe and affordable housing and transport; clean energy for all; and equitable social welfare policies. Multisectoral governance might take different forms in each country, but it will require strategic partnerships, cabinet-level coordination across ministries, and management of diverse partners, with clear roles for each, including for non-state actors and the private sector. Heads of state or prime ministers must designate a cross-cutting government ministry or equivalent to ensure joined-up action and budgeting for pro-child policies and to demand harmonised assistance from global stakeholders, whose support is currently fragmented and inefficient. Wealthy countries generally have better child health and development outcomes, but their historic and current greenhouse gas emissions threaten the lives of all children. The ecological damage unleashed today endangers the future of children's lives on our planet, their only home. As a result, our understanding of progress on child health and wellbeing must give priority to measures of ecological sustainability and equity to ensure we protect all children, including the most vulnerable. We assessed the feasibility of monitoring countries' progress through a new child flourishing and futures profile, developed on the basis of survive and thrive SDG indicators reported by 180 countries, territories, and areas (hereafter referred to as countries), and future threats to children's wellbeing using the proxy of greenhouse gas emissions by country. We also complemented the profile with existing measures of economic equity. The poorest countries have a long way to go towards supporting their children's ability to live healthy lives, but wealthier countries threaten the future of all children through carbon pollution, on course to cause runaway climate change and environmental disaster. Not a single country performed well on all three measures of child flourishing, sustainability, and equity. The SDG indicators already provide a strong foundation for monitoring progress. However, we only found a very small amount of country data for the indicators used to track child health and wellbeing, which all countries agreed to collect. SDG monitoring needs a strong boost in investment to bridge the large data gaps in key indicators (with <50% of countries reporting data for many indicators), to allow for subnational disaggregation if governments are to monitor, review, and act. To ensure our children grow and flourish, we require timely and accurate population data on health, nutrition, educational access and performance, housing, and environmental security, among other entitlements. Harnessing the power of citizen accountability mechanisms will be essential to fill the data gaps. We also propose the development of user-friendly country dashboards to assess the effects on children's wellbeing and sustainable development. Given the urgency for action, regular reports on the SDGs to the UN General Assembly must be the anchor of strong advocacy on action for children everywhere. Although we recognise the role business plays in wealth and job creation, the commercial sector's profit motive poses many threats to child health and wellbeing, not least the environmental damage unleashed by unregulated industry. More immediately, children around the world are enormously exposed to advertising from business, whose marketing techniques exploit their developmental vulnerability and whose products can harm their health and wellbeing. Companies make huge profits from marketing products directly to children and promoting addictive or unhealthy commodities, including fast foods, sugar-sweetened beverages, alcohol, and tobacco, all of which are major causes of non-communicable diseases. Children's large and growing online exposure, while bringing benefits in terms of information access and social support, also exposes them to exploitation, as well as to bullying, gambling, and grooming by criminals and sexual abusers. Industry self-regulation does not work, and the existing global frameworks are not sufficient. A far stronger and more comprehensive approach to regulation is required. We call for the development of an Optional Protocol to the CRC (ie, an additional component to the treaty that must be independently ratified), to protect children from the marketing of tobacco, alcohol, formula milk, sugar-sweetened beverages, gambling, and potentially damaging social media, and the inappropriate use of their personal data. Countries who have led the way in protecting children from the harms of commercial marketing, supported by civil society, can support a protocol for adoption by the UN General Assembly, providing impetus for further legal and constitutional protections for children at national level. Children and young people are full of energy, ideas, and hope for the future. They are also angry at the state of the world. Worldwide, school-children and young people are protesting about environmental threats from fossil fuel economies. We must find better ways to amplify their voices and skills for the planet's sustainable and healthy future. The SDGs require governments to place children at the very centre of their plans to address this crisis. This Commission makes positive and optimistic recommendations\u2013but we have no time to lose, and no excuses if we fail. A new global movement for child and adolescent health is today an urgent necessity.",
    "doi": "10.1016/s0140-6736(19)32540-1",
    "url": "https://openalex.org/W3006754301",
    "pdf_url": "http://www.thelancet.com/article/S0140673619325401/pdf",
    "venue": "The Lancet",
    "citation_count": 1018,
    "fields_of_study": [
      "Commission",
      "Political science",
      "Medicine",
      "Family medicine",
      "Law"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769647"
  },
  {
    "source": "openalex",
    "source_id": "W4210867863",
    "title": "Ethics of AI-Enabled Recruiting and Selection: A Review and Research Agenda",
    "authors": [
      "Anna Lena Hunkenschroer",
      "Christoph Luetge"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1007/s10551-022-05049-6",
    "url": "https://openalex.org/W4210867863",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10551-022-05049-6.pdf",
    "venue": "Journal of Business Ethics",
    "citation_count": 320,
    "fields_of_study": [
      "Business ethics",
      "Novelty",
      "Extant taxon",
      "Process (computing)",
      "Engineering ethics"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769779"
  },
  {
    "source": "openalex",
    "source_id": "W2998691503",
    "title": "Automation, Algorithms, and Beyond: Why Work Design Matters More Than Ever in a Digital World",
    "authors": [
      "Sharon K. Parker",
      "Gudela Grote"
    ],
    "year": 2019,
    "abstract": "Abstract We propose a central role for work design in understanding the effects of digital technologies. We give examples of how new technologies can\u2014depending on various factors\u2014positively and negatively affect job resources (autonomy/control, skill use, job feedback, relational aspects) and job demands (e.g., performance monitoring), with consequences for employee well\u2010being, safety, and performance. We identify four intervention strategies. First, work design choices need to be proactively considered during technology implementation, consistent with the sociotechnical systems principle of joint optimization. Second, human\u2010centred design principles should be explicitly considered in the design and procurement of new technologies. Third, organizationally oriented intervention strategies need to be supported by macro\u2010level policies. Fourth, there is a need to go beyond a focus on upskilling employees to help them adapt to technology change, to also focus on training employees, as well as other stakeholders, in work design and related topics. Finally, we identify directions for moving the field forward, including new research questions (e.g., job autonomy in the context of machine learning; understanding designers\u2019 work design mindsets; investigating how job crafting applies to technology); a reorientation of methods (e.g., interdisciplinary, intervention studies); and steps for achieving practical impact.",
    "doi": "10.1111/apps.12241",
    "url": "https://openalex.org/W2998691503",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/apps.12241",
    "venue": "Applied Psychology",
    "citation_count": 659,
    "fields_of_study": [
      "Job design",
      "Sociotechnical system",
      "Autonomy",
      "Computer science",
      "Knowledge management"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769781"
  },
  {
    "source": "openalex",
    "source_id": "W2990290777",
    "title": "Artificial intelligence in clinical and genomic diagnostics",
    "authors": [
      "Raquel Dias",
      "Ali Torkamani"
    ],
    "year": 2019,
    "abstract": null,
    "doi": "10.1186/s13073-019-0689-8",
    "url": "https://openalex.org/W2990290777",
    "pdf_url": "https://genomemedicine.biomedcentral.com/track/pdf/10.1186/s13073-019-0689-8",
    "venue": "Genome Medicine",
    "citation_count": 425,
    "fields_of_study": [
      "Artificial intelligence",
      "Computer science",
      "Deep learning",
      "Precision medicine",
      "Genomics"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769798"
  },
  {
    "source": "openalex",
    "source_id": "W4223899585",
    "title": "Transfer learning for medical image classification: a literature review",
    "authors": [
      "Kim Eun Hee",
      "Alejandro Cosa\u2010Linan",
      "Nandhini Santhanam",
      "Mahboubeh Jannesari",
      "M\u00e1t\u00e9 E. Maros",
      "Thomas Ganslandt"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1186/s12880-022-00793-7",
    "url": "https://openalex.org/W4223899585",
    "pdf_url": "https://bmcmedimaging.biomedcentral.com/track/pdf/10.1186/s12880-022-00793-7",
    "venue": "BMC Medical Imaging",
    "citation_count": 807,
    "fields_of_study": [
      "Computer science",
      "Extractor",
      "Transfer of learning",
      "Artificial intelligence",
      "Task (project management)"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769802"
  },
  {
    "source": "openalex",
    "source_id": "W4376139682",
    "title": "The role of ChatGPT in higher education: Benefits, challenges, and future research directions",
    "authors": [
      "Tareq Rasul",
      "Sumesh Nair",
      "Diane Robyn Kalendra",
      "Mulyadi Robin",
      "Fernando de Oliveira Santini",
      "Wagner J\u00fanior Ladeira",
      "Mingwei Sun",
      "Ingrid Day",
      "Raouf Ahmad Rather",
      "Liz Heathcote"
    ],
    "year": 2023,
    "abstract": "This paper examines the potential benefits and challenges of using the generative AI model, ChatGPT, in higher education, in the backdrop of the constructivist theory of learning. This perspective-type study presents five benefits of ChatGPT: the potential to facilitate adaptive learning, provide personalised feedback, support research and data analysis, offer automated administrative services, and aid in developing innovative assessments. Additionally, the paper identifies five challenges: academic integrity concerns, reliability issues, inability to evaluate and reinforce graduate skill sets, limitations in assessing learning outcomes, and potential biases and falsified information in information processing. The paper argues that tertiary educators and students must exercise caution when using ChatGPT for academic purposes to ensure its ethical, reliable, and effective use. To achieve this, the paper proposes various propositions, such as prioritising education on the responsible and ethical use of ChatGPT, devising new assessment strategies, addressing bias and falsified information, and including AI literacy as part of graduate skills. By balancing the potential benefits and challenges, ChatGPT can enhance students\u2019 learning experiences in higher education.",
    "doi": "10.37074/jalt.2023.6.1.29",
    "url": "https://openalex.org/W4376139682",
    "pdf_url": "https://journals.sfu.ca/jalt/index.php/jalt/article/download/787/583",
    "venue": "Journal of Applied Learning & Teaching",
    "citation_count": 486,
    "fields_of_study": [
      "Perspective (graphical)",
      "Higher education",
      "Engineering ethics",
      "Reliability (semiconductor)",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769805"
  },
  {
    "source": "openalex",
    "source_id": "W3115247823",
    "title": "Artificial intelligence for good health: a scoping review of the ethics literature",
    "authors": [
      "Kathleen Murphy",
      "Erica Di Ruggiero",
      "Ross Upshur",
      "Donald J. Willison",
      "Neha Malhotra",
      "Jia Cai",
      "Nakul Malhotra",
      "Vincci Lui",
      "Jennifer Gibson"
    ],
    "year": 2021,
    "abstract": "Abstract Background Artificial intelligence (AI) has been described as the \u201cfourth industrial revolution\u201d with transformative and global implications, including in healthcare, public health, and global health. AI approaches hold promise for improving health systems worldwide, as well as individual and population health outcomes. While AI may have potential for advancing health equity within and between countries, we must consider the ethical implications of its deployment in order to mitigate its potential harms, particularly for the most vulnerable. This scoping review addresses the following question: What ethical issues have been identified in relation to AI in the field of health, including from a global health perspective? Methods Eight electronic databases were searched for peer reviewed and grey literature published before April 2018 using the concepts of health, ethics, and AI, and their related terms. Records were independently screened by two reviewers and were included if they reported on AI in relation to health and ethics and were written in the English language. Data was charted on a piloted data charting form, and a descriptive and thematic analysis was performed. Results Upon reviewing 12,722 articles, 103 met the predetermined inclusion criteria. The literature was primarily focused on the ethics of AI in health care, particularly on carer robots, diagnostics, and precision medicine, but was largely silent on ethics of AI in public and population health. The literature highlighted a number of common ethical concerns related to privacy, trust, accountability and responsibility, and bias. Largely missing from the literature was the ethics of AI in global health, particularly in the context of low- and middle-income countries (LMICs). Conclusions The ethical issues surrounding AI in the field of health are both vast and complex. While AI holds the potential to improve health and health systems, our analysis suggests that its introduction should be approached with cautious optimism. The dearth of literature on the ethics of AI within LMICs, as well as in public health, also points to a critical need for further research into the ethical implications of AI within both global and public health, to ensure that its development and implementation is ethical for everyone, everywhere.",
    "doi": "10.1186/s12910-021-00577-8",
    "url": "https://openalex.org/W3115247823",
    "pdf_url": "https://bmcmedethics.biomedcentral.com/track/pdf/10.1186/s12910-021-00577-8",
    "venue": "BMC Medical Ethics",
    "citation_count": 367,
    "fields_of_study": [
      "Philosophy of medicine",
      "Public health",
      "Health care",
      "Population health",
      "Accountability"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769822"
  },
  {
    "source": "openalex",
    "source_id": "W3197232629",
    "title": "The growing field of digital psychiatry: current evidence and the future of apps, social media, chatbots, and virtual reality",
    "authors": [
      "John Torous",
      "Sandra Bucci",
      "Imogen Bell",
      "Lars Vedel Kessing",
      "Maria Faurholt\u2010Jepsen",
      "Pauline Whelan",
      "Andr\u00e9 F. Carvalho",
      "Matcheri S. Keshavan",
      "Jake Linardon",
      "Joseph Firth"
    ],
    "year": 2021,
    "abstract": "As the COVID\u201019 pandemic has largely increased the utilization of telehealth, mobile mental health technologies \u2013 such as smartphone apps, vir\u00adtual reality, chatbots, and social media \u2013 have also gained attention. These digital health technologies offer the potential of accessible and scalable interventions that can augment traditional care. In this paper, we provide a comprehensive update on the overall field of digital psychiatry, covering three areas. First, we outline the relevance of recent technological advances to mental health research and care, by detailing how smartphones, social media, artificial intelligence and virtual reality present new opportunities for \u201cdigital phenotyping\u201d and remote intervention. Second, we review the current evidence for the use of these new technological approaches across different mental health contexts, covering their emerging efficacy in self\u2010management of psychological well\u2010being and early intervention, along with more nascent research supporting their use in clinical management of long\u2010term psychiatric conditions \u2013 including major depression; anxiety, bipolar and psychotic disorders; and eating and substance use disorders \u2013 as well as in child and adolescent mental health care. Third, we discuss the most pressing challenges and opportunities towards real\u2010world implementation, using the Integrated Promoting Action on Research Implementation in Health Services (i\u2010PARIHS) framework to explain how the innovations themselves, the recipients of these innovations, and the context surrounding innovations all must be considered to facilitate their adoption and use in mental health care systems. We conclude that the new technological capabilities of smartphones, artificial intelligence, social media and virtual reality are already changing mental health care in unforeseen and exciting ways, each accompanied by an early but promising evidence base. We point out that further efforts towards strengthening implementation are needed, and detail the key issues at the patient, provider and policy levels which must now be addressed for digital health technologies to truly improve mental health research and treatment in the future.",
    "doi": "10.1002/wps.20883",
    "url": "https://openalex.org/W3197232629",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/wps.20883",
    "venue": "World Psychiatry",
    "citation_count": 956,
    "fields_of_study": [
      "Mental health",
      "Social media",
      "Context (archaeology)",
      "Psychological intervention",
      "Telemedicine"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769851"
  },
  {
    "source": "openalex",
    "source_id": "W4386714740",
    "title": "Ethics and discrimination in artificial intelligence-enabled recruitment practices",
    "authors": [
      "Zhisheng Chen"
    ],
    "year": 2023,
    "abstract": "Abstract This study aims to address the research gap on algorithmic discrimination caused by AI-enabled recruitment and explore technical and managerial solutions. The primary research approach used is a literature review. The findings suggest that AI-enabled recruitment has the potential to enhance recruitment quality, increase efficiency, and reduce transactional work. However, algorithmic bias results in discriminatory hiring practices based on gender, race, color, and personality traits. The study indicates that algorithmic bias stems from limited raw data sets and biased algorithm designers. To mitigate this issue, it is recommended to implement technical measures, such as unbiased dataset frameworks and improved algorithmic transparency, as well as management measures like internal corporate ethical governance and external oversight. Employing Grounded Theory, the study conducted survey analysis to collect firsthand data on respondents\u2019 experiences and perceptions of AI-driven recruitment applications and discrimination.",
    "doi": "10.1057/s41599-023-02079-x",
    "url": "https://openalex.org/W4386714740",
    "pdf_url": "https://www.nature.com/articles/s41599-023-02079-x.pdf",
    "venue": "Humanities and Social Sciences Communications",
    "citation_count": 277,
    "fields_of_study": [
      "Transparency (behavior)",
      "Computer science",
      "Corporate governance",
      "Big Five personality traits",
      "Raw data"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769875"
  },
  {
    "source": "openalex",
    "source_id": "W2988293491",
    "title": "The Chinese approach to artificial intelligence: an analysis of policy, ethics, and regulation",
    "authors": [
      "Huw Roberts",
      "Josh Cowls",
      "Jessica Morley",
      "Mariarosaria Taddeo",
      "Vincent Wang",
      "Luciano Floridi"
    ],
    "year": 2020,
    "abstract": "Abstract In July 2017, China\u2019s State Council released the country\u2019s strategy for developing artificial intelligence (AI), entitled \u2018New Generation Artificial Intelligence Development Plan\u2019 (\u65b0\u4e00\u4ee3\u4eba\u5de5\u667a\u80fd\u53d1\u5c55\u89c4\u5212). This strategy outlined China\u2019s aims to become the world leader in AI by 2030, to monetise AI into a trillion-yuan (ca. 150 billion dollars) industry, and to emerge as the driving force in defining ethical norms and standards for AI. Several reports have analysed specific aspects of China\u2019s AI policies or have assessed the country\u2019s technical capabilities. Instead, in this article, we focus on the socio-political background and policy debates that are shaping China\u2019s AI strategy. In particular, we analyse the main strategic areas in which China is investing in AI and the concurrent ethical debates that are delimiting its use. By focusing on the policy backdrop, we seek to provide a more comprehensive and critical understanding of China\u2019s AI policy by bringing together debates and analyses of a wide array of policy documents.",
    "doi": "10.1007/s00146-020-00992-2",
    "url": "https://openalex.org/W2988293491",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s00146-020-00992-2.pdf",
    "venue": "AI & Society",
    "citation_count": 485,
    "fields_of_study": [
      "China",
      "Politics",
      "State (computer science)",
      "Political science",
      "Applications of artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769888"
  },
  {
    "source": "openalex",
    "source_id": "W3161181201",
    "title": "Algorithms as work designers: How algorithmic management influences the design of jobs",
    "authors": [
      "Xavier Parent\u2010Rocheleau",
      "Sharon K. Parker"
    ],
    "year": 2021,
    "abstract": null,
    "doi": "10.1016/j.hrmr.2021.100838",
    "url": "https://openalex.org/W3161181201",
    "pdf_url": "https://www.sciencedirect.com/science/article/pii/S1053482221000176",
    "venue": "Human Resource Management Review",
    "citation_count": 285,
    "fields_of_study": [
      "Job design",
      "Computer science",
      "Sociotechnical system",
      "Workload",
      "Bridge (graph theory)"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769902"
  },
  {
    "source": "openalex",
    "source_id": "W4320040080",
    "title": "The Ethical Implications of Artificial Intelligence (AI) For Meaningful Work",
    "authors": [
      "Sarah Bankins",
      "Paul Formosa"
    ],
    "year": 2023,
    "abstract": "Abstract The increasing workplace use of artificially intelligent (AI) technologies has implications for the experience of meaningful human work. Meaningful work refers to the perception that one\u2019s work has worth, significance, or a higher purpose. The development and organisational deployment of AI is accelerating, but the ways in which this will support or diminish opportunities for meaningful work and the ethical implications of these changes remain under-explored. This conceptual paper is positioned at the intersection of the meaningful work and ethical AI literatures and offers a detailed assessment of the ways in which the deployment of AI can enhance or diminish employees\u2019 experiences of meaningful work. We first outline the nature of meaningful work and draw on philosophical and business ethics accounts to establish its ethical importance. We then explore the impacts of three paths of AI deployment (replacing some tasks, \u2018tending the machine\u2019, and amplifying human skills) across five dimensions constituting a holistic account of meaningful work, and finally assess the ethical implications. In doing so we help to contextualise the meaningful work literature for the era of AI, extend the ethical AI literature into the workplace, and conclude with a range of practical implications and future research directions.",
    "doi": "10.1007/s10551-023-05339-7",
    "url": "https://openalex.org/W4320040080",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10551-023-05339-7.pdf",
    "venue": "Journal of Business Ethics",
    "citation_count": 280,
    "fields_of_study": [
      "Business ethics",
      "Software deployment",
      "Work (physics)",
      "Engineering ethics",
      "Perception"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769904"
  },
  {
    "source": "openalex",
    "source_id": "W3014499801",
    "title": "How to Design AI for Social Good: Seven Essential Factors",
    "authors": [
      "Luciano Floridi",
      "Josh Cowls",
      "Thomas C. King",
      "Mariarosaria Taddeo"
    ],
    "year": 2020,
    "abstract": "Abstract The idea of artificial intelligence for social good (henceforth AI4SG) is gaining traction within information societies in general and the AI community in particular. It has the potential to tackle social problems through the development of AI-based solutions. Yet, to date, there is only limited understanding of what makes AI socially good in theory, what counts as AI4SG in practice, and how to reproduce its initial successes in terms of policies. This article addresses this gap by identifying seven ethical factors that are essential for future AI4SG initiatives. The analysis is supported by 27 case examples of AI4SG projects. Some of these factors are almost entirely novel to AI, while the significance of other factors is heightened by the use of AI. From each of these factors, corresponding best practices are formulated which, subject to context and balance, may serve as preliminary guidelines to ensure that well-designed AI is more likely to serve the social good.",
    "doi": "10.1007/s11948-020-00213-5",
    "url": "https://openalex.org/W3014499801",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s11948-020-00213-5.pdf",
    "venue": "Science and Engineering Ethics",
    "citation_count": 348,
    "fields_of_study": [
      "Philosophy of science",
      "Context (archaeology)",
      "Subject (documents)",
      "Engineering ethics",
      "Management science"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769922"
  },
  {
    "source": "openalex",
    "source_id": "W3046399757",
    "title": "A Research Agenda for Hybrid Intelligence: Augmenting Human Intellect With Collaborative, Adaptive, Responsible, and Explainable Artificial Intelligence",
    "authors": [
      "Zeynep Akata",
      "Dan Balliet",
      "Maarten de Rijke",
      "Frank Dignum",
      "Virginia Dignum",
      "Guszti Eiben",
      "Antske Fokkens",
      "Davide Grossi",
      "Koen V. Hindriks",
      "Holger H. Hoos",
      "Hayley Hung",
      "Catholijn M. Jonker",
      "Christof Monz",
      "Mark A. Neerincx",
      "Frans A. Oliehoek",
      "Henry Prakken",
      "Stefan Schlobach",
      "Linda van der Gaag",
      "Frank van Harmelen",
      "Herke van Hoof",
      "M. Birna van Riemsdijk",
      "Aimee van Wynsberghe",
      "Rineke Verbrugge",
      "Bart Verheij",
      "Piek Vossen",
      "Max Welling"
    ],
    "year": 2020,
    "abstract": "We define hybrid intelligence (HI) as the combination of human and machine intelligence, augmenting human intellect and capabilities instead of replacing them and achieving goals that were unreachable by either humans or machines. HI is an important new research focus for artificial intelligence, and we set a research agenda for HI by formulating four challenges.",
    "doi": "10.1109/mc.2020.2996587",
    "url": "https://openalex.org/W3046399757",
    "pdf_url": "https://ieeexplore.ieee.org/ielx7/2/9153282/09153877.pdf",
    "venue": "Computer",
    "citation_count": 335,
    "fields_of_study": [
      "Intellect",
      "Computer science",
      "Human intelligence",
      "Artificial intelligence",
      "Set (abstract data type)"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769942"
  },
  {
    "source": "openalex",
    "source_id": "W3014972121",
    "title": "Co-Designing Checklists to Understand Organizational Challenges and Opportunities around Fairness in AI",
    "authors": [
      "Michael Madaio",
      "Luke Stark",
      "Jennifer Wortman Vaughan",
      "Hanna Wallach"
    ],
    "year": 2020,
    "abstract": "Many organizations have published principles intended to guide the ethical development and deployment of AI systems; however, their abstract nature makes them difficult to operationalize. Some organizations have therefore produced AI ethics checklists, as well as checklists for more specific concepts, such as fairness, as applied to AI systems. But unless checklists are grounded in practitioners' needs, they may be misused. To understand the role of checklists in AI ethics, we conducted an iterative co-design process with 48 practitioners, focusing on fairness. We co-designed an AI fairness checklist and identified desiderata and concerns for AI fairness checklists in general. We found that AI fairness checklists could provide organizational infrastructure for formalizing ad-hoc processes and empowering individual advocates. We highlight aspects of organizational culture that may impact the efficacy of AI fairness checklists, and suggest future design directions.",
    "doi": "10.1145/3313831.3376445",
    "url": "https://openalex.org/W3014972121",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3313831.3376445",
    "venue": null,
    "citation_count": 370,
    "fields_of_study": [
      "Operationalization",
      "Checklist",
      "Knowledge management",
      "Process (computing)",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769950"
  },
  {
    "source": "openalex",
    "source_id": "W3129794348",
    "title": "The ethics of algorithms: key problems and solutions",
    "authors": [
      "Andreas Tsamados",
      "Nikita Aggarwal",
      "Josh Cowls",
      "Jessica Morley",
      "Huw Roberts",
      "Mariarosaria Taddeo",
      "Luciano Floridi"
    ],
    "year": 2021,
    "abstract": "Abstract Research on the ethics of algorithms has grown substantially over the past decade. Alongside the exponential development and application of machine learning algorithms, new ethical problems and solutions relating to their ubiquitous use in society have been proposed. This article builds on a review of the ethics of algorithms published in 2016 (Mittelstadt et al. Big Data Soc 3(2), 2016). The goals are to contribute to the debate on the identification and analysis of the ethical implications of algorithms, to provide an updated analysis of epistemic and normative concerns, and to offer actionable guidance for the governance of the design, development and deployment of algorithms.",
    "doi": "10.1007/s00146-021-01154-8",
    "url": "https://openalex.org/W3129794348",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s00146-021-01154-8.pdf",
    "venue": "AI & Society",
    "citation_count": 299,
    "fields_of_study": [
      "Normative",
      "Key (lock)",
      "Computer science",
      "Software deployment",
      "Corporate governance"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769963"
  },
  {
    "source": "openalex",
    "source_id": "W3164960502",
    "title": "Leveraging Artificial Intelligence in Marketing for Social Good\u2014An Ethical Perspective",
    "authors": [
      "Erik Hermann"
    ],
    "year": 2021,
    "abstract": null,
    "doi": "10.1007/s10551-021-04843-y",
    "url": "https://openalex.org/W3164960502",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10551-021-04843-y.pdf",
    "venue": "Journal of Business Ethics",
    "citation_count": 302,
    "fields_of_study": [
      "Business ethics",
      "Perspective (graphical)",
      "Interdependence",
      "Stakeholder",
      "Sociology"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769974"
  },
  {
    "source": "openalex",
    "source_id": "W4379010216",
    "title": "Reflection on whether Chat GPT should be banned by academia from the perspective of education and teaching",
    "authors": [
      "Hao Yu"
    ],
    "year": 2023,
    "abstract": "OPINION article Front. Psychol., 01 June 2023Sec. Educational Psychology Volume 14 - 2023 | https://doi.org/10.3389/fpsyg.2023.1181712",
    "doi": "10.3389/fpsyg.2023.1181712",
    "url": "https://openalex.org/W4379010216",
    "pdf_url": "https://www.frontiersin.org/articles/10.3389/fpsyg.2023.1181712/pdf",
    "venue": "Frontiers in Psychology",
    "citation_count": 357,
    "fields_of_study": [
      "Perspective (graphical)",
      "Psychology",
      "Reflection (computer programming)",
      "Medical education",
      "Engineering ethics"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769977"
  },
  {
    "source": "openalex",
    "source_id": "W2919720720",
    "title": "From Big Data to Precision Medicine",
    "authors": [
      "Tim Hulsen",
      "Saumya Shekhar Jamuar",
      "Alan R. Moody",
      "Jason H. Karnes",
      "Orsolya Varga",
      "Stine Hedensted",
      "Roberto Spreafico",
      "D Hafler",
      "Eoin McKinney"
    ],
    "year": 2019,
    "abstract": "For over a decade the term \"Big data\" has been used to describe the rapid increase in volume, variety and velocity of information available, not just in medical research but in almost every aspect of our lives. As scientists, we now have the capacity to rapidly generate, store and analyse data that, only a few years ago, would have taken many years to compile. However, \"Big data\" no longer means what it once did. The term has expanded and now refers not to just large data volume, but to our increasing ability to analyse and interpret those data. Tautologies such as \"data analytics\" and \"data science\" have emerged to describe approaches to the volume of available information as it grows ever larger. New methods dedicated to improving data collection, storage, cleaning, processing and interpretation continue to be developed, although not always by, or for, medical researchers. Exploiting new tools to extract meaning from large volume information has the potential to drive real change in clinical practice, from personalized therapy and intelligent drug design to population screening and electronic health record mining. As ever, where new technology promises \"Big Advances,\" significant challenges remain. Here we discuss both the opportunities and challenges posed to biomedical research by our increasing ability to tackle large datasets. Important challenges include the need for standardization of data content, format, and clinical definitions, a heightened need for collaborative networks with sharing of both data and expertise and, perhaps most importantly, a need to reconsider how and when analytic methodology is taught to medical researchers. We also set \"Big data\" analytics in context: recent advances may appear to promise a revolution, sweeping away conventional approaches to medical science. However, their real promise lies in their synergy with, not replacement of, classical hypothesis-driven methods. The generation of novel, data-driven hypotheses based on interpretable models will always require stringent validation and experimental testing. Thus, hypothesis-generating research founded on large datasets adds to, rather than replaces, traditional hypothesis driven science. Each can benefit from the other and it is through using both that we can improve clinical practice.",
    "doi": "10.3389/fmed.2019.00034",
    "url": "https://openalex.org/W2919720720",
    "pdf_url": "https://www.frontiersin.org/articles/10.3389/fmed.2019.00034/pdf",
    "venue": "Frontiers in Medicine",
    "citation_count": 449,
    "fields_of_study": [
      "Big data",
      "Data science",
      "Standardization",
      "Variety (cybernetics)",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769981"
  },
  {
    "source": "openalex",
    "source_id": "W4361002760",
    "title": "The Role of ChatGPT in Data Science: How AI-Assisted Conversational Interfaces Are Revolutionizing the Field",
    "authors": [
      "Hossein Hassani",
      "Emmanuel Sirimal Silva"
    ],
    "year": 2023,
    "abstract": "ChatGPT, a conversational AI interface that utilizes natural language processing and machine learning algorithms, is taking the world by storm and is the buzzword across many sectors today. Given the likely impact of this model on data science, through this perspective article, we seek to provide an overview of the potential opportunities and challenges associated with using ChatGPT in data science, provide readers with a snapshot of its advantages, and stimulate interest in its use for data science projects. The paper discusses how ChatGPT can assist data scientists in automating various aspects of their workflow, including data cleaning and preprocessing, model training, and result interpretation. It also highlights how ChatGPT has the potential to provide new insights and improve decision-making processes by analyzing unstructured data. We then examine the advantages of ChatGPT\u2019s architecture, including its ability to be fine-tuned for a wide range of language-related tasks and generate synthetic data. Limitations and issues are also addressed, particularly around concerns about bias and plagiarism when using ChatGPT. Overall, the paper concludes that the benefits outweigh the costs and ChatGPT has the potential to greatly enhance the productivity and accuracy of data science workflows and is likely to become an increasingly important tool for intelligence augmentation in the field of data science. ChatGPT can assist with a wide range of natural language processing tasks in data science, including language translation, sentiment analysis, and text classification. However, while ChatGPT can save time and resources compared to training a model from scratch, and can be fine-tuned for specific use cases, it may not perform well on certain tasks if it has not been specifically trained for them. Additionally, the output of ChatGPT may be difficult to interpret, which could pose challenges for decision-making in data science applications.",
    "doi": "10.3390/bdcc7020062",
    "url": "https://openalex.org/W4361002760",
    "pdf_url": "https://www.mdpi.com/2504-2289/7/2/62/pdf?version=1679985158",
    "venue": "Big Data and Cognitive Computing",
    "citation_count": 358,
    "fields_of_study": [
      "Computer science",
      "Data science",
      "Workflow",
      "Field (mathematics)",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:10.770018"
  },
  {
    "source": "openalex",
    "source_id": "W4253545088",
    "title": "The ARRIVE guidelines 2.0: updated guidelines for reporting animal research",
    "authors": [
      "Nathalie Percie du Sert",
      "Viki Hurst",
      "Amrita Ahluwalia",
      "Sabina Alam",
      "Marc T. Avey",
      "Monya Baker",
      "William J. Browne",
      "Alejandra Clark",
      "Innes C. Cuthill",
      "Ulrich Dirnagl",
      "Michael Emerson",
      "Paul Garner",
      "Stephen T. Holgate",
      "David W. Howells",
      "Natasha A. Karp",
      "Stanley E. Lazic",
      "Katie Lidster",
      "Catriona MacCallum",
      "Malcolm Macleod",
      "Esther J. Pearl",
      "Ole H. Petersen",
      "Frances Rawle",
      "Penny S. Reynolds",
      "Kieron Rooney",
      "Emily S. Sena",
      "Shai D. Silberberg",
      "Thomas Steckler",
      "Hanno W\u00fcrbel"
    ],
    "year": 2020,
    "abstract": "Abstract Reproducible science requires transparent reporting. The ARRIVE guidelines (Animal Research: Reporting of In Vivo Experiments) were originally developed in 2010 to improve the reporting of animal research. They consist of a checklist of information to include in publications describing in vivo experiments to enable others to scrutinise the work adequately, evaluate its methodological rigour, and reproduce the methods and results. Despite considerable levels of endorsement by funders and journals over the years, adherence to the guidelines has been inconsistent, and the anticipated improvements in the quality of reporting in animal research publications have not been achieved. Here, we introduce ARRIVE 2.0. The guidelines have been updated and information reorganised to facilitate their use in practice. We used a Delphi exercise to prioritise and divide the items of the guidelines into 2 sets, the \u2018ARRIVE Essential 10,\u2019 which constitutes the minimum requirement, and the \u2018Recommended Set,\u2019 which describes the research context. This division facilitates improved reporting of animal research by supporting a stepwise approach to implementation. This helps journal editors and reviewers verify that the most important items are being reported in manuscripts. We have also developed the accompanying Explanation and Elaboration document, which serves (1) to explain the rationale behind each item in the guidelines, (2) to clarify key concepts, and (3) to provide illustrative examples. We aim, through these changes, to help ensure that researchers, reviewers, and journal editors are better equipped to improve the rigour and transparency of the scientific process and thus reproducibility.",
    "doi": "10.1113/jp280389",
    "url": "https://openalex.org/W4253545088",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1113/JP280389",
    "venue": "The Journal of Physiology",
    "citation_count": 615,
    "fields_of_study": [
      "Rigour",
      "Checklist",
      "Transparency (behavior)",
      "Context (archaeology)",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:10.770050"
  },
  {
    "source": "openalex",
    "source_id": "W4386697749",
    "title": "A foundation model for generalizable disease detection from retinal images",
    "authors": [
      "Yukun Zhou",
      "Mark A. Chia",
      "Siegfried K. Wagner",
      "Murat Se\u00e7kin Ayhan",
      "Dominic J. Williamson",
      "Robbert Struyven",
      "Timing Liu",
      "Moucheng Xu",
      "Mateo Gende",
      "Peter Woodward-Court",
      "Yuka Kihara",
      "Naomi E. Allen",
      "John Gallacher",
      "Thomas J. Littlejohns",
      "Tariq Aslam",
      "Richard D. Unwin",
      "Graeme C. Black",
      "Panagiotis I. Sergouniotis",
      "Denize Atan",
      "Andrew D. Dick",
      "Cathy Williams",
      "Sarah Barman",
      "Jennifer H. Barrett",
      "Sarah Mackie",
      "Tasanee Braithwaite",
      "Roxana O. Carare",
      "Sarah Ennis",
      "Jane Whitney Gibson",
      "Andrew Lotery",
      "Jay Self",
      "Usha Chakravarthy",
      "Ruth Hogg",
      "Euan Paterson",
      "Jayne V. Woodside",
      "T\u00fcnde Pet\u0151",
      "Gareth J. McKay",
      "Bernadette McGuinness",
      "Paul J. Foster",
      "Konstantinos Balaskas",
      "Anthony P. Khawaja",
      "Nikolas Pontikos",
      "Jugnoo S. Rahi",
      "Gerassimos Lascaratos",
      "Praveen J. Patel",
      "Michelle Chan",
      "Sharon Chua",
      "Alexander Day",
      "Parul Desai",
      "Cathy Egan",
      "Marcus Fruttiger",
      "David F. Garway\u2010Heath",
      "Alison J. Hardcastle",
      "Peng T. Khaw",
      "Tony Moore",
      "Sobha Sivaprasad",
      "Nicholas G. Strouthidis",
      "Dhanes Thomas",
      "Adnan Tufail",
      "Ananth C. Viswanathan",
      "Bal Dhillon",
      "Tom MacGillivray",
      "Cathie Sudlow",
      "V\u00e9ronique Vitart",
      "Alex S. F. Doney",
      "Emanuele Trucco",
      "Jeremy A. Guggeinheim",
      "James P. Morgan",
      "Christopher J. Hammond",
      "Katie Williams",
      "Pirro G. Hysi",
      "Simon Harding",
      "Yalin Zheng",
      "Robert Luben",
      "Philip J. Luthert",
      "Zihan Sun",
      "Martin McKibbin",
      "Eoin O\u2019Sullivan",
      "Richard A. Oram",
      "Mike Weedon",
      "Christopher G. Owen",
      "Alicja R. Rudnicka",
      "Naveed Sattar",
      "David Steel",
      "Irene Stratton",
      "Robyn J. Tapp",
      "Max Yates",
      "Axel Petzold",
      "Savita Madhusudhan",
      "Andr\u00e9 Altmann",
      "Aaron Lee",
      "Eric J. Topol",
      "Alastair K. Denniston",
      "Daniel C. Alexander",
      "Pearse A. Keane"
    ],
    "year": 2023,
    "abstract": "Abstract Medical artificial intelligence (AI) offers great potential for recognizing signs of health conditions in retinal images and expediting the diagnosis of eye diseases and systemic disorders 1 . However, the development of AI models requires substantial annotation and models are usually task-specific with limited generalizability to different clinical applications 2 . Here, we present RETFound, a foundation model for retinal images that learns generalizable representations from unlabelled retinal images and provides a basis for label-efficient model adaptation in several applications. Specifically, RETFound is trained on 1.6 million unlabelled retinal images by means of self-supervised learning and then adapted to disease detection tasks with explicit labels. We show that adapted RETFound consistently outperforms several comparison models in the diagnosis and prognosis of sight-threatening eye diseases, as well as incident prediction of complex systemic disorders such as heart failure and myocardial infarction with fewer labelled data. RETFound provides a generalizable solution to improve model performance and alleviate the annotation workload of experts to enable broad clinical AI applications from retinal imaging.",
    "doi": "10.1038/s41586-023-06555-x",
    "url": "https://openalex.org/W4386697749",
    "pdf_url": "https://www.nature.com/articles/s41586-023-06555-x.pdf",
    "venue": "Nature",
    "citation_count": 663,
    "fields_of_study": [
      "Computer science",
      "Artificial intelligence",
      "Generalizability theory",
      "Retinal",
      "Machine learning"
    ],
    "retrieved_at": "2026-02-02T16:58:10.770099"
  },
  {
    "source": "openalex",
    "source_id": "W3011648816",
    "title": "Contributions and Risks of Artificial Intelligence (AI) in Building Smarter Cities: Insights from a Systematic Review of the Literature",
    "authors": [
      "Tan Yi\u011fitcanlar",
      "Kevin C. Desouza",
      "Luke Butler",
      "Farnoosh Roozkhosh"
    ],
    "year": 2020,
    "abstract": "Artificial intelligence (AI) is one of the most disruptive technologies of our time. Interest in the use of AI for urban innovation continues to grow. Particularly, the rise of smart cities\u2014urban locations that are enabled by community, technology, and policy to deliver productivity, innovation, livability, wellbeing, sustainability, accessibility, good governance, and good planning\u2014has increased the demand for AI-enabled innovations. There is, nevertheless, no scholarly work that provides a comprehensive review on the topic. This paper generates insights into how AI can contribute to the development of smarter cities. A systematic review of the literature is selected as the methodologic approach. Results are categorized under the main smart city development dimensions, i.e., economy, society, environment, and governance. The findings of the systematic review containing 93 articles disclose that: (a) AI in the context of smart cities is an emerging field of research and practice. (b) The central focus of the literature is on AI technologies, algorithms, and their current and prospective applications. (c) AI applications in the context of smart cities mainly concentrate on business efficiency, data analytics, education, energy, environmental sustainability, health, land use, security, transport, and urban management areas. (d) There is limited scholarly research investigating the risks of wider AI utilization. (e) Upcoming disruptions of AI in cities and societies have not been adequately examined. Current and potential contributions of AI to the development of smarter cities are outlined in this paper to inform scholars of prospective areas for further research.",
    "doi": "10.3390/en13061473",
    "url": "https://openalex.org/W3011648816",
    "pdf_url": "https://www.mdpi.com/1996-1073/13/6/1473/pdf?version=1585797303",
    "venue": "Energies",
    "citation_count": 474,
    "fields_of_study": [
      "Context (archaeology)",
      "Corporate governance",
      "Sustainability",
      "Smart city",
      "Systematic review"
    ],
    "retrieved_at": "2026-02-02T16:58:10.770131"
  },
  {
    "source": "openalex",
    "source_id": "W2972413052",
    "title": "Algorithmic management and app\u2010work in the gig economy: A research agenda for employment relations and HRM",
    "authors": [
      "James Duggan",
      "Ultan Sherman",
      "Ronan Carbery",
      "Anthony McDonnell"
    ],
    "year": 2019,
    "abstract": "Abstract Current understanding of what constitutes work in the growing gig economy is heavily conflated, ranging from conceptualisations of independent contracting to other forms of contingent labour. This article calls for a move away from problematic aggregations by proposing a classification of gig work into three variants, all based strongly upon key technological features: app\u2010work, crowdwork, and capital platform work. Focusing specifically on the app\u2010work variant, this article's more delineated focus on the textured dimensions of this work proposes new lines of enquiry into employment relationships and human resource management. Examining the crucial role of algorithmic management, we critically discuss the impact of this novel mediation tool used by gig organisations for the nature of employment relations within app\u2010work, work assignment processes, and performance management. In so doing, we propose a series of research questions that can serve as a guide for future research in this increasingly important field.",
    "doi": "10.1111/1748-8583.12258",
    "url": "https://openalex.org/W2972413052",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/1748-8583.12258",
    "venue": "Human Resource Management Journal",
    "citation_count": 780,
    "fields_of_study": [
      "Gig economy",
      "Work (physics)",
      "Conflation",
      "Mediation",
      "Human resource management"
    ],
    "retrieved_at": "2026-02-02T16:58:10.770181"
  },
  {
    "source": "openalex",
    "source_id": "W2973871066",
    "title": "Machine learning for clinical decision support in infectious diseases: a narrative review of current applications",
    "authors": [
      "Nathan Peiffer\u2010Smadja",
      "Timothy M. Rawson",
      "Raheelah Ahmad",
      "Albert Buchard",
      "Pantelis Georgiou",
      "Fran\u00e7ois-Xavier Lescure",
      "Gabriel Birgand",
      "Alison Holmes"
    ],
    "year": 2019,
    "abstract": "Considering comprehensive patient data from socioeconomically diverse healthcare settings, including primary care and LMICs, may improve the ability of ML-CDSS to suggest decisions adapted to various clinical contexts. Currents gaps identified in the evaluation of ML-CDSS must also be addressed in order to know the potential impact of such tools for clinicians and patients.",
    "doi": "10.1016/j.cmi.2019.09.009",
    "url": "https://openalex.org/W2973871066",
    "pdf_url": "http://www.clinicalmicrobiologyandinfection.com/article/S1198743X1930494X/pdf",
    "venue": "Clinical Microbiology and Infection",
    "citation_count": 505,
    "fields_of_study": [
      "Antimicrobial stewardship",
      "Clinical decision support system",
      "Medicine",
      "MEDLINE",
      "Sepsis"
    ],
    "retrieved_at": "2026-02-02T16:58:10.770210"
  },
  {
    "source": "openalex",
    "source_id": "W2969896603",
    "title": "A Survey on Bias and Fairness in Machine Learning",
    "authors": [
      "Ninareh Mehrabi",
      "Fred Morstatter",
      "Nripsuta Ani Saxena",
      "Kristina Lerman",
      "Aram Galstyan"
    ],
    "year": 2021,
    "abstract": "With the widespread use of artificial intelligence (AI) systems and applications in our everyday lives, accounting for fairness has gained significant importance in designing and engineering of such systems. AI systems can be used in many sensitive environments to make important and life-changing decisions; thus, it is crucial to ensure that these decisions do not reflect discriminatory behavior toward certain groups or populations. More recently some work has been developed in traditional machine learning and deep learning that address such challenges in different subdomains. With the commercialization of these systems, researchers are becoming more aware of the biases that these applications can contain and are attempting to address them. In this survey, we investigated different real-world applications that have shown biases in various ways, and we listed different sources of biases that can affect AI applications. We then created a taxonomy for fairness definitions that machine learning researchers have defined to avoid the existing bias in AI systems. In addition to that, we examined different domains and subdomains in AI showing what researchers have observed with regard to unfair outcomes in the state-of-the-art methods and ways they have tried to address them. There are still many future directions and solutions that can be taken to mitigate the problem of bias in AI systems. We are hoping that this survey will motivate researchers to tackle these issues in the near future by observing existing work in their respective fields.",
    "doi": "10.1145/3457607",
    "url": "https://openalex.org/W2969896603",
    "pdf_url": "https://arxiv.org/pdf/1908.09635",
    "venue": "ACM Computing Surveys",
    "citation_count": 316,
    "fields_of_study": [
      "Computer science",
      "Artificial intelligence",
      "Commercialization",
      "Data science",
      "Taxonomy (biology)"
    ],
    "retrieved_at": "2026-02-02T16:58:10.770220"
  },
  {
    "source": "openalex",
    "source_id": "W4386637335",
    "title": "Considerations for addressing bias in artificial intelligence for health equity",
    "authors": [
      "Michael D. Abr\u00e0moff",
      "Michelle E. Tarver",
      "Nilsa Loyo\u2010Berr\u00edos",
      "Sylvia Trujillo",
      "Danton Char",
      "Ziad Obermeyer",
      "Malvina Eydelman",
      "William H. Maisel"
    ],
    "year": 2023,
    "abstract": null,
    "doi": "10.1038/s41746-023-00913-9",
    "url": "https://openalex.org/W4386637335",
    "pdf_url": "https://www.nature.com/articles/s41746-023-00913-9.pdf",
    "venue": "npj Digital Medicine",
    "citation_count": 258,
    "fields_of_study": [
      "Equity (law)",
      "Health care",
      "Health equity",
      "Business",
      "Digital health"
    ],
    "retrieved_at": "2026-02-02T16:58:10.770243"
  },
  {
    "source": "openalex",
    "source_id": "W3026607820",
    "title": "Artificial intelligence ethics guidelines for developers and users: clarifying their content and normative implications",
    "authors": [
      "Mark Ryan",
      "Bernd Carsten Stahl"
    ],
    "year": 2020,
    "abstract": "Purpose The purpose of this paper is clearly illustrate this convergence and the prescriptive recommendations that such documents entail. There is a significant amount of research into the ethical consequences of artificial intelligence (AI). This is reflected by many outputs across academia, policy and the media. Many of these outputs aim to provide guidance to particular stakeholder groups. It has recently been shown that there is a large degree of convergence in terms of the principles upon which these guidance documents are based. Despite this convergence, it is not always clear how these principles are to be translated into practice. Design/methodology/approach In this paper, the authors move beyond the high-level ethical principles that are common across the AI ethics guidance literature and provide a description of the normative content that is covered by these principles. The outcome is a comprehensive compilation of normative requirements arising from existing guidance documents. This is not only required for a deeper theoretical understanding of AI ethics discussions but also for the creation of practical and implementable guidance for developers and users of AI. Findings In this paper, the authors therefore provide a detailed explanation of the normative implications of existing AI ethics guidelines but directed towards developers and organisational users of AI. The authors believe that the paper provides the most comprehensive account of ethical requirements in AI currently available, which is of interest not only to the research and policy communities engaged in the topic but also to the user communities that require guidance when developing or deploying AI systems. Originality/value The authors believe that they have managed to compile the most comprehensive document collecting existing guidance which can guide practical action but will hopefully also support the consolidation of the guidelines landscape. The authors\u2019 findings should also be of academic interest and inspire philosophical research on the consistency and justification of the various normative statements that can be found in the literature.",
    "doi": "10.1108/jices-12-2019-0138",
    "url": "https://openalex.org/W3026607820",
    "pdf_url": "https://www.emerald.com/insight/content/doi/10.1108/JICES-12-2019-0138/full/pdf?title=artificial-intelligence-ethics-guidelines-for-developers-and-users-clarifying-their-content-and-normative-implications",
    "venue": "Journal of Information Communication and Ethics in Society",
    "citation_count": 253,
    "fields_of_study": [
      "Normative",
      "Stakeholder",
      "Computer science",
      "Engineering ethics",
      "Convergence (economics)"
    ],
    "retrieved_at": "2026-02-02T16:58:10.770247"
  },
  {
    "source": "openalex",
    "source_id": "W4376643691",
    "title": "Biases in Large Language Models: Origins, Inventory, and Discussion",
    "authors": [
      "Roberto Navigli",
      "Simone Conia",
      "Bj\u00f6rn Ro\u00df"
    ],
    "year": 2023,
    "abstract": "In this article, we introduce and discuss the pervasive issue of bias in the large language models that are currently at the core of mainstream approaches to Natural Language Processing (NLP). We first introduce data selection bias, that is, the bias caused by the choice of texts that make up a training corpus. Then, we survey the different types of social bias evidenced in the text generated by language models trained on such corpora, ranging from gender to age, from sexual orientation to ethnicity, and from religion to culture. We conclude with directions focused on measuring, reducing, and tackling the aforementioned types of bias.",
    "doi": "10.1145/3597307",
    "url": "https://openalex.org/W4376643691",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3597307",
    "venue": "Journal of Data and Information Quality",
    "citation_count": 267,
    "fields_of_study": [
      "Computer science",
      "Mainstream",
      "Natural language processing",
      "Gender bias",
      "Selection (genetic algorithm)"
    ],
    "retrieved_at": "2026-02-02T16:58:10.770276"
  },
  {
    "source": "openalex",
    "source_id": "W4292731246",
    "title": "The uselessness of AI ethics",
    "authors": [
      "Luke Munn"
    ],
    "year": 2022,
    "abstract": "Abstract As the awareness of AI\u2019s power and danger has risen, the dominant response has been a turn to ethical principles. A flood of AI guidelines and codes of ethics have been released in both the public and private sector in the last several years. However, these are meaningless principles which are contested or incoherent, making them difficult to apply; they are isolated principles situated in an industry and education system which largely ignores ethics; and they are toothless principles which lack consequences and adhere to corporate agendas. For these reasons, I argue that AI ethical principles are useless, failing to mitigate the racial, social, and environmental damages of AI technologies in any meaningful sense. The result is a gap between high-minded principles and technological practice. Even when this gap is acknowledged and principles seek to be \u201coperationalized,\u201d the translation from complex social concepts to technical rulesets is non-trivial. In a zero-sum world, the dominant turn to AI principles is not just fruitless but a dangerous distraction, diverting immense financial and human resources away from potentially more effective activity. I conclude by highlighting alternative approaches to AI justice that go beyond ethical principles: thinking more broadly about systems of oppression and more narrowly about accuracy and auditing.",
    "doi": "10.1007/s43681-022-00209-w",
    "url": "https://openalex.org/W4292731246",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s43681-022-00209-w.pdf",
    "venue": "AI and Ethics",
    "citation_count": 271,
    "fields_of_study": [
      "Operationalization",
      "Oppression",
      "Engineering ethics",
      "Sociology",
      "Environmental ethics"
    ],
    "retrieved_at": "2026-02-02T16:58:10.770287"
  },
  {
    "source": "openalex",
    "source_id": "W3020975691",
    "title": "Explainable Deep Learning: A Field Guide for the Uninitiated",
    "authors": [
      "Gabri\u00eblle Ras",
      "Ning Xie",
      "Marcel van Gerven",
      "Derek Doran"
    ],
    "year": 2022,
    "abstract": "Deep neural networks (DNNs) are an indispensable machine learning tool despite the difficulty of diagnosing what aspects of a model\u2019s input drive its decisions. In countless real-world domains, from legislation and law enforcement to healthcare, such diagnosis is essential to ensure that DNN decisions are driven by aspects appropriate in the context of its use. The development of methods and studies enabling the explanation of a DNN\u2019s decisions has thus blossomed into an active and broad area of research. The field\u2019s complexity is exacerbated by competing definitions of what it means \u201cto explain\u201d the actions of a DNN and to evaluate an approach\u2019s \u201cability to explain\u201d. This article offers a field guide to explore the space of explainable deep learning for those in the AI/ML field who are uninitiated. The field guide: i) Introduces three simple dimensions defining the space of foundational methods that contribute to explainable deep learning, ii) discusses the evaluations for model explanations, iii) places explainability in the context of other related deep learning research areas, and iv) discusses user-oriented explanation design and future directions. We hope the guide is seen as a starting point for those embarking on this research field.",
    "doi": "10.1613/jair.1.13200",
    "url": "https://openalex.org/W3020975691",
    "pdf_url": "https://www.jair.org/index.php/jair/article/download/13200/26763",
    "venue": "Journal of Artificial Intelligence Research",
    "citation_count": 383,
    "fields_of_study": [
      "Field (mathematics)",
      "Deep learning",
      "Context (archaeology)",
      "Artificial intelligence",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:10.770306"
  },
  {
    "source": "openalex",
    "source_id": "W3025490408",
    "title": "AI for social good: unlocking the opportunity for positive impact",
    "authors": [
      "Nenad Toma\u0161ev",
      "Julien Cornebise",
      "Frank Hutter",
      "Shakir Mohamed",
      "Angela Picciariello",
      "Bec Connelly",
      "Danielle Belgrave",
      "Daphne Ezer",
      "Fanny Cachat van der Haert",
      "Frank Mugisha",
      "Gerald Abila",
      "Hiromi Arai",
      "Hisham Almiraat",
      "Julia Proskurnia",
      "Kyle Snyder",
      "Mihoko Otake",
      "Mustafa Othman",
      "Tobias Glasmachers",
      "Wilfried De Wever",
      "Yee Whye Teh",
      "Mohammad Emtiyaz Khan",
      "Ruben De Winne",
      "Tom Schaul",
      "Claudia Clopath"
    ],
    "year": 2020,
    "abstract": null,
    "doi": "10.1038/s41467-020-15871-z",
    "url": "https://openalex.org/W3025490408",
    "pdf_url": "https://www.nature.com/articles/s41467-020-15871-z.pdf",
    "venue": "Nature Communications",
    "citation_count": 313,
    "fields_of_study": [
      "Computer science",
      "Domain (mathematical analysis)",
      "Set (abstract data type)",
      "Sustainable development",
      "Key (lock)"
    ],
    "retrieved_at": "2026-02-02T16:58:10.770326"
  },
  {
    "source": "openalex",
    "source_id": "W4380319827",
    "title": "Regulating ChatGPT and other Large Generative AI Models",
    "authors": [
      "Philipp Hacker",
      "Andreas Engel",
      "Marco Mauer"
    ],
    "year": 2023,
    "abstract": "Large generative AI models (LGAIMs), such as ChatGPT, GPT-4 or Stable Diffusion, are rapidly transforming the way we communicate, illustrate, and create. However, AI regulation, in the EU and beyond, has primarily focused on conventional AI models, not LGAIMs. This paper will situate these new generative models in the current debate on trustworthy AI regulation, and ask how the law can be tailored to their capabilities. After laying technical foundations, the legal part of the paper proceeds in four steps, covering (1) direct regulation, (2) data protection, (3) content moderation, and (4) policy proposals. It suggests a novel terminology to capture the AI value chain in LGAIM settings by differentiating between LGAIM developers, deployers, professional and non-professional users, as well as recipients of LGAIM output. We tailor regulatory duties to these different actors along the value chain and suggest strategies to ensure that LGAIMs are trustworthy and deployed for the benefit of society at large. Rules in the AI Act and other direct regulation must match the specificities of pre-trained models. The paper argues for three layers of obligations concerning LGAIMs (minimum standards for all LGAIMs; high-risk obligations for high-risk use cases; collaborations along the AI value chain). In general, regulation should focus on concrete high-risk applications, and not the pre-trained model itself, and should include (i) obligations regarding transparency and (ii) risk management. Non-discrimination provisions (iii) may, however, apply to LGAIM developers. Lastly, (iv) the core of the DSA's content moderation rules should be expanded to cover LGAIMs. This includes notice and action mechanisms, and trusted flaggers.",
    "doi": "10.1145/3593013.3594067",
    "url": "https://openalex.org/W4380319827",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3593013.3594067",
    "venue": null,
    "citation_count": 376,
    "fields_of_study": [
      "Transparency (behavior)",
      "Generative grammar",
      "Computer science",
      "Terminology",
      "Generative model"
    ],
    "retrieved_at": "2026-02-02T16:58:10.770329"
  },
  {
    "source": "openalex",
    "source_id": "W3092843175",
    "title": "The Sustainability of Artificial Intelligence: An Urbanistic Viewpoint from the Lens of Smart and Sustainable Cities",
    "authors": [
      "Tan Yi\u011fitcanlar",
      "Federico Cugurullo"
    ],
    "year": 2020,
    "abstract": "The popularity and application of artificial intelligence (AI) are increasing rapidly all around the world\u2014where, in simple terms, AI is a technology which mimics the behaviors commonly associated with human intelligence. Today, various AI applications are being used in areas ranging from marketing to banking and finance, from agriculture to healthcare and security, from space exploration to robotics and transport, and from chatbots to artificial creativity and manufacturing. More recently, AI applications have also started to become an integral part of many urban services. Urban artificial intelligences manage the transport systems of cities, run restaurants and shops where every day urbanity is expressed, repair urban infrastructure, and govern multiple urban domains such as traffic, air quality monitoring, garbage collection, and energy. In the age of uncertainty and complexity that is upon us, the increasing adoption of AI is expected to continue, and so its impact on the sustainability of our cities. This viewpoint explores and questions the sustainability of AI from the lens of smart and sustainable cities, and generates insights into emerging urban artificial intelligences and the potential symbiosis between AI and a smart and sustainable urbanism. In terms of methodology, this viewpoint deploys a thorough review of the current status of AI and smart and sustainable cities literature, research, developments, trends, and applications. In so doing, it contributes to existing academic debates in the fields of smart and sustainable cities and AI. In addition, by shedding light on the uptake of AI in cities, the viewpoint seeks to help urban policymakers, planners, and citizens make informed decisions about a sustainable adoption of AI.",
    "doi": "10.3390/su12208548",
    "url": "https://openalex.org/W3092843175",
    "pdf_url": "https://www.mdpi.com/2071-1050/12/20/8548/pdf?version=1602816385",
    "venue": "Sustainability",
    "citation_count": 289,
    "fields_of_study": [
      "Sustainability",
      "Popularity",
      "Creativity",
      "Smart city",
      "Sustainable city"
    ],
    "retrieved_at": "2026-02-02T16:58:10.770351"
  },
  {
    "source": "openalex",
    "source_id": "W4229441880",
    "title": "Integrating Ethics and Career Futures with Technical Learning to Promote AI Literacy for Middle School Students: An Exploratory Study",
    "authors": [
      "Helen Zhang",
      "Irene Lee",
      "Safinah Ali",
      "Daniella DiPaola",
      "Yihong Cheng",
      "Cynthia Breazeal"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1007/s40593-022-00293-3",
    "url": "https://openalex.org/W4229441880",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s40593-022-00293-3.pdf",
    "venue": "International Journal of Artificial Intelligence in Education",
    "citation_count": 290,
    "fields_of_study": [
      "Futures contract",
      "Educational technology",
      "Exploratory research",
      "Literacy",
      "Mathematics education"
    ],
    "retrieved_at": "2026-02-02T16:58:10.770374"
  },
  {
    "source": "openalex",
    "source_id": "W4389359039",
    "title": "Generative artificial intelligence",
    "authors": [
      "Leonardo Banh",
      "Gero Strobel"
    ],
    "year": 2023,
    "abstract": null,
    "doi": "10.1007/s12525-023-00680-1",
    "url": "https://openalex.org/W4389359039",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s12525-023-00680-1.pdf",
    "venue": "Electronic Markets",
    "citation_count": 312,
    "fields_of_study": [
      "Generative grammar",
      "Computer science",
      "Artificial intelligence",
      "Field (mathematics)",
      "Generative model"
    ],
    "retrieved_at": "2026-02-02T16:58:10.770377"
  },
  {
    "source": "openalex",
    "source_id": "W4390608362",
    "title": "Transformative Potential of AI in Healthcare: Definitions, Applications, and Navigating the Ethical Landscape and Public Perspectives",
    "authors": [
      "Molly Bekbolatova",
      "Jonathan Mayer",
      "Chi Wei Ong",
      "Milan Toma"
    ],
    "year": 2024,
    "abstract": "Artificial intelligence (AI) has emerged as a crucial tool in healthcare with the primary aim of improving patient outcomes and optimizing healthcare delivery. By harnessing machine learning algorithms, natural language processing, and computer vision, AI enables the analysis of complex medical data. The integration of AI into healthcare systems aims to support clinicians, personalize patient care, and enhance population health, all while addressing the challenges posed by rising costs and limited resources. As a subdivision of computer science, AI focuses on the development of advanced algorithms capable of performing complex tasks that were once reliant on human intelligence. The ultimate goal is to achieve human-level performance with improved efficiency and accuracy in problem-solving and task execution, thereby reducing the need for human intervention. Various industries, including engineering, media/entertainment, finance, and education, have already reaped significant benefits by incorporating AI systems into their operations. Notably, the healthcare sector has witnessed rapid growth in the utilization of AI technology. Nevertheless, there remains untapped potential for AI to truly revolutionize the industry. It is important to note that despite concerns about job displacement, AI in healthcare should not be viewed as a threat to human workers. Instead, AI systems are designed to augment and support healthcare professionals, freeing up their time to focus on more complex and critical tasks. By automating routine and repetitive tasks, AI can alleviate the burden on healthcare professionals, allowing them to dedicate more attention to patient care and meaningful interactions. However, legal and ethical challenges must be addressed when embracing AI technology in medicine, alongside comprehensive public education to ensure widespread acceptance.",
    "doi": "10.3390/healthcare12020125",
    "url": "https://openalex.org/W4390608362",
    "pdf_url": "https://www.mdpi.com/2227-9032/12/2/125/pdf?version=1704440667",
    "venue": "Healthcare",
    "citation_count": 309,
    "fields_of_study": [
      "Transformative learning",
      "Health care",
      "Computer science",
      "Artificial intelligence",
      "Knowledge management"
    ],
    "retrieved_at": "2026-02-02T16:58:10.770380"
  },
  {
    "source": "openalex",
    "source_id": "W4386223224",
    "title": "Artificial intelligence in intelligent tutoring systems toward sustainable education: a systematic review",
    "authors": [
      "Chien-Chang Lin",
      "Anna Y.Q. Huang",
      "Owen H.T. Lu"
    ],
    "year": 2023,
    "abstract": null,
    "doi": "10.1186/s40561-023-00260-y",
    "url": "https://openalex.org/W4386223224",
    "pdf_url": "https://slejournal.springeropen.com/counter/pdf/10.1186/s40561-023-00260-y",
    "venue": "Smart Learning Environments",
    "citation_count": 359,
    "fields_of_study": [
      "Software deployment",
      "Computer science",
      "Knowledge management",
      "Sustainable development",
      "Political science"
    ],
    "retrieved_at": "2026-02-02T16:58:10.770402"
  },
  {
    "source": "openalex",
    "source_id": "W3037647569",
    "title": "Artificial intelligence in health care: laying the Foundation for Responsible, sustainable, and inclusive innovation in low- and middle-income countries",
    "authors": [
      "Hassane Alami",
      "Lysanne Rivard",
      "Pascale Lehoux",
      "Steven J. Hoffman",
      "St\u00e9phanie B.M. Cadeddu",
      "Mathilde Savoldelli",
      "M. Samri",
      "Mohamed Ali Ag Ahmed",
      "Richard Fleet",
      "Jean\u2010Paul Fortin"
    ],
    "year": 2020,
    "abstract": "Abstract The World Health Organization and other institutions are considering Artificial Intelligence (AI) as a technology that can potentially address some health system gaps, especially the reduction of global health inequalities in low- and middle-income countries (LMICs). However, because most AI-based health applications are developed and implemented in high-income countries, their use in LMICs contexts is recent and there is a lack of robust local evaluations to guide decision-making in low-resource settings. After discussing the potential benefits as well as the risks and challenges raised by AI-based health care, we propose five building blocks to guide the development and implementation of more responsible, sustainable, and inclusive AI health care technologies in LMICs.",
    "doi": "10.1186/s12992-020-00584-1",
    "url": "https://openalex.org/W3037647569",
    "pdf_url": "https://globalizationandhealth.biomedcentral.com/track/pdf/10.1186/s12992-020-00584-1",
    "venue": "Globalization and Health",
    "citation_count": 241,
    "fields_of_study": [
      "Low and middle income countries",
      "Health care",
      "Health services research",
      "Public health",
      "Global health"
    ],
    "retrieved_at": "2026-02-02T16:58:10.770406"
  },
  {
    "source": "openalex",
    "source_id": "W2948100573",
    "title": "The Challenges of Algorithm-Based HR Decision-Making for Personal Integrity",
    "authors": [
      "Ulrich Leicht\u2010Deobald",
      "Thorsten Busch",
      "Christoph Schank",
      "Antoinette Weibel",
      "Simon Daniel Schafheitle",
      "Isabelle Wildhaber",
      "Gabriel Kasper"
    ],
    "year": 2019,
    "abstract": null,
    "doi": "10.1007/s10551-019-04204-w",
    "url": "https://openalex.org/W2948100573",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10551-019-04204-w.pdf",
    "venue": "Journal of Business Ethics",
    "citation_count": 252,
    "fields_of_study": [
      "Business ethics",
      "Quality of Life Research",
      "Intersection (aeronautics)",
      "Compliance (psychology)",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:11.621954"
  },
  {
    "source": "openalex",
    "source_id": "W3207559276",
    "title": "The AI gambit: leveraging artificial intelligence to combat climate change\u2014opportunities, challenges, and recommendations",
    "authors": [
      "Josh Cowls",
      "Andreas Tsamados",
      "Mariarosaria Taddeo",
      "Luciano Floridi"
    ],
    "year": 2021,
    "abstract": null,
    "doi": "10.1007/s00146-021-01294-x",
    "url": "https://openalex.org/W3207559276",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s00146-021-01294-x.pdf",
    "venue": "AI & Society",
    "citation_count": 376,
    "fields_of_study": [
      "Greenhouse gas",
      "Climate change",
      "Carbon footprint",
      "European union",
      "Corporate governance"
    ],
    "retrieved_at": "2026-02-02T16:58:11.621968"
  },
  {
    "source": "openalex",
    "source_id": "W4387397415",
    "title": "Artificial intelligence \u2010 driven sustainable development: Examining organizational, technical, and processing approaches to achieving global goals",
    "authors": [
      "Ignat Kulkov",
      "Julia Kulkova",
      "Ren\u00e9 Rohrbeck",
      "Lo\u00efck Menvielle",
      "Valtteri Kaartemo",
      "Hannu Makkonen"
    ],
    "year": 2023,
    "abstract": "Abstract This study presents a comprehensive literature review using a systematic approach to explore the role of artificial intelligence (AI) in promoting sustainable development in line with the United Nations Sustainable Development Goals (SDGs). The systematic review approach was applied to collect and analyze topics, and the literature search was conducted in two stages, encompassing 57 articles that met the research requirements. Our analysis reveals that AI's contribution to sustainability is concentrated within three key areas: organizational, technical, and processing aspects. The organizational aspect focuses on the integration of AI in companies and industries, addressing barriers to implementation and the relationship between companies, partners, and customers. The technical aspect highlights the development of AI algorithms that can address global challenges and contribute to the growth of stability and development in society. The processing aspect emphasizes the internal transformation of companies, their business models, and strategies in response to AI integration. Our proposed conceptual model outlines the essential elements organizations must consider when incorporating AI into their sustainability efforts, such as strategic alignment, infrastructure development, change management, and continuous improvement. By addressing these critical aspects, organizations can harness the potential of AI to drive positive social, environmental, and economic outcomes, ultimately contributing to the achievement of the SDGs. The model serves as a comprehensive framework for organizations seeking to leverage AI for sustainable development, but it should be adapted to individual contexts to ensure its relevance and effectiveness.",
    "doi": "10.1002/sd.2773",
    "url": "https://openalex.org/W4387397415",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/sd.2773",
    "venue": "Sustainable Development",
    "citation_count": 264,
    "fields_of_study": [
      "Sustainable development",
      "Sustainability",
      "Leverage (statistics)",
      "Knowledge management",
      "Process management"
    ],
    "retrieved_at": "2026-02-02T16:58:11.621972"
  },
  {
    "source": "openalex",
    "source_id": "W3049452588",
    "title": "The National COVID Cohort Collaborative (N3C): Rationale, design, infrastructure, and deployment",
    "authors": [
      "Melissa Haendel",
      "Christopher G. Chute",
      "Tellen D. Bennett",
      "David Eichmann",
      "Justin Guinney",
      "Warren A. Kibbe",
      "Philip Payne",
      "Emily Pfaff",
      "Peter N. Robinson",
      "Joel Saltz",
      "Heidi Spratt",
      "Christine Suver",
      "John Wilbanks",
      "Adam Wilcox",
      "Andrew E. Williams",
      "Chunlei Wu",
      "Clair Blacketer",
      "Robert L. Bradford",
      "James J. Cimino",
      "Marshall Clark",
      "Evan W Colmenares",
      "Patricia A. Francis",
      "Davera Gabriel",
      "Alexis Graves",
      "Raju Hemadri",
      "Stephanie Hong",
      "George Hripscak",
      "Dazhi Jiao",
      "Jeffrey G. Klann",
      "Kristin Kostka",
      "Adam M Lee",
      "Harold P. Lehmann",
      "Lora Lingrey",
      "Robert Miller",
      "Michele Morris",
      "Shawn N. Murphy",
      "Karthik Natarajan",
      "Matvey B. Palchuk",
      "Usman Ullah Sheikh",
      "Harold R. Solbrig",
      "Shyam Visweswaran",
      "Anita Walden",
      "Kellie M Walters",
      "Griffin M. Weber",
      "Xiaohan Tanner Zhang",
      "Richard L. Zhu",
      "Benjamin Amor",
      "Andrew T. Girvin",
      "Amin Manna",
      "Nabeel Qureshi",
      "Michael G. Kurilla",
      "Sam Michael",
      "Lili Portilla",
      "Joni L. Rutter",
      "Christopher P. Austin",
      "Kenneth Gersing"
    ],
    "year": 2020,
    "abstract": "Abstract Objective Coronavirus disease 2019 (COVID-19) poses societal challenges that require expeditious data and knowledge sharing. Though organizational clinical data are abundant, these are largely inaccessible to outside researchers. Statistical, machine learning, and causal analyses are most successful with large-scale data beyond what is available in any given organization. Here, we introduce the National COVID Cohort Collaborative (N3C), an open science community focused on analyzing patient-level data from many centers. Materials and Methods The Clinical and Translational Science Award Program and scientific community created N3C to overcome technical, regulatory, policy, and governance barriers to sharing and harmonizing individual-level clinical data. We developed solutions to extract, aggregate, and harmonize data across organizations and data models, and created a secure data enclave to enable efficient, transparent, and reproducible collaborative analytics. Results Organized in inclusive workstreams, we created legal agreements and governance for organizations and researchers; data extraction scripts to identify and ingest positive, negative, and possible COVID-19 cases; a data quality assurance and harmonization pipeline to create a single harmonized dataset; population of the secure data enclave with data, machine learning, and statistical analytics tools; dissemination mechanisms; and a synthetic data pilot to democratize data access. Conclusions The N3C has demonstrated that a multisite collaborative learning health network can overcome barriers to rapidly build a scalable infrastructure incorporating multiorganizational clinical data for COVID-19 analytics. We expect this effort to save lives by enabling rapid collaboration among clinicians, researchers, and data scientists to identify treatments and specialized care and thereby reduce the immediate and long-term impacts of COVID-19.",
    "doi": "10.1093/jamia/ocaa196",
    "url": "https://openalex.org/W3049452588",
    "pdf_url": "https://academic.oup.com/jamia/article-pdf/28/3/427/37306721/ocaa196.pdf",
    "venue": "Journal of the American Medical Informatics Association",
    "citation_count": 565,
    "fields_of_study": [
      "Computer science",
      "Analytics",
      "Data governance",
      "Data sharing",
      "Data science"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622015"
  },
  {
    "source": "openalex",
    "source_id": "W4387457231",
    "title": "Harnessing the power of synthetic data in healthcare: innovation, application, and privacy",
    "authors": [
      "Mauro Giuffr\u00e8",
      "Dennis Shung"
    ],
    "year": 2023,
    "abstract": null,
    "doi": "10.1038/s41746-023-00927-3",
    "url": "https://openalex.org/W4387457231",
    "pdf_url": "https://www.nature.com/articles/s41746-023-00927-3.pdf",
    "venue": "npj Digital Medicine",
    "citation_count": 283,
    "fields_of_study": [
      "Big data",
      "Distrust",
      "Accountability",
      "Context (archaeology)",
      "Health care"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622041"
  },
  {
    "source": "openalex",
    "source_id": "W4220980752",
    "title": "The Role of Artificial Intelligence in Early Cancer Diagnosis",
    "authors": [
      "Benjamin Hunter",
      "Sumeet Hindocha",
      "Richard W. Lee"
    ],
    "year": 2022,
    "abstract": "Improving the proportion of patients diagnosed with early-stage cancer is a key priority of the World Health Organisation. In many tumour groups, screening programmes have led to improvements in survival, but patient selection and risk stratification are key challenges. In addition, there are concerns about limited diagnostic workforces, particularly in light of the COVID-19 pandemic, placing a strain on pathology and radiology services. In this review, we discuss how artificial intelligence algorithms could assist clinicians in (1) screening asymptomatic patients at risk of cancer, (2) investigating and triaging symptomatic patients, and (3) more effectively diagnosing cancer recurrence. We provide an overview of the main artificial intelligence approaches, including historical models such as logistic regression, as well as deep learning and neural networks, and highlight their early diagnosis applications. Many data types are suitable for computational analysis, including electronic healthcare records, diagnostic images, pathology slides and peripheral blood, and we provide examples of how these data can be utilised to diagnose cancer. We also discuss the potential clinical implications for artificial intelligence algorithms, including an overview of models currently used in clinical practice. Finally, we discuss the potential limitations and pitfalls, including ethical concerns, resource demands, data security and reporting standards.",
    "doi": "10.3390/cancers14061524",
    "url": "https://openalex.org/W4220980752",
    "pdf_url": "https://www.mdpi.com/2072-6694/14/6/1524/pdf?version=1647426117",
    "venue": "Cancers",
    "citation_count": 297,
    "fields_of_study": [
      "Artificial intelligence",
      "Medicine",
      "Computer science",
      "Data science",
      "Intensive care medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622043"
  },
  {
    "source": "openalex",
    "source_id": "W4392772072",
    "title": "AI in education: A review of personalized learning and educational technology",
    "authors": [
      "Oyebola Olusola Ayeni",
      "Nancy Mohd Al Hamad",
      "Onyebuchi Nneamaka Chisom",
      "Blessing Osawaru",
      "Ololade Elizabeth Adewusi"
    ],
    "year": 2024,
    "abstract": "The integration of Artificial Intelligence (AI) in education has ushered in a transformative era, redefining traditional teaching and learning methods. This review explores the multifaceted role of AI in education, with a particular focus on personalized learning and educational technology. The synergy between AI and education promises to address individualized needs, enhance student engagement, and optimize learning outcomes. Personalized learning, enabled by AI algorithms, tailors educational experiences to the unique needs, preferences, and pace of each student. This approach goes beyond a one-size-fits-all model, fostering a more inclusive and effective learning environment. The review delves into the diverse applications of AI-driven personalized learning, ranging from adaptive content delivery and real-time feedback to intelligent tutoring systems. It analyzes the impact of these technologies on student performance, highlighting the potential to narrow educational gaps and cater to diverse learning styles. Educational technology, powered by AI, extends beyond the classroom, encompassing online platforms, virtual reality, and interactive tools. The review explores the integration of AI in curriculum development, content creation, and assessment methods, offering insights into how these technologies augment the teaching and learning experience. Furthermore, the review examines the role of AI in automating administrative tasks, allowing educators to redirect their focus towards personalized instruction. Challenges and ethical considerations associated with the adoption of AI in education are also scrutinized. Privacy concerns, algorithmic biases, and the digital divide are discussed, emphasizing the importance of responsible AI implementation. The review underscores the need for collaborative efforts among educators, policymakers, and technologists to establish ethical guidelines and ensure the equitable distribution of AI-enhanced educational resources. This review provides a comprehensive examination of the evolving landscape of AI in education, with a spotlight on personalized learning and educational technology. As the symbiosis between AI and education continues to evolve, this synthesis of current research and trends aims to guide future developments, fostering an informed and progressive approach to the integration of AI in the educational sphere.",
    "doi": "10.30574/gscarr.2024.18.2.0062",
    "url": "https://openalex.org/W4392772072",
    "pdf_url": "https://gsconlinepress.com/journals/gscarr/sites/default/files/GSCARR-2024-0062.pdf",
    "venue": "GSC Advanced Research and Reviews",
    "citation_count": 276,
    "fields_of_study": [
      "Personalized learning",
      "Mathematics education",
      "Educational technology",
      "Computer science",
      "Psychology"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622060"
  },
  {
    "source": "openalex",
    "source_id": "W3081423662",
    "title": "Artificial intelligence in radiation oncology",
    "authors": [
      "Elizabeth Huynh",
      "Ahmed Hosny",
      "Christian V. Guthier",
      "Danielle S. Bitterman",
      "Steven Petit",
      "Daphne A. Haas\u2010Kogan",
      "Benjamin H. Kann",
      "Hugo J.W.L. Aerts",
      "Raymond H. Mak"
    ],
    "year": 2020,
    "abstract": null,
    "doi": "10.1038/s41571-020-0417-8",
    "url": "https://openalex.org/W3081423662",
    "pdf_url": "https://www.nature.com/articles/s41571-020-0417-8.pdf",
    "venue": "Nature Reviews Clinical Oncology",
    "citation_count": 373,
    "fields_of_study": [
      "Radiation oncology",
      "Medical physics",
      "Medicine",
      "Oncology",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622087"
  },
  {
    "source": "openalex",
    "source_id": "W4387340031",
    "title": "A Systematic Review of the Barriers to the Implementation of Artificial Intelligence in Healthcare",
    "authors": [
      "Molla Imaduddin Ahmed",
      "Brendan Spooner",
      "John Isherwood",
      "Mark A. Lane",
      "Emma Orrock",
      "Ashley R. Dennison"
    ],
    "year": 2023,
    "abstract": null,
    "doi": "10.7759/cureus.46454",
    "url": "https://openalex.org/W4387340031",
    "pdf_url": "https://assets.cureus.com/uploads/review_article/pdf/170025/20231004-24282-g79tke.pdf",
    "venue": "Cureus",
    "citation_count": 255,
    "fields_of_study": [
      "Health care",
      "Medicine",
      "Covert",
      "Healthcare delivery",
      "Workforce"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622090"
  },
  {
    "source": "openalex",
    "source_id": "W4200045082",
    "title": "AI in marketing, consumer research and psychology: A systematic literature review and research agenda",
    "authors": [
      "Marcello M. Mariani",
      "Rodrigo Perez\u2010Vega",
      "Jochen Wirtz"
    ],
    "year": 2021,
    "abstract": "Abstract This study is the first to provide an integrated view on the body of knowledge of artificial intelligence (AI) published in the marketing, consumer research, and psychology literature. By leveraging a systematic literature review using a data\u2010driven approach and quantitative methodology (including bibliographic coupling), this study provides an overview of the emerging intellectual structure of AI research in the three bodies of literature examined. We identified eight topical clusters: (1) memory and computational logic; (2) decision making and cognitive processes; (3) neural networks; (4) machine learning and linguistic analysis; (5) social media and text mining; (6) social media content analytics; (7) technology acceptance and adoption; and (8) big data and robots. Furthermore, we identified a total of 412 theoretical lenses used in these studies with the most frequently used being: (1) the unified theory of acceptance and use of technology; (2) game theory; (3) theory of mind; (4) theory of planned behavior; (5) computational theories; (6) behavioral reasoning theory; (7) decision theories; and (8) evolutionary theory. Finally, we propose a research agenda to advance the scholarly debate on AI in the three literatures studied with an emphasis on cross\u2010fertilization of theories used across fields, and neglected research topics.",
    "doi": "10.1002/mar.21619",
    "url": "https://openalex.org/W4200045082",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/mar.21619",
    "venue": "Psychology and Marketing",
    "citation_count": 484,
    "fields_of_study": [
      "Big data",
      "Consumer behaviour",
      "Social media",
      "Psychology",
      "Cognition"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622093"
  },
  {
    "source": "openalex",
    "source_id": "W4389636360",
    "title": "Can Large Language Models Transform Computational Social Science?",
    "authors": [
      "Caleb Ziems",
      "William A. Held",
      "Omar Ahmed Shaikh",
      "Jiaao Chen",
      "Zhehao Zhang",
      "Diyi Yang"
    ],
    "year": 2023,
    "abstract": "Abstract Large language models (LLMs) are capable of successfully performing many language processing tasks zero-shot (without training data). If zero-shot LLMs can also reliably classify and explain social phenomena like persuasiveness and political ideology, then LLMs could augment the computational social science (CSS) pipeline in important ways. This work provides a road map for using LLMs as CSS tools. Towards this end, we contribute a set of prompting best practices and an extensive evaluation pipeline to measure the zero-shot performance of 13 language models on 25 representative English CSS benchmarks. On taxonomic labeling tasks (classification), LLMs fail to outperform the best fine-tuned models but still achieve fair levels of agreement with humans. On free-form coding tasks (generation), LLMs produce explanations that often exceed the quality of crowdworkers\u2019 gold references. We conclude that the performance of today\u2019s LLMs can augment the CSS research pipeline in two ways: (1) serving as zero-shot data annotators on human annotation teams, and (2) bootstrapping challenging creative generation tasks (e.g., explaining the underlying attributes of a text). In summary, LLMs are posed to meaningfully participate in social science analysis in partnership with humans.",
    "doi": "10.1162/coli_a_00502",
    "url": "https://openalex.org/W4389636360",
    "pdf_url": "https://direct.mit.edu/coli/article-pdf/doi/10.1162/coli_a_00502/2191886/coli_a_00502.pdf",
    "venue": "Computational Linguistics",
    "citation_count": 354,
    "fields_of_study": [
      "Pipeline (software)",
      "Computer science",
      "Bootstrapping (finance)",
      "Set (abstract data type)",
      "Data science"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622110"
  },
  {
    "source": "openalex",
    "source_id": "W4319348251",
    "title": "Accountability in artificial intelligence: what it is and how it works",
    "authors": [
      "Claudio Novelli",
      "Mariarosaria Taddeo",
      "Luciano Floridi"
    ],
    "year": 2023,
    "abstract": "Abstract Accountability is a cornerstone of the governance of artificial intelligence (AI). However, it is often defined too imprecisely because its multifaceted nature and the sociotechnical structure of AI systems imply a variety of values, practices, and measures to which accountability in AI can refer. We address this lack of clarity by defining accountability in terms of answerability, identifying three conditions of possibility (authority recognition, interrogation, and limitation of power), and an architecture of seven features (context, range, agent, forum, standards, process, and implications). We analyze this architecture through four accountability goals (compliance, report, oversight, and enforcement). We argue that these goals are often complementary and that policy-makers emphasize or prioritize some over others depending on the proactive or reactive use of accountability and the missions of AI governance.",
    "doi": "10.1007/s00146-023-01635-y",
    "url": "https://openalex.org/W4319348251",
    "pdf_url": "https://doi.org/10.1007/s00146-023-01635-y",
    "venue": "AI & Society",
    "citation_count": 264,
    "fields_of_study": [
      "Accountability",
      "CLARITY",
      "Cornerstone",
      "Variety (cybernetics)",
      "Corporate governance"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622126"
  },
  {
    "source": "openalex",
    "source_id": "W4365504037",
    "title": "A survey on deep learning tools dealing with data scarcity: definitions, challenges, solutions, tips, and applications",
    "authors": [
      "Laith Alzubaidi",
      "Jinshuai Bai",
      "Aiman Al-Sabaawi",
      "Jos\u00e9 Santamar\u00eda",
      "A. S. Albahri",
      "Bashar Sami Nayyef Al-dabbagh",
      "Mohammed A. Fadhel",
      "Mohamed Manoufali",
      "Jinglan Zhang",
      "Ali H. Al\u2010Timemy",
      "Ye Duan",
      "Amjed Abdullah",
      "Laith Farhan",
      "Yi Lu",
      "Ashish Gupta",
      "Felix Albu",
      "Amin Abbosh",
      "Yuantong Gu"
    ],
    "year": 2023,
    "abstract": null,
    "doi": "10.1186/s40537-023-00727-2",
    "url": "https://openalex.org/W4365504037",
    "pdf_url": "https://journalofbigdata.springeropen.com/counter/pdf/10.1186/s40537-023-00727-2",
    "venue": "Journal Of Big Data",
    "citation_count": 658,
    "fields_of_study": [
      "Computer science",
      "Deep learning",
      "Artificial intelligence",
      "Machine learning",
      "Generalization"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622139"
  },
  {
    "source": "openalex",
    "source_id": "W3135354507",
    "title": "Developing Middle School Students' AI Literacy",
    "authors": [
      "Irene Lee",
      "Safinah Ali",
      "Baiyu Zhang",
      "Daniella DiPaola",
      "Cynthia Breazeal"
    ],
    "year": 2021,
    "abstract": "In this experience report, we describe an AI summer workshop designed to prepare middle school students to become informed citizens and critical consumers of AI technology and to develop their foundational knowledge and skills to support future endeavors as AI-empowered workers. The workshop featured the 30-hour \"Developing AI Literacy\" or DAILy curriculum that is grounded in literature on child development, ethics education, and career development. The participants in the workshop were students between the ages of 10 and 14; 87% were from underrepresented groups in STEM and Computing. In this paper we describe the online curriculum, its implementation during synchronous online workshop sessions in summer of 2020, and preliminary findings on student outcomes. We reflect on the successes and lessons we learned in terms of supporting students' engagement and conceptual learning of AI, shifting attitudes toward AI, and fostering conceptions of future selves as AI-enabled workers. We conclude with discussions of the affordances and barriers to bringing AI education to students from underrepresented groups in STEM and Computing.",
    "doi": "10.1145/3408877.3432513",
    "url": "https://openalex.org/W3135354507",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3408877.3432513",
    "venue": null,
    "citation_count": 223,
    "fields_of_study": [
      "Affordance",
      "Curriculum",
      "Literacy",
      "Mathematics education",
      "Pedagogy"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622142"
  },
  {
    "source": "openalex",
    "source_id": "W3009563704",
    "title": "Deep Learning for Cardiac Image Segmentation: A Review",
    "authors": [
      "Chen Chen",
      "Chen Qin",
      "Huaqi Qiu",
      "Giacomo Tarroni",
      "Jinming Duan",
      "Wenjia Bai",
      "Daniel Rueckert"
    ],
    "year": 2020,
    "abstract": "Deep learning has become the most widely used approach for cardiac image segmentation in recent years. In this paper, we provide a review of over 100 cardiac image segmentation papers using deep learning, which covers common imaging modalities including magnetic resonance imaging (MRI), computed tomography (CT), and ultrasound and major anatomical structures of interest (ventricles, atria, and vessels). In addition, a summary of publicly available cardiac image datasets and code repositories are included to provide a base for encouraging reproducible research. Finally, we discuss the challenges and limitations with current deep learning-based approaches (scarcity of labels, model generalizability across different domains, interpretability) and suggest potential directions for future research.",
    "doi": "10.3389/fcvm.2020.00025",
    "url": "https://openalex.org/W3009563704",
    "pdf_url": "https://www.frontiersin.org/articles/10.3389/fcvm.2020.00025/pdf",
    "venue": "Frontiers in Cardiovascular Medicine",
    "citation_count": 790,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:11.622156"
  },
  {
    "source": "openalex",
    "source_id": "W4308885870",
    "title": "Multimodal machine learning in precision health: A scoping review",
    "authors": [
      "Adrienne Kline",
      "Hanyin Wang",
      "Yikuan Li",
      "Saya R Dennis",
      "Meghan R. Hutch",
      "Zhenxing Xu",
      "Fei Wang",
      "Feixiong Cheng",
      "Yuan Luo"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1038/s41746-022-00712-8",
    "url": "https://openalex.org/W4308885870",
    "pdf_url": "https://www.nature.com/articles/s41746-022-00712-8.pdf",
    "venue": "npj Digital Medicine",
    "citation_count": 370,
    "fields_of_study": [
      "Computer science",
      "Artificial intelligence",
      "Machine learning",
      "Multimodal therapy",
      "Psychology"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622167"
  },
  {
    "source": "openalex",
    "source_id": "W2995872180",
    "title": "Medical education trends for future physicians in the era of advanced technology and artificial intelligence: an integrative review",
    "authors": [
      "Eui\u2010Ryoung Han",
      "Sanghee Yeo",
      "Min Jeong Kim",
      "Young\u2010Hee Lee",
      "Kwi Hwa Park",
      "HyeRin Roh"
    ],
    "year": 2019,
    "abstract": "Abstract Background Medical education must adapt to different health care contexts, including digitalized health care systems and a digital generation of students in a hyper-connected world. The aims of this study are to identify and synthesize the values that medical educators need to implement in the curricula and to introduce representative educational programs. Methods An integrative review was conducted to combine data from various research designs. We searched for articles on PubMed, Scopus, Web of Science, and EBSCO ERIC between 2011 and 2017. Key search terms were \u201cundergraduate medical education,\u201d \u201cfuture,\u201d \u201ctwenty-first century,\u201d \u201cmillennium,\u201d \u201ccurriculum,\u201d \u201cteaching,\u201d \u201clearning,\u201d and \u201cassessment.\u201d We screened and extracted them according to inclusion and exclusion criteria from titles and abstracts. All authors read the full texts and discussed them to reach a consensus about the themes and subthemes. Data appraisal was performed using a modified Hawker \u2018s evaluation form. Results Among the 7616 abstracts initially identified, 28 full-text articles were selected to reflect medical education trends and suggest suitable educational programs. The integrative themes and subthemes of future medical education are as follows: 1) a humanistic approach to patient safety that involves encouraging humanistic doctors and facilitating collaboration; 2) early experience and longitudinal integration by early exposure to patient-oriented integration and longitudinal integrated clerkships; 3) going beyond hospitals toward society by responding to changing community needs and showing respect for diversity; and 4) student-driven learning with advanced technology through active learning with individualization, social interaction, and resource accessibility. Conclusions This review integrated the trends in undergraduate medical education in readiness for the anticipated changes in medical environments. The detailed programs introduced in this study could be useful for medical educators in the development of curricula. Further research is required to integrate the educational trends into graduate and continuing medical education, and to investigate the status or effects of innovative educational programs in each medical school or environment.",
    "doi": "10.1186/s12909-019-1891-5",
    "url": "https://openalex.org/W2995872180",
    "pdf_url": "https://bmcmededuc.biomedcentral.com/track/pdf/10.1186/s12909-019-1891-5",
    "venue": "BMC Medical Education",
    "citation_count": 364,
    "fields_of_study": [
      "Curriculum",
      "Medical education",
      "Inclusion (mineral)",
      "Scopus",
      "Diversity (politics)"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622169"
  },
  {
    "source": "openalex",
    "source_id": "W3029725182",
    "title": "Ethical principles in machine learning and artificial intelligence: cases from the field and possible ways forward",
    "authors": [
      "Samuele Lo Piano"
    ],
    "year": 2020,
    "abstract": "Abstract Decision-making on numerous aspects of our daily lives is being outsourced to machine-learning (ML) algorithms and artificial intelligence (AI), motivated by speed and efficiency in the decision process. ML approaches\u2014one of the typologies of algorithms underpinning artificial intelligence\u2014are typically developed as black boxes. The implication is that ML code scripts are rarely scrutinised; interpretability is usually sacrificed in favour of usability and effectiveness. Room for improvement in practices associated with programme development have also been flagged along other dimensions, including inter alia fairness, accuracy, accountability, and transparency. In this contribution, the production of guidelines and dedicated documents around these themes is discussed. The following applications of AI-driven decision-making are outlined: (a) risk assessment in the criminal justice system, and (b) autonomous vehicles, highlighting points of friction across ethical principles. Possible ways forward towards the implementation of governance on AI are finally examined.",
    "doi": "10.1057/s41599-020-0501-9",
    "url": "https://openalex.org/W3029725182",
    "pdf_url": "https://www.nature.com/articles/s41599-020-0501-9.pdf",
    "venue": "Humanities and Social Sciences Communications",
    "citation_count": 216,
    "fields_of_study": [
      "Accountability",
      "Interpretability",
      "Transparency (behavior)",
      "Underpinning",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622195"
  },
  {
    "source": "openalex",
    "source_id": "W4388333366",
    "title": "Generative Artificial Intelligence: Implications and Considerations for Higher Education Practice",
    "authors": [
      "Tom Farrelly",
      "Nick Baker"
    ],
    "year": 2023,
    "abstract": "Generative Artificial Intelligence (GAI) has emerged as a transformative force in higher education, offering both challenges and opportunities. This paper explores the multifaceted impact of GAI on academic work, with a focus on student life and, in particular, the implications for international students. While GAI, exemplified by models like ChatGPT, has the potential to revolutionize education, concerns about academic integrity have arisen, leading to debates on the use of AI detection tools. This essay highlights the difficulties in reliably detecting AI-generated content, raising concerns about potential false accusations against students. It also discusses biases within AI models, emphasizing the need for fairness and equity in AI-based assessments with a particular emphasis on the disproportionate impact of GAI on international students, who already face biases and discrimination. It also highlights the potential for AI to mitigate some of these challenges by providing language support and accessibility features. Finally, this essay acknowledges the disruptive potential of GAI in higher education and calls for a balanced approach that addresses both the challenges and opportunities it presents by emphasizing the importance of AI literacy and ethical considerations in adopting AI technologies to ensure equitable access and positive outcomes for all students. We offer a coda to Ng et al.\u2019s AI competency framework, mapped to the Revised Bloom\u2019s Taxonomy, through a lens of cultural competence with AI as a means of supporting educators to use these tools equitably in their teaching.",
    "doi": "10.3390/educsci13111109",
    "url": "https://openalex.org/W4388333366",
    "pdf_url": "https://www.mdpi.com/2227-7102/13/11/1109/pdf?version=1699079828",
    "venue": "Education Sciences",
    "citation_count": 294,
    "fields_of_study": [
      "Transformative learning",
      "Generative grammar",
      "Engineering ethics",
      "Competence (human resources)",
      "Equity (law)"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622209"
  },
  {
    "source": "openalex",
    "source_id": "W4392769984",
    "title": "A scoping review of artificial intelligence in medical education: BEME Guide No. 84",
    "authors": [
      "Morris Gordon",
      "Michelle Daniel",
      "Aderonke Ajiboye",
      "Hussein Uraiby",
      "Nicole Y. Xu",
      "Rangana Bartlett",
      "Janice L. Hanson",
      "Mary R. Haas",
      "Maxwell Spadafore",
      "Ciaran Grafton\u2010Clarke",
      "Rayhan Yousef Gasiea",
      "Colin Michie",
      "Janet Corral",
      "Brian Kwan",
      "Diana Dolmans",
      "Satid Thammasitboon"
    ],
    "year": 2024,
    "abstract": "The current literature has been charted. The findings underscore the need for ongoing research to explore uncharted areas and address potential risks associated with AI use in medical education. This work serves as a foundational resource for educators, policymakers, and researchers in navigating AI's evolving role in medical education. A framework to support future high utility reporting is proposed, the FACETS framework.",
    "doi": "10.1080/0142159x.2024.2314198",
    "url": "https://openalex.org/W4392769984",
    "pdf_url": "https://www.tandfonline.com/doi/pdf/10.1080/0142159X.2024.2314198?needAccess=true",
    "venue": "Medical Teacher",
    "citation_count": 289,
    "fields_of_study": [
      "MEDLINE",
      "Medical education",
      "Thematic analysis",
      "Systematic review",
      "Psychology"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622229"
  },
  {
    "source": "openalex",
    "source_id": "W4296405185",
    "title": "Power to the People? Opportunities and Challenges for Participatory AI",
    "authors": [
      "Abeba Birhane",
      "William M. Isaac",
      "Vinodkumar Prabhakaran",
      "Mark D\u00edaz",
      "Madeleine Clare Elish",
      "Iason Gabriel",
      "Shakir Mohamed"
    ],
    "year": 2022,
    "abstract": "Participatory approaches to artificial intelligence (AI) and machine learning\\n(ML) are gaining momentum: the increased attention comes partly with the view\\nthat participation opens the gateway to an inclusive, equitable, robust,\\nresponsible and trustworthy AI.Among other benefits, participatory approaches\\nare essential to understanding and adequately representing the needs, desires\\nand perspectives of historically marginalized communities. However, there\\ncurrently exists lack of clarity on what meaningful participation entails and\\nwhat it is expected to do. In this paper we first review participatory\\napproaches as situated in historical contexts as well as participatory methods\\nand practices within the AI and ML pipeline. We then introduce three case\\nstudies in participatory AI.Participation holds the potential for beneficial,\\nemancipatory and empowering technology design, development and deployment while\\nalso being at risk for concerns such as cooptation and conflation with other\\nactivities. We lay out these limitations and concerns and argue that as\\nparticipatory AI/ML becomes in vogue, a contextual and nuanced understanding of\\nthe term as well as consideration of who the primary beneficiaries of\\nparticipatory activities ought to be constitute crucial factors to realizing\\nthe benefits and opportunities that participation brings.\\n",
    "doi": "10.1145/3551624.3555290",
    "url": "https://openalex.org/W4296405185",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3551624.3555290",
    "venue": null,
    "citation_count": 233,
    "fields_of_study": [
      "Citizen journalism",
      "Participatory GIS",
      "Sociology",
      "Software deployment",
      "Participatory evaluation"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622237"
  },
  {
    "source": "openalex",
    "source_id": "W3164718925",
    "title": "Considering the possibilities and pitfalls of Generative Pre-trained Transformer 3 (GPT-3) in healthcare delivery",
    "authors": [
      "Diane M. Korngiebel",
      "Sean D. Mooney"
    ],
    "year": 2021,
    "abstract": "Natural language computer applications are becoming increasingly sophisticated and, with the recent release of Generative Pre-trained Transformer 3, they could be deployed in healthcare-related contexts that have historically comprised human-to-human interaction. However, for GPT-3 and similar applications to be considered for use in health-related contexts, possibilities and pitfalls need thoughtful exploration. In this article, we briefly introduce some opportunities and cautions that would accompany advanced Natural Language Processing applications deployed in eHealth.",
    "doi": "10.1038/s41746-021-00464-x",
    "url": "https://openalex.org/W3164718925",
    "pdf_url": "https://www.nature.com/articles/s41746-021-00464-x.pdf",
    "venue": "npj Digital Medicine",
    "citation_count": 253,
    "fields_of_study": [
      "Generative grammar",
      "Transformer",
      "eHealth",
      "Computer science",
      "Health care"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622252"
  },
  {
    "source": "openalex",
    "source_id": "W4391006361",
    "title": "A meta systematic review of artificial intelligence in higher education: a call for increased ethics, collaboration, and rigour",
    "authors": [
      "Melissa Bond",
      "Hassan Khosravi",
      "Maarten de Laat",
      "Nina Bergdahl",
      "Violeta Negrea",
      "Emily Oxley",
      "Phuong Pham",
      "Sin Wang Chong",
      "George Siemens"
    ],
    "year": 2024,
    "abstract": null,
    "doi": "10.1186/s41239-023-00436-z",
    "url": "https://openalex.org/W4391006361",
    "pdf_url": "https://educationaltechnologyjournal.springeropen.com/counter/pdf/10.1186/s41239-023-00436-z",
    "venue": "International Journal of Educational Technology in Higher Education",
    "citation_count": 381,
    "fields_of_study": [
      "Systematic review",
      "Rigour",
      "Higher education",
      "Profiling (computer programming)",
      "Scopus"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622260"
  },
  {
    "source": "openalex",
    "source_id": "W4410381134",
    "title": "Human Rights and Artificial Intelligence in Healthcare-Related Settings: A Grammar of Human Rights Approach",
    "authors": [
      "Helga Molb\u00e6k-Steensig",
      "Martin Scheinin"
    ],
    "year": 2025,
    "abstract": "Abstract This article examines the expanding role of Artificial Intelligence ( AI ) in healthcare and associated human rights concerns, including whether new EU legislation takes all relevant human rights concerns into account. AI presents promising ways to fulfil the right to health through improving diagnostics, treatments, and resource allocation, but its use also comes with risks concerning privacy, bias, discrimination, and human dignity. Existing literature often relies on the rather vague FATE (Fairness, Accountability, Transparency, Ethics) principles, but recent calls have been made for a human-rights-based approach more broadly to ensure the legality and ethics of AI applications. This article responds to that call by proposing a structured methodology for reconciling rights, considering both the different structures of civil and political versus economic, social and cultural human rights, the negative and positive obligations of the state, and the interplay with different AI design choices.",
    "doi": "10.1163/15718093-bja10146",
    "url": "https://openalex.org/W4410381134",
    "pdf_url": "https://hdl.handle.net/1814/93650",
    "venue": "European Journal of Health Law",
    "citation_count": 1,
    "fields_of_study": [
      "Human rights",
      "Dignity",
      "Principle of legality",
      "Accountability",
      "Law and economics"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622262"
  },
  {
    "source": "openalex",
    "source_id": "W3094948551",
    "title": "CatBoost for big data: an interdisciplinary review",
    "authors": [
      "John Hancock",
      "Taghi M. Khoshgoftaar"
    ],
    "year": 2020,
    "abstract": null,
    "doi": "10.1186/s40537-020-00369-8",
    "url": "https://openalex.org/W3094948551",
    "pdf_url": "https://journalofbigdata.springeropen.com/track/pdf/10.1186/s40537-020-00369-8",
    "venue": "Journal Of Big Data",
    "citation_count": 1435,
    "fields_of_study": [
      "Computer science",
      "Machine learning",
      "Artificial intelligence",
      "Decision tree",
      "Categorical variable"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622275"
  },
  {
    "source": "openalex",
    "source_id": "W4387966489",
    "title": "The value of standards for health datasets in artificial intelligence-based applications",
    "authors": [
      "Anmol Arora",
      "Joseph Alderman",
      "Joanne Palmer",
      "Shaswath Ganapathi",
      "Elinor Laws",
      "Melissa D. McCradden",
      "Lauren Oakden\u2010Rayner",
      "Stephen Pfohl",
      "Marzyeh Ghassemi",
      "Francis McKay",
      "Darren Treanor",
      "Negar Rostamzadeh",
      "Bilal A. Mateen",
      "Jacqui Gath",
      "Adewole O. Adebajo",
      "Stephanie Kuku",
      "Rubeta Matin",
      "Katherine Heller",
      "Elizabeth Sapey",
      "Neil J. Sebire",
      "Heather Cole-Lewis",
      "Melanie Calvert",
      "Alastair K. Denniston",
      "Xiaoxuan Liu"
    ],
    "year": 2023,
    "abstract": null,
    "doi": "10.1038/s41591-023-02608-w",
    "url": "https://openalex.org/W4387966489",
    "pdf_url": "https://www.nature.com/articles/s41591-023-02608-w.pdf",
    "venue": "Nature Medicine",
    "citation_count": 223,
    "fields_of_study": [
      "Best practice",
      "Data science",
      "Diversity (politics)",
      "Health care",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622279"
  },
  {
    "source": "openalex",
    "source_id": "W3131580611",
    "title": "Responsible Urban Innovation with Local Government Artificial Intelligence (AI): A Conceptual Framework and Research Agenda",
    "authors": [
      "Tan Yi\u011fitcanlar",
      "Juan M. Corchado",
      "Rashid Mehmood",
      "Rita Yi Man Li",
      "Karen Mossberger",
      "Kevin C. Desouza"
    ],
    "year": 2021,
    "abstract": null,
    "doi": "10.3390/joitmc7010071",
    "url": "https://openalex.org/W3131580611",
    "pdf_url": "https://www.mdpi.com/2199-8531/7/1/71/pdf",
    "venue": "Journal of Open Innovation Technology Market and Complexity",
    "citation_count": 212,
    "fields_of_study": [
      "Government (linguistics)",
      "Urbanization",
      "Futures contract",
      "Conceptual framework",
      "Management science"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622281"
  },
  {
    "source": "openalex",
    "source_id": "W3168386798",
    "title": "A panoramic view and swot analysis of artificial intelligence for achieving the sustainable development goals by 2030: progress and prospects",
    "authors": [
      "Iv\u00e1n Palomares",
      "Eugenio Mart\u00ednez\u2010C\u00e1mara",
      "Rosana Montes",
      "Pablo Garc\u00eda-Moral",
      "Manuel Chiach\u00edo",
      "Juan Chiach\u00edo",
      "Sergio Alonso",
      "Francisco Javier Melero",
      "Daniel Molina",
      "B\u00e1rbara Cables Fern\u00e1ndez",
      "Cristina Moral Santaella",
      "Rosario Marchena",
      "Javier P\u00e9rez de Vargas",
      "Francisco Herrera"
    ],
    "year": 2021,
    "abstract": null,
    "doi": "10.1007/s10489-021-02264-y",
    "url": "https://openalex.org/W3168386798",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10489-021-02264-y.pdf",
    "venue": "Applied Intelligence",
    "citation_count": 235,
    "fields_of_study": [
      "SWOT analysis",
      "Blueprint",
      "Prosperity",
      "Sustainable development",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622285"
  },
  {
    "source": "openalex",
    "source_id": "W4282027681",
    "title": "A Survey on the Fairness of Recommender Systems",
    "authors": [
      "Yifan Wang",
      "Weizhi Ma",
      "Min Zhang",
      "Yiqun Liu",
      "Shaoping Ma"
    ],
    "year": 2022,
    "abstract": "Recommender systems are an essential tool to relieve the information overload challenge and play an important role in people\u2019s daily lives. Since recommendations involve allocations of social resources (e.g., job recommendation), an important issue is whether recommendations are fair. Unfair recommendations are not only unethical but also harm the long-term interests of the recommender system itself. As a result, fairness issues in recommender systems have recently attracted increasing attention. However, due to multiple complex resource allocation processes and various fairness definitions, the research on fairness in recommendation is scattered. To fill this gap, we review over 60 papers published in top conferences/journals, including TOIS, SIGIR, and WWW. First, we summarize fairness definitions in the recommendation and provide several views to classify fairness issues. Then, we review recommendation datasets and measurements in fairness studies and provide an elaborate taxonomy of fairness methods in the recommendation. Finally, we conclude this survey by outlining some promising future directions.",
    "doi": "10.1145/3547333",
    "url": "https://openalex.org/W4282027681",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3547333",
    "venue": "ACM Transactions on Information Systems",
    "citation_count": 286,
    "fields_of_study": [
      "Recommender system",
      "Computer science",
      "Information retrieval",
      "World Wide Web"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622287"
  },
  {
    "source": "openalex",
    "source_id": "W3135371071",
    "title": "Towards Accountability for Machine Learning Datasets: Practices from Software Engineering and Infrastructure",
    "authors": [
      "Ben Hutchinson",
      "Andrew Smart",
      "Alex Hanna",
      "Emily Denton",
      "Christina Greer",
      "Oddur Kjartansson",
      "Parker Barnes",
      "Margaret Mitchell"
    ],
    "year": 2021,
    "abstract": "Datasets that power machine learning are often used, shared, and reused with little visibility into the processes of deliberation that led to their creation. As artificial intelligence systems are increasingly used in high-stakes tasks, system development and deployment practices must be adapted to address the very real consequences of how model development data is constructed and used in practice. This includes greater transparency about data, and accountability for decisions made when developing it. In this paper, we introduce a rigorous framework for dataset development transparency that supports decision-making and accountability. The framework uses the cyclical, infrastructural and engineering nature of dataset development to draw on best practices from the software development lifecycle. Each stage of the data development lifecycle yields documents that facilitate improved communication and decision-making, as well as drawing attention to the value and necessity of careful data work. The proposed framework makes visible the often overlooked work and decisions that go into dataset creation, a critical step in closing the accountability gap in artificial intelligence and a critical/necessary resource aligned with recent work on auditing processes.",
    "doi": "10.1145/3442188.3445918",
    "url": "https://openalex.org/W3135371071",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3442188.3445918",
    "venue": null,
    "citation_count": 222,
    "fields_of_study": [
      "Accountability",
      "Computer science",
      "Transparency (behavior)",
      "Software deployment",
      "Deliberation"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622301"
  },
  {
    "source": "openalex",
    "source_id": "W3199196172",
    "title": "Putting AI ethics to work: are the tools fit for purpose?",
    "authors": [
      "Jacqui Ayling",
      "Adriane Chapman"
    ],
    "year": 2021,
    "abstract": "Abstract Bias, unfairness and lack of transparency and accountability in Artificial Intelligence (AI) systems, and the potential for the misuse of predictive models for decision-making have raised concerns about the ethical impact and unintended consequences of new technologies for society across every sector where data-driven innovation is taking place. This paper reviews the landscape of suggested ethical frameworks with a focus on those which go beyond high-level statements of principles and offer practical tools for application of these principles in the production and deployment of systems. This work provides an assessment of these practical frameworks with the lens of known best practices for impact assessment and audit of technology. We review other historical uses of risk assessments and audits and create a typology that allows us to compare current AI ethics tools to Best Practices found in previous methodologies from technology, environment, privacy, finance and engineering. We analyse current AI ethics tools and their support for diverse stakeholders and components of the AI development and deployment lifecycle as well as the types of tools used to facilitate use. From this, we identify gaps in current AI ethics tools in auditing and risk assessment that should be considered going forward.",
    "doi": "10.1007/s43681-021-00084-x",
    "url": "https://openalex.org/W3199196172",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s43681-021-00084-x.pdf",
    "venue": "AI and Ethics",
    "citation_count": 209,
    "fields_of_study": [
      "Audit",
      "Transparency (behavior)",
      "Software deployment",
      "Accountability",
      "Unintended consequences"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622316"
  },
  {
    "source": "openalex",
    "source_id": "W4383737134",
    "title": "A Survey on Large Language Models: Applications, Challenges, Limitations, and Practical Usage",
    "authors": [
      "Muhammad Usman Hadi",
      "qasem al tashi",
      "Rizwan Qureshi",
      "Abbas Shah",
      "Amgad Muneer",
      "Muhammad Irfan",
      "Anas Zafar",
      "Muhammad Bilal Shaikh",
      "Naveed Akhtar",
      "Jia Wu",
      "Seyedali Mirjalili"
    ],
    "year": 2023,
    "abstract": "&lt;p&gt;Within the vast expanse of computerized language processing, a revolutionary entity known as Large Language Models (LLMs) has emerged, wielding immense power in its capacity to comprehend intricate linguistic patterns and conjure coherent and contextually fitting responses. Large language models (LLMs) are a type of artificial intelligence (AI) that have emerged as powerful tools for a wide range of tasks, including natural language processing (NLP), machine translation, and question-answering. This survey paper provides a comprehensive overview of LLMs, including their history, architecture, training methods, applications, and challenges. The paper begins by discussing the fundamental concepts of generative AI and the architecture of generative pre- trained transformers (GPT). It then provides an overview of the history of LLMs, their evolution over time, and the different training methods that have been used to train them. The paper then discusses the wide range of applications of LLMs, including medical, education, finance, and engineering. It also discusses how LLMs are shaping the future of AI and how they can be used to solve real-world problems. The paper then discusses the challenges associated with deploying LLMs in real-world scenarios, including ethical considerations, model biases, interpretability, and computational resource requirements. It also highlights techniques for enhancing the robustness and controllability of LLMs, and addressing bias, fairness, and generation quality issues. Finally, the paper concludes by highlighting the future of LLM research and the challenges that need to be addressed in order to make LLMs more reliable and useful. This survey paper is intended to provide researchers, practitioners, and enthusiasts with a comprehensive understanding of LLMs, their evolution, applications, and challenges. By consolidating the state-of-the-art knowledge in the field, this survey serves as a valuable resource for further advancements in the development and utilization of LLMs for a wide range of real-world applications. The GitHub repo for this project is available at https://github.com/anas-zafar/LLM-Survey&lt;/p&gt;",
    "doi": "10.36227/techrxiv.23589741.v1",
    "url": "https://openalex.org/W4383737134",
    "pdf_url": "https://www.techrxiv.org/doi/pdf/10.36227/techrxiv.23589741.v1",
    "venue": null,
    "citation_count": 327,
    "fields_of_study": [
      "Interpretability",
      "Computer science",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622332"
  },
  {
    "source": "openalex",
    "source_id": "W4327672398",
    "title": "Speculative futures on ChatGPT and generative artificial intelligence (AI): A collective reflection from the educational landscape",
    "authors": [
      "Aras Bozkurt",
      "J. Xiao",
      "Steven Imanuel Lambert",
      "A. Pazurek",
      "H. Crompton",
      "S. Koseoglu",
      "Robert Farrow",
      "Melissa Bond",
      "Chrissi Nerantzi",
      "Selina Honeychurch",
      "Maha Bali",
      "Jon Dron",
      "Kamran Mir",
      "Bonnie Stewart",
      "Eamon Costello",
      "Jon Mason",
      "Christian M. Stracke",
      "E. Romero-Hall",
      "A. Koutropoulos",
      "C. M. Toquero",
      "L. Singh",
      "A. Tlili",
      "Kyungmee Lee",
      "Mark Nichols",
      "E. Ossiannilsson",
      "M. Brown",
      "V. Irvine",
      "Juliana Elisa Raffaghelli",
      "G. Santos-Hermosa",
      "Orna Farrell",
      "T. Adam",
      "Y. L. Thong",
      "S. Sani-Bozkurt",
      "R. C. Sharma",
      "Stefan Hrastinski",
      "Petar Jandri\u0107"
    ],
    "year": 2023,
    "abstract": "While ChatGPT has recently become very popular, AI has a long history and philosophy. This paper intends to explore the promises and pitfalls of the Generative Pre-trained Transformer (GPT) AI and potentially future technologies by adopting a speculative methodology. Speculative future narratives with a specific focus on educational contexts are provided in an attempt to identify emerging themes and discuss their implications for education in the 21st century. Affordances of (using) AI in Education (AIEd) and possible adverse effects are identified and discussed which emerge from the narratives. It is argued that now is the best of times to define human vs AI contribution to education because AI can accomplish more and more educational activities that used to be the prerogative of human educators. Therefore, it is imperative to rethink the respective roles of technology and human educators in education with a future-oriented mindset.",
    "doi": "10.5281/zenodo.7636568",
    "url": "https://openalex.org/W4327672398",
    "pdf_url": "https://eprints.gla.ac.uk/294292/1/294292.pdf",
    "venue": "Enlighten: Publications (The University of Glasgow)",
    "citation_count": 315,
    "fields_of_study": [
      "Futures contract",
      "Reflection (computer programming)",
      "Generative grammar",
      "Collective intelligence",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622359"
  },
  {
    "source": "openalex",
    "source_id": "W4389794809",
    "title": "Guiding Principles to Address the Impact of Algorithm Bias on Racial and Ethnic Disparities in Health and Health Care",
    "authors": [
      "Marshall H. Chin",
      "Nasim Afsarmanesh",
      "Arlene S. Bierman",
      "Christine Chang",
      "Caleb J. Col\u00f3n-Rodr\u00edguez",
      "Prashila Dullabh",
      "Deborah Duran",
      "Malika Fair",
      "Tina Hernandez\u2010Boussard",
      "Maia Hightower",
      "Anjali Jain",
      "William B. Jordan",
      "Stephen Konya",
      "Roslyn Holliday Moore",
      "Tamra Tyree Moore",
      "Richard Rodriguez",
      "Gauher Shaheen",
      "Lynne Page Snyder",
      "Mithuna Srinivasan",
      "Craig A. Umscheid",
      "Lucila Ohno\u2010Machado"
    ],
    "year": 2023,
    "abstract": "Importance Health care algorithms are used for diagnosis, treatment, prognosis, risk stratification, and allocation of resources. Bias in the development and use of algorithms can lead to worse outcomes for racial and ethnic minoritized groups and other historically marginalized populations such as individuals with lower income. Objective To provide a conceptual framework and guiding principles for mitigating and preventing bias in health care algorithms to promote health and health care equity. Evidence Review The Agency for Healthcare Research and Quality and the National Institute for Minority Health and Health Disparities convened a diverse panel of experts to review evidence, hear from stakeholders, and receive community feedback. Findings The panel developed a conceptual framework to apply guiding principles across an algorithm\u2019s life cycle, centering health and health care equity for patients and communities as the goal, within the wider context of structural racism and discrimination. Multiple stakeholders can mitigate and prevent bias at each phase of the algorithm life cycle, including problem formulation (phase 1); data selection, assessment, and management (phase 2); algorithm development, training, and validation (phase 3); deployment and integration of algorithms in intended settings (phase 4); and algorithm monitoring, maintenance, updating, or deimplementation (phase 5). Five principles should guide these efforts: (1) promote health and health care equity during all phases of the health care algorithm life cycle; (2) ensure health care algorithms and their use are transparent and explainable; (3) authentically engage patients and communities during all phases of the health care algorithm life cycle and earn trustworthiness; (4) explicitly identify health care algorithmic fairness issues and trade-offs; and (5) establish accountability for equity and fairness in outcomes from health care algorithms. Conclusions and Relevance Multiple stakeholders must partner to create systems, processes, regulations, incentives, standards, and policies to mitigate and prevent algorithmic bias. Reforms should implement guiding principles that support promotion of health and health care equity in all phases of the algorithm life cycle as well as transparency and explainability, authentic community engagement and ethical partnerships, explicit identification of fairness issues and trade-offs, and accountability for equity and fairness.",
    "doi": "10.1001/jamanetworkopen.2023.45050",
    "url": "https://openalex.org/W4389794809",
    "pdf_url": "https://jamanetwork.com/journals/jamanetworkopen/articlepdf/2812958/chin_2023_sc_230007_1702050468.82841.pdf",
    "venue": "JAMA Network Open",
    "citation_count": 176,
    "fields_of_study": [
      "Health equity",
      "Health care",
      "Algorithm",
      "Ethnic group",
      "Health policy"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622373"
  },
  {
    "source": "openalex",
    "source_id": "W3196248941",
    "title": "Five sources of bias in natural language processing",
    "authors": [
      "Dirk Hovy",
      "Shrimai Prabhumoye"
    ],
    "year": 2021,
    "abstract": "Abstract Recently, there has been an increased interest in demographically grounded bias in natural language processing (NLP) applications. Much of the recent work has focused on describing bias and providing an overview of bias in a larger context. Here, we provide a simple, actionable summary of this recent work. We outline five sources where bias can occur in NLP systems: (1) the data, (2) the annotation process, (3) the input representations, (4) the models, and finally (5) the research design (or how we conceptualize our research). We explore each of the bias sources in detail in this article, including examples and links to related work, as well as potential counter\u2010measures.",
    "doi": "10.1111/lnc3.12432",
    "url": "https://openalex.org/W3196248941",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/lnc3.12432",
    "venue": "Language and Linguistics Compass",
    "citation_count": 253,
    "fields_of_study": [
      "Computer science",
      "Context (archaeology)",
      "Natural language processing",
      "Natural (archaeology)",
      "Process (computing)"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622402"
  },
  {
    "source": "openalex",
    "source_id": "W4280488363",
    "title": "Reporting guideline for the early stage clinical evaluation of decision support systems driven by artificial intelligence: DECIDE-AI",
    "authors": [
      "Baptiste Vasey",
      "Myura Nagendran",
      "Bruce Campbell",
      "David A. Clifton",
      "Gary S. Collins",
      "Spiros Denaxas",
      "Alastair K. Denniston",
      "Livia Faes",
      "Bart Geerts",
      "Mudathir Ibrahim",
      "Xiaoxuan Liu",
      "Bilal A. Mateen",
      "Piyush Mathur",
      "Melissa D. McCradden",
      "Lauren Morgan",
      "Johan Ordish",
      "Campbell Rogers",
      "Suchi Saria",
      "Daniel Shu Wei Ting",
      "Peter Watkinson",
      "Wim Weber",
      "Peter Wheatstone",
      "Peter McCulloch"
    ],
    "year": 2022,
    "abstract": "A growing number of artificial intelligence (AI)-based clinical decision support systems are showing promising performance in preclinical, in silico evaluation, but few have yet demonstrated real benefit to patient care. Early-stage clinical evaluation is important to assess an AI system's actual clinical performance at small scale, ensure its safety, evaluate the human factors surrounding its use and pave the way to further large-scale trials. However, the reporting of these early studies remains inadequate. The present statement provides a multi-stakeholder, consensus-based reporting guideline for the Developmental and Exploratory Clinical Investigations of DEcision support systems driven by Artificial Intelligence (DECIDE-AI). We conducted a two-round, modified Delphi process to collect and analyze expert opinion on the reporting of early clinical evaluation of AI systems. Experts were recruited from 20 pre-defined stakeholder categories. The final composition and wording of the guideline was determined at a virtual consensus meeting. The checklist and the Explanation &amp; Elaboration (E&amp;E) sections were refined based on feedback from a qualitative evaluation process. In total, 123 experts participated in the first round of Delphi, 138 in the second round, 16 in the consensus meeting and 16 in the qualitative evaluation. The DECIDE-AI reporting guideline comprises 17 AI-specific reporting items (made of 28 subitems) and ten generic reporting items, with an E&amp;E paragraph provided for each. Through consultation and consensus with a range of stakeholders, we developed a guideline comprising key items that should be reported in early-stage clinical studies of AI-based decision support systems in healthcare. By providing an actionable checklist of minimal reporting items, the DECIDE-AI guideline will facilitate the appraisal of these studies and replicability of their findings.",
    "doi": "10.1136/bmj-2022-070904",
    "url": "https://openalex.org/W4280488363",
    "pdf_url": "https://www.bmj.com/content/bmj/377/bmj-2022-070904.full.pdf",
    "venue": "BMJ",
    "citation_count": 269,
    "fields_of_study": [
      "Guideline",
      "Checklist",
      "Delphi method",
      "Decision support system",
      "Clinical decision support system"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622415"
  },
  {
    "source": "openalex",
    "source_id": "W4386711999",
    "title": "The GenAI is out of the bottle: generative artificial intelligence from a business model innovation perspective",
    "authors": [
      "Dominik K. Kanbach",
      "Louisa Heiduk",
      "Georg Blueher",
      "Maximilian Schreiter",
      "Alexander Lahmann"
    ],
    "year": 2023,
    "abstract": null,
    "doi": "10.1007/s11846-023-00696-z",
    "url": "https://openalex.org/W4386711999",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s11846-023-00696-z.pdf",
    "venue": "Review of Managerial Science",
    "citation_count": 328,
    "fields_of_study": [
      "Variety (cybernetics)",
      "Perspective (graphical)",
      "Generative grammar",
      "Business model",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622436"
  },
  {
    "source": "openalex",
    "source_id": "W4295854586",
    "title": "Explainable Artificial Intelligence Applications in Cyber Security: State-of-the-Art in Research",
    "authors": [
      "Zhibo Zhang",
      "Hussam Al Hamadi",
      "Ernesto Damiani",
      "Chan Yeob Yeun",
      "Fatma Taher"
    ],
    "year": 2022,
    "abstract": "This survey presents a comprehensive review of current literature on\\nExplainable Artificial Intelligence (XAI) methods for cyber security\\napplications. Due to the rapid development of Internet-connected systems and\\nArtificial Intelligence in recent years, Artificial Intelligence including\\nMachine Learning (ML) and Deep Learning (DL) has been widely utilized in the\\nfields of cyber security including intrusion detection, malware detection, and\\nspam filtering. However, although Artificial Intelligence-based approaches for\\nthe detection and defense of cyber attacks and threats are more advanced and\\nefficient compared to the conventional signature-based and rule-based cyber\\nsecurity strategies, most ML-based techniques and DL-based techniques are\\ndeployed in the black-box manner, meaning that security experts and customers\\nare unable to explain how such procedures reach particular conclusions. The\\ndeficiencies of transparency and interpretability of existing Artificial\\nIntelligence techniques would decrease human users' confidence in the models\\nutilized for the defense against cyber attacks, especially in current\\nsituations where cyber attacks become increasingly diverse and complicated.\\nTherefore, it is essential to apply XAI in the establishment of cyber security\\nmodels to create more explainable models while maintaining high accuracy and\\nallowing human users to comprehend, trust, and manage the next generation of\\ncyber defense mechanisms. Although there are papers reviewing Artificial\\nIntelligence applications in cyber security areas and the vast literature on\\napplying XAI in many fields including healthcare, financial services, and\\ncriminal justice, the surprising fact is that there are currently no survey\\nresearch articles that concentrate on XAI applications in cyber security.\\n",
    "doi": "10.1109/access.2022.3204051",
    "url": "https://openalex.org/W4295854586",
    "pdf_url": "https://ieeexplore.ieee.org/ielx7/6287639/6514899/09875264.pdf",
    "venue": "IEEE Access",
    "citation_count": 322,
    "fields_of_study": [
      "Computer science",
      "Computer security",
      "State (computer science)",
      "Artificial intelligence",
      "Data science"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622439"
  },
  {
    "source": "openalex",
    "source_id": "W4283156811",
    "title": "The Fallacy of AI Functionality",
    "authors": [
      "Inioluwa Deborah Raji",
      "I. Elizabeth Kumar",
      "Aaron Horowitz",
      "Andrew D. Selbst"
    ],
    "year": 2022,
    "abstract": "Deployed AI systems often do not work. They can be constructed haphazardly,\\ndeployed indiscriminately, and promoted deceptively. However, despite this\\nreality, scholars, the press, and policymakers pay too little attention to\\nfunctionality. This leads to technical and policy solutions focused on\\n\"ethical\" or value-aligned deployments, often skipping over the prior question\\nof whether a given system functions, or provides any benefits at all. To\\ndescribe the harms of various types of functionality failures, we analyze a set\\nof case studies to create a taxonomy of known AI functionality issues. We then\\npoint to policy and organizational responses that are often overlooked and\\nbecome more readily available once functionality is drawn into focus. We argue\\nthat functionality is a meaningful AI policy challenge, operating as a\\nnecessary first step towards protecting affected communities from algorithmic\\nharm.\\n",
    "doi": "10.1145/3531146.3533158",
    "url": "https://openalex.org/W4283156811",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3531146.3533158",
    "venue": "2022 ACM Conference on Fairness, Accountability, and Transparency",
    "citation_count": 197,
    "fields_of_study": [
      "Fallacy",
      "Harm",
      "Computer science",
      "Set (abstract data type)",
      "Value (mathematics)"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622457"
  },
  {
    "source": "openalex",
    "source_id": "W4313313935",
    "title": "Engineering Education in the Era of ChatGPT: Promise and Pitfalls of Generative AI for Education",
    "authors": [
      "Junaid Qadir"
    ],
    "year": 2022,
    "abstract": "&lt;p&gt;Engineering education is constantly evolving to keep up with the latest technological developments and meet the changing needs of the engineering industry. One promising development in this field is the use of generative artificial intelligence technology, such as the ChatGPT conversational agent. ChatGPT has the potential to offer personalized and effective learning experiences by providing students with customized feedback and explanations, as well as creating realistic virtual simulations for hands-on learning. However, it is important to also consider the limitations of this technology. ChatGPT and other generative AI systems are only as good as their training data and may perpetuate biases or even generate and spread misinformation. Additionally, the use of generative AI in education raises ethical concerns such as the potential for unethical or dishonest use by students and the potential unemployment of humans who are made redundant by technology. While the current state of generative AI technology represented by ChatGPT is impressive but flawed, it is only a preview of what is to come. It is important for engineering educators to understand the implications of this technology and study how to adapt the engineering education ecosystem to ensure that the next generation of engineers can take advantage of the benefits offered by generative AI while minimizing any negative consequences.&lt;/p&gt;",
    "doi": "10.36227/techrxiv.21789434.v1",
    "url": "https://openalex.org/W4313313935",
    "pdf_url": "https://www.techrxiv.org/articles/preprint/Engineering_Education_in_the_Era_of_ChatGPT_Promise_and_Pitfalls_of_Generative_AI_for_Education/21789434/1/files/38676764.pdf",
    "venue": null,
    "citation_count": 258,
    "fields_of_study": [
      "Generative grammar",
      "Misinformation",
      "Computer science",
      "Artificial intelligence",
      "Generative model"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622468"
  },
  {
    "source": "openalex",
    "source_id": "W4240644295",
    "title": "The ARRIVE guidelines 2.0: Updated guidelines for reporting animal research",
    "authors": [
      "Nathalie Percie du Sert",
      "Viki Hurst",
      "Amrita Ahluwalia",
      "Sabina Alam",
      "Marc T. Avey",
      "Monya Baker",
      "William J. Browne",
      "Alejandra Clark",
      "Innes C. Cuthill",
      "Ulrich Dirnagl",
      "Michael Emerson",
      "Paul Garner",
      "Stephen T. Holgate",
      "David W. Howells",
      "Natasha A. Karp",
      "Stanley E. Lazic",
      "Katie Lidster",
      "Catriona MacCallum",
      "Malcolm Macleod",
      "Esther J. Pearl",
      "Ole H. Petersen",
      "Frances Rawle",
      "Penny S. Reynolds",
      "Kieron Rooney",
      "Emily S. Sena",
      "Shai D. Silberberg",
      "Thomas Steckler",
      "Hanno W\u00fcrbel"
    ],
    "year": 2020,
    "abstract": null,
    "doi": "10.1186/s12917-020-02451-y",
    "url": "https://openalex.org/W4240644295",
    "pdf_url": "https://bmcvetres.biomedcentral.com/track/pdf/10.1186/s12917-020-02451-y",
    "venue": "BMC Veterinary Research",
    "citation_count": 399,
    "fields_of_study": [
      "Rigour",
      "Checklist",
      "Transparency (behavior)",
      "Context (archaeology)",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622487"
  },
  {
    "source": "openalex",
    "source_id": "W3111333805",
    "title": "The Recent Progress and Applications of Digital Technologies in Healthcare: A Review",
    "authors": [
      "Maksut Senbekov",
      "Timur Saliev",
      "Zhanar Bukeyeva",
      "Aigul Almabayeva",
      "Marina Zhanaliyeva",
      "Nazym Aitenova",
      "Yerzhan Toishibekov",
      "Ildar Fakhradiyev"
    ],
    "year": 2020,
    "abstract": "Background. The implementation of medical digital technologies can provide better accessibility and flexibility of healthcare for the public. It encompasses the availability of open information on the health, treatment, complications, and recent progress on biomedical research. At present, even in low-income countries, diagnostic and medical services are becoming more accessible and available. However, many issues related to digital health technologies remain unmet, including the reliability, safety, testing, and ethical aspects. Purpose. The aim of the review is to discuss and analyze the recent progress on the application of big data, artificial intelligence, telemedicine, block-chain platforms, smart devices in healthcare, and medical education. Basic Design. The publication search was carried out using Google Scholar, PubMed, Web of Sciences, Medline, Wiley Online Library, and CrossRef databases. The review highlights the applications of artificial intelligence, \u201cbig data,\u201d telemedicine and block-chain technologies, and smart devices (internet of things) for solving the real problems in healthcare and medical education. Major Findings. We identified 252 papers related to the digital health area. However, the number of papers discussed in the review was limited to 152 due to the exclusion criteria. The literature search demonstrated that digital health technologies became highly sought due to recent pandemics, including COVID-19. The disastrous dissemination of COVID-19 through all continents triggered the need for fast and effective solutions to localize, manage, and treat the viral infection. In this regard, the use of telemedicine and other e-health technologies might help to lessen the pressure on healthcare systems. Summary. Digital platforms can help optimize diagnosis, consulting, and treatment of patients. However, due to the lack of official regulations and recommendations, the stakeholders, including private and governmental organizations, are facing the problem with adequate validation and approbation of novel digital health technologies. In this regard, proper scientific research is required before a digital product is deployed for the healthcare sector.",
    "doi": "10.1155/2020/8830200",
    "url": "https://openalex.org/W3111333805",
    "pdf_url": "https://downloads.hindawi.com/journals/ijta/2020/8830200.pdf",
    "venue": "International Journal of Telemedicine and Applications",
    "citation_count": 388,
    "fields_of_study": [
      "Telemedicine",
      "Digital health",
      "Health care",
      "Flexibility (engineering)",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622490"
  },
  {
    "source": "openalex",
    "source_id": "W4224288650",
    "title": "Priorities for cancer research in low- and middle-income countries: a global perspective",
    "authors": [
      "C.S. Pramesh",
      "Rajendra Badwe",
      "Nirmala Bhoo\u2010Pathy",
      "Christopher M. Booth",
      "Girish Chinnaswamy",
      "Anna Dare",
      "Victor Piana de Andrade",
      "David J. Hunter",
      "Satish Gopal",
      "Mary Gospodarowicz",
      "Sanjeeva Gunasekera",
      "Andr\u00e8 Ilbawi",
      "Sharon Kapambwe",
      "T. Peter Kingham",
      "Tezer Kutluk",
      "Nirmal Lamichhane",
      "Miriam Mutebi",
      "Jackson Orem",
      "Groesbeck P. Parham",
      "Priya Ranganathan",
      "Manju Sengar",
      "Richard Sullivan",
      "Soumya Swaminathan",
      "Ian F. Tannock",
      "Vivek Tomar",
      "Verna Vanderpuye",
      "Cherian Varghese",
      "Elisabete Weiderpass"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1038/s41591-022-01738-x",
    "url": "https://openalex.org/W4224288650",
    "pdf_url": "https://www.nature.com/articles/s41591-022-01738-x.pdf",
    "venue": "Nature Medicine",
    "citation_count": 362,
    "fields_of_study": [
      "Low and middle income countries",
      "Perspective (graphical)",
      "Business",
      "Control (management)",
      "Cancer"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622517"
  },
  {
    "source": "openalex",
    "source_id": "W3048335295",
    "title": "Out of the laboratory and into the classroom: the future of artificial intelligence in education",
    "authors": [
      "Daniel Schiff"
    ],
    "year": 2020,
    "abstract": null,
    "doi": "10.1007/s00146-020-01033-8",
    "url": "https://openalex.org/W3048335295",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s00146-020-01033-8.pdf",
    "venue": "AI & Society",
    "citation_count": 280,
    "fields_of_study": [
      "Sociotechnical system",
      "Status quo",
      "Skepticism",
      "Alienation",
      "Democratization"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622519"
  },
  {
    "source": "openalex",
    "source_id": "W3082604781",
    "title": "HyperKvasir, a comprehensive multi-class image and video dataset for gastrointestinal endoscopy",
    "authors": [
      "Hanna Borgli",
      "Vajira Thambawita",
      "Pia H. Smedsrud",
      "Steven A. Hicks",
      "Debesh Jha",
      "Sigrun Losada Eskeland",
      "Kristin Ranheim Randel",
      "Konstantin Pogorelov",
      "Mathias Lux",
      "Duc Tien Dang Nguyen",
      "Dag Johansen",
      "Carsten Griwodz",
      "H\u00e5kon Kvale Stensland",
      "Enrique Garcia-Ceja",
      "Peter T. Schmidt",
      "Hugo L. Hammer",
      "Michael A. Riegler",
      "P\u00e5l Halvorsen",
      "Thomas de Lange"
    ],
    "year": 2020,
    "abstract": "Abstract Artificial intelligence is currently a hot topic in medicine. However, medical data is often sparse and hard to obtain due to legal restrictions and lack of medical personnel for the cumbersome and tedious process to manually label training data. These constraints make it difficult to develop systems for automatic analysis, like detecting disease or other lesions. In this respect, this article presents HyperKvasir , the largest image and video dataset of the gastrointestinal tract available today. The data is collected during real gastro- and colonoscopy examinations at B\u00e6rum Hospital in Norway and partly labeled by experienced gastrointestinal endoscopists. The dataset contains 110,079 images and 374 videos, and represents anatomical landmarks as well as pathological and normal findings. The total number of images and video frames together is around 1 million. Initial experiments demonstrate the potential benefits of artificial intelligence-based computer-assisted diagnosis systems. The HyperKvasir dataset can play a valuable role in developing better algorithms and computer-assisted examination systems not only for gastro- and colonoscopy, but also for other fields in medicine.",
    "doi": "10.1038/s41597-020-00622-y",
    "url": "https://openalex.org/W3082604781",
    "pdf_url": "https://www.nature.com/articles/s41597-020-00622-y.pdf",
    "venue": "Scientific Data",
    "citation_count": 458,
    "fields_of_study": [
      "Computer science",
      "Colonoscopy",
      "Artificial intelligence",
      "Class (philosophy)",
      "Process (computing)"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622523"
  },
  {
    "source": "openalex",
    "source_id": "W4388488349",
    "title": "Should ChatGPT be biased? Challenges and risks of bias in large language models",
    "authors": [
      "Emilio Ferrara"
    ],
    "year": 2023,
    "abstract": "As generative language models, exemplified by ChatGPT, continue to advance in their capabilities, the spotlight on biases inherent in these models intensifies. This paper delves into the distinctive challenges and risks associated with biases specifically in large-scale language models. We explore the origins of biases, stemming from factors such as training data, model specifications, algorithmic constraints, product design, and policy decisions. Our examination extends to the ethical implications arising from the unintended consequences of biased model outputs. In addition, we analyze the intricacies of mitigating biases, acknowledging the inevitable persistence of some biases, and consider the consequences of deploying these models across diverse applications, including virtual assistants, content generation, and chatbots. Finally, we provide an overview of current approaches for identifying, quantifying, and mitigating biases in language models, underscoring the need for a collaborative, multidisciplinary effort to craft AI systems that embody equity, transparency, and responsibility. This article aims to catalyze a thoughtful discourse within the AI community, prompting researchers and developers to consider the unique role of biases in the domain of generative language models and the ongoing quest for ethical AI.",
    "doi": "10.5210/fm.v28i11.13346",
    "url": "https://openalex.org/W4388488349",
    "pdf_url": "https://firstmonday.org/ojs/index.php/fm/article/download/13346/11369",
    "venue": "First Monday",
    "citation_count": 181,
    "fields_of_study": [
      "Unintended consequences",
      "Transparency (behavior)",
      "Computer science",
      "Generative grammar",
      "Language model"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622538"
  },
  {
    "source": "openalex",
    "source_id": "W4386619339",
    "title": "Deep Learning and Artificial Intelligence in Sustainability: A Review of SDGs, Renewable Energy, and Environmental Health",
    "authors": [
      "Zhencheng Fan",
      "Zheng Yan",
      "Shiping Wen"
    ],
    "year": 2023,
    "abstract": "Artificial intelligence (AI) and deep learning (DL) have shown tremendous potential in driving sustainability across various sectors. This paper reviews recent advancements in AI and DL and explores their applications in achieving sustainable development goals (SDGs), renewable energy, environmental health, and smart building energy management. AI has the potential to contribute to 134 of the 169 targets across all SDGs, but the rapid development of these technologies necessitates comprehensive regulatory oversight to ensure transparency, safety, and ethical standards. In the renewable energy sector, AI and DL have been effectively utilized in optimizing energy management, fault detection, and power grid stability. They have also demonstrated promise in enhancing waste management and predictive analysis in photovoltaic power plants. In the field of environmental health, the integration of AI and DL has facilitated the analysis of complex spatial data, improving exposure modeling and disease prediction. However, challenges such as the explainability and transparency of AI and DL models, the scalability and high dimensionality of data, the integration with next-generation wireless networks, and ethics and privacy concerns need to be addressed. Future research should focus on enhancing the explainability and transparency of AI and DL models, developing scalable algorithms for processing large datasets, exploring the integration of AI with next-generation wireless networks, and addressing ethical and privacy considerations. Additionally, improving the energy efficiency of AI and DL models is crucial to ensure the sustainable use of these technologies. By addressing these challenges and fostering responsible and innovative use, AI and DL can significantly contribute to a more sustainable future.",
    "doi": "10.3390/su151813493",
    "url": "https://openalex.org/W4386619339",
    "pdf_url": "https://www.mdpi.com/2071-1050/15/18/13493/pdf?version=1694397493",
    "venue": "Sustainability",
    "citation_count": 236,
    "fields_of_study": [
      "Transparency (behavior)",
      "Sustainability",
      "Renewable energy",
      "Computer science",
      "Scalability"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622553"
  },
  {
    "source": "openalex",
    "source_id": "W4234956358",
    "title": "Artificial Intelligence for a Better Future",
    "authors": [
      "Bernd Carsten Stahl"
    ],
    "year": 2021,
    "abstract": "This open access book proposes a novel approach to Artificial Intelligence (AI) ethics. AI offers many advantages: better and faster medical diagnoses, improved business processes and efficiency, and the automation of boring work. But undesirable and ethically problematic consequences are possible too: biases and discrimination, breaches of privacy and security, and societal distortions such as unemployment, economic exploitation and weakened democratic processes. There is even a prospect, ultimately, of super-intelligent machines replacing humans. The key question, then, is: how can we benefit from AI while addressing its ethical problems? This book presents an innovative answer to the question by presenting a different perspective on AI and its ethical consequences. Instead of looking at individual AI techniques, applications or ethical issues, we can understand AI as a system of ecosystems, consisting of numerous interdependent technologies, applications and stakeholders. Developing this idea, the book explores how AI ecosystems can be shaped to foster human flourishing. Drawing on rich empirical insights and detailed conceptual analysis, it suggests practical measures to ensure that AI is used to make the world a better place.",
    "doi": "10.1007/978-3-030-69978-9",
    "url": "https://openalex.org/W4234956358",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/978-3-030-69978-9.pdf",
    "venue": "SpringerBriefs in research and innovation governance",
    "citation_count": 238,
    "fields_of_study": [
      "Computer science",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622572"
  },
  {
    "source": "openalex",
    "source_id": "W2995382404",
    "title": "Roles for computing in social change",
    "authors": [
      "Rediet Abebe",
      "Solon Barocas",
      "Jon Kleinberg",
      "Karen Levy",
      "Manish Raghavan",
      "David G. Robinson"
    ],
    "year": 2020,
    "abstract": "A recent normative turn in computer science has brought concerns about fairness, bias, and accountability to the core of the field. Yet recent scholarship has warned that much of this technical work treats problematic features of the status quo as fixed, and fails to address deeper patterns of injustice and inequality. While acknowledging these critiques, we posit that computational research has valuable roles to play in addressing social problems -- roles whose value can be recognized even from a perspective that aspires toward fundamental social change. In this paper, we articulate four such roles, through an analysis that considers the opportunities as well as the significant risks inherent in such work. Computing research can serve as a diagnostic, helping us to understand and measure social problems with precision and clarity. As a formalizer, computing shapes how social problems are explicitly defined --- changing how those problems, and possible responses to them, are understood. Computing serves as rebuttal when it illuminates the boundaries of what is possible through technical means. And computing acts as synecdoche when it makes long-standing social problems newly salient in the public eye. We offer these paths forward as modalities that leverage the particular strengths of computational work in the service of social change, without overclaiming computing's capacity to solve social problems on its own.",
    "doi": "10.1145/3351095.3372871",
    "url": "https://openalex.org/W2995382404",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3351095.3372871",
    "venue": null,
    "citation_count": 196,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:11.622587"
  },
  {
    "source": "openalex",
    "source_id": "W4312000342",
    "title": "Economics of Artificial Intelligence in Healthcare: Diagnosis vs. Treatment",
    "authors": [
      "Narendra N. Khanna",
      "Mahesh Maindarkar",
      "Vijay Viswanathan",
      "Jos\u00e9 Fernandes e Fernandes",
      "Sudip Paul",
      "Mrinalini Bhagawati",
      "Puneet Ahluwalia",
      "Zolt\u00e1n Ruzsa",
      "Aditya Sharma",
      "Raghu Kolluri",
      "Inder M. Singh",
      "John R. Laird",
      "Mostafa Fatemi",
      "Azra Alizad",
      "Luca Saba",
      "Vikas Agarwal",
      "Aman Sharma",
      "Jagjit S. Teji",
      "Mustafa Al-Maini",
      "Vijay Rathore",
      "Subbaram Naidu",
      "Kiera Liblik",
      "Amer M. Johri",
      "Monika Turk",
      "Lopamudra Mohanty",
      "David Sobel",
      "Martin Miner",
      "Klaudija Vi\u0161kovi\u0107",
      "George Tsoulfas",
      "Athanase D. Protogerou",
      "George D. Kitas",
      "Mostafa M. Fouda",
      "Seemant Chaturvedi",
      "Mannudeep K. Kalra",
      "Jasjit S. Suri"
    ],
    "year": 2022,
    "abstract": "Motivation: The price of medical treatment continues to rise due to (i) an increasing population; (ii) an aging human growth; (iii) disease prevalence; (iv) a rise in the frequency of patients that utilize health care services; and (v) increase in the price. Objective: Artificial Intelligence (AI) is already well-known for its superiority in various healthcare applications, including the segmentation of lesions in images, speech recognition, smartphone personal assistants, navigation, ride-sharing apps, and many more. Our study is based on two hypotheses: (i) AI offers more economic solutions compared to conventional methods; (ii) AI treatment offers stronger economics compared to AI diagnosis. This novel study aims to evaluate AI technology in the context of healthcare costs, namely in the areas of diagnosis and treatment, and then compare it to the traditional or non-AI-based approaches. Methodology: PRISMA was used to select the best 200 studies for AI in healthcare with a primary focus on cost reduction, especially towards diagnosis and treatment. We defined the diagnosis and treatment architectures, investigated their characteristics, and categorized the roles that AI plays in the diagnostic and therapeutic paradigms. We experimented with various combinations of different assumptions by integrating AI and then comparing it against conventional costs. Lastly, we dwell on three powerful future concepts of AI, namely, pruning, bias, explainability, and regulatory approvals of AI systems. Conclusions: The model shows tremendous cost savings using AI tools in diagnosis and treatment. The economics of AI can be improved by incorporating pruning, reduction in AI bias, explainability, and regulatory approvals.",
    "doi": "10.3390/healthcare10122493",
    "url": "https://openalex.org/W4312000342",
    "pdf_url": "https://www.mdpi.com/2227-9032/10/12/2493/pdf?version=1670894037",
    "venue": "Healthcare",
    "citation_count": 290,
    "fields_of_study": [
      "Health care",
      "Population ageing",
      "Population",
      "Artificial intelligence",
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622608"
  },
  {
    "source": "openalex",
    "source_id": "W2884074583",
    "title": "AI and Big Data: A blueprint for a human rights, social and ethical impact assessment",
    "authors": [
      "Alessandro Mantelero"
    ],
    "year": 2018,
    "abstract": "The use of algorithms in modern data processing techniques, as well as data-intensive technological trends, suggests the adoption of a broader view of the data protection impact assessment. This will force data controllers to go beyond the traditional focus on data quality and security, and consider the impact of data processing on fundamental rights and collective social and ethical values. Building on studies of the collective dimension of data protection, this article sets out to embed this new perspective in an assessment model centred on human rights (Human Rights, Ethical and Social Impact Assessment-HRESIA). This self-assessment model intends to overcome the limitations of the existing assessment models, which are either too closely focused on data processing or have an extent and granularity that make them too complicated to evaluate the consequences of a given use of data. In terms of architecture, the HRESIA has two main elements: a self-assessment questionnaire and an ad hoc expert committee. As a blueprint, this contribution focuses mainly on the nature of the proposed model, its architecture and its challenges; a more detailed description of the model and the content of the questionnaire will be discussed in a future publication drawing on the ongoing research.",
    "doi": "10.1016/j.clsr.2018.05.017",
    "url": "https://openalex.org/W2884074583",
    "pdf_url": "https://www.sciencedirect.com/science/article/pii/S0267364918302012?via%3Dihub",
    "venue": "Computer law & security review",
    "citation_count": 263,
    "fields_of_study": [
      "Blueprint",
      "Computer science",
      "Social impact assessment",
      "Data quality",
      "Data science"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622627"
  },
  {
    "source": "openalex",
    "source_id": "W4399518864",
    "title": "The impact of generative artificial intelligence on socioeconomic inequalities and policy making",
    "authors": [
      "Valerio Capraro",
      "Austin Lentsch",
      "Daron Acemo\u011flu",
      "Selin Akg\u00fcn",
      "Aisel Akhmedova",
      "Ennio Bilancini",
      "Jean\u2010Fran\u00e7ois Bonnefon",
      "Pablo Bra\u00f1as\u2010Garza",
      "Luigi Butera",
      "Karen M. Douglas",
      "Jim A. C. Everett",
      "Gerd Gigerenzer",
      "Christine Greenhow",
      "Daniel A. Hashimoto",
      "Julianne Holt\u2010Lunstad",
      "Jolanda Jetten",
      "Simon Johnson",
      "Werner H. Kunz",
      "Chiara Longoni",
      "Pete Lunn",
      "Simone Natale",
      "Stefanie Paluch",
      "Iyad Rahwan",
      "Neil Selwyn",
      "Vivek Singh",
      "Siddharth Suri",
      "Jennifer Sutcliffe",
      "Joe Tomlinson",
      "Sander van der Linden",
      "Paul A. M. Van Lange",
      "Friederike Wall",
      "Jay Joseph Van Bavel",
      "Riccardo Viale"
    ],
    "year": 2024,
    "abstract": "Abstract Generative artificial intelligence (AI) has the potential to both exacerbate and ameliorate existing socioeconomic inequalities. In this article, we provide a state-of-the-art interdisciplinary overview of the potential impacts of generative AI on (mis)information and three information-intensive domains: work, education, and healthcare. Our goal is to highlight how generative AI could worsen existing inequalities while illuminating how AI may help mitigate pervasive social problems. In the information domain, generative AI can democratize content creation and access but may dramatically expand the production and proliferation of misinformation. In the workplace, it can boost productivity and create new jobs, but the benefits will likely be distributed unevenly. In education, it offers personalized learning, but may widen the digital divide. In healthcare, it might improve diagnostics and accessibility, but could deepen pre-existing inequalities. In each section, we cover a specific topic, evaluate existing research, identify critical gaps, and recommend research directions, including explicit trade-offs that complicate the derivation of a priori hypotheses. We conclude with a section highlighting the role of policymaking to maximize generative AI's potential to reduce inequalities while mitigating its harmful effects. We discuss strengths and weaknesses of existing policy frameworks in the European Union, the United States, and the United Kingdom, observing that each fails to fully confront the socioeconomic challenges we have identified. We propose several concrete policies that could promote shared prosperity through the advancement of generative AI. This article emphasizes the need for interdisciplinary collaborations to understand and address the complex challenges of generative AI.",
    "doi": "10.1093/pnasnexus/pgae191",
    "url": "https://openalex.org/W4399518864",
    "pdf_url": "https://academic.oup.com/pnasnexus/article-pdf/3/6/pgae191/58184311/pgae191.pdf",
    "venue": "PNAS Nexus",
    "citation_count": 217,
    "fields_of_study": [
      "Generative grammar",
      "Inequality",
      "Socioeconomic status",
      "Computer science",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622646"
  },
  {
    "source": "openalex",
    "source_id": "W3161588210",
    "title": "Replicability, Robustness, and Reproducibility in Psychological Science",
    "authors": [
      "Brian A. Nosek",
      "Tom E Hardwicke",
      "Hannah Moshontz",
      "Aur\u00e9lien Allard",
      "Katherine S. Corker",
      "Anna Dreber",
      "Fiona Fidler",
      "Joe Hilgard",
      "Melissa Kline Struhl",
      "Mich\u00e8le B. Nuijten",
      "Julia M. Rohrer",
      "Felipe Romero",
      "Anne M. Scheel",
      "Laura D. Scherer",
      "Felix D. Sch\u00f6nbrodt",
      "Simine Vazire"
    ],
    "year": 2021,
    "abstract": "Replication\u2014an important, uncommon, and misunderstood practice\u2014is gaining appreciation in psychology. Achieving replicability is important for making research progress. If findings are not replicable, then prediction and theory development are stifled. If findings are replicable, then interrogation of their meaning and validity can advance knowledge. Assessing replicability can be productive for generating and testing hypotheses by actively confronting current understandings to identify weaknesses and spur innovation. For psychology, the 2010s might be characterized as a decade of active confrontation. Systematic and multi-site replication projects assessed current understandings and observed surprising failures to replicate many published findings. Replication efforts highlighted sociocultural challenges such as disincentives to conduct replications and a tendency to frame replication as a personal attack rather than a healthy scientific practice, and they raised awareness that replication contributes to self-correction. Nevertheless, innovation in doing and understanding replication and its cousins, reproducibility and robustness, has positioned psychology to improve research practices and accelerate progress.",
    "doi": "10.1146/annurev-psych-020821-114157",
    "url": "https://openalex.org/W3161588210",
    "pdf_url": "https://www.annualreviews.org/doi/pdf/10.1146/annurev-psych-020821-114157",
    "venue": "Annual Review of Psychology",
    "citation_count": 676,
    "fields_of_study": [
      "Psychology",
      "Replication (statistics)",
      "Sociocultural evolution",
      "Social psychology",
      "Psychological science"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622667"
  },
  {
    "source": "openalex",
    "source_id": "W4220921529",
    "title": "Digital transformation, for better or worse: a critical multi\u2010level research agenda",
    "authors": [
      "Justyna D\u0105browska",
      "Argyro Almpanopoulou",
      "Alexander Brem",
      "Henry Chesbrough",
      "Valentina Cucino",
      "Alberto Di Minin",
      "Ferran Giones",
      "Henri Hakala",
      "Cristina Marullo",
      "Anne\u2010Laure Mention",
      "Letizia Mortara",
      "Sladjana N\u00f8rskov",
      "Petra A. Nylund",
      "Calogero Maria Oddo",
      "Agnieszka Radziwon",
      "Paavo Ritala"
    ],
    "year": 2022,
    "abstract": "For better or worse, digital technologies are reshaping everything, from customer behaviors and expectations to organizational and manufacturing systems, business models, markets, and ultimately society. To understand this overarching transformation, this paper extends the previous literature which has focused mostly on the organizational level by developing a multi\u2010level research agenda for digital transformation (DT). In this regard, we propose an extended definition of DT as \u201ca socioeconomic change across individuals, organizations, ecosystems, and societies that are shaped by the adoption and utilization of digital technologies.\u201d We suggest four lenses to interpret the DT phenomenon: individuals (utilizing and adopting digital technologies), organizations (strategizing and coordinating both internal and external transformation), ecosystems (harnessing digital technologies in governance and co\u2010producing value propositions), and geopolitical frameworks (regulating the environments in which individuals and organizations are embedded). Based on these lenses, we build a multi\u2010level research agenda at the intersection between the bright and dark sides of DT and introduce the PIAI framework, which captures a process of perception , interpretation , and action that ultimately leads to possible impact . The PIAI framework identifies a critical research agenda consisting of a non\u2010exhaustive list of topics that can assist researchers to deepen their understanding of the DT phenomenon and provide guidance to managers and policymakers when making strategic decisions that seek to shape and guide the DT.",
    "doi": "10.1111/radm.12531",
    "url": "https://openalex.org/W4220921529",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/radm.12531",
    "venue": "R and D Management",
    "citation_count": 278,
    "fields_of_study": [
      "Transformation (genetics)",
      "Digital transformation",
      "Computer science",
      "Political science",
      "World Wide Web"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622682"
  },
  {
    "source": "openalex",
    "source_id": "W4381587418",
    "title": "Opportunities and challenges for ChatGPT and large language models in biomedicine and health",
    "authors": [
      "Shubo Tian",
      "Qiao Jin",
      "Lana Yeganova",
      "Po\u2010Ting Lai",
      "Qingqing Zhu",
      "Xiuying Chen",
      "Yifan Yang",
      "Qingyu Chen",
      "Won Bae Kim",
      "Donald C. Comeau",
      "Rezarta Islamaj",
      "Aadit Kapoor",
      "Xin Gao",
      "Zhiyong Lu"
    ],
    "year": 2023,
    "abstract": "Abstract ChatGPT has drawn considerable attention from both the general public and domain experts with its remarkable text generation capabilities. This has subsequently led to the emergence of diverse applications in the field of biomedicine and health. In this work, we examine the diverse applications of large language models (LLMs), such as ChatGPT, in biomedicine and health. Specifically, we explore the areas of biomedical information retrieval, question answering, medical text summarization, information extraction and medical education and investigate whether LLMs possess the transformative power to revolutionize these tasks or whether the distinct complexities of biomedical domain presents unique challenges. Following an extensive literature survey, we find that significant advances have been made in the field of text generation tasks, surpassing the previous state-of-the-art methods. For other applications, the advances have been modest. Overall, LLMs have not yet revolutionized biomedicine, but recent rapid progress indicates that such methods hold great potential to provide valuable means for accelerating discovery and improving health. We also find that the use of LLMs, like ChatGPT, in the fields of biomedicine and health entails various risks and challenges, including fabricated information in its generated responses, as well as legal and privacy concerns associated with sensitive patient data. We believe this survey can provide a comprehensive and timely overview to biomedical researchers and healthcare practitioners on the opportunities and challenges associated with using ChatGPT and other LLMs for transforming biomedicine and health.",
    "doi": "10.1093/bib/bbad493",
    "url": "https://openalex.org/W4381587418",
    "pdf_url": "https://academic.oup.com/bib/article-pdf/25/1/bbad493/54942208/bbad493.pdf",
    "venue": "Briefings in Bioinformatics",
    "citation_count": 305,
    "fields_of_study": [
      "Biomedicine",
      "Computer science",
      "Data science",
      "Natural language processing",
      "Bioinformatics"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622702"
  },
  {
    "source": "openalex",
    "source_id": "W4293231014",
    "title": "Citizen science in environmental and ecological sciences",
    "authors": [
      "Dilek Fraisl",
      "Gerid Hager",
      "Baptiste Bedessem",
      "Margaret M. Gold",
      "Pen\u2010Yuan Hsing",
      "Finn Danielsen",
      "Colleen Hitchcock",
      "Joseph M. Hulbert",
      "Jaume Piera",
      "Helen Spiers",
      "Mart\u00edn Thiel",
      "Muki Haklay"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1038/s43586-022-00144-4",
    "url": "https://openalex.org/W4293231014",
    "pdf_url": "https://www.nature.com/articles/s43586-022-00144-4.pdf",
    "venue": "Nature Reviews Methods Primers",
    "citation_count": 413,
    "fields_of_study": [
      "Citizen science",
      "Data sharing",
      "Open science",
      "Engineering ethics",
      "Data collection"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622728"
  },
  {
    "source": "openalex",
    "source_id": "W4388895516",
    "title": "Harnessing the Power of AI: A Comprehensive Review of Its Impact and Challenges in Nursing Science and Healthcare",
    "authors": [
      "Seema Yelne",
      "Minakshi Chaudhary",
      "Karishma Dod",
      "Akhtaribano Sayyad",
      "Ranjana Sharma"
    ],
    "year": 2023,
    "abstract": "This comprehensive review delves into the impact and challenges of Artificial Intelligence (AI) in nursing science and healthcare. AI has already demonstrated its transformative potential in these fields, with applications spanning from personalized care and diagnostic accuracy to predictive analytics and telemedicine. However, the integration of AI has its complexities, including concerns related to data privacy, ethical considerations, and biases in algorithms and datasets. The future of healthcare appears promising, with AI poised to advance diagnostics, treatment, and healthcare practices. Nevertheless, it is crucial to remember that AI should complement, not replace, healthcare professionals, preserving the essential human element of care. To maximize AI's potential in healthcare, interdisciplinary collaboration, ethical guidelines, and the protection of patient rights are essential. This review concludes with a call to action, emphasizing the need for ongoing research and collective efforts to ensure that AI contributes to improved healthcare outcomes while upholding the highest standards of ethics and patient-centered care.",
    "doi": "10.7759/cureus.49252",
    "url": "https://openalex.org/W4388895516",
    "pdf_url": "https://assets.cureus.com/uploads/review_article/pdf/206741/20231122-10807-1n3hf8c.pdf",
    "venue": "Cureus",
    "citation_count": 159,
    "fields_of_study": [
      "Transformative learning",
      "Health care",
      "Medicine",
      "Engineering ethics",
      "Applications of artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622731"
  },
  {
    "source": "openalex",
    "source_id": "W3014246070",
    "title": "Primer on an ethics of AI-based decision support systems in the clinic",
    "authors": [
      "Matthias Braun",
      "Patrik Hummel",
      "Susanne Beck",
      "Peter Dabrock"
    ],
    "year": 2020,
    "abstract": "Making good decisions in extremely complex and difficult processes and situations has always been both a key task as well as a challenge in the clinic and has led to a large amount of clinical, legal and ethical routines, protocols and reflections in order to guarantee fair, participatory and up-to-date pathways for clinical decision-making. Nevertheless, the complexity of processes and physical phenomena, time as well as economic constraints and not least further endeavours as well as achievements in medicine and healthcare continuously raise the need to evaluate and to improve clinical decision-making. This article scrutinises if and how clinical decision-making processes are challenged by the rise of so-called artificial intelligence-driven decision support systems (AI-DSS). In a first step, this article analyses how the rise of AI-DSS will affect and transform the modes of interaction between different agents in the clinic. In a second step, we point out how these changing modes of interaction also imply shifts in the conditions of trustworthiness, epistemic challenges regarding transparency, the underlying normative concepts of agency and its embedding into concrete contexts of deployment and, finally, the consequences for (possible) ascriptions of responsibility. Third, we draw first conclusions for further steps regarding a \u2018meaningful human control\u2019 of clinical AI-DSS.",
    "doi": "10.1136/medethics-2019-105860",
    "url": "https://openalex.org/W3014246070",
    "pdf_url": "https://jme.bmj.com/content/medethics/47/12/e3.full.pdf",
    "venue": "Journal of Medical Ethics",
    "citation_count": 211,
    "fields_of_study": [
      "Normative",
      "Transparency (behavior)",
      "Agency (philosophy)",
      "Computer science",
      "Decision support system"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622746"
  },
  {
    "source": "openalex",
    "source_id": "W2972211076",
    "title": "Toward clinical digital phenotyping: a timely opportunity to consider purpose, quality, and safety",
    "authors": [
      "Kit Huckvale",
      "Svetha Venkatesh",
      "Helen Christensen"
    ],
    "year": 2019,
    "abstract": null,
    "doi": "10.1038/s41746-019-0166-1",
    "url": "https://openalex.org/W2972211076",
    "pdf_url": "https://www.nature.com/articles/s41746-019-0166-1.pdf",
    "venue": "npj Digital Medicine",
    "citation_count": 411,
    "fields_of_study": [
      "Multidisciplinary approach",
      "Digital health",
      "Psychological intervention",
      "Quality (philosophy)",
      "Relevance (law)"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622768"
  },
  {
    "source": "openalex",
    "source_id": "W3184865800",
    "title": "Machine learning and algorithmic fairness in public and population health",
    "authors": [
      "Vishwali Mhasawade",
      "Yuan Zhao",
      "Rumi Chunara"
    ],
    "year": 2021,
    "abstract": null,
    "doi": "10.1038/s42256-021-00373-4",
    "url": "https://openalex.org/W3184865800",
    "pdf_url": "https://www.nature.com/articles/s42256-021-00373-4.pdf",
    "venue": "Nature Machine Intelligence",
    "citation_count": 193,
    "fields_of_study": [
      "Health equity",
      "Public health",
      "Population health",
      "Artificial intelligence",
      "Machine learning"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622772"
  },
  {
    "source": "openalex",
    "source_id": "W4381570295",
    "title": "Navigating the Ethical Challenges of Artificial Intelligence in Higher Education: An Analysis of Seven Global AI Ethics Policies",
    "authors": [
      "Zouhaier Slimi",
      "Beatriz Villarejo-Carballido"
    ],
    "year": 2023,
    "abstract": "AI use in higher education raises ethical concerns that must be addressed. Biased algorithms pose a significant threat, especially if used in admission or grading processes, as they could have devastating effects on students. Another issue is the displacement of human educators by AI systems, and there are concerns about transparency and accountability as AI becomes more integrated into decision-making processes. This paper examined three AI objectives related higher education: biased algorithms, AI and decision-making, and human displacement. Discourse analysis of seven AI ethics policies was conducted, including those from UNESCO, China, the European Commission, Google, MIT, Sanford HAI, and Carnegie Mellon. The findings indicate that stakeholders must work together to address these challenges and ensure responsible AI deployment in higher education while maximizing its benefits. Fair use and protecting individuals, especially those with vulnerable characteristics, are crucial. Gender bias must be avoided in algorithm development, learning data sets, and AI decision-making. Data collection, labeling, and algorithm documentation must be of the highest quality to ensure traceability and openness. Universities must study the ethical, social, and policy implications of AI to ensure responsible development and deployment. The AI ethics policies stress responsible AI development and deployment, with a focus on transparency and accountability. Making AI systems more transparent and answerable may reduce the adverse effects of displacement. In conclusion, AI must be considered ethically in higher education, and stakeholders must ensure that AI is used responsibly, fairly, and in a way that maximizes its benefits while minimizing its risks.",
    "doi": "10.18421/tem122-02",
    "url": "https://openalex.org/W4381570295",
    "pdf_url": "https://www.temjournal.com/content/122/TEMJournalMay2023_590_602.pdf",
    "venue": "TEM Journal",
    "citation_count": 145,
    "fields_of_study": [
      "Accountability",
      "Transparency (behavior)",
      "Software deployment",
      "Openness to experience",
      "Documentation"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622774"
  },
  {
    "source": "openalex",
    "source_id": "W4288083800",
    "title": "Lessons from archives",
    "authors": [
      "Eun Seo Jo",
      "Timnit Gebru"
    ],
    "year": 2020,
    "abstract": "A growing body of work shows that many problems in fairness, accountability, transparency, and ethics in machine learning systems are rooted in decisions surrounding the data collection and annotation process. In spite of its fundamental nature however, data collection remains an overlooked part of the machine learning (ML) pipeline. In this paper, we argue that a new specialization should be formed within ML that is focused on methodologies for data collection and annotation: efforts that require institutional frameworks and procedures. Specifically for sociocultural data, parallels can be drawn from archives and libraries. Archives are the longest standing communal effort to gather human information and archive scholars have already developed the language and procedures to address and discuss many challenges pertaining to data collection such as consent, power, inclusivity, transparency, and ethics & privacy. We discuss these five key approaches in document collection practices in archives that can inform data collection in sociocultural ML. By showing data collection practices from another field, we encourage ML research to be more cognizant and systematic in data collection and draw from interdisciplinary expertise.",
    "doi": "10.1145/3351095.3372829",
    "url": "https://openalex.org/W4288083800",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3351095.3372829",
    "venue": null,
    "citation_count": 211,
    "fields_of_study": [
      "Transparency (behavior)",
      "Data collection",
      "Accountability",
      "Sociocultural evolution",
      "Parallels"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622796"
  },
  {
    "source": "openalex",
    "source_id": "W3097060730",
    "title": "Federated Learning in Smart City Sensing: Challenges and Opportunities",
    "authors": [
      "Ji Chu Jiang",
      "Burak Kantarc\u0131",
      "Sema Oktu\u011f",
      "Tolga Soyata"
    ],
    "year": 2020,
    "abstract": "Smart Cities sensing is an emerging paradigm to facilitate the transition into smart city services. The advent of the Internet of Things (IoT) and the widespread use of mobile devices with computing and sensing capabilities has motivated applications that require data acquisition at a societal scale. These valuable data can be leveraged to train advanced Artificial Intelligence (AI) models that serve various smart services that benefit society in all aspects. Despite their effectiveness, legacy data acquisition models backed with centralized Machine Learning models entail security and privacy concerns, and lead to less participation in large-scale sensing and data provision for smart city services. To overcome these challenges, Federated Learning is a novel concept that can serve as a solution to the privacy and security issues encountered within the process of data collection. This survey article presents an overview of smart city sensing and its current challenges followed by the potential of Federated Learning in addressing those challenges. A comprehensive discussion of the state-of-the-art methods for Federated Learning is provided along with an in-depth discussion on the applicability of Federated Learning in smart city sensing; clear insights on open issues, challenges, and opportunities in this field are provided as guidance for the researchers studying this subject matter.",
    "doi": "10.3390/s20216230",
    "url": "https://openalex.org/W3097060730",
    "pdf_url": "https://www.mdpi.com/1424-8220/20/21/6230/pdf?version=1604998232",
    "venue": "Sensors",
    "citation_count": 283,
    "fields_of_study": [
      "Computer science",
      "Process (computing)",
      "Smart city",
      "Data science",
      "Field (mathematics)"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622814"
  },
  {
    "source": "openalex",
    "source_id": "W4392293571",
    "title": "Global Regulatory Frameworks for the Use of Artificial Intelligence (AI) in the Healthcare Services Sector",
    "authors": [
      "Kavitha Palaniappan",
      "Elaine Yan Ting Lin",
      "Silke Vogel"
    ],
    "year": 2024,
    "abstract": "The healthcare sector is faced with challenges due to a shrinking healthcare workforce and a rise in chronic diseases that are worsening with demographic and epidemiological shifts. Digital health interventions that include artificial intelligence (AI) are being identified as some of the potential solutions to these challenges. The ultimate aim of these AI systems is to improve the patient\u2019s health outcomes and satisfaction, the overall population\u2019s health, and the well-being of healthcare professionals. The applications of AI in healthcare services are vast and are expected to assist, automate, and augment several healthcare services. Like any other emerging innovation, AI in healthcare also comes with its own risks and requires regulatory controls. A review of the literature was undertaken to study the existing regulatory landscape for AI in the healthcare services sector in developed nations. In the global regulatory landscape, most of the regulations for AI revolve around Software as a Medical Device (SaMD) and are regulated under digital health products. However, it is necessary to note that the current regulations may not suffice as AI-based technologies are capable of working autonomously, adapting their algorithms, and improving their performance over time based on the new real-world data that they have encountered. Hence, a global regulatory convergence for AI in healthcare, similar to the voluntary AI code of conduct that is being developed by the US-EU Trade and Technology Council, would be beneficial to all nations, be it developing or developed.",
    "doi": "10.3390/healthcare12050562",
    "url": "https://openalex.org/W4392293571",
    "pdf_url": "https://www.mdpi.com/2227-9032/12/5/562/pdf?version=1709256793",
    "venue": "Healthcare",
    "citation_count": 207,
    "fields_of_study": [
      "Health care",
      "Workforce",
      "Digital health",
      "Business",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622832"
  },
  {
    "source": "openalex",
    "source_id": "W4386242492",
    "title": "AI Art and its Impact on Artists",
    "authors": [
      "Harry H. Jiang",
      "Lauren T. Brown",
      "Jessica Yi-Yun Cheng",
      "Mehtab Khan",
      "Abhishek Gupta",
      "Deja Workman",
      "Alex Hanna",
      "Johnathan Flowers",
      "Timnit Gebru"
    ],
    "year": 2023,
    "abstract": "The last 3 years have resulted in machine learning (ML)-based image generators with the ability to output consistently higher quality images based on natural language prompts as inputs. As a result, many popular commercial \"generative AI Art\" products have entered the market, making generative AI an estimated $48B industry [125]. However, many professional artists have spoken up about the harms they have experienced due to the proliferation of large scale image generators trained on image/text pairs from the Internet. In this paper, we review some of these harms which include reputational damage, economic loss, plagiarism and copyright infringement. To guard against these issues while reaping the potential benefits of image generators, we provide recommendations such as regulation that forces organizations to disclose their training data, and tools that help artists prevent using their content as training data without their consent.",
    "doi": "10.1145/3600211.3604681",
    "url": "https://openalex.org/W4386242492",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3600211.3604681",
    "venue": null,
    "citation_count": 204,
    "fields_of_study": [
      "Guard (computer science)",
      "Generative grammar",
      "Computer science",
      "The Internet",
      "Quality (philosophy)"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622853"
  },
  {
    "source": "openalex",
    "source_id": "W4379508361",
    "title": "The Advent of Generative Language Models in Medical Education",
    "authors": [
      "Mert Karabacak",
      "Burak Berksu Ozkara",
      "Konstantinos Margetis",
      "Max Wintermark",
      "Sotirios Bisdas"
    ],
    "year": 2023,
    "abstract": "Artificial intelligence (AI) and generative language models (GLMs) present significant opportunities for enhancing medical education, including the provision of realistic simulations, digital patients, personalized feedback, evaluation methods, and the elimination of language barriers. These advanced technologies can facilitate immersive learning environments and enhance medical students' educational outcomes. However, ensuring content quality, addressing biases, and managing ethical and legal concerns present obstacles. To mitigate these challenges, it is necessary to evaluate the accuracy and relevance of AI-generated content, address potential biases, and develop guidelines and policies governing the use of AI-generated content in medical education. Collaboration among educators, researchers, and practitioners is essential for developing best practices, guidelines, and transparent AI models that encourage the ethical and responsible use of GLMs and AI in medical education. By sharing information about the data used for training, obstacles encountered, and evaluation methods, developers can increase their credibility and trustworthiness within the medical community. In order to realize the full potential of AI and GLMs in medical education while mitigating potential risks and obstacles, ongoing research and interdisciplinary collaboration are necessary. By collaborating, medical professionals can ensure that these technologies are effectively and responsibly integrated, contributing to enhanced learning experiences and patient care.",
    "doi": "10.2196/48163",
    "url": "https://openalex.org/W4379508361",
    "pdf_url": "https://mededu.jmir.org/2023/1/e48163/PDF",
    "venue": "JMIR Medical Education",
    "citation_count": 186,
    "fields_of_study": [
      "Credibility",
      "Relevance (law)",
      "Computer science",
      "Quality (philosophy)",
      "Knowledge management"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622866"
  },
  {
    "source": "openalex",
    "source_id": "W4302305162",
    "title": "Ethics and diversity in artificial intelligence policies, strategies and initiatives",
    "authors": [
      "Cathy Roche",
      "P. J. Wall",
      "David Lewis"
    ],
    "year": 2022,
    "abstract": "Abstract A burgeoning of Artificial Intelligence (AI) technologies in recent years has led to increased discussion about its potential to address many issues considered otherwise intractable, including those highlighted by the United Nations 2030 Agenda for Sustainable Development and associated Sustainable Development Goals. In tandem with this growth in AI is an expanding body of documentation regarding how such advanced technologies should be governed and managed. Issued by a variety of sources and comprising frameworks, policies and guidelines, this body of work encompasses the legal, social, ethical and policy issues around AI. With at least 470 such documents identified, as of May 2021, in the Council of Europe\u2019s tracker of AI initiatives, questions are emerging around the diversity of views expressed, especially regarding the influence of the Global North or Euro-American perspectives. Our previous analysis of a corpus of largely grey literature discovered blind spots regarding both gender representation and perspectives from the Global South. Expanding on that work, this paper examines a significantly extended corpus, with a focus on the role of underrepresented groups in the wider AI discourse. We find that voices from the Global South and consideration of alternative ethical approaches are largely absent from the conversation. In light of the prominence of social, cultural and ethical perspectives from the Global North, this paper explores implications for the development of standards for ethical AI. Concluding by offering approaches to incorporate more diverse ethical viewpoints and beliefs, we call for increased consideration of power structures when developing AI ethics policies and standards within these alternative socio-cultural and socio-economic contexts.",
    "doi": "10.1007/s43681-022-00218-9",
    "url": "https://openalex.org/W4302305162",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s43681-022-00218-9.pdf",
    "venue": "AI and Ethics",
    "citation_count": 144,
    "fields_of_study": [
      "Viewpoints",
      "Conversation",
      "Diversity (politics)",
      "Political science",
      "Engineering ethics"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622885"
  },
  {
    "source": "openalex",
    "source_id": "W4385469325",
    "title": "A Survey on ChatGPT: AI\u2013Generated Contents, Challenges, and Solutions",
    "authors": [
      "Yuntao Wang",
      "Yanghe Pan",
      "Miao Yan",
      "Zhou Su",
      "Tom H. Luan"
    ],
    "year": 2023,
    "abstract": "With the widespread use of large artificial intelligence (AI) models such as ChatGPT, AI-generated content (AIGC) has garnered increasing attention and is leading a paradigm shift in content creation and knowledge representation. AIGC uses generative large AI algorithms to assist or replace humans in creating massive, high-quality, and human-like content at a faster pace and lower cost, based on user-provided prompts. Despite the recent significant progress in AIGC, security, privacy, ethical, and legal challenges still need to be addressed. This paper presents an in-depth survey of working principles, security and privacy threats, state-of-the-art solutions, and future challenges of the AIGC paradigm. Specifically, we first explore the enabling technologies, general architecture of AIGC, and discuss its working modes and key characteristics. Then, we investigate the taxonomy of security and privacy threats to AIGC and highlight the ethical and societal implications of GPT and AIGC technologies. Furthermore, we review the state-of-the-art AIGC watermarking approaches for regulatable AIGC paradigms regarding the AIGC model and its produced content. Finally, we identify future challenges and open research directions related to AIGC.",
    "doi": "10.1109/ojcs.2023.3300321",
    "url": "https://openalex.org/W4385469325",
    "pdf_url": "https://ieeexplore.ieee.org/ielx7/8782664/9024218/10221755.pdf",
    "venue": "IEEE Open Journal of the Computer Society",
    "citation_count": 273,
    "fields_of_study": [
      "Pace",
      "Computer science",
      "Key (lock)",
      "Data science",
      "Generative grammar"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622911"
  },
  {
    "source": "openalex",
    "source_id": "W2786522954",
    "title": "Patiency is not a virtue: the design of intelligent systems and systems of ethics",
    "authors": [
      "Joanna J. Bryson"
    ],
    "year": 2018,
    "abstract": "The question of whether AI systems such as robots can or should be afforded moral agency or patiency is not one amenable either to discovery or simple reasoning, because we as societies constantly reconstruct our artefacts, including our ethical systems. Consequently, the place of AI systems in society is a matter of normative, not descriptive ethics. Here I start from a functionalist assumption, that ethics is the set of behaviour that maintains a society. This assumption allows me to exploit the theoretical biology of sociality and autonomy to explain our moral intuitions. From this grounding I extend to consider possible ethics for maintaining either human- or of artefact-centred societies. I conclude that while constructing AI systems as either moral agents or patients is possible, neither is desirable. In particular, I argue that we are unlikely to construct a coherent ethics in which it it is ethical to afford AI moral subjectivity. We are therefore obliged not to build AI we are obliged to.",
    "doi": "10.1007/s10676-018-9448-6",
    "url": "https://openalex.org/W2786522954",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007%2Fs10676-018-9448-6.pdf",
    "venue": "Ethics and Information Technology",
    "citation_count": 234,
    "fields_of_study": [
      "Autonomy",
      "Epistemology",
      "Sociology",
      "Exploit",
      "Normative"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622927"
  },
  {
    "source": "openalex",
    "source_id": "W4318483790",
    "title": "Evaluation of artificial intelligence techniques in disease diagnosis and prediction",
    "authors": [
      "Nafiseh Ghaffar Nia",
      "Erkan Kaplano\u011flu",
      "Ahad Nasab"
    ],
    "year": 2023,
    "abstract": "Abstract A broad range of medical diagnoses is based on analyzing disease images obtained through high-tech digital devices. The application of artificial intelligence (AI) in the assessment of medical images has led to accurate evaluations being performed automatically, which in turn has reduced the workload of physicians, decreased errors and times in diagnosis, and improved performance in the prediction and detection of various diseases. AI techniques based on medical image processing are an essential area of research that uses advanced computer algorithms for prediction, diagnosis, and treatment planning, leading to a remarkable impact on decision-making procedures. Machine Learning (ML) and Deep Learning (DL) as advanced AI techniques are two main subfields applied in the healthcare system to diagnose diseases, discover medication, and identify patient risk factors. The advancement of electronic medical records and big data technologies in recent years has accompanied the success of ML and DL algorithms. ML includes neural networks and fuzzy logic algorithms with various applications in automating forecasting and diagnosis processes. DL algorithm is an ML technique that does not rely on expert feature extraction, unlike classical neural network algorithms. DL algorithms with high-performance calculations give promising results in medical image analysis, such as fusion, segmentation, recording, and classification. Support Vector Machine (SVM) as an ML method and Convolutional Neural Network (CNN) as a DL method is usually the most widely used techniques for analyzing and diagnosing diseases. This review study aims to cover recent AI techniques in diagnosing and predicting numerous diseases such as cancers, heart, lung, skin, genetic, and neural disorders, which perform more precisely compared to specialists without human error. Also, AI's existing challenges and limitations in the medical area are discussed and highlighted.",
    "doi": "10.1007/s44163-023-00049-5",
    "url": "https://openalex.org/W4318483790",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s44163-023-00049-5.pdf",
    "venue": "Discover Artificial Intelligence",
    "citation_count": 321,
    "fields_of_study": [
      "Artificial intelligence",
      "Computer science",
      "Medical diagnosis",
      "Machine learning",
      "Artificial neural network"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622941"
  },
  {
    "source": "openalex",
    "source_id": "W4386293515",
    "title": "Artificial intelligence in clinical medicine: catalyzing a sustainable global healthcare paradigm",
    "authors": [
      "Gokul Krishnan",
      "Shiana Singh",
      "Monika Pathania",
      "Siddharth Gosavi",
      "Shuchi Abhishek",
      "Ashwin Parchani",
      "Minakshi Dhar"
    ],
    "year": 2023,
    "abstract": "As the demand for quality healthcare increases, healthcare systems worldwide are grappling with time constraints and excessive workloads, which can compromise the quality of patient care. Artificial intelligence (AI) has emerged as a powerful tool in clinical medicine, revolutionizing various aspects of patient care and medical research. The integration of AI in clinical medicine has not only improved diagnostic accuracy and treatment outcomes, but also contributed to more efficient healthcare delivery, reduced costs, and facilitated better patient experiences. This review article provides an extensive overview of AI applications in history taking, clinical examination, imaging, therapeutics, prognosis and research. Furthermore, it highlights the critical role AI has played in transforming healthcare in developing nations.",
    "doi": "10.3389/frai.2023.1227091",
    "url": "https://openalex.org/W4386293515",
    "pdf_url": "https://www.frontiersin.org/articles/10.3389/frai.2023.1227091/pdf",
    "venue": "Frontiers in Artificial Intelligence",
    "citation_count": 241,
    "fields_of_study": [
      "Health care",
      "Compromise",
      "Healthcare delivery",
      "Healthcare system",
      "Quality (philosophy)"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622964"
  },
  {
    "source": "openalex",
    "source_id": "W3037473845",
    "title": "A typology of circular economy discourses: Navigating the diverse visions of a contested paradigm",
    "authors": [
      "Martin Calisto Friant",
      "Walter J.V. Vermeulen",
      "Roberta Salomone"
    ],
    "year": 2020,
    "abstract": "The circular economy (CE) has recently become a popular discourse especially in government and corporate sectors. Given the socio-ecological challenges of the Anthropocene, the concept of CE could indeed help the transition to a sustainable, just and resilient future. However, the actual definition, objectives and forms of implementation of the CE are still unclear, inconsistent, and contested. Different actors and sectors are thus articulating circular discourses which align with their interests, and which often do not sufficiently examine the ecological, social and political implications of circularity. In this context, this research asks how to better navigate and analyse the history, complexity and plurality of circularity discourses by conceptually differentiating them in a comprehensive discourse typology. To answer this question a critical literature review has been carried out, which first, examines and reflects on the core challenges, gaps and limitations of the CE concept. Second, this research develops a comprehensive timeline of circularity thinking, which identifies and conceptually classifies 72 different CE-related concepts from the Global North and South (such as Gandhian and steady-state economics, buen vivir, doughnut economics and degrowth). This leads to the development of a typology of circularity discourses, which classifies circularity visions according to their position on fundamental social, technological, political and ecological issues. This research thus seeks to provide a basis for a more inclusive and comprehensive discussion on the topic, which opens the imaginary regarding the many circular futures that can exist and allows for a cross-pollination of ideas, policy options, strategies, practices and solutions.",
    "doi": "10.1016/j.resconrec.2020.104917",
    "url": "https://openalex.org/W3037473845",
    "pdf_url": "https://ars.els-cdn.com/content/image/1-s2.0-S0921344920302354-fx1_lrg.jpg",
    "venue": "Resources Conservation and Recycling",
    "citation_count": 549,
    "fields_of_study": [
      "Vision",
      "Typology",
      "Circular economy",
      "Degrowth",
      "Context (archaeology)"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622975"
  },
  {
    "source": "openalex",
    "source_id": "W4392621828",
    "title": "E-commerce and consumer behavior: A review of AI-powered personalization and market trends",
    "authors": [
      "Mustafa Ayobami Raji",
      "Hameedat Bukola Olodo",
      "Timothy Tolulope Oke",
      "Wilhelmina Afua Addy",
      "Onyeka Chrisanctus Ofodile",
      "Adedoyin Tolulope Oyewole"
    ],
    "year": 2024,
    "abstract": "In the dynamic landscape of electronic commerce (e-commerce), understanding and adapting to evolving consumer behavior is critical for the sustained success of online businesses. This review delves into the intersection of e-commerce and consumer behavior, focusing on the transformative role of Artificial Intelligence (AI)-powered personalization and its impact on market trends. The advent of AI has revolutionized the way e-commerce platforms engage with and cater to individual consumer preferences. AI-powered personalization techniques leverage advanced algorithms to analyze vast datasets, enabling the delivery of highly tailored and relevant content, product recommendations, and user experiences. This review explores the intricate mechanisms of AI-driven personalization, examining how it enhances customer engagement, satisfaction, and loyalty. Furthermore, the study investigates the prominent market trends shaped by AI in e-commerce. From chatbots and virtual assistants facilitating seamless customer interactions to predictive analytics optimizing inventory management, AI is driving innovation across various facets of the online retail landscape. The analysis delves into the integration of machine learning algorithms in predicting consumer preferences, streamlining the purchasing process, and fostering a more personalized shopping journey. As e-commerce continues to evolve, the review also explores the challenges and ethical considerations associated with AI-powered personalization. Issues such as data privacy, algorithmic bias, and the delicate balance between customization and intrusiveness are examined to provide a comprehensive understanding of the broader implications of AI in shaping consumer behavior. Ultimately, this review offers valuable insights into the symbiotic relationship between e-commerce and consumer behavior, shedding light on the transformative power of AI-powered personalization and its influence on emerging market trends. As businesses navigate the digital landscape, understanding and harnessing the potential of AI-driven strategies become imperative for staying competitive and meeting the evolving expectations of tech-savvy consumers.",
    "doi": "10.30574/gscarr.2024.18.3.0090",
    "url": "https://openalex.org/W4392621828",
    "pdf_url": "https://gsconlinepress.com/journals/gscarr/sites/default/files/GSCARR-2024-0090.pdf",
    "venue": "GSC Advanced Research and Reviews",
    "citation_count": 181,
    "fields_of_study": [
      "Personalization",
      "E-commerce",
      "Business",
      "Advertising",
      "Commerce"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622996"
  },
  {
    "source": "openalex",
    "source_id": "W4394688113",
    "title": "REVOLUTIONIZING EDUCATION THROUGH AI: A COMPREHENSIVE REVIEW OF ENHANCING LEARNING EXPERIENCES",
    "authors": [
      "Oseremi Onesi-Ozigagun",
      "Yinka James Ololade",
      "Nsisong Louis Eyo-Udo",
      "Damilola Oluwaseun Ogundipe"
    ],
    "year": 2024,
    "abstract": "Artificial Intelligence (AI) is transforming the landscape of education, offering innovative solutions to enhance learning experiences. This review provides a comprehensive overview of how AI is revolutionizing education, focusing on its impact on learning outcomes, teaching methodologies, and the overall educational ecosystem. The adoption of AI in education has led to personalized learning experiences tailored to individual student needs. AI-powered adaptive learning systems analyze student performance data to create customized learning paths, ensuring that students receive content at their pace and level of understanding. This personalized approach improves student engagement and academic performance. AI is also reshaping teaching methodologies, providing educators with tools to streamline administrative tasks and enhance instructional strategies. AI-powered tools can automate grading, create interactive lessons, and provide real-time feedback to students. This allows teachers to focus more on facilitating learning and developing critical thinking skills in students. Furthermore, AI is revolutionizing the assessment process, moving beyond traditional exams to more dynamic and insightful evaluation methods. AI-powered assessment tools can analyze student responses in real-time, providing immediate feedback and insights into student comprehension and learning progress. The integration of AI in education also extends to administrative functions, such as student enrollment, scheduling, and resource allocation. AI-powered systems can optimize these processes, leading to more efficient and effective management of educational institutions. Despite the numerous benefits of AI in education, challenges remain, including concerns about data privacy, algorithmic bias, and the need for teacher training. Addressing these challenges will be crucial to maximizing the potential of AI in education and ensuring equitable access to quality education for all. In conclusion, AI is revolutionizing education by enhancing learning experiences, transforming teaching methodologies, and optimizing administrative processes. As AI continues to evolve, its impact on education is expected to grow, offering new opportunities to improve learning outcomes and prepare students for success in the digital age. Keywords: Revolutionizing, AI, Enhancing, Learning, Experiences.",
    "doi": "10.51594/ijarss.v6i4.1011",
    "url": "https://openalex.org/W4394688113",
    "pdf_url": "https://fepbl.com/index.php/ijarss/article/download/1011/1233",
    "venue": "International Journal of Applied Research in Social Sciences",
    "citation_count": 211,
    "fields_of_study": [
      "Engineering ethics",
      "Psychology",
      "Engineering"
    ],
    "retrieved_at": "2026-02-02T16:58:11.623019"
  },
  {
    "source": "openalex",
    "source_id": "W2784070037",
    "title": "Big healthcare data: preserving security and privacy",
    "authors": [
      "Karim Abouelmehdi",
      "Abderrahim Beni-Hessane",
      "Hayat Khaloufi"
    ],
    "year": 2018,
    "abstract": "Abstract Big data has fundamentally changed the way organizations manage, analyze and leverage data in any industry. One of the most promising fields where big data can be applied to make a change is healthcare. Big healthcare data has considerable potential to improve patient outcomes, predict outbreaks of epidemics, gain valuable insights, avoid preventable diseases, reduce the cost of healthcare delivery and improve the quality of life in general. However, deciding on the allowable uses of data while preserving security and patient\u2019s right to privacy is a difficult task. Big data, no matter how useful for the advancement of medical science and vital to the success of all healthcare organizations, can only be used if security and privacy issues are addressed. To ensure a secure and trustworthy big data environment, it is essential to identify the limitations of existing solutions and envision directions for future research. In this paper, we have surveyed the state-of-the-art security and privacy challenges in big data as applied to healthcare industry, assessed how security and privacy issues occur in case of big healthcare data and discussed ways in which they may be addressed. We mainly focused on the recently proposed methods based on anonymization and encryption, compared their strengths and limitations, and envisioned future research directions.",
    "doi": "10.1186/s40537-017-0110-7",
    "url": "https://openalex.org/W2784070037",
    "pdf_url": "https://journalofbigdata.springeropen.com/track/pdf/10.1186/s40537-017-0110-7",
    "venue": "Journal Of Big Data",
    "citation_count": 705,
    "fields_of_study": [
      "Big data",
      "Computer science",
      "Health care",
      "Leverage (statistics)",
      "Encryption"
    ],
    "retrieved_at": "2026-02-02T16:58:11.623043"
  },
  {
    "source": "openalex",
    "source_id": "W3001824711",
    "title": "Security and the smart city: A systematic review",
    "authors": [
      "Julian Laufs",
      "Herv\u00e9 Borrion",
      "Ben Bradford"
    ],
    "year": 2020,
    "abstract": null,
    "doi": "10.1016/j.scs.2020.102023",
    "url": "https://openalex.org/W3001824711",
    "pdf_url": "https://www.sciencedirect.com/science/article/pii/S221067072030010X",
    "venue": "Sustainable Cities and Society",
    "citation_count": 278,
    "fields_of_study": [
      "Smart city",
      "Architectural engineering",
      "Engineering",
      "Computer security",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:11.623061"
  },
  {
    "source": "openalex",
    "source_id": "W2989347311",
    "title": "The Organizational Reproduction of Inequality",
    "authors": [
      "John Amis",
      "Johanna Mair",
      "Kamal A. Munir"
    ],
    "year": 2019,
    "abstract": "With societal inequalities continuing to increase and organizations providing the vast majority of people with their income, we wanted to assess the ways in which organizational practices are implicated in the burgeoning of social and economic inequality. Following an integrative review of the literature drawn from across the social sciences, we found that the multiple ways in which five major organizational practices \u2013 hiring, role allocation, promotion, compensation and structuring \u2013 are enacted emerged as being central to the reproduction of inequality. We also uncovered how the persistence of these practices, and the inequality they induce, can be largely attributed to a constellation of three highly institutionalized myths, efficiency, meritocracy and positive globalization. Our analysis further reveals how, as scholars, we bear a corresponding responsibility to reconsider how we engage in research on and teaching about organizations. The implications of this for our future work are discussed.",
    "doi": "10.5465/annals.2017.0033",
    "url": "https://openalex.org/W2989347311",
    "pdf_url": "https://www.research.ed.ac.uk/en/publications/ffe6689d-f349-4603-94d7-1ba5552e923f",
    "venue": "Academy of Management Annals",
    "citation_count": 416,
    "fields_of_study": [
      "Meritocracy",
      "Reproduction",
      "Inequality",
      "Social inequality",
      "Globalization"
    ],
    "retrieved_at": "2026-02-02T16:58:11.623063"
  },
  {
    "source": "openalex",
    "source_id": "W4391898528",
    "title": "REVIEWING THE ETHICAL IMPLICATIONS OF AI IN DECISION MAKING PROCESSES",
    "authors": [
      "Femi Osasona",
      "Olukunle Oladipupo Amoo",
      "Akoh Atadoga",
      "Temitayo Oluwaseun Abrahams",
      "Oluwatoyin Ajoke Farayola",
      "Benjamin Samson Ayinla"
    ],
    "year": 2024,
    "abstract": "Artificial Intelligence (AI) has rapidly become an integral part of decision-making processes across various industries, revolutionizing the way choices are made. This Review delves into the ethical considerations associated with the use of AI in decision-making, exploring the implications of algorithms, automation, and machine learning. The incorporation of AI in decision-making introduces a myriad of ethical concerns that demand careful scrutiny. The opacity of algorithms raises questions about transparency, accountability, and bias. Decision-making processes driven by AI can be complex and difficult to interpret, leading to challenges in understanding how and why specific choices are made. As a result, ethical concerns emerge regarding the potential lack of transparency and accountability, especially when these decisions impact individuals or societal groups. Bias in AI algorithms poses a critical ethical challenge. Machine learning models learn from historical data, and if that data is biased, the AI system may perpetuate and even exacerbate existing biases. Addressing this challenge requires meticulous examination of training data, algorithmic design, and ongoing monitoring to ensure fairness and mitigate discrimination. The increased reliance on AI in decision-making processes also raises concerns about accountability and responsibility. When AI systems make decisions, determining who is ultimately responsible for those decisions becomes a complex ethical issue. Establishing a framework for accountability is crucial to ensure that individuals, organizations, and developers share responsibility for the outcomes of AI-driven decisions. Moreover, ethical considerations extend to the broader societal impact of AI in decision-making. Issues such as job displacement, economic inequality, and the potential concentration of power in the hands of a few require careful ethical examination. Striking a balance between technological advancement and social responsibility is paramount to ensuring that AI benefits society as a whole. In conclusion, this review highlights the ethical implications of integrating AI into decision-making processes. It underscores the need for transparency, fairness, and accountability to address concerns related to bias, responsibility, and the broader societal impact of AI-driven decisions. Ethical frameworks must evolve alongside technological advancements to foster a responsible and equitable integration of AI in decision-making processes. Keywords: Ethical, Implications, AI, Decision Making, Process.",
    "doi": "10.51594/ijmer.v6i2.773",
    "url": "https://openalex.org/W4391898528",
    "pdf_url": "https://fepbl.com/index.php/ijmer/article/download/773/967",
    "venue": "International Journal of Management & Entrepreneurship Research",
    "citation_count": 141,
    "fields_of_study": [
      "Engineering ethics",
      "Ethical decision",
      "Management science",
      "Political science",
      "Psychology"
    ],
    "retrieved_at": "2026-02-02T16:58:11.623077"
  },
  {
    "source": "openalex",
    "source_id": "W3137761476",
    "title": "Does \u201cAI\u201d stand for augmenting inequality in the era of covid-19 healthcare?",
    "authors": [
      "David Leslie",
      "Anjali Mazumder",
      "Aidan Peppin",
      "Maria K Wolters",
      "Alexa Hagerty"
    ],
    "year": 2021,
    "abstract": "Among the most damaging characteristics of the covid-19 pandemic has been its\\ndisproportionate effect on disadvantaged communities. As the outbreak has\\nspread globally, factors such as systemic racism, marginalisation, and\\nstructural inequality have created path dependencies that have led to poor\\nhealth outcomes. These social determinants of infectious disease and\\nvulnerability to disaster have converged to affect already disadvantaged\\ncommunities with higher levels of economic instability, disease exposure,\\ninfection severity, and death. Artificial intelligence (AI) technologies are an\\nimportant part of the health informatics toolkit used to fight contagious\\ndisease. AI is well known, however, to be susceptible to algorithmic biases\\nthat can entrench and augment existing inequality. Uncritically deploying AI in\\nthe fight against covid-19 thus risks amplifying the pandemic's adverse effects\\non vulnerable groups, exacerbating health inequity. In this paper, we claim\\nthat AI systems can introduce or reflect bias and discrimination in three ways:\\nin patterns of health discrimination that become entrenched in datasets, in\\ndata representativeness, and in human choices made during the design,\\ndevelopment, and deployment of these systems. We highlight how the use of AI\\ntechnologies threaten to exacerbate the disparate effect of covid-19 on\\nmarginalised, under-represented, and vulnerable groups, particularly black,\\nAsian, and other minoritised ethnic people, older populations, and those of\\nlower socioeconomic status. We conclude that, to mitigate the compounding\\neffects of AI on inequalities associated with covid-19, decision makers,\\ntechnology developers, and health officials must account for the potential\\nbiases and inequities at all stages of the AI process.\\n",
    "doi": "10.1136/bmj.n304",
    "url": "https://openalex.org/W3137761476",
    "pdf_url": "https://www.bmj.com/content/bmj/372/bmj.n304.full.pdf",
    "venue": "BMJ",
    "citation_count": 155,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:11.623106"
  },
  {
    "source": "openalex",
    "source_id": "W4385059984",
    "title": "A Review of Trustworthy and Explainable Artificial Intelligence (XAI)",
    "authors": [
      "Vinay Chamola",
      "Vikas Hassija",
      "A. Razia Sulthana",
      "Debshishu Ghosh",
      "Divyansh Dhingra",
      "Biplab Sikdar"
    ],
    "year": 2023,
    "abstract": "The advancement of Artificial Intelligence (AI) technology has accelerated the development of several systems that are elicited from it. This boom has made the systems vulnerable to security attacks and allows considerable bias in order to handle errors in the system. This puts humans at risk and leaves machines, robots, and data defenseless. Trustworthy AI (TAI) guarantees human value and the environment. In this paper, we present a comprehensive review of the state-of-the-art on how to build a Trustworthy and eXplainable AI, taking into account that AI is a black box with little insight into its underlying structure. The paper also discusses various TAI components, their corresponding bias, and inclinations that make the system unreliable. The study also discusses the necessity for TAI in many verticals, including banking, healthcare, autonomous system, and IoT. We unite the ways of building trust in all fragmented areas of data protection, pricing, expense, reliability, assurance, and decision-making processes utilizing TAI in several diverse industries and to differing degrees. It also emphasizes the importance of transparent and post hoc explanation models in the construction of an eXplainable AI and lists the potential drawbacks and pitfalls of building eXplainable AI. Finally, the policies for developing TAI in the autonomous vehicle construction sectors are thoroughly examined and eclectic ways of building a reliable, interpretable, eXplainable, and Trustworthy AI systems are explained to guarantee safe autonomous vehicle systems.",
    "doi": "10.1109/access.2023.3294569",
    "url": "https://openalex.org/W4385059984",
    "pdf_url": "https://ieeexplore.ieee.org/ielx7/6287639/6514899/10188681.pdf",
    "venue": "IEEE Access",
    "citation_count": 220,
    "fields_of_study": [
      "Computer science",
      "Trustworthiness",
      "Boom",
      "Order (exchange)",
      "Computer security"
    ],
    "retrieved_at": "2026-02-02T16:58:11.623125"
  },
  {
    "source": "openalex",
    "source_id": "W4394009485",
    "title": "AI-Driven Clinical Decision Support Systems: An Ongoing Pursuit of Potential",
    "authors": [
      "Malek Elhaddad",
      "Sara Hamam"
    ],
    "year": 2024,
    "abstract": "Clinical Decision Support Systems (CDSS) are essential tools in contemporary healthcare, enhancing clinicians' decisions and patient outcomes. The integration of artificial intelligence (AI) is now revolutionizing CDSS even further. This review delves into AI technologies transforming CDSS, their applications in healthcare decision-making, associated challenges, and the potential trajectory toward fully realizing AI-CDSS's potential. The review begins by laying the groundwork with a definition of CDSS and its function within the healthcare field. It then highlights the increasingly significant role that AI is playing in enhancing CDSS effectiveness and efficiency, underlining its evolving prominence in shaping healthcare practices. It examines the integration of AI technologies into CDSS, including machine learning algorithms like neural networks and decision trees, natural language processing, and deep learning. It also addresses the challenges associated with AI integration, such as interpretability and bias. We then shift to AI applications within CDSS, with real-life examples of AI-driven diagnostics, personalized treatment recommendations, risk prediction, early intervention, and AI-assisted clinical documentation. The review emphasizes user-centered design in AI-CDSS integration, addressing usability, trust, workflow, and ethical and legal considerations. It acknowledges prevailing obstacles and suggests strategies for successful AI-CDSS adoption, highlighting the need for workflow alignment and interdisciplinary collaboration. The review concludes by summarizing key findings, underscoring AI's transformative potential in CDSS, and advocating for continued research and innovation. It emphasizes the need for collaborative efforts to realize a future where AI-powered CDSS optimizes healthcare delivery and improves patient outcomes.",
    "doi": "10.7759/cureus.57728",
    "url": "https://openalex.org/W4394009485",
    "pdf_url": "https://assets.cureus.com/uploads/review_article/pdf/244463/20240406-13366-1bzxzru.pdf",
    "venue": "Cureus",
    "citation_count": 168,
    "fields_of_study": [
      "Clinical decision support system",
      "Workflow",
      "Interpretability",
      "Usability",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:11.623143"
  },
  {
    "source": "openalex",
    "source_id": "W3178786669",
    "title": "Ethics-Based Auditing of Automated Decision-Making Systems: Nature, Scope, and Limitations",
    "authors": [
      "Jakob M\u00f6kander",
      "Jessica Morley",
      "Mariarosaria Taddeo",
      "Luciano Floridi"
    ],
    "year": 2021,
    "abstract": null,
    "doi": "10.1007/s11948-021-00319-4",
    "url": "https://openalex.org/W3178786669",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s11948-021-00319-4.pdf",
    "venue": "Science and Engineering Ethics",
    "citation_count": 151,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:11.623162"
  },
  {
    "source": "openalex",
    "source_id": "W4388424540",
    "title": "Artificial intelligence in language instruction: impact on English learning achievement, L2 motivation, and self-regulated learning",
    "authors": [
      "Ling Wei"
    ],
    "year": 2023,
    "abstract": "Introduction This mixed methods study examines the effects of AI-mediated language instruction on English learning achievement, L2 motivation, and self-regulated learning among English as a Foreign Language (EFL) learners. It addresses the increasing interest in AI-driven educational technologies and their potential to revolutionize language instruction. Methods Two intact classes, consisting of a total of 60 university students, participated in this study. The experimental group received AI-mediated instruction, while the control group received traditional language instruction. Pre-tests and post-tests were administered to evaluate English learning achievement across various domains, including grammar, vocabulary, reading comprehension, and writing skills. Additionally, self-report questionnaires were employed to assess L2 motivation and self-regulated learning. Results Quantitative analysis revealed that the experimental group achieved significantly higher English learning outcomes in all assessed areas compared to the control group. Furthermore, they exhibited greater L2 motivation and more extensive utilization of self-regulated learning strategies. These results suggest that AI-mediated instruction positively impacts English learning achievement, L2 motivation, and self-regulated learning. Discussion Qualitative analysis of semi-structured interviews with 14 students from the experimental group shed light on the transformative effects of the AI platform. It was found to enhance engagement and offer personalized learning experiences, ultimately boosting motivation and fostering self-regulated learning. These findings emphasize the potential of AI-mediated language instruction to improve language learning outcomes, motivate learners, and promote autonomy. Conclusion This study contributes to evidence-based language pedagogy, offering valuable insights to educators and researchers interested in incorporating AI-powered platforms into language classrooms. The results support the notion that AI-mediated language instruction holds promise in revolutionizing language learning, and it highlights the positive impact of AI-driven educational technologies in the realm of language education.",
    "doi": "10.3389/fpsyg.2023.1261955",
    "url": "https://openalex.org/W4388424540",
    "pdf_url": "https://www.frontiersin.org/articles/10.3389/fpsyg.2023.1261955/pdf?isPublishedV2=False",
    "venue": "Frontiers in Psychology",
    "citation_count": 325,
    "fields_of_study": [
      "Psychology",
      "Mathematics education",
      "Learner autonomy",
      "Language learning strategies",
      "Language acquisition"
    ],
    "retrieved_at": "2026-02-02T16:58:11.623164"
  },
  {
    "source": "openalex",
    "source_id": "W4327952037",
    "title": "How to Bell the Cat? A Theoretical Review of Generative Artificial Intelligence towards Digital Disruption in All Walks of Life",
    "authors": [
      "Subhra R. Mondal",
      "Subhankar Das",
      "Vasiliki Vrana"
    ],
    "year": 2023,
    "abstract": "Generative Artificial Intelligence (GAI) has brought revolutionary changes to the world, enabling businesses to create new experiences by combining virtual and physical worlds. As the use of GAI grows along with the Metaverse, it is explored by academics, researchers, and industry communities for its endless possibilities. From ChatGPT by OpenAI to Bard AI by Google, GAI is a leading technology in physical and virtual business platforms. This paper focuses on GAI\u2019s economic and societal impact and the challenges it poses. Businesses must rethink their operations and strategies to create hybrid physical and virtual experiences using GAI. This study proposes a framework that can help business managers develop effective strategies to enhance their operations. It analyzes the initial applications of GAI in multiple sectors to promote the development of future customer solutions and explores how GAI can help businesses create new value propositions and experiences for their customers, and the possibilities of digital communication and information technology. A research agenda is proposed for developing GAI for business management to enhance organizational efficiency. The results highlight a healthy conversation on the potential of GAI in various business sectors to improve customer experience.",
    "doi": "10.3390/technologies11020044",
    "url": "https://openalex.org/W4327952037",
    "pdf_url": "https://www.mdpi.com/2227-7080/11/2/44/pdf?version=1679053742",
    "venue": "Technologies",
    "citation_count": 230,
    "fields_of_study": [
      "Metaverse",
      "Conversation",
      "Generative grammar",
      "Knowledge management",
      "Value (mathematics)"
    ],
    "retrieved_at": "2026-02-02T16:58:11.623186"
  },
  {
    "source": "openalex",
    "source_id": "W3213019454",
    "title": "Bosses without a heart: socio-demographic and cross-cultural determinants of attitude toward Emotional AI in the workplace",
    "authors": [
      "Peter Mantello",
      "Tung Manh Ho",
      "Minh\u2010Hoang Nguyen",
      "Quan\u2010Hoang Vuong"
    ],
    "year": 2021,
    "abstract": null,
    "doi": "10.1007/s00146-021-01290-1",
    "url": "https://openalex.org/W3213019454",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s00146-021-01290-1.pdf",
    "venue": "AI & Society",
    "citation_count": 173,
    "fields_of_study": [
      "Performing arts",
      "Psychology",
      "Social psychology",
      "Applied psychology",
      "Visual arts"
    ],
    "retrieved_at": "2026-02-02T16:58:11.623203"
  },
  {
    "source": "openalex",
    "source_id": "W4210739840",
    "title": "Embedded ethics: a proposal for integrating ethics into the development of medical AI",
    "authors": [
      "Stuart McLennan",
      "Amelia Fiske",
      "Daniel W. Tigard",
      "Ruth M\u00fcller",
      "Sami Haddadin",
      "Alena Buyx"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1186/s12910-022-00746-3",
    "url": "https://openalex.org/W4210739840",
    "pdf_url": "https://bmcmedethics.biomedcentral.com/track/pdf/10.1186/s12910-022-00746-3",
    "venue": "BMC Medical Ethics",
    "citation_count": 176,
    "fields_of_study": [
      "Philosophy of medicine",
      "Engineering ethics",
      "Medical law",
      "Information ethics",
      "Nursing ethics"
    ],
    "retrieved_at": "2026-02-02T16:58:11.623206"
  },
  {
    "source": "openalex",
    "source_id": "W3014487746",
    "title": "Directions in abusive language training data, a systematic review: Garbage in, garbage out",
    "authors": [
      "Bertie Vidgen",
      "Leon Derczynski"
    ],
    "year": 2020,
    "abstract": "Data-driven and machine learning based approaches for detecting, categorising and measuring abusive content such as hate speech and harassment have gained traction due to their scalability, robustness and increasingly high performance. Making effective detection systems for abusive content relies on having the right training datasets, reflecting a widely accepted mantra in computer science: Garbage In, Garbage Out. However, creating training datasets which are large, varied, theoretically-informed and that minimize biases is difficult, laborious and requires deep expertise. This paper systematically reviews 63 publicly available training datasets which have been created to train abusive language classifiers. It also reports on creation of a dedicated website for cataloguing abusive language data hatespeechdata.com . We discuss the challenges and opportunities of open science in this field, and argue that although more dataset sharing would bring many benefits it also poses social and ethical risks which need careful consideration. Finally, we provide evidence-based recommendations for practitioners creating new abusive content training datasets.",
    "doi": "10.1371/journal.pone.0243300",
    "url": "https://openalex.org/W3014487746",
    "pdf_url": "https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0243300&type=printable",
    "venue": "PLoS ONE",
    "citation_count": 269,
    "fields_of_study": [
      "Garbage",
      "Computer science",
      "Programming language"
    ],
    "retrieved_at": "2026-02-02T16:58:11.623208"
  },
  {
    "source": "openalex",
    "source_id": "W4383605161",
    "title": "A Survey on Evaluation of Large Language Models",
    "authors": [
      "Yupeng Chang",
      "Xu Wang",
      "Jindong Wang",
      "Yuan-Hsuan Wu",
      "Kaijie Zhu",
      "Hao Chen",
      "Linyi Yang",
      "Xiaoyuan Yi",
      "Cunxiang Wang",
      "Yidong Wang",
      "Wei Ye",
      "Yue Zhang",
      "Yi Chang",
      "Philip S. Yu",
      "Qiang Yang",
      "Xing Xie"
    ],
    "year": 2023,
    "abstract": "Large language models (LLMs) are gaining increasing popularity in both academia and industry, owing to their unprecedented performance in various applications. As LLMs continue to play a vital role in both research and daily use, their evaluation becomes increasingly critical, not only at the task level, but also at the society level for better understanding of their potential risks. Over the past years, significant efforts have been made to examine LLMs from various perspectives. This paper presents a comprehensive review of these evaluation methods for LLMs, focusing on three key dimensions: what to evaluate, where to evaluate, and how to evaluate. Firstly, we provide an overview from the perspective of evaluation tasks, encompassing general natural language processing tasks, reasoning, medical usage, ethics, educations, natural and social sciences, agent applications, and other areas. Secondly, we answer the `where' and `how' questions by diving into the evaluation methods and benchmarks, which serve as crucial components in assessing performance of LLMs. Then, we summarize the success and failure cases of LLMs in different tasks. Finally, we shed light on several future challenges that lie ahead in LLMs evaluation. Our aim is to offer invaluable insights to researchers in the realm of LLMs evaluation, thereby aiding the development of more proficient LLMs. Our key point is that evaluation should be treated as an essential discipline to better assist the development of LLMs. We consistently maintain the related open-source materials at: https://github.com/MLGroupJLU/LLM-eval-survey.",
    "doi": "10.48550/arxiv.2307.03109",
    "url": "https://openalex.org/W4383605161",
    "pdf_url": "https://arxiv.org/pdf/2307.03109",
    "venue": "arXiv (Cornell University)",
    "citation_count": 193,
    "fields_of_study": [
      "Popularity",
      "Engineering ethics",
      "Psychology",
      "Engineering",
      "Social psychology"
    ],
    "retrieved_at": "2026-02-02T16:58:11.623223"
  },
  {
    "source": "openalex",
    "source_id": "W2897037622",
    "title": "Considerations for ethics review of big data health research: A scoping review",
    "authors": [
      "Marcello Ienca",
      "Agata Ferretti",
      "Samia Hurst",
      "Milo A. Puhan",
      "Christian Lovis",
      "Effy Vayena"
    ],
    "year": 2018,
    "abstract": "Big data trends in biomedical and health research enable large-scale and multi-dimensional aggregation and analysis of heterogeneous data sources, which could ultimately result in preventive, diagnostic and therapeutic benefit. The methodological novelty and computational complexity of big data health research raises novel challenges for ethics review. In this study, we conducted a scoping review of the literature using five databases to identify and map the major challenges of health-related big data for Ethics Review Committees (ERCs) or analogous institutional review boards. A total of 1093 publications were initially identified, 263 of which were included in the final synthesis after abstract and full-text screening performed independently by two researchers. Both a descriptive numerical summary and a thematic analysis were performed on the full-texts of all articles included in the synthesis. Our findings suggest that while big data trends in biomedicine hold the potential for advancing clinical research, improving prevention and optimizing healthcare delivery, yet several epistemic, scientific and normative challenges need careful consideration. These challenges have relevance for both the composition of ERCs and the evaluation criteria that should be employed by ERC members when assessing the methodological and ethical viability of health-related big data studies. Based on this analysis, we provide some preliminary recommendations on how ERCs could adaptively respond to those challenges. This exploration is designed to synthesize useful information for researchers, ERCs and relevant institutional bodies involved in the conduction and/or assessment of health-related big data research.",
    "doi": "10.1371/journal.pone.0204937",
    "url": "https://openalex.org/W2897037622",
    "pdf_url": "https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0204937&type=printable",
    "venue": "PLoS ONE",
    "citation_count": 247,
    "fields_of_study": [
      "Big data",
      "Biomedicine",
      "Novelty",
      "Data science",
      "Thematic analysis"
    ],
    "retrieved_at": "2026-02-02T16:58:11.623242"
  },
  {
    "source": "openalex",
    "source_id": "W4377197101",
    "title": "Embracing Large Language Models for Medical Applications: Opportunities and Challenges",
    "authors": [
      "Mert Karabacak",
      "Konstantinos Margetis"
    ],
    "year": 2023,
    "abstract": "Large language models (LLMs) have the potential to revolutionize the field of medicine by, among other applications, improving diagnostic accuracy and supporting clinical decision-making. However, the successful integration of LLMs in medicine requires addressing challenges and considerations specific to the medical domain. This viewpoint article provides a comprehensive overview of key aspects for the successful implementation of LLMs in medicine, including transfer learning, domain-specific fine-tuning, domain adaptation, reinforcement learning with expert input, dynamic training, interdisciplinary collaboration, education and training, evaluation metrics, clinical validation, ethical considerations, data privacy, and regulatory frameworks. By adopting a multifaceted approach and fostering interdisciplinary collaboration, LLMs can be developed, validated, and integrated into medical practice responsibly, effectively, and ethically, addressing the needs of various medical disciplines and diverse patient populations. Ultimately, this approach will ensure that LLMs enhance patient care and improve overall health outcomes for all.",
    "doi": "10.7759/cureus.39305",
    "url": "https://openalex.org/W4377197101",
    "pdf_url": "https://assets.cureus.com/uploads/editorial/pdf/149797/20230521-25813-1nibw3l.pdf",
    "venue": "Cureus",
    "citation_count": 178,
    "fields_of_study": [
      "Adaptation (eye)",
      "Medicine",
      "Domain (mathematical analysis)",
      "Health care",
      "Engineering ethics"
    ],
    "retrieved_at": "2026-02-02T16:58:11.623261"
  },
  {
    "source": "openalex",
    "source_id": "W4223506650",
    "title": "The medical algorithmic audit",
    "authors": [
      "Xiaoxuan Liu",
      "Ben Glocker",
      "Melissa D. McCradden",
      "Marzyeh Ghassemi",
      "Alastair K. Denniston",
      "Lauren Oakden\u2010Rayner"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1016/s2589-7500(22)00003-6",
    "url": "https://openalex.org/W4223506650",
    "pdf_url": "http://www.thelancet.com/article/S2589750022000036/pdf",
    "venue": "The Lancet Digital Health",
    "citation_count": 195,
    "fields_of_study": [
      "Computer science",
      "Audit",
      "Software deployment",
      "Context (archaeology)",
      "Task (project management)"
    ],
    "retrieved_at": "2026-02-02T16:58:11.623274"
  },
  {
    "source": "openalex",
    "source_id": "W4386497355",
    "title": "Deep learning: systematic review, models, challenges, and research directions",
    "authors": [
      "Tala Talaei Khoei",
      "Hadjar Ould Slimane",
      "Naima Kaabouch"
    ],
    "year": 2023,
    "abstract": "Abstract The current development in deep learning is witnessing an exponential transition into automation applications. This automation transition can provide a promising framework for higher performance and lower complexity. This ongoing transition undergoes several rapid changes, resulting in the processing of the data by several studies, while it may lead to time-consuming and costly models. Thus, to address these challenges, several studies have been conducted to investigate deep learning techniques; however, they mostly focused on specific learning approaches, such as supervised deep learning. In addition, these studies did not comprehensively investigate other deep learning techniques, such as deep unsupervised and deep reinforcement learning techniques. Moreover, the majority of these studies neglect to discuss some main methodologies in deep learning, such as transfer learning, federated learning, and online learning. Therefore, motivated by the limitations of the existing studies, this study summarizes the deep learning techniques into supervised, unsupervised, reinforcement, and hybrid learning-based models. In addition to address each category, a brief description of these categories and their models is provided. Some of the critical topics in deep learning, namely, transfer, federated, and online learning models, are explored and discussed in detail. Finally, challenges and future directions are outlined to provide wider outlooks for future researchers.",
    "doi": "10.1007/s00521-023-08957-4",
    "url": "https://openalex.org/W4386497355",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s00521-023-08957-4.pdf",
    "venue": "Neural Computing and Applications",
    "citation_count": 301,
    "fields_of_study": [
      "Deep learning",
      "Artificial intelligence",
      "Computer science",
      "Transfer of learning",
      "Machine learning"
    ],
    "retrieved_at": "2026-02-02T16:58:11.623276"
  },
  {
    "source": "openalex",
    "source_id": "W3192526842",
    "title": "How Artificial Intelligence affords digital innovation: A cross-case analysis of Scandinavian companies",
    "authors": [
      "Cristina Trocin",
      "Ingrid V\u00e5ge Hovland",
      "Patrick Mikalef",
      "Christian Dremel"
    ],
    "year": 2021,
    "abstract": "Artificial Intelligence (AI) is fuelling a new breed of digital innovation in Human Resource Management (HRM) by creating new opportunities for complying with General Data Protection Regulation (GDPR) during data collection and analysis, decreasing biases, and offering targeted recommendations. However, AI is also posing challenges to organisations and key assumptions about digital innovation processes and outcomes, making it unclear how to combine AI affordances with actors, goals, and tasks. We conducted a qualitative multiple-case study in Scandinavian organisations offering HR services. Grounded theory guided our data collection and analysis. Input-Process-Output framework and affordance theory supported the analysis of specific information processing constraints and enablers. We developed a framework to explain how AI affordances enable digital innovation and address the calls about definitional boundaries between innovation processes and outcomes. We showed how AI affordances are actualised and how this leads to reontologising decision-making and providing data driven legitimisation. Our study contributes to digital innovation research by elucidating AI affordances and their actualisation in organisations. We conclude with the implications to theory and practice, limitations, and suggestions for future research.",
    "doi": "10.1016/j.techfore.2021.121081",
    "url": "https://openalex.org/W3192526842",
    "pdf_url": "https://linkinghub.elsevier.com/science/article/pii/S0040162521005138/pdfft?md5=f79a148995ffa4224f45831a4d28f6da&pid=1-s2.0-S0040162521005138-main.pdf",
    "venue": "Technological Forecasting and Social Change",
    "citation_count": 166,
    "fields_of_study": [
      "Affordance",
      "Knowledge management",
      "Process (computing)",
      "Computer science",
      "Data science"
    ],
    "retrieved_at": "2026-02-02T16:58:11.623293"
  },
  {
    "source": "openalex",
    "source_id": "W2999472659",
    "title": "A Survey on the Internet of Things (IoT) Forensics: Challenges, Approaches, and Open Issues",
    "authors": [
      "Maria Stoyanova",
      "Yannis Nikoloudakis",
      "Spyros Panagiotakis",
      "Evangelos Pallis",
      "Evangelos Markakis"
    ],
    "year": 2020,
    "abstract": "&lt;p&gt;Today is the era of the Internet of Things (IoT). The recent advances in hardware and information technology have accelerated the deployment of billions of interconnected, smart and adaptive devices in critical infrastructures like health, transportation, environmental control, and home automation. Transferring data over a network without requiring any kind of human-to-computer or human-to-human interaction, brings reliability and convenience to consumers, but also opens a new world of opportunity for intruders, and introduces a whole set of unique and complicated questions to the field of Digital Forensics. Although IoT data could be a rich source of evidence, forensics professionals cope with diverse problems, starting from the huge variety of IoT devices and non-standard formats, to the multi-tenant cloud infrastructure and the resulting multi-jurisdictional litigations. A further challenge is the end-to-end encryption which represents a trade-off between users&#39; right to privacy and the success of the forensics investigation. Due to its volatile nature, digital evidence has to be acquired and analyzed using validated tools and techniques that ensure the maintenance of the Chain of Custody. Therefore, the purpose of this paper is to identify and discuss the main issues involved in the complex process of IoT-based investigations, particularly all legal, privacy and cloud security challenges. Furthermore, this work provides an overview of the past and current theoretical models in the digital forensics science. Special attention is paid to frameworks that aim to extract data in a privacy-preserving manner or secure the evidence integrity using decentralized blockchain-based solutions. In addition, the present paper addresses the ongoing Forensics-as-a-Service (FaaS) paradigm, as well as some promising cross-cutting data reduction and forensics intelligence techniques. Finally, several other research trends and open issues are presented, with emphasis on the need for proactive Forensics Readiness strategies and generally agreed-upon standards.&lt;/p&gt;",
    "doi": "10.1109/comst.2019.2962586",
    "url": "https://openalex.org/W2999472659",
    "pdf_url": "https://ieeexplore.ieee.org/ielx7/9739/9102343/08950109.pdf",
    "venue": "IEEE Communications Surveys & Tutorials",
    "citation_count": 799,
    "fields_of_study": [
      "Computer science",
      "Digital forensics",
      "Computer security",
      "Digital evidence",
      "Cloud computing"
    ],
    "retrieved_at": "2026-02-02T16:58:11.623309"
  },
  {
    "source": "openalex",
    "source_id": "W3048672457",
    "title": "An Introduction to Ethics in Robotics and AI",
    "authors": [
      "Christoph Bartneck",
      "Christoph L\u00fctge",
      "Alan R. Wagner",
      "Sean Welsh"
    ],
    "year": 2020,
    "abstract": null,
    "doi": "10.1007/978-3-030-51110-4",
    "url": "https://openalex.org/W3048672457",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007%2F978-3-030-51110-4.pdf",
    "venue": "SpringerBriefs in ethics",
    "citation_count": 194,
    "fields_of_study": [
      "Artificial intelligence",
      "Robotics",
      "Engineering ethics",
      "Cognitive science",
      "Psychology"
    ],
    "retrieved_at": "2026-02-02T16:58:11.623332"
  },
  {
    "source": "openalex",
    "source_id": "W4300484403",
    "title": "Artificial Intelligence and Learning Analytics in Teacher Education: A Systematic Review",
    "authors": [
      "Sdenka Zobeida Salas\u2010Pilco",
      "Kejiang Xiao",
      "Xinyun Hu"
    ],
    "year": 2022,
    "abstract": "In recent years, artificial intelligence (AI) and learning analytics (LA) have been introduced into the field of education, where their use has great potential to enhance the teaching and learning processes. Researchers have focused on applying these technologies to teacher education, as they see the value of technology for educating. Therefore, a systematic review of the literature on AI and LA in teacher education is necessary to understand their impact in the field. Our methodology follows the PRISMA guidelines, and 30 studies related to teacher education were identified. This review analyzes and discusses the several ways in which AI and LA are being integrated in teacher education based on the studies\u2019 goals, participants, data sources, and the tools used to enhance teaching and learning activities. The findings indicate that (a) there is a focus on studying the behaviors, perceptions, and digital competence of pre- and in-service teachers regarding the use of AI and LA in their teaching practices; (b) the main data sources are behavioral data, discourse data, and statistical data; (c) machine learning algorithms are employed in most of the studies; and (d) the ethical clearance is mentioned by few studies. The implications will be valuable for teachers and educational authorities, informing their decisions regarding the effective use of AI and LA technologies to support teacher education.",
    "doi": "10.3390/educsci12080569",
    "url": "https://openalex.org/W4300484403",
    "pdf_url": "https://www.mdpi.com/2227-7102/12/8/569/pdf?version=1660996643",
    "venue": "Education Sciences",
    "citation_count": 216,
    "fields_of_study": [
      "Competence (human resources)",
      "Teacher education",
      "Computer science",
      "Learning analytics",
      "Analytics"
    ],
    "retrieved_at": "2026-02-02T16:58:11.623335"
  },
  {
    "source": "openalex",
    "source_id": "W2990170714",
    "title": "Artificial intelligence supported patient self-care in chronic heart failure: a paradigm shift from reactive to predictive, preventive and personalised care",
    "authors": [
      "Matthew Barrett",
      "Josiane Boyne",
      "Julia Brandts",
      "Hans\u2010Peter Brunner\u2010La Rocca",
      "Lieven De Maesschalck",
      "Kurt De Wit",
      "Lana Dixon",
      "Casper Eurlings",
      "Donna Fitzsimons",
      "Olga Golubnitschaja",
      "Arjan Hageman",
      "Frank Heemskerk",
      "Andr\u00e9 Hintzen",
      "Thomas M. Helms",
      "Loreena Hill",
      "Thom Hoedemakers",
      "Nikolaus Marx",
      "Kenneth McDonald",
      "Marc Mertens",
      "Dirk M\u00fcller\u2010Wieland",
      "Alexander Palant",
      "Jens Piesk",
      "Andrew Pomazanskyi",
      "Jan Ramaekers",
      "Peter Ruff",
      "Katharina Sch\u00fctt",
      "Yash Shekhawat",
      "Chantal F. Ski",
      "David R. Thompson",
      "Andrew Tsirkin",
      "Kay van der Mierden",
      "Chris Watson",
      "Bettina Zippel\u2010Schultz"
    ],
    "year": 2019,
    "abstract": "Abstract Heart failure (HF) is one of the most complex chronic disorders with high prevalence, mainly due to the ageing population and better treatment of underlying diseases. Prevalence will continue to rise and is estimated to reach 3% of the population in Western countries by 2025. It is the most important cause of hospitalisation in subjects aged 65 years or more, resulting in high costs and major social impact. The current \u201cone-size-fits-all\u201d approach in the treatment of HF does not result in best outcome for all patients. These facts are an imminent threat to good quality management of patients with HF. An unorthodox approach from a new vision on care is required. We propose a novel predictive, preventive and personalised medicine approach where patients are truly leading their management, supported by an easily accessible online application that takes advantage of artificial intelligence. This strategy paper describes the needs in HF care, the needed paradigm shift and the elements that are required to achieve this shift. Through the inspiring collaboration of clinical and high-tech partners from North-West Europe combining state of the art HF care, artificial intelligence, serious gaming and patient coaching, a virtual doctor is being created. The results are expected to advance and personalise self-care, where standard care tasks are performed by the patients themselves, in principle without involvement of healthcare professionals, the latter being able to focus on complex conditions. This new vision on care will significantly reduce costs per patient while improving outcomes to enable long-term sustainability of top-level HF care.",
    "doi": "10.1007/s13167-019-00188-9",
    "url": "https://openalex.org/W2990170714",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s13167-019-00188-9.pdf",
    "venue": "The EPMA Journal",
    "citation_count": 186,
    "fields_of_study": [
      "Paradigm shift",
      "Heart failure",
      "Medicine",
      "Intensive care medicine",
      "Internal medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:11.623357"
  },
  {
    "source": "openalex",
    "source_id": "W4285799063",
    "title": "Operationalising ethics in artificial intelligence for healthcare: a framework for AI developers",
    "authors": [
      "Pravik Solanki",
      "John Grundy",
      "Waqar Hussain"
    ],
    "year": 2022,
    "abstract": "Abstract Artificial intelligence (AI) offers much promise for improving healthcare. However, it runs the looming risk of causing individual and societal harms; for instance, exacerbating inequalities amongst minority groups, or enabling compromises in the confidentiality of patients\u2019 sensitive data. As such, there is an expanding, unmet need for ensuring AI for healthcare is developed in concordance with human values and ethics. Augmenting \u201cprinciple-based\u201d guidance that highlight adherence to ethical ideals (without necessarily offering translation into actionable practices), we offer a solution-based framework for operationalising ethics in AI for healthcare. Our framework is built from a scoping review of existing solutions of ethical AI guidelines, frameworks and technical solutions to address human values such as self-direction in healthcare. Our view spans the entire length of the AI lifecycle: data management, model development, deployment and monitoring. Our focus in this paper is to collate actionable solutions (whether technical or non-technical in nature), which can be steps that enable and empower developers in their daily practice to ensuring ethical practices in the broader picture. Our framework is intended to be adopted by AI developers, with recommendations that are accessible and driven by the existing literature. We endorse the recognised need for \u2018ethical AI checklists\u2019 co-designed with health AI practitioners, which could further operationalise the technical solutions we have collated. Since the risks to health and wellbeing are so large, we believe a proactive approach is necessary for ensuring human values and ethics are appropriately respected in AI for healthcare.",
    "doi": "10.1007/s43681-022-00195-z",
    "url": "https://openalex.org/W4285799063",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s43681-022-00195-z.pdf",
    "venue": "AI and Ethics",
    "citation_count": 134,
    "fields_of_study": [
      "Health care",
      "Confidentiality",
      "Engineering ethics",
      "Knowledge management",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:11.623377"
  },
  {
    "source": "openalex",
    "source_id": "W4387956898",
    "title": "Using artificial intelligence to improve public health: a narrative review",
    "authors": [
      "David B. Olawade",
      "Ojima J. Wada",
      "Aanuoluwapo Clement David-Olawade",
      "Edward Kunonga",
      "Olawale J. Abaire",
      "Jonathan Ling"
    ],
    "year": 2023,
    "abstract": "Artificial intelligence (AI) is a rapidly evolving tool revolutionizing many aspects of healthcare. AI has been predominantly employed in medicine and healthcare administration. However, in public health, the widespread employment of AI only began recently, with the advent of COVID-19. This review examines the advances of AI in public health and the potential challenges that lie ahead. Some of the ways AI has aided public health delivery are via spatial modeling, risk prediction, misinformation control, public health surveillance, disease forecasting, pandemic/epidemic modeling, and health diagnosis. However, the implementation of AI in public health is not universal due to factors including limited infrastructure, lack of technical understanding, data paucity, and ethical/privacy issues.",
    "doi": "10.3389/fpubh.2023.1196397",
    "url": "https://openalex.org/W4387956898",
    "pdf_url": "https://www.frontiersin.org/articles/10.3389/fpubh.2023.1196397/pdf?isPublishedV2=False",
    "venue": "Frontiers in Public Health",
    "citation_count": 194,
    "fields_of_study": [
      "Misinformation",
      "Public health",
      "Health care",
      "Pandemic",
      "Data science"
    ],
    "retrieved_at": "2026-02-02T16:58:11.623398"
  },
  {
    "source": "openalex",
    "source_id": "W4381572755",
    "title": "Auditing large language models: a three-layered approach",
    "authors": [
      "Jakob M\u00f6kander",
      "Jonas Schuett",
      "Hannah Rose Kirk",
      "Luciano Floridi"
    ],
    "year": 2023,
    "abstract": "Abstract Large language models (LLMs) represent a major advance in artificial intelligence (AI) research. However, the widespread use of LLMs is also coupled with significant ethical and social challenges. Previous research has pointed towards auditing as a promising governance mechanism to help ensure that AI systems are designed and deployed in ways that are ethical, legal, and technically robust. However, existing auditing procedures fail to address the governance challenges posed by LLMs, which display emergent capabilities and are adaptable to a wide range of downstream tasks. In this article, we address that gap by outlining a novel blueprint for how to audit LLMs. Specifically, we propose a three-layered approach, whereby governance audits (of technology providers that design and disseminate LLMs), model audits (of LLMs after pre-training but prior to their release), and application audits (of applications based on LLMs) complement and inform each other. We show how audits, when conducted in a structured and coordinated manner on all three levels, can be a feasible and effective mechanism for identifying and managing some of the ethical and social risks posed by LLMs. However, it is important to remain realistic about what auditing can reasonably be expected to achieve. Therefore, we discuss the limitations not only of our three-layered approach but also of the prospect of auditing LLMs at all. Ultimately, this article seeks to expand the methodological toolkit available to technology providers and policymakers who wish to analyse and evaluate LLMs from technical, ethical, and legal perspectives.",
    "doi": "10.1007/s43681-023-00289-2",
    "url": "https://openalex.org/W4381572755",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s43681-023-00289-2.pdf",
    "venue": "AI and Ethics",
    "citation_count": 155,
    "fields_of_study": [
      "Audit",
      "Corporate governance",
      "Blueprint",
      "Public relations",
      "Business"
    ],
    "retrieved_at": "2026-02-02T16:58:11.623408"
  },
  {
    "source": "openalex",
    "source_id": "W3112134271",
    "title": "The Future of Sensitivity Analysis: An essential discipline for systems modeling and policy support",
    "authors": [
      "Saman Razavi",
      "Anthony J. Jakeman",
      "Andrea Saltelli",
      "Cl\u00e9mentine Prieur",
      "Bertrand Iooss",
      "Emanuele Borgonovo",
      "Elmar Plischke",
      "Samuele Lo Piano",
      "Takuya Iwanaga",
      "William E. Becker",
      "Stefano Tarantola",
      "Joseph H. A. Guillaume",
      "John Jakeman",
      "Hoshin V. Gupta",
      "Nicola Melillo",
      "Giovanni Rabitti",
      "Vincent Chabridon",
      "Qingyun Duan",
      "Xifu Sun",
      "Stef\u00e1n Thor Smith",
      "Razi Sheikholeslami",
      "Nasim Hosseini",
      "Masoud Asadzadeh",
      "Arnald Puy",
      "Sergei Kucherenko",
      "Holger R. Maier"
    ],
    "year": 2020,
    "abstract": null,
    "doi": "10.1016/j.envsoft.2020.104954",
    "url": "https://openalex.org/W3112134271",
    "pdf_url": "https://www.sciencedirect.com/science/article/pii/S1364815220310112?via%3Dihub",
    "venue": "Environmental Modelling & Software",
    "citation_count": 543,
    "fields_of_study": [
      "Warrant",
      "Multidisciplinary approach",
      "Variety (cybernetics)",
      "Structuring",
      "Management science"
    ],
    "retrieved_at": "2026-02-02T16:58:12.547494"
  },
  {
    "source": "openalex",
    "source_id": "W3137784937",
    "title": "The ethics of people analytics: risks, opportunities and recommendations",
    "authors": [
      "Aizhan Tursunbayeva",
      "Claudia Pagliari",
      "Stefano Di Lauro",
      "Gilda Antonelli"
    ],
    "year": 2021,
    "abstract": "Purpose This research analyzed the existing academic and grey literature concerning the technologies and practices of people analytics (PA), to understand how ethical considerations are being discussed by researchers, industry experts and practitioners, and to identify gaps, priorities and recommendations for ethical practice. Design/methodology/approach An iterative \u201cscoping review\u201d method was used to capture and synthesize relevant academic and grey literature. This is suited to emerging areas of innovation where formal research lags behind evidence from professional or technical sources. Findings Although the grey literature contains a growing stream of publications aimed at helping PA practitioners to \u201cbe ethical,\u201d overall, research on ethical issues in PA is still at an early stage. Optimistic and technocentric perspectives dominate the PA discourse, although key themes seen in the wider literature on digital/data ethics are also evident. Risks and recommendations for PA projects concerned transparency and diverse stakeholder inclusion, respecting privacy rights, fair and proportionate use of data, fostering a systemic culture of ethical practice, delivering benefits for employees, including ethical outcomes in business models, ensuring legal compliance and using ethical charters. Research limitations/implications This research adds to current debates over the future of work and employment in a digitized, algorithm-driven society. Practical implications The research provides an accessible summary of the risks, opportunities, trade-offs and regulatory issues for PA, as well as a framework for integrating ethical strategies and practices. Originality/value By using a scoping methodology to surface and analyze diverse literatures, this study fills a gap in existing knowledge on ethical aspects of PA. The findings can inform future academic research, organizations using or considering PA products, professional associations developing relevant guidelines and policymakers adapting regulations. It is also timely, given the increase in digital monitoring of employees working from home during the Covid-19 pandemic.",
    "doi": "10.1108/pr-12-2019-0680",
    "url": "https://openalex.org/W3137784937",
    "pdf_url": "https://www.emerald.com/insight/content/doi/10.1108/PR-12-2019-0680/full/pdf?title=the-ethics-of-people-analytics-risks-opportunities-and-recommendations",
    "venue": "Personnel Review",
    "citation_count": 139,
    "fields_of_study": [
      "Originality",
      "Transparency (behavior)",
      "Grey literature",
      "Stakeholder",
      "Responsible Research and Innovation"
    ],
    "retrieved_at": "2026-02-02T16:58:12.547513"
  },
  {
    "source": "openalex",
    "source_id": "W2959327140",
    "title": "The Ethics of Digital Well-Being: A Thematic Review",
    "authors": [
      "Christopher Burr",
      "Mariarosaria Taddeo",
      "Luciano Floridi"
    ],
    "year": 2020,
    "abstract": "Abstract This article presents the first thematic review of the literature on the ethical issues concerning digital well-being. The term \u2018digital well-being\u2019 is used to refer to the impact of digital technologies on what it means to live a life that is good for a human being. The review explores the existing literature on the ethics of digital well-being, with the goal of mapping the current debate and identifying open questions for future research. The review identifies major issues related to several key social domains: healthcare, education, governance and social development, and media and entertainment. It also highlights three broader themes: positive computing, personalised human\u2013computer interaction, and autonomy and self-determination. The review argues that three themes will be central to ongoing discussions and research by showing how they can be used to identify open questions related to the ethics of digital well-being.",
    "doi": "10.1007/s11948-020-00175-8",
    "url": "https://openalex.org/W2959327140",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s11948-020-00175-8.pdf",
    "venue": "Science and Engineering Ethics",
    "citation_count": 277,
    "fields_of_study": [
      "Philosophy of science",
      "Engineering ethics",
      "Thematic map",
      "Thematic analysis",
      "Epistemology"
    ],
    "retrieved_at": "2026-02-02T16:58:12.547559"
  },
  {
    "source": "openalex",
    "source_id": "W3088155791",
    "title": "Human-centered AI: The role of Human-centered Design Research in the development of AI",
    "authors": [
      "Jan Auernhammer"
    ],
    "year": 2020,
    "abstract": "Artificial Intelligence has the tremendous potential to produce progress and innovation in society. Designing AI for people has been expressed as essential for societal well-being and the common good. However, human-centered is often used generically without any commitment to a philosophy or overarching approach. This paper outlines different philosophical perspectives and several Human-centered Design approaches and discusses their contribution to the development of Artificial Intelligence. The paper argues that humanistic design research should play a vital role in the pan-disciplinary collaboration with technologists and policymakers to mitigate the impact of AI. Ultimately, Human-centered Artificial Intelligence incorporates involving people and designing Artificial Intelligence systems for people through a genuine human-centered philosophy and approach.",
    "doi": "10.21606/drs.2020.282",
    "url": "https://openalex.org/W3088155791",
    "pdf_url": "https://dl.designresearchsociety.org/cgi/viewcontent.cgi?article=1178&context=drs-conference-papers",
    "venue": "Proceedings of DRS",
    "citation_count": 170,
    "fields_of_study": [
      "Humanism",
      "Engineering ethics",
      "Artificial intelligence",
      "Discipline",
      "Human development (humanity)"
    ],
    "retrieved_at": "2026-02-02T16:58:12.547575"
  },
  {
    "source": "openalex",
    "source_id": "W3208914105",
    "title": "Discriminating Data",
    "authors": [
      "Wendy Hui Kyong Chun",
      "Alex Barnett"
    ],
    "year": 2021,
    "abstract": "How big data and machine learning encode discrimination and create agitated clusters of comforting rage. In Discriminating Data, Wendy Hui Kyong Chun reveals how polarization is a goal\u2014not an error\u2014within big data and machine learning. These methods, she argues, encode segregation, eugenics, and identity politics through their default assumptions and conditions. Correlation, which grounds big data's predictive potential, stems from twentieth-century eugenic attempts to \u201cbreed\u201d a better future. Recommender systems foster angry clusters of sameness through homophily. Users are \u201ctrained\u201d to become authentically predictable via a politics and technology of recognition. Machine learning and data analytics thus seek to disrupt the future by making disruption impossible. Chun, who has a background in systems design engineering as well as media studies and cultural theory, explains that although machine learning algorithms may not officially include race as a category, they embed whiteness as a default. Facial recognition technology, for example, relies on the faces of Hollywood celebrities and university undergraduates\u2014groups not famous for their diversity. Homophily emerged as a concept to describe white U.S. resident attitudes to living in biracial yet segregated public housing. Predictive policing technology deploys models trained on studies of predominantly underserved neighborhoods. Trained on selected and often discriminatory or dirty data, these algorithms are only validated if they mirror this data. How can we release ourselves from the vice-like grip of discriminatory data? Chun calls for alternative algorithms, defaults, and interdisciplinary coalitions in order to desegregate networks and foster a more democratic big data.",
    "doi": "10.7551/mitpress/14050.001.0001",
    "url": "https://openalex.org/W3208914105",
    "pdf_url": "https://direct.mit.edu/books/monograph/5237/bookpreview-pdf/2236528",
    "venue": "The MIT Press eBooks",
    "citation_count": 341,
    "fields_of_study": [
      "Big data",
      "Homophily",
      "Artificial intelligence",
      "Computer science",
      "Politics"
    ],
    "retrieved_at": "2026-02-02T16:58:12.547588"
  },
  {
    "source": "openalex",
    "source_id": "W4281254423",
    "title": "Beyond bias and discrimination: redefining the AI ethics principle of fairness in healthcare machine-learning algorithms",
    "authors": [
      "Benedetta Giovanola",
      "Simona Tiribelli"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1007/s00146-022-01455-6",
    "url": "https://openalex.org/W4281254423",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s00146-022-01455-6.pdf",
    "venue": "AI & Society",
    "citation_count": 143,
    "fields_of_study": [
      "Framing (construction)",
      "Value (mathematics)",
      "Computer science",
      "Health care",
      "Distributive property"
    ],
    "retrieved_at": "2026-02-02T16:58:12.547611"
  },
  {
    "source": "openalex",
    "source_id": "W4205154488",
    "title": "A review of Earth Artificial Intelligence",
    "authors": [
      "Ziheng Sun",
      "L. Sandoval",
      "Robert Crystal\u2010Ornelas",
      "S. Mostafa Mousavi",
      "Jinbo Wang",
      "Cindy Lin",
      "Nicoleta Cristea",
      "Daniel Tong",
      "Wendy Hawley Carande",
      "Xiaogang Ma",
      "Yuhan Rao",
      "James A. Bednar",
      "Amanda Tan",
      "Jianwu Wang",
      "Sanjay Purushotham",
      "Thomas E. Gill",
      "Julien Chastang",
      "Daniel L. Howard",
      "Benjamin Holt",
      "Chandana Gangodagamage",
      "Peisheng Zhao",
      "Pablo Rivas",
      "Zachary Chester",
      "Javier Orduz",
      "Aji John"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1016/j.cageo.2022.105034",
    "url": "https://openalex.org/W4205154488",
    "pdf_url": "https://www.sciencedirect.com/science/article/am/pii/S0098300422000036?via%3Dihub",
    "venue": "Computers & Geosciences",
    "citation_count": 245,
    "fields_of_study": [
      "Earth (classical element)",
      "Geology",
      "Computer science",
      "Artificial intelligence",
      "Mathematics"
    ],
    "retrieved_at": "2026-02-02T16:58:12.547617"
  },
  {
    "source": "openalex",
    "source_id": "W4386390931",
    "title": "Future of education in the era of generative artificial intelligence: Consensus among Chinese scholars on applications of ChatGPT in schools",
    "authors": [
      "Ming Liu",
      "Yiling Ren",
      "Lucy Michael Nyagoga",
      "Francis Stonier",
      "Zhongming Wu",
      "Liang Yu"
    ],
    "year": 2023,
    "abstract": "Abstract ChatGPT is an artificial intelligence chatbot that utilizes advanced natural language processing technologies, including large language models, to produce human\u2010like responses to user queries spanning a wide range of topics from programming to mathematics. As an emerging generative artificial intelligence (GAI) tool, it presents novel opportunities and challenges to the ongoing digital transformation of education. This article employs a systematic review approach to summarize the viewpoints of Chinese scholars and experts regarding the implementation of GAI in education. The research findings indicate that a majority of Chinese scholars support the cautious integration of GAI into education as it serves as a learning tool that offers personalized educational experiences for students. However, it also raises concerns related to academic integrity and the potential hindrance to students' critical thinking skills. Consequently, a framework called DATS, which outlines an optimization path for future GAI applications in schools, is proposed. The framework takes into account the perspectives of four key stakeholders: developers, administrators, teachers, and students.",
    "doi": "10.1002/fer3.10",
    "url": "https://openalex.org/W4386390931",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/fer3.10",
    "venue": "Future in Educational Research",
    "citation_count": 197,
    "fields_of_study": [
      "Viewpoints",
      "Chatbot",
      "Generative grammar",
      "Computer science",
      "Knowledge management"
    ],
    "retrieved_at": "2026-02-02T16:58:12.547621"
  },
  {
    "source": "openalex",
    "source_id": "W3110910775",
    "title": "Artificial intelligence for human flourishing \u2013 Beyond principles for machine learning",
    "authors": [
      "Bernd Carsten Stahl",
      "Andreas G. Andreou",
      "Philip Brey",
      "Tally Hatzakis",
      "A. S. Kirichenko",
      "Kevin Macnish",
      "St\u00e9phanie Laulh\u00e9 Shaelou",
      "Alpesh Patel",
      "Mark Ryan",
      "David Wright"
    ],
    "year": 2020,
    "abstract": "The technical and economic benefits of artificial intelligence (AI) are counterbalanced by legal, social and ethical issues. It is challenging to conceptually capture and empirically measure both benefits and downsides. We therefore provide an account of the findings and implications of a multi-dimensional study of AI, comprising 10 case studies, five scenarios, an ethical impact analysis of AI, a human rights analysis of AI and a technical analysis of known and potential threats and vulnerabilities. Based on our findings, we separate AI ethics discourse into three streams: (1) specific issues related to the application of machine learning, (2) social and political questions arising in a digitally enabled society and (3) metaphysical questions about the nature of reality and humanity. Human rights principles and legislation have a key role to play in addressing the ethics of AI. This work helps to steer AI to contribute to human flourishing.",
    "doi": "10.1016/j.jbusres.2020.11.030",
    "url": "https://openalex.org/W3110910775",
    "pdf_url": "https://www.sciencedirect.com/science/article/pii/S0148296320307839?via%3Dihub",
    "venue": "Journal of Business Research",
    "citation_count": 161,
    "fields_of_study": [
      "Flourishing",
      "Humanity",
      "Legislation",
      "Politics",
      "Metaphysics"
    ],
    "retrieved_at": "2026-02-02T16:58:12.547638"
  },
  {
    "source": "openalex",
    "source_id": "W3207360334",
    "title": "Application Scenarios for Artificial Intelligence in Nursing Care: Rapid Review",
    "authors": [
      "Kathrin Seibert",
      "Dominik Domhoff",
      "Dominik Bruch",
      "Matthias Schulte\u2010Althoff",
      "Daniel F\u00fcrstenau",
      "Felix Bie\u00dfmann",
      "Karin Wolf\u2010Ostermann"
    ],
    "year": 2021,
    "abstract": "Background Artificial intelligence (AI) holds the promise of supporting nurses\u2019 clinical decision-making in complex care situations or conducting tasks that are remote from direct patient interaction, such as documentation processes. There has been an increase in the research and development of AI applications for nursing care, but there is a persistent lack of an extensive overview covering the evidence base for promising application scenarios. Objective This study synthesizes literature on application scenarios for AI in nursing care settings as well as highlights adjacent aspects in the ethical, legal, and social discourse surrounding the application of AI in nursing care. Methods Following a rapid review design, PubMed, CINAHL, Association for Computing Machinery Digital Library, Institute of Electrical and Electronics Engineers Xplore, Digital Bibliography &amp; Library Project, and Association for Information Systems Library, as well as the libraries of leading AI conferences, were searched in June 2020. Publications of original quantitative and qualitative research, systematic reviews, discussion papers, and essays on the ethical, legal, and social implications published in English were included. Eligible studies were analyzed on the basis of predetermined selection criteria. Results The titles and abstracts of 7016 publications and 704 full texts were screened, and 292 publications were included. Hospitals were the most prominent study setting, followed by independent living at home; fewer application scenarios were identified for nursing homes or home care. Most studies used machine learning algorithms, whereas expert or hybrid systems were entailed in less than every 10th publication. The application context of focusing on image and signal processing with tracking, monitoring, or the classification of activity and health followed by care coordination and communication, as well as fall detection, was the main purpose of AI applications. Few studies have reported the effects of AI applications on clinical or organizational outcomes, lacking particularly in data gathered outside laboratory conditions. In addition to technological requirements, the reporting and inclusion of certain requirements capture more overarching topics, such as data privacy, safety, and technology acceptance. Ethical, legal, and social implications reflect the discourse on technology use in health care but have mostly not been discussed in meaningful and potentially encompassing detail. Conclusions The results highlight the potential for the application of AI systems in different nursing care settings. Considering the lack of findings on the effectiveness and application of AI systems in real-world scenarios, future research should reflect on a more nursing care\u2013specific perspective toward objectives, outcomes, and benefits. We identify that, crucially, an advancement in technological-societal discourse that surrounds the ethical and legal implications of AI applications in nursing care is a necessary next step. Further, we outline the need for greater participation among all of the stakeholders involved.",
    "doi": "10.2196/26522",
    "url": "https://openalex.org/W3207360334",
    "pdf_url": "https://www.jmir.org/2021/11/e26522/PDF",
    "venue": "Journal of Medical Internet Research",
    "citation_count": 250,
    "fields_of_study": [
      "Nursing",
      "Nursing care",
      "Psychology",
      "Computer science",
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:12.547653"
  },
  {
    "source": "openalex",
    "source_id": "W3138924974",
    "title": "Enabling Technologies for Urban Smart Mobility: Recent Trends, Opportunities and Challenges",
    "authors": [
      "Sara Paiva",
      "Mohd Abdul Ahad",
      "Gautami Tripathi",
      "Noushaba Feroz",
      "Gabriella Casalino"
    ],
    "year": 2021,
    "abstract": "The increasing population across the globe makes it essential to link smart and sustainable city planning with the logistics of transporting people and goods, which will significantly contribute to how societies will face mobility in the coming years. The concept of smart mobility emerged with the popularity of smart cities and is aligned with the sustainable development goals defined by the United Nations. A reduction in traffic congestion and new route optimizations with reduced ecological footprint are some of the essential factors of smart mobility; however, other aspects must also be taken into account, such as the promotion of active mobility and inclusive mobility, encouraging the use of other types of environmentally friendly fuels and engagement with citizens. The Internet of Things (IoT), Artificial Intelligence (AI), Blockchain and Big Data technology will serve as the main entry points and fundamental pillars to promote the rise of new innovative solutions that will change the current paradigm for cities and their citizens. Mobility-as-a-service, traffic flow optimization, the optimization of logistics and autonomous vehicles are some of the services and applications that will encompass several changes in the coming years with the transition of existing cities into smart cities. This paper provides an extensive review of the current trends and solutions presented in the scope of smart mobility and enabling technologies that support it. An overview of how smart mobility fits into smart cities is provided by characterizing its main attributes and the key benefits of using smart mobility in a smart city ecosystem. Further, this paper highlights other various opportunities and challenges related to smart mobility. Lastly, the major services and applications that are expected to arise in the coming years within smart mobility are explored with the prospective future trends and scope.",
    "doi": "10.3390/s21062143",
    "url": "https://openalex.org/W3138924974",
    "pdf_url": "https://www.mdpi.com/1424-8220/21/6/2143/pdf?version=1620823207",
    "venue": "Sensors",
    "citation_count": 337,
    "fields_of_study": [
      "Smart city",
      "Population",
      "Popularity",
      "Scope (computer science)",
      "Sustainable transport"
    ],
    "retrieved_at": "2026-02-02T16:58:12.547693"
  },
  {
    "source": "openalex",
    "source_id": "W4287266177",
    "title": "A practical guide to multi-objective reinforcement learning and planning",
    "authors": [
      "Conor F. Hayes",
      "Roxana R\u0103dulescu",
      "Eugenio Bargiacchi",
      "Johan K\u00e4llstr\u00f6m",
      "Matthew D Macfarlane",
      "Mathieu Reymond",
      "Timothy Verstraeten",
      "Luisa Zintgraf",
      "Richard Dazeley",
      "Fredrik Heintz",
      "Enda Howley",
      "Athirai A. Irissappane",
      "Patrick Mannion",
      "Ann Now\u00e9",
      "Gabriel de Oliveira Ramos",
      "Marcello Restelli",
      "Peter Vamplew",
      "Diederik M. Roijers"
    ],
    "year": 2022,
    "abstract": "Real-world sequential decision-making tasks are generally complex, requiring trade-offs between multiple, often conflicting, objectives. Despite this, the majority of research in reinforcement learning and decision-theoretic planning either assumes only a single objective, or that multiple objectives can be adequately handled via a simple linear combination. Such approaches may oversimplify the underlying problem and hence produce suboptimal results. This paper serves as a guide to the application of multi-objective methods to difficult problems, and is aimed at researchers who are already familiar with single-objective reinforcement learning and planning methods who wish to adopt a multi-objective perspective on their research, as well as practitioners who encounter multi-objective decision problems in practice. It identifies the factors that may influence the nature of the desired solution, and illustrates by example how these influence the design of multi-objective decision-making systems for complex problems.",
    "doi": "10.1007/s10458-022-09552-y",
    "url": "https://openalex.org/W4287266177",
    "pdf_url": "https://hdl.handle.net/11311/1231792",
    "venue": "Virtual Community of Pathological Anatomy (University of Castilla La Mancha)",
    "citation_count": 277,
    "fields_of_study": [
      "Reinforcement learning",
      "Computer science",
      "Perspective (graphical)",
      "Management science",
      "Simple (philosophy)"
    ],
    "retrieved_at": "2026-02-02T16:58:12.547718"
  },
  {
    "source": "openalex",
    "source_id": "W4392922283",
    "title": "Artificial intelligence in positive mental health: a narrative review",
    "authors": [
      "Anoushka Thakkar",
      "Ankita Gupta",
      "Avinash De Sousa"
    ],
    "year": 2024,
    "abstract": "The paper reviews the entire spectrum of Artificial Intelligence (AI) in mental health and its positive role in mental health. AI has a huge number of promises to offer mental health care and this paper looks at multiple facets of the same. The paper first defines AI and its scope in the area of mental health. It then looks at various facets of AI like machine learning, supervised machine learning and unsupervised machine learning and other facets of AI. The role of AI in various psychiatric disorders like neurodegenerative disorders, intellectual disability and seizures are discussed along with the role of AI in awareness, diagnosis and intervention in mental health disorders. The role of AI in positive emotional regulation and its impact in schizophrenia, autism spectrum disorders and mood disorders is also highlighted. The article also discusses the limitations of AI based approaches and the need for AI based approaches in mental health to be culturally aware, with structured flexible algorithms and an awareness of biases that can arise in AI. The ethical issues that may arise with the use of AI in mental health are also visited.",
    "doi": "10.3389/fdgth.2024.1280235",
    "url": "https://openalex.org/W4392922283",
    "pdf_url": "https://www.frontiersin.org/journals/digital-health/articles/10.3389/fdgth.2024.1280235/pdf",
    "venue": "Frontiers in Digital Health",
    "citation_count": 159,
    "fields_of_study": [
      "Mental health",
      "Psychology",
      "Schizophrenia (object-oriented programming)",
      "Intervention (counseling)",
      "Autism"
    ],
    "retrieved_at": "2026-02-02T16:58:12.547732"
  },
  {
    "source": "openalex",
    "source_id": "W4294243134",
    "title": "Experimental evidence of effective human\u2013AI collaboration in medical decision-making",
    "authors": [
      "Carlo Reverberi",
      "Tommaso Rigon",
      "Aldo Solari",
      "Cesare Hassan",
      "Paolo Cherubini",
      "Giulio Antonelli",
      "Halim Awadie",
      "Sebastian Bernhofer",
      "Sabela Carballal",
      "M\u00e1rio Dinis\u2010Ribeiro",
      "A Fern\u00e1ndez-Clotet",
      "Gl\u00f2ria Fern\u00e1ndez\u2010Esparrach",
      "Ian M. Gralnek",
      "Yuta Higasa",
      "Taku Hirabayashi",
      "Tatsuki Hirai",
      "Mineo Iwatate",
      "Miki Kawano",
      "Markus Mader",
      "A Maieron",
      "Sebastian Mattes",
      "Tastuya Nakai",
      "\u00cdngrid Ord\u00e1s",
      "Raquel Ortig\u00e3o",
      "Oswaldo Ort\u00edz",
      "Mar\u00eda Pellis\u00e9",
      "Cl\u00e1udia L\u00facia de Oliveira Pinto",
      "Florian Riedl",
      "Ariadna S\u00e1nchez",
      "Emanuel Steiner",
      "Yukari Tanaka",
      "Andrea Cherubini",
      "Andrea Cherubini"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1038/s41598-022-18751-2",
    "url": "https://openalex.org/W4294243134",
    "pdf_url": "https://www.nature.com/articles/s41598-022-18751-2.pdf",
    "venue": "Scientific Reports",
    "citation_count": 172,
    "fields_of_study": [
      "Medical decision making",
      "Clinical decision making",
      "Data science",
      "Computer science",
      "MEDLINE"
    ],
    "retrieved_at": "2026-02-02T16:58:12.547753"
  },
  {
    "source": "openalex",
    "source_id": "W4385156372",
    "title": "AI governance: themes, knowledge gaps and future agendas",
    "authors": [
      "Teemu Birkstedt",
      "Matti Minkkinen",
      "Anushree Tandon",
      "Matti M\u00e4ntym\u00e4ki"
    ],
    "year": 2023,
    "abstract": "Purpose Following the surge of documents laying out organizations' ethical principles for their use of artificial intelligence (AI), there is a growing demand for translating ethical principles to practice through AI governance (AIG). AIG has emerged as a rapidly growing, yet fragmented, research area. This paper synthesizes the organizational AIG literature by outlining research themes and knowledge gaps as well as putting forward future agendas. Design/methodology/approach The authors undertake a systematic literature review on AIG, addressing the current state of its conceptualization and suggesting future directions for AIG scholarship and practice. The review protocol was developed following recommended guidelines for systematic reviews and the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA). Findings The results of the authors\u2019 review confirmed the assumption that AIG is an emerging research topic with few explicit definitions. Moreover, the authors\u2019 review identified four themes in the AIG literature: technology, stakeholders and context, regulation and processes. The central knowledge gaps revealed were the limited understanding of AIG implementation, lack of attention to the AIG context, uncertain effectiveness of ethical principles and regulation, and insufficient operationalization of AIG processes. To address these gaps, the authors present four future AIG agendas: technical, stakeholder and contextual, regulatory, and process. Going forward, the authors propose focused empirical research on organizational AIG processes, the establishment of an AI oversight unit and collaborative governance as a research approach. Research limitations/implications To address the identified knowledge gaps, the authors present the following working definition of AIG: AI governance is a system of rules, practices and processes employed to ensure an organization's use of AI technologies aligns with its strategies, objectives, and values, complete with legal requirements, ethical principles and the requirements set by stakeholders. Going forward, the authors propose focused empirical research on organizational AIG processes, the establishment of an AI oversight unit and collaborative governance as a research approach. Practical implications For practitioners, the authors highlight training and awareness, stakeholder management and the crucial role of organizational culture, including senior management commitment. Social implications For society, the authors review elucidates the multitude of stakeholders involved in AI governance activities and complexities related to balancing the needs of different stakeholders. Originality/value By delineating the AIG concept and the associated research themes, knowledge gaps and future agendas, the authors review builds a foundation for organizational AIG research, calling for broad contextual investigations and a deep understanding of AIG mechanisms. For practitioners, the authors highlight training and awareness, stakeholder management and the crucial role of organizational culture, including senior management commitment.",
    "doi": "10.1108/intr-01-2022-0042",
    "url": "https://openalex.org/W4385156372",
    "pdf_url": "https://www.emerald.com/insight/content/doi/10.1108/INTR-01-2022-0042/full/pdf?title=ai-governance-themes-knowledge-gaps-and-future-agendas",
    "venue": "Internet Research",
    "citation_count": 152,
    "fields_of_study": [
      "Conceptualization",
      "Operationalization",
      "Corporate governance",
      "Systematic review",
      "Scholarship"
    ],
    "retrieved_at": "2026-02-02T16:58:12.547757"
  },
  {
    "source": "openalex",
    "source_id": "W3156728378",
    "title": "Conversational commerce: entering the next stage of AI-powered digital assistants",
    "authors": [
      "Janarthanan Balakrishnan",
      "Yogesh K. Dwivedi"
    ],
    "year": 2021,
    "abstract": "Abstract Digital assistant is a recent advancement benefited through data-driven innovation. Though digital assistants have become an integral member of user conversations, but there is no theory that relates user perception towards this AI powered technology. The purpose of the research is to investigate the role of technology attitude and AI attributes in enhancing purchase intention through digital assistants. A conceptual model is proposed after identifying three major AI factors namely, perceived anthropomorphism, perceived intelligence, and perceived animacy. To test the model, the study employed structural equation modeling using 440 sample. The results indicated that perceived anthropomorphism plays the most significant role in building a positive attitude and purchase intention through digital assistants. Though the study is built using technology-related variables, the hypotheses are proposed based on various psychology-related theories such as uncanny valley theory, the theory of mind, developmental psychology, and cognitive psychology theory. The study\u2019s theoretical contributions are discussed within the scope of these theories. Besides the theoretical contribution, the study also offers illuminating practical implications for developers and marketers\u2019 benefit.",
    "doi": "10.1007/s10479-021-04049-5",
    "url": "https://openalex.org/W3156728378",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10479-021-04049-5.pdf",
    "venue": "Annals of Operations Research",
    "citation_count": 230,
    "fields_of_study": [
      "Uncanny valley",
      "Perception",
      "Scope (computer science)",
      "Structural equation modeling",
      "Theory of planned behavior"
    ],
    "retrieved_at": "2026-02-02T16:58:12.547800"
  },
  {
    "source": "openalex",
    "source_id": "W4384827671",
    "title": "Artificial intelligence governance: Ethical considerations and implications for social responsibility",
    "authors": [
      "Mark Anthony Camilleri"
    ],
    "year": 2023,
    "abstract": "Abstract A number of articles are increasingly raising awareness on the different uses of artificial intelligence (AI) technologies for customers and businesses. Many authors discuss about their benefits and possible challenges. However, for the time being, there is still limited research focused on AI principles and regulatory guidelines for the developers of expert systems like machine learning (ML) and/or deep learning (DL) technologies. This research addresses this knowledge gap in the academic literature. The objectives of this contribution are threefold: (i) It describes AI governance frameworks that were put forward by technology conglomerates, policy makers and by intergovernmental organizations, (ii) It sheds light on the extant literature on \u2018AI governance\u2019 as well as on the intersection of \u2018AI\u2019 and \u2018corporate social responsibility\u2019 (CSR), (iii) It identifies key dimensions of AI governance, and elaborates about the promotion of accountability and transparency; explainability, interpretability and reproducibility; fairness and inclusiveness; privacy and safety of end users, as well as on the prevention of risks and of cyber security issues from AI systems. This research implies that all those who are involved in the research, development and maintenance of AI systems, have social and ethical responsibilities to bear toward their consumers as well as to other stakeholders in society.",
    "doi": "10.1111/exsy.13406",
    "url": "https://openalex.org/W4384827671",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/exsy.13406",
    "venue": "Expert Systems",
    "citation_count": 141,
    "fields_of_study": [
      "Accountability",
      "Transparency (behavior)",
      "Interpretability",
      "Corporate governance",
      "Extant taxon"
    ],
    "retrieved_at": "2026-02-02T16:58:12.547818"
  },
  {
    "source": "openalex",
    "source_id": "W4386712902",
    "title": "AI Fairness in Data Management and Analytics: A Review on Challenges, Methodologies and Applications",
    "authors": [
      "Pu Chen",
      "Linna Wu",
      "Lei Wang"
    ],
    "year": 2023,
    "abstract": "This article provides a comprehensive overview of the fairness issues in artificial intelligence (AI) systems, delving into its background, definition, and development process. The article explores the fairness problem in AI through practical applications and current advances and focuses on bias analysis and fairness training as key research directions. The paper explains in detail the concept, implementation, characteristics, and use cases of each method. The paper explores strategies to reduce bias and improve fairness in AI systems, reviews challenges and solutions to real-world AI fairness applications, and proposes future research directions. In addition, this study provides an in-depth comparative analysis of the various approaches, utilizing cutting-edge research information to elucidate their different characteristics, strengths, and weaknesses. The results of the comparison provide guidance for future research. The paper concludes with an overview of existing challenges in practical applications and suggests priorities and solutions for future research. The conclusions provide insights for promoting fairness in AI systems. The information reviewed in this paper is drawn from reputable sources, including leading academic journals, prominent conference proceedings, and well-established online repositories dedicated to AI fairness. However, it is important to recognize that research nuances, sample sizes, and contextual factors may create limitations that affect the generalizability of the findings.",
    "doi": "10.3390/app131810258",
    "url": "https://openalex.org/W4386712902",
    "pdf_url": "https://www.mdpi.com/2076-3417/13/18/10258/pdf?version=1694597295",
    "venue": "Applied Sciences",
    "citation_count": 123,
    "fields_of_study": [
      "Generalizability theory",
      "Computer science",
      "Strengths and weaknesses",
      "Data science",
      "Management science"
    ],
    "retrieved_at": "2026-02-02T16:58:12.547840"
  },
  {
    "source": "openalex",
    "source_id": "W4296776307",
    "title": "Integrated multimodal artificial intelligence framework for healthcare applications",
    "authors": [
      "Luis R. Soenksen",
      "Yu Ma",
      "Cynthia Zeng",
      "L\u00e9onard Boussioux",
      "Kimberly Villalobos Carballo",
      "Liangyuan Na",
      "Holly Wiberg",
      "Michael Lingzhi Li",
      "Ignacio Fuentes",
      "Dimitris Bertsimas"
    ],
    "year": 2022,
    "abstract": "Abstract Artificial intelligence (AI) systems hold great promise to improve healthcare over the next decades. Specifically, AI systems leveraging multiple data sources and input modalities are poised to become a viable method to deliver more accurate results and deployable pipelines across a wide range of applications. In this work, we propose and evaluate a unified Holistic AI in Medicine (HAIM) framework to facilitate the generation and testing of AI systems that leverage multimodal inputs. Our approach uses generalizable data pre-processing and machine learning modeling stages that can be readily adapted for research and deployment in healthcare environments. We evaluate our HAIM framework by training and characterizing 14,324 independent models based on HAIM-MIMIC-MM, a multimodal clinical database ( N = 34,537 samples) containing 7279 unique hospitalizations and 6485 patients, spanning all possible input combinations of 4 data modalities (i.e., tabular, time-series, text, and images), 11 unique data sources and 12 predictive tasks. We show that this framework can consistently and robustly produce models that outperform similar single-source approaches across various healthcare demonstrations (by 6\u201333%), including 10 distinct chest pathology diagnoses, along with length-of-stay and 48 h mortality predictions. We also quantify the contribution of each modality and data source using Shapley values, which demonstrates the heterogeneity in data modality importance and the necessity of multimodal inputs across different healthcare-relevant tasks. The generalizable properties and flexibility of our Holistic AI in Medicine (HAIM) framework could offer a promising pathway for future multimodal predictive systems in clinical and operational healthcare settings.",
    "doi": "10.1038/s41746-022-00689-4",
    "url": "https://openalex.org/W4296776307",
    "pdf_url": "https://www.nature.com/articles/s41746-022-00689-4.pdf",
    "venue": "npj Digital Medicine",
    "citation_count": 244,
    "fields_of_study": [
      "Computer science",
      "Leverage (statistics)",
      "Artificial intelligence",
      "Modalities",
      "Machine learning"
    ],
    "retrieved_at": "2026-02-02T16:58:12.547861"
  },
  {
    "source": "openalex",
    "source_id": "W4385757151",
    "title": "Using ChatGPT in academic writing is (not) a form of plagiarism: What does the literature say?",
    "authors": [
      "Adeeb M. Jarrah",
      "Yousef Wardat",
      "Patr\u00edcia Fidalgo"
    ],
    "year": 2023,
    "abstract": "This study aims to review the existing literature on using ChatGPT in academic writing and its implications regarding plagiarism. Various databases, including Scopus, Google Scholar, ScienceDirect, and ProQuest, were searched using specific keywords related to ChatGPT in academia, academic research, higher education, academic publishing, and ethical challenges. The review provides an overview of studies investigating the use of ChatGPT in academic writing and its potential association with plagiarism. The results of this study contribute to our understanding of the use and misuse of ChatGPT in academic writing, considering the growing concern regarding plagiarism in higher education. The findings suggest that ChatGPT can be a valuable writing tool; however, it is crucial to follow responsible practices to uphold academic integrity and ensure ethical use. Properly citing and attributing ChatGPT\u2019s contribution is essential in recognizing its role, preventing plagiarism, and upholding the principles of scholarly writing. By adhering to established citation guidelines, authors can maximize ChatGPT\u2019s benefits while maintaining responsible usage.",
    "doi": "10.30935/ojcmt/13572",
    "url": "https://openalex.org/W4385757151",
    "pdf_url": "https://www.ojcmt.net/download/using-chatgpt-in-academic-writing-is-not-a-form-of-plagiarism-what-does-the-literature-say-13572.pdf",
    "venue": "Online Journal of Communication and Media Technologies",
    "citation_count": 188,
    "fields_of_study": [
      "Academic writing",
      "Scopus",
      "Academic integrity",
      "Citation",
      "Publishing"
    ],
    "retrieved_at": "2026-02-02T16:58:12.547882"
  },
  {
    "source": "openalex",
    "source_id": "W3212259563",
    "title": "Operationalising AI ethics: barriers, enablers and next steps",
    "authors": [
      "Jessica Morley",
      "Libby Kinsey",
      "Anat Elhalal",
      "Francesca Garcia",
      "Marta Ziosi",
      "Luciano Floridi"
    ],
    "year": 2021,
    "abstract": "Abstract By mid-2019 there were more than 80 AI ethics guides available in the public domain. Despite this, 2020 saw numerous news stories break related to ethically questionable uses of AI. In part, this is because AI ethics theory remains highly abstract, and of limited practical applicability to those actually responsible for designing algorithms and AI systems. Our previous research sought to start closing this gap between the \u2018what\u2019 and the \u2018how\u2019 of AI ethics through the creation of a searchable typology of tools and methods designed to translate between the five most common AI ethics principles and implementable design practices. Whilst a useful starting point, that research rested on the assumption that all AI practitioners are aware of the ethical implications of AI, understand their importance, and are actively seeking to respond to them. In reality, it is unclear whether this is the case. It is this limitation that we seek to overcome here by conducting a mixed-methods qualitative analysis to answer the following four questions: what do AI practitioners understand about the need to translate ethical principles into practice? What motivates AI practitioners to embed ethical principles into design practices? What barriers do AI practitioners face when attempting to translate ethical principles into practice? And finally, what assistance do AI practitioners want and need when translating ethical principles into practice?",
    "doi": "10.1007/s00146-021-01308-8",
    "url": "https://openalex.org/W3212259563",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s00146-021-01308-8.pdf",
    "venue": "AI & Society",
    "citation_count": 173,
    "fields_of_study": [
      "Typology",
      "Engineering ethics",
      "Point (geometry)",
      "Face (sociological concept)",
      "Closing (real estate)"
    ],
    "retrieved_at": "2026-02-02T16:58:12.547898"
  },
  {
    "source": "openalex",
    "source_id": "W3209760672",
    "title": "The Lancet and Financial Times Commission on governing health futures 2030: growing up in a digital world",
    "authors": [
      "Ilona Kickbusch",
      "Dario Piselli",
      "Anurag Agrawal",
      "Ran D. Balicer",
      "Olivia Banner",
      "M Adelhardt",
      "Emanuele Capobianco",
      "Christopher Fabian",
      "Amandeep S. Gill",
      "Deborah Lupton",
      "Rohinton Medhora",
      "Njide Ndili",
      "Andrzej Ry\u015b",
      "Nanjira Sambuli",
      "Dykki Settle",
      "Soumya Swaminathan",
      "Jeanette Vega Morales",
      "Miranda Wolpert",
      "Andrew Wyckoff",
      "Lan Xue",
      "Aferdita Bytyqi",
      "Christian Franz",
      "Whitney Gray",
      "Louise Holly",
      "Micaela Neumann",
      "Lipsa Panda",
      "Robert D. Smith",
      "Enow Awah Georges Stevens",
      "Brian Li Han Wong"
    ],
    "year": 2021,
    "abstract": null,
    "doi": "10.1016/s0140-6736(21)01824-9",
    "url": "https://openalex.org/W3209760672",
    "pdf_url": "http://www.thelancet.com/article/S0140673621018249/pdf",
    "venue": "The Lancet",
    "citation_count": 356,
    "fields_of_study": [
      "Digital health",
      "Digital transformation",
      "Futures contract",
      "Health care",
      "Political science"
    ],
    "retrieved_at": "2026-02-02T16:58:12.547921"
  },
  {
    "source": "openalex",
    "source_id": "W4393993191",
    "title": "Generative AI for Customizable Learning Experiences",
    "authors": [
      "Ivica Pesovski",
      "Ricardo Santos",
      "Roberto Henriques",
      "Vladimir Trajkovik"
    ],
    "year": 2024,
    "abstract": "The introduction of accessible generative artificial intelligence opens promising opportunities for the implementation of personalized learning methods in any educational environment. Personalized learning has been conceptualized for a long time, but it has only recently become realistic and truly achievable. In this paper, we propose an affordable and sustainable approach toward personalizing learning materials as part of the complete educational process. We have created a tool within a pre-existing learning management system at a software engineering college that automatically generates learning materials based on the learning outcomes provided by the professor for a particular class. The learning materials were composed in three distinct styles, the initial one being the traditional professor style and the other two variations adopting a pop-culture influence, namely Batman and Wednesday Addams. Each lesson, besides being delivered in three different formats, contained automatically generated multiple-choice questions that students could use to check their progress. This paper contains complete instructions for developing such a tool with the help of large language models using OpenAI\u2019s API and an analysis of the preliminary experiment of its usage performed with the help of 20 college students studying software engineering at a European university. Participation in the study was optional and on voluntary basis. Each student\u2019s tool usage was quantified, and two questionnaires were conducted: one immediately after subject completion and another 6 months later to assess both immediate and long-term effects, perceptions, and preferences. The results indicate that students found the multiple variants of the learning materials really engaging. While predominantly utilizing the traditional variant of the learning materials, they found this approach inspiring, would recommend it to other students, and would like to see it more in classes. The most popular feature were the automatically generated quiz-style tests that they used to assess their understanding. Preliminary evidence suggests that the use of various versions of learning materials leads to an increase in students\u2019 study time, especially for students who have not mastered the topic otherwise. The study\u2019s small sample size of 20 students restricts its ability to generalize its findings, but its results provide useful early insights and lay the groundwork for future research on AI-supported educational strategies.",
    "doi": "10.3390/su16073034",
    "url": "https://openalex.org/W4393993191",
    "pdf_url": "https://www.mdpi.com/2071-1050/16/7/3034/pdf?version=1712310661",
    "venue": "Sustainability",
    "citation_count": 176,
    "fields_of_study": [
      "Generative grammar",
      "Generative Design",
      "Computer science",
      "Generative model",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:12.547924"
  },
  {
    "source": "openalex",
    "source_id": "W4381550225",
    "title": "ChatGPT and the Future of Digital Health: A Study on Healthcare Workers\u2019 Perceptions and Expectations",
    "authors": [
      "Mohamad\u2010Hani Temsah",
      "Fadi Aljamaan",
      "Khalid H. Malki",
      "Khalid Alhasan",
      "Ibraheem Altamimi",
      "Razan Aljarbou",
      "Faisal Bazuhair",
      "Abdulmajeed AlSubaihin",
      "Naif Abdulmajeed",
      "Fatimah Alshahrani",
      "Reem Temsah",
      "Turki Alshahrani",
      "Lama Al-Eyadhy",
      "Serin Mohammed Alkhateeb",
      "Basema Saddik",
      "Rabih Halwani",
      "Amr Jamal",
      "Jaffar A. Al\u2010Tawfiq",
      "Ayman Al\u2010Eyadhy"
    ],
    "year": 2023,
    "abstract": "This study aimed to assess the knowledge, attitudes, and intended practices of healthcare workers (HCWs) in Saudi Arabia towards ChatGPT, an artificial intelligence (AI) Chatbot, within the first three months after its launch. We also aimed to identify potential barriers to AI Chatbot adoption among healthcare professionals. A cross-sectional survey was conducted among 1057 HCWs in Saudi Arabia, distributed electronically via social media channels from 21 February to 6 March 2023. The survey evaluated HCWs\u2019 familiarity with ChatGPT-3.5, their satisfaction, intended future use, and perceived usefulness in healthcare practice. Of the respondents, 18.4% had used ChatGPT for healthcare purposes, while 84.1% of non-users expressed interest in utilizing AI Chatbots in the future. Most participants (75.1%) were comfortable with incorporating ChatGPT into their healthcare practice. HCWs perceived the Chatbot to be useful in various aspects of healthcare, such as medical decision-making (39.5%), patient and family support (44.7%), medical literature appraisal (48.5%), and medical research assistance (65.9%). A majority (76.7%) believed ChatGPT could positively impact the future of healthcare systems. Nevertheless, concerns about credibility and the source of information provided by AI Chatbots (46.9%) were identified as the main barriers. Although HCWs recognize ChatGPT as a valuable addition to digital health in the early stages of adoption, addressing concerns regarding accuracy, reliability, and medicolegal implications is crucial. Therefore, due to their unreliability, the current forms of ChatGPT and other Chatbots should not be used for diagnostic or treatment purposes without human expert oversight. Ensuring the trustworthiness and dependability of AI Chatbots is essential for successful implementation in healthcare settings. Future research should focus on evaluating the clinical outcomes of ChatGPT and benchmarking its performance against other AI Chatbots.",
    "doi": "10.3390/healthcare11131812",
    "url": "https://openalex.org/W4381550225",
    "pdf_url": "https://www.mdpi.com/2227-9032/11/13/1812/pdf?version=1687515031",
    "venue": "Healthcare",
    "citation_count": 164,
    "fields_of_study": [
      "Health care",
      "Chatbot",
      "Credibility",
      "Medicine",
      "Digital health"
    ],
    "retrieved_at": "2026-02-02T16:58:12.547958"
  },
  {
    "source": "openalex",
    "source_id": "W4309604980",
    "title": "Ethical Conundrums in the Application of Artificial Intelligence (AI) in Healthcare\u2014A Scoping Review of Reviews",
    "authors": [
      "Sreenidhi Prakash",
      "Jyotsna Needamangalam Balaji",
      "Ashish Joshi",
      "Krishna Mohan Surapaneni"
    ],
    "year": 2022,
    "abstract": "Background: With the availability of extensive health data, artificial intelligence has an inordinate capability to expedite medical explorations and revamp healthcare.Artificial intelligence is set to reform the practice of medicine soon. Despite the mammoth advantages of artificial intelligence in the medical field, there exists inconsistency in the ethical and legal framework for the application of AI in healthcare. Although research has been conducted by various medical disciplines investigating the ethical implications of artificial intelligence in the healthcare setting, the literature lacks a holistic approach. Objective: The purpose of this review is to ascertain the ethical concerns of AI applications in healthcare, to identify the knowledge gaps and provide recommendations for an ethical and legal framework. Methodology: Electronic databases Pub Med and Google Scholar were extensively searched based on the search strategy pertaining to the purpose of this review. Further screening of the included articles was done on the grounds of the inclusion and exclusion criteria. Results: The search yielded a total of 1238 articles, out of which 16 articles were identified to be eligible for this review. The selection was strictly based on the inclusion and exclusion criteria mentioned in the manuscript. Conclusion: Artificial intelligence (AI) is an exceedingly puissant technology, with the prospect of advancing medical practice in the years to come. Nevertheless, AI brings with it a colossally abundant number of ethical and legal problems associated with its application in healthcare. There are manifold stakeholders in the legal and ethical issues revolving around AI and medicine. Thus, a multifaceted approach involving policymakers, developers, healthcare providers and patients is crucial to arrive at a feasible solution for mitigating the legal and ethical problems pertaining to AI in healthcare.",
    "doi": "10.3390/jpm12111914",
    "url": "https://openalex.org/W4309604980",
    "pdf_url": "https://www.mdpi.com/2075-4426/12/11/1914/pdf?version=1668597688",
    "venue": "Journal of Personalized Medicine",
    "citation_count": 134,
    "fields_of_study": [
      "Health care",
      "Inclusion (mineral)",
      "Artificial intelligence",
      "Applications of artificial intelligence",
      "Engineering ethics"
    ],
    "retrieved_at": "2026-02-02T16:58:12.547983"
  },
  {
    "source": "openalex",
    "source_id": "W2976689229",
    "title": "Big Data and Human Resources Management: The Rise of Talent Analytics",
    "authors": [
      "Manuela Nocker",
      "Vania Sena"
    ],
    "year": 2019,
    "abstract": "The purpose of this paper is to discuss the opportunities talent analytics offers HR practitioners. As the availability of methodologies for the analysis of large volumes of data has substantially improved over the last ten years, talent analytics has started to be used by organizations to manage their workforce. This paper discusses the benefits and costs associated with the use of talent analytics within an organization as well as to highlight the differences between talent analytics and other sub-fields of business analytics. It will discuss a number of case studies on how talent analytics can improve organizational decision-making. From the case studies, we will identify key channels through which the adoption of talent analytics can improve the performance of the HR function and eventually of the whole organization. While discussing the opportunities that talent analytics offer organizations, this paper highlights the costs (in terms of data governance and ethics) that the widespread use of talent analytics can generate. Finally, it highlights the importance of trust in supporting the successful implementation of talent analytics projects.",
    "doi": "10.3390/socsci8100273",
    "url": "https://openalex.org/W2976689229",
    "pdf_url": "https://www.mdpi.com/2076-0760/8/10/273/pdf?version=1570869084",
    "venue": "Social Sciences",
    "citation_count": 173,
    "fields_of_study": [
      "Analytics",
      "Business analytics",
      "Big data",
      "Business intelligence",
      "Data science"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548011"
  },
  {
    "source": "openalex",
    "source_id": "W4390587679",
    "title": "A Systematic Review and Meta-Analysis of Artificial Intelligence Tools in Medicine and Healthcare: Applications, Considerations, Limitations, Motivation and Challenges",
    "authors": [
      "Hussain A. Younis",
      "Taiseer Abdalla Elfadil Eisa",
      "Maged Nasser",
      "Thaeer Mueen Sahib",
      "Ameen A. Noor",
      "Osamah Mohammed Alyasiri",
      "Sani Salisu",
      "Israa M. Hayder",
      "Hameed A. Younis",
      "Hameed AbdulKareem Younis",
      "Hameed AbdulKareem Younis"
    ],
    "year": 2024,
    "abstract": "Artificial intelligence (AI) has emerged as a transformative force in various sectors, including medicine and healthcare. Large language models like ChatGPT showcase AI\u2019s potential by generating human-like text through prompts. ChatGPT\u2019s adaptability holds promise for reshaping medical practices, improving patient care, and enhancing interactions among healthcare professionals, patients, and data. In pandemic management, ChatGPT rapidly disseminates vital information. It serves as a virtual assistant in surgical consultations, aids dental practices, simplifies medical education, and aids in disease diagnosis. A total of 82 papers were categorised into eight major areas, which are G1: treatment and medicine, G2: buildings and equipment, G3: parts of the human body and areas of the disease, G4: patients, G5: citizens, G6: cellular imaging, radiology, pulse and medical images, G7: doctors and nurses, and G8: tools, devices and administration. Balancing AI\u2019s role with human judgment remains a challenge. A systematic literature review using the PRISMA approach explored AI\u2019s transformative potential in healthcare, highlighting ChatGPT\u2019s versatile applications, limitations, motivation, and challenges. In conclusion, ChatGPT\u2019s diverse medical applications demonstrate its potential for innovation, serving as a valuable resource for students, academics, and researchers in healthcare. Additionally, this study serves as a guide, assisting students, academics, and researchers in the field of medicine and healthcare alike.",
    "doi": "10.3390/diagnostics14010109",
    "url": "https://openalex.org/W4390587679",
    "pdf_url": "https://www.mdpi.com/2075-4418/14/1/109/pdf?version=1704340606",
    "venue": "Diagnostics",
    "citation_count": 185,
    "fields_of_study": [
      "Transformative learning",
      "Health care",
      "Medical education",
      "Applications of artificial intelligence",
      "Knowledge management"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548032"
  },
  {
    "source": "openalex",
    "source_id": "W3212538456",
    "title": "Characteristics of publicly available skin cancer image datasets: a systematic review",
    "authors": [
      "David Wen",
      "Saad M Khan",
      "Antonio Ji Xu",
      "Hussein Ibrahim",
      "Luke Smith",
      "Jose Caballero",
      "Luis Zepeda",
      "Carlos de Blas Perez",
      "Alastair K Denniston",
      "Xiaoxuan Liu",
      "Rubeta N Matin"
    ],
    "year": 2021,
    "abstract": "Publicly available skin image datasets are increasingly used to develop machine learning algorithms for skin cancer diagnosis. However, the total number of datasets and their respective content is currently unclear. This systematic review aimed to identify and evaluate all publicly available skin image datasets used for skin cancer diagnosis by exploring their characteristics, data access requirements, and associated image metadata. A combined MEDLINE, Google, and Google Dataset search identified 21 open access datasets containing 106 950 skin lesion images, 17 open access atlases, eight regulated access datasets, and three regulated access atlases. Images and accompanying data from open access datasets were evaluated by two independent reviewers. Among the 14 datasets that reported country of origin, most (11 [79%]) originated from Europe, North America, and Oceania exclusively. Most datasets (19 [91%]) contained dermoscopic images or macroscopic photographs only. Clinical information was available regarding age for 81 662 images (76\u00b74%), sex for 82 848 (77\u00b75%), and body site for 79 561 (74\u00b74%). Subject ethnicity data were available for 1415 images (1\u00b73%), and Fitzpatrick skin type data for 2236 (2\u00b71%). There was limited and variable reporting of characteristics and metadata among datasets, with substantial under-representation of darker skin types. This is the first systematic review to characterise publicly available skin image datasets, highlighting limited applicability to real-life clinical settings and restricted population representation, precluding generalisability. Quality standards for characteristics and metadata reporting for skin image datasets are needed.",
    "doi": "10.1016/s2589-7500(21)00252-1",
    "url": "https://openalex.org/W3212538456",
    "pdf_url": "http://www.thelancet.com/article/S2589750021002521/pdf",
    "venue": "The Lancet Digital Health",
    "citation_count": 196,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:12.548054"
  },
  {
    "source": "openalex",
    "source_id": "W2940105172",
    "title": "INTERNATIONAL HUMAN RIGHTS LAW AS A FRAMEWORK FOR ALGORITHMIC ACCOUNTABILITY",
    "authors": [
      "Lorna McGregor",
      "Daragh Murray",
      "Vivian Ng"
    ],
    "year": 2019,
    "abstract": "Abstract Existing approaches to \u2018algorithmic accountability\u2019, such as transparency, provide an important baseline, but are insufficient to address the (potential) harm to human rights caused by the use of algorithms in decision-making. In order to effectively address the impact on human rights, we argue that a framework that sets out a shared understanding and means of assessing harm; is capable of dealing with multiple actors and different forms of responsibility; and applies across the full algorithmic life cycle, from conception to deployment, is needed. While generally overlooked in debates on algorithmic accountability, in this article, we suggest that international human rights law already provides this framework. We apply this framework to illustrate the effect it has on the choices to employ algorithms in decision-making in the first place and the safeguards required. While our analysis indicates that in some circumstances, the use of algorithms may be restricted, we argue that these findings are not \u2018anti-innovation\u2019 but rather appropriate checks and balances to ensure that algorithms contribute to society, while safeguarding against risks.",
    "doi": "10.1017/s0020589319000046",
    "url": "https://openalex.org/W2940105172",
    "pdf_url": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/1D6D0A456B36BA7512A6AFF17F16E9B6/S0020589319000046a.pdf/div-class-title-international-human-rights-law-as-a-framework-for-algorithmic-accountability-div.pdf",
    "venue": "International and Comparative Law Quarterly",
    "citation_count": 175,
    "fields_of_study": [
      "Accountability",
      "Harm",
      "Transparency (behavior)",
      "Human rights",
      "Safeguarding"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548076"
  },
  {
    "source": "openalex",
    "source_id": "W4394580929",
    "title": "Autonomous Vehicles: Evolution of Artificial Intelligence and the Current Industry Landscape",
    "authors": [
      "Divya Garikapati",
      "Sneha Sudhir Shetiya"
    ],
    "year": 2024,
    "abstract": "The advent of autonomous vehicles has heralded a transformative era in transportation, reshaping the landscape of mobility through cutting-edge technologies. Central to this evolution is the integration of artificial intelligence (AI), propelling vehicles into realms of unprecedented autonomy. Commencing with an overview of the current industry landscape with respect to Operational Design Domain (ODD), this paper delves into the fundamental role of AI in shaping the autonomous decision-making capabilities of vehicles. It elucidates the steps involved in the AI-powered development life cycle in vehicles, addressing various challenges such as safety, security, privacy, and ethical considerations in AI-driven software development for autonomous vehicles. The study presents statistical insights into the usage and types of AI algorithms over the years, showcasing the evolving research landscape within the automotive industry. Furthermore, the paper highlights the pivotal role of parameters in refining algorithms for both trucks and cars, facilitating vehicles to adapt, learn, and improve performance over time. It concludes by outlining different levels of autonomy, elucidating the nuanced usage of AI algorithms, and discussing the automation of key tasks and the software package size at each level. Overall, the paper provides a comprehensive analysis of the current industry landscape, focusing on several critical aspects.",
    "doi": "10.3390/bdcc8040042",
    "url": "https://openalex.org/W4394580929",
    "pdf_url": "https://www.mdpi.com/2504-2289/8/4/42/pdf?version=1712549668",
    "venue": "Big Data and Cognitive Computing",
    "citation_count": 144,
    "fields_of_study": [
      "Current (fluid)",
      "Engineering",
      "Business",
      "Electrical engineering"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548093"
  },
  {
    "source": "openalex",
    "source_id": "W2986660526",
    "title": "Personnel selection in the digital age: a review of validity and applicant reactions, and future research challenges",
    "authors": [
      "Stephen A. Woods",
      "Sara Ahmed",
      "Ioannis Nikolaou",
      "Ana Cristina Costa",
      "Neil Anderson"
    ],
    "year": 2019,
    "abstract": "We present a targeted review of recent developments and advances in digital selection procedures (DSPs) with particular attention to advances in internet-based techniques. By reviewing the emergence of DSPs in selection research and practice, we highlight five main categories of methods (online applications, online psychometric testing, digital interviews, gamified assessment and social media). We discuss the evidence base for each of these DSP groups, focusing on construct and criterion validity, and applicant reactions to their use in organizations. Based on the findings of our review, we present a critique of the evidence base for DSPs in industrial, work and organizational psychology and set out an agenda for advancing research. We identify pressing gaps in our understanding of DSPs, and ten key questions to be answered. Given that DSPs are likely to depart further from traditional non-digital selection procedures in the future, a theme in this agenda is the need to establish a distinct and specific literature on DSPs, and to do so at a pace that reflects the speed of the underlying technological advancement. In concluding, we, therefore, issue a call to action for selection researchers in work and organizational psychology to commence a new and rigorous multidisciplinary programme of scientific study of DSPs.",
    "doi": "10.1080/1359432x.2019.1681401",
    "url": "https://openalex.org/W2986660526",
    "pdf_url": "https://bradscholars.brad.ac.uk/bitstreams/f18b4768-85c8-45d5-b629-825fe1c199ea/download",
    "venue": "European Journal of Work and Organizational Psychology",
    "citation_count": 191,
    "fields_of_study": [
      "Selection (genetic algorithm)",
      "Pace",
      "Set (abstract data type)",
      "Construct (python library)",
      "The Internet"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548113"
  },
  {
    "source": "openalex",
    "source_id": "W3008345757",
    "title": "Global value chains: A review of the multi-disciplinary literature",
    "authors": [
      "Liena Kano",
      "Eric W. K. Tsang",
      "Henry Wai\u2010chung Yeung"
    ],
    "year": 2020,
    "abstract": "Abstract This article reviews the rapidly growing domain of global value chain (GVC) research by analyzing several highly cited conceptual frameworks and then appraising GVC studies published in such disciplines as international business, general management, supply chain management, operations management, economic geography, regional and development studies, and international political economy. Building on GVC conceptual frameworks, we conducted the review based on a comparative institutional perspective that encompasses critical governance issues at the micro-, GVC, and macro-levels. Our results indicate that some of these issues have garnered significantly more scholarly attention than others. We suggest several future research topics such as microfoundations of GVC governance, GVC mapping, learning, impact of lead firm ownership and strategy, dynamics of GVC arrangements, value creation and distribution, financialization, digitization, the impact of renewed protectionism, the impact of GVCs on their macro-environment, and chain-level performance management.",
    "doi": "10.1057/s41267-020-00304-2",
    "url": "https://openalex.org/W3008345757",
    "pdf_url": "https://link.springer.com/content/pdf/10.1057/s41267-020-00304-2.pdf",
    "venue": "Journal of International Business Studies",
    "citation_count": 621,
    "fields_of_study": [
      "Microfoundations",
      "Protectionism",
      "Corporate governance",
      "Global value chain",
      "Value (mathematics)"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548135"
  },
  {
    "source": "openalex",
    "source_id": "W4206698631",
    "title": "Trustworthy Augmented Intelligence in Health Care",
    "authors": [
      "Elliott Crigger",
      "Karen Reinbold",
      "Chelsea Hanson",
      "Audiey Kao",
      "Kathleen Blake",
      "Mira Irons"
    ],
    "year": 2022,
    "abstract": "Abstract Augmented Intelligence (AI) systems have the power to transform health care and bring us closer to the quadruple aim: enhancing patient experience, improving population health, reducing costs, and improving the work life of health care providers. Earning physicians' trust is critical for accelerating adoption of AI into patient care. As technology evolves, the medical community will need to develop standards for these innovative technologies and re-visit current regulatory systems that physicians and patients rely on to ensure that health care AI is responsible, evidence-based, free from bias, and designed and deployed to promote equity. To develop actionable guidance for trustworthy AI in health care, the AMA reviewed literature on the challenges health care AI poses and reflected on existing guidance as a starting point for addressing those challenges (including models for regulating the introduction of innovative technologies into clinical care).",
    "doi": "10.1007/s10916-021-01790-z",
    "url": "https://openalex.org/W4206698631",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10916-021-01790-z.pdf",
    "venue": "Journal of Medical Systems",
    "citation_count": 118,
    "fields_of_study": [
      "Health informatics",
      "Trustworthiness",
      "Health care",
      "Computer science",
      "Internet privacy"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548153"
  },
  {
    "source": "openalex",
    "source_id": "W3116658655",
    "title": "Framing governance for a contested emerging technology:insights from AI policy",
    "authors": [
      "Inga Ulnicane",
      "William Knight",
      "Tonii Leach",
      "Bernd Carsten Stahl",
      "Winter-Gladys Wanjiku"
    ],
    "year": 2020,
    "abstract": "ABSTRACT This paper examines how the governance in AI policy documents have been framed as way to resolve public controversies surrounding AI. It draws on the studies of governance of emerging technologies, the concept of policy framing, and analysis of 49 recent policy documents dedicated to AI which have been prepared in the context of technological hype expecting fast advances of AI that will fundamentally change economy and society. The hype about AI is accompanied by major public controversy about positive and negative effects of AI. Against the backdrop of this policy controversy, governance emerges as one of the frames that diagnoses the problems and offers prescriptions. Accordingly, the current governance characterized by oligopoly of a small number of large companies is indicated as one of the reasons for problems such as lack of consideration of societal needs and concerns. To address these problems, governance frame in AI policy documents assigns more active and collaborative roles to the state and society. Amid public controversies, the state is assigned the roles of promoting and facilitating AI development while at the same time being a guarantor of risk mitigation and enabler of societal engagement. High expectations are assigned to public engagement with multiple publics as a way to increase diversity, representation and equality in AI development and use. While this governance frame might have a normative appeal, it is not specific about addressing some well-known challenges of the proposed governance mode such as risks of capture by vested interests or difficulties to achieve consensus.",
    "doi": "10.1080/14494035.2020.1855800",
    "url": "https://openalex.org/W3116658655",
    "pdf_url": "https://academic.oup.com/policyandsociety/article-pdf/40/2/158/42564407/14494035.2020.1855800.pdf",
    "venue": "Policy and Society",
    "citation_count": 193,
    "fields_of_study": [
      "Framing (construction)",
      "Corporate governance",
      "Public policy",
      "Normative",
      "Appeal"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548168"
  },
  {
    "source": "openalex",
    "source_id": "W2808048733",
    "title": "Understanding and Resolving Failures in Human-Robot Interaction: Literature Review and Model Development",
    "authors": [
      "Shanee Honig",
      "Tal Oron-Gilad"
    ],
    "year": 2018,
    "abstract": "While substantial effort has been invested in making robots more reliable, experience demonstrates that robots operating in unstructured environments are often challenged by frequent failures. Despite this, robots have not yet reached a level of design that allows effective management of faulty or unexpected behavior by untrained users. To understand why this may be the case, an in-depth literature review was done to explore when people perceive and resolve robot failures, how robots communicate failure, how failures influence people's perceptions and feelings toward robots, and how these effects can be mitigated. Fifty-two studies were identified relating to communicating failures and their causes, the influence of failures on human-robot interaction (HRI), and mitigating failures. Since little research has been done on these topics within the HRI community, insights from the fields of human computer interaction (HCI), human factors engineering, cognitive engineering and experimental psychology are presented and discussed. Based on the literature, we developed a model of information processing for robotic failures (Robot Failure Human Information Processing, RF-HIP), that guides the discussion of our findings. The model describes the way people perceive, process, and act on failures in human robot interaction. The model includes three main parts: (1) communicating failures, (2) perception and comprehension of failures, and (3) solving failures. Each part contains several stages, all influenced by contextual considerations and mitigation strategies. Several gaps in the literature have become evident as a result of this evaluation. More focus has been given to technical failures than interaction failures. Few studies focused on human errors, on communicating failures, or the cognitive, psychological, and social determinants that impact the design of mitigation strategies. By providing the stages of human information processing, RF-HIP can be used as a tool to promote the development of user-centered failure-handling strategies for HRIs.",
    "doi": "10.3389/fpsyg.2018.00861",
    "url": "https://openalex.org/W2808048733",
    "pdf_url": "https://www.frontiersin.org/articles/10.3389/fpsyg.2018.00861/pdf",
    "venue": "Frontiers in Psychology",
    "citation_count": 294,
    "fields_of_study": [
      "Psychology",
      "Cognitive science",
      "Cognitive psychology",
      "Human\u2013computer interaction",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548190"
  },
  {
    "source": "openalex",
    "source_id": "W4362611851",
    "title": "Environmentally sustainable smart cities and their converging AI, IoT, and big data technologies and solutions: an integrated approach to an extensive literature review",
    "authors": [
      "Simon Elias Bibri",
      "Alexandre Alahi",
      "Ayyoob Sharifi",
      "John Krogstie"
    ],
    "year": 2023,
    "abstract": "Abstract There have recently been intensive efforts aimed at addressing the challenges of environmental degradation and climate change through the applied innovative solutions of AI, IoT, and Big Data. Given the synergistic potential of these advanced technologies, their convergence is being embraced and leveraged by smart cities in an attempt to make progress toward reaching the environmental targets of sustainable development goals under what has been termed \u201cenvironmentally sustainable smart cities.\u201d This new paradigm of urbanism represents a significant research gap in and of itself. To fill this gap, this study explores the key research trends and driving factors of environmentally sustainable smart cities and maps their thematic evolution. Further, it examines the fragmentation, amalgamation, and transition of their underlying models of urbanism as well as their converging AI, IoT, and Big Data technologies and solutions. It employs and combines bibliometric analysis and evidence synthesis methods. A total of 2,574 documents were collected from the Web of Science database and compartmentalized into three sub-periods: 1991\u20132015, 2016\u20132019, and 2020\u20132021. The results show that environmentally sustainable smart cities are a rapidly growing trend that markedly escalated during the second and third periods\u2014due to the acceleration of the digitalization and decarbonization agendas\u2014thanks to COVID-19 and the rapid advancement of data-driven technologies. The analysis also reveals that, while the overall priority research topics have been dynamic over time\u2014some AI models and techniques and environmental sustainability areas have received more attention than others. The evidence synthesized indicates that the increasing criticism of the fragmentation of smart cities and sustainable cities, the widespread diffusion of the SDGs agenda, and the dominance of advanced ICT have significantly impacted the materialization of environmentally sustainable smart cities, thereby influencing the landscape and dynamics of smart cities. It also suggests that the convergence of AI, IoT, and Big Data technologies provides new approaches to tackling the challenges of environmental sustainability. However, these technologies involve environmental costs and pose ethical risks and regulatory conundrums. The findings can inform scholars and practitioners of the emerging data-driven technology solutions of smart cities, as well as assist policymakers in designing and implementing responsive environmental policies.",
    "doi": "10.1186/s42162-023-00259-2",
    "url": "https://openalex.org/W4362611851",
    "pdf_url": "https://energyinformatics.springeropen.com/counter/pdf/10.1186/s42162-023-00259-2",
    "venue": "Energy Informatics",
    "citation_count": 206,
    "fields_of_study": [
      "Internet of Things",
      "Big data",
      "Computer science",
      "Environmentally friendly",
      "Smart city"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548217"
  },
  {
    "source": "openalex",
    "source_id": "W4390906507",
    "title": "Artificial Intelligence Alone Will Not Democratise Education: On Educational Inequality, Techno-Solutionism and Inclusive Tools",
    "authors": [
      "Sahan Bulathwela",
      "Mar\u00eda P\u00e9rez\u2010Ortiz",
      "Catherine Holloway",
      "Mutlu Cukurova",
      "John Shawe\u2010Taylor"
    ],
    "year": 2024,
    "abstract": "Artificial Intelligence (AI) in Education claims to have the potential for building personalised curricula, as well as bringing opportunities for democratising education and creating a renaissance of new ways of teaching and learning. Millions of students are starting to benefit from the use of these technologies, but millions more around the world are not, due to the digital divide and deep pre-existing social and educational inequalities. If this trend continues, the first large-scale delivery of AI in Education could lead to greater educational inequality, along with a global misallocation of educational resources motivated by the current techno-solutionist narrative, which proposes technological solutions as a quick and flawless way to solve complex real-world problems. This work focuses on posing questions about the future of AI in Education, intending to initiate the pressing conversation that could set the right foundations (e.g., inclusion and diversity) for a new generation of education that is permeated with AI technology. The main goal of our opinion piece is to conceptualise a sustainable, large-scale and inclusive AI for the education ecosystem that facilitates equitable, high-quality lifelong learning opportunities for all. The contribution starts by synthesising how AI might change how we learn and teach, focusing on the case of personalised learning companions and assistive technology for disability. Then, we move on to discuss some socio-technical features that will be crucial to avoiding the perils of these AI systems worldwide (and perhaps ensuring their success by leveraging more inclusive education). This work also discusses the potential of using AI together with free, participatory and democratic resources, such as Wikipedia, Open Educational Resources and open-source tools. We emphasise the need for collectively designing human-centred, transparent, interactive and collaborative AI-based algorithms that empower and give complete agency to stakeholders, as well as supporting new emerging pedagogies. Finally, we ask what it would take for this educational revolution to provide egalitarian and empowering access to education that transcends any political, cultural, language, geographical and learning-ability barriers, so that educational systems can be responsive to all learners\u2019 needs.",
    "doi": "10.3390/su16020781",
    "url": "https://openalex.org/W4390906507",
    "pdf_url": "https://www.mdpi.com/2071-1050/16/2/781/pdf?version=1705417242",
    "venue": "Sustainability",
    "citation_count": 149,
    "fields_of_study": [
      "Curriculum",
      "Inclusion (mineral)",
      "Conversation",
      "Scale (ratio)",
      "Engineering ethics"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548253"
  },
  {
    "source": "openalex",
    "source_id": "W4210402525",
    "title": "From Greenwashing to Machinewashing: A Model and Future Directions Derived from Reasoning by Analogy",
    "authors": [
      "Peter Seele",
      "Mario D. Schultz"
    ],
    "year": 2022,
    "abstract": "Abstract This article proposes a conceptual mapping to outline salient properties and relations that allow for a knowledge transfer from the well-established greenwashing phenomenon to the more recent machinewashing. We account for relevant dissimilarities, indicating where conceptual boundaries may be drawn. Guided by a \u201creasoning by analogy\u201d approach, the article addresses the structural analogy and machinewashing idiosyncrasies leading to a novel and theoretically informed model of machinewashing. Consequently, machinewashing is defined as a strategy that organizations adopt to engage in misleading behavior (communication and/or action) about ethical Artificial Intelligence (AI)/algorithmic systems. Machinewashing involves misleading information about ethical AI communicated or omitted via words, visuals, or the underlying algorithm of AI itself. Furthermore, and going beyond greenwashing, machinewashing may be used for symbolic actions such as (covert) lobbying and prevention of stricter regulation. By outlining diverse theoretical foundations of the established greenwashing domain and their relation to specific research questions, the article proposes a machinewashing model and a set of theory-related research questions on the macro, meso, and micro-level for future machinewashing research. We conclude by stressing limitations and by outlining practical implications for organizations and policymakers.",
    "doi": "10.1007/s10551-022-05054-9",
    "url": "https://openalex.org/W4210402525",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10551-022-05054-9.pdf",
    "venue": "Journal of Business Ethics",
    "citation_count": 137,
    "fields_of_study": [
      "Analogy",
      "Greenwashing",
      "Action (physics)",
      "Salient",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548286"
  },
  {
    "source": "openalex",
    "source_id": "W4379743664",
    "title": "A systematic review of Green <scp>AI</scp>",
    "authors": [
      "Roberto Verdecchia",
      "June Sallou",
      "Lu\u00eds Cruz"
    ],
    "year": 2023,
    "abstract": "Abstract With the ever\u2010growing adoption of artificial intelligence (AI)\u2010based systems, the carbon footprint of AI is no longer negligible. AI researchers and practitioners are therefore urged to hold themselves accountable for the carbon emissions of the AI models they design and use. This led in recent years to the appearance of researches tackling AI environmental sustainability, a field referred to as Green AI. Despite the rapid growth of interest in the topic, a comprehensive overview of Green AI research is to date still missing. To address this gap, in this article, we present a systematic review of the Green AI literature. From the analysis of 98 primary studies, different patterns emerge. The topic experienced a considerable growth from 2020 onward. Most studies consider monitoring AI model footprint, tuning hyperparameters to improve model sustainability, or benchmarking models. A mix of position papers, observational studies, and solution papers are present. Most papers focus on the training phase, are algorithm\u2010agnostic or study neural networks, and use image data. Laboratory experiments are the most common research strategy. Reported Green AI energy savings go up to 115%, with savings over 50% being rather common. Industrial parties are involved in Green AI studies, albeit most target academic readers. Green AI tool provisioning is scarce. As a conclusion, the Green AI research field results to have reached a considerable level of maturity. Therefore, from this review emerges that the time is suitable to adopt other Green AI research strategies, and port the numerous promising academic results to industrial practice. This article is categorized under: Technologies &gt; Machine Learning",
    "doi": "10.1002/widm.1507",
    "url": "https://openalex.org/W4379743664",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/widm.1507",
    "venue": "Wiley Interdisciplinary Reviews Data Mining and Knowledge Discovery",
    "citation_count": 214,
    "fields_of_study": [
      "Artificial intelligence",
      "Sustainability",
      "Benchmarking",
      "Carbon footprint",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548311"
  },
  {
    "source": "openalex",
    "source_id": "W3083287224",
    "title": "Trust in Robots: Challenges and Opportunities",
    "authors": [
      "Bing Cai Kok",
      "Harold Soh"
    ],
    "year": 2020,
    "abstract": null,
    "doi": "10.1007/s43154-020-00029-y",
    "url": "https://openalex.org/W3083287224",
    "pdf_url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC7467858/",
    "venue": "Current Robotics Reports",
    "citation_count": 188,
    "fields_of_study": [
      "Robot",
      "Trustworthiness",
      "Computer science",
      "Robotics",
      "Human\u2013computer interaction"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548336"
  },
  {
    "source": "openalex",
    "source_id": "W3174417986",
    "title": "Accelerating AI Adoption with Responsible AI Signals and Employee Engagement Mechanisms in Health Care",
    "authors": [
      "Weisha Wang",
      "Long Chen",
      "Mengran Xiong",
      "Yichuan Wang"
    ],
    "year": 2021,
    "abstract": null,
    "doi": "10.1007/s10796-021-10154-4",
    "url": "https://openalex.org/W3174417986",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10796-021-10154-4.pdf",
    "venue": "Information Systems Frontiers",
    "citation_count": 122,
    "fields_of_study": [
      "Autonomy",
      "Beneficence",
      "Economic Justice",
      "Health care",
      "Psychology"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548339"
  },
  {
    "source": "openalex",
    "source_id": "W4393335480",
    "title": "Foundation metrics for evaluating effectiveness of healthcare conversations powered by generative AI",
    "authors": [
      "Mahyar Abbasian",
      "Elahe Khatibi",
      "Iman Azimi",
      "David Oniani",
      "Zahra Shakeri Hossein Abad",
      "Alexander Thieme",
      "Ram D. Sriram",
      "Zhongqi Yang",
      "Yanshan Wang",
      "Bryant Lin",
      "Olivier Gevaert",
      "Li-Jia Li",
      "Ramesh Jain",
      "Amir M. Rahmani"
    ],
    "year": 2024,
    "abstract": "Abstract Generative Artificial Intelligence is set to revolutionize healthcare delivery by transforming traditional patient care into a more personalized, efficient, and proactive process. Chatbots, serving as interactive conversational models, will probably drive this patient-centered transformation in healthcare. Through the provision of various services, including diagnosis, personalized lifestyle recommendations, dynamic scheduling of follow-ups, and mental health support, the objective is to substantially augment patient health outcomes, all the while mitigating the workload burden on healthcare providers. The life-critical nature of healthcare applications necessitates establishing a unified and comprehensive set of evaluation metrics for conversational models. Existing evaluation metrics proposed for various generic large language models (LLMs) demonstrate a lack of comprehension regarding medical and health concepts and their significance in promoting patients\u2019 well-being. Moreover, these metrics neglect pivotal user-centered aspects, including trust-building, ethics, personalization, empathy, user comprehension, and emotional support. The purpose of this paper is to explore state-of-the-art LLM-based evaluation metrics that are specifically applicable to the assessment of interactive conversational models in healthcare. Subsequently, we present a comprehensive set of evaluation metrics designed to thoroughly assess the performance of healthcare chatbots from an end-user perspective. These metrics encompass an evaluation of language processing abilities, impact on real-world clinical tasks, and effectiveness in user-interactive conversations. Finally, we engage in a discussion concerning the challenges associated with defining and implementing these metrics, with particular emphasis on confounding factors such as the target audience, evaluation methods, and prompt techniques involved in the evaluation process.",
    "doi": "10.1038/s41746-024-01074-z",
    "url": "https://openalex.org/W4393335480",
    "pdf_url": "https://www.nature.com/articles/s41746-024-01074-z.pdf",
    "venue": "npj Digital Medicine",
    "citation_count": 141,
    "fields_of_study": [
      "Health care",
      "Computer science",
      "Personalization",
      "Set (abstract data type)",
      "Process (computing)"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548344"
  },
  {
    "source": "openalex",
    "source_id": "W2982915530",
    "title": "WeBuildAI",
    "authors": [
      "Min Kyung Lee",
      "Daniel Kusbit",
      "Anson Kahng",
      "Ji Tae Kim",
      "Xinran Yuan",
      "Allissa Chan",
      "Daniel See",
      "Ritesh Noothigattu",
      "Siheon Lee",
      "Alexandros Psomas",
      "Ariel D. Procaccia"
    ],
    "year": 2019,
    "abstract": "Algorithms increasingly govern societal functions, impacting multiple stakeholders and social groups. How can we design these algorithms to balance varying interests in a moral, legitimate way? As one answer to this question, we present WeBuildAI, a collective participatory framework that enables people to build algorithmic policy for their communities. The key idea of the framework is to enable stakeholders to construct a computational model that represents their views and to have those models vote on their behalf to create algorithmic policy. As a case study, we applied this framework to a matching algorithm that operates an on-demand food donation transportation service in order to adjudicate equity and efficiency trade-offs. The service's stakeholders--donors, volunteers, recipient organizations, and nonprofit employees--used the framework to design the algorithm through a series of studies in which we researched their experiences. Our findings suggest that the framework successfully enabled participants to build models that they felt confident represented their own beliefs. Participatory algorithm design also improved both procedural fairness and the distributive outcomes of the algorithm, raised participants' algorithmic awareness, and helped identify inconsistencies in human decision-making in the governing organization. Our work demonstrates the feasibility, potential and challenges of community involvement in algorithm design.",
    "doi": "10.1145/3359283",
    "url": "https://openalex.org/W2982915530",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3359283",
    "venue": "Proceedings of the ACM on Human-Computer Interaction",
    "citation_count": 174,
    "fields_of_study": [
      "Computer science",
      "Equity (law)",
      "Construct (python library)",
      "Participatory design",
      "Citizen journalism"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548368"
  },
  {
    "source": "openalex",
    "source_id": "W4281775820",
    "title": "Transparency of AI in Healthcare as a Multilayered System of Accountabilities: Between Legal Requirements and Technical Limitations",
    "authors": [
      "Anastasiya Kiseleva",
      "Dimitris Kotzinos",
      "Paul De Hert"
    ],
    "year": 2022,
    "abstract": "The lack of transparency is one of the artificial intelligence (AI)'s fundamental challenges, but the concept of transparency might be even more opaque than AI itself. Researchers in different fields who attempt to provide the solutions to improve AI's transparency articulate different but neighboring concepts that include, besides transparency, explainability and interpretability. Yet, there is no common taxonomy neither within one field (such as data science) nor between different fields (law and data science). In certain areas like healthcare, the requirements of transparency are crucial since the decisions directly affect people's lives. In this paper, we suggest an interdisciplinary vision on how to tackle the issue of AI's transparency in healthcare, and we propose a single point of reference for both legal scholars and data scientists on transparency and related concepts. Based on the analysis of the European Union (EU) legislation and literature in computer science, we submit that transparency shall be considered the \u201cway of thinking\u201d and umbrella concept characterizing the process of AI's development and use. Transparency shall be achieved through a set of measures such as interpretability and explainability, communication, auditability, traceability, information provision, record-keeping, data governance and management, and documentation. This approach to deal with transparency is of general nature, but transparency measures shall be always contextualized. By analyzing transparency in the healthcare context, we submit that it shall be viewed as a system of accountabilities of involved subjects (AI developers, healthcare professionals, and patients) distributed at different layers (insider, internal, and external layers, respectively). The transparency-related accountabilities shall be built-in into the existing accountability picture which justifies the need to investigate the relevant legal frameworks. These frameworks correspond to different layers of the transparency system. The requirement of informed medical consent correlates to the external layer of transparency and the Medical Devices Framework is relevant to the insider and internal layers. We investigate the said frameworks to inform AI developers on what is already expected from them with regards to transparency. We also discover the gaps in the existing legislative frameworks concerning AI's transparency in healthcare and suggest the solutions to fill them in.",
    "doi": "10.3389/frai.2022.879603",
    "url": "https://openalex.org/W4281775820",
    "pdf_url": "https://www.frontiersin.org/articles/10.3389/frai.2022.879603/pdf",
    "venue": "Frontiers in Artificial Intelligence",
    "citation_count": 200,
    "fields_of_study": [
      "Transparency (behavior)",
      "Health care",
      "Business",
      "Healthcare system",
      "Risk analysis (engineering)"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548387"
  },
  {
    "source": "openalex",
    "source_id": "W3142698583",
    "title": "Sociotechnical Envelopment of Artificial Intelligence: An Approach to Organizational Deployment of Inscrutable Artificial Intelligence Systems",
    "authors": [
      "Aleksandre Asatiani",
      "Pekka Malo",
      "Per R\u00e5dberg Nagb\u00f8l",
      "Esko Penttinen",
      "Tapani Rinta-Kahila",
      "Antti Salovaara"
    ],
    "year": 2021,
    "abstract": "The paper presents an approach for implementing inscrutable (i.e., nonexplainable) artificial intelligence (AI) such as neural networks in an accountable and safe manner in organizational settings. Drawing on an exploratory case study and the recently proposed concept of envelopment, it describes a case of an organization successfully \u201cenveloping\u201d its AI solutions to balance the performance benefits of flexible AI models with the risks that inscrutable models can entail. The authors present several envelopment methods\u2014establishing clear boundaries within which the AI is to interact with its surroundings, choosing and curating the training data well, and appropriately managing input and output sources\u2014alongside their influence on the choice of AI models within the organization. This work makes two key contributions: It introduces the concept of sociotechnical envelopment by demonstrating the ways in which an organization\u2019s successful AI envelopment depends on the interaction of social and technical factors, thus extending the literature\u2019s focus beyond mere technical issues. Secondly, the empirical examples illustrate how operationalizing a sociotechnical envelopment enables an organization to manage the trade-off between low explainability and high performance presented by inscrutable models. These contributions pave the way for more responsible, accountable AI implementations in organizations, whereby humans can gain better control of even inscrutable machine-learning models.",
    "doi": "10.17705/1jais.00664",
    "url": "https://openalex.org/W3142698583",
    "pdf_url": "https://aisel.aisnet.org/cgi/viewcontent.cgi?article=2001&context=jais",
    "venue": "Journal of the Association for Information Systems",
    "citation_count": 148,
    "fields_of_study": [
      "Sociotechnical system",
      "Operationalization",
      "Computer science",
      "Data envelopment analysis",
      "Management science"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548421"
  },
  {
    "source": "openalex",
    "source_id": "W3192184597",
    "title": "Data science and AI in FinTech: an overview",
    "authors": [
      "Longbing Cao",
      "Qiang Yang",
      "Philip S. Yu"
    ],
    "year": 2021,
    "abstract": null,
    "doi": "10.1007/s41060-021-00278-w",
    "url": "https://openalex.org/W3192184597",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s41060-021-00278-w.pdf",
    "venue": "International Journal of Data Science and Analytics",
    "citation_count": 158,
    "fields_of_study": [
      "Cryptocurrency",
      "Big data",
      "Financial services",
      "Data science",
      "Futures contract"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548441"
  },
  {
    "source": "openalex",
    "source_id": "W3027907822",
    "title": "Can Building \u201cArtificially Intelligent Cities\u201d Safeguard Humanity from Natural Disasters, Pandemics, and Other Catastrophes? An Urban Scholar\u2019s Perspective",
    "authors": [
      "Tan Yi\u011fitcanlar",
      "Luke Butler",
      "Emily Windle",
      "Kevin C. Desouza",
      "Rashid Mehmood",
      "Juan M. Corchado"
    ],
    "year": 2020,
    "abstract": "In recent years, artificial intelligence (AI) has started to manifest itself at an unprecedented pace. With highly sophisticated capabilities, AI has the potential to dramatically change our cities and societies. Despite its growing importance, the urban and social implications of AI are still an understudied area. In order to contribute to the ongoing efforts to address this research gap, this paper introduces the notion of an artificially intelligent city as the potential successor of the popular smart city brand\u2014where the smartness of a city has come to be strongly associated with the use of viable technological solutions, including AI. The study explores whether building artificially intelligent cities can safeguard humanity from natural disasters, pandemics, and other catastrophes. All of the statements in this viewpoint are based on a thorough review of the current status of AI literature, research, developments, trends, and applications. This paper generates insights and identifies prospective research questions by charting the evolution of AI and the potential impacts of the systematic adoption of AI in cities and societies. The generated insights inform urban policymakers, managers, and planners on how to ensure the correct uptake of AI in our cities, and the identified critical questions offer scholars directions for prospective research and development.",
    "doi": "10.3390/s20102988",
    "url": "https://openalex.org/W3027907822",
    "pdf_url": "https://www.mdpi.com/1424-8220/20/10/2988/pdf",
    "venue": "Sensors",
    "citation_count": 184,
    "fields_of_study": [
      "Pace",
      "Successor cardinal",
      "Humanity",
      "Safeguard",
      "Natural disaster"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548445"
  },
  {
    "source": "openalex",
    "source_id": "W4281627170",
    "title": "An AI-based Decision Support System for Predicting Mental Health Disorders",
    "authors": [
      "Salih Tutun",
      "Marina Johnson",
      "Abdulaziz Ahmed",
      "Abdullah Albizri",
      "Sedat Irgil",
      "Ilker Yesilkaya",
      "Esma Nur Ucar",
      "Tanalp Sengun",
      "Antoine Harfouche"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1007/s10796-022-10282-5",
    "url": "https://openalex.org/W4281627170",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10796-022-10282-5.pdf",
    "venue": "Information Systems Frontiers",
    "citation_count": 136,
    "fields_of_study": [
      "Mental health",
      "Medical diagnosis",
      "Computer science",
      "Anxiety",
      "Classification of mental disorders"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548466"
  },
  {
    "source": "openalex",
    "source_id": "W3134656840",
    "title": "Data preparation for artificial intelligence in medical imaging: A comprehensive guide to open-access platforms and tools",
    "authors": [
      "Oliver D\u00edaz",
      "Kaisar Kushibar",
      "Richard Osuala",
      "Akis Linardos",
      "Lidia Garrucho",
      "Laura Igual",
      "Petia Radeva",
      "Fred Prior",
      "Polyxeni Gkontra",
      "Karim Lekadir"
    ],
    "year": 2021,
    "abstract": "The vast amount of data produced by today's medical imaging systems has led medical professionals to turn to novel technologies in order to efficiently handle their data and exploit the rich information present in them. In this context, artificial intelligence (AI) is emerging as one of the most prominent solutions, promising to revolutionise every day clinical practice and medical research. The pillar supporting the development of reliable and robust AI algorithms is the appropriate preparation of the medical images to be used by the AI-driven solutions. Here, we provide a comprehensive guide for the necessary steps to prepare medical images prior to developing or applying AI algorithms. The main steps involved in a typical medical image preparation pipeline include: (i) image acquisition at clinical sites, (ii) image de-identification to remove personal information and protect patient privacy, (iii) data curation to control for image and associated information quality, (iv) image storage, and (v) image annotation. There exists a plethora of open access tools to perform each of the aforementioned tasks and are hereby reviewed. Furthermore, we detail medical image repositories covering different organs and diseases. Such repositories are constantly increasing and enriched with the advent of big data. Lastly, we offer directions for future work in this rapidly evolving field.",
    "doi": "10.1016/j.ejmp.2021.02.007",
    "url": "https://openalex.org/W3134656840",
    "pdf_url": "http://www.physicamedica.com/article/S1120179721000958/pdf",
    "venue": "Physica Medica",
    "citation_count": 134,
    "fields_of_study": [
      "Computer science",
      "Medical imaging",
      "Artificial intelligence",
      "Data science"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548470"
  },
  {
    "source": "openalex",
    "source_id": "W4362653910",
    "title": "Global Encyclopedia of Public Administration, Public Policy, and Governance",
    "authors": [
      "Ali Farazmand\ufeff"
    ],
    "year": 2022,
    "abstract": "This second edition serves as a comprehensive collection of global scholarship regarding the vast fields of public administration and public policy.",
    "doi": "10.1007/978-3-030-66252-3",
    "url": "https://openalex.org/W4362653910",
    "pdf_url": "https://link.springer.com/content/pdf/bfm:978-3-030-66252-3/1?pdf=chapter%20toc",
    "venue": null,
    "citation_count": 244,
    "fields_of_study": [
      "Scholarship",
      "Encyclopedia",
      "Public administration",
      "Administration (probate law)",
      "Corporate governance"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548490"
  },
  {
    "source": "openalex",
    "source_id": "W4229457720",
    "title": "Understanding and shaping the future of work with self-determination theory",
    "authors": [
      "Maryl\u00e8ne Gagn\u00e9",
      "Sharon K. Parker",
      "Mark Griffin",
      "Patrick D. Dunlop",
      "Caroline Knight",
      "Florian E. Klonek",
      "Xavier Parent\u2010Rocheleau"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1038/s44159-022-00056-w",
    "url": "https://openalex.org/W4229457720",
    "pdf_url": "https://www.nature.com/articles/s44159-022-00056-w.pdf",
    "venue": "Nature Reviews Psychology",
    "citation_count": 302,
    "fields_of_study": [
      "Self-determination theory",
      "Competence (human resources)",
      "Autonomy",
      "Work (physics)",
      "Work motivation"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548496"
  },
  {
    "source": "openalex",
    "source_id": "W3126217793",
    "title": "AI in Context and the Sustainable Development Goals: Factoring in the Unsustainability of the Sociotechnical System",
    "authors": [
      "Henrik Skaug S\u00e6tra"
    ],
    "year": 2021,
    "abstract": "Artificial intelligence (AI) is associated with both positive and negative impacts on both people and planet, and much attention is currently devoted to analyzing and evaluating these impacts. In 2015, the UN set 17 Sustainable Development Goals (SDGs), consisting of environmental, social, and economic goals. This article shows how the SDGs provide a novel and useful framework for analyzing and categorizing the benefits and harms of AI. AI is here considered in context as part of a sociotechnical system consisting of larger structures and economic and political systems, rather than as a simple tool that can be analyzed in isolation. This article distinguishes between direct and indirect effects of AI and divides the SDGs into five groups based on the kinds of impact AI has on them. While AI has great positive potential, it is also intimately linked to nonuniversal access to increasingly large data sets and the computing infrastructure required to make use of them. As a handful of nations and companies control the development and application of AI, this raises important questions regarding the potential negative implications of AI on the SDGs. The conceptual framework here presented helps structure the analysis of which of the SDGs AI might be useful in attaining and which goals are threatened by the increased use of AI.",
    "doi": "10.3390/su13041738",
    "url": "https://openalex.org/W3126217793",
    "pdf_url": "https://www.mdpi.com/2071-1050/13/4/1738/pdf?version=1612681180",
    "venue": "Sustainability",
    "citation_count": 133,
    "fields_of_study": [
      "Sociotechnical system",
      "Factoring",
      "Sustainable development",
      "Context (archaeology)",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548499"
  },
  {
    "source": "openalex",
    "source_id": "W2609656715",
    "title": "Job Insecurity and the Changing Workplace: Recent Developments and the Future Trends in Job Insecurity Research",
    "authors": [
      "Cynthia Lee",
      "Guohua Huang",
      "Susan J. Ashford"
    ],
    "year": 2017,
    "abstract": "This article updates our understanding of the field of job insecurity (JI) by incorporating studies across the globe since 2003, analyzes what we know, and offers ideas on how to move forward. We begin by reviewing the conceptualization and operationalization of job insecurity. We then review empirical studies of the antecedents, consequences, and moderators of JI effects, as well as the various theoretical perspectives used to explain the relationship of JI to various outcomes. Our analyses also consider JI research in different regions of the world, highlighting the cross-cultural differences. We conclude by identifying areas in need of future research. We propose that JI is and will continue to be a predominant employment issue, such that research into it will only increase in importance and relevance. In particular, we call for in-depth research that carefully considers the rapid changes in the workplace today and in the future.",
    "doi": "10.1146/annurev-orgpsych-032117-104651",
    "url": "https://openalex.org/W2609656715",
    "pdf_url": "https://www.annualreviews.org/doi/pdf/10.1146/annurev-orgpsych-032117-104651",
    "venue": "Annual Review of Organizational Psychology and Organizational Behavior",
    "citation_count": 356,
    "fields_of_study": [
      "Operationalization",
      "Globe",
      "Conceptualization",
      "Job insecurity",
      "Relevance (law)"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548519"
  },
  {
    "source": "openalex",
    "source_id": "W4385497937",
    "title": "What ChatGPT Tells Us about Gender: A Cautionary Tale about Performativity and Gender Biases in AI",
    "authors": [
      "Nicole Gross"
    ],
    "year": 2023,
    "abstract": "Large language models and generative AI, such as ChatGPT, have gained influence over people\u2019s personal lives and work since their launch, and are expected to scale even further. While the promises of generative artificial intelligence are compelling, this technology harbors significant biases, including those related to gender. Gender biases create patterns of behavior and stereotypes that put women, men and gender-diverse people at a disadvantage. Gender inequalities and injustices affect society as a whole. As a social practice, gendering is achieved through the repeated citation of rituals, expectations and norms. Shared understandings are often captured in scripts, including those emerging in and from generative AI, which means that gendered views and gender biases get grafted back into social, political and economic life. This paper\u2019s central argument is that large language models work performatively, which means that they perpetuate and perhaps even amplify old and non-inclusive understandings of gender. Examples from ChatGPT are used here to illustrate some gender biases in AI. However, this paper also puts forward that AI can work to mitigate biases and act to \u2018undo gender\u2019.",
    "doi": "10.3390/socsci12080435",
    "url": "https://openalex.org/W4385497937",
    "pdf_url": "https://www.mdpi.com/2076-0760/12/8/435/pdf?version=1690954844",
    "venue": "Social Sciences",
    "citation_count": 130,
    "fields_of_study": [
      "Performativity",
      "Generative grammar",
      "Argument (complex analysis)",
      "Disadvantage",
      "Sociology"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548534"
  },
  {
    "source": "openalex",
    "source_id": "W4386973901",
    "title": "Large AI Models in Health Informatics: Applications, Challenges, and the Future",
    "authors": [
      "Jianing Qiu",
      "Lin Li",
      "Jiankai Sun",
      "Jiachuan Peng",
      "Peilun Shi",
      "Ruiyang Zhang",
      "Yinzhao Dong",
      "Kyle Lam",
      "Frank P.-W. Lo",
      "Bo Xiao",
      "Wu Yuan",
      "Ningli Wang",
      "Dong Xu",
      "Benny Lo"
    ],
    "year": 2023,
    "abstract": "Large AI models, or foundation models, are models recently emerging with massive scales both parameter-wise and data-wise, the magnitudes of which can reach beyond billions. Once pretrained, large AI models demonstrate impressive performance in various downstream tasks. A prime example is ChatGPT, whose capability has compelled people's imagination about the far-reaching influence that large AI models can have and their potential to transform different domains of our lives. In health informatics, the advent of large AI models has brought new paradigms for the design of methodologies. The scale of multi-modal data in the biomedical and health domain has been ever-expanding especially since the community embraced the era of deep learning, which provides the ground to develop, validate, and advance large AI models for breakthroughs in health-related areas. This article presents a comprehensive review of large AI models, from background to their applications. We identify seven key sectors in which large AI models are applicable and might have substantial influence, including: 1) bioinformatics; 2) medical diagnosis; 3) medical imaging; 4) medical informatics; 5) medical education; 6) public health; and 7) medical robotics. We examine their challenges, followed by a critical discussion about potential future directions and pitfalls of large AI models in transforming the field of health informatics.",
    "doi": "10.1109/jbhi.2023.3316750",
    "url": "https://openalex.org/W4386973901",
    "pdf_url": "https://ieeexplore.ieee.org/ielx7/6221020/6363502/10261199.pdf",
    "venue": "IEEE Journal of Biomedical and Health Informatics",
    "citation_count": 193,
    "fields_of_study": [
      "Computer science",
      "Health informatics",
      "Informatics",
      "Data science",
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548555"
  },
  {
    "source": "openalex",
    "source_id": "W3090868346",
    "title": "Artificial intelligence in the water domain: Opportunities for responsible use",
    "authors": [
      "Neelke Doorn"
    ],
    "year": 2020,
    "abstract": null,
    "doi": "10.1016/j.scitotenv.2020.142561",
    "url": "https://openalex.org/W3090868346",
    "pdf_url": "https://ars.els-cdn.com/content/image/1-s2.0-S0048969720360903-ga1_lrg.jpg",
    "venue": "The Science of The Total Environment",
    "citation_count": 118,
    "fields_of_study": [
      "Water sector",
      "Domain (mathematical analysis)",
      "Data science",
      "Citizen journalism",
      "Management science"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548576"
  },
  {
    "source": "openalex",
    "source_id": "W3005369330",
    "title": "Toward an Understanding of Responsible Artificial Intelligence Practices",
    "authors": [
      "Yichuan Wang",
      "Mengran Xiong",
      "Hossein Olya"
    ],
    "year": 2020,
    "abstract": "Artificial Intelligence (AI) is influencing all aspects of human and business activities nowadays. Although potential benefits emerged from AI technologies have been widely discussed in many current literature, there is an urgently need to understand how AI can be designed to operate responsibly and act in a manner meeting stakeholders\u2019 expectations and applicable regulations. We seek to fill the gap by exploring the practices of responsible AI and identifying the potential benefits when implementing responsible AI practices. In this study, 10 responsible AI cases were selected from different industries to better understand the use of responsible AI in practices. Four responsible AI practices are identified, including governance, ethically design solutions, risk control and training and education and five strategies for firms who are considering to adopt responsible AI practices are recommended.",
    "doi": "10.24251/hicss.2020.610",
    "url": "https://openalex.org/W3005369330",
    "pdf_url": "http://localhost:4000/bitstreams/b08af779-9e45-45ef-bc0d-1d1d8855364e/download",
    "venue": "Proceedings of the ... Annual Hawaii International Conference on System Sciences/Proceedings of the Annual Hawaii International Conference on System Sciences",
    "citation_count": 128,
    "fields_of_study": [
      "Corporate governance",
      "Applications of artificial intelligence",
      "Knowledge management",
      "Best practice",
      "Control (management)"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548580"
  },
  {
    "source": "openalex",
    "source_id": "W4283157303",
    "title": "Predictability and Surprise in Large Generative Models",
    "authors": [
      "Deep Ganguli",
      "Danny Hernandez",
      "Liane Lovitt",
      "Amanda Askell",
      "Yuntao Bai",
      "Anna Chen",
      "Tom Conerly",
      "Nova Dassarma",
      "Dawn Drain",
      "Nelson Elhage",
      "Sheer El Showk",
      "Stanislav Fort",
      "Zac Hatfield-Dodds",
      "Tom Henighan",
      "Scott G. Johnston",
      "Andy Jones",
      "Nicholas Joseph",
      "Jackson Kernian",
      "Shauna Kravec",
      "Ben Mann",
      "Neel Nanda",
      "Kamal Ndousse",
      "Catherine Olsson",
      "Daniela Amodei",
      "Tom Brown",
      "Jared Kaplan",
      "Sam McCandlish",
      "Christopher Olah",
      "Dario Amodei",
      "Jack Clark"
    ],
    "year": 2022,
    "abstract": "Large-scale pre-training has recently emerged as a technique for creating capable, general purpose, generative models such as GPT-3, Megatron-Turing NLG, Gopher, and many others. In this paper, we highlight a counterintuitive property of such models and discuss the policy implications of this property. Namely, these generative models have an unusual combination of predictable loss on a broad training distribution (as embodied in their \"scaling laws\"), and unpredictable specific capabilities, inputs, and outputs. We believe that the high-level predictability and appearance of useful capabilities drives rapid development of such models, while the unpredictable qualities make it difficult to anticipate the consequences of model deployment. We go through examples of how this combination can lead to socially harmful behavior with examples from the literature and real world observations, and we also perform two novel experiments to illustrate our point about harms from unpredictability. Furthermore, we analyze how these conflicting properties combine to give model developers various motivations for deploying these models, and challenges that can hinder deployment. We conclude with a list of possible interventions the AI community may take to increase the chance of these models having a beneficial impact. We intend this paper to be useful to policymakers who want to understand and regulate AI systems, technologists who care about the potential policy impact of their work, and academics who want to analyze, critique, and potentially develop large generative models.",
    "doi": "10.1145/3531146.3533229",
    "url": "https://openalex.org/W4283157303",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3531146.3533229",
    "venue": "2022 ACM Conference on Fairness, Accountability, and Transparency",
    "citation_count": 161,
    "fields_of_study": [
      "Counterintuitive",
      "Computer science",
      "Predictability",
      "Generative grammar",
      "Surprise"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548597"
  },
  {
    "source": "openalex",
    "source_id": "W4391974599",
    "title": "Generative AI for Transformative Healthcare: A Comprehensive Study of Emerging Models, Applications, Case Studies, and Limitations",
    "authors": [
      "Siva Sai",
      "Aanchal Gaur",
      "R Vijay Sai",
      "Vinay Chamola",
      "Mohsen Guizani",
      "Joel J. P. C. Rodrigues"
    ],
    "year": 2024,
    "abstract": "Generative artificial intelligence (GAI) can be broadly described as an artificial intelligence system capable of generating images, text, and other media types with human prompts. GAI models like ChatGPT, DALL-E, and Bard have recently caught the attention of industry and academia equally. GAI applications span various industries like art, gaming, fashion, and healthcare. In healthcare, GAI shows promise in medical research, diagnosis, treatment, and patient care and is already making strides in real-world deployments. There has yet to be any detailed study concerning the applications and scope of GAI in healthcare. Addressing this research gap, we explore several applications, real-world scenarios, and limitations of GAI in healthcare. We examine how GAI models like ChatGPT and DALL-E can be leveraged to aid in the applications of medical imaging, drug discovery, personalized patient treatment, medical simulation and training, clinical trial optimization, mental health support, healthcare operations and research, medical chatbots, human movement simulation, and a few more applications. Along with applications, we cover four real-world healthcare scenarios that employ GAI: visual snow syndrome diagnosis, molecular drug optimization, medical education, and dentistry. We also provide an elaborate discussion on seven healthcare-customized LLMs like Med-PaLM, BioGPT, DeepHealth, etc.,Since GAI is still evolving, it poses challenges like the lack of professional expertise in decision making, risk of patient data privacy, issues in integrating with existing healthcare systems, and the problem of data bias which are elaborated on in this work along with several other challenges. We also put forward multiple directions for future research in GAI for healthcare.",
    "doi": "10.1109/access.2024.3367715",
    "url": "https://openalex.org/W4391974599",
    "pdf_url": "https://ieeexplore.ieee.org/ielx7/6287639/6514899/10440330.pdf",
    "venue": "IEEE Access",
    "citation_count": 175,
    "fields_of_study": [
      "Transformative learning",
      "Generative grammar",
      "Computer science",
      "Health care",
      "Data science"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548626"
  },
  {
    "source": "openalex",
    "source_id": "W4288514369",
    "title": "Recommendations for ethical and responsible use of artificial intelligence in digital agriculture",
    "authors": [
      "Rozita Dara",
      "Seyed Mehdi Hazrati Fard",
      "Jasmin Kaur"
    ],
    "year": 2022,
    "abstract": "Artificial intelligence (AI) applications are an integral and emerging component of digital agriculture. AI can help ensure sustainable production in agriculture by enhancing agricultural operations and decision-making. Recommendations about soil condition and pesticides or automatic devices for milking and apple picking are examples of AI applications in digital agriculture. Although AI offers many benefits in farming, AI systems may raise ethical issues and risks that should be assessed and proactively managed. Poor design and configuration of intelligent systems may impose harm and unintended consequences on digital agriculture. Invasion of farmers' privacy, damaging animal welfare due to robotic technologies, and lack of accountability for issues resulting from the use of AI tools are only some examples of ethical challenges in digital agriculture. This paper examines the ethical challenges of the use of AI in agriculture in six categories including fairness, transparency, accountability, sustainability, privacy, and robustness. This study further provides recommendations for agriculture technology providers (ATPs) and policymakers on how to proactively mitigate ethical issues that may arise from the use of AI in farming. These recommendations cover a wide range of ethical considerations, such as addressing farmers' privacy concerns, ensuring reliable AI performance, enhancing sustainability in AI systems, and reducing AI bias.",
    "doi": "10.3389/frai.2022.884192",
    "url": "https://openalex.org/W4288514369",
    "pdf_url": "https://www.frontiersin.org/articles/10.3389/frai.2022.884192/pdf",
    "venue": "Frontiers in Artificial Intelligence",
    "citation_count": 119,
    "fields_of_study": [
      "Agriculture",
      "Sustainability",
      "Transparency (behavior)",
      "Accountability",
      "Harm"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548648"
  },
  {
    "source": "openalex",
    "source_id": "W3177473168",
    "title": "Emerging Consensus on \u2018Ethical AI\u2019: Human Rights Critique of Stakeholder Guidelines",
    "authors": [
      "Sakiko Fukuda\u2010Parr",
      "Elizabeth Gibbons"
    ],
    "year": 2021,
    "abstract": "Abstract Voluntary guidelines on \u2018ethical practices\u2019 have been the response by stakeholders to address the growing concern over harmful social consequences of artificial intelligence and digital technologies. Issued by dozens of actors from industry, government and professional associations, the guidelines are creating a consensus on core standards and principles for ethical design, development and deployment of artificial intelligence (AI). Using human rights principles (equality, participation and accountability) and attention to the right to privacy, this paper reviews 15 guidelines preselected to be strongest on human rights, and on global health. We find about half of these ground their guidelines in international human rights law and incorporate the key principles; even these could go further, especially in suggesting ways to operationalize them. Those that adopt the ethics framework are particularly weak in laying out standards for accountability, often focusing on \u2018transparency\u2019, and remaining silent on enforceability and participation which would effectively protect the social good. These guidelines mention human rights as a rhetorical device to obscure the absence of enforceable standards and accountability measures, and give their attention to the single right to privacy. These \u2018ethics\u2019 guidelines, disproportionately from corporations and other interest groups, are also weak on addressing inequalities and discrimination. We argue that voluntary guidelines are creating a set of de facto norms and re\u2010interpretation of the term \u2018human rights\u2019 for what would be considered \u2018ethical\u2019 practice in the field. This exposes an urgent need for action by governments and civil society to develop more rigorous standards and regulatory measures, grounded in international human rights frameworks, capable of holding Big Tech and other powerful actors to account.",
    "doi": "10.1111/1758-5899.12965",
    "url": "https://openalex.org/W3177473168",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/1758-5899.12965",
    "venue": "Global Policy",
    "citation_count": 106,
    "fields_of_study": [
      "Accountability",
      "Human rights",
      "Public relations",
      "Political science",
      "Operationalization"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548667"
  },
  {
    "source": "openalex",
    "source_id": "W3148438775",
    "title": "A Review on Explainability in Multimodal Deep Neural Nets",
    "authors": [
      "Gargi Joshi",
      "Rahee Walambe",
      "Ketan Kotecha"
    ],
    "year": 2021,
    "abstract": "Artificial Intelligence techniques powered by deep neural nets have achieved much success in several application domains, most significantly and notably in the Computer Vision applications and Natural Language Processing tasks. Surpassing human-level performance propelled the research in the applications where different modalities amongst language, vision, sensory, text play an important role in accurate predictions and identification. Several multimodal fusion methods employing deep learning models are proposed in the literature. Despite their outstanding performance, the complex, opaque and black-box nature of the deep neural nets limits their social acceptance and usability. This has given rise to the quest for model interpretability and explainability, more so in the complex tasks involving multimodal AI methods. This paper extensively reviews the present literature to present a comprehensive survey and commentary on the explainability in multimodal deep neural nets, especially for the vision and language tasks. Several topics on multimodal AI and its applications for generic domains have been covered in this paper, including the significance, datasets, fundamental building blocks of the methods and techniques, challenges, applications, and future trends in this domain",
    "doi": "10.1109/access.2021.3070212",
    "url": "https://openalex.org/W3148438775",
    "pdf_url": "https://ieeexplore.ieee.org/ielx7/6287639/9312710/09391727.pdf",
    "venue": "IEEE Access",
    "citation_count": 181,
    "fields_of_study": [
      "Computer science",
      "Artificial neural network",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548691"
  },
  {
    "source": "openalex",
    "source_id": "W4225323865",
    "title": "Interpretability and fairness evaluation of deep learning models on MIMIC-IV dataset",
    "authors": [
      "Chuizheng Meng",
      "Loc Trinh",
      "Nan Xu",
      "James Enouen",
      "Yan Liu"
    ],
    "year": 2022,
    "abstract": "Abstract The recent release of large-scale healthcare datasets has greatly propelled the research of data-driven deep learning models for healthcare applications. However, due to the nature of such deep black-boxed models, concerns about interpretability, fairness, and biases in healthcare scenarios where human lives are at stake call for a careful and thorough examination of both datasets and models. In this work, we focus on MIMIC-IV (Medical Information Mart for Intensive Care, version IV), the largest publicly available healthcare dataset, and conduct comprehensive analyses of interpretability as well as dataset representation bias and prediction fairness of deep learning models for in-hospital mortality prediction. First, we analyze the interpretability of deep learning mortality prediction models and observe that (1) the best-performing interpretability method successfully identifies critical features for mortality prediction on various prediction models as well as recognizing new important features that domain knowledge does not consider; (2) prediction models rely on demographic features, raising concerns in fairness. Therefore, we then evaluate the fairness of models and do observe the unfairness: (1) there exists disparate treatment in prescribing mechanical ventilation among patient groups across ethnicity, gender and age; (2) models often rely on racial attributes unequally across subgroups to generate their predictions. We further draw concrete connections between interpretability methods and fairness metrics by showing how feature importance from interpretability methods can be beneficial in quantifying potential disparities in mortality predictors. Our analysis demonstrates that the prediction performance is not the only factor to consider when evaluating models for healthcare applications, since high prediction performance might be the result of unfair utilization of demographic features. Our findings suggest that future research in AI models for healthcare applications can benefit from utilizing the analysis workflow of interpretability and fairness as well as verifying if models achieve superior performance at the cost of introducing bias.",
    "doi": "10.1038/s41598-022-11012-2",
    "url": "https://openalex.org/W4225323865",
    "pdf_url": "https://www.nature.com/articles/s41598-022-11012-2.pdf",
    "venue": "Scientific Reports",
    "citation_count": 159,
    "fields_of_study": [
      "Interpretability",
      "Computer science",
      "Machine learning",
      "Artificial intelligence",
      "Deep learning"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548709"
  },
  {
    "source": "openalex",
    "source_id": "W3024478970",
    "title": "Artificial Intelligence and Health Technology Assessment: Anticipating a New Level of Complexity",
    "authors": [
      "Hassane Alami",
      "Pascale Lehoux",
      "Yannick Auclair",
      "Mich\u00e8le de Guise",
      "Marie\u2010Pierre Gagnon",
      "James Shaw",
      "Denis Roy",
      "Richard Fleet",
      "Mohamed Ali Ag Ahmed",
      "Jean\u2010Paul Fortin"
    ],
    "year": 2020,
    "abstract": "Artificial intelligence (AI) is seen as a strategic lever to improve access, quality, and efficiency of care and services and to build learning and value-based health systems. Many studies have examined the technical performance of AI within an experimental context. These studies provide limited insights into the issues that its use in a real-world context of care and services raises. To help decision makers address these issues in a systemic and holistic manner, this viewpoint paper relies on the health technology assessment core model to contrast the expectations of the health sector toward the use of AI with the risks that should be mitigated for its responsible deployment. The analysis adopts the perspective of payers (ie, health system organizations and agencies) because of their central role in regulating, financing, and reimbursing novel technologies. This paper suggests that AI-based systems should be seen as a health system transformation lever, rather than a discrete set of technological devices. Their use could bring significant changes and impacts at several levels: technological, clinical, human and cognitive (patient and clinician), professional and organizational, economic, legal, and ethical. The assessment of AI\u2019s value proposition should thus go beyond technical performance and cost logic by performing a holistic analysis of its value in a real-world context of care and services. To guide AI development, generate knowledge, and draw lessons that can be translated into action, the right political, regulatory, organizational, clinical, and technological conditions for innovation should be created as a first step.",
    "doi": "10.2196/17707",
    "url": "https://openalex.org/W3024478970",
    "pdf_url": "https://www.jmir.org/2020/7/e17707/PDF",
    "venue": "Journal of Medical Internet Research",
    "citation_count": 146,
    "fields_of_study": [
      "Value proposition",
      "Context (archaeology)",
      "Knowledge management",
      "Health care",
      "Software deployment"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548738"
  },
  {
    "source": "openalex",
    "source_id": "W4393170828",
    "title": "Privacy and Security Concerns in Generative AI: A Comprehensive Survey",
    "authors": [
      "Abenezer Golda",
      "Kidus Abebe Mekonen",
      "Amit Pandey",
      "Anushka Singh",
      "Vikas Hassija",
      "Vinay Chamola",
      "Biplab Sikdar"
    ],
    "year": 2024,
    "abstract": "Generative Artificial Intelligence (GAI) has sparked a transformative wave across various domains, including machine learning, healthcare, business, and entertainment, owing to its remarkable ability to generate lifelike data. This comprehensive survey offers a meticulous examination of the privacy and security challenges inherent to GAI. It provides five pivotal perspectives essential for a comprehensive understanding of these intricacies. The paper encompasses discussions on GAI architectures, diverse generative model types, practical applications, and recent advancements within the field. In addition, it highlights current security strategies and proposes sustainable solutions, emphasizing user, developer, institutional, and policymaker involvement.",
    "doi": "10.1109/access.2024.3381611",
    "url": "https://openalex.org/W4393170828",
    "pdf_url": "https://ieeexplore.ieee.org/ielx7/6287639/6514899/10478883.pdf",
    "venue": "IEEE Access",
    "citation_count": 161,
    "fields_of_study": [
      "Computer science",
      "Computer security",
      "Internet privacy",
      "Information privacy",
      "Data science"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548762"
  },
  {
    "source": "openalex",
    "source_id": "W4385732922",
    "title": "Survey on Explainable AI: From Approaches, Limitations and Applications Aspects",
    "authors": [
      "Wenli Yang",
      "Yu-Chen Wei",
      "H. Wei",
      "Yanyu Chen",
      "Guan Huang",
      "Xiang Li",
      "Renjie Li",
      "Naimeng Yao",
      "Xinyi Wang",
      "Xiaotong Gu",
      "Muhammad Bilal Amin",
      "Byeong Ho Kang"
    ],
    "year": 2023,
    "abstract": null,
    "doi": "10.1007/s44230-023-00038-y",
    "url": "https://openalex.org/W4385732922",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s44230-023-00038-y.pdf",
    "venue": "Human-Centric Intelligent Systems",
    "citation_count": 160,
    "fields_of_study": [
      "Transparency (behavior)",
      "Computer science",
      "Process (computing)",
      "Data science",
      "Key (lock)"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548776"
  },
  {
    "source": "openalex",
    "source_id": "W3204423820",
    "title": "FairFed: Enabling Group Fairness in Federated Learning",
    "authors": [
      "Yahya H. Ezzeldin",
      "Shen Yan",
      "Chaoyang He",
      "Emilio Ferrara",
      "A. Salman Avestimehr"
    ],
    "year": 2023,
    "abstract": "Training ML models which are fair across different demographic groups is of critical importance due to the increased integration of ML in crucial decision-making scenarios such as healthcare and recruitment. Federated learning has been viewed as a promising solution for collaboratively training machine learning models among multiple parties while maintaining their local data privacy. However, federated learning also poses new challenges in mitigating the potential bias against certain populations (e.g., demographic groups), as this typically requires centralized access to the sensitive information (e.g., race, gender) of each datapoint. Motivated by the importance and challenges of group fairness in federated learning, in this work, we propose FairFed, a novel algorithm for fairness-aware aggregation to enhance group fairness in federated learning. Our proposed approach is server-side and agnostic to the applied local debiasing thus allowing for flexible use of different local debiasing methods across clients. We evaluate FairFed empirically versus common baselines for fair ML and federated learning and demonstrate that it provides fairer models, particularly under highly heterogeneous data distributions across clients. We also demonstrate the benefits of FairFed in scenarios involving naturally distributed real-life data collected from different geographical locations or departments within an organization.",
    "doi": "10.1609/aaai.v37i6.25911",
    "url": "https://openalex.org/W3204423820",
    "pdf_url": "https://ojs.aaai.org/index.php/AAAI/article/download/25911/25683",
    "venue": "Proceedings of the AAAI Conference on Artificial Intelligence",
    "citation_count": 147,
    "fields_of_study": [
      "Debiasing",
      "Federated learning",
      "Computer science",
      "Work (physics)",
      "Machine learning"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548780"
  },
  {
    "source": "openalex",
    "source_id": "W4297540759",
    "title": "Collaboration among recruiters and artificial intelligence: removing human prejudices in employment",
    "authors": [
      "Zhisheng Chen"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1007/s10111-022-00716-0",
    "url": "https://openalex.org/W4297540759",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10111-022-00716-0.pdf",
    "venue": "Cognition Technology & Work",
    "citation_count": 120,
    "fields_of_study": [
      "Interview",
      "Promotion (chess)",
      "Process (computing)",
      "Stakeholder",
      "Perception"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548799"
  },
  {
    "source": "openalex",
    "source_id": "W4397008103",
    "title": "The synergistic interplay of artificial intelligence and digital twin in environmentally planning sustainable smart cities: A comprehensive systematic review",
    "authors": [
      "Simon Elias Bibri",
      "Jeffrey Huang",
      "Senthil Kumar Jagatheesaperumal",
      "John Krogstie"
    ],
    "year": 2024,
    "abstract": "The dynamic landscape of sustainable smart cities is witnessing a significant transformation due to the integration of emerging computational technologies and innovative models. These advancements are reshaping data-driven planning strategies, practices, and approaches, thereby facilitating the achievement of environmental sustainability goals. This transformative wave signals a fundamental shift - marked by the synergistic operation of artificial intelligence (AI), artificial intelligence of things (AIoT), and urban digital twin (UDT) technologies. While previous research has largely explored urban AI, urban AIoT, and UDT in isolation, a significant knowledge gap exists regarding their synergistic interplay, collaborative integration, and collective impact on data-driven environmental planning in the dynamic context of sustainable smart cities. To address this gap, this study conducts a comprehensive systematic review to uncover the intricate interactions among these interconnected technologies, models, and domains while elucidating the nuanced dynamics and untapped synergies in the complex ecosystem of sustainable smart cities. Central to this study are four guiding research questions: 1. What theoretical and practical foundations underpin the convergence of AI, AIoT, UDT, data-driven planning, and environmental sustainability in sustainable smart cities, and how can these components be synthesized into a novel comprehensive framework? 2. How does integrating AI and AIoT reshape the landscape of data-driven planning to improve the environmental performance of sustainable smart cities? 3. How can AI and AIoT augment the capabilities of UDT to enhance data-driven environmental planning processes in sustainable smart cities? 4. What challenges and barriers arise in integrating and implementing AI, AIoT, and UDT in data-driven environmental urban planning, and what strategies can be devised to surmount or mitigate them? Methodologically, this study involves a rigorous analysis and synthesis of studies published between January 2019 and December 2023, comprising an extensive body of literature totaling 185 studies. The findings of this study surpass mere interdisciplinary theoretical enrichment, offering valuable insights into the transformative potential of integrating AI, AIoT, and UDT technologies to advance sustainable urban development practices. By enhancing data-driven environmental planning processes, these integrated technologies and models offer innovative solutions to address complex environmental challenges. However, this endeavor is fraught with formidable challenges and complexities that require careful navigation and mitigation to achieve desired outcomes. This study serves as a comprehensive reference guide, spurring groundbreaking research endeavors, stimulating practical implementations, informing strategic initiatives, and shaping policy formulations in sustainable urban development. These insights have profound implications for researchers, practitioners, and policymakers, providing a roadmap for fostering resiliently designed, technologically advanced, and environmentally conscious urban environments.",
    "doi": "10.1016/j.ese.2024.100433",
    "url": "https://openalex.org/W4397008103",
    "pdf_url": "https://ars.els-cdn.com/content/image/1-s2.0-S2666498424000474-ga1_lrg.jpg",
    "venue": "Environmental Science and Ecotechnology",
    "citation_count": 149,
    "fields_of_study": [
      "Sustainability",
      "Transformative learning",
      "Context (archaeology)",
      "Smart city",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548803"
  },
  {
    "source": "openalex",
    "source_id": "W3134214835",
    "title": "Algorithmic Impact Assessments and Accountability",
    "authors": [
      "Jacob Metcalf",
      "Emanuel Moss",
      "Elizabeth Anne Watkins",
      "Ranjit Singh",
      "Madeleine Clare Elish"
    ],
    "year": 2021,
    "abstract": "Algorithmic impact assessments (AIAs) are an emergent form of accountability for organizations that build and deploy automated decision-support systems. They are modeled after impact assessments in other domains. Our study of the history of impact assessments shows that \"impacts\" are an evaluative construct that enable actors to identify and ameliorate harms experienced because of a policy decision or system. Every domain has different expectations and norms around what constitutes impacts and harms, how potential harms are rendered as impacts of a particular undertaking, who is responsible for conducting such assessments, and who has the authority to act on them to demand changes to that undertaking. By examining proposals for AIAs in relation to other domains, we find that there is a distinct risk of constructing algorithmic impacts as organizationally understandable metrics that are nonetheless inappropriately distant from the harms experienced by people, and which fall short of building the relationships required for effective accountability. As impact assessments become a commonplace process for evaluating harms, the FAccT community, in its efforts to address this challenge, should A) understand impacts as objects that are co-constructed accountability relationships, B) attempt to construct impacts as close as possible to actual harms, and C) recognize that accountability governance requires the input of various types of expertise and affected communities. We conclude with lessons for assembling cross-expertise consensus for the co-construction of impacts and building robust accountability relationships.",
    "doi": "10.1145/3442188.3445935",
    "url": "https://openalex.org/W3134214835",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3442188.3445935",
    "venue": null,
    "citation_count": 137,
    "fields_of_study": [
      "Accountability",
      "Construct (python library)",
      "Process (computing)",
      "Corporate governance",
      "Risk analysis (engineering)"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548841"
  },
  {
    "source": "openalex",
    "source_id": "W4390056019",
    "title": "Advancing nursing practice with artificial intelligence: Enhancing preparedness for the future",
    "authors": [
      "Moustaq Karim Khan Rony",
      "Mst. Rina Parvin",
      "Silvia Ferdousi"
    ],
    "year": 2023,
    "abstract": "Abstract Aim This article aimed to explore the role of AI in advancing nursing practice, focusing on its impact on readiness for the future. Design and Methods A position paper, the methodology comprises three key steps. First, a comprehensive literature search using specific keywords in reputable databases was conducted to gather current information on AI in nursing. Second, data extraction and synthesis from selected articles were performed. Finally, a thematic analysis identifies recurring themes to provide insights into AI's impact on future nursing practice. Results The findings highlight the transformative role of AI in advancing nursing practice and preparing nurses for the future, including enhancing nursing practice with AI, preparing nurses for the future (AI education and training) and associated, ethical considerations and challenges. AI\u2010enabled robotics and telehealth solutions expand the reach of nursing care, improving accessibility of healthcare services and remote monitoring capabilities of patients' health conditions.",
    "doi": "10.1002/nop2.2070",
    "url": "https://openalex.org/W4390056019",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/nop2.2070",
    "venue": "Nursing Open",
    "citation_count": 145,
    "fields_of_study": [
      "Transformative learning",
      "Preparedness",
      "Nursing",
      "Thematic analysis",
      "Nursing practice"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548863"
  },
  {
    "source": "openalex",
    "source_id": "W4281728823",
    "title": "MACHINE LEARNING FOR INTELLIGENT ENERGY CONSUMPTION IN SMART HOMES",
    "authors": [
      "Asem S. Al\u2010Zoubi"
    ],
    "year": 2022,
    "abstract": "The growth of personal pleasure is a direct result of a person's ability to provide themselves with energy. Since people may construct and enhance their way of life more swiftly with current innovation, valuable energy has become a sought-after expansion for many years due to the utilization of smart houses and structures. The demand for energy is greater than the supply, resulting in a lack of energy. In order to keep up with the demand for energy, new strategies are being developed. Many areas' residential energy use is between 30 and 40 percent. There has been an increase in the need for intelligence in applications like as asset management, energy-efficient automating, safety, and healthcare monitoring as a result of smart homes coming into existence and expanding. Energy consumption optimization is being tackled with the use of an energy management approach in this study. There has been a recent surge in interest in data fusion in the context of building energy efficiency. Accuracy and miss rate of energy consumption predictions were calculated utilizing the data fusion technique presented by the proposed study. Simulated findings are being compared with those of previously reported methods. It also has a prediction accuracy of 92 percent, which is greater than that of any other technique that has been previously reported. It's becoming increasingly important for households to keep their power costs down as the amount of electricity they consume rises and dispersed new energy sources are introduced. The installation of a home energy management system is a practical solution to these issues.",
    "doi": "10.54489/ijcim.v2i1.75",
    "url": "https://openalex.org/W4281728823",
    "pdf_url": "https://journals.gaftim.com/index.php/ijcim/article/download/75/36",
    "venue": "International Journal of Computations Information and Manufacturing (IJCIM)",
    "citation_count": 171,
    "fields_of_study": [
      "Energy consumption",
      "Context (archaeology)",
      "Energy management",
      "Energy (signal processing)",
      "Efficient energy use"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548878"
  },
  {
    "source": "openalex",
    "source_id": "W4310118256",
    "title": "Artificial Intelligence and Sustainable Decisions",
    "authors": [
      "Jingchen Zhao",
      "Beatriz G\u00f3mez Fari\u00f1as"
    ],
    "year": 2022,
    "abstract": "Abstract When addressing corporate sustainability challenges, artificial intelligence (AI) is a double-edged sword. AI can make significant progress on the most complicated environmental and social problems faced by humans. On the other hand, the efficiencies and innovations generated by AI may also bring new risks, such as automated bias and conflicts with human ethics. We argue that companies and governments should make collective efforts to address sustainability challenges and risks brought by AI. Accountable and sustainable AI can be achieved through a proactive regulatory framework supported by rigorous corporate policies and reports. Given the rapidly evolving nature of this technology, we propose a harmonised and risk-based regulatory approach that accommodates diverse AI solutions to achieve the common good. Ensuring an adequate level of technological neutrality and proportionality of the regulation is the key to mitigating the wide range of potential risks inherent to the use of AI. Instead of promoting sustainability, unregulated AI would be a threat since it would not be possible to effectively monitor its effects on the economy, society and environment. Such a suitable regulatory framework would not only create a consensus concerning the risks to avoid and how to do so but also include enforcement mechanisms to ensure a trustworthy and ethical use of AI in the boardroom. Once this objective is achieved, it will be possible to refer to this technological development as a common good in itself that constitutes an essential asset to human development.",
    "doi": "10.1007/s40804-022-00262-2",
    "url": "https://openalex.org/W4310118256",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s40804-022-00262-2.pdf",
    "venue": "European Business Organization Law Review",
    "citation_count": 148,
    "fields_of_study": [
      "Sustainability",
      "Risk analysis (engineering)",
      "Precautionary principle",
      "Business",
      "Sustainable development"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548904"
  },
  {
    "source": "openalex",
    "source_id": "W4309702579",
    "title": "Priorities for successful use of artificial intelligence by public health organizations: a literature review",
    "authors": [
      "Stacey Fisher",
      "Laura C. Rosella"
    ],
    "year": 2022,
    "abstract": "Abstract Artificial intelligence (AI) has the potential to improve public health\u2019s ability to promote the health of all people in all communities. To successfully realize this potential and use AI for public health functions it is important for public health organizations to thoughtfully develop strategies for AI implementation. Six key priorities for successful use of AI technologies by public health organizations are discussed: 1) Contemporary data governance; 2) Investment in modernized data and analytic infrastructure and procedures; 3) Addressing the skills gap in the workforce; 4) Development of strategic collaborative partnerships; 5) Use of good AI practices for transparency and reproducibility, and; 6) Explicit consideration of equity and bias.",
    "doi": "10.1186/s12889-022-14422-z",
    "url": "https://openalex.org/W4309702579",
    "pdf_url": "https://bmcpublichealth.biomedcentral.com/counter/pdf/10.1186/s12889-022-14422-z",
    "venue": "BMC Public Health",
    "citation_count": 130,
    "fields_of_study": [
      "Biostatistics",
      "Medicine",
      "Public health",
      "Epidemiology",
      "Environmental health"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548926"
  },
  {
    "source": "openalex",
    "source_id": "W3182537641",
    "title": "Balancing skills in the digital transformation era: The future of jobs and the role of higher education",
    "authors": [
      "Vera G. Goulart",
      "Lara Bartocci Liboni",
      "Luciana Oranges Cezarino"
    ],
    "year": 2021,
    "abstract": "Developing human resources and matching job profiles are essential tasks to promote economic and social growth. The technology-related job market has undergone significant changes over recent years, mainly due to technological advances that have pushed industry toward new demands for skilled professionals. This change in required skills and competencies has led to a gap between what companies need and the professional profiles that are available in the job market. Technology companies are often unable to find an employee who meets the required profile, resulting in financial loss and extra training expenses. It is therefore essential that higher education in technology is reconsidered to address job market demands. Thus the goal of this work is to evaluate the relationship between the professional profile required by information technology (IT) companies and what students are taught on IT-related programs in higher education institutions (HEIs). The authors adopt a systemic perspective in three different qualitative approaches. They cross-check and link data on educational curricula acquired from interviews with IT human resource managers (HRMs) and student focus groups. The analysis reveals that HEIs must go beyond the transfer of knowledge and technical qualification in IT, promoting a comprehensive education that incorporates personal development goals, with a focus on developing social and emotional skills. The study focuses on the emerging economy of Brazil and presents findings from which other developing countries can learn. The results reveal the critical role of soft skills in the professional development and employability of students and the associated challenge for technical education. In conclusion, the authors also highlight the importance of partnerships between HEIs and HRMs as a fundamental strategy to fulfill the current skills gap.",
    "doi": "10.1177/09504222211029796",
    "url": "https://openalex.org/W3182537641",
    "pdf_url": "http://hdl.handle.net/10278/3742108",
    "venue": "Industry and Higher Education",
    "citation_count": 199,
    "fields_of_study": [
      "Employability",
      "Curriculum",
      "Higher education",
      "Human resources",
      "Business"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548939"
  },
  {
    "source": "openalex",
    "source_id": "W4384920712",
    "title": "Explainable AI for Bioinformatics: Methods, Tools and Applications",
    "authors": [
      "Md. Rezaul Karim",
      "Tanhim Islam",
      "Md Shajalal",
      "Oya Beyan",
      "Christoph Lange",
      "Michael Cochez",
      "Dietrich Rebholz\u2010Schuhmann",
      "Stefan Decker"
    ],
    "year": 2023,
    "abstract": "Abstract Artificial intelligence (AI) systems utilizing deep neural networks and machine learning (ML) algorithms are widely used for solving critical problems in bioinformatics, biomedical informatics and precision medicine. However, complex ML models that are often perceived as opaque and black-box methods make it difficult to understand the reasoning behind their decisions. This lack of transparency can be a challenge for both end-users and decision-makers, as well as AI developers. In sensitive areas such as healthcare, explainability and accountability are not only desirable properties but also legally required for AI systems that can have a significant impact on human lives. Fairness is another growing concern, as algorithmic decisions should not show bias or discrimination towards certain groups or individuals based on sensitive attributes. Explainable AI (XAI) aims to overcome the opaqueness of black-box models and to provide transparency in how AI systems make decisions. Interpretable ML models can explain how they make predictions and identify factors that influence their outcomes. However, the majority of the state-of-the-art interpretable ML methods are domain-agnostic and have evolved from fields such as computer vision, automated reasoning or statistics, making direct application to bioinformatics problems challenging without customization and domain adaptation. In this paper, we discuss the importance of explainability and algorithmic transparency in the context of bioinformatics. We provide an overview of model-specific and model-agnostic interpretable ML methods and tools and outline their potential limitations. We discuss how existing interpretable ML methods can be customized and fit to bioinformatics research problems. Further, through case studies in bioimaging, cancer genomics and text mining, we demonstrate how XAI methods can improve transparency and decision fairness. Our review aims at providing valuable insights and serving as a starting point for researchers wanting to enhance explainability and decision transparency while solving bioinformatics problems. GitHub: https://github.com/rezacsedu/XAI-for-bioinformatics.",
    "doi": "10.1093/bib/bbad236",
    "url": "https://openalex.org/W4384920712",
    "pdf_url": "https://academic.oup.com/bib/advance-article-pdf/doi/10.1093/bib/bbad236/50926106/bbad236.pdf",
    "venue": "Briefings in Bioinformatics",
    "citation_count": 134,
    "fields_of_study": [
      "Transparency (behavior)",
      "Computer science",
      "Artificial intelligence",
      "Context (archaeology)",
      "Domain (mathematical analysis)"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548966"
  },
  {
    "source": "openalex",
    "source_id": "W2903165924",
    "title": "Journalism, media and technology trends and predictions 2018",
    "authors": [
      "Nic Newman",
      "Cherubini, Federica"
    ],
    "year": 2023,
    "abstract": "2019 will be the year when the regulation of platform companies starts to become real following growing concern about misinformation, privacy, and market power. Something once considered unthinkable has become \u2018inevitable\u2019, in the words of Apple boss Tim Cook \u2013 though the details will be messy, hard-fought, and take time to play out. Meanwhile the spread of false, misleading and extreme content will continue to undermine democracies around the world with polarising elections in India, Indonesia and Europe likely flashpoints. Journalism will continue to be hollowed out by structural shifts that have already led to significant falls in advertising revenue. Publishers are looking to subscriptions to make up the difference but the limits of this approach are likely to become apparent in 2019. Taken together these trends are likely to lead to the biggest wave of journalistic lay-offs in years \u2013 weakening further the ability of publishers to hold populist politicians and powerful business leaders to account. This annual trends and predictions report explores key developments in the practice and business of journalism. It explores publishers\u2019 relationships with platforms, the boom in podcasting and voice activated technologies and the potential for Artificial Intelligence in the newsroom.",
    "doi": "10.5287/bodleian:nokoozeep",
    "url": "https://openalex.org/W2903165924",
    "pdf_url": "https://ora.ox.ac.uk/objects/uuid:0cc75001-5e8f-4143-bff7-cbb761a58ad6",
    "venue": "Oxford University Research Archive (ORA) (University of Oxford)",
    "citation_count": 274,
    "fields_of_study": [
      "Journalism",
      "Quality (philosophy)",
      "Computer science",
      "Public relations",
      "Multimedia"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548994"
  },
  {
    "source": "openalex",
    "source_id": "W3198532692",
    "title": "Digital Mental Health for Young People: A Scoping Review of Ethical Promises and Challenges",
    "authors": [
      "Blanche Wies",
      "Constantin Landers",
      "Marcello Ienca"
    ],
    "year": 2021,
    "abstract": "Mental health disorders are complex disorders of the nervous system characterized by a behavioral or mental pattern that causes significant distress or impairment of personal functioning. Mental illness is of particular concern for younger people. The WHO estimates that around 20% of the world's children and adolescents have a mental health condition, a rate that is almost double compared to the general population. One approach toward mitigating the medical and socio-economic effects of mental health disorders is leveraging the power of digital health technology to deploy assistive, preventative, and therapeutic solutions for people in need. We define \u201cdigital mental health\u201d as any application of digital health technology for mental health assessment, support, prevention, and treatment. However, there is only limited evidence that digital mental health tools can be successfully implemented in clinical settings. Authors have pointed to a lack of technical and medical standards for digital mental health apps, personalized neurotechnology, and assistive cognitive technology as a possible cause of suboptimal adoption and implementation in the clinical setting. Further, ethical concerns have been raised related to insufficient effectiveness, lack of adequate clinical validation, and user-centered design as well as data privacy vulnerabilities of current digital mental health products. The aim of this paper is to report on a scoping review we conducted to capture and synthesize the growing literature on the promises and ethical challenges of digital mental health for young people aged 0\u201325. This review seeks to survey the scope and focus of the relevant literature, identify major benefits and opportunities of ethical significance (e.g., reducing suffering and improving well-being), and provide a comprehensive mapping of the emerging ethical challenges. Our findings provide a comprehensive synthesis of the current literature and offer a detailed informative basis for any stakeholder involved in the development, deployment, and management of ethically-aligned digital mental health solutions for young people.",
    "doi": "10.3389/fdgth.2021.697072",
    "url": "https://openalex.org/W3198532692",
    "pdf_url": "https://www.frontiersin.org/articles/10.3389/fdgth.2021.697072/pdf",
    "venue": "Frontiers in Digital Health",
    "citation_count": 216,
    "fields_of_study": [
      "Mental health",
      "Digital health",
      "Scope (computer science)",
      "Psychology",
      "Mental illness"
    ],
    "retrieved_at": "2026-02-02T16:58:12.549015"
  },
  {
    "source": "openalex",
    "source_id": "W4400118952",
    "title": "When large language models meet personalization: perspectives of challenges and opportunities",
    "authors": [
      "Jing Chen",
      "Zheng Liu",
      "Xu Huang",
      "Chenwang Wu",
      "Qi Liu",
      "Gangwei Jiang",
      "Yuanhao Pu",
      "Yuxuan Lei",
      "Xiaolong Chen",
      "Xingmei Wang",
      "Kai Zheng",
      "Defu Lian",
      "Enhong Chen"
    ],
    "year": 2024,
    "abstract": "Abstract The advent of large language models marks a revolutionary breakthrough in artificial intelligence. With the unprecedented scale of training and model parameters, the capability of large language models has been dramatically improved, leading to human-like performances in understanding, language synthesizing, common-sense reasoning, etc. Such a major leap forward in general AI capacity will fundamentally change the pattern of how personalization is conducted. For one thing, it will reform the way of interaction between humans and personalization systems. Instead of being a passive medium of information filtering, like conventional recommender systems and search engines, large language models present the foundation for active user engagement. On top of such a new foundation, users\u2019 requests can be proactively explored, and users\u2019 required information can be delivered in a natural, interactable, and explainable way. For another thing, it will also considerably expand the scope of personalization, making it grow from the sole function of collecting personalized information to the compound function of providing personalized services. By leveraging large language models as a general-purpose interface, the personalization systems may compile user\u2019s requests into plans, calls the functions of external tools (e.g., search engines, calculators, service APIs, etc.) to execute the plans, and integrate the tools\u2019 outputs to complete the end-to-end personalization tasks. Today, large language models are still being rapidly developed, whereas the application in personalization is largely unexplored. Therefore, we consider it to be right the time to review the challenges in personalization and the opportunities to address them with large language models. In particular, we dedicate this perspective paper to the discussion of the following aspects: the development and challenges for the existing personalization system, the newly emerged capabilities of large language models, and the potential ways of making use of large language models for personalization.",
    "doi": "10.1007/s11280-024-01276-1",
    "url": "https://openalex.org/W4400118952",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s11280-024-01276-1.pdf",
    "venue": "World Wide Web",
    "citation_count": 226,
    "fields_of_study": [
      "Personalization",
      "Computer science",
      "Function (biology)",
      "Scope (computer science)",
      "Language model"
    ],
    "retrieved_at": "2026-02-02T16:58:12.549046"
  },
  {
    "source": "openalex",
    "source_id": "W4392052182",
    "title": "AI-Powered Innovation in Digital Transformation: Key Pillars and Industry Impact",
    "authors": [
      "Abdulaziz Aldoseri",
      "Khalifa N. Al\u2010Khalifa",
      "A.M.S. Hamouda"
    ],
    "year": 2024,
    "abstract": "Digital transformation systems generate a substantial volume of data, creating opportunities for potential innovation, particularly those driven by artificial intelligence. This study focuses on the intricate relationship between artificial intelligence and innovation as foundational elements in the digital transformation framework for sustained growth and operational excellence. This study provides a holistic perspective on the cultivation and pillars of AI-powered innovation, highlighting their pivotal role in revolutionizing industries, including healthcare, education, finance, manufacturing, transportation, and agriculture. The work emphasizes the key pillars essential for fostering AI-powered innovation, including monitoring performance measurement to use the power of the present, continuous learning and innovation, data analytics and insights, predictive analytics, and innovative product development. This study investigates how these pillars serve as the foundation for groundbreaking advancements, driving efficiency, enhancing decision-making processes, and fostering creativity within organizations. This study explores the significance of continuous learning, interdisciplinary collaboration, and industry partnerships in nurturing a thriving AI-powered innovation ecosystem. By understanding and harnessing these fundamental elements, businesses can navigate the complexities of the digital age, fostering innovation that not only optimizes processes but also enhances the overall human experience, ushering in a new era of technological excellence and societal progress.",
    "doi": "10.3390/su16051790",
    "url": "https://openalex.org/W4392052182",
    "pdf_url": "https://www.mdpi.com/2071-1050/16/5/1790/pdf?version=1708581624",
    "venue": "Sustainability",
    "citation_count": 168,
    "fields_of_study": [
      "Key (lock)",
      "Digital transformation",
      "Transformation (genetics)",
      "Manufacturing engineering",
      "Business"
    ],
    "retrieved_at": "2026-02-02T16:58:12.549073"
  },
  {
    "source": "openalex",
    "source_id": "W4285740054",
    "title": "You Can\u2019t Have AI Both Ways: Balancing Health Data Privacy and Access Fairly",
    "authors": [
      "Marieke Bak",
      "Vince I. Madai",
      "Marie-Christine Fritzsche",
      "Michaela Th. Mayrhofer",
      "Stuart McLennan"
    ],
    "year": 2022,
    "abstract": "Artificial intelligence (AI) in healthcare promises to make healthcare safer, more accurate, and more cost-effective. Public and private actors have been investing significant amounts of resources into the field. However, to benefit from data-intensive medicine, particularly from AI technologies, one must first and foremost have access to data. It has been previously argued that the conventionally used \u201cconsent or anonymize approach\u201d undermines data-intensive medicine, and worse, may ultimately harm patients. Yet, this is still a dominant approach in European countries and framed as an either-or choice. In this paper, we contrast the different data governance approaches in the EU and their advantages and disadvantages in the context of healthcare AI. We detail the ethical trade-offs inherent to data-intensive medicine, particularly the balancing of data privacy and data access, and the subsequent prioritization between AI and other effective health interventions. If countries wish to allocate resources to AI, they also need to make corresponding efforts to improve (secure) data access. We conclude that it is unethical to invest significant amounts of public funds into AI development whilst at the same time limiting data access through strict privacy measures, as this constitutes a waste of public resources. The \u201cAI revolution\u201d in healthcare can only realise its full potential if a fair, inclusive engagement process spells out the values underlying (trans) national data governance policies and their impact on AI development, and priorities are set accordingly.",
    "doi": "10.3389/fgene.2022.929453",
    "url": "https://openalex.org/W4285740054",
    "pdf_url": "https://www.frontiersin.org/articles/10.3389/fgene.2022.929453/pdf",
    "venue": "Frontiers in Genetics",
    "citation_count": 103,
    "fields_of_study": [
      "Context (archaeology)",
      "Data governance",
      "Harm",
      "Health care",
      "Internet privacy"
    ],
    "retrieved_at": "2026-02-02T16:58:12.549095"
  },
  {
    "source": "openalex",
    "source_id": "W3001754608",
    "title": "Toward situated interventions for algorithmic equity",
    "authors": [
      "Michael Katell",
      "Meg Young",
      "Dharma Dailey",
      "Bernease Herman",
      "Vivian Guetler",
      "Aaron Tam",
      "Corinne Bintz",
      "Daniella Raz",
      "P. M. Krafft"
    ],
    "year": 2020,
    "abstract": "Research to date aimed at the fairness, accountability, and transparency of algorithmic systems has largely focused on topics such as identifying failures of current systems and on technical interventions intended to reduce bias in computational processes. Researchers have given less attention to methods that account for the social and political contexts of specific, situated technical systems at their points of use. Co-developing algorithmic accountability interventions in communities supports outcomes that are more likely to address problems in their situated context and re-center power with those most disparately affected by the harms of algorithmic systems. In this paper we report on our experiences using participatory and co-design methods for algorithmic accountability in a project called the Algorithmic Equity Toolkit. The main insights we gleaned from our experiences were: (i) many meaningful interventions toward equitable algorithmic systems are non-technical; (ii) community organizations derive the most value from localized materials as opposed to what is \"scalable\" beyond a particular policy context; (iii) framing harms around algorithmic bias suggests that more accurate data is the solution, at the risk of missing deeper questions about whether some technologies should be used at all. More broadly, we found that community-based methods are important inroads to addressing algorithmic harms in their situated contexts.",
    "doi": "10.1145/3351095.3372874",
    "url": "https://openalex.org/W3001754608",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3351095.3372874",
    "venue": null,
    "citation_count": 132,
    "fields_of_study": [
      "Situated",
      "Accountability",
      "Computer science",
      "Equity (law)",
      "Framing (construction)"
    ],
    "retrieved_at": "2026-02-02T16:58:12.549118"
  },
  {
    "source": "openalex",
    "source_id": "W4390315357",
    "title": "The Robots Are Here: Navigating the Generative AI Revolution in Computing Education",
    "authors": [
      "James Prather",
      "Paul Denny",
      "Juho Leinonen",
      "Brett A. Becker",
      "Ibrahim Albluwi",
      "Michelle Craig",
      "Hieke Keuning",
      "Natalie Kiesler",
      "Tobias Kohn",
      "Andrew Luxton-Reilly",
      "Stephen MacNeil",
      "Andrew Petersen",
      "Raymond Pettit",
      "Brent N. Reeves",
      "Jarom\u00edr \u0160avelka"
    ],
    "year": 2023,
    "abstract": "Recent advancements in artificial intelligence (AI) and specifically generative AI (GenAI) are threatening to fundamentally reshape computing and society. Largely driven by large language models (LLMs), many tools are now able to interpret and generate both natural language instructions and source code. These capabilities have sparked urgent questions in the computing education community around how educators should adapt their pedagogy to address the challenges and to leverage the opportunities presented by this new technology. In this working group report, we undertake a comprehensive exploration of generative AI in the context of computing education and make five significant contributions. First, we provide a detailed review of the literature on LLMs in computing education and synthesise findings from 71 primary articles, nearly 80% of which have been published in the first 8 months of 2023. Second, we report the findings of a survey of computing students and instructors from across 20 countries, capturing prevailing attitudes towards GenAI/LLMs and their use in computing education contexts. Third, to understand how pedagogy is already changing, we offer insights collected from in-depth interviews with 22 computing educators from five continents. Fourth, we use the ACM Code of Ethics to frame a discussion of ethical issues raised by the use of large language models in computing education, and we provide concrete advice for policy makers, educators, and students. Finally, we benchmark the performance of several current GenAI models/tools on various computing education datasets, and highlight the extent to which the capabilities of current models are rapidly improving.",
    "doi": "10.1145/3623762.3633499",
    "url": "https://openalex.org/W4390315357",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3623762.3633499",
    "venue": null,
    "citation_count": 260,
    "fields_of_study": [
      "Computer science",
      "Leverage (statistics)",
      "Context (archaeology)",
      "Generative grammar",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:12.549138"
  },
  {
    "source": "openalex",
    "source_id": "W2982867001",
    "title": "A multi-dimensional approach to disinformation: Report of the independent High level Group on fake news and online disinformation",
    "authors": [
      "Madeleine de Cock Buning"
    ],
    "year": 2018,
    "abstract": "In January 2018, the European Commission set up a highlevel group of experts (\u00abthe HLEG\u00bb) to advise on policy initiatives to counter fake news and disinformation spread online. The HLEG consisted of 39 members and was chaired by Prof. Dr. Madeleine de Cock Buning. Its members had different backgrounds, including academia and journalism, written press and broadcasting organizations, online platforms as well as civil society and fact-checking organizations. The HLEG\u2019s tasks were to advise the Commission on all issues arising in the context of false information spread across traditional and social media and on possible ways to cope with its social and political consequences. The main deliverable of the HLEG was a report designed to review best practices in the light of fundamental principles, and suitable responses stemming from such principles. The analysis presented in this Report starts from a shared understanding of disinformation as a phenomenon that goes well beyond the term \u00abfake news\u00bb. This term has been appropriated and used misleadingly by powerful actors to dismiss coverage that is simply found disagreeable. Disinformation as defined in this Report includes all forms of false, inaccurate, or misleading information designed, presented and promoted to intentionally cause public harm or for profit. It does not cover issues arising from the creation and dissemination online of illegal content (notably defamation, hate speech, incitement to violence), which are subject to regulatory remedies under EU or national laws. Nor does it cover other forms of deliberate but not misleading distortions of facts such a satire and parody. Problems of disinformation are deeply intertwined with the development of digital media. They are driven by actors \u2014 state or non-state political actors, for-profit actors, media, citizens, individually or in groups \u2014 and by manipulative uses of communication infrastructures that have been harnessed to produce, circulate and amplify disinformation on a larger scale than previously, often in new ways that are still poorly mapped and understood.",
    "doi": "10.2759/739290",
    "url": "https://openalex.org/W2982867001",
    "pdf_url": "https://hdl.handle.net/1814/70297",
    "venue": "Cadmus - EUI Research Repository (European University Institute)",
    "citation_count": 301,
    "fields_of_study": [
      "Disinformation",
      "Group (periodic table)",
      "Fake news",
      "Political science",
      "Internet privacy"
    ],
    "retrieved_at": "2026-02-02T16:58:12.549160"
  },
  {
    "source": "openalex",
    "source_id": "W3169231731",
    "title": "Federated Learning in a Medical Context: A Systematic Literature Review",
    "authors": [
      "Bjarne Pfitzner",
      "Nico Steckhan",
      "Bert Arnrich"
    ],
    "year": 2021,
    "abstract": "Data privacy is a very important issue. Especially in fields like medicine, it is paramount to abide by the existing privacy regulations to preserve patients\u2019 anonymity. However, data is required for research and training machine learning models that could help gain insight into complex correlations or personalised treatments that may otherwise stay undiscovered. Those models generally scale with the amount of data available, but the current situation often prohibits building large databases across sites. So it would be beneficial to be able to combine similar or related data from different sites all over the world while still preserving data privacy. Federated learning has been proposed as a solution for this, because it relies on the sharing of machine learning models, instead of the raw data itself. That means private data never leaves the site or device it was collected on. Federated learning is an emerging research area, and many domains have been identified for the application of those methods. This systematic literature review provides an extensive look at the concept of and research into federated learning and its applicability for confidential healthcare datasets.",
    "doi": "10.1145/3412357",
    "url": "https://openalex.org/W3169231731",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3412357",
    "venue": "ACM Transactions on Internet Technology",
    "citation_count": 243,
    "fields_of_study": [
      "Computer science",
      "Confidentiality",
      "Federated learning",
      "Context (archaeology)",
      "Data science"
    ],
    "retrieved_at": "2026-02-02T16:58:12.549194"
  },
  {
    "source": "openalex",
    "source_id": "W4389286730",
    "title": "ARTIFICIAL INTELLIGENCE IN DEVELOPING COUNTRIES: BRIDGING THE GAP BETWEEN POTENTIAL AND IMPLEMENTATION",
    "authors": [
      "Adebayo Olusegun Aderibigbe",
      "Peter Efosa Ohenhen",
      "Nwabueze Kelvin Nwaobia",
      "Joachim Osheyor Gidiagba",
      "Emmanuel Chigozie Ani"
    ],
    "year": 2023,
    "abstract": "This paper examines the role of Artificial Intelligence (AI) in developing countries, focusing on bridging the gap between its vast potential and effective implementation. As AI technologies advance globally, their impact on socio-economic development becomes increasingly critical, particularly in regions with diverse challenges and opportunities. The study investigates the current landscape of AI adoption in developing countries, analyzing the potential benefits, challenges, and ethical considerations. Through a comprehensive review of literature and case studies, the paper explores strategies and solutions for harnessing AI's transformative power in diverse sectors such as healthcare, agriculture, and education. The findings emphasize the importance of capacity building, public-private partnerships, and tailored policy frameworks to address infrastructure limitations and skill gaps. The research contributes to a nuanced understanding of the opportunities and complexities surrounding AI implementation in developing countries, providing insights for policymakers, practitioners, and scholars seeking to navigate this evolving technological landscape Keywords: Artificial Intelligence; Global Connectivity; Emerging Technologies; Organizational Resilience; Sustainable Growth; Developing Country.",
    "doi": "10.51594/csitrj.v4i3.629",
    "url": "https://openalex.org/W4389286730",
    "pdf_url": "https://fepbl.com/index.php/csitrj/article/download/629/799",
    "venue": "Computer Science & IT Research Journal",
    "citation_count": 105,
    "fields_of_study": [
      "Transformative learning",
      "Bridging (networking)",
      "Developing country",
      "Resilience (materials science)",
      "Emerging technologies"
    ],
    "retrieved_at": "2026-02-02T16:58:12.549214"
  },
  {
    "source": "openalex",
    "source_id": "W4213424378",
    "title": "Artificial Intelligence-Virtual Trainer: Innovative Didactics Aimed at Personalized Training Needs",
    "authors": [
      "Zhisheng Chen"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1007/s13132-022-00985-0",
    "url": "https://openalex.org/W4213424378",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s13132-022-00985-0.pdf",
    "venue": "Journal of the Knowledge Economy",
    "citation_count": 129,
    "fields_of_study": [
      "Trainer",
      "Training (meteorology)",
      "Process (computing)",
      "Computer science",
      "Knowledge management"
    ],
    "retrieved_at": "2026-02-02T16:58:12.549231"
  },
  {
    "source": "openalex",
    "source_id": "W3159204223",
    "title": "Responsible Artificial Intelligence (AI) for Value Formation and Market Performance in Healthcare: the Mediating Role of Patient\u2019s Cognitive Engagement",
    "authors": [
      "Pradeep Kumar",
      "Yogesh K. Dwivedi",
      "Ambuj Anand"
    ],
    "year": 2021,
    "abstract": null,
    "doi": "10.1007/s10796-021-10136-6",
    "url": "https://openalex.org/W3159204223",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10796-021-10136-6.pdf",
    "venue": "Information Systems Frontiers",
    "citation_count": 138,
    "fields_of_study": [
      "Mediation",
      "Health care",
      "Context (archaeology)",
      "Cognition",
      "Knowledge management"
    ],
    "retrieved_at": "2026-02-02T16:58:12.549234"
  },
  {
    "source": "openalex",
    "source_id": "W3156205870",
    "title": "Z-Inspection<sup>\u00ae</sup>: A Process to Assess Trustworthy AI",
    "authors": [
      "Roberto V. Zicari",
      "John Brodersen",
      "James Brusseau",
      "Boris D\u00fcdder",
      "Timo Eichhorn",
      "Todor Ivanov",
      "Georgios Kararigas",
      "Pedro Kringen",
      "Melissa McCullough",
      "Florian M\u00f6slein",
      "Naveed Mushtaq",
      "Gemma Roig",
      "Norman St\u00fcrtz",
      "Karsten Tolle",
      "Jesmin Jahan Tithi",
      "Irmhild van Halem",
      "Magnus Westerlund"
    ],
    "year": 2021,
    "abstract": "The ethical and societal implications of artificial intelligence systems raise concerns. In this article, we outline a novel process based on applied ethics, namely, Z-Inspection <sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\u00ae</sup> , to assess if an AI system is trustworthy. We use the definition of trustworthy AI given by the high-level European Commission's expert group on AI. Z-Inspection <sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\u00ae</sup> is a general inspection process that can be applied to a variety of domains where AI systems are used, such as business, healthcare, and public sector, among many others. To the best of our knowledge, Z-Inspection <sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\u00ae</sup> is the first process to assess trustworthy AI in practice.",
    "doi": "10.1109/tts.2021.3066209",
    "url": "https://openalex.org/W3156205870",
    "pdf_url": "https://ieeexplore.ieee.org/ielx7/8566059/9459493/09380498.pdf",
    "venue": "IEEE Transactions on Technology and Society",
    "citation_count": 109,
    "fields_of_study": [
      "Trustworthiness",
      "Process (computing)",
      "Artificial intelligence",
      "Computer science",
      "Computer security"
    ],
    "retrieved_at": "2026-02-02T16:58:12.549239"
  },
  {
    "source": "openalex",
    "source_id": "W4387652542",
    "title": "ESMO Guidance for Reporting Oncology real-World evidence (GROW)",
    "authors": [
      "Lu\u00eds Castelo-Branco",
      "Anna Pellat",
      "Diogo Martins-Branco",
      "Antonios Valachis",
      "Jeroen W. G. Derksen",
      "Karijn P.M. Suijkerbuijk",
      "Urania Dafni",
      "Tereza Dellaporta",
      "Arndt Vogel",
      "Arsela Prelaj",
      "Rolf H. H. Groenwold",
      "Henrique Martins",
      "Rolf A. Stahel",
      "Judith M. Bliss",
      "Jakob Nikolas Kather",
      "Nuria Ribelles",
      "Francesco Perrone",
      "Peter Hall",
      "Rodrigo Dienstmann",
      "Christopher M. Booth",
      "George Pentheroudakis",
      "Suzette Delaloge",
      "Miriam Koopman"
    ],
    "year": 2023,
    "abstract": null,
    "doi": "10.1016/j.annonc.2023.10.001",
    "url": "https://openalex.org/W4387652542",
    "pdf_url": "http://www.annalsofoncology.org/article/S0923753423040188/pdf",
    "venue": "Annals of Oncology",
    "citation_count": 173,
    "fields_of_study": [
      "Medicine",
      "Real world evidence",
      "Multidisciplinary approach",
      "Expert opinion",
      "Oncology"
    ],
    "retrieved_at": "2026-02-02T16:58:12.549254"
  },
  {
    "source": "openalex",
    "source_id": "W4207071830",
    "title": "Diffused responsibility: attributions of responsibility in the use of AI-driven clinical decision support systems",
    "authors": [
      "Hannah Bleher",
      "Matthias Braun"
    ],
    "year": 2022,
    "abstract": "Abstract Good decision-making is a complex endeavor, and particularly so in a health context. The possibilities for day-to-day clinical practice opened up by AI-driven clinical decision support systems (AI-CDSS) give rise to fundamental questions around responsibility. In causal, moral and legal terms the application of AI-CDSS is challenging existing attributions of responsibility. In this context, responsibility gaps are often identified as main problem. Mapping out the changing dynamics and levels of attributing responsibility, we argue in this article that the application of AI-CDSS causes diffusions of responsibility with respect to a causal, moral, and legal dimension. Responsibility diffusion describes the situation where multiple options and several agents can be considered for attributing responsibility. Using the example of an AI-driven \u2018digital tumor board\u2019, we illustrate how clinical decision-making is changed and diffusions of responsibility take place. Not denying or attempting to bridge responsibility gaps, we argue that dynamics and ambivalences are inherent in responsibility, which is based on normative considerations such as avoiding experiences of disregard and vulnerability of human life, which are inherently accompanied by a moment of uncertainty, and is characterized by revision openness. Against this background and to avoid responsibility gaps, the article concludes with suggestions for managing responsibility diffusions in clinical decision-making with AI-CDSS.",
    "doi": "10.1007/s43681-022-00135-x",
    "url": "https://openalex.org/W4207071830",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s43681-022-00135-x.pdf",
    "venue": "AI and Ethics",
    "citation_count": 120,
    "fields_of_study": [
      "Moral responsibility",
      "Normative",
      "Context (archaeology)",
      "Attribution",
      "Social responsibility"
    ],
    "retrieved_at": "2026-02-02T16:58:12.549258"
  },
  {
    "source": "openalex",
    "source_id": "W4312516176",
    "title": "Causal Inference in Natural Language Processing: Estimation, Prediction, Interpretation and Beyond",
    "authors": [
      "Amir Feder",
      "Katherine A. Keith",
      "Emaad Manzoor",
      "Reid Pryzant",
      "Dhanya Sridhar",
      "Zach Wood-Doughty",
      "Jacob Eisenstein",
      "Justin Grimmer",
      "Roi Reichart",
      "Margaret E. Roberts",
      "Brandon Stewart",
      "Victor Veitch",
      "Diyi Yang"
    ],
    "year": 2022,
    "abstract": "Abstract A fundamental goal of scientific research is to learn about causal relationships. However, despite its critical role in the life and social sciences, causality has not had the same importance in Natural Language Processing (NLP), which has traditionally placed more emphasis on predictive tasks. This distinction is beginning to fade, with an emerging area of interdisciplinary research at the convergence of causal inference and language processing. Still, research on causality in NLP remains scattered across domains without unified definitions, benchmark datasets and clear articulations of the challenges and opportunities in the application of causal inference to the textual domain, with its unique properties. In this survey, we consolidate research across academic areas and situate it in the broader NLP landscape. We introduce the statistical challenge of estimating causal effects with text, encompassing settings where text is used as an outcome, treatment, or to address confounding. In addition, we explore potential uses of causal inference to improve the robustness, fairness, and interpretability of NLP models. We thus provide a unified overview of causal inference for the NLP community.1",
    "doi": "10.1162/tacl_a_00511",
    "url": "https://openalex.org/W4312516176",
    "pdf_url": "https://direct.mit.edu/tacl/article-pdf/doi/10.1162/tacl_a_00511/2054690/tacl_a_00511.pdf",
    "venue": "Transactions of the Association for Computational Linguistics",
    "citation_count": 177,
    "fields_of_study": [
      "Causal inference",
      "Computer science",
      "Interpretability",
      "Inference",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:12.549279"
  },
  {
    "source": "openalex",
    "source_id": "W2998524378",
    "title": "Real-World Integration of a Sepsis Deep Learning Technology Into Routine Clinical Care: Implementation Study",
    "authors": [
      "Mark Sendak",
      "William Ratliff",
      "Dina Sarro",
      "Elizabeth Alderton",
      "Joseph Futoma",
      "Michael Gao",
      "Marshall Nichols",
      "Mike Revoir",
      "Faraz Yashar",
      "Corinne Miller",
      "Kelly Kester",
      "Sahil Sandhu",
      "Kristin Corey",
      "Nathan Brajer",
      "Christelle Tan",
      "Anthony Lin",
      "Tres Brown",
      "Susan Engelbosch",
      "Kevin J. Anstrom",
      "Madeleine Clare Elish",
      "Katherine Heller",
      "Rebecca Donohoe",
      "Jason Theiling",
      "Eric G. Poon",
      "Suresh Balu",
      "Armando Bedoya",
      "Cara O\u2019Brien"
    ],
    "year": 2019,
    "abstract": "Background Successful integrations of machine learning into routine clinical care are exceedingly rare, and barriers to its adoption are poorly characterized in the literature. Objective This study aims to report a quality improvement effort to integrate a deep learning sepsis detection and management platform, Sepsis Watch, into routine clinical care. Methods In 2016, a multidisciplinary team consisting of statisticians, data scientists, data engineers, and clinicians was assembled by the leadership of an academic health system to radically improve the detection and treatment of sepsis. This report of the quality improvement effort follows the learning health system framework to describe the problem assessment, design, development, implementation, and evaluation plan of Sepsis Watch. Results Sepsis Watch was successfully integrated into routine clinical care and reshaped how local machine learning projects are executed. Frontline clinical staff were highly engaged in the design and development of the workflow, machine learning model, and application. Novel machine learning methods were developed to detect sepsis early, and implementation of the model required robust infrastructure. Significant investment was required to align stakeholders, develop trusting relationships, define roles and responsibilities, and to train frontline staff, leading to the establishment of 3 partnerships with internal and external research groups to evaluate Sepsis Watch. Conclusions Machine learning models are commonly developed to enhance clinical decision making, but successful integrations of machine learning into routine clinical care are rare. Although there is no playbook for integrating deep learning into clinical care, learnings from the Sepsis Watch integration can inform efforts to develop machine learning technologies at other health care delivery systems.",
    "doi": "10.2196/15182",
    "url": "https://openalex.org/W2998524378",
    "pdf_url": "https://medinform.jmir.org/2020/7/e15182/PDF",
    "venue": "JMIR Medical Informatics",
    "citation_count": 192,
    "fields_of_study": [
      "Workflow",
      "Health care",
      "Artificial intelligence",
      "Quality management",
      "Multidisciplinary approach"
    ],
    "retrieved_at": "2026-02-02T16:58:12.549300"
  },
  {
    "source": "openalex",
    "source_id": "W4288083725",
    "title": "One Explanation Does Not Fit All",
    "authors": [
      "Kacper Sokol",
      "Peter Flach"
    ],
    "year": 2020,
    "abstract": null,
    "doi": "10.1007/s13218-020-00637-y",
    "url": "https://openalex.org/W4288083725",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s13218-020-00637-y.pdf",
    "venue": "KI - K\u00fcnstliche Intelligenz",
    "citation_count": 143,
    "fields_of_study": [
      "Transparency (behavior)",
      "Computer science",
      "Interpretability",
      "Counterfactual thinking",
      "Context (archaeology)"
    ],
    "retrieved_at": "2026-02-02T16:58:12.549325"
  },
  {
    "source": "openalex",
    "source_id": "W3133752603",
    "title": "The Ethics of Emotion in Artificial Intelligence Systems",
    "authors": [
      "Luke Stark",
      "Jesse Hoey"
    ],
    "year": 2021,
    "abstract": "In this paper, we develop a taxonomy of conceptual models and proxy data used for digital analysis of human emotional expression and outline how the combinations and permutations of these models and data impact their incorporation into artificial intelligence (AI) systems. We argue we should not take computer scientists at their word that the paradigms for human emotions they have developed internally and adapted from other disciplines can produce ground truth about human emotions; instead, we ask how different conceptualizations of what emotions are, and how they can be sensed, measured and transformed into data, shape the ethical and social implications of these AI systems.",
    "doi": "10.1145/3442188.3445939",
    "url": "https://openalex.org/W3133752603",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3442188.3445939",
    "venue": null,
    "citation_count": 142,
    "fields_of_study": [
      "Computer science",
      "Human intelligence",
      "Taxonomy (biology)",
      "Artificial intelligence",
      "Data science"
    ],
    "retrieved_at": "2026-02-02T16:58:12.549328"
  },
  {
    "source": "openalex",
    "source_id": "W4386913199",
    "title": "Generative AI and ChatGPT in School Children\u2019s Education: Evidence from a School Lesson",
    "authors": [
      "Jussi S. Jauhiainen",
      "Agust\u00edn Garagorry Guerra"
    ],
    "year": 2023,
    "abstract": "In 2023, the global use of generative AI, particularly ChatGPT-3.5 and -4, witnessed a significant surge, sparking discussions on its sustainable implementation across various domains, including education from primary schools to universities. However, practical testing and evaluation in school education are still relatively unexplored. This article examines the utilization of generative AI in primary school education. The study involved 110 pupils, aged 8\u201314 years old, studying in the 4th\u20136th grades across four classes in two schools. Using laptops, pupils participated in test lessons where content, text, figures, and exercises were generated and modified using generative AI, specifically ChatGPT-3.5. The results demonstrated that it was possible to use ChatGPT-3.5, as one example of generative AI, to personify learning material so that it would meet the knowledge and learning skills of pupils with different levels of knowledge. A clear majority of pupils enjoyed learning the generative AI-modified material. There is a promising potential of generative AI use in school education, supporting pupils\u2019 motivated learning and skills development. However, these tools need to be developed, refined and optimized to ensure proper adaptation and to create impactful, inclusive, and sustainable learning in schools to benefit pupils, teachers and education managers alike.",
    "doi": "10.3390/su151814025",
    "url": "https://openalex.org/W4386913199",
    "pdf_url": "https://www.mdpi.com/2071-1050/15/18/14025/pdf?version=1695347129",
    "venue": "Sustainability",
    "citation_count": 171,
    "fields_of_study": [
      "Generative grammar",
      "Mathematics education",
      "Test (biology)",
      "Generative model",
      "Adaptation (eye)"
    ],
    "retrieved_at": "2026-02-02T16:58:12.549340"
  },
  {
    "source": "openalex",
    "source_id": "W2972141736",
    "title": "Artificial Intelligence and Music: Open Questions of Copyright Law and Engineering Praxis",
    "authors": [
      "Bob L. Sturm",
      "Mar\u00eda Teresa Iglesias",
      "Oded Ben\u2010Tal",
      "Marius Miron",
      "Em\u00edlia G\u00f3mez"
    ],
    "year": 2019,
    "abstract": "The application of artificial intelligence (AI) to music stretches back many decades, and presents numerous unique opportunities for a variety of uses, such as the recommendation of recorded music from massive commercial archives, or the (semi-)automated creation of music. Due to unparalleled access to music data and effective learning algorithms running on high-powered computational hardware, AI is now producing surprising outcomes in a domain fully entrenched in human creativity\u2014not to mention a revenue source around the globe. These developments call for a close inspection of what is occurring, and consideration of how it is changing and can change our relationship with music for better and for worse. This article looks at AI applied to music from two perspectives: copyright law and engineering praxis. It grounds its discussion in the development and use of a specific application of AI in music creation, which raises further and unanticipated questions. Most of the questions collected in this article are open as their answers are not yet clear at this time, but they are nonetheless important to consider as AI technologies develop and are applied more widely to music, not to mention other domains centred on human creativity.",
    "doi": "10.3390/arts8030115",
    "url": "https://openalex.org/W2972141736",
    "pdf_url": "https://www.mdpi.com/2076-0752/8/3/115/pdf?version=1567732463",
    "venue": "Arts",
    "citation_count": 115,
    "fields_of_study": [
      "Creativity",
      "Praxis",
      "Globe",
      "Computer science",
      "Music and artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:12.549360"
  },
  {
    "source": "openalex",
    "source_id": "W3157651069",
    "title": "A Proposed Framework on Integrating Health Equity and Racial Justice into the Artificial Intelligence Development Lifecycle",
    "authors": [
      "Irene Dankwa\u2010Mullan",
      "Elisabeth Scheufele",
      "Michael E. Matheny",
      "Yuri Quintana",
      "Wendy W. Chapman",
      "Gretchen Purcell Jackson",
      "Brett R. South"
    ],
    "year": 2021,
    "abstract": "The COVID-19 pandemic has created multiple opportunities to deploy artificial intelligence (AI)-driven tools and applied interventions to understand, mitigate, and manage the pandemic and its consequences. The disproportionate impact of COVID-19 on racial/ethnic minority and socially disadvantaged populations underscores the need to anticipate and address social inequalities and health disparities in AI development and application. Before the pandemic, there was growing optimism about AI's role in addressing inequities and enhancing personalized care. Unfortunately, ethical and social issues that are encountered in scaling, developing, and applying advanced technologies in health care settings have intensified during the rapidly evolving public health crisis. Critical voices concerned with the disruptive potentials and risk for engineered inequities have called for reexamining ethical guidelines in the development and application of AI. This paper proposes a framework to incorporate ethical AI principles into the development process in ways that intentionally promote racial health equity and social justice. Without centering on equity, justice, and ethical AI, these tools may exacerbate structural inequities that can lead to disparate health outcomes.",
    "doi": "10.1353/hpu.2021.0065",
    "url": "https://openalex.org/W3157651069",
    "pdf_url": "https://muse.jhu.edu/pub/1/article/789672",
    "venue": "Journal of Health Care for the Poor and Underserved",
    "citation_count": 98,
    "fields_of_study": [
      "Health equity",
      "Disadvantaged",
      "Equity (law)",
      "Optimism",
      "Health care"
    ],
    "retrieved_at": "2026-02-02T16:58:12.549381"
  },
  {
    "source": "openalex",
    "source_id": "W3158393586",
    "title": "Ensuring that biomedical AI benefits diverse populations",
    "authors": [
      "James Zou",
      "Londa Schiebinger"
    ],
    "year": 2021,
    "abstract": null,
    "doi": "10.1016/j.ebiom.2021.103358",
    "url": "https://openalex.org/W3158393586",
    "pdf_url": "http://www.thelancet.com/article/S2352396421001511/pdf",
    "venue": "EBioMedicine",
    "citation_count": 109,
    "fields_of_study": [
      "Computational biology",
      "MEDLINE",
      "Data science",
      "Biology",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:12.549398"
  },
  {
    "source": "openalex",
    "source_id": "W3136853555",
    "title": "Implicit bias in healthcare: clinical practice, research and decision making",
    "authors": [
      "Dipesh P Gopal",
      "Ula Chetty",
      "Patrick O\u2019Donnell",
      "Camille Gajria",
      "Jodie Blackadder-Weinstein"
    ],
    "year": 2021,
    "abstract": null,
    "doi": "10.7861/fhj.2020-0233",
    "url": "https://openalex.org/W3136853555",
    "pdf_url": "https://www.rcpjournals.org/content/futurehosp/8/1/40.full.pdf",
    "venue": "Future Healthcare Journal",
    "citation_count": 251,
    "fields_of_study": [
      "Debiasing",
      "Prejudice (legal term)",
      "Cognitive bias",
      "Implicit bias",
      "Psychology"
    ],
    "retrieved_at": "2026-02-02T16:58:12.549402"
  },
  {
    "source": "openalex",
    "source_id": "W2609499779",
    "title": "What is open peer review? A systematic review",
    "authors": [
      "Tony Ross\u2010Hellauer"
    ],
    "year": 2017,
    "abstract": "<ns4:p><ns4:bold>Background</ns4:bold>: \u201cOpen peer review\u201d (OPR), despite being a major pillar of Open Science, has neither a standardized definition nor an agreed schema of its features and implementations. The literature reflects this, with numerous overlapping and contradictory definitions. While for some the term refers to peer review where the identities of both author and reviewer are disclosed to each other, for others it signifies systems where reviewer reports are published alongside articles. For others it signifies both of these conditions, and for yet others it describes systems where not only \u201cinvited experts\u201d are able to comment. For still others, it includes a variety of combinations of these and other novel methods.</ns4:p><ns4:p><ns4:bold>Methods</ns4:bold>: Recognising the absence of a consensus view on what open peer review is, this article undertakes a systematic review of definitions of \u201copen peer review\u201d or \u201copen review\u201d, to create a corpus of 122 definitions. These definitions are systematically analysed to build a coherent typology of the various innovations in peer review signified by the term, and hence provide the precise technical definition currently lacking.</ns4:p><ns4:p><ns4:bold>Results</ns4:bold>: This quantifiable data yields rich information on the range and extent of differing definitions over time and by broad subject area. Quantifying definitions in this way allows us to accurately portray exactly how ambiguously the phrase \u201copen peer review\u201d has been used thus far, for the literature offers 22 distinct configurations of seven traits, effectively meaning that there are 22 different definitions of OPR in the literature reviewed.</ns4:p><ns4:p><ns4:bold>Conclusions</ns4:bold>: I propose a pragmatic definition of open peer review as an umbrella term for a number of overlapping ways that peer review models can be adapted in line with the aims of Open Science, including making reviewer and author identities open, publishing review reports and enabling greater participation in the peer review process.</ns4:p>",
    "doi": "10.12688/f1000research.11369.2",
    "url": "https://openalex.org/W2609499779",
    "pdf_url": "https://f1000research.com/articles/6-588/v2/pdf",
    "venue": "F1000Research",
    "citation_count": 408,
    "fields_of_study": [
      "Open peer review",
      "Plant biology",
      "Open science",
      "Open data",
      "Peer review"
    ],
    "retrieved_at": "2026-02-02T16:58:13.386545"
  },
  {
    "source": "openalex",
    "source_id": "W4229079094",
    "title": "Rethinking Fairness: An Interdisciplinary Survey of Critiques of Hegemonic ML Fairness Approaches",
    "authors": [
      "Lindsay Weinberg"
    ],
    "year": 2022,
    "abstract": "This survey article assesses and compares existing critiques of current fairness-enhancing technical interventions in machine learning (ML) that draw from a range of non-computing disciplines, including philosophy, feminist studies, critical race and ethnic studies, legal studies, anthropology, and science and technology studies. It bridges epistemic divides in order to offer an interdisciplinary understanding of the possibilities and limits of hegemonic computational approaches to ML fairness for producing just outcomes for society\u2019s most marginalized. The article is organized according to nine major themes of critique wherein these different fields intersect: 1) how \"fairness\" in AI fairness research gets defined; 2) how problems for AI systems to address get formulated; 3) the impacts of abstraction on how AI tools function and its propensity to lead to technological solutionism; 4) how racial classification operates within AI fairness research; 5) the use of AI fairness measures to avoid regulation and engage in ethics washing; 6) an absence of participatory design and democratic deliberation in AI fairness considerations; 7) data collection practices that entrench \u201cbias,\u201d are non-consensual, and lack transparency; 8) the predatory inclusion of marginalized groups into AI systems; and 9) a lack of engagement with AI\u2019s long-term social and ethical outcomes. Drawing from these critiques, the article concludes by imagining future ML fairness research directions that actively disrupt entrenched power dynamics and structural injustices in society.",
    "doi": "10.1613/jair.1.13196",
    "url": "https://openalex.org/W4229079094",
    "pdf_url": "https://jair.org/index.php/jair/article/download/13196/26797",
    "venue": "Journal of Artificial Intelligence Research",
    "citation_count": 113,
    "fields_of_study": [
      "Sociology",
      "Deliberation",
      "Transparency (behavior)",
      "Hegemony",
      "Inclusion (mineral)"
    ],
    "retrieved_at": "2026-02-02T16:58:13.386601"
  },
  {
    "source": "openalex",
    "source_id": "W4378009112",
    "title": "AI-Augmented HRM: Literature review and a proposed multilevel framework for future research",
    "authors": [
      "Verma Prikshat",
      "Mohammad Islam",
      "Parth Patel",
      "Ashish Malik",
      "Pawan Budhwar",
      "Suraksha Gupta"
    ],
    "year": 2023,
    "abstract": null,
    "doi": "10.1016/j.techfore.2023.122645",
    "url": "https://openalex.org/W4378009112",
    "pdf_url": "https://www.sciencedirect.com/science/article/pii/S004016252300330X",
    "venue": "Technological Forecasting and Social Change",
    "citation_count": 113,
    "fields_of_study": [
      "Systematic review",
      "Context (archaeology)",
      "Hospitality",
      "Knowledge management",
      "Human resource management"
    ],
    "retrieved_at": "2026-02-02T16:58:13.386631"
  },
  {
    "source": "openalex",
    "source_id": "W3202196203",
    "title": "The European Commission\u2019s Proposal for an Artificial Intelligence Act\u2014A Critical Assessment by Members of the Robotics and AI Law Society (RAILS)",
    "authors": [
      "Martin Ebers",
      "Veronica R. S. Hoch",
      "Frank Rosenkranz",
      "Hannah Ruschemeier",
      "Bj\u00f6rn Steinr\u00f6tter"
    ],
    "year": 2021,
    "abstract": "On 21 April 2021, the European Commission presented its long-awaited proposal for a Regulation \u201claying down harmonized rules on Artificial Intelligence\u201d, the so-called \u201cArtificial Intelligence Act\u201d (AIA). This article takes a critical look at the proposed regulation. After an introduction (1), the paper analyzes the unclear preemptive effect of the AIA and EU competences (2), the scope of application (3), the prohibited uses of Artificial Intelligence (AI) (4), the provisions on high-risk AI systems (5), the obligations of providers and users (6), the requirements for AI systems with limited risks (7), the enforcement system (8), the relationship of the AIA with the existing legal framework (9), and the regulatory gaps (10). The last section draws some final conclusions (11).",
    "doi": "10.3390/j4040043",
    "url": "https://openalex.org/W3202196203",
    "pdf_url": "https://www.mdpi.com/2571-8800/4/4/43/pdf?version=1633664227",
    "venue": "J \u2014 Multidisciplinary Scientific Journal",
    "citation_count": 128,
    "fields_of_study": [
      "Scope (computer science)",
      "Commission",
      "European commission",
      "Artificial intelligence",
      "Enforcement"
    ],
    "retrieved_at": "2026-02-02T16:58:13.386636"
  },
  {
    "source": "openalex",
    "source_id": "W3109670077",
    "title": "The impact of using algorithms for managerial decisions on public employees' procedural justice",
    "authors": [
      "Rosanna Nagtegaal"
    ],
    "year": 2020,
    "abstract": null,
    "doi": "10.1016/j.giq.2020.101536",
    "url": "https://openalex.org/W3109670077",
    "pdf_url": "https://www.sciencedirect.com/science/article/pii/S0740624X20303154",
    "venue": "Government Information Quarterly",
    "citation_count": 128,
    "fields_of_study": [
      "Panacea (medicine)",
      "Procedural justice",
      "Perception",
      "Transparency (behavior)",
      "Economic Justice"
    ],
    "retrieved_at": "2026-02-02T16:58:13.386650"
  },
  {
    "source": "openalex",
    "source_id": "W4392691776",
    "title": "Assessing the research landscape and clinical utility of large language models: a scoping review",
    "authors": [
      "Ye\u2010Jean Park",
      "Abhinav Pillai",
      "Jiawen Deng",
      "Eddie Guo",
      "Mehul Gupta",
      "Mike Paget",
      "Christopher Naugler"
    ],
    "year": 2024,
    "abstract": "Abstract Importance Large language models (LLMs) like OpenAI\u2019s ChatGPT are powerful generative systems that rapidly synthesize natural language responses. Research on LLMs has revealed their potential and pitfalls, especially in clinical settings. However, the evolving landscape of LLM research in medicine has left several gaps regarding their evaluation, application, and evidence base. Objective This scoping review aims to (1) summarize current research evidence on the accuracy and efficacy of LLMs in medical applications, (2) discuss the ethical, legal, logistical, and socioeconomic implications of LLM use in clinical settings, (3) explore barriers and facilitators to LLM implementation in healthcare, (4) propose a standardized evaluation framework for assessing LLMs\u2019 clinical utility, and (5) identify evidence gaps and propose future research directions for LLMs in clinical applications. Evidence review We screened 4,036 records from MEDLINE, EMBASE, CINAHL, medRxiv, bioRxiv, and arXiv from January 2023 (inception of the search) to June 26, 2023 for English-language papers and analyzed findings from 55 worldwide studies. Quality of evidence was reported based on the Oxford Centre for Evidence-based Medicine recommendations. Findings Our results demonstrate that LLMs show promise in compiling patient notes, assisting patients in navigating the healthcare system, and to some extent, supporting clinical decision-making when combined with human oversight. However, their utilization is limited by biases in training data that may harm patients, the generation of inaccurate but convincing information, and ethical, legal, socioeconomic, and privacy concerns. We also identified a lack of standardized methods for evaluating LLMs\u2019 effectiveness and feasibility. Conclusions and relevance This review thus highlights potential future directions and questions to address these limitations and to further explore LLMs\u2019 potential in enhancing healthcare delivery.",
    "doi": "10.1186/s12911-024-02459-6",
    "url": "https://openalex.org/W4392691776",
    "pdf_url": "https://bmcmedinformdecismak.biomedcentral.com/counter/pdf/10.1186/s12911-024-02459-6",
    "venue": "BMC Medical Informatics and Decision Making",
    "citation_count": 135,
    "fields_of_study": [
      "CINAHL",
      "MEDLINE",
      "Health care",
      "Medicine",
      "Socioeconomic status"
    ],
    "retrieved_at": "2026-02-02T16:58:13.386654"
  },
  {
    "source": "openalex",
    "source_id": "W4385650719",
    "title": "Artificial Intelligence Ethics and Challenges in Healthcare Applications: A Comprehensive Review in the Context of the European GDPR Mandate",
    "authors": [
      "Mohammad Amini",
      "Marcia Jesus",
      "Davood Fanaei Sheikholeslami",
      "Paulo Alves",
      "Aliakbar Hassanzadeh Benam",
      "Fatemeh Hariri"
    ],
    "year": 2023,
    "abstract": "This study examines the ethical issues surrounding the use of Artificial Intelligence (AI) in healthcare, specifically nursing, under the European General Data Protection Regulation (GDPR). The analysis delves into how GDPR applies to healthcare AI projects, encompassing data collection and decision-making stages, to reveal the ethical implications at each step. A comprehensive review of the literature categorizes research investigations into three main categories: Ethical Considerations in AI; Practical Challenges and Solutions in AI Integration; and Legal and Policy Implications in AI. The analysis uncovers a significant research deficit in this field, with a particular focus on data owner rights and AI ethics within GDPR compliance. To address this gap, the study proposes new case studies that emphasize the importance of comprehending data owner rights and establishing ethical norms for AI use in medical applications, especially in nursing. This review makes a valuable contribution to the AI ethics debate and assists nursing and healthcare professionals in developing ethical AI practices. The insights provided help stakeholders navigate the intricate terrain of data protection, ethical considerations, and regulatory compliance in AI-driven healthcare. Lastly, the study introduces a case study of a real AI health-tech project named SENSOMATT, spotlighting GDPR and privacy issues.",
    "doi": "10.3390/make5030053",
    "url": "https://openalex.org/W4385650719",
    "pdf_url": "https://www.mdpi.com/2504-4990/5/3/53/pdf?version=1691412599",
    "venue": "Machine Learning and Knowledge Extraction",
    "citation_count": 104,
    "fields_of_study": [
      "Mandate",
      "Engineering ethics",
      "Health care",
      "General Data Protection Regulation",
      "Context (archaeology)"
    ],
    "retrieved_at": "2026-02-02T16:58:13.386681"
  },
  {
    "source": "openalex",
    "source_id": "W3201150582",
    "title": "Corporate digital responsibility (CDR) in construction engineering\u2014ethical guidelines for the application of digital transformation and artificial intelligence (AI) in user practice",
    "authors": [
      "Bianca Christina Weber-Lewerenz"
    ],
    "year": 2021,
    "abstract": null,
    "doi": "10.1007/s42452-021-04776-1",
    "url": "https://openalex.org/W3201150582",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s42452-021-04776-1.pdf",
    "venue": "SN Applied Sciences",
    "citation_count": 129,
    "fields_of_study": [
      "Digitization",
      "Digital transformation",
      "Process (computing)",
      "Government (linguistics)",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:13.386701"
  },
  {
    "source": "openalex",
    "source_id": "W2973057865",
    "title": "Platforms in the peer-to-peer sharing economy",
    "authors": [
      "Jochen Wirtz",
      "Kevin Kam Fung So",
      "Makarand Mody",
      "Stephanie Q. Liu",
      "HaeEun Helen Chun"
    ],
    "year": 2019,
    "abstract": "Purpose The purpose of this paper is to examine peer-to-peer sharing platform business models, their sources of competitive advantage, and the roles, motivations and behaviors of key actors in their ecosystems. Design/methodology/approach This paper uses a conceptual approach that is rooted in the service, tourism and hospitality, and strategy literature. Findings First, this paper defines key types of platform business models in the sharing economy anddescribes their characteristics. In particular, the authors propose the differentiation between sharing platforms of capacity-constrained vs capacity-unconstrained assets and advance five core properties of the former. Second, the authors contrast platform business models with their pipeline business model counterparts to understand the fundamental differences between them. One important conclusion is that platforms cater to vastly more heterogeneous assets and consumer needs and, therefore, require liquidity and analytics for high-quality matching. Third, the authors examine the competitive position of platforms and conclude that their widely taken \u201cwinner takes it all\u201d assumption is not valid. Primary network effects are less important once a critical level of liquidity has been reached and may even turn negative if increased listings raise friction in the form of search costs. Once a critical level of liquidity has been reached, a platform\u2019s competitive position depends on stakeholder trust and service provider and user loyalty. Fourth, the authors integrate and synthesize the literature on key platform stakeholders of platform businesses (i.e. users, service providers, and regulators) and their roles and motivations. Finally, directions for further research are advanced. Practical implications This paper helps platform owners, service providers and users understand better the implications of sharing platform business models and how to position themselves in such ecosystems. Originality/value This paper integrates the extant literature on sharing platforms, takes a novel approach in delineating their key properties and dimensions, and provides insights into the evolving and dynamic forms of sharing platforms including converging business models.",
    "doi": "10.1108/josm-11-2018-0369",
    "url": "https://openalex.org/W2973057865",
    "pdf_url": "https://www.emerald.com/insight/content/doi/10.1108/JOSM-11-2018-0369/full/pdf?title=platforms-in-the-peer-to-peer-sharing-economy",
    "venue": "Journal of service management",
    "citation_count": 378,
    "fields_of_study": [
      "Sharing economy",
      "Business model",
      "Business",
      "Industrial organization",
      "Key (lock)"
    ],
    "retrieved_at": "2026-02-02T16:58:13.386704"
  },
  {
    "source": "openalex",
    "source_id": "W2998535576",
    "title": "Detection of Suicide Ideation in Social Media Forums Using Deep Learning",
    "authors": [
      "Michael M. Tadesse",
      "Hongfei Lin",
      "Bo Xu",
      "Liang Yang"
    ],
    "year": 2019,
    "abstract": "Suicide ideation expressed in social media has an impact on language usage. Many at-risk individuals use social forum platforms to discuss their problems or get access to information on similar tasks. The key objective of our study is to present ongoing work on automatic recognition of suicidal posts. We address the early detection of suicide ideation through deep learning and machine learning-based classification approaches applied to Reddit social media. For such purpose, we employ an LSTM-CNN combined model to evaluate and compare to other classification models. Our experiment shows the combined neural network architecture with word embedding techniques can achieve the best relevance classification results. Additionally, our results support the strength and ability of deep learning architectures to build an effective model for a suicide risk assessment in various text classification tasks.",
    "doi": "10.3390/a13010007",
    "url": "https://openalex.org/W2998535576",
    "pdf_url": "https://www.mdpi.com/1999-4893/13/1/7/pdf?version=1577442085",
    "venue": "Algorithms",
    "citation_count": 227,
    "fields_of_study": [
      "Computer science",
      "Social media",
      "Deep learning",
      "Word embedding",
      "Suicidal ideation"
    ],
    "retrieved_at": "2026-02-02T16:58:13.386734"
  },
  {
    "source": "openalex",
    "source_id": "W3155872716",
    "title": "Spatiotemporal data mining: a survey on challenges and open problems",
    "authors": [
      "Ali Hamdi",
      "Khaled Shaban",
      "Abdelkarim Erradi",
      "Amr Mohamed",
      "Shakila Khan Rumi",
      "Flora D. Salim"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1007/s10462-021-09994-y",
    "url": "https://openalex.org/W3155872716",
    "pdf_url": null,
    "venue": null,
    "citation_count": 131,
    "fields_of_study": [
      "Computer science",
      "Data science",
      "Cluster analysis",
      "Data mining",
      "Visualization"
    ],
    "retrieved_at": "2026-02-02T16:58:13.386751"
  },
  {
    "source": "openalex",
    "source_id": "W4387970754",
    "title": "AI Chatbots in Digital Mental Health",
    "authors": [
      "Luke Balcombe"
    ],
    "year": 2023,
    "abstract": "Artificial intelligence (AI) chatbots have gained prominence since 2022. Powered by big data, natural language processing (NLP) and machine learning (ML) algorithms, they offer the potential to expand capabilities, improve productivity and provide guidance and support in various domains. Human\u2013Artificial Intelligence (HAI) is proposed to help with the integration of human values, empathy and ethical considerations into AI in order to address the limitations of AI chatbots and enhance their effectiveness. Mental health is a critical global concern, with a substantial impact on individuals, communities and economies. Digital mental health solutions, leveraging AI and ML, have emerged to address the challenges of access, stigma and cost in mental health care. Despite their potential, ethical and legal implications surrounding these technologies remain uncertain. This narrative literature review explores the potential of AI chatbots to revolutionize digital mental health while emphasizing the need for ethical, responsible and trustworthy AI algorithms. The review is guided by three key research questions: the impact of AI chatbots on technology integration, the balance between benefits and harms, and the mitigation of bias and prejudice in AI applications. Methodologically, the review involves extensive database and search engine searches, utilizing keywords related to AI chatbots and digital mental health. Peer-reviewed journal articles and media sources were purposively selected to address the research questions, resulting in a comprehensive analysis of the current state of knowledge on this evolving topic. In conclusion, AI chatbots hold promise in transforming digital mental health but must navigate complex ethical and practical challenges. The integration of HAI principles, responsible regulation and scoping reviews are crucial to maximizing their benefits while minimizing potential risks. Collaborative approaches and modern educational solutions may enhance responsible use and mitigate biases in AI applications, ensuring a more inclusive and effective digital mental health landscape.",
    "doi": "10.3390/informatics10040082",
    "url": "https://openalex.org/W4387970754",
    "pdf_url": "https://www.mdpi.com/2227-9709/10/4/82/pdf?version=1698398262",
    "venue": "Informatics",
    "citation_count": 99,
    "fields_of_study": [
      "Mental health",
      "Digital health",
      "Empathy",
      "Big data",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:13.386754"
  },
  {
    "source": "openalex",
    "source_id": "W3088512781",
    "title": "Transforming knowledge systems for life on Earth: Visions of future systems and how to get there",
    "authors": [
      "Ioan Fazey",
      "Niko Sch\u00e4pke",
      "Guido Caniglia",
      "Anthony Hodgson",
      "Ian Kendrick",
      "Christopher J. Lyon",
      "Glenn G. Page",
      "James Patterson",
      "Chris Riedy",
      "Tim Strasser",
      "S. Verveen",
      "David Adams",
      "Bruce Evan Goldstein",
      "Matthias Klaes",
      "Graham Leicester",
      "Alison Linyard",
      "Adrienne McCurdy",
      "Paul Ryan",
      "Bill Sharpe",
      "Giorgia Silvestri",
      "Ali Yansyah Abdurrahim",
      "David J. Abson",
      "Olufemi Adetunji",
      "Paulina Aldunce",
      "Carlos Alvarez-Pereira",
      "Jennifer Marie Amparo",
      "Helene Amundsen",
      "Lakin Anderson",
      "Lotta Andersson",
      "Michael Asquith",
      "Karoline Augenstein",
      "Jack Barrie",
      "David Bent",
      "Julia Bentz",
      "Arvid Bergsten",
      "Carol L. Berzonsky",
      "Ol\u00edvia Bina",
      "Kirsty Blackstock",
      "Joanna Boehnert",
      "Hilary Bradbury",
      "Christine Brand",
      "Jessica B\u00f6hme",
      "Marianne Mille B\u00f8jer",
      "Esther Carmen",
      "Lakshmi Charli-Joseph",
      "Sarah Choudhury",
      "Supot Chunhachoti-ananta",
      "Jessica Cockburn",
      "John Colvin",
      "Irena Leisbet Ceridwen Connon",
      "Rosalind Cornforth",
      "Robin S. Cox",
      "Nicholas A. Cradock-Henry",
      "Laura Cramer",
      "Almendra Cremaschi",
      "Halvor Dannevig",
      "Catherine T. Day",
      "Cathel de Lima Hutchison",
      "Anke de Vrieze",
      "Vikas Desai",
      "Jonathan Dolley",
      "Dominic Duckett",
      "Rachael Durrant",
      "Markus Egermann",
      "Emily Elsner",
      "Chris Fremantle",
      "Jessica Fullwood-Thomas",
      "Diego Galafassi",
      "Jen Gobby",
      "Ami Golland",
      "Shiara Kirana Gonz\u00e1lez-Padr\u00f3n",
      "Irmelin Gram-Hanssen",
      "Jakob Grandin",
      "Sara Grenni",
      "Jade Lauren Gunnell",
      "Felipe Gusm\u00e3o",
      "Maike Hamann",
      "Brian Harding",
      "Gavin Harper",
      "Mia Hesselgren",
      "Dina Hestad",
      "Cheryl Heykoop",
      "Johan Holm\u00e9n",
      "Kirsty Holstead",
      "Claire Hoolohan",
      "Andra\u2010Ioana Horcea\u2010Milcu",
      "Lummina Horlings",
      "Stuart Mark Howden",
      "Rachel Howell",
      "Sarah Huque",
      "Mirna Liz Inturias Canedo",
      "Chidinma Yvonne Iro",
      "Christopher D. Ives",
      "Beatrice John",
      "Rajiv Joshi",
      "Sadhbh Ju\u00e1rez-Bourke",
      "Dauglas Wafula Juma",
      "Bea Cecilie Karlsen",
      "Lea Kliem",
      "Andreas Kl\u00e4y"
    ],
    "year": 2020,
    "abstract": null,
    "doi": "10.1016/j.erss.2020.101724",
    "url": "https://openalex.org/W3088512781",
    "pdf_url": "https://www.sciencedirect.com/science/article/pii/S2214629620302991?via%3Dihub",
    "venue": "Energy Research & Social Science",
    "citation_count": 250,
    "fields_of_study": [
      "Vision",
      "Futures studies",
      "Engineering ethics",
      "Futures contract",
      "Enlightenment"
    ],
    "retrieved_at": "2026-02-02T16:58:13.386795"
  },
  {
    "source": "openalex",
    "source_id": "W4388354324",
    "title": "Better regulation for the green transition",
    "authors": [
      "Yola Th\u00fcrer"
    ],
    "year": 2023,
    "abstract": "Climate change and other environmental threats require urgent government action. This policy paper discusses how governments can use better regulation instruments (good regulatory practices, risk-based and agile approaches, regulatory delivery, international regulatory cooperation, economic regulators, and behavioural insights) to design, implement and evaluate efficient and effective regulations for the environment. It explores the challenges governments face and presents good practices for environmental and other regulations, to ensure that all policy instruments coherently pursue environmental goals. Finally, the paper suggests how regulatory policy systems can meet present and future environmental challenges. It argues that to fully exploit the potential of better regulation for the environment, governments should implement measures that ensure an inclusive, cooperative, outcome-based and global approach to regulating.",
    "doi": "10.1787/c91a04bc-en",
    "url": "https://openalex.org/W4388354324",
    "pdf_url": "https://www.oecd-ilibrary.org/deliver/c91a04bc-en.pdf?itemId=%2Fcontent%2Fpaper%2Fc91a04bc-en&mimeType=pdf",
    "venue": "Public governance policy papers",
    "citation_count": 397,
    "fields_of_study": [
      "Exploit",
      "Environmental regulation",
      "Government (linguistics)",
      "Business",
      "Action (physics)"
    ],
    "retrieved_at": "2026-02-02T16:58:13.386798"
  },
  {
    "source": "openalex",
    "source_id": "W4220863829",
    "title": "Deep Learning and Medical Image Analysis for COVID-19 Diagnosis and Prediction",
    "authors": [
      "Tianming Liu",
      "Eliot L. Siegel",
      "Dinggang Shen"
    ],
    "year": 2022,
    "abstract": "The coronavirus disease 2019 (COVID-19) pandemic has imposed dramatic challenges to health-care organizations worldwide. To combat the global crisis, the use of thoracic imaging has played a major role in the diagnosis, prediction, and management of COVID-19 patients with moderate to severe symptoms or with evidence of worsening respiratory status. In response, the medical image analysis community acted quickly to develop and disseminate deep learning models and tools to meet the urgent need of managing and interpreting large amounts of COVID-19 imaging data. This review aims to not only summarize existing deep learning and medical image analysis methods but also offer in-depth discussions and recommendations for future investigations. We believe that the wide availability of high-quality, curated, and benchmarked COVID-19 imaging data sets offers the great promise of a transformative test bed to develop, validate, and disseminate novel deep learning methods in the frontiers of data science and artificial intelligence.",
    "doi": "10.1146/annurev-bioeng-110220-012203",
    "url": "https://openalex.org/W4220863829",
    "pdf_url": "https://www.annualreviews.org/doi/pdf/10.1146/annurev-bioeng-110220-012203",
    "venue": "Annual Review of Biomedical Engineering",
    "citation_count": 115,
    "fields_of_study": [
      "Deep learning",
      "Dissemination",
      "Coronavirus disease 2019 (COVID-19)",
      "Transformative learning",
      "Pandemic"
    ],
    "retrieved_at": "2026-02-02T16:58:13.386811"
  },
  {
    "source": "openalex",
    "source_id": "W4283275376",
    "title": "Artificial intelligence and blockchain implementation in supply chains: a pathway to sustainability and data monetisation?",
    "authors": [
      "Naoum Tsolakis",
      "Roman Schumacher",
      "Manoj Dora",
      "Mukesh Kumar"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1007/s10479-022-04785-2",
    "url": "https://openalex.org/W4283275376",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10479-022-04785-2.pdf",
    "venue": "Annals of Operations Research",
    "citation_count": 249,
    "fields_of_study": [
      "Supply chain",
      "Sustainability",
      "Big data",
      "Fast fashion",
      "Process management"
    ],
    "retrieved_at": "2026-02-02T16:58:13.386827"
  },
  {
    "source": "openalex",
    "source_id": "W4391023377",
    "title": "The IDEAL framework for surgical robotics: development, comparative evaluation and long-term monitoring",
    "authors": [
      "Hani J. Marcus",
      "Pedro T. Ram\u00edrez",
      "Danyal Z. Khan",
      "Hugo Layard Horsfall",
      "John Hanrahan",
      "Simon C. Williams",
      "David Beard",
      "Rani Akhil Bhat",
      "Ken Catchpole",
      "Andrew Cook",
      "Katrina Hutchison",
      "Janet Martin",
      "Tom Melvin",
      "Danail Stoyanov",
      "Maroeska M. Rovers",
      "Nicholas Raison",
      "Prokar Dasgupta",
      "David Noonan",
      "Deborah Stocken",
      "Georgia Sturt",
      "Anne Vanhoestenberghe",
      "Baptiste Vasey",
      "Peter McCulloch",
      "Ajai Chari",
      "Fanny Ficuciello",
      "Effy Vayena",
      "Chris Baber",
      "Marco A. Zenati",
      "Alan Kuntz",
      "Karen Kerr",
      "Nigel Horwood",
      "Katherine Anderon",
      "Ka\u2010Wai Kwok",
      "Rich Mahoney",
      "Bill Peine",
      "Ferdinando Rodriquez Y. Baena",
      "Pietro Valdastri",
      "Richard Leparmentier",
      "Len Evans",
      "Rebecca Langley",
      "Garnette R. Sutherland",
      "Sanju Lama",
      "Naeem Soomro",
      "Justin Collins",
      "Mario M. Leit\u00e3o",
      "James Kinross",
      "Alvin C. Goh",
      "Bernard J. Park",
      "Matthias Weigl",
      "Rebecca Randell",
      "Steven Yule",
      "Duncan McPherson",
      "Laura Pickup",
      "Richard J. E. Skipworth",
      "Jennifer T. Anger",
      "Denny Yu",
      "Lora Cavuoto",
      "Ann M. Bisantz",
      "Tara Cohen",
      "Mirre Scholte",
      "Guy J. Maddern",
      "Laura Sampietro-Colom",
      "Alane Clark",
      "Tammy Clifford",
      "Bel\u00e9n Corbacho",
      "Cynthia P Iglesias",
      "Janneke P.C. Grutters",
      "Katrina Hutchinson",
      "Lesley Booth",
      "Heather Draper",
      "Len Evans",
      "Sarah Goering",
      "Alexander A. Kon",
      "Rebecca Langley",
      "Rob Sparrow",
      "Kamran Ahmed",
      "Deena Harji",
      "Teodor Grantcharov",
      "Lars Konge",
      "Art Sedrakyan",
      "Joel Horowitz",
      "Arsenio P\u00e1ez",
      "Kamran Ahmed",
      "Deena Harji",
      "Teodor Grantcharov",
      "Lars Konge",
      "Additional collaborators",
      "Art Sedrakyan",
      "Joel Horowitz",
      "Arsenio Paez"
    ],
    "year": 2024,
    "abstract": null,
    "doi": "10.1038/s41591-023-02732-7",
    "url": "https://openalex.org/W4391023377",
    "pdf_url": "https://www.nature.com/articles/s41591-023-02732-7.pdf",
    "venue": "Nature Medicine",
    "citation_count": 112,
    "fields_of_study": [
      "Robotics",
      "Artificial intelligence",
      "Context (archaeology)",
      "Robot",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:13.386843"
  },
  {
    "source": "openalex",
    "source_id": "W4312910656",
    "title": "Efficient Acceleration of Deep Learning Inference on Resource-Constrained Edge Devices: A Review",
    "authors": [
      "Md Maruf Hossain Shuvo",
      "Syed K. Islam",
      "Jianlin Cheng",
      "Bashir I. Morshed"
    ],
    "year": 2022,
    "abstract": "\u00a9 1963-2012 IEEE. cc-by",
    "doi": "10.1109/jproc.2022.3226481",
    "url": "https://openalex.org/W4312910656",
    "pdf_url": "https://ieeexplore.ieee.org/ielx7/5/10015202/09985008.pdf",
    "venue": "Proceedings of the IEEE",
    "citation_count": 268,
    "fields_of_study": [
      "Computer science",
      "Edge device",
      "Cloud computing",
      "Edge computing",
      "Software deployment"
    ],
    "retrieved_at": "2026-02-02T16:58:13.386846"
  },
  {
    "source": "openalex",
    "source_id": "W3134822068",
    "title": "You Can't Sit With Us",
    "authors": [
      "Inioluwa Deborah Raji",
      "Morgan Klaus Scheuerman",
      "Razvan Amironesei"
    ],
    "year": 2021,
    "abstract": "Given a growing concern about the lack of ethical consideration in the Artificial Intelligence (AI) field, many have begun to question how dominant approaches to the disciplinary education of computer science (CS)---and its implications for AI---has led to the current \"ethics crisis\". However, we claim that the current AI ethics education space relies on a form of \"exclusionary pedagogy,\" where ethics is distilled for computational approaches, but there is no deeper epistemological engagement with other ways of knowing that would benefit ethical thinking or an acknowledgement of the limitations of uni-vocal computational thinking. This results in indifference, devaluation, and a lack of mutual support between CS and humanistic social science (HSS), elevating the myth of technologists as \"ethical unicorns\" that can do it all, though their disciplinary tools are ultimately limited. Through an analysis of computer science education literature and a review of college-level course syllabi in AI ethics, we discuss the limitations of the epistemological assumptions and hierarchies of knowledge which dictate current attempts at including ethics education in CS training and explore evidence for the practical mechanisms through which this exclusion occurs. We then propose a shift towards a substantively collaborative, holistic, and ethically generative pedagogy in AI education.",
    "doi": "10.1145/3442188.3445914",
    "url": "https://openalex.org/W3134822068",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3442188.3445914",
    "venue": null,
    "citation_count": 128,
    "fields_of_study": [
      "Acknowledgement",
      "Discipline",
      "Engineering ethics",
      "Syllabus",
      "Philosophy of science"
    ],
    "retrieved_at": "2026-02-02T16:58:13.386851"
  },
  {
    "source": "openalex",
    "source_id": "W4393229110",
    "title": "Ethics and responsible AI deployment",
    "authors": [
      "Petar Radanliev",
      "Omar Santos",
      "Alistair Brandon\u2010Jones",
      "Adam Joinson"
    ],
    "year": 2024,
    "abstract": "As Artificial Intelligence (AI) becomes more prevalent, protecting personal privacy is a critical ethical issue that must be addressed. This article explores the need for ethical AI systems that safeguard individual privacy while complying with ethical standards. By taking a multidisciplinary approach, the research examines innovative algorithmic techniques such as differential privacy, homomorphic encryption, federated learning, international regulatory frameworks, and ethical guidelines. The study concludes that these algorithms effectively enhance privacy protection while balancing the utility of AI with the need to protect personal data. The article emphasises the importance of a comprehensive approach that combines technological innovation with ethical and regulatory strategies to harness the power of AI in a way that respects and protects individual privacy.",
    "doi": "10.3389/frai.2024.1377011",
    "url": "https://openalex.org/W4393229110",
    "pdf_url": "https://www.frontiersin.org/articles/10.3389/frai.2024.1377011/pdf?isPublishedV2=False",
    "venue": "Frontiers in Artificial Intelligence",
    "citation_count": 100,
    "fields_of_study": [
      "Software deployment",
      "Safeguard",
      "Multidisciplinary approach",
      "Engineering ethics",
      "Information privacy"
    ],
    "retrieved_at": "2026-02-02T16:58:13.386871"
  },
  {
    "source": "openalex",
    "source_id": "W4392153984",
    "title": "The potential of generative AI for personalized persuasion at scale",
    "authors": [
      "Sandra Matz",
      "Jacob D. Teeny",
      "Sumer S. Vaid",
      "H. Peters",
      "Gabriella M. Harari",
      "Moran Cerf"
    ],
    "year": 2024,
    "abstract": "Abstract Matching the language or content of a message to the psychological profile of its recipient (known as \u201cpersonalized persuasion\u201d) is widely considered to be one of the most effective messaging strategies. We demonstrate that the rapid advances in large language models (LLMs), like ChatGPT, could accelerate this influence by making personalized persuasion scalable. Across four studies (consisting of seven sub-studies; total N = 1788), we show that personalized messages crafted by ChatGPT exhibit significantly more influence than non-personalized messages. This was true across different domains of persuasion (e.g., marketing of consumer products, political appeals for climate action), psychological profiles (e.g., personality traits, political ideology, moral foundations), and when only providing the LLM with a single, short prompt naming or describing the targeted psychological dimension. Thus, our findings are among the first to demonstrate the potential for LLMs to automate, and thereby scale, the use of personalized persuasion in ways that enhance its effectiveness and efficiency. We discuss the implications for researchers, practitioners, and the general public.",
    "doi": "10.1038/s41598-024-53755-0",
    "url": "https://openalex.org/W4392153984",
    "pdf_url": "https://www.nature.com/articles/s41598-024-53755-0.pdf",
    "venue": "Scientific Reports",
    "citation_count": 160,
    "fields_of_study": [
      "Persuasion",
      "Dimension (graph theory)",
      "Matching (statistics)",
      "Scale (ratio)",
      "Politics"
    ],
    "retrieved_at": "2026-02-02T16:58:13.386885"
  },
  {
    "source": "openalex",
    "source_id": "W3121264940",
    "title": "The Rise and Decline of General Laws of Capitalism",
    "authors": [
      "Daron Acemo\u011flu",
      "James A. Robinson"
    ],
    "year": 2015,
    "abstract": "Thomas Piketty's (2013) book, Capital in the 21st Century, follows in the tradition of the great classical economists, like Marx and Ricardo, in formulating general laws of capitalism to diagnose and predict the dynamics of inequality. We argue that general economic laws are unhelpful as a guide to understanding the past or predicting the future because they ignore the central role of political and economic institutions, as well as the endogenous evolution of technology, in shaping the distribution of resources in society. We use regression evidence to show that the main economic force emphasized in Piketty's book, the gap between the interest rate and the growth rate, does not appear to explain historical patterns of inequality (especially, the share of income accruing to the upper tail of the distribution). We then use the histories of inequality of South Africa and Sweden to illustrate that inequality dynamics cannot be understood without embedding economic factors in the context of economic and political institutions, and also that the focus on the share of top incomes can give a misleading characterization of the true nature of inequality.",
    "doi": "10.1257/jep.29.1.3",
    "url": "https://openalex.org/W3121264940",
    "pdf_url": "https://www.aeaweb.org/articles/pdf/doi/10.1257/jep.29.1.3",
    "venue": "The Journal of Economic Perspectives",
    "citation_count": 313,
    "fields_of_study": [
      "Capitalism",
      "Inequality",
      "Economics",
      "Context (archaeology)",
      "Economic inequality"
    ],
    "retrieved_at": "2026-02-02T16:58:13.386903"
  },
  {
    "source": "openalex",
    "source_id": "W4361185690",
    "title": "ChatGPT for Education and Research: Opportunities, Threats, and Strategies",
    "authors": [
      "Md. Mostafizer Rahman",
      "Yutaka Watanobe"
    ],
    "year": 2023,
    "abstract": "In recent years, the rise of advanced artificial intelligence technologies has had a profound impact on many fields, including education and research. One such technology is ChatGPT, a powerful large language model developed by OpenAI. This technology offers exciting opportunities for students and educators, including personalized feedback, increased accessibility, interactive conversations, lesson preparation, evaluation, and new ways to teach complex concepts. However, ChatGPT poses different threats to the traditional education and research system, including the possibility of cheating on online exams, human-like text generation, diminished critical thinking skills, and difficulties in evaluating information generated by ChatGPT. This study explores potential opportunities and threats that ChatGPT poses to overall education from the perspective of students and educators. Furthermore, for programming learning, we explore how ChatGPT helps students improve their programming skills. To demonstrate this, we conducted different coding-related experiments with ChatGPT, including code generation from problem descriptions, pseudocode generation of algorithms from texts, and code correction. We also verified the generated codes with an online judge system to evaluate their accuracy.",
    "doi": "10.20944/preprints202303.0473.v1",
    "url": "https://openalex.org/W4361185690",
    "pdf_url": "https://www.preprints.org/manuscript/202303.0473/v1/download",
    "venue": "Preprints.org",
    "citation_count": 156,
    "fields_of_study": [
      "Cheating",
      "Computer science",
      "Perspective (graphical)",
      "Coding (social sciences)",
      "Code (set theory)"
    ],
    "retrieved_at": "2026-02-02T16:58:13.386922"
  },
  {
    "source": "openalex",
    "source_id": "W2983996708",
    "title": "Procedural Justice in Algorithmic Fairness",
    "authors": [
      "Min Kyung Lee",
      "Anuraag Jain",
      "Hea Jin",
      "Shashank Kumar Ojha",
      "Daniel Kusbit"
    ],
    "year": 2019,
    "abstract": "As algorithms increasingly take managerial and governance roles, it is ever more important to build them to be perceived as fair and adopted by people. With this goal, we propose a procedural justice framework in algorithmic decision-making drawing from procedural justice theory, which lays out elements that promote a sense of fairness among users. As a case study, we built an interface that leveraged two key elements of the framework---transparency and outcome control---and evaluated it in the context of goods division. Our interface explained the algorithm's allocative fairness properties (standards clarity) and outcomes through an input-output matrix (outcome explanation), then allowed people to interactively adjust the algorithmic allocations as a group (outcome control). The findings from our within-subjects laboratory study suggest that standards clarity alone did not increase perceived fairness; outcome explanation had mixed effects, increasing or decreasing perceived fairness and reducing algorithmic accountability; and outcome control universally improved perceived fairness by allowing people to realize the inherent limitations of decisions and redistribute the goods to better fit their contexts, and by bringing human elements into final decision-making.",
    "doi": "10.1145/3359284",
    "url": "https://openalex.org/W2983996708",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3359284",
    "venue": "Proceedings of the ACM on Human-Computer Interaction",
    "citation_count": 197,
    "fields_of_study": [
      "CLARITY",
      "Outcome (game theory)",
      "Allocative efficiency",
      "Accountability",
      "Transparency (behavior)"
    ],
    "retrieved_at": "2026-02-02T16:58:13.386943"
  },
  {
    "source": "openalex",
    "source_id": "W4391026828",
    "title": "The Challenges of Machine Learning: A Critical Review",
    "authors": [
      "Enrico Barbierato",
      "Alice Gatti"
    ],
    "year": 2024,
    "abstract": "The concept of learning has multiple interpretations, ranging from acquiring knowledge or skills to constructing meaning and social development. Machine Learning (ML) is considered a branch of Artificial Intelligence (AI) and develops algorithms that can learn from data and generalize their judgment to new observations by exploiting primarily statistical methods. The new millennium has seen the proliferation of Artificial Neural Networks (ANNs), a formalism able to reach extraordinary achievements in complex problems such as computer vision and natural language recognition. In particular, designers claim that this formalism has a strong resemblance to the way the biological neurons operate. This work argues that although ML has a mathematical/statistical foundation, it cannot be strictly regarded as a science, at least from a methodological perspective. The main reason is that ML algorithms have notable prediction power although they cannot necessarily provide a causal explanation about the achieved predictions. For example, an ANN could be trained on a large dataset of consumer financial information to predict creditworthiness. The model takes into account various factors like income, credit history, debt, spending patterns, and more. It then outputs a credit score or a decision on credit approval. However, the complex and multi-layered nature of the neural network makes it almost impossible to understand which specific factors or combinations of factors the model is using to arrive at its decision. This lack of transparency can be problematic, especially if the model denies credit and the applicant wants to know the specific reasons for the denial. The model\u2019s \u201cblack box\u201d nature means it cannot provide a clear explanation or breakdown of how it weighed the various factors in its decision-making process. Secondly, this work rejects the belief that a machine can simply learn from data, either in supervised or unsupervised mode, just by applying statistical methods. The process of learning is much more complex, as it requires the full comprehension of a learned ability or skill. In this sense, further ML advancements, such as reinforcement learning and imitation learning denote encouraging similarities to similar cognitive skills used in human learning.",
    "doi": "10.3390/electronics13020416",
    "url": "https://openalex.org/W4391026828",
    "pdf_url": "https://www.mdpi.com/2079-9292/13/2/416/pdf?version=1705653285",
    "venue": "Electronics",
    "citation_count": 131,
    "fields_of_study": [
      "Artificial intelligence",
      "Artificial neural network",
      "Machine learning",
      "Computer science",
      "Denial"
    ],
    "retrieved_at": "2026-02-02T16:58:13.386961"
  },
  {
    "source": "openalex",
    "source_id": "W3206204366",
    "title": "Enablers and Inhibitors of AI-Powered Voice Assistants: A Dual-Factor Approach by Integrating the Status Quo Bias and Technology Acceptance Model",
    "authors": [
      "Janarthanan Balakrishnan",
      "Yogesh K. Dwivedi",
      "Laurie Hughes",
      "Fr\u00e9d\u00e9ric Boy"
    ],
    "year": 2021,
    "abstract": null,
    "doi": "10.1007/s10796-021-10203-y",
    "url": "https://openalex.org/W3206204366",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10796-021-10203-y.pdf",
    "venue": "Information Systems Frontiers",
    "citation_count": 144,
    "fields_of_study": [
      "Status quo bias",
      "Status quo",
      "Regret",
      "Value (mathematics)",
      "Psychology"
    ],
    "retrieved_at": "2026-02-02T16:58:13.386996"
  },
  {
    "source": "openalex",
    "source_id": "W2900379068",
    "title": "Data Science as Political Action: Grounding Data Science in a Politics of Justice",
    "authors": [
      "Ben Green"
    ],
    "year": 2021,
    "abstract": "In response to public scrutiny of data-driven algorithms, the field of data science has adopted ethics training and principles. Although ethics can help data scientists reflect on certain normative aspects of their work, such efforts are ill-equipped to generate a data science that avoids social harms and promotes social justice. In this article, I argue that data science must embrace a political orientation. Data scientists must recognize themselves as political actors engaged in normative constructions of society and evaluate their work according to its downstream impacts on people's lives. I first articulate why data scientists must recognize themselves as political actors. In this section, I respond to three arguments that data scientists commonly invoke when challenged to take political positions regarding their work. In confronting these arguments, I describe why attempting to remain apolitical is itself a political stance--a fundamentally conservative one--and why data science's attempts to promote \"social good\" dangerously rely on unarticulated and incrementalist political assumptions. I then propose a framework for how data science can evolve toward a deliberative and rigorous politics of social justice. I conceptualize the process of developing a politically engaged data science as a sequence of four stages. Pursuing these new approaches will empower data scientists with new methods for thoughtfully and rigorously contributing to social justice.",
    "doi": "10.23919/jsc.2021.0029",
    "url": "https://openalex.org/W2900379068",
    "pdf_url": "https://ieeexplore.ieee.org/ielx7/8964404/9684739/09684742.pdf",
    "venue": "Journal of Social Computing",
    "citation_count": 114,
    "fields_of_study": [
      "Politics",
      "Scrutiny",
      "Normative",
      "Sociology",
      "Epistemology"
    ],
    "retrieved_at": "2026-02-02T16:58:13.386999"
  },
  {
    "source": "openalex",
    "source_id": "W4390584313",
    "title": "A Conceptual Model for Inclusive Technology: Advancing Disability Inclusion through Artificial Intelligence",
    "authors": [
      "Maram Fahaad Almufareh",
      "Sumaira Kausar",
      "Mamoona Humayun",
      "Samabia Tehsin"
    ],
    "year": 2024,
    "abstract": "Artificial intelligence (AI) has ushered in transformative changes, championing inclusion and accessibility for individuals with disabilities. This article delves into the remarkable AI-driven solutions that have revolutionized their lives across various domains. From assistive technologies such as voice recognition and AI-powered smart glasses catering to diverse needs, to healthcare benefiting from early disease detection algorithms and wearable devices that monitor vital signs and alert caregivers in emergencies, AI has steered in significant enhancements. Moreover, AI-driven prosthetics and exoskeletons have substantially improved mobility for those with limb impairments. The realm of education has not been left untouched, with AI tools creating inclusive learning environments that adapt to individual learning styles, paving the way for academic success among students with disabilities. However, the boundless potential of AI also presents ethical concerns and challenges. Issues like safeguarding data privacy, mitigating algorithmic bias, and bridging the digital divide must be thoughtfully addressed to fully harness AI\u2019s potential in empowering individuals with disabilities. To complement these achievements, a robust conceptual model for AI disability inclusion serves as the theoretical framework, guiding the development of tailored AI solutions. By striking a harmonious balance between innovation and ethics, AI has the power to significantly enhance the overall quality of life for individuals with disabilities across a spectrum of vital areas.",
    "doi": "10.57197/jdr-2023-0060",
    "url": "https://openalex.org/W4390584313",
    "pdf_url": "https://www.scienceopen.com/document_file/10696e8f-ab40-4c4f-be70-09fda6533ae8/ScienceOpen/jdr20230060.pdf",
    "venue": "Journal of Disability Research",
    "citation_count": 103,
    "fields_of_study": [
      "Inclusion (mineral)",
      "Safeguarding",
      "Transformative learning",
      "Realm",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387022"
  },
  {
    "source": "openalex",
    "source_id": "W3001779409",
    "title": "Stigma, biomarkers, and algorithmic bias: recommendations for precision behavioral health with artificial intelligence",
    "authors": [
      "Colin G. Walsh",
      "Beenish Moalla Chaudhry",
      "Prerna Dua",
      "Kenneth W. Goodman",
      "Bonnie J. Kaplan",
      "Ramakanth Kavuluru",
      "Anthony Solomonides",
      "Vignesh Subbian"
    ],
    "year": 2020,
    "abstract": "Abstract Effective implementation of artificial intelligence in behavioral healthcare delivery depends on overcoming challenges that are pronounced in this domain. Self and social stigma contribute to under-reported symptoms, and under-coding worsens ascertainment. Health disparities contribute to algorithmic bias. Lack of reliable biological and clinical markers hinders model development, and model explainability challenges impede trust among users. In this perspective, we describe these challenges and discuss design and implementation recommendations to overcome them in intelligent systems for behavioral and mental health.",
    "doi": "10.1093/jamiaopen/ooz054",
    "url": "https://openalex.org/W3001779409",
    "pdf_url": "https://academic.oup.com/jamiaopen/article-pdf/3/1/9/33419078/ooz054.pdf",
    "venue": "JAMIA Open",
    "citation_count": 111,
    "fields_of_study": [
      "Stigma (botany)",
      "Artificial intelligence",
      "Psychology",
      "Computer science",
      "Machine learning"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387045"
  },
  {
    "source": "openalex",
    "source_id": "W4380988459",
    "title": "Artificial Intelligence &amp; Creativity: A Manifesto for Collaboration",
    "authors": [
      "Florent Vinchon",
      "Todd Lubart",
      "Sabrina Bartolotta",
      "Valentin Gironnay",
      "Marion Botella",
      "Samira Bourgeois\u2010Bougrine",
      "Jean\u2010Marie Burkhardt",
      "Nathalie Bonnardel",
      "Giovanni Emanuele Corazza",
      "Vlad Petre Gl\u0103veanu",
      "Michael Hanchett Hanson",
      "Zorana Iv\u010devi\u0107",
      "Maciej Karwowski",
      "James C. Kaufman",
      "Takeshi Okada",
      "Roni Reiter\u2010Palmon",
      "Andrea Gaggioli"
    ],
    "year": 2023,
    "abstract": "ABSTRACT With the advent of artificial intelligence (AI), the field of creativity faces new opportunities and challenges. This manifesto explores several scenarios of human\u2013machine collaboration on creative tasks and proposes \u201cfundamental laws of generative AI\u201d to reinforce the responsible and ethical use of AI in the creativity field. Four scenarios are proposed and discussed: \u201cCo\u2010Cre\u2010AI\u2010tion,\u201d \u201cOrganic,\u201d \u201cPlagiarism 3.0,\u201d and \u201cShut down,\u201d each illustrating different possible futures based on the collaboration between humans and machines. In addition, we have incorporated an AI\u2010generated manifesto that also highlights important themes, ranging from accessibility and ethics to cultural sensitivity. The fundamental laws proposed aim to prevent AIs from generating harmful content and competing directly with humans. Creating labels and laws are also highlighted to ensure responsible use of AIs. The positive future of creativity and AI lies in a harmonious collaboration that can benefit everyone, potentially leading to a new level of creative productivity respecting ethical considerations and human values during the creative process.",
    "doi": "10.1002/jocb.597",
    "url": "https://openalex.org/W4380988459",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/jocb.597",
    "venue": "The Journal of Creative Behavior",
    "citation_count": 165,
    "fields_of_study": [
      "Manifesto",
      "Creativity",
      "Field (mathematics)",
      "Generative grammar",
      "Productivity"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387057"
  },
  {
    "source": "openalex",
    "source_id": "W4205865577",
    "title": "Operationalizing and Implementing Pretrained, Large Artificial Intelligence Linguistic Models in the US Health Care System: Outlook of Generative Pretrained Transformer 3 (GPT-3) as a Service Model",
    "authors": [
      "Emre Sezg\u0131n",
      "Joseph Sirrianni",
      "Simon Lin Linwood"
    ],
    "year": 2022,
    "abstract": "Generative pretrained transformer models have been popular recently due to their enhanced capabilities and performance. In contrast to many existing artificial intelligence models, generative pretrained transformer models can perform with very limited training data. Generative pretrained transformer 3 (GPT-3) is one of the latest releases in this pipeline, demonstrating human-like logical and intellectual responses to prompts. Some examples include writing essays, answering complex questions, matching pronouns to their nouns, and conducting sentiment analyses. However, questions remain with regard to its implementation in health care, specifically in terms of operationalization and its use in clinical practice and research. In this viewpoint paper, we briefly introduce GPT-3 and its capabilities and outline considerations for its implementation and operationalization in clinical practice through a use case. The implementation considerations include (1) processing needs and information systems infrastructure, (2) operating costs, (3) model biases, and (4) evaluation metrics. In addition, we outline the following three major operational factors that drive the adoption of GPT-3 in the US health care system: (1) ensuring Health Insurance Portability and Accountability Act compliance, (2) building trust with health care providers, and (3) establishing broader access to the GPT-3 tools. This viewpoint can inform health care practitioners, developers, clinicians, and decision makers toward understanding the use of the powerful artificial intelligence tools integrated into hospital systems and health care.",
    "doi": "10.2196/32875",
    "url": "https://openalex.org/W4205865577",
    "pdf_url": "https://medinform.jmir.org/2022/2/e32875/PDF",
    "venue": "JMIR Medical Informatics",
    "citation_count": 121,
    "fields_of_study": [
      "Operationalization",
      "Computer science",
      "Software portability",
      "Generative grammar",
      "Health Insurance Portability and Accountability Act"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387075"
  },
  {
    "source": "openalex",
    "source_id": "W3037207300",
    "title": "Should You Fine-Tune BERT for Automated Essay Scoring?",
    "authors": [
      "Elijah Mayfield",
      "Alan W. Black"
    ],
    "year": 2020,
    "abstract": "Most natural language processing research now recommends large Transformer-based models with fine-tuning for supervised classification tasks; older strategies like bag-of-words features and linear models have fallen out of favor. Here we investigate whether, in automated essay scoring (AES) research, deep neural models are an appropriate technological choice. We find that fine-tuning BERT produces similar performance to classical models at significant additional cost. We argue that while state-of-the-art strategies do match existing best results, they come with opportunity costs in computational resources. We conclude with a review of promising areas for research on student essays where the unique characteristics of Transformers may provide benefits over classical methods to justify the costs.",
    "doi": "10.18653/v1/2020.bea-1.15",
    "url": "https://openalex.org/W3037207300",
    "pdf_url": "https://www.aclweb.org/anthology/2020.bea-1.15.pdf",
    "venue": null,
    "citation_count": 119,
    "fields_of_study": [
      "Transformer",
      "Computer science",
      "Artificial intelligence",
      "Deep neural networks",
      "Machine learning"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387096"
  },
  {
    "source": "openalex",
    "source_id": "W3039283728",
    "title": "Inclusive Economic Sustainability: SDGs and Global Inequality",
    "authors": [
      "Arno J van Niekerk"
    ],
    "year": 2020,
    "abstract": "In view of the 2020 global health crisis and its repercussions on the global economy, the need to redirect conventional economic thinking towards securing global economic sustainability is most critical. The Sustainable Development Goals (SDGs) are a significant move in this direction. However, in the past few years, a clearer understanding of inclusive economics and sustainability indicators have progressed our ability to reduce economic exclusion, chiefly represented by global inequality. Collective wellbeing within the \u201cglobal village\u201d is shaped largely by these avenues/directions, thus presenting the question: can an improved combination of sustainability priorities be identified that would substantially enhance countries\u2019 adoption of the SDGs? New, inclusive paths to economic progress are essential to a world economy in crisis recovery mode. The aim of the paper is to qualitatively identify key indicators from these different directions to, collectively, address some of the most significant drivers of global inequality, thus improving the adoption rate of the SDGs. As its main contribution, the study found that for economic inclusivity to realistically reduce global inequality its full integration into three areas is necessary: business models, public policy and community development. This should also be supported by \u201csocial covenants\u201d to facilitate improved SDG adoption by countries.",
    "doi": "10.3390/su12135427",
    "url": "https://openalex.org/W3039283728",
    "pdf_url": "https://www.mdpi.com/2071-1050/12/13/5427/pdf?version=1594000965",
    "venue": "Sustainability",
    "citation_count": 175,
    "fields_of_study": [
      "Sustainability",
      "Inequality",
      "Sustainable development",
      "Social sustainability",
      "Economic inequality"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387111"
  },
  {
    "source": "openalex",
    "source_id": "W4388007985",
    "title": "The Participatory Turn in AI Design: Theoretical Foundations and the Current State of Practice",
    "authors": [
      "Fernando Delgado",
      "Stephen Yang",
      "Michael Madaio",
      "Qian Yang"
    ],
    "year": 2023,
    "abstract": "Despite the growing consensus that stakeholders affected by AI systems should participate in their design, enormous variation and implicit disagreements exist among current approaches. For researchers and practitioners who are interested in taking a participatory approach to AI design and development, it remains challenging to assess the extent to which any participatory approach grants substantive agency to stakeholders. This article thus aims to ground what we dub the \"participatory turn\" in AI design by synthesizing existing theoretical literature on participation and through empirical investigation and critique of its current practices. Specifically, we derive a conceptual framework through synthesis of literature across technology design, political theory, and the social sciences that researchers and practitioners can leverage to evaluate approaches to participation in AI design. Additionally, we articulate empirical findings concerning the current state of participatory practice in AI design based on an analysis of recently published research and semi-structured interviews with 12 AI researchers and practitioners. We use these empirical findings to understand the current state of participatory practice and subsequently provide guidance to better align participatory goals and methods in a way that accounts for practical constraints.",
    "doi": "10.1145/3617694.3623261",
    "url": "https://openalex.org/W4388007985",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3617694.3623261",
    "venue": null,
    "citation_count": 136,
    "fields_of_study": [
      "Current (fluid)",
      "Turn (biochemistry)",
      "State (computer science)",
      "Participatory design",
      "Citizen journalism"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387132"
  },
  {
    "source": "openalex",
    "source_id": "W4391579939",
    "title": "A CRITICAL REVIEW OF AI-DRIVEN STRATEGIES FOR ENTREPRENEURIAL SUCCESS",
    "authors": [
      "Favour Oluwadamilare Usman",
      "Nsisong Louis Eyo-Udo",
      "Emmanuel Augustine Etukudoh",
      "Beryl Odonkor",
      "Chidera Victoria Ibeh",
      "Ayodeji Adegbola"
    ],
    "year": 2024,
    "abstract": "In the rapidly evolving landscape of entrepreneurship, the integration of Artificial Intelligence (AI) has emerged as a transformative force, reshaping traditional business paradigms and offering unprecedented opportunities for success. This paper provides a comprehensive and critical review of AI-driven strategies employed by entrepreneurs to enhance their ventures. The review encompasses a thorough analysis of key AI applications, their impact on various aspects of entrepreneurship, and the potential benefits and challenges associated with their implementation. The first section explores the role of AI in market analysis, highlighting how advanced data analytics and predictive modelling contribute to informed decision-making and market forecasting. The discussion then extends to AI-driven innovations in product development, emphasizing the acceleration of ideation, prototyping, and customization through machine learning algorithms. Next, the paper scrutinizes the influence of AI on customer engagement and relationship management. It delves into the personalized customer experiences facilitated by chatbots, recommendation systems, and sentiment analysis, while also addressing ethical considerations surrounding data privacy and algorithmic biases. Entrepreneurial operations and efficiency gains are examined in the subsequent section, emphasizing AI's impact on supply chain management, logistics, and resource optimization. The review underscores the potential for increased productivity and cost-effectiveness through the implementation of AI-powered automation and smart systems. Despite the myriad advantages, the paper critically examines challenges such as ethical concerns, job displacement, and the digital divide. It emphasizes the need for a balanced approach that addresses the societal impact of AI adoption while fostering inclusive entrepreneurial ecosystems. In conclusion, this critical review not only provides a comprehensive overview of the current landscape of AI-driven strategies in entrepreneurship but also offers insights into the potential future developments and challenges. Entrepreneurs, policymakers, and researchers can leverage this analysis to navigate the evolving intersection of AI and entrepreneurship, fostering a sustainable and ethically sound environment for entrepreneurial success in the digital era. Keywords: Artificial Intelligence (AI), Entrepreneurship, Strategic Implementation, Innovation, Market Analysis, Predictive Modelling.",
    "doi": "10.51594/ijmer.v6i1.748",
    "url": "https://openalex.org/W4391579939",
    "pdf_url": "https://fepbl.com/index.php/ijmer/article/download/748/939",
    "venue": "International Journal of Management & Entrepreneurship Research",
    "citation_count": 95,
    "fields_of_study": [
      "Critical success factor",
      "Psychology",
      "Computer science",
      "Knowledge management"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387150"
  },
  {
    "source": "openalex",
    "source_id": "W4386525386",
    "title": "Perceptions and Acceptance of Artificial Intelligence: A Multi-Dimensional Study",
    "authors": [
      "Michael Gerlich"
    ],
    "year": 2023,
    "abstract": "In this comprehensive study, insights from 1389 scholars across the US, UK, Germany, and Switzerland shed light on the multifaceted perceptions of artificial intelligence (AI). AI\u2019s burgeoning integration into everyday life promises enhanced efficiency and innovation. The Trustworthy AI principles by the European Commission, emphasising data safeguarding, security, and judicious governance, serve as the linchpin for AI\u2019s widespread acceptance. A correlation emerged between societal interpretations of AI\u2019s impact and elements like trustworthiness, associated risks, and usage/acceptance. Those discerning AI\u2019s threats often view its prospective outcomes pessimistically, while proponents recognise its transformative potential. These inclinations resonate with trust and AI\u2019s perceived singularity. Consequently, factors such as trust, application breadth, and perceived vulnerabilities shape public consensus, depicting AI as humanity\u2019s boon or bane. The study also accentuates the public\u2019s divergent views on AI\u2019s evolution, underlining the malleability of opinions amidst polarising narratives.",
    "doi": "10.3390/socsci12090502",
    "url": "https://openalex.org/W4386525386",
    "pdf_url": "https://www.mdpi.com/2076-0760/12/9/502/pdf?version=1694056018",
    "venue": "Social Sciences",
    "citation_count": 125,
    "fields_of_study": [
      "Safeguarding",
      "Trustworthiness",
      "Transformative learning",
      "Perception",
      "Psychology"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387180"
  },
  {
    "source": "openalex",
    "source_id": "W2957812729",
    "title": "Beyond the hype of big data and artificial intelligence: building foundations for knowledge and wisdom",
    "authors": [
      "Josip Car",
      "Aziz Sheikh",
      "Paul Wicks",
      "Marc S. Williams"
    ],
    "year": 2019,
    "abstract": null,
    "doi": "10.1186/s12916-019-1382-x",
    "url": "https://openalex.org/W2957812729",
    "pdf_url": "https://bmcmedicine.biomedcentral.com/track/pdf/10.1186/s12916-019-1382-x",
    "venue": "BMC Medicine",
    "citation_count": 124,
    "fields_of_study": [
      "Big data",
      "Health care",
      "Medicine",
      "Data sharing",
      "Data science"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387199"
  },
  {
    "source": "openalex",
    "source_id": "W3197217312",
    "title": "Digitalization, accounting and accountability: A literature review and reflections on future research in public services",
    "authors": [
      "Deborah Agostino",
      "Iris Saliterer",
      "Ileana Steccolini"
    ],
    "year": 2021,
    "abstract": "Abstract This study discusses the current state of the art and future directions of research on digitalization, accountability, and accounting in public services. Through a systematic literature review, we investigate 232 articles published between 1998 and the first quarter of 2020. These studies are analyzed looking at the implications of the increasing digitalization of the public realm for the (i) production of data, (ii) consumption of data, and (iii) their subsequent effects. Based upon this analysis, we identify the following emerging critical digital accountability issues and related future research avenues: the potential for dialogic and horizontal, multicentric accountability; the blurring of accountability roles and boundaries; the increasing relevance of translation processes and translators\u2019 roles\u2014and the need to ensure accountability in such translations; the need to pay stronger attention to social equity and inclusivity implications of digitalization.",
    "doi": "10.1111/faam.12301",
    "url": "https://openalex.org/W3197217312",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/faam.12301",
    "venue": "Financial Accountability and Management",
    "citation_count": 226,
    "fields_of_study": [
      "Accountability",
      "Realm",
      "Social accounting",
      "Public relations",
      "Political science"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387202"
  },
  {
    "source": "openalex",
    "source_id": "W3153254740",
    "title": "Digitalization and AI in European Agriculture: A Strategy for Achieving Climate and Biodiversity Targets?",
    "authors": [
      "Beatrice Garske",
      "Antonia Bau",
      "Felix Ekardt"
    ],
    "year": 2021,
    "abstract": "This article analyzes the environmental opportunities and limitations of digitalization in the agricultural sector by applying qualitative governance analysis. Agriculture is recognized as a key application area for digital technologies, including artificial intelligence. This is not least because it faces major sustainability challenges, especially with regard to meeting the climate and biodiversity targets set out in the Paris Agreement and the Convention on Biological Diversity, as well as the water-related objectives of EU environmental legislation. Based on an overview of the possible applications of digital technologies in agriculture, the article offers a status quo analysis of legal acts with relevance to digitalization in the EU agricultural sector. It is found that a reliable legal framework with regard to product liability and product safety, as well as data privacy, data access, and data security is important in this context. In addition, the European Common Agricultural Policy, as the most important funding instrument for digital innovations in the agricultural sector, should be designed in such a way that it links digitalization-related objectives more closely with sustainability targets. So far, the existing EU governance does not fully exploit the potentials of digitalization for environmental protection, and sight is lost of possible negative side effects such as rebound and shifting effects. Therefore, the article also offers proposals for the optimization of EU governance.",
    "doi": "10.3390/su13094652",
    "url": "https://openalex.org/W3153254740",
    "pdf_url": "https://www.mdpi.com/2071-1050/13/9/4652/pdf?version=1619075255",
    "venue": "Sustainability",
    "citation_count": 121,
    "fields_of_study": [
      "Sustainability",
      "European union",
      "Business",
      "Context (archaeology)",
      "Agriculture"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387217"
  },
  {
    "source": "openalex",
    "source_id": "W3121927947",
    "title": "Human-Centered Artificial Intelligence for Designing Accessible Cultural Heritage",
    "authors": [
      "Galena Pisoni",
      "Natalia D\u00edaz-Rodr\u00edguez",
      "Hannie Gijlers",
      "Linda Tonolli"
    ],
    "year": 2021,
    "abstract": "This paper reviews the literature concerning technology used for creating and delivering accessible museum and cultural heritage sites experiences. It highlights the importance of the delivery suited for everyone from different areas of expertise, namely interaction design, pedagogical and participatory design, and it presents how recent and future artificial intelligence (AI) developments can be used for this aim, i.e.,improving and widening online and in situ accessibility. From the literature review analysis, we articulate a conceptual framework that incorporates key elements that constitute museum and cultural heritage online experiences and how these elements are related to each other. Concrete opportunities for future directions empirical research for accessibility of cultural heritage contents are suggested and further discussed.",
    "doi": "10.3390/app11020870",
    "url": "https://openalex.org/W3121927947",
    "pdf_url": "https://www.mdpi.com/2076-3417/11/2/870/pdf?version=1611229675",
    "venue": "Applied Sciences",
    "citation_count": 144,
    "fields_of_study": [
      "Cultural heritage",
      "Citizen journalism",
      "Engineering",
      "Engineering ethics",
      "Sociology"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387239"
  },
  {
    "source": "openalex",
    "source_id": "W4300960556",
    "title": "Technology, Megatrends and Work: Thoughts on the Future of Business Ethics",
    "authors": [
      "Premilla D\u2019Cruz",
      "Shuili Du",
      "Ernesto Noronha",
      "K. Praveen Parboteeah",
      "Hannah Trittin\u2010Ulbrich",
      "Glen Whelan"
    ],
    "year": 2022,
    "abstract": "Abstract To commemorate 40 years since the founding of the Journal of Business Ethics, the editors in chief of the journal have invited the editors to provide commentaries on the future of business ethics. This essay comprises a selection of commentaries aimed at creating dialogue around the theme Technology, Megatrends and Work . Of all the profound changes in business, technology is perhaps the most ubiquitous. There is not a facet of our lives unaffected by internet technologies and artificial intelligence. The Journal of Business Ethics established a dedicated section that focuses on Technology and Business Ethics, yet issues related to this phenomenon run right through all the sections. Kirsten Martin, editor of the Technology and Business Ethics section, joins our interim social media editor, Hannah Trittin-UIbrich, to advance a human-centric approach to the development and application of digital technologies that places Business Ethics at centre of the analysis. For Shuili Du, technology is the defining condition for a new era of Corporate Social Responsibility\u2014CSR 3.0\u2014which she defines as \u201ca company\u2019s socially responsible strategies and practices that deal with key ethical and socio-technical issues associated with AI and related technologies on the one hand and leverage the power of AI and related technologies to tackle social and environmental problems on the other hand.\u201d It is not just technologies that are a determining feature of our lives but technology companies, an argument made by Glen Whelan as he examines Big Business and the need for a Big Business Ethics as we try to understand the impact of Big Tech on our post-work world. Indeed, as noted by Ernesto Noronha and Premilla D\u2019Cruz, megatrends in addition to advancement in technologies, namely globalization, the greening of economies, and changes in demographics and migration, are shaping the future for workers in ways previously unimaginable. Contributing to this important debate, Praveen Parboteeah considers the influence of another longstanding but oft overlooked megatrend, the role of religion in the workplace. Given the enormity of the influence of technology and other megatrends in our world, it is not surprising that this essay introduces ground-breaking ideas that speak to the future of business ethics research.",
    "doi": "10.1007/s10551-022-05240-9",
    "url": "https://openalex.org/W4300960556",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10551-022-05240-9.pdf",
    "venue": "Journal of Business Ethics",
    "citation_count": 98,
    "fields_of_study": [
      "Business ethics",
      "Quality of Life Research",
      "Work (physics)",
      "Engineering ethics",
      "Sociology"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387252"
  },
  {
    "source": "openalex",
    "source_id": "W4366588310",
    "title": "Human and artificial intelligence collaboration for socially shared regulation in learning",
    "authors": [
      "Sanna J\u00e4rvel\u00e4",
      "Andy Nguyen",
      "Allyson F. Hadwin"
    ],
    "year": 2023,
    "abstract": "Abstract Artificial intelligence (AI) has generated a plethora of new opportunities, potential and challenges for understanding and supporting learning. In this paper, we position human and AI collaboration for socially shared regulation (SSRL) in learning. Particularly, this paper reflects on the intersection of human and AI collaboration in SSRL research, which presents an exciting prospect for advancing our understanding and support of learning regulation. Our aim is to operationalize this human\u2010AI collaboration by introducing a novel trigger concept and a hybrid human\u2010AI shared regulation in learning (HASRL) model. Through empirical examples that present AI affordances for SSRL research, we demonstrate how humans and AI can synergistically work together to improve learning regulation. We argue that the integration of human and AI strengths via hybrid intelligence is critical to unlocking a new era in learning sciences research. Our proposed frameworks present an opportunity for empirical evidence and innovative designs that articulate the potential for human\u2010AI collaboration in facilitating effective SSRL in teaching and learning. Practitioner notes What is already known about this topic For collaborative learning to succeed, socially shared regulation has been acknowledged as a key factor. Artificial intelligence (AI) is a powerful and potentially disruptive technology that can reveal new insights to support learning. It is questionable whether traditional theories of how people learn are useful in the age of AI. What this paper adds Introduces a trigger concept and a hybrid Human\u2010AI Shared Regulation in Learning (HASRL) model to offer insights into how the human\u2010AI collaboration could occur to operationalize SSRL research. Demonstrates the potential use of AI to advance research and practice on socially shared regulation of learning. Provides clear suggestions for future human\u2010AI collaboration in learning and teaching aiming at enhancing human learning and regulatory skills. Implications for practice and/or policy Educational technology developers could utilize our proposed framework to better align technological and theoretical aspects for their design of adaptive support that can facilitate students' socially shared regulation of learning. Researchers and practitioners could benefit from methodological development incorporating human\u2010AI collaboration for capturing, processing and analysing multimodal data to examine and support learning regulation.",
    "doi": "10.1111/bjet.13325",
    "url": "https://openalex.org/W4366588310",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/bjet.13325",
    "venue": "British Journal of Educational Technology",
    "citation_count": 198,
    "fields_of_study": [
      "Operationalization",
      "Affordance",
      "Artificial intelligence",
      "Computer science",
      "Human intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387287"
  },
  {
    "source": "openalex",
    "source_id": "W4385417140",
    "title": "\u0397ow to Use Artificial Intelligence (AI) as a Resource, Methodological and Analysis Tool in Qualitative Research?",
    "authors": [
      "Prokopis Christou"
    ],
    "year": 2023,
    "abstract": "Artificial Intelligence (AI) has had far-reaching effects in research and the academic world. It has been used in many ways by the scientific community within the context of qualitative research, such as literature and systematic reviews, for conceptualization purposes, thematic and content analysis. It has however prompted concerns and questions about the potential for unreliable research, bias, and unethical behavior in the outcomes of AI-produced research. The purpose this paper is to examine the current use of AI in research, its strengths and limitations, dilemmas and ethical considerations from theoretical critical perspective principles, while delivering five key considerations for the appropriate, rigorous, and reliable use of AI in research practice. The first step is to become acquainted with the data generated by AI systems. The second is concerned with removing biased content and addressing ethical concerns when using AI, while the third is concerned with cross-referencing information generated by AI. The fourth step is to control the analysis process. The fifth and most important key consideration is the demonstration of cognitive input and skills by the researcher throughout the process of using AI in any qualitative research study and in reaching conclusions.",
    "doi": "10.46743/2160-3715/2023.6406",
    "url": "https://openalex.org/W4385417140",
    "pdf_url": "https://nsuworks.nova.edu/cgi/viewcontent.cgi?article=6406&context=tqr",
    "venue": "The Qualitative Report",
    "citation_count": 89,
    "fields_of_study": [
      "Conceptualization",
      "Qualitative research",
      "Thematic analysis",
      "Process (computing)",
      "Context (archaeology)"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387324"
  },
  {
    "source": "openalex",
    "source_id": "W4381684347",
    "title": "The Power of Artificial Intelligence in Recruitment: An Analytical Review of Current AI-Based Recruitment Strategies",
    "authors": [
      "Wael Abdulrahman Albassam"
    ],
    "year": 2023,
    "abstract": "Purpose: The aim of this study is to contribute to the understanding of the power of artificial intelligence (AI) in recruitment and to highlight the opportunities and challenges associated with its use. Theoretical framework: This paper provides a comprehensive analytical review of current AI-based recruitment strategies, drawing on both academic research and industry reports. Design/methodology/approach: The paper critically evaluates the potential benefits and drawbacks of using AI in recruitment and assesses the effectiveness of various AI-based recruitment strategies. Findings: The results indicate that AI-based recruitment strategies such as resume screening, candidate matching, video interviewing, chatbots, predictive analytics, gamification, virtual reality assessments, and social media screening offer significant potential benefits for organizations, including improved efficiency, cost savings, and better-quality hires. However, the use of AI in recruitment also raises ethical and legal concerns, including the potential for algorithmic bias and discrimination. Research, Practical &amp; Social implications: The study concludes by emphasizing the need for further research and development to ensure that AI-based recruitment strategies are effective, unbiased, and aligned with ethical and legal standards. Originality/value: The value of the study lies in its comprehensive exploration of AI in recruitment, synthesizing insights from academic and industry perspectives, and assessing the balance of potential benefits against ethical and legal concerns.",
    "doi": "10.26668/businessreview/2023.v8i6.2089",
    "url": "https://openalex.org/W4381684347",
    "pdf_url": "https://doi.org/10.26668/businessreview/2023.v8i6.2089",
    "venue": "International Journal of Professional Business Review",
    "citation_count": 81,
    "fields_of_study": [
      "Originality",
      "Value (mathematics)",
      "Quality (philosophy)",
      "Ethical issues",
      "Applications of artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387343"
  },
  {
    "source": "openalex",
    "source_id": "W4391820410",
    "title": "Digital transformation: A multidisciplinary perspective and future research agenda",
    "authors": [
      "Justin Paul",
      "Akiko Ueno",
      "Charles Dennis",
      "Eleftherios Alamanos",
      "Lucill J. Curtis",
      "Pantea Foroudi",
      "Agnieszka Kacprzak",
      "Werner H. Kunz",
      "Jonathan Liu",
      "Reza Marvi",
      "Sree Lekshmi Sreekumaran Nair",
      "Ozlem Ozdemir",
      "Eleonora Pantano",
      "\u0398\u03ac\u03bd\u03bf\u03c2 \u03a0\u03b1\u03c0\u03b1\u03b4\u03cc\u03c0\u03bf\u03c5\u03bb\u03bf\u03c2",
      "Olivia Petit",
      "Sapna Tyagi",
      "Jochen Wirtz"
    ],
    "year": 2024,
    "abstract": "Abstract Digital transformation has had an unprecedented influence on all sectors of business over the last decade. We are now entering an era characterized by the extensive digital transformation of businesses, society, and consumers. Therefore, digital transformation has become a pivotal focus for organizations across various sectors in recent years. Despite differing scholarly perspectives on the concept and elements of digital transformation, a consensus exists that it significantly impacts consumer decisions and necessitates organizational adaptation. Recent challenges such as the COVID\u201019 pandemic have further accelerated the need for digital transformation and its effects on consumers. This necessitates an editorial perspective on this most important topic to establish future research agenda encompassing the various dimensions of digital transformation. The purpose of this editorial perspective is to review research on digital transformation from a multidisciplinary viewpoint and provide insights into several key domains\u2014Internet\u2010of\u2010Things, social media, mobile apps, artificial intelligence, augmented and virtual reality, the metaverse, and corporate digital responsibility\u2014that are poised to fuel the pace of digital transformation. Each domain is analyzed through a lens of introduction, role, importance, multifaceted impact, and conclusions. Future research directions are suggested.",
    "doi": "10.1111/ijcs.13015",
    "url": "https://openalex.org/W4391820410",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/ijcs.13015",
    "venue": "International Journal of Consumer Studies",
    "citation_count": 141,
    "fields_of_study": [
      "Digital transformation",
      "Pace",
      "Multidisciplinary approach",
      "Perspective (graphical)",
      "Social media"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387365"
  },
  {
    "source": "openalex",
    "source_id": "W2971581810",
    "title": "Responsible AI: requirements and challenges",
    "authors": [
      "Malik Ghallab"
    ],
    "year": 2019,
    "abstract": null,
    "doi": "10.1186/s42467-019-0003-z",
    "url": "https://openalex.org/W2971581810",
    "pdf_url": "https://aiperspectives.springeropen.com/track/pdf/10.1186/s42467-019-0003-z",
    "venue": "AI Perspectives",
    "citation_count": 106,
    "fields_of_study": [
      "Interdependence",
      "Position paper",
      "Risk analysis (engineering)",
      "Position (finance)",
      "Business"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387384"
  },
  {
    "source": "openalex",
    "source_id": "W4392394652",
    "title": "Generative Artificial Intelligence in Education: From Deceptive to Disruptive.",
    "authors": [
      "Marc Alier",
      "Francisco Jos\u00e9 Garc\u00eda\u2010Pe\u00f1alvo",
      "Jorge D. Camba"
    ],
    "year": 2024,
    "abstract": "Generative Artificial Intelligence (GenAI) has emerged as a promising technology that can create original content, such as text, images, and sound. The use of GenAI in educational settings is becoming increasingly popular and offers a range of opportunities and challenges. This special issue explores the management and integration of GenAI in educational settings, including the ethical considerations, best practices, and opportunities. The potential of GenAI in education is vast. By using algorithms and data, GenAI can create original content that can be used to augment traditional teaching methods, creating a more interactive and personalized learning experience. In addition, GenAI can be utilized as an assessment tool and for providing feedback to students using generated content. For instance, it can be used to create custom quizzes, generate essay prompts, or even grade essays. The use of GenAI as an assessment tool can reduce the workload of teachers and help students receive prompt feedback on their work. Incorporating GenAI in educational settings also poses challenges related to academic integrity. With availability of GenAI models, students can use them to study or complete their homework assignments, which can raise concerns about the authenticity and authorship of the delivered work. Therefore, it is important to ensure that academic standards are maintained, and the originality of the student's work is preserved. This issue highlights the need for implementing ethical practices in the use of GenAI models and ensuring that the technology is used to support and not replace the student's learning experience.",
    "doi": "10.9781/ijimai.2024.02.011",
    "url": "https://openalex.org/W4392394652",
    "pdf_url": "https://doi.org/10.9781/ijimai.2024.02.011",
    "venue": "International Journal of Interactive Multimedia and Artificial Intelligence",
    "citation_count": 120,
    "fields_of_study": [
      "Computer science",
      "Generative grammar",
      "Artificial intelligence",
      "Data science"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387387"
  },
  {
    "source": "openalex",
    "source_id": "W4206349320",
    "title": "The social and ethical impacts of artificial intelligence in agriculture: mapping the agricultural AI literature",
    "authors": [
      "Mark Ryan"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1007/s00146-021-01377-9",
    "url": "https://openalex.org/W4206349320",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s00146-021-01377-9.pdf",
    "venue": "AI & Society",
    "citation_count": 132,
    "fields_of_study": [
      "Engineering ethics",
      "Sustainability",
      "Autonomy",
      "Thematic analysis",
      "Agriculture"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387411"
  },
  {
    "source": "openalex",
    "source_id": "W3177667502",
    "title": "Artificial Intelligence as a Service",
    "authors": [
      "Sebastian Lins",
      "Konstantin D. Pandl",
      "Heiner Teigeler",
      "Scott Thiebes",
      "C.P. Bayer",
      "Ali Sunyaev"
    ],
    "year": 2021,
    "abstract": "Artificial intelligence as a service, AIaaS, Artificial intelligence, Cloud computing, Machine learning as a service",
    "doi": "10.1007/s12599-021-00708-w",
    "url": "https://openalex.org/W3177667502",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s12599-021-00708-w.pdf",
    "venue": "Business & Information Systems Engineering",
    "citation_count": 105,
    "fields_of_study": [
      "Service (business)",
      "Computer science",
      "Artificial intelligence",
      "Engineering",
      "Business"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387416"
  },
  {
    "source": "openalex",
    "source_id": "W4283643667",
    "title": "Trust in Artificial Intelligence: Comparing Trust Processes Between Human and Automated Trustees in Light of Unfair Bias",
    "authors": [
      "Markus Langer",
      "Cornelius J. K\u00f6nig",
      "Caroline Back",
      "Victoria Hemsing"
    ],
    "year": 2022,
    "abstract": "Abstract Automated systems based on artificial intelligence (AI) increasingly support decisions with ethical implications where decision makers need to trust these systems. However, insights regarding trust in automated systems predominantly stem from contexts where the main driver of trust is that systems produce accurate outputs (e.g., alarm systems for monitoring tasks). It remains unclear whether what we know about trust in automated systems translates to application contexts where ethical considerations (e.g., fairness) are crucial in trust development. In personnel selection, as a sample context where ethical considerations are important, we investigate trust processes in light of a trust violation relating to unfair bias and a trust repair intervention. Specifically, participants evaluated preselection outcomes (i.e., sets of preselected applicants) by either a human or an automated system across twelve selection tasks. We additionally varied information regarding imperfection of the human and automated system. In task rounds five through eight, the preselected applicants were predominantly male, thus constituting a trust violation due to potential unfair bias. Before task round nine, participants received an excuse for the biased preselection (i.e., a trust repair intervention). The results of the online study showed that participants have initially less trust in automated systems. Furthermore, the trust violation and the trust repair intervention had weaker effects for the automated system. Those effects were partly stronger when highlighting system imperfection. We conclude that insights from classical areas of automation only partially translate to the many emerging application contexts of such systems where ethical considerations are central to trust processes.",
    "doi": "10.1007/s10869-022-09829-9",
    "url": "https://openalex.org/W4283643667",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10869-022-09829-9.pdf",
    "venue": "Journal of Business and Psychology",
    "citation_count": 91,
    "fields_of_study": [
      "Industrial and organizational psychology",
      "Task (project management)",
      "Excuse",
      "Context (archaeology)",
      "Psychology"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387421"
  },
  {
    "source": "openalex",
    "source_id": "W4382939841",
    "title": "Artificial Intelligence in K-12 Education: eliciting and reflecting on Swedish teachers' understanding of AI and its implications for teaching &amp; learning",
    "authors": [
      "Johanna Velander",
      "Mohammed Ahmed Taiye",
      "Nuno Otero",
      "Marcelo Milrad"
    ],
    "year": 2023,
    "abstract": null,
    "doi": "10.1007/s10639-023-11990-4",
    "url": "https://openalex.org/W4382939841",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10639-023-11990-4.pdf",
    "venue": "Education and Information Technologies",
    "citation_count": 123,
    "fields_of_study": [
      "Curriculum",
      "Literacy",
      "Mathematics education",
      "Educational technology",
      "Professional development"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387444"
  },
  {
    "source": "openalex",
    "source_id": "W2511953903",
    "title": "Evaluation in artificial intelligence: from task-oriented to ability-oriented measurement",
    "authors": [
      "Jos\u00e9 Hern\u00e1ndez\u2010Orallo"
    ],
    "year": 2016,
    "abstract": null,
    "doi": "10.1007/s10462-016-9505-7",
    "url": "https://openalex.org/W2511953903",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10462-016-9505-7.pdf",
    "venue": "Artificial Intelligence Review",
    "citation_count": 180,
    "fields_of_study": [
      "Computer science",
      "Task (project management)",
      "Artificial intelligence",
      "Adaptation (eye)",
      "Perspective (graphical)"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387447"
  },
  {
    "source": "openalex",
    "source_id": "W4399164841",
    "title": "Computer Science Curricula 2023",
    "authors": [
      "Amruth N. Kumar",
      "Rajendra K. Raj",
      "Sherif G. Aly",
      "Monica Anderson",
      "Brett A. Becker",
      "Richard Blumenthal",
      "Eric Eaton",
      "Susan L. Epstein",
      "Michael Goldweber",
      "Pankaj Jalote",
      "D. Lea",
      "Michael J. Oudshoorn",
      "Marcelo Pias",
      "Susan Reiser",
      "Christian Serv\u00edn",
      "Rahul Simha",
      "Titus Winters",
      "Qiao Xiang"
    ],
    "year": 2024,
    "abstract": null,
    "doi": "10.1145/3664191",
    "url": "https://openalex.org/W4399164841",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3664191",
    "venue": "ACM eBooks",
    "citation_count": 146,
    "fields_of_study": [
      "Curriculum",
      "Engineering ethics",
      "Computer science",
      "Mathematics education",
      "Engineering"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387453"
  },
  {
    "source": "openalex",
    "source_id": "W3041268394",
    "title": "Algorithmic fairness in education",
    "authors": [
      "Ren\u00e9 F. Kizilcec",
      "Hansol Lee"
    ],
    "year": 2022,
    "abstract": "Data-driven predictive models are increasingly used in education to support students, instructors, and administrators, which has raised concerns about the fairness of their predictions and uses of these algorithmic systems. In this introduction to algorithmic fairness in education, we draw parallels to prior literature on educational access, bias, and discrimination, and we examine core components of algorithmic systems (measurement, model learning, and action) to identify sources of bias and discrimination in the process of developing and deploying these systems. Statistical, similarity-based, and causal notions of fairness are reviewed and contrasted in how they apply in educational contexts. Recommendations for policymakers and developers of educational technology offer guidance for promoting algorithmic fairness in education.",
    "doi": "10.4324/9780429329067-10",
    "url": "https://openalex.org/W3041268394",
    "pdf_url": "https://api.taylorfrancis.com/content/chapters/edit/download?identifierName=doi&identifierValue=10.4324/9780429329067-10&type=chapterpdf",
    "venue": null,
    "citation_count": 116,
    "fields_of_study": [
      "Computer science",
      "Sociology"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387456"
  },
  {
    "source": "openalex",
    "source_id": "W4224030925",
    "title": "Reactions towards organizational change: a systematic literature review",
    "authors": [
      "Khai Wah Khaw",
      "Alhamzah Alnoor",
      "Hadi AL\u2010Abrrow",
      "Victor Tiberius",
      "Yuvaraj Ganesan",
      "Nadia A. Atshan"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1007/s12144-022-03070-6",
    "url": "https://openalex.org/W4224030925",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s12144-022-03070-6.pdf",
    "venue": "Current Psychology",
    "citation_count": 187,
    "fields_of_study": [
      "Extant taxon",
      "Categorization",
      "Psychology",
      "Resistance (ecology)",
      "Organizational change"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387469"
  },
  {
    "source": "openalex",
    "source_id": "W3112535338",
    "title": "Artificial Intelligence (AI) Deployments in Africa: Benefits, Challenges and Policy Dimensions",
    "authors": [
      "Arthur Gwagwa",
      "Erika Kraemer\u2010Mbula",
      "Nagla Rizk",
      "Isaac Rutenberg",
      "Jeremy de Beer"
    ],
    "year": 2020,
    "abstract": "The deployment of artificial intelligence (AI) technologies is proliferating on the African continent, but policy responses are still at their early stages. This article provides an overview of the main elements of AI deployment in Africa, AI's core benefits and challenges in African settings, and AI's core policy dimensions for the continent. It is argued that for AI to build, rather than undermine, socio-economic inclusion in African settings, policymakers need to be cognisant of the following key dimensions: gender equity, cultural and linguistic diversity, and labour market shifts.",
    "doi": "10.23962/10539/30361",
    "url": "https://openalex.org/W3112535338",
    "pdf_url": "http://wiredspace.wits.ac.za/bitstream/10539/30361/3/AJIC-Issue-26-2020-Gwagwa-et-al.pdf",
    "venue": "The African Journal of Information and Communication (AJIC)",
    "citation_count": 116,
    "fields_of_study": [
      "Software deployment",
      "Diversity (politics)",
      "Equity (law)",
      "Core (optical fiber)",
      "Inclusion (mineral)"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387473"
  },
  {
    "source": "openalex",
    "source_id": "W3119358510",
    "title": "Teasing out Artificial Intelligence in Medicine: An Ethical Critique of Artificial Intelligence and Machine Learning in Medicine",
    "authors": [
      "Mark Arnold"
    ],
    "year": 2021,
    "abstract": null,
    "doi": "10.1007/s11673-020-10080-1",
    "url": "https://openalex.org/W3119358510",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s11673-020-10080-1.pdf",
    "venue": "Journal of Bioethical Inquiry",
    "citation_count": 101,
    "fields_of_study": [
      "Beneficence",
      "Autonomy",
      "Paternalism",
      "Philosophy of medicine",
      "Medical law"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387484"
  },
  {
    "source": "openalex",
    "source_id": "W4385311368",
    "title": "Smart cities: the role of Internet of Things and machine learning in realizing a data-centric smart environment",
    "authors": [
      "Amin Ullah",
      "Syed Myhammad Anwar",
      "Jianqiang Li",
      "Lubna Nadeem",
      "Tariq Mahmood",
      "Amjad Rehman",
      "Tanzila Saba"
    ],
    "year": 2023,
    "abstract": null,
    "doi": "10.1007/s40747-023-01175-4",
    "url": "https://openalex.org/W4385311368",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s40747-023-01175-4.pdf",
    "venue": "Complex & Intelligent Systems",
    "citation_count": 199,
    "fields_of_study": [
      "Smart city",
      "Leverage (statistics)",
      "Big data",
      "Computer science",
      "Implementation"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387487"
  },
  {
    "source": "openalex",
    "source_id": "W3037105702",
    "title": "Approaches Based on Artificial Intelligence and the Internet of Intelligent Things to Prevent the Spread of COVID-19: Scoping Review",
    "authors": [
      "Aya Sedky Adly",
      "Afnan Sedky Adly",
      "Mahmoud Sedky Adly"
    ],
    "year": 2020,
    "abstract": "Background Artificial intelligence (AI) and the Internet of Intelligent Things (IIoT) are promising technologies to prevent the concerningly rapid spread of coronavirus disease (COVID-19) and to maximize safety during the pandemic. With the exponential increase in the number of COVID-19 patients, it is highly possible that physicians and health care workers will not be able to treat all cases. Thus, computer scientists can contribute to the fight against COVID-19 by introducing more intelligent solutions to achieve rapid control of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), the virus that causes the disease. Objective The objectives of this review were to analyze the current literature, discuss the applicability of reported ideas for using AI to prevent and control COVID-19, and build a comprehensive view of how current systems may be useful in particular areas. This may be of great help to many health care administrators, computer scientists, and policy makers worldwide. Methods We conducted an electronic search of articles in the MEDLINE, Google Scholar, Embase, and Web of Knowledge databases to formulate a comprehensive review that summarizes different categories of the most recently reported AI-based approaches to prevent and control the spread of COVID-19. Results Our search identified the 10 most recent AI approaches that were suggested to provide the best solutions for maximizing safety and preventing the spread of COVID-19. These approaches included detection of suspected cases, large-scale screening, monitoring, interactions with experimental therapies, pneumonia screening, use of the IIoT for data and information gathering and integration, resource allocation, predictions, modeling and simulation, and robotics for medical quarantine. Conclusions We found few or almost no studies regarding the use of AI to examine COVID-19 interactions with experimental therapies, the use of AI for resource allocation to COVID-19 patients, or the use of AI and the IIoT for COVID-19 data and information gathering/integration. Moreover, the adoption of other approaches, including use of AI for COVID-19 prediction, use of AI for COVID-19 modeling and simulation, and use of AI robotics for medical quarantine, should be further emphasized by researchers because these important approaches lack sufficient numbers of studies. Therefore, we recommend that computer scientists focus on these approaches, which are still not being adequately addressed.",
    "doi": "10.2196/19104",
    "url": "https://openalex.org/W3037105702",
    "pdf_url": "https://www.jmir.org/2020/8/e19104/PDF",
    "venue": "Journal of Medical Internet Research",
    "citation_count": 138,
    "fields_of_study": [
      "Coronavirus disease 2019 (COVID-19)",
      "Computer science",
      "Pandemic",
      "The Internet",
      "Control (management)"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387490"
  },
  {
    "source": "openalex",
    "source_id": "W3008680281",
    "title": "Structural racism in precision medicine: leaving no one behind",
    "authors": [
      "Lester Darryl Genevi\u00e8ve",
      "Andrea Martani",
      "David Shaw",
      "Bernice S. Elger",
      "Tenzin Wangmo"
    ],
    "year": 2020,
    "abstract": null,
    "doi": "10.1186/s12910-020-0457-8",
    "url": "https://openalex.org/W3008680281",
    "pdf_url": "https://bmcmedethics.biomedcentral.com/track/pdf/10.1186/s12910-020-0457-8",
    "venue": "BMC Medical Ethics",
    "citation_count": 120,
    "fields_of_study": [
      "Racism",
      "Philosophy of medicine",
      "Health care",
      "Health equity",
      "Public relations"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387525"
  },
  {
    "source": "openalex",
    "source_id": "W4386249236",
    "title": "ChatGPT Perpetuates Gender Bias in Machine Translation and Ignores Non-Gendered Pronouns: Findings across Bengali and Five other Low-Resource Languages",
    "authors": [
      "Sourojit Ghosh",
      "Aylin Caliskan"
    ],
    "year": 2023,
    "abstract": "In this multicultural age, language translation is one of the most performed tasks, and it is becoming increasingly AI-moderated and automated. As a novel AI system, ChatGPT claims to be proficient in machine translation tasks and in this paper, we put that claim to the test. Specifically, we examine ChatGPT's accuracy in translating between English and languages that exclusively use gender-neutral pronouns. We center this study around Bengali, the 7th most spoken language globally, but also generalize our findings across five other languages: Farsi, Malay, Tagalog, Thai, and Turkish. We find that ChatGPT perpetuates gender defaults and stereotypes assigned to certain occupations (e.g., man = doctor, woman = nurse) or actions (e.g., woman = cook, man = go to work), as it converts gender-neutral pronouns in languages to 'he' or 'she'. We also observe ChatGPT completely failing to translate the English gender-neutral singular pronoun 'they' into equivalent gender-neutral pronouns in other languages, as it produces translations that are incoherent and incorrect. While it does respect and provide appropriately gender-marked versions of Bengali words when prompted with gender information in English, ChatGPT appears to confer a higher respect to men than to women in the same occupation. We conclude that ChatGPT exhibits the same gender biases which have been demonstrated for tools like Google Translate or MS Translator, as we provide recommendations for a human centered approach for future designers of AI systems that perform machine translation to better accommodate such low-resource languages.",
    "doi": "10.1145/3600211.3604672",
    "url": "https://openalex.org/W4386249236",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3600211.3604672",
    "venue": null,
    "citation_count": 89,
    "fields_of_study": [
      "Bengali",
      "Computer science",
      "Pronoun",
      "Grammatical gender",
      "Machine translation"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387528"
  },
  {
    "source": "openalex",
    "source_id": "W2990278906",
    "title": "\u201cWhere\u2019s the I-O?\u201d Artificial Intelligence and Machine Learning in Talent Management Systems",
    "authors": [
      "Manuel F. Gonzalez",
      "John Capman",
      "Frederick L. Oswald",
      "Evan R. Theys",
      "David L. Tomczak"
    ],
    "year": 2019,
    "abstract": "Artificial intelligence (AI) and machine learning (ML) have seen widespread adoption by organizations seeking to identify and hire high-quality job applicants. Yet the volume, variety, and velocity of professional involvement among I-O psychologists remains relatively limited when it comes to developing and evaluating AI/ML applications for talent assessment and selection. Furthermore, there is a paucity of empirical research that investigates the reliability, validity, and fairness of AI/ML tools in organizational contexts. To stimulate future involvement and research, we share our review and perspective on the current state of AI/ML in talent assessment as well as its benefits and potential pitfalls; and in addressing the issue of fairness, we present experimental evidence regarding the potential for AI/ML to evoke adverse reactions from job applicants during selection procedures. We close by emphasizing increased collaboration among I-O psychologists, computer scientists, legal scholars, and members of other professional disciplines in developing, implementing, and evaluating AI/ML applications in organizational contexts.",
    "doi": "10.25035/pad.2019.03.005",
    "url": "https://openalex.org/W2990278906",
    "pdf_url": "https://scholarworks.bgsu.edu/cgi/viewcontent.cgi?article=1102&context=pad",
    "venue": "Personnel Assessment and Decisions",
    "citation_count": 101,
    "fields_of_study": [
      "Variety (cybernetics)",
      "Artificial intelligence",
      "Perspective (graphical)",
      "Personnel selection",
      "Knowledge management"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387551"
  },
  {
    "source": "openalex",
    "source_id": "W4387373263",
    "title": "Unveiling the Influence of Artificial Intelligence and Machine Learning on Financial Markets: A Comprehensive Analysis of AI Applications in Trading, Risk Management, and Financial Operations",
    "authors": [
      "Mohammad El Hajj",
      "Jamil Hammoud"
    ],
    "year": 2023,
    "abstract": "This study explores the adoption and impact of artificial intelligence (AI) and machine learning (ML) in financial markets, utilizing a mixed-methods approach that includes a quantitative survey and a qualitative analysis of existing research papers, reports, and articles. The quantitative results demonstrate the growing adoption of AI and ML technologies in financial institutions and their most common applications, such as algorithmic trading, risk management, fraud detection, credit scoring, and customer service. Additionally, the qualitative analysis identifies key themes, including AI and ML adoption trends, challenges and barriers to adoption, the role of regulation, workforce transformation, and ethical and social considerations. The study highlights the need for financial professionals to adapt their skills and for organizations to address challenges, such as data privacy concerns, regulatory compliance, and ethical considerations. The research contributes to the knowledge on AI and ML in finance, helping policymakers, regulators, and professionals understand their benefits and challenges.",
    "doi": "10.3390/jrfm16100434",
    "url": "https://openalex.org/W4387373263",
    "pdf_url": "https://www.mdpi.com/1911-8074/16/10/434/pdf?version=1696474078",
    "venue": "Journal of risk and financial management",
    "citation_count": 121,
    "fields_of_study": [
      "Financial services",
      "Workforce",
      "Finance",
      "Risk management",
      "Financial market"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387566"
  },
  {
    "source": "openalex",
    "source_id": "W2989612956",
    "title": "Opportunities and Risks for Citizen Science in the Age of Artificial Intelligence",
    "authors": [
      "Luigi Ceccaroni",
      "James Bibby",
      "Erin Roger",
      "Paul Flemons",
      "Katina Michael",
      "Laura L. Fagan",
      "Jessica L. Oliver"
    ],
    "year": 2019,
    "abstract": "Members of the public are making substantial contributions to science as citizen scientists, and advances in technologies have enabled citizens to make even more substantial contributions. Technologies that allow computers and machines to function in an intelligent manner, often referred to as artificial intelligence (AI), are now being applied in citizen science. Discussions about guidelines, responsibilities, and ethics of AI usage are already happening outside the field of citizen science. We suggest such considerations should also be explored carefully in the context of citizen science applications. To start the conversation, we offer the citizen science community an essay to introduce the state-of-play for AI in citizen science and its potential uses in the future. We begin by presenting a systematic overview of AI technologies currently being applied, highlighting exemplary projects for each technology type described. We then discuss how AI is likely to be increasingly utilised in citizen science into the future, and, through scenarios, we explore both future opportunities and potential risks. Lastly, we conclude by providing recommendations that warrant consideration by the citizen science community, such as developing a data stewardship plan to inform citizens in advance of plans and expected outcomes of using data for AI training, or adopting good practice around anonymity. Our intent is for this essay to lead to further critical discussions among citizen science practitioners, which is needed for responsible, ethical, and useful use of AI in citizen science.",
    "doi": "10.5334/cstp.241",
    "url": "https://openalex.org/W2989612956",
    "pdf_url": "http://theoryandpractice.citizenscienceassociation.org/articles/10.5334/cstp.241/galley/138/download/",
    "venue": "Citizen Science Theory and Practice",
    "citation_count": 105,
    "fields_of_study": [
      "Citizen science",
      "Stewardship (theology)",
      "Context (archaeology)",
      "Engineering ethics",
      "Conversation"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387583"
  },
  {
    "source": "openalex",
    "source_id": "W4226290207",
    "title": "A Survey of Algorithmic Recourse: Contrastive Explanations and Consequential Recommendations",
    "authors": [
      "Amir-Hossein Karimi",
      "Gilles Barthe",
      "Bernhard Sch\u00f6lkopf",
      "Isabel Valera"
    ],
    "year": 2022,
    "abstract": "Machine learning is increasingly used to inform decision making in sensitive situations where decisions have consequential effects on individuals\u2019 lives. In these settings, in addition to requiring models to be accurate and robust, socially relevant values such as fairness, privacy, accountability, and explainability play an important role in the adoption and impact of said technologies. In this work, we focus on algorithmic recourse , which is concerned with providing explanations and recommendations to individuals who are unfavorably treated by automated decision-making systems. We first perform an extensive literature review, and align the efforts of many authors by presenting unified definitions, formulations, and solutions to recourse. Then, we provide an overview of the prospective research directions toward which the community may engage, challenging existing assumptions and making explicit connections to other ethical challenges such as security, privacy, and fairness.",
    "doi": "10.1145/3527848",
    "url": "https://openalex.org/W4226290207",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3527848",
    "venue": "ACM Computing Surveys",
    "citation_count": 118,
    "fields_of_study": [
      "Computer science",
      "Accountability",
      "Focus (optics)",
      "Work (physics)",
      "Management science"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387604"
  },
  {
    "source": "openalex",
    "source_id": "W4381686136",
    "title": "Enhancing Student Engagement: Harnessing \u201cAIED\u201d\u2019s Power in Hybrid Education\u2014A Review Analysis",
    "authors": [
      "Amjad Almusaed",
      "Asaad Almssad",
      "\u0130brahim Yitmen",
      "Raad Z. Homod"
    ],
    "year": 2023,
    "abstract": "Hybrid learning is a complex combination of face-to-face and online learning. This model combines the use of multimedia materials with traditional classroom work. Virtual hybrid learning is employed alongside face-to-face methods. That aims to investigate using Artificial Intelligence (AI) to increase student engagement in hybrid learning settings. Educators are confronted with contemporary issues in maintaining their students\u2019 interest and motivation as the popularity of online and hybrid education continues to grow, where many educational institutions are adopting this model due to its flexibility, student-teacher engagement, and peer-to-peer interaction. AI will help students communicate, collaborate, and receive real-time feedback, all of which are challenges in education. This article examines the advantages and disadvantages of hybrid education and the optimal approaches for incorporating Artificial Intelligence (AI) in educational settings. The research findings suggest that using AI can revolutionize hybrid education, as it enhances both student and instructor autonomy while fostering a more engaging and interactive learning environment.",
    "doi": "10.3390/educsci13070632",
    "url": "https://openalex.org/W4381686136",
    "pdf_url": "https://www.mdpi.com/2227-7102/13/7/632/pdf?version=1687687644",
    "venue": "Education Sciences",
    "citation_count": 199,
    "fields_of_study": [
      "Popularity",
      "Flexibility (engineering)",
      "Blended learning",
      "Autonomy",
      "Student engagement"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387620"
  },
  {
    "source": "openalex",
    "source_id": "W4383817745",
    "title": "Artificial Intelligence and Public Health: Evaluating ChatGPT Responses to Vaccination Myths and Misconceptions",
    "authors": [
      "Giovanna Deiana",
      "Marco Dettori",
      "Antonella Arghittu",
      "Antonio Azara",
      "Giovanni Gabutti",
      "Paolo Castiglia"
    ],
    "year": 2023,
    "abstract": "Artificial intelligence (AI) tools, such as ChatGPT, are the subject of intense debate regarding their possible applications in contexts such as health care. This study evaluates the Correctness, Clarity, and Exhaustiveness of the answers provided by ChatGPT on the topic of vaccination. The World Health Organization\u2019s 11 \u201cmyths and misconceptions\u201d about vaccinations were administered to both the free (GPT-3.5) and paid version (GPT-4.0) of ChatGPT. The AI tool\u2019s responses were evaluated qualitatively and quantitatively, in reference to those myth and misconceptions provided by WHO, independently by two expert Raters. The agreement between the Raters was significant for both versions (p of K &lt; 0.05). Overall, ChatGPT responses were easy to understand and 85.4% accurate although one of the questions was misinterpreted. Qualitatively, the GPT-4.0 responses were superior to the GPT-3.5 responses in terms of Correctness, Clarity, and Exhaustiveness (\u0394 = 5.6%, 17.9%, 9.3%, respectively). The study shows that, if appropriately questioned, AI tools can represent a useful aid in the health care field. However, when consulted by non-expert users, without the support of expert medical advice, these tools are not free from the risk of eliciting misleading responses. Moreover, given the existing social divide in information access, the improved accuracy of answers from the paid version raises further ethical issues.",
    "doi": "10.3390/vaccines11071217",
    "url": "https://openalex.org/W4383817745",
    "pdf_url": "https://www.mdpi.com/2076-393X/11/7/1217/pdf?version=1688973439",
    "venue": "Vaccines",
    "citation_count": 149,
    "fields_of_study": [
      "CLARITY",
      "Correctness",
      "Health care",
      "Mythology",
      "Field (mathematics)"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387637"
  },
  {
    "source": "openalex",
    "source_id": "W4390638955",
    "title": "Artificial intelligence (AI) learning tools in K-12 education: A\u00a0scoping review",
    "authors": [
      "Iris Heung Yue Yim",
      "Jiahong Su"
    ],
    "year": 2024,
    "abstract": "Abstract Artificial intelligence (AI) literacy is a global strategic objective in education. However, little is known about how AI should be taught. In this paper, 46 studies in academic conferences and journals are reviewed to investigate pedagogical strategies, learning tools, assessment methods in AI literacy education in K-12 contexts, and students\u2019 learning outcomes. The investigation reveals that the promotion of AI literacy education has seen significant progress in the past two decades. This highlights that intelligent agents, including Google\u2019s Teachable Machine, Learning ML, and Machine Learning for Kids, are age-appropriate tools for AI literacy education in K-12 contexts. Kindergarten students can benefit from learning tools such as PopBots, while software devices, such as Scratch and Python, which help to develop the computational thinking of AI algorithms, can be introduced to both primary and secondary schools. The research shows that project-based, human\u2013computer collaborative learning and play- and game-based approaches, with constructivist methodologies, have been applied frequently in AI literacy education. Cognitive, affective, and behavioral learning outcomes, course satisfaction and soft skills acquisition have been reported. The paper informs educators of appropriate learning tools, pedagogical strategies, assessment methodologies in AI literacy education, and students\u2019 learning outcomes. Research implications and future research directions within the K-12 context are also discussed.",
    "doi": "10.1007/s40692-023-00304-9",
    "url": "https://openalex.org/W4390638955",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s40692-023-00304-9.pdf",
    "venue": "Journal of Computers in Education",
    "citation_count": 142,
    "fields_of_study": [
      "Computer science",
      "Artificial intelligence",
      "Literacy",
      "Learning sciences",
      "Mathematics education"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387658"
  },
  {
    "source": "openalex",
    "source_id": "W2951969346",
    "title": "Business and the Ethical Implications of Technology: Introduction to the Symposium",
    "authors": [
      "Kirsten Martin",
      "Katie Shilton",
      "J. Allen Smith"
    ],
    "year": 2019,
    "abstract": null,
    "doi": "10.1007/s10551-019-04213-9",
    "url": "https://openalex.org/W2951969346",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10551-019-04213-9.pdf",
    "venue": "Journal of Business Ethics",
    "citation_count": 95,
    "fields_of_study": [
      "Business ethics",
      "Engineering ethics",
      "Ethics of technology",
      "Value (mathematics)",
      "Sociology"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387679"
  },
  {
    "source": "openalex",
    "source_id": "W4283644014",
    "title": "Human-Centered Artificial Intelligence: The Superlative Approach to Achieve Sustainable Development Goals in the Fourth Industrial Revolution",
    "authors": [
      "David Mhlanga"
    ],
    "year": 2022,
    "abstract": "Artificial intelligence (AI) is currently being developed by large corporations, and governments all over the world are yearning for it. AI isn\u2019t a futuristic concept; it is already here, and it is being implemented in a range of industries. Finance, national security, health care, criminal justice, transportation, and smart cities are all examples of this. There are countless examples of AI having a substantial impact on the world and complementing human abilities. However, due to the immense societal ramifications of these technologies, AI is on the verge of disrupting a host of industries, so the technique by which AI systems are created must be better understood. The goal of the study was to look at what it meant to be human-centred, how to create human-centred AI, and what considerations should be made for human-centred AI to achieve sustainability and the SDGs. Using a systematic literature review technique, the study discovered that a human-centred AI strategy strives to create and implement AI systems in ways that benefit mankind and serve their interests. The study also found that a human-in-the-loop concept should be used to develop procedures for creating human-centred AI, as well as other initiatives, such as the promotion of AI accountability, encouraging businesses to use autonomy wisely, to motivate businesses to be aware of human and algorithmic biases, to ensure that businesses prioritize customers, and form multicultural teams to tackle AI research. The study concluded with policy recommendations for human-centred AI to help accomplish the SDGs, including expanding government AI investments, addressing data and algorithm biases, and resolving data access issues, among other things.",
    "doi": "10.3390/su14137804",
    "url": "https://openalex.org/W4283644014",
    "pdf_url": "https://www.mdpi.com/2071-1050/14/13/7804/pdf?version=1656331391",
    "venue": "Sustainability",
    "citation_count": 104,
    "fields_of_study": [
      "Accountability",
      "Autonomy",
      "Promotion (chess)",
      "Sustainability",
      "Sustainable development"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387682"
  },
  {
    "source": "openalex",
    "source_id": "W4387012889",
    "title": "Machine learning in precision diabetes care and cardiovascular risk prediction",
    "authors": [
      "Evangelos K. Oikonomou",
      "Rohan Khera"
    ],
    "year": 2023,
    "abstract": null,
    "doi": "10.1186/s12933-023-01985-3",
    "url": "https://openalex.org/W4387012889",
    "pdf_url": "https://cardiab.biomedcentral.com/counter/pdf/10.1186/s12933-023-01985-3",
    "venue": "Cardiovascular Diabetology",
    "citation_count": 126,
    "fields_of_study": [
      "Medicine",
      "Context (archaeology)",
      "Artificial intelligence",
      "Precision medicine",
      "Risk analysis (engineering)"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387706"
  },
  {
    "source": "openalex",
    "source_id": "W4391256306",
    "title": "How should we change teaching and assessment in response to increasingly powerful generative Artificial Intelligence? Outcomes of the ChatGPT teacher survey",
    "authors": [
      "Matt Bower",
      "Jodie Torrington",
      "Jennifer W. M. Lai",
      "Peter Petocz",
      "Mark Alfano"
    ],
    "year": 2024,
    "abstract": "Abstract There has been widespread media commentary about the potential impact of generative Artificial Intelligence (AI) such as ChatGPT on the Education field, but little examination at scale of how educators believe teaching and assessment should change as a result of generative AI. This mixed methods study examines the views of educators ( n = 318) from a diverse range of teaching levels, experience levels, discipline areas, and regions about the impact of AI on teaching and assessment, the ways that they believe teaching and assessment should change, and the key motivations for changing their practices. The majority of teachers felt that generative AI would have a major or profound impact on teaching and assessment, though a sizeable minority felt it would have a little or no impact. Teaching level, experience, discipline area, region, and gender all significantly influenced perceived impact of generative AI on teaching and assessment. Higher levels of awareness of generative AI predicted higher perceived impact, pointing to the possibility of an \u2018ignorance effect\u2019. Thematic analysis revealed the specific curriculum, pedagogy, and assessment changes that teachers feel are needed as a result of generative AI, which centre around learning with AI, higher-order thinking, ethical values, a focus on learning processes and face-to-face relational learning. Teachers were most motivated to change their teaching and assessment practices to increase the performance expectancy of their students and themselves. We conclude by discussing the implications of these findings in a world with increasingly prevalent AI.",
    "doi": "10.1007/s10639-023-12405-0",
    "url": "https://openalex.org/W4391256306",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10639-023-12405-0.pdf",
    "venue": "Education and Information Technologies",
    "citation_count": 129,
    "fields_of_study": [
      "Generative grammar",
      "Curriculum",
      "Psychology",
      "Ignorance",
      "Teaching method"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387709"
  },
  {
    "source": "openalex",
    "source_id": "W4385416665",
    "title": "The Power of Generative AI: A Review of Requirements, Models, Input\u2013Output Formats, Evaluation Metrics, and Challenges",
    "authors": [
      "Ajay Bandi",
      "Pydi Venkata Satya Ramesh Adapa",
      "Yudu Eswar Vinay Pratap Kumar Kuchi"
    ],
    "year": 2023,
    "abstract": "Generative artificial intelligence (AI) has emerged as a powerful technology with numerous applications in various domains. There is a need to identify the requirements and evaluation metrics for generative AI models designed for specific tasks. The purpose of the research aims to investigate the fundamental aspects of generative AI systems, including their requirements, models, input\u2013output formats, and evaluation metrics. The study addresses key research questions and presents comprehensive insights to guide researchers, developers, and practitioners in the field. Firstly, the requirements necessary for implementing generative AI systems are examined and categorized into three distinct categories: hardware, software, and user experience. Furthermore, the study explores the different types of generative AI models described in the literature by presenting a taxonomy based on architectural characteristics, such as variational autoencoders (VAEs), generative adversarial networks (GANs), diffusion models, transformers, language models, normalizing flow models, and hybrid models. A comprehensive classification of input and output formats used in generative AI systems is also provided. Moreover, the research proposes a classification system based on output types and discusses commonly used evaluation metrics in generative AI. The findings contribute to advancements in the field, enabling researchers, developers, and practitioners to effectively implement and evaluate generative AI models for various applications. The significance of the research lies in understanding that generative AI system requirements are crucial for effective planning, design, and optimal performance. A taxonomy of models aids in selecting suitable options and driving advancements. Classifying input\u2013output formats enables leveraging diverse formats for customized systems, while evaluation metrics establish standardized methods to assess model quality and performance.",
    "doi": "10.3390/fi15080260",
    "url": "https://openalex.org/W4385416665",
    "pdf_url": "https://www.mdpi.com/1999-5903/15/8/260/pdf?version=1690812126",
    "venue": "Future Internet",
    "citation_count": 489,
    "fields_of_study": [
      "Computer science",
      "Generative grammar",
      "Field (mathematics)",
      "Taxonomy (biology)",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387732"
  },
  {
    "source": "openalex",
    "source_id": "W2981124546",
    "title": "Psychosocial Factors Affecting Artificial Intelligence Adoption in Health Care in China: Cross-Sectional Study",
    "authors": [
      "Tiantian Ye",
      "Jiaolong Xue",
      "Mingguang He",
      "Jing Gu",
      "Haotian Lin",
      "Xu Bin",
      "Yu Cheng"
    ],
    "year": 2019,
    "abstract": "Background Poor quality primary health care is a major issue in China, particularly in blindness prevention. Artificial intelligence (AI) could provide early screening and accurate auxiliary diagnosis to improve primary care services and reduce unnecessary referrals, but the application of AI in medical settings is still an emerging field. Objective This study aimed to investigate the general public\u2019s acceptance of ophthalmic AI devices, with reference to those already used in China, and the interrelated influencing factors that shape people\u2019s intention to use these devices. Methods We proposed a model of ophthalmic AI acceptance based on technology acceptance theories and variables from other health care\u2013related studies. The model was verified via a 32-item questionnaire with 7-point Likert scales completed by 474 respondents (nationally random sampled). Structural equation modeling was used to evaluate item and construct reliability and validity via a confirmatory factor analysis, and the model\u2019s path effects, significance, goodness of fit, and mediation and moderation effects were analyzed. Results Standardized factor loadings of items were between 0.583 and 0.876. Composite reliability of 9 constructs ranged from 0.673 to 0.841. The discriminant validity of all constructs met the Fornell and Larcker criteria. Model fit indicators such as standardized root mean square residual (0.057), comparative fit index (0.915), and root mean squared error of approximation (0.049) demonstrated good fit. Intention to use (R2=0.515) is significantly affected by subjective norms (beta=.408; P&lt;.001), perceived usefulness (beta=.336; P=.03), and resistance bias (beta=\u2013.237; P=.02). Subjective norms and perceived behavior control had an indirect impact on intention to use through perceived usefulness and perceived ease of use. Eye health consciousness had an indirect positive effect on intention to use through perceived usefulness. Trust had a significant moderation effect (beta=\u2013.095; P=.049) on the effect path of perceived usefulness to intention to use. Conclusions The item, construct, and model indicators indicate reliable interpretation power and help explain the levels of public acceptance of ophthalmic AI devices in China. The influence of subjective norms can be linked to Confucian culture, collectivism, authoritarianism, and conformity mentality in China. Overall, the use of AI in diagnostics and clinical laboratory analysis is underdeveloped, and the Chinese public are generally mistrustful of medical staff and the Chinese medical system. Stakeholders such as doctors and AI suppliers should therefore avoid making misleading or over-exaggerated claims in the promotion of AI health care products.",
    "doi": "10.2196/14316",
    "url": "https://openalex.org/W2981124546",
    "pdf_url": "https://www.jmir.org/2019/10/e14316/PDF",
    "venue": "Journal of Medical Internet Research",
    "citation_count": 127,
    "fields_of_study": [
      "Structural equation modeling",
      "Confirmatory factor analysis",
      "Psychosocial",
      "Psychology",
      "Construct validity"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387758"
  },
  {
    "source": "openalex",
    "source_id": "W4385168292",
    "title": "Summary for Policymakers",
    "authors": [
      "Jim Skea",
      "P.R. Shukla",
      "Andy Reisinger",
      "Raphael Slade",
      "Minal Pathak",
      "Alaa Al Khourdajie",
      "Ren\u00e9e van Diemen",
      "Amjad Abdulla",
      "Keigo Akimoto",
      "Mustafa Babiker",
      "Quan Bai",
      "I. Bashmakov",
      "Christopher Bataille",
      "G\u00f6ran Berndes",
      "Gabriel Blanco",
      "Kornelis Blok",
      "Mercedes Bustamante",
      "Edward Byers",
      "Luisa F. Cabeza",
      "Katherine Calvin",
      "Carlo Carraro",
      "Leon Clarke",
      "Annette Cowie",
      "Felix Creutzig",
      "Diriba Korecha Dadi",
      "Dipak Dasgupta",
      "Heleen de Coninck",
      "Fatima Denton",
      "Shobhakar Dhakal",
      "Navroz K. Dubash",
      "Oliver Geden",
      "Michael Grubb",
      "C\u00e9line Guivarch",
      "Sumana Gupta",
      "Andrea N. Hahmann",
      "Kirsten Halsn\u00e6s",
      "Paulina Jaramillo",
      "Kejun Jiang",
      "Frank Jotzo",
      "Tae Yong Jung",
      "Suzana Kahn Ribeiro",
      "Smail Khennas",
      "\u015eiir K\u0131lk\u0131\u015f",
      "Silvia Kreibiehl",
      "Volker Krey",
      "Elmar Kriegler",
      "William F. Lamb",
      "Franck Lecocq",
      "Shuaib Lwasa",
      "Nagmeldin Mahmoud",
      "Cheikh Mbow",
      "David McCollum",
      "Jan C. Minx",
      "Catherine Mitchell",
      "Rachid Mrabet",
      "Yacob Mulugetta",
      "G.J. Nabuurs",
      "Gregory F. Nemet",
      "Peter J. Newman",
      "Leila Niamir",
      "Lennart Nilsson",
      "Sudarmanto Budi Nugroho",
      "Chukwumerije Okereke",
      "Shonali Pachauri",
      "Anthony Patt",
      "Ram\u00f3n Pichs-Madruga",
      "Joana Portugal\u2010Pereira",
      "Lavanya Rajamani",
      "Keywan Riahi",
      "Joyashree Roy",
      "Yamina Saheb",
      "Roberto Schaeffer",
      "Karen C. Seto",
      "Shreya Some",
      "Linda Steg",
      "Ferenc L. T\u00f3th",
      "Di\u00e1na \u00dcrge-Vorsatz",
      "Detlef P. van Vuuren",
      "Elena Verdolini",
      "Purvi Vyas",
      "Yi\u2010Ming Wei",
      "Mariama Williams"
    ],
    "year": 2023,
    "abstract": "The Working Group III (WGIII) contribution to the IPCC\u2019s Sixth Assessment Report (AR6) assesses literature on the scientific, technological, environmental, economic and social aspects of mitigation of climate change.The report reflects new findings in the relevant literature and builds on previous IPCC reports, including the WGIII contribution to the IPCC\u2019s Fifth Assessment Report (AR5), the WGI and WGII contributions to AR6 and the three Special Reports in the Sixth Assessment cycle, as well as other UN assessments.",
    "doi": "10.1017/9781009157926.001",
    "url": "https://openalex.org/W4385168292",
    "pdf_url": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/ABC31CEA863CB6AD8FEB6911A872B321/stamped-9781009157933pre2_3-48.pdf/summary-for-policymakers.pdf",
    "venue": "Cambridge University Press eBooks",
    "citation_count": 510,
    "fields_of_study": [
      "Action (physics)",
      "Content (measure theory)",
      "Computer science",
      "Mathematics",
      "Physics"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387809"
  },
  {
    "source": "openalex",
    "source_id": "W4392378814",
    "title": "Opportunities, challenges, and benefits of AI innovation in government services: a review",
    "authors": [
      "Khalifa Alhosani",
      "Saadat M. Alhashmi"
    ],
    "year": 2024,
    "abstract": "Abstract Artificial intelligence (AI) has emerged as an excellent tool across multiple industries and holds great promise for the government, society, and economy. However, the absence of a distinct consensus regarding the definition and scope of artificial intelligence hinders its practical implementation in government settings. This article examines the various methodologies, emphases, and goals within artificial intelligence, emphasizing its ability to enhance human capabilities in critical situations. Considering the present advantages and enhanced productivity brought about by AI adoption in trailblazing government departments, this study explores the possible benefits and limitations of AI usage in the public sector. By looking at the cross-disciplinary difficulties of public AI applications, such as language hurdles and service delays, this study highlights the necessity for a thorough knowledge of the risks, impediments, and incentives of employing AI for government services. The study hopes to provide insight into AI research's ultimate aims, including object manipulation, natural language processing, and reasoning. This study emphasizes the potential for greater productivity, simplified procedures, and reduced obligations by analyzing the pros and cons of using AI in the public sector. Further, organizational theory is considered a tool for figuring out how to deal with challenges and maximize possibilities associated with AI deployment. The theory is used as the conceptual framework to understand the benefits, opportunities, and challenges involved in using AI when providing government services. The results of this research help us better understand how AI may revolutionize public service delivery by stimulating new ideas and improving efficiency. This study covers critical questions about organizational theory's role in improving government AI adoption, the challenges governments have in adopting AI, and the potential benefits AI might offer public service delivery. The research recommends a strategic approach to AI adoption in the public sector, considering organizational, ethical, and societal implications while recognizing the possibility of AI's transformative impacts on governments' service provision.",
    "doi": "10.1007/s44163-024-00111-w",
    "url": "https://openalex.org/W4392378814",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s44163-024-00111-w.pdf",
    "venue": "Discover Artificial Intelligence",
    "citation_count": 86,
    "fields_of_study": [
      "Government (linguistics)",
      "Business",
      "Knowledge management",
      "Computer science",
      "Philosophy"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387820"
  },
  {
    "source": "openalex",
    "source_id": "W2579952554",
    "title": "The Vision of \u201cIndustrie 4.0\u201d in the Making\u2014a Case of Future Told, Tamed, and Traded",
    "authors": [
      "Sabine Pfeiffer"
    ],
    "year": 2017,
    "abstract": "Since industrial trade fair Hannover Messe 2011, the term \"Industrie 4.0\" has ignited a vision of a new Industrial Revolution and has been inspiring a lively, ongoing debate among the German public about the future of work, and hence society, ever since. The discourse around this vision of the future eventually spread to other countries, with public awareness reaching a temporary peak in 2016 when the World Economic Forum's meeting in Davos was held with the motto \"Mastering the Fourth Industrial Revolution.\" How is it possible for a vision originally established by three German engineers to unfold and bear fruit at a global level in such a short period of time? This article begins with a summary of the key ideas that are discussed under the label Industrie 4.0. The main purpose, based on an in-depth discourse analysis, is to debunk the myth about the origin of this powerful vision and to trace the narrative back to the global economic crisis in 2009 and thus to the real actors, central discourse patterns, and hidden intentions of this vision of a new Industrial Revolution. In conclusion, the discourse analysis reveals that this is not a case of visioneering but one of a future told, tamed, and traded.",
    "doi": "10.1007/s11569-016-0280-3",
    "url": "https://openalex.org/W2579952554",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007%2Fs11569-016-0280-3.pdf",
    "venue": "NanoEthics",
    "citation_count": 310,
    "fields_of_study": [
      "German",
      "Philosophy of technology",
      "Industrial Revolution",
      "Narrative",
      "Mythology"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387849"
  },
  {
    "source": "openalex",
    "source_id": "W3176588943",
    "title": "Questioning Racial and Gender Bias in AI-based Recommendations: Do Espoused National Cultural Values Matter?",
    "authors": [
      "Manjul Gupta",
      "Carlos M. Parra",
      "Denis Dennehy"
    ],
    "year": 2021,
    "abstract": null,
    "doi": "10.1007/s10796-021-10156-2",
    "url": "https://openalex.org/W3176588943",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10796-021-10156-2.pdf",
    "venue": "Information Systems Frontiers",
    "citation_count": 98,
    "fields_of_study": [
      "Realm",
      "Psychology",
      "Affect (linguistics)",
      "Social psychology",
      "Masculinity"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387869"
  },
  {
    "source": "openalex",
    "source_id": "W4304142408",
    "title": "Does AI Debias Recruitment? Race, Gender, and AI\u2019s \u201cEradication of Difference\u201d",
    "authors": [
      "Eleanor Drage",
      "Kerry Mackereth"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1007/s13347-022-00543-1",
    "url": "https://openalex.org/W4304142408",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s13347-022-00543-1.pdf",
    "venue": "Philosophy & Technology",
    "citation_count": 89,
    "fields_of_study": [
      "Race (biology)",
      "Meritocracy",
      "Categorization",
      "Power (physics)",
      "Outsourcing"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387873"
  },
  {
    "source": "openalex",
    "source_id": "W2760844412",
    "title": "Learning to Generalize: Meta-Learning for Domain Generalization",
    "authors": [
      "Da Li",
      "Yongxin Yang",
      "Yi-Zhe Song",
      "Timothy M. Hospedales"
    ],
    "year": 2017,
    "abstract": "Domain shift refers to the well known problem that a model trained in one source domain performs poorly when applied to a target domain with different statistics. {Domain Generalization} (DG) techniques attempt to alleviate this issue by producing models which by design generalize well to novel testing domains. We propose a novel {meta-learning} method for domain generalization. Rather than designing a specific model that is robust to domain shift as in most previous DG work, we propose a model agnostic training procedure for DG. Our algorithm simulates train/test domain shift during training by synthesizing virtual testing domains within each mini-batch. The meta-optimization objective requires that steps to improve training domain performance should also improve testing domain performance. This meta-learning procedure trains models with good generalization ability to novel domains. We evaluate our method and achieve state of the art results on a recent cross-domain image classification benchmark, as well demonstrating its potential on two classic reinforcement learning tasks.",
    "doi": "10.48550/arxiv.1710.03463",
    "url": "https://openalex.org/W2760844412",
    "pdf_url": "https://arxiv.org/pdf/1710.03463",
    "venue": "arXiv (Cornell University)",
    "citation_count": 113,
    "fields_of_study": [
      "Generalization",
      "Computer science",
      "Domain (mathematical analysis)",
      "Benchmark (surveying)",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387876"
  },
  {
    "source": "openalex",
    "source_id": "W3007819350",
    "title": "Ethical concerns around use of artificial intelligence in health care research from the perspective of patients with meningioma, caregivers and health care providers: a qualitative study",
    "authors": [
      "Melissa D. McCradden",
      "Ami Baba",
      "Ashirbani Saha",
      "Sidra Ahmad",
      "Kanwar Boparai",
      "Pantea Fadaiefard",
      "Michael D. Cusimano"
    ],
    "year": 2020,
    "abstract": "In this preliminary study, patients and caregivers reported a mixture of hopefulness and concern around the use of AI in health care research, whereas providers were generally more skeptical. These findings provide a point of departure for institutions adopting health AI solutions to consider the ethical implications of this work by understanding stakeholders' perspectives.",
    "doi": "10.9778/cmajo.20190151",
    "url": "https://openalex.org/W3007819350",
    "pdf_url": "http://www.cmajopen.ca/content/8/1/E90.full.pdf",
    "venue": "CMAJ Open",
    "citation_count": 96,
    "fields_of_study": [
      "Snowball sampling",
      "Health care",
      "Qualitative research",
      "Medicine",
      "Delegate"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387894"
  },
  {
    "source": "openalex",
    "source_id": "W2787318954",
    "title": "Using futures methods to create transformative spaces: visions of a good Anthropocene in southern Africa",
    "authors": [
      "Laura Pereira",
      "Tanja Hichert",
      "Maike Hamann",
      "Rika Preiser",
      "Reinette Biggs"
    ],
    "year": 2018,
    "abstract": "CITATION: Pereira, L. M., et al. 2018. Using futures methods to create transformative spaces : visions of a good Anthropocene in southern Africa. Ecology and Society, 23(1):19, doi:10.5751/ES-09907-230119.",
    "doi": "10.5751/es-09907-230119",
    "url": "https://openalex.org/W2787318954",
    "pdf_url": "https://www.ecologyandsociety.org/vol23/iss1/art19/ES-2017-9907.pdf",
    "venue": "Ecology and Society",
    "citation_count": 211,
    "fields_of_study": [
      "Anthropocene",
      "Vision",
      "Transformative learning",
      "Futures contract",
      "Environmental ethics"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387905"
  },
  {
    "source": "openalex",
    "source_id": "W4390564972",
    "title": "The impact of AI on accounting practices: A review: Exploring how artificial intelligence is transforming traditional accounting methods and financial reporting",
    "authors": [
      "Beryl Odonkor",
      "Simon Kaggwa",
      "Prisca Ugomma Uwaoma",
      "Azeez Olanipekun Hassan",
      "Oluwatoyin Ajoke Farayola"
    ],
    "year": 2024,
    "abstract": "This paper delves into the transformative impact of Artificial Intelligence (AI) on traditional accounting practices, examining its role in reshaping financial reporting, auditing, and decision-making processes. The study explores the evolution from manual, labor-intensive accounting methods to sophisticated, AI-driven approaches by setting it against the backdrop of rapid technological advancements. The aim is to critically assess how AI integration is redefining the landscape of accounting, highlighting both the opportunities and challenges it presents. The study meticulously analyzes peer-reviewed articles, case studies, and industry reports from the last decade by employing a systematic literature review and bibliometric analysis. This methodology ensures a comprehensive understanding of AI's integration in accounting, its effectiveness in enhancing accuracy and efficiency, and the strategic implications for accounting professionals and firms. The findings reveal that AI significantly improves the accuracy and efficiency of financial reporting, automating routine tasks and enabling predictive analytics for strategic decision-making. However, challenges such as the need for skilled personnel adept in AI, data privacy concerns, and the high costs of AI integration are notable. The study also highlights the resistance to change as a significant barrier to AI adoption in accounting practices. In conclusion, the paper recommends a balanced approach to AI integration in accounting, emphasizing the need for continuous learning, adaptation, and strategic planning. It advocates for investment in training and development to build AI competency and stresses the importance of ethical considerations and regulatory compliance. The study concludes that while AI presents challenges, its potential to revolutionize accounting practices is undeniable, offering new avenues for growth and innovation in the digital era.",
    "doi": "10.30574/wjarr.2024.21.1.2721",
    "url": "https://openalex.org/W4390564972",
    "pdf_url": "https://wjarr.com/sites/default/files/WJARR-2023-2721.pdf",
    "venue": "World Journal of Advanced Research and Reviews",
    "citation_count": 119,
    "fields_of_study": [
      "Audit",
      "Accounting",
      "Transformative learning",
      "Knowledge management",
      "Business"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387913"
  },
  {
    "source": "openalex",
    "source_id": "W4353050783",
    "title": "Artificial intelligence applied to potential assessment and talent identification in an organisational context",
    "authors": [
      "Tiago Jacob Fernandes Fran\u00e7a",
      "Henrique S\u00e3o Mamede",
      "Jo\u00e3o Barroso",
      "V\u00edtor Santos"
    ],
    "year": 2023,
    "abstract": "Our study provides valuable insights into the relationship between artificial intelligence (AI) and Human Resource Management (HRM). We have minimised bias and ensured reliable findings by employing a systematic literature review and the PRISMA statement. Our comprehensive synthesis of the studies included in this research, along with a bibliometric analysis of articles, journals, indexes, authors' affiliations, citations, keyword co-occurrences, and co-authorship analysis, has produced robust results. The discussion of our findings focuses on critical areas of interest, such as AI and Talent, AI Bias, Ethics and Law, and their impact on Human Resource (HR) management. Our research highlights the recognition by organisations of the importance of talent management in achieving a competitive advantage as higher-level skills become increasingly necessary. Although some HR managers have adopted AI technology for talent acquisition, our study reveals that there is still room for improvement. Our study is in line with previous research that acknowledges the potential for AI to revolutionise HR management and the future of work. Our findings emphasise the need for HR managers to be proactive in embracing technology and bridging the technological, human, societal, and governmental gaps. Our study contributes to the growing body of AI and HR management knowledge, providing essential insights and recommendations for future research. The importance of our study lies in its focus on the role of HR in promoting the benefits of AI-based applications, thereby creating a larger body of knowledge from an organisational perspective.",
    "doi": "10.1016/j.heliyon.2023.e14694",
    "url": "https://openalex.org/W4353050783",
    "pdf_url": "http://www.cell.com/article/S2405844023019011/pdf",
    "venue": "Heliyon",
    "citation_count": 68,
    "fields_of_study": [
      "Knowledge management",
      "Human resource management",
      "Context (archaeology)",
      "Human resources",
      "Talent management"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387938"
  },
  {
    "source": "openalex",
    "source_id": "W3025019304",
    "title": "Reinforcement Learning for Clinical Decision Support in Critical Care: Comprehensive Review",
    "authors": [
      "Siqi Liu",
      "Kay Choong See",
      "Kee Yuan Ngiam",
      "Leo Anthony Celi",
      "Xingzhi Sun",
      "Mengling Feng"
    ],
    "year": 2020,
    "abstract": "Background Decision support systems based on reinforcement learning (RL) have been implemented to facilitate the delivery of personalized care. This paper aimed to provide a comprehensive review of RL applications in the critical care setting. Objective This review aimed to survey the literature on RL applications for clinical decision support in critical care and to provide insight into the challenges of applying various RL models. Methods We performed an extensive search of the following databases: PubMed, Google Scholar, Institute of Electrical and Electronics Engineers (IEEE), ScienceDirect, Web of Science, Medical Literature Analysis and Retrieval System Online (MEDLINE), and Excerpta Medica Database (EMBASE). Studies published over the past 10 years (2010-2019) that have applied RL for critical care were included. Results We included 21 papers and found that RL has been used to optimize the choice of medications, drug dosing, and timing of interventions and to target personalized laboratory values. We further compared and contrasted the design of the RL models and the evaluation metrics for each application. Conclusions RL has great potential for enhancing decision making in critical care. Challenges regarding RL system design, evaluation metrics, and model choice exist. More importantly, further work is required to validate RL in authentic clinical environments.",
    "doi": "10.2196/18477",
    "url": "https://openalex.org/W3025019304",
    "pdf_url": "https://www.jmir.org/2020/7/e18477/PDF",
    "venue": "Journal of Medical Internet Research",
    "citation_count": 189,
    "fields_of_study": [
      "Reinforcement learning",
      "Computer science",
      "Clinical decision support system",
      "Decision support system",
      "MEDLINE"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387961"
  },
  {
    "source": "openalex",
    "source_id": "W2944361236",
    "title": "Digital Medicine: A Primer on Measurement",
    "authors": [
      "Andrea Coravos",
      "Jennifer C. Goldsack",
      "Daniel R. Karlin",
      "Camille Nebeker",
      "Eric Perakslis",
      "Noah Zimmerman",
      "Michael Kelley Erb"
    ],
    "year": 2019,
    "abstract": "Technology is changing how we practice medicine. Sensors and wearables are getting smaller and cheaper, and algorithms are becoming powerful enough to predict medical outcomes. Yet despite rapid advances, healthcare lags behind other industries in truly putting these technologies to use. A major barrier to entry is the cross-disciplinary approach required to create such tools, requiring knowledge from many people across many fields. We aim to drive the field forward by unpacking that barrier, providing a brief introduction to core concepts and terms that define digital medicine. Specifically, we contrast \u201cclinical research\u201d versus routine \u201cclinical care,\u201d outlining the security, ethical, regulatory, and legal issues developers must consider as digital medicine products go to market. We classify types of digital measurements and how to use and validate these measures in different settings. To make this resource engaging and accessible, we have included illustrations and figures throughout that we hope readers will borrow from liberally. This primer is the first in a series that will accelerate the safe and effective advancement of the field of digital medicine.",
    "doi": "10.1159/000500413",
    "url": "https://openalex.org/W2944361236",
    "pdf_url": "https://www.karger.com/Article/Pdf/500413",
    "venue": "Digital Biomarkers",
    "citation_count": 156,
    "fields_of_study": [
      "Field (mathematics)",
      "Health care",
      "Resource (disambiguation)",
      "Data science",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387982"
  },
  {
    "source": "openalex",
    "source_id": "W4386724197",
    "title": "Is ChatGPT Leading Generative AI? What is Beyond Expectations?",
    "authors": [
      "\u00d6mer Ayd\u0131n",
      "Enis Karaarslan"
    ],
    "year": 2023,
    "abstract": "Generative AI has the potential to change the way we do things. The chatbot is one of the most popular implementation areas. Even though companies like Google and Meta had chatbots, ChatGPT became popular as it was made publicly available. Although ChatGPT is still in the early stages of its development, it attracted the attention of people and capital groups. It has taken the public interest; people from different fields, ages, and education levels started using ChatGPT. There have been many trials with ChatGPT. It is possible to see a lot of news and shares on the Internet. The study aims to shed light on what is happening in the literature and get an insight into the user expectations of ChatGPT and Generative AI. We also give information about the competitors of ChatGPT, such as Google\u2019s Bard AI, Claude, Meta\u2019s Wit.ai and Tencent\u2019s HunyuanAide. We describe technical and structural fundamentals and try to shed light on who will win the race. We also shared information about the GPT4 version of OpenAI's ChatGPT. We share the early stage due diligence and current situation analysis for all these points. We examine preprint papers and published articles. We also included striking posts on the LinkedIn platform and a compilation of various blogs and news. We also made use of ChatGPT in editing the content of these resources of this study. We can get an insight into the people's interests through their questions submitted to ChatGPT. We can also understand the capabilities of GPT3, GPT4 and also predict further enhancements.",
    "doi": "10.21541/apjess.1293702",
    "url": "https://openalex.org/W4386724197",
    "pdf_url": "https://dergipark.org.tr/en/download/article-file/3127764",
    "venue": "Academic Platform Journal of Engineering and Smart Systems",
    "citation_count": 150,
    "fields_of_study": [
      "Generative grammar",
      "Competitor analysis",
      "Diligence",
      "World Wide Web",
      "The Internet"
    ],
    "retrieved_at": "2026-02-02T16:58:13.388001"
  },
  {
    "source": "openalex",
    "source_id": "W3015184088",
    "title": "Managing the MNE subsidiary: Advancing a multi-level and dynamic research agenda",
    "authors": [
      "Klaus E. Meyer",
      "Chengguang Li",
      "Andreas Schotter"
    ],
    "year": 2020,
    "abstract": "Abstract Multinational enterprise (MNE) subsidiaries abroad are important organizations in their own rights. They typically hold some of the MNE\u2019s most critical resources, and operate at the forefront of complex international environments. In this review, we identify and organize theoretical and empirical research on subsidiary management based on over 600 articles in leading academic journals. We develop a conceptual framework that integrates complementary streams of theoretical and empirical research with the subsidiary as its focal unit of analysis. In particular, we review six lines of research on subsidiary scope, practices, knowledge management, engagement with local market and nonmarket actors, performance, and individuals within subsidiaries. We highlight theoretical perspectives that have contributed to, and been advanced by, research on MNE subsidiaries. Based on the review, we explore future research agendas, linking the contemporary research themes with two main thrusts. First, subsidiary management is a multi-level phenomenon that would benefit from more microfoundational research. Second, subsidiary management operates at key interfaces of technology paradigm shifts, and of disruptions in the political and institutional environment. Research into the dynamics of subsidiary management would thus enhance our understanding of international business in a volatile global economy.",
    "doi": "10.1057/s41267-020-00318-w",
    "url": "https://openalex.org/W3015184088",
    "pdf_url": "https://link.springer.com/content/pdf/10.1057/s41267-020-00318-w.pdf",
    "venue": "Journal of International Business Studies",
    "citation_count": 316,
    "fields_of_study": [
      "Subsidiary",
      "Multinational corporation",
      "International business",
      "Conceptual framework",
      "Scope (computer science)"
    ],
    "retrieved_at": "2026-02-02T16:58:13.388026"
  },
  {
    "source": "openalex",
    "source_id": "W3120171868",
    "title": "Digital transformation: What we have learned (thus far) and what is next",
    "authors": [
      "Sabrina Schneider",
      "Olga Kokshagina"
    ],
    "year": 2021,
    "abstract": "There is certainly a lot of discussion about digital technologies, their transformative nature, and their potentially disruptive impact on business and society. The number of publications on digital technologies and their impact on business and management have risen dramatically. This paper's main objective is to draw attention to practical and research\u2010related views on what we know and what we still need to learn about business and management in the digital era. We do so by combining the insights obtained from interviews with senior managers in charge of their firm's digital transformation activities in 2017 with the results of a systematic literature review covering a decade of practice\u2010oriented, academic literature on the impact of digital technologies. We identify the challenges that firms face at the beginning of their digital transformation efforts and summarize the managerial guidance offered by 242 publications over the years, 133 of which have been published since 2017. Based on the analysis conducted, we discuss the emerging solutions for a number of the key challenges identified in 2017, flag the remaining ones, and identify new themes that require attention. This leads us to propose an agenda for future, practice\u2010oriented research on digital transformation.",
    "doi": "10.1111/caim.12414",
    "url": "https://openalex.org/W3120171868",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/caim.12414",
    "venue": "Creativity and Innovation Management",
    "citation_count": 167,
    "fields_of_study": [
      "Digital transformation",
      "Transformative learning",
      "Key (lock)",
      "Digital strategy",
      "Face (sociological concept)"
    ],
    "retrieved_at": "2026-02-02T16:58:13.388044"
  },
  {
    "source": "openalex",
    "source_id": "W3012477544",
    "title": "Working in the digitized economy: HRM theory &amp; practice",
    "authors": [
      "Catherine E. Connelly",
      "Christian Fieseler",
      "Matej \u010cerne",
      "Steffen R. Giessner",
      "Sut I Wong"
    ],
    "year": 2020,
    "abstract": null,
    "doi": "10.1016/j.hrmr.2020.100762",
    "url": "https://openalex.org/W3012477544",
    "pdf_url": "https://www.sciencedirect.com/science/article/pii/S1053482220300358",
    "venue": "Human Resource Management Review",
    "citation_count": 112,
    "fields_of_study": [
      "Gig economy",
      "Human resource management",
      "Context (archaeology)",
      "Phenomenon",
      "Knowledge management"
    ],
    "retrieved_at": "2026-02-02T16:58:13.388062"
  },
  {
    "source": "openalex",
    "source_id": "W4391598857",
    "title": "A Comprehensive Review of AI Techniques for Addressing Algorithmic Bias in Job Hiring",
    "authors": [
      "Elham Albaroudi",
      "Taha Mansouri",
      "Ali Alameer"
    ],
    "year": 2024,
    "abstract": "The study comprehensively reviews artificial intelligence (AI) techniques for addressing algorithmic bias in job hiring. More businesses are using AI in curriculum vitae (CV) screening. While the move improves efficiency in the recruitment process, it is vulnerable to biases, which have adverse effects on organizations and the broader society. This research aims to analyze case studies on AI hiring to demonstrate both successful implementations and instances of bias. It also seeks to evaluate the impact of algorithmic bias and the strategies to mitigate it. The basic design of the study entails undertaking a systematic review of existing literature and research studies that focus on artificial intelligence techniques employed to mitigate bias in hiring. The results demonstrate that the correction of the vector space and data augmentation are effective natural language processing (NLP) and deep learning techniques for mitigating algorithmic bias in hiring. The findings underscore the potential of artificial intelligence techniques in promoting fairness and diversity in the hiring process with the application of artificial intelligence techniques. The study contributes to human resource practice by enhancing hiring algorithms\u2019 fairness. It recommends the need for collaboration between machines and humans to enhance the fairness of the hiring process. The results can help AI developers make algorithmic changes needed to enhance fairness in AI-driven tools. This will enable the development of ethical hiring tools, contributing to fairness in society.",
    "doi": "10.3390/ai5010019",
    "url": "https://openalex.org/W4391598857",
    "pdf_url": "https://www.mdpi.com/2673-2688/5/1/19/pdf?version=1707285598",
    "venue": "AI",
    "citation_count": 76,
    "fields_of_study": [
      "Computer science",
      "Data science",
      "Political science"
    ],
    "retrieved_at": "2026-02-02T16:58:13.388065"
  },
  {
    "source": "openalex",
    "source_id": "W4323900663",
    "title": "Quality, Usability, and Effectiveness of mHealth Apps and the Role of Artificial Intelligence: Current Scenario and Challenges",
    "authors": [
      "Alejandro D\u00e9niz-Garc\u00eda",
      "Himar Fabelo",
      "Antonio J. Rodr\u00edguez-Almeida",
      "Garlene Zamora-Zamorano",
      "Mar\u00eda Castro-Fern\u00e1ndez",
      "Mar\u00eda del Pino Alberiche-Ruano",
      "Terje Solvoll",
      "Concei\u00e7\u00e3o Granja",
      "Thomas Schopf",
      "Gustavo M. Callic\u00f3",
      "Cristina Soguero-Ru\u00edz",
      "Ana M. W\u00e4gner"
    ],
    "year": 2023,
    "abstract": "The use of artificial intelligence (AI) and big data in medicine has increased in recent years. Indeed, the use of AI in mobile health (mHealth) apps could considerably assist both individuals and health care professionals in the prevention and management of chronic diseases, in a person-centered manner. Nonetheless, there are several challenges that must be overcome to provide high-quality, usable, and effective mHealth apps. Here, we review the rationale and guidelines for the implementation of mHealth apps and the challenges regarding quality, usability, and user engagement and behavior change, with a special focus on the prevention and management of noncommunicable diseases. We suggest that a cocreation-based framework is the best method to address these challenges. Finally, we describe the current and future roles of AI in improving personalized medicine and provide recommendations for developing AI-based mHealth apps. We conclude that the implementation of AI and mHealth apps for routine clinical practice and remote health care will not be feasible until we overcome the main challenges regarding data privacy and security, quality assessment, and the reproducibility and uncertainty of AI results. Moreover, there is a lack of both standardized methods to measure the clinical outcomes of mHealth apps and techniques to encourage user engagement and behavior changes in the long term. We expect that in the near future, these obstacles will be overcome and that the ongoing European project, Watching the risk factors (WARIFA), will provide considerable advances in the implementation of AI-based mHealth apps for disease prevention and health promotion.",
    "doi": "10.2196/44030",
    "url": "https://openalex.org/W4323900663",
    "pdf_url": "https://www.jmir.org/2023/1/e44030/PDF",
    "venue": "Journal of Medical Internet Research",
    "citation_count": 190,
    "fields_of_study": [
      "mHealth",
      "Usability",
      "Health care",
      "Computer science",
      "Quality (philosophy)"
    ],
    "retrieved_at": "2026-02-02T16:58:13.388086"
  },
  {
    "source": "openalex",
    "source_id": "W4224249136",
    "title": "Digital Transformation in Smart Farm and Forest Operations Needs Human-Centered AI: Challenges and Future Directions",
    "authors": [
      "Andreas Holzinger",
      "Anna Saranti",
      "Alessa Angerschmid",
      "Carl Orge Retzlaff",
      "Andreas Gronauer",
      "Vladimir Pejakovi\u0107",
      "Francisco Medel-Jim\u00e9nez",
      "Theresa Krexner",
      "Christoph Gollob",
      "Karl Stampfer"
    ],
    "year": 2022,
    "abstract": "The main impetus for the global efforts toward the current digital transformation in almost all areas of our daily lives is due to the great successes of artificial intelligence (AI), and in particular, the workhorse of AI, statistical machine learning (ML). The intelligent analysis, modeling, and management of agricultural and forest ecosystems, and of the use and protection of soils, already play important roles in securing our planet for future generations and will become irreplaceable in the future. Technical solutions must encompass the entire agricultural and forestry value chain. The process of digital transformation is supported by cyber-physical systems enabled by advances in ML, the availability of big data and increasing computing power. For certain tasks, algorithms today achieve performances that exceed human levels. The challenge is to use multimodal information fusion, i.e., to integrate data from different sources (sensor data, images, *omics), and explain to an expert why a certain result was achieved. However, ML models often react to even small changes, and disturbances can have dramatic effects on their results. Therefore, the use of AI in areas that matter to human life (agriculture, forestry, climate, health, etc.) has led to an increased need for trustworthy AI with two main components: explainability and robustness. One step toward making AI more robust is to leverage expert knowledge. For example, a farmer/forester in the loop can often bring in experience and conceptual understanding to the AI pipeline\u2014no AI can do this. Consequently, human-centered AI (HCAI) is a combination of \u201cartificial intelligence\u201d and \u201cnatural intelligence\u201d to empower, amplify, and augment human performance, rather than replace people. To achieve practical success of HCAI in agriculture and forestry, this article identifies three important frontier research areas: (1) intelligent information fusion; (2) robotics and embodied intelligence; and (3) augmentation, explanation, and verification for trusted decision support. This goal will also require an agile, human-centered design approach for three generations (G). G1: Enabling easily realizable applications through immediate deployment of existing technology. G2: Medium-term modification of existing technology. G3: Advanced adaptation and evolution beyond state-of-the-art.",
    "doi": "10.3390/s22083043",
    "url": "https://openalex.org/W4224249136",
    "pdf_url": "https://www.mdpi.com/1424-8220/22/8/3043/pdf?version=1652184539",
    "venue": "Sensors",
    "citation_count": 154,
    "fields_of_study": [
      "Artificial intelligence",
      "Computer science",
      "Big data",
      "Leverage (statistics)",
      "Data science"
    ],
    "retrieved_at": "2026-02-02T16:58:13.388107"
  },
  {
    "source": "openalex",
    "source_id": "W3209891779",
    "title": "Scientific, Legal, and Ethical Concerns About AI-Based Personnel Selection Tools: A Call to Action",
    "authors": [
      "Nancy T. Tippins",
      "Frederick L. Oswald",
      "S. Morton McPhail"
    ],
    "year": 2021,
    "abstract": "Organizations are increasingly turning toward personnel selection tools that rely on artificial intelligence (AI) technologies and machine learning algorithms that, together, intend to predict the future success of employees better than traditional tools. These new forms of assessment include online games, video-based interviews, and big data pulled from many sources, including test responses, test-taking behavior, applications, resumes, and social media. Speedy processing, lower costs, convenient access, and applicant engagement are often and rightfully cited as the practical advantages for using these selection tools. At the same time, however, these tools raise serious concerns about their effectiveness in terms their conceptual relevance to the job, their basis in a job analysis to ensure job relevancy, their measurement characteristics (reliability and stability), their validity in predicting employee-relevant outcomes, their evidence and normative information being updated appropriately, and the associated ethical concerns around what information is being represented to employers and told to job candidates. This paper explores these concerns, concluding with an urgent call to industrial and organizational psychologists to extend existing professional standards for employment testing to these new AI and machine learning based forms of testing, including standards and requirements for their documentation.",
    "doi": "10.25035/pad.2021.02.001",
    "url": "https://openalex.org/W3209891779",
    "pdf_url": "https://scholarworks.bgsu.edu/cgi/viewcontent.cgi?article=1170&context=pad",
    "venue": "Personnel Assessment and Decisions",
    "citation_count": 103,
    "fields_of_study": [
      "Relevance (law)",
      "Computer science",
      "Personnel selection",
      "Test (biology)",
      "Normative"
    ],
    "retrieved_at": "2026-02-02T16:58:13.388138"
  },
  {
    "source": "openalex",
    "source_id": "W4225496733",
    "title": "Financial Risk Management and Explainable, Trustworthy, Responsible AI",
    "authors": [
      "Sebastian Fritz-Morgenthal",
      "Bernhard Hein",
      "Jochen Papenbrock"
    ],
    "year": 2022,
    "abstract": "This perspective paper is based on several sessions by the members of the Round Table AI at FIRM 1 , with input from a number of external and international speakers. Its particular focus lies on the management of the model risk of productive models in banks and other financial institutions. The models in view range from simple rules-based approaches to Artificial Intelligence (AI) or Machine learning (ML) models with a high level of sophistication. The typical applications of those models are related to predictions and decision making around the value chain of credit risk (including accounting side under IFRS9 or related national GAAP approaches), insurance risk or other financial risk types. We expect more models of higher complexity in the space of anti-money laundering, fraud detection and transaction monitoring as well as a rise of AI/ML models as alternatives to current methods in solving some of the more intricate stochastic differential equations needed for the pricing and/or valuation of derivatives. The same type of model is also successful in areas unrelated to risk management, such as sales optimization, customer lifetime value considerations, robo-advisory, and other fields of applications. The paper refers to recent related publications from central banks, financial supervisors and regulators as well as other relevant sources and working groups. It aims to give practical advice for establishing a risk-based governance and testing framework for the mentioned model types and discusses the use of recent technologies, approaches, and platforms to support the establishment of responsible, trustworthy, explainable, auditable, and manageable AI/ML in production. In view of the recent EU publication on AI, also referred to as the EU Artificial Intelligence Act (AIA), we also see a certain added value for this paper as an instigator of further thinking outside of the financial services sector, in particular where \u201cHigh Risk\u201d models according to the mentioned EU consultation are concerned.",
    "doi": "10.3389/frai.2022.779799",
    "url": "https://openalex.org/W4225496733",
    "pdf_url": "https://www.frontiersin.org/articles/10.3389/frai.2022.779799/pdf",
    "venue": "Frontiers in Artificial Intelligence",
    "citation_count": 87,
    "fields_of_study": [
      "Sophistication",
      "Risk management",
      "Valuation (finance)",
      "Computer science",
      "Corporate governance"
    ],
    "retrieved_at": "2026-02-02T16:58:13.388157"
  },
  {
    "source": "openalex",
    "source_id": "W4390480754",
    "title": "On the Integration of Artificial Intelligence and Blockchain Technology: A Perspective About Security",
    "authors": [
      "Alexandr Kuznetsov",
      "Paolo Sernani",
      "Luca Romeo",
      "Emanuele Frontoni",
      "Adriano Mancini"
    ],
    "year": 2024,
    "abstract": "As reliance on disruptive applications based on Artificial Intelligence (AI) and Blockchain grows, the need for secure and trustworthy solutions becomes ever more critical. Whereas much research has been conducted on AI and Blockchain, there is a shortage of comprehensive studies examining their integration from a security perspective. Hence, this survey addresses such a gap and provides insights for policymakers, researchers, and practitioners exploiting AI and Blockchain\u2019s evolving integration. Specifically, this paper analyzes the potential benefits of the integration of AI and Blockchain as well as the related security concerns, identifying possible mitigation strategies, suggesting regulatory measures, and describing the impact it has on public trust.",
    "doi": "10.1109/access.2023.3349019",
    "url": "https://openalex.org/W4390480754",
    "pdf_url": "https://ieeexplore.ieee.org/ielx7/6287639/6514899/10379100.pdf",
    "venue": "IEEE Access",
    "citation_count": 98,
    "fields_of_study": [
      "Blockchain",
      "Perspective (graphical)",
      "Computer science",
      "Computer security",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:13.388185"
  },
  {
    "source": "openalex",
    "source_id": "W4281706229",
    "title": "A reimbursement framework for artificial intelligence in healthcare",
    "authors": [
      "Michael D. Abr\u00e0moff",
      "Cybil Roehrenbeck",
      "Sylvia Trujillo",
      "Juli D. Goldstein",
      "A. S. Graves",
      "Michael X. Repka",
      "Ezequiel Silva"
    ],
    "year": 2022,
    "abstract": "Responsible adoption of healthcare artificial intelligence (AI) requires that AI systems which benefit patients and populations, including autonomous AI systems, are incentivized financially at a consistent and sustainable level. We present a framework for analytically determining value and cost of each unique AI service. The framework\u2019s processes involve affected stakeholders, including patients, providers, legislators, payors, and AI creators, in order to find an optimum balance among ethics, workflow, cost, and value as identified by each of these stakeholders. We use a real world, completed, an example of a specific autonomous AI service, to show how multiple \u201cguardrails\u201d for the AI system implementation enforce ethical principles. It can guide the development of sustainable reimbursement for future AI services, ensuring the quality of care, healthcare equity, and mitigation of potential bias, and thereby contribute to realize the potential of AI to improve clinical outcomes for patients and populations, improve access, remove disparities, and reduce cost.",
    "doi": "10.1038/s41746-022-00621-w",
    "url": "https://openalex.org/W4281706229",
    "pdf_url": "https://www.nature.com/articles/s41746-022-00621-w.pdf",
    "venue": "npj Digital Medicine",
    "citation_count": 93,
    "fields_of_study": [
      "Reimbursement",
      "Workflow",
      "Health care",
      "Equity (law)",
      "Business"
    ],
    "retrieved_at": "2026-02-02T16:58:13.388201"
  },
  {
    "source": "openalex",
    "source_id": "W4200423370",
    "title": "Perspectives on Digital Humanism",
    "authors": [
      "Hannes Werthner",
      "Erich Prem",
      "Edward A. Lee",
      "Carlo Ghezzi"
    ],
    "year": 2021,
    "abstract": "Stephanie Wogowitsch, from the e-commerce group of TU Wien",
    "doi": "10.1007/978-3-030-86144-5",
    "url": "https://openalex.org/W4200423370",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/978-3-030-86144-5.pdf",
    "venue": null,
    "citation_count": 92,
    "fields_of_study": [
      "Humanism",
      "Philosophy",
      "Theology"
    ],
    "retrieved_at": "2026-02-02T16:58:13.388217"
  },
  {
    "source": "openalex",
    "source_id": "W2941568957",
    "title": "What's Inside the Black Box? AI Challenges for Lawyers and Researchers",
    "authors": [
      "Ronald Yu",
      "Gabriele Spina Al\u00ec"
    ],
    "year": 2019,
    "abstract": "Abstract The Artificial intelligence revolution is happening and is going to drastically re-shape legal research in both the private sector and academia. AI research tools present several advantages over traditional research methods. They allow for the analysis and review of large datasets (\u2018Big Data\u2019) and can identify patterns that are imperceptible to human researchers. However, the wonders of AI legal research are not without perils. Because of their complexity, AI systems can escape the control and understanding of their operators and programmers. Therefore, especially when run by researchers with insufficient IT background, computational AI research may skew analyses or result in flawed research. Premised thus, the main goals of this paper, written by Ronald Yu and Gabriele Spina Al\u00ec, are to analyse some of the factors that can jeopardize the reliability of AI-assisted legal research and to review some of the solutions to mitigate this situation.",
    "doi": "10.1017/s1472669619000021",
    "url": "https://openalex.org/W2941568957",
    "pdf_url": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/8A547878999427F7222C3CEFC3CE5E01/S1472669619000021a.pdf/div-class-title-what-s-inside-the-black-box-ai-challenges-for-lawyers-and-researchers-div.pdf",
    "venue": "Legal Information Management",
    "citation_count": 127,
    "fields_of_study": [
      "Black box",
      "Big data",
      "Computer science",
      "Data science",
      "Reliability (semiconductor)"
    ],
    "retrieved_at": "2026-02-02T16:58:13.388221"
  },
  {
    "source": "openalex",
    "source_id": "W3136635219",
    "title": "Adoption of artificial intelligence in breast imaging: evaluation, ethical constraints and limitations",
    "authors": [
      "Sarah Hickman",
      "Gabrielle Baxter",
      "Fiona J. Gilbert"
    ],
    "year": 2021,
    "abstract": null,
    "doi": "10.1038/s41416-021-01333-w",
    "url": "https://openalex.org/W3136635219",
    "pdf_url": "https://www.nature.com/articles/s41416-021-01333-w.pdf",
    "venue": "British Journal of Cancer",
    "citation_count": 102,
    "fields_of_study": [
      "Workflow",
      "Breast imaging",
      "Health care",
      "Computer science",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:13.388236"
  },
  {
    "source": "openalex",
    "source_id": "W4394855484",
    "title": "AI and Ethics: A Systematic Review of the Ethical Considerations of Large Language Model Use in Surgery Research",
    "authors": [
      "Sophia M. Pressman",
      "Sahar Borna",
      "Cesar A. Gomez-Cabello",
      "Syed Ali Haider",
      "Clifton R. Haider",
      "Antonio J. Forte"
    ],
    "year": 2024,
    "abstract": "Introduction: As large language models receive greater attention in medical research, the investigation of ethical considerations is warranted. This review aims to explore surgery literature to identify ethical concerns surrounding these artificial intelligence models and evaluate how autonomy, beneficence, nonmaleficence, and justice are represented within these ethical discussions to provide insights in order to guide further research and practice. Methods: A systematic review was conducted in accordance with the Preferred Reporting Items for Systematic Reviews and Meta-Analyses guidelines. Five electronic databases were searched in October 2023. Eligible studies included surgery-related articles that focused on large language models and contained adequate ethical discussion. Study details, including specialty and ethical concerns, were collected. Results: The literature search yielded 1179 articles, with 53 meeting the inclusion criteria. Plastic surgery, orthopedic surgery, and neurosurgery were the most represented surgical specialties. Autonomy was the most explicitly cited ethical principle. The most frequently discussed ethical concern was accuracy (n = 45, 84.9%), followed by bias, patient confidentiality, and responsibility. Conclusion: The ethical implications of using large language models in surgery are complex and evolving. The integration of these models into surgery necessitates continuous ethical discourse to ensure responsible and ethical use, balancing technological advancement with human dignity and safety.",
    "doi": "10.3390/healthcare12080825",
    "url": "https://openalex.org/W4394855484",
    "pdf_url": "https://www.mdpi.com/2227-9032/12/8/825/pdf?version=1713249916",
    "venue": "Healthcare",
    "citation_count": 79,
    "fields_of_study": [
      "Beneficence",
      "Autonomy",
      "Dignity",
      "Confidentiality",
      "Engineering ethics"
    ],
    "retrieved_at": "2026-02-02T16:58:14.584771"
  },
  {
    "source": "openalex",
    "source_id": "W4312129526",
    "title": "Confronting racially exclusionary practices in the acquisition and analyses of neuroimaging data",
    "authors": [
      "Jocelyn A. Ricard",
      "Termara Parker",
      "Elvisha Dhamala",
      "Jasmine Kwasa",
      "AZA Stephen Allsop",
      "Avram J. Holmes"
    ],
    "year": 2022,
    "abstract": "Across the brain sciences, institutions and individuals have begun to actively acknowledge and address the presence of racism, bias, and associated barriers to inclusivity within our community. However, even with these recent calls to action, limited attention has been directed to inequities in the research methods and analytic approaches we use. The very process of science, including how we recruit, the methodologies we utilize and the analyses we conduct, can have marked downstream effects on the equity and generalizability of scientific discoveries across the global population. Despite our best intentions, the use of field-standard approaches can inadvertently exclude participants from engaging in research and yield biased brain-behavior relationships. To address these pressing issues, we discuss actionable ways and important questions to move the fields of neuroscience and psychology forward in designing better studies to address the history of exclusionary practices in human brain mapping.",
    "doi": "10.1038/s41593-022-01218-y",
    "url": "https://openalex.org/W4312129526",
    "pdf_url": "https://www.nature.com/articles/s41593-022-01218-y.pdf",
    "venue": "Nature Neuroscience",
    "citation_count": 139,
    "fields_of_study": [
      "Neurolaw",
      "Generalizability theory",
      "Psychology",
      "Social neuroscience",
      "Neuroimaging"
    ],
    "retrieved_at": "2026-02-02T16:58:14.584808"
  },
  {
    "source": "openalex",
    "source_id": "W4200460915",
    "title": "Responsible media technology and AI: challenges and research directions",
    "authors": [
      "Christoph Trattner",
      "Dietmar Jannach",
      "Enrico Motta",
      "Irene Costera Meijer",
      "Nicholas Diakopoulos",
      "Mehdi Elahi",
      "Andreas L. Opdahl",
      "Bj\u00f8rnar Tessem",
      "Nj\u00e5l Borch",
      "Morten Fjeld",
      "Lilja \u00d8vrelid",
      "Koenraad De Smedt",
      "Hallvard Moe"
    ],
    "year": 2021,
    "abstract": "Abstract The last two decades have witnessed major disruptions to the traditional media industry as a result of technological breakthroughs. New opportunities and challenges continue to arise, most recently as a result of the rapid advance and adoption of artificial intelligence technologies. On the one hand, the broad adoption of these technologies may introduce new opportunities for diversifying media offerings, fighting disinformation, and advancing data-driven journalism. On the other hand, techniques such as algorithmic content selection and user personalization can introduce risks and societal threats. The challenge of balancing these opportunities and benefits against their potential for negative impacts underscores the need for more research in responsible media technology. In this paper, we first describe the major challenges\u2014both for societies and the media industry\u2014that come with modern media technology. We then outline various places in the media production and dissemination chain, where research gaps exist, where better technical approaches are needed, and where technology must be designed in a way that can effectively support responsible editorial processes and principles. We argue that a comprehensive approach to research in responsible media technology, leveraging an interdisciplinary approach and a close cooperation between the media industry and academic institutions, is urgently needed.",
    "doi": "10.1007/s43681-021-00126-4",
    "url": "https://openalex.org/W4200460915",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s43681-021-00126-4.pdf",
    "venue": "AI and Ethics",
    "citation_count": 86,
    "fields_of_study": [
      "Disinformation",
      "Personalization",
      "Emerging technologies",
      "Social media",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:14.584824"
  },
  {
    "source": "openalex",
    "source_id": "W4388907242",
    "title": "Artificial Intelligence and Sensor Innovations: Enhancing Livestock Welfare with a Human-Centric Approach",
    "authors": [
      "Suresh Neethirajan"
    ],
    "year": 2023,
    "abstract": "Abstract In the wake of rapid advancements in artificial intelligence (AI) and sensor technologies, a new horizon of possibilities has emerged across diverse sectors. Livestock farming, a domain often sidelined in conventional AI discussions, stands at the cusp of this transformative wave. This paper delves into the profound potential of AI and sensor innovations in reshaping animal welfare in livestock farming, with a pronounced emphasis on a human-centric paradigm. Central to our discourse is the symbiotic interplay between cutting-edge technology and human expertise. While AI and sensor mechanisms offer real-time, comprehensive, and objective insights into animal welfare, it\u2019s the farmer\u2019s intrinsic knowledge of their livestock and environment that should steer these technological strides. We champion the notion of technology as an enhancer of farmers\u2019 innate capabilities, not a substitute. Our manuscript sheds light on: Objective Animal Welfare Indicators: An exhaustive exploration of health, behavioral, and physiological metrics, underscoring AI\u2019s prowess in delivering precise, timely, and objective evaluations. Farmer-Centric Approach: A focus on the pivotal role of farmers in the adept adoption and judicious utilization of AI and sensor technologies, coupled with discussions on crafting intuitive, pragmatic, and cost-effective solutions tailored to farmers' distinct needs. Ethical and Social Implications: A discerning scrutiny of the digital metamorphosis in farming, encompassing facets like animal privacy, data safeguarding, responsible AI deployment, and potential technological access disparities. Future Pathways: Advocacy for principled technology design, unambiguous responsible use guidelines, and fair technology access, all echoing the fundamental principles of human-centric computing and analytics. In essence, our paper furnishes pioneering insights at the crossroads of farming, animal welfare, technology, and ethics. It presents a rejuvenated perspective, bridging the chasm between technological advancements and their human beneficiaries, resonating seamlessly with the ethos of the Human-Centric Intelligent Systems journal. This comprehensive analysis thus marks a significant stride in the burgeoning domain of human-centric intelligent systems, especially within the digital livestock farming landscape, fostering a harmonious coexistence of technology, animals, and humans.",
    "doi": "10.1007/s44230-023-00050-2",
    "url": "https://openalex.org/W4388907242",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s44230-023-00050-2.pdf",
    "venue": "Human-Centric Intelligent Systems",
    "citation_count": 100,
    "fields_of_study": [
      "Animal welfare",
      "Transformative learning",
      "Safeguarding",
      "Responsible Research and Innovation",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:14.584842"
  },
  {
    "source": "openalex",
    "source_id": "W4387461693",
    "title": "Artificial Intelligence (AI) Trust Framework and Maturity Model: Applying an Entropy Lens to Improve Security, Privacy, and Ethical AI",
    "authors": [
      "Michael Mylrea",
      "Nikki Robinson"
    ],
    "year": 2023,
    "abstract": "Recent advancements in artificial intelligence (AI) technology have raised concerns about the ethical, moral, and legal safeguards. There is a pressing need to improve metrics for assessing security and privacy of AI systems and to manage AI technology in a more ethical manner. To address these challenges, an AI Trust Framework and Maturity Model is proposed to enhance trust in the design and management of AI systems. Trust in AI involves an agreed-upon understanding between humans and machines about system performance. The framework utilizes an \u201centropy lens\u201d to root the study in information theory and enhance transparency and trust in \u201cblack box\u201d AI systems, which lack ethical guardrails. High entropy in AI systems can decrease human trust, particularly in uncertain and competitive environments. The research draws inspiration from entropy studies to improve trust and performance in autonomous human\u2013machine teams and systems, including interconnected elements in hierarchical systems. Applying this lens to improve trust in AI also highlights new opportunities to optimize performance in teams. Two use cases are described to validate the AI framework\u2019s ability to measure trust in the design and management of AI systems.",
    "doi": "10.3390/e25101429",
    "url": "https://openalex.org/W4387461693",
    "pdf_url": "https://www.mdpi.com/1099-4300/25/10/1429/pdf?version=1696854810",
    "venue": "Entropy",
    "citation_count": 78,
    "fields_of_study": [
      "Computer science",
      "Transparency (behavior)",
      "Through-the-lens metering",
      "Entropy (arrow of time)",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:14.584870"
  },
  {
    "source": "openalex",
    "source_id": "W4387099986",
    "title": "The promise of digital healthcare technologies",
    "authors": [
      "Andy Wai Kan Yeung",
      "Ali Torkamani",
      "Atul J. Butte",
      "Benjamin S. Glicksberg",
      "Bj\u00f6rn W. Schuller",
      "Blanca Rodr\u00edguez",
      "Daniel Shu Wei Ting",
      "David W. Bates",
      "Eva Schaden",
      "Lili Yuan",
      "Harald Willschke",
      "Jeroen van der Laak",
      "Josip Car",
      "Kazem Rahimi",
      "Leo Anthony Celi",
      "Maciej Banach",
      "Maria Klete\u010dka-Pulker",
      "Oliver Kimberger",
      "Roland Eils",
      "Sheikh Mohammed Shariful Islam",
      "Stephen T.C. Wong",
      "Tien Yin Wong",
      "Wei Gao",
      "S\u00f8ren Brunak",
      "Atanas G. Atanasov"
    ],
    "year": 2023,
    "abstract": "Digital health technologies have been in use for many years in a wide spectrum of healthcare scenarios. This narrative review outlines the current use and the future strategies and significance of digital health technologies in modern healthcare applications. It covers the current state of the scientific field (delineating major strengths, limitations, and applications) and envisions the future impact of relevant emerging key technologies. Furthermore, we attempt to provide recommendations for innovative approaches that would accelerate and benefit the research, translation and utilization of digital health technologies.",
    "doi": "10.3389/fpubh.2023.1196596",
    "url": "https://openalex.org/W4387099986",
    "pdf_url": "https://www.frontiersin.org/articles/10.3389/fpubh.2023.1196596/pdf?isPublishedV2=False",
    "venue": "Frontiers in Public Health",
    "citation_count": 168,
    "fields_of_study": [
      "Digital health",
      "Health care",
      "Narrative review",
      "Emerging technologies",
      "Key (lock)"
    ],
    "retrieved_at": "2026-02-02T16:58:14.584889"
  },
  {
    "source": "openalex",
    "source_id": "W3177938779",
    "title": "Academic Integrity in Online Assessment: A Research Review",
    "authors": [
      "Olivia Leslie Holden",
      "Meghan E. Norris",
      "Valerie A. Kuhlmeier"
    ],
    "year": 2021,
    "abstract": "This paper provides a review of current research on academic integrity in higher education, with a focus on its application to assessment practices in online courses. Understanding the types and causes of academic dishonesty can inform the suite of methods that might be used to most effectively promote academic integrity. Thus, the paper first addresses the question of why students engage in academically dishonest behaviours. Then, a review of current methods to reduce academically dishonest behaviours is presented. Acknowledging the increasing use of online courses within the postsecondary curriculum, it is our hope that this review will aid instructors and administrators in their decision-making process regarding online evaluations and encourage future study that will form the foundation of evidence-based practices.",
    "doi": "10.3389/feduc.2021.639814",
    "url": "https://openalex.org/W3177938779",
    "pdf_url": "https://www.frontiersin.org/articles/10.3389/feduc.2021.639814/pdf",
    "venue": "Frontiers in Education",
    "citation_count": 259,
    "fields_of_study": [
      "Academic integrity",
      "Academic dishonesty",
      "Engineering ethics",
      "Suite",
      "Process (computing)"
    ],
    "retrieved_at": "2026-02-02T16:58:14.584899"
  },
  {
    "source": "openalex",
    "source_id": "W4327620114",
    "title": "What does the public think about artificial intelligence?\u2014A criticality map to understand bias in the public perception of AI",
    "authors": [
      "Philipp Brauner",
      "Alexander Hick",
      "Ralf Philipsen",
      "Martina Ziefle"
    ],
    "year": 2023,
    "abstract": "Introduction Artificial Intelligence (AI) has become ubiquitous in medicine, business, manufacturing and transportation, and is entering our personal lives. Public perceptions of AI are often shaped either by admiration for its benefits and possibilities, or by uncertainties, potential threats and fears about this opaque and perceived as mysterious technology. Understanding the public perception of AI, as well as its requirements and attributions, is essential for responsible research and innovation and enables aligning the development and governance of future AI systems with individual and societal needs. Methods To contribute to this understanding, we asked 122 participants in Germany how they perceived 38 statements about artificial intelligence in different contexts (personal, economic, industrial, social, cultural, health). We assessed their personal evaluation and the perceived likelihood of these aspects becoming reality. Results We visualized the responses in a criticality map that allows the identification of issues that require particular attention from research and policy-making. The results show that the perceived evaluation and the perceived expectations differ considerably between the domains. The aspect perceived as most critical is the fear of cybersecurity threats, which is seen as highly likely and least liked. Discussion The diversity of users influenced the evaluation: People with lower trust rated the impact of AI as more positive but less likely. Compared to people with higher trust, they consider certain features and consequences of AI to be more desirable, but they think the impact of AI will be smaller. We conclude that AI is still a \u201cblack box\u201d for many. Neither the opportunities nor the risks can yet be adequately assessed, which can lead to biased and irrational control beliefs in the public perception of AI. The article concludes with guidelines for promoting AI literacy to facilitate informed decision-making.",
    "doi": "10.3389/fcomp.2023.1113903",
    "url": "https://openalex.org/W4327620114",
    "pdf_url": "https://www.frontiersin.org/articles/10.3389/fcomp.2023.1113903/pdf",
    "venue": "Frontiers in Computer Science",
    "citation_count": 104,
    "fields_of_study": [
      "Perception",
      "Admiration",
      "Attribution",
      "Psychology",
      "Diversity (politics)"
    ],
    "retrieved_at": "2026-02-02T16:58:14.584911"
  },
  {
    "source": "openalex",
    "source_id": "W4283204686",
    "title": "A Virtue-Based Framework to Support Putting AI Ethics into Practice",
    "authors": [
      "Thilo Hagendorff"
    ],
    "year": 2022,
    "abstract": "Abstract Many ethics initiatives have stipulated sets of principles and standards for good technology development in the AI sector. However, several AI ethics researchers have pointed out a lack of practical realization of these principles. Following that, AI ethics underwent a practical turn, but without deviating from the principled approach. This paper proposes a complementary to the principled approach that is based on virtue ethics. It defines four \u201cbasic AI virtues\u201d, namely justice, honesty, responsibility and care, all of which represent specific motivational settings that constitute the very precondition for ethical decision making in the AI field. Moreover, it defines two \u201csecond-order AI virtues\u201d, prudence and fortitude, that bolster achieving the basic virtues by helping with overcoming bounded ethicality or hidden psychological forces that can impair ethical decision making and that are hitherto disregarded in AI ethics. Lastly, the paper describes measures for successfully cultivating the mentioned virtues in organizations dealing with AI research and development.",
    "doi": "10.1007/s13347-022-00553-z",
    "url": "https://openalex.org/W4283204686",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s13347-022-00553-z.pdf",
    "venue": "Philosophy & Technology",
    "citation_count": 82,
    "fields_of_study": [
      "Philosophy of technology",
      "Virtue",
      "Virtue ethics",
      "Philosophy of science",
      "Epistemology"
    ],
    "retrieved_at": "2026-02-02T16:58:14.584940"
  },
  {
    "source": "openalex",
    "source_id": "W4393188496",
    "title": "AI: the future of humanity",
    "authors": [
      "Soha Rawas"
    ],
    "year": 2024,
    "abstract": "Abstract Artificial intelligence (AI) is reshaping humanity's future, and this manuscript provides a comprehensive exploration of its implications, applications, challenges, and opportunities. The revolutionary potential of AI is investigated across numerous sectors, with a focus on addressing global concerns. The influence of AI on areas such as healthcare, transportation, banking, and education is revealed through historical insights and conversations on different AI systems. Ethical considerations and the significance of responsible AI development are addressed. Furthermore, this study investigates AI's involvement in addressing global issues such as climate change, public health, and social justice. This paper serves as a resource for policymakers, researchers, and practitioners understanding the complex link between AI and humans.",
    "doi": "10.1007/s44163-024-00118-3",
    "url": "https://openalex.org/W4393188496",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s44163-024-00118-3.pdf",
    "venue": "Discover Artificial Intelligence",
    "citation_count": 68,
    "fields_of_study": [
      "Humanity",
      "Environmental ethics",
      "Philosophy",
      "Theology"
    ],
    "retrieved_at": "2026-02-02T16:58:14.584959"
  },
  {
    "source": "openalex",
    "source_id": "W4362522403",
    "title": "Surveying Public Perceptions of Artificial Intelligence in Health Care in the United States: Systematic Review",
    "authors": [
      "Becca Beets",
      "Todd P. Newman",
      "Emily L. Howell",
      "Luye Bao",
      "Shiyu Yang"
    ],
    "year": 2023,
    "abstract": "Background This paper reviews nationally representative public opinion surveys on artificial intelligence (AI) in the United States, with a focus on areas related to health care. The potential health applications of AI continue to gain attention owing to their promise as well as challenges. For AI to fulfill its potential, it must not only be adopted by physicians and health providers but also by patients and other members of the public. Objective This study reviews the existing survey research on the United States\u2019 public attitudes toward AI in health care and reveals the challenges and opportunities for more effective and inclusive engagement on the use of AI in health settings. Methods We conducted a systematic review of public opinion surveys, reports, and peer-reviewed journal articles published on Web of Science, PubMed, and Roper iPoll between January 2010 and January 2022. We include studies that are nationally representative US public opinion surveys and include at least one or more questions about attitudes toward AI in health care contexts. Two members of the research team independently screened the included studies. The reviewers screened study titles, abstracts, and methods for Web of Science and PubMed search results. For the Roper iPoll search results, individual survey items were assessed for relevance to the AI health focus, and survey details were screened to determine a nationally representative US sample. We reported the descriptive statistics available for the relevant survey questions. In addition, we performed secondary analyses on 4 data sets to further explore the findings on attitudes across different demographic groups. Results This review includes 11 nationally representative surveys. The search identified 175 records, 39 of which were assessed for inclusion. Surveys include questions related to familiarity and experience with AI; applications, benefits, and risks of AI in health care settings; the use of AI in disease diagnosis, treatment, and robotic caregiving; and related issues of data privacy and surveillance. Although most Americans have heard of AI, they are less aware of its specific health applications. Americans anticipate that medicine is likely to benefit from advances in AI; however, the anticipated benefits vary depending on the type of application. Specific application goals, such as disease prediction, diagnosis, and treatment, matter for the attitudes toward AI in health care among Americans. Most Americans reported wanting control over their personal health data. The willingness to share personal health information largely depends on the institutional actor collecting the data and the intended use. Conclusions Americans in general report seeing health care as an area in which AI applications could be particularly beneficial. However, they have substantial levels of concern regarding specific applications, especially those in which AI is involved in decision-making and regarding the privacy of health information.",
    "doi": "10.2196/40337",
    "url": "https://openalex.org/W4362522403",
    "pdf_url": "https://www.jmir.org/2023/1/e40337/PDF",
    "venue": "Journal of Medical Internet Research",
    "citation_count": 110,
    "fields_of_study": [
      "Public opinion",
      "Public health",
      "Health care",
      "Relevance (law)",
      "MEDLINE"
    ],
    "retrieved_at": "2026-02-02T16:58:14.584972"
  },
  {
    "source": "openalex",
    "source_id": "W2913771223",
    "title": "Software fairness",
    "authors": [
      "Yuriy Brun",
      "Alexandra Meliou"
    ],
    "year": 2018,
    "abstract": "A goal of software engineering research is advancing software quality and the success of the software engineering process. However, while recent studies have demonstrated a new kind of defect in software related to its ability to operate in fair and unbiased manner, software engineering has not yet wholeheartedly tackled these new kinds of defects, thus leaving software vulnerable. This paper outlines a vision for how software engineering research can help reduce fairness defects and represents a call to action by the software engineering research community to reify that vision. Modern software is riddled with examples of biased behavior, from automated translation injecting gender stereotypes, to vision systems failing to see faces of certain races, to the US criminal justice sytem relying on biased computational assessments of crime recidivism. While systems may learn bias from biased data, bias can also emerge from ambiguous or incomplete requirement specification, poor design, implementation bugs, and unintended component interactions. We argue that software fairness is analogous to software quality, and that numerous software engineering challenges in the areas of requirements, specification, design, testing, and verification need to be tackled to solve this problem.",
    "doi": "10.1145/3236024.3264838",
    "url": "https://openalex.org/W2913771223",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3236024.3264838",
    "venue": null,
    "citation_count": 118,
    "fields_of_study": [
      "Computer science",
      "Software engineering",
      "Social software engineering",
      "Software construction",
      "Software development"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585010"
  },
  {
    "source": "openalex",
    "source_id": "W4383722515",
    "title": "Harnessing the Power of ChatGPT for Automating Systematic Review Process: Methodology, Case Study, Limitations, and Future Directions",
    "authors": [
      "Ahmad Alshami",
      "Moustafa Elsayed",
      "Eslam Ali",
      "Abdelrahman E. E. Eltoukhy",
      "Tarek Zayed"
    ],
    "year": 2023,
    "abstract": "Systematic reviews (SR) are crucial in synthesizing and analyzing existing scientific literature to inform evidence-based decision-making. However, traditional SR methods often have limitations, including a lack of automation and decision support, resulting in time-consuming and error-prone reviews. To address these limitations and drive the field forward, we harness the power of the revolutionary language model, ChatGPT, which has demonstrated remarkable capabilities in various scientific writing tasks. By utilizing ChatGPT\u2019s natural language processing abilities, our objective is to automate and streamline the steps involved in traditional SR, explicitly focusing on literature search, screening, data extraction, and content analysis. Therefore, our methodology comprises four modules: (1) Preparation of Boolean research terms and article collection, (2) Abstract screening and articles categorization, (3) Full-text filtering and information extraction, and (4) Content analysis to identify trends, challenges, gaps, and proposed solutions. Throughout each step, our focus has been on providing quantitative analyses to strengthen the robustness of the review process. To illustrate the practical application of our method, we have chosen the topic of IoT applications in water and wastewater management and quality monitoring due to its critical importance and the dearth of comprehensive reviews in this field. The findings demonstrate the potential of ChatGPT in bridging the gap between traditional SR methods and AI language models, resulting in enhanced efficiency and reliability of SR processes. Notably, ChatGPT exhibits exceptional performance in filtering and categorizing relevant articles, leading to significant time and effort savings. Our quantitative assessment reveals the following: (1) the overall accuracy of ChatGPT for article discarding and classification is 88%, and (2) the F-1 scores of ChatGPT for article discarding and classification are 91% and 88%, respectively, compared to expert assessments. However, we identify limitations in its suitability for article extraction. Overall, this research contributes valuable insights to the field of SR, empowering researchers to conduct more comprehensive and reliable reviews while advancing knowledge and decision-making across various domains.",
    "doi": "10.3390/systems11070351",
    "url": "https://openalex.org/W4383722515",
    "pdf_url": "https://www.mdpi.com/2079-8954/11/7/351/pdf?version=1688974508",
    "venue": "Systems",
    "citation_count": 183,
    "fields_of_study": [
      "Computer science",
      "Data science",
      "Automation",
      "Robustness (evolution)",
      "Field (mathematics)"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585027"
  },
  {
    "source": "openalex",
    "source_id": "W3201470614",
    "title": "The Application of the Principles of Responsible AI on Social Media Marketing for Digital Health",
    "authors": [
      "Rui Liu",
      "Suraksha Gupta",
      "Parth Patel"
    ],
    "year": 2021,
    "abstract": null,
    "doi": "10.1007/s10796-021-10191-z",
    "url": "https://openalex.org/W3201470614",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10796-021-10191-z.pdf",
    "venue": "Information Systems Frontiers",
    "citation_count": 86,
    "fields_of_study": [
      "Social media",
      "Scrutiny",
      "Health care",
      "Dissemination",
      "Public relations"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585053"
  },
  {
    "source": "openalex",
    "source_id": "W3174685870",
    "title": "Societal Biases in Language Generation: Progress and Challenges",
    "authors": [
      "Emily Sheng",
      "Kai-Wei Chang",
      "Prem Natarajan",
      "Nanyun Peng"
    ],
    "year": 2021,
    "abstract": "Emily Sheng, Kai-Wei Chang, Prem Natarajan, Nanyun Peng. Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers). 2021.",
    "doi": "10.18653/v1/2021.acl-long.330",
    "url": "https://openalex.org/W3174685870",
    "pdf_url": "https://aclanthology.org/2021.acl-long.330.pdf",
    "venue": null,
    "citation_count": 108,
    "fields_of_study": [
      "Computer science",
      "Joint (building)",
      "Computational linguistics",
      "Volume (thermodynamics)",
      "Natural language processing"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585057"
  },
  {
    "source": "openalex",
    "source_id": "W3102619004",
    "title": "A governance framework for algorithmic accountability and transparency",
    "authors": [
      "Ansgar Koene",
      "Chris Clifton",
      "Yohko Hatada",
      "Helena Webb",
      "Rashida Richardson"
    ],
    "year": 2019,
    "abstract": "Algorithmic systems are increasingly being used as part of decision-making processes in both the public and private sectors, with potentially significant consequences for individuals, organisations and societies as a whole. Algorithmic systems in this context refer to the combination of algorithms, data and the interface process that together determine the outcomes that affect end users. Many types of decisions can be made faster and more efficiently using algorithms. A significant factor in the adoption of algorithmic systems for decision-making is their capacity to process large amounts of varied data sets (i.e. big data), which can be paired with machine learning methods in order to infer statistical models directly from the data. The same properties of scale, complexity and autonomous model inference however are linked to increasing concerns that many of these systems are opaque to the people affected by their use and lack clear explanations for the decisions they make. This lack of transparency risks undermining meaningful scrutiny and accountability, which is a significant concern when these systems are applied as part of decision-making processes that can have a considerable impact on people's human rights (e.g. critical safety decisions in autonomous vehicles; allocation of health and social service resources, etc.). This study develops policy options for the governance of algorithmic transparency and accountability, based on an analysis of the social, technical and regulatory challenges posed by algorithmic systems. Based on a review and analysis of existing proposals for governance of algorithmic systems, a set of four policy options are proposed, each of which addresses a different aspect of algorithmic transparency and accountability: 1. awareness raising: education, watchdogs and whistleblowers; 2. accountability in public-sector use of algorithmic decision-making; 3. regulatory oversight and legal liability; and 4. global coordination for algorithmic governance.",
    "doi": "10.2861/59990",
    "url": "https://openalex.org/W3102619004",
    "pdf_url": "https://nottingham-repository.worktribe.com/output/3979928",
    "venue": "Repository@Nottingham (University of Nottingham)",
    "citation_count": 105,
    "fields_of_study": [
      "Accountability",
      "Transparency (behavior)",
      "Computer science",
      "Corporate governance",
      "Scrutiny"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585063"
  },
  {
    "source": "openalex",
    "source_id": "W4206914990",
    "title": "Data Integration Challenges for Machine Learning in Precision Medicine",
    "authors": [
      "Mireya Mart\u00ednez-Garc\u00eda",
      "Enrique Hern\u00e1ndez\u2013Lemus"
    ],
    "year": 2022,
    "abstract": "A main goal of Precision Medicine is that of incorporating and integrating the vast corpora on different databases about the molecular and environmental origins of disease, into analytic frameworks, allowing the development of individualized, context-dependent diagnostics, and therapeutic approaches. In this regard, artificial intelligence and machine learning approaches can be used to build analytical models of complex disease aimed at prediction of personalized health conditions and outcomes. Such models must handle the wide heterogeneity of individuals in both their genetic predisposition and their social and environmental determinants. Computational approaches to medicine need to be able to efficiently manage, visualize and integrate, large datasets combining structure, and unstructured formats. This needs to be done while constrained by different levels of confidentiality, ideally doing so within a unified analytical architecture. Efficient data integration and management is key to the successful application of computational intelligence approaches to medicine. A number of challenges arise in the design of successful designs to medical data analytics under currently demanding conditions of performance in personalized medicine, while also subject to time, computational power, and bioethical constraints. Here, we will review some of these constraints and discuss possible avenues to overcome current challenges.",
    "doi": "10.3389/fmed.2021.784455",
    "url": "https://openalex.org/W4206914990",
    "pdf_url": "https://www.frontiersin.org/articles/10.3389/fmed.2021.784455/pdf",
    "venue": "Frontiers in Medicine",
    "citation_count": 133,
    "fields_of_study": [
      "Computer science",
      "Data science",
      "Precision medicine",
      "Confidentiality",
      "Context (archaeology)"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585085"
  },
  {
    "source": "openalex",
    "source_id": "W4288707390",
    "title": "Drug repurposing: a systematic review on root causes, barriers and facilitators",
    "authors": [
      "Nithya Krishnamurthy",
      "Alyssa Grimshaw",
      "Sydney A. Axson",
      "Sung Hee Choe",
      "Jennifer Miller"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1186/s12913-022-08272-z",
    "url": "https://openalex.org/W4288707390",
    "pdf_url": "https://bmchealthservres.biomedcentral.com/counter/pdf/10.1186/s12913-022-08272-z",
    "venue": "BMC Health Services Research",
    "citation_count": 218,
    "fields_of_study": [
      "Medicine",
      "Repurposing",
      "MEDLINE",
      "Transparency (behavior)",
      "Cochrane Library"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585102"
  },
  {
    "source": "openalex",
    "source_id": "W3095556657",
    "title": "Artificial cognition: How experimental psychology can help generate explainable artificial intelligence",
    "authors": [
      "J Taylor",
      "Graham W. Taylor"
    ],
    "year": 2020,
    "abstract": "Artificial intelligence powered by deep neural networks has reached a level of complexity where it can be difficult or impossible to express how a model makes its decisions. This black-box problem is especially concerning when the model makes decisions with consequences for human well-being. In response, an emerging field called explainable artificial intelligence (XAI) aims to increase the interpretability, fairness, and transparency of machine learning. In this paper, we describe how cognitive psychologists can make contributions to XAI. The human mind is also a black box, and cognitive psychologists have over 150 years of experience modeling it through experimentation. We ought to translate the methods and rigor of cognitive psychology to the study of artificial black boxes in the service of explainability. We provide a review of XAI for psychologists, arguing that current methods possess a blind spot that can be complemented by the experimental cognitive tradition. We also provide a framework for research in XAI, highlight exemplary cases of experimentation within XAI inspired by psychological science, and provide a tutorial on experimenting with machines. We end by noting the advantages of an experimental approach and invite other psychologists to conduct research in this exciting new field.",
    "doi": "10.3758/s13423-020-01825-5",
    "url": "https://openalex.org/W3095556657",
    "pdf_url": "https://link.springer.com/content/pdf/10.3758/s13423-020-01825-5.pdf",
    "venue": "Psychonomic Bulletin & Review",
    "citation_count": 102,
    "fields_of_study": [
      "Interpretability",
      "Cognition",
      "Psychology",
      "Field (mathematics)",
      "Transparency (behavior)"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585104"
  },
  {
    "source": "openalex",
    "source_id": "W4390058985",
    "title": "The Limitations and Ethical Considerations of ChatGPT",
    "authors": [
      "Shangying Hua",
      "Shuangci Jin",
      "Shengyi Jiang"
    ],
    "year": 2023,
    "abstract": "ABSTRACT With the advancements of artificial intelligence technology, ChatGPT, a new practice of artificial intelligence, holds immense potential across multiple fields. Its user-friendly human-machine interface, rapid response capabilities, and delivery of high-quality answers have attracted considerable attention and widespread usage. Regarded by many as a groundbreaking advancement in AI, ChatGPT represents a new milestone in the field. However, as with any technological evolution, the emergence of ChatGPT brings not only benefits, but also inevitable security risks and ethical issues. This paper provides specific information about ChatGPT, including its technology, limitations, ethical issues, governance paths and future directions. Specifically, we firstly offered a thorough exploration of the technical implementation details of GPT series models. Next, we provided an intricate analysis elucidating the reasons for limitations and scrutinized the consequential impacts, such as malicious misuse, privacy violation, and so on. Finally, we explore diverse governance paths to mitigate the impacts of ChatGPT and present future directions. This review aims to equip users with crucial knowledge, facilitating well-informed decision-making, effectively handling of potential challenges in employing ChatGPT, and staying abreast with the rapidly evolving landscape of this technology.",
    "doi": "10.1162/dint_a_00243",
    "url": "https://openalex.org/W4390058985",
    "pdf_url": "https://direct.mit.edu/dint/article-pdf/doi/10.1162/dint_a_00243/2200207/dint_a_00243.pdf",
    "venue": "Data Intelligence",
    "citation_count": 81,
    "fields_of_study": [
      "Milestone",
      "Field (mathematics)",
      "Computer science",
      "Corporate governance",
      "Ethical issues"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585121"
  },
  {
    "source": "openalex",
    "source_id": "W3183372445",
    "title": "Exploring perceptions of healthcare technologies enabled by artificial intelligence: an online, scenario-based survey",
    "authors": [
      "Alison L. Antes",
      "Sara Burrous",
      "Bryan A. Sisk",
      "Matthew J. Schuelke",
      "Jason D. Keune",
      "James M. DuBois"
    ],
    "year": 2021,
    "abstract": null,
    "doi": "10.1186/s12911-021-01586-8",
    "url": "https://openalex.org/W3183372445",
    "pdf_url": "https://bmcmedinformdecismak.biomedcentral.com/counter/pdf/10.1186/s12911-021-01586-8",
    "venue": "BMC Medical Informatics and Decision Making",
    "citation_count": 86,
    "fields_of_study": [
      "Openness to experience",
      "Psychosocial",
      "Health care",
      "Psychology",
      "Applied psychology"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585137"
  },
  {
    "source": "openalex",
    "source_id": "W4200352435",
    "title": "Blind spots in AI ethics",
    "authors": [
      "Thilo Hagendorff"
    ],
    "year": 2021,
    "abstract": "Abstract This paper critically discusses blind spots in AI ethics. AI ethics discourses typically stick to a certain set of topics concerning principles evolving mainly around explainability, fairness, and privacy. All these principles can be framed in a way that enables their operationalization by technical means. However, this requires stripping down the multidimensionality of very complex social constructs to something that is idealized, measurable, and calculable. Consequently, rather conservative, mainstream notions of the mentioned principles are conveyed, whereas critical research, alternative perspectives, and non-ideal approaches are largely neglected. Hence, one part of the paper considers specific blind spots regarding the very topics AI ethics focusses on. The other part, then, critically discusses blind spots regarding to topics that hold significant ethical importance but are hardly or not discussed at all in AI ethics. Here, the paper focuses on negative externalities of AI systems, exemplarily discussing the casualization of clickwork, AI ethics\u2019 strict anthropocentrism, and AI\u2019s environmental impact. Ultimately, the paper is intended to be a critical commentary on the ongoing development of the field of AI ethics. It makes the case for a rediscovery of the strength of ethics in the AI field, namely its sensitivity to suffering and harms that are caused by and connected to AI technologies.",
    "doi": "10.1007/s43681-021-00122-8",
    "url": "https://openalex.org/W4200352435",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s43681-021-00122-8.pdf",
    "venue": "AI and Ethics",
    "citation_count": 87,
    "fields_of_study": [
      "Mainstream",
      "Field (mathematics)",
      "Operationalization",
      "Engineering ethics",
      "Ideal (ethics)"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585139"
  },
  {
    "source": "openalex",
    "source_id": "W4392658848",
    "title": "Generative AI in Higher Education",
    "authors": [
      "Cecilia Ka Yuk Chan",
      "Tom Colloton"
    ],
    "year": 2024,
    "abstract": "Chan and Colloton\u2019s book is one of the first to provide a comprehensive examination of the use and impact of ChatGPT and Generative AI (GenAI) in higher education.&#13;\\n&#13;\\nSince November 2022, every conversation in higher education has involved ChatGPT and its impact on all aspects of teaching and learning. The book explores the necessity of AI literacy tailored to professional contexts, assess the strengths and weaknesses of incorporating ChatGPT in curriculum design, and delve into the transformation of assessment methods in the GenAI era. The authors introduce the Six Assessment Redesign Pivotal Strategies (SARPS) and an AI Assessment Integration Framework, encouraging a learner-centric assessment model. The necessity for well-crafted AI educational policies is explored, as well as a blueprint for policy formulation in academic institutions. Technical enthusiasts are catered to with a deep dive into the mechanics behind GenAI, from the history of neural networks to the latest advances and applications of GenAI technologies.&#13;\\n&#13;\\nWith an eye on the future of AI in education, this book will appeal to educators, students and scholars interested in the wider societal implications and the transformative role of GenAI in pedagogy and research.",
    "doi": "10.4324/9781003459026",
    "url": "https://openalex.org/W4392658848",
    "pdf_url": "https://api.taylorfrancis.com/content/books/oa-mono/download?identifierName=doi&identifierValue=10.4324/9781003459026&type=webpdf",
    "venue": null,
    "citation_count": 105,
    "fields_of_study": [
      "Generative grammar",
      "Artificial intelligence",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585156"
  },
  {
    "source": "openalex",
    "source_id": "W4389559236",
    "title": "AI-Enabled Medical Education: Threads of Change, Promising Futures, and Risky Realities Across Four Potential Future Worlds",
    "authors": [
      "Michelle Knopp",
      "Eric J. Warm",
      "Danielle Weber",
      "Matthew Kelleher",
      "Benjamin Kinnear",
      "Daniel J. Schumacher",
      "Sally A. Santen",
      "Eneida A. Mendon\u00e7a",
      "Laurah Turner"
    ],
    "year": 2023,
    "abstract": "Background The rapid trajectory of artificial intelligence (AI) development and advancement is quickly outpacing society's ability to determine its future role. As AI continues to transform various aspects of our lives, one critical question arises for medical education: what will be the nature of education, teaching, and learning in a future world where the acquisition, retention, and application of knowledge in the traditional sense are fundamentally altered by AI? Objective The purpose of this perspective is to plan for the intersection of health care and medical education in the future. Methods We used GPT-4 and scenario-based strategic planning techniques to craft 4 hypothetical future worlds influenced by AI's integration into health care and medical education. This method, used by organizations such as Shell and the Accreditation Council for Graduate Medical Education, assesses readiness for alternative futures and effectively manages uncertainty, risk, and opportunity. The detailed scenarios provide insights into potential environments the medical profession may face and lay the foundation for hypothesis generation and idea-building regarding responsible AI implementation. Results The following 4 worlds were created using OpenAI\u2019s GPT model: AI Harmony, AI conflict, The world of Ecological Balance, and Existential Risk. Risks include disinformation and misinformation, loss of privacy, widening inequity, erosion of human autonomy, and ethical dilemmas. Benefits involve improved efficiency, personalized interventions, enhanced collaboration, early detection, and accelerated research. Conclusions To ensure responsible AI use, the authors suggest focusing on 3 key areas: developing a robust ethical framework, fostering interdisciplinary collaboration, and investing in education and training. A strong ethical framework emphasizes patient safety, privacy, and autonomy while promoting equity and inclusivity. Interdisciplinary collaboration encourages cooperation among various experts in developing and implementing AI technologies, ensuring that they address the complex needs and challenges in health care and medical education. Investing in education and training prepares professionals and trainees with necessary skills and knowledge to effectively use and critically evaluate AI technologies. The integration of AI in health care and medical education presents a critical juncture between transformative advancements and significant risks. By working together to address both immediate and long-term risks and consequences, we can ensure that AI integration leads to a more equitable, sustainable, and prosperous future for both health care and medical education. As we engage with AI technologies, our collective actions will ultimately determine the state of the future of health care and medical education to harness AI's power while ensuring the safety and well-being of humanity.",
    "doi": "10.2196/50373",
    "url": "https://openalex.org/W4389559236",
    "pdf_url": "https://mededu.jmir.org/2023/1/e50373/PDF",
    "venue": "JMIR Medical Education",
    "citation_count": 87,
    "fields_of_study": [
      "Engineering ethics",
      "Health care",
      "Autonomy",
      "Public relations",
      "Sociology"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585173"
  },
  {
    "source": "openalex",
    "source_id": "W4388441462",
    "title": "ChatGPT is a Remarkable Tool\u2014For Experts",
    "authors": [
      "Amos Azaria",
      "Rina Azoulay",
      "Shulamit Reches"
    ],
    "year": 2023,
    "abstract": "ABSTRACT This paper investigates the capabilities of ChatGPT as an automated assistant in diverse domains, including scientific writing, mathematics, education, programming, and healthcare. We explore the potential of ChatGPT to enhance productivity, streamline problem-solving processes, and improve writing style. Furthermore, we highlight the potential risks associated with excessive reliance on ChatGPT in these fields. These limitations encompass factors like incorrect and fictitious responses, inaccuracies in code, limited logical reasoning abilities, overconfidence, and critical ethical concerns of copyright and privacy violation. We outline areas and objectives where ChatGPT proves beneficial, applications where it should be used judiciously, and scenarios where its reliability may be limited. In light of observed limitations, and given that the tool's fundamental errors may pose a special challenge for non-experts, ChatGPT should be used with a strategic methodology. By drawing from comprehensive experimental studies, we offer methods and flowcharts for effectively using ChatGPT. Our recommendations emphasize iterative interaction with ChatGPT and independent verification of its outputs. Considering the importance of utilizing ChatGPT judiciously and with expertise, we recommend its usage for experts who are well-versed in the respective domains.",
    "doi": "10.1162/dint_a_00235",
    "url": "https://openalex.org/W4388441462",
    "pdf_url": "https://direct.mit.edu/dint/article-pdf/doi/10.1162/dint_a_00235/2170613/dint_a_00235.pdf",
    "venue": "Data Intelligence",
    "citation_count": 86,
    "fields_of_study": [
      "Computer science",
      "Overconfidence effect",
      "Reliability (semiconductor)",
      "Management science",
      "Flowchart"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585207"
  },
  {
    "source": "openalex",
    "source_id": "W4313550453",
    "title": "Artificial Intelligence-Driven Talent Management System: Exploring the Risks and Options for Constructing a Theoretical Foundation",
    "authors": [
      "Ali Faqihi",
      "Shah Jahan Miah"
    ],
    "year": 2023,
    "abstract": "AI (Artificial intelligence) has the potential to improve strategies to talent management by implementing advanced automated systems for workforce management. AI can make this improvement a reality. The objective of this study is to discover the new requirements for generating a new AI-oriented artefact so that the issues pertaining to talent management are effectively addressed. The design artefact is an intelligent Human Resource Management (HRM) automation solution for talent career management primarily based on a talent intelligent module. Improving connections between professional assessment and planning features is the key goal of this initiative. Utilising a design science methodology we investigate the use of organised machine learning approaches. This technique is the key component of a complete AI solution framework that would be further informed through a suggested moderation of technology-organisation-environment (TOE) theory with the theory of diffusion of innovation (DOI). This framework was devised in order solve AI-related problems. Aside from the automated components available in talent management solutions, this study will make recommendations for practical approaches researchers may follow to fulfil a company\u2019s specific requirements for talent growth.",
    "doi": "10.3390/jrfm16010031",
    "url": "https://openalex.org/W4313550453",
    "pdf_url": "https://www.mdpi.com/1911-8074/16/1/31/pdf?version=1674009161",
    "venue": "Journal of risk and financial management",
    "citation_count": 77,
    "fields_of_study": [
      "Knowledge management",
      "Talent management",
      "Component (thermodynamics)",
      "Automation",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585223"
  },
  {
    "source": "openalex",
    "source_id": "W4281843594",
    "title": "IMPROVING HOME SECURITY USING BLOCKCHAIN",
    "authors": [
      "Nada Ratkovi\u0107"
    ],
    "year": 2022,
    "abstract": "The major problem with the use of smart home technology is that it often leads to various security issues. This mainly happens because the devices use open internet connections that may be vulnerable and subjected to multiple threats, hackers, and viruses. Some household IoT devices are forcefully introduced to the market, exposing the customers to significant risk factors. The websites and links do not have any copyright information or any privacy policies, due to which the hackers may immediately steal the confidential information of the user. For instance, the door locking password may be hacked by cyber criminals, and they may use it to attack the home when there is nobody in the home. This paper presents how to use block-chain to improve home security.",
    "doi": "10.54489/ijcim.v2i1.72",
    "url": "https://openalex.org/W4281843594",
    "pdf_url": "https://journals.gaftim.com/index.php/ijcim/article/download/72/33",
    "venue": "International Journal of Computations Information and Manufacturing (IJCIM)",
    "citation_count": 125,
    "fields_of_study": [
      "Hacker",
      "Computer security",
      "nobody",
      "Internet privacy",
      "Password"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585239"
  },
  {
    "source": "openalex",
    "source_id": "W3157668147",
    "title": "The Biography of an Algorithm: Performing algorithmic technologies in organizations",
    "authors": [
      "Vern Glaser",
      "Neil Pollock",
      "Luciana D\u2019Adderio"
    ],
    "year": 2021,
    "abstract": "Algorithms are ubiquitous in modern organizations. Typically, researchers have viewed algorithms as self-contained computational tools that either magnify organizational capabilities or generate unintended negative consequences. To overcome this limited understanding of algorithms as stable entities, we propose two moves. The first entails building on a performative perspective to theorize algorithms as entangled, relational, emergent, and nested assemblages that use theories\u2014and the sociomaterial networks they invoke\u2014to automate decisions, enact roles and expertise, and perform calculations. The second move entails building on our dynamic perspective on algorithms to theorize how algorithms evolve as they move across contexts and over time. To this end, we introduce a biographical perspective on algorithms which traces their evolution by focusing on key \u201cbiographical moments.\u201d We conclude by discussing how our performativity-inspired biographical perspective on algorithms can help management and organization scholars better understand organizational decision-making, the spread of technologies and their logics, and the dynamics of practices and routines.",
    "doi": "10.1177/26317877211004609",
    "url": "https://openalex.org/W3157668147",
    "pdf_url": "https://doi.org/10.1177/26317877211004609",
    "venue": "Organization Theory",
    "citation_count": 118,
    "fields_of_study": [
      "Performative utterance",
      "Perspective (graphical)",
      "Performativity",
      "Computer science",
      "Key (lock)"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585251"
  },
  {
    "source": "openalex",
    "source_id": "W3134210117",
    "title": "An Action-Oriented AI Policy Toolkit for Technology Audits by Community Advocates and Activists",
    "authors": [
      "P. M. Krafft",
      "Meg Young",
      "Michael Katell",
      "Jennifer E. Lee",
      "Shankar Narayan",
      "Micah Epstein",
      "Dharma Dailey",
      "Bernease Herman",
      "Aaron Tam",
      "Vivian Guetler",
      "Corinne Bintz",
      "Daniella Raz",
      "Pa Ousman Jobe",
      "Franziska Putz",
      "Brian Robick",
      "Bissan Barghouti"
    ],
    "year": 2021,
    "abstract": "Motivated by the extensive documented disparate harms of artificial intelligence (AI), many recent practitioner-facing reflective tools have been created to promote responsible AI development. However, the use of such tools internally by technology development firms addresses responsible AI as an issue of closed-door compliance rather than a matter of public concern. Recent advocate and activist efforts intervene in AI as a public policy problem, inciting a growing number of cities to pass bans or other ordinances on AI and surveillance technologies. In support of this broader ecology of political actors, we present a set of reflective tools intended to increase public participation in technology advocacy for AI policy action. To this end, the Algorithmic Equity Toolkit (the AEKit) provides a practical policy-facing definition of AI, a flowchart for assessing technologies against that definition, a worksheet for decomposing AI systems into constituent parts, and a list of probing questions that can be posed to vendors, policy-makers, or government agencies. The AEKit carries an action-orientation towards political encounters between community groups in the public and their representatives, opening up the work of AI reflection and remediation to multiple points of intervention. Unlike current reflective tools available to practitioners, our toolkit carries with it a politics of community participation and activism.",
    "doi": "10.1145/3442188.3445938",
    "url": "https://openalex.org/W3134210117",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3442188.3445938",
    "venue": null,
    "citation_count": 72,
    "fields_of_study": [
      "Public policy",
      "Public relations",
      "Politics",
      "Audit",
      "Equity (law)"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585266"
  },
  {
    "source": "openalex",
    "source_id": "W4391617198",
    "title": "Integrating Artificial Intelligence for Drug Discovery in the Context of Revolutionizing Drug Delivery",
    "authors": [
      "Anita Ioana Vi\u0219an",
      "Irina Negu\u021b"
    ],
    "year": 2024,
    "abstract": "Drug development is expensive, time-consuming, and has a high failure rate. In recent years, artificial intelligence (AI) has emerged as a transformative tool in drug discovery, offering innovative solutions to complex challenges in the pharmaceutical industry. This manuscript covers the multifaceted role of AI in drug discovery, encompassing AI-assisted drug delivery design, the discovery of new drugs, and the development of novel AI techniques. We explore various AI methodologies, including machine learning and deep learning, and their applications in target identification, virtual screening, and drug design. This paper also discusses the historical development of AI in medicine, emphasizing its profound impact on healthcare. Furthermore, it addresses AI\u2019s role in the repositioning of existing drugs and the identification of drug combinations, underscoring its potential in revolutionizing drug delivery systems. The manuscript provides a comprehensive overview of the AI programs and platforms currently used in drug discovery, illustrating the technological advancements and future directions of this field. This study not only presents the current state of AI in drug discovery but also anticipates its future trajectory, highlighting the challenges and opportunities that lie ahead.",
    "doi": "10.3390/life14020233",
    "url": "https://openalex.org/W4391617198",
    "pdf_url": "https://www.mdpi.com/2075-1729/14/2/233/pdf?version=1707364240",
    "venue": "Life",
    "citation_count": 203,
    "fields_of_study": [
      "Drug discovery",
      "Identification (biology)",
      "Context (archaeology)",
      "Computer science",
      "Data science"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585283"
  },
  {
    "source": "openalex",
    "source_id": "W4310228395",
    "title": "Bias and Debias in Recommender System: A Survey and Future Directions",
    "authors": [
      "Jiawei Chen",
      "Hande Dong",
      "Xiang Wang",
      "Fuli Feng",
      "Meng Wang",
      "Xiangnan He"
    ],
    "year": 2020,
    "abstract": "While recent years have witnessed a rapid growth of research papers on recommender system (RS), most of the papers focus on inventing machine learning models to better fit user behavior data. However, user behavior data is observational rather than experimental. This makes various biases widely exist in the data, including but not limited to selection bias, position bias, exposure bias, and popularity bias. Blindly fitting the data without considering the inherent biases will result in many serious issues, e.g., the discrepancy between offline evaluation and online metrics, hurting user satisfaction and trust on the recommendation service, etc. To transform the large volume of research models into practical improvements, it is highly urgent to explore the impacts of the biases and perform debiasing when necessary. When reviewing the papers that consider biases in RS, we find that, to our surprise, the studies are rather fragmented and lack a systematic organization. The terminology ``bias'' is widely used in the literature, but its definition is usually vague and even inconsistent across papers. This motivates us to provide a systematic survey of existing work on RS biases. In this paper, we first summarize seven types of biases in recommendation, along with their definitions and characteristics. We then provide a taxonomy to position and organize the existing work on recommendation debiasing. Finally, we identify some open challenges and envision some future directions, with the hope of inspiring more research work on this important yet less investigated topic. The summary of debiasing methods reviewed in this survey can be found at \\url{https://github.com/jiawei-chen/RecDebiasing}.",
    "doi": "10.48550/arxiv.2010.03240",
    "url": "https://openalex.org/W4310228395",
    "pdf_url": "https://arxiv.org/pdf/2010.03240",
    "venue": "arXiv (Cornell University)",
    "citation_count": 159,
    "fields_of_study": [
      "Debiasing",
      "Computer science",
      "Recommender system",
      "Terminology",
      "Popularity"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585300"
  },
  {
    "source": "openalex",
    "source_id": "W4382318759",
    "title": "Digital innovations for\u00a0sustainable and\u00a0resilient agricultural systems",
    "authors": [
      "Robert Finger"
    ],
    "year": 2023,
    "abstract": "Abstract Digitalisation is rapidly transforming the agri-food sector. This paper investigates emerging opportunities, challenges and policy options. We show that digital innovations can contribute to more sustainable and resilient agricultural systems. For example, digital innovations enable increased productivity, reduced environmental footprints and higher resilience of farms. However, these optimistic outcomes of increasing digitalisation of the agricultural sector will not emerge on their own, but this development comes with several challenges, costs and risks, e.g. in economic, social and ethical dimensions. We provide policy recommendations to explore opportunities and avoid risks. Moreover, we discuss implications for future research in agricultural economics.",
    "doi": "10.1093/erae/jbad021",
    "url": "https://openalex.org/W4382318759",
    "pdf_url": "https://academic.oup.com/erae/advance-article-pdf/doi/10.1093/erae/jbad021/50725484/jbad021.pdf",
    "venue": "European Review of Agricultural Economics",
    "citation_count": 172,
    "fields_of_study": [
      "Agriculture",
      "Resilience (materials science)",
      "Productivity",
      "Business",
      "Agricultural productivity"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585320"
  },
  {
    "source": "openalex",
    "source_id": "W4406199489",
    "title": "Generative AI in Higher Education: Balancing Innovation and Integrity",
    "authors": [
      "Nigel Francis",
      "Sue Jones",
      "David P. Smith"
    ],
    "year": 2025,
    "abstract": "Generative Artificial Intelligence (GenAI) is rapidly transforming the landscape of higher education, offering novel opportunities for personalised learning and innovative assessment methods. This paper explores the dual-edged nature of GenAI\u2019s integration into educational practices, focusing on both its potential to enhance student engagement and learning outcomes and the significant challenges it poses to academic integrity and equity. Through a comprehensive review of current literature, we examine the implications of GenAI on assessment practices, highlighting the need for robust ethical frameworks to guide its use. Our analysis is framed within pedagogical theories, including social constructivism and competency-based learning, highlighting the importance of balancing human expertise and AI capabilities. We also address broader ethical concerns associated with GenAI, such as the risks of bias, the digital divide, and the environmental impact of AI technologies. This paper argues that while GenAI can provide substantial benefits in terms of automation and efficiency, its integration must be managed with care to avoid undermining the authenticity of student work and exacerbating existing inequalities. Finally, we propose a set of recommendations for educational institutions, including developing GenAI literacy programmes, revising assessment designs to incorporate critical thinking and creativity, and establishing transparent policies that ensure fairness and accountability in GenAI use. By fostering a responsible approach to GenAI, higher education can harness its potential while safeguarding the core values of academic integrity and inclusive education.",
    "doi": "10.3389/bjbs.2024.14048",
    "url": "https://openalex.org/W4406199489",
    "pdf_url": "https://www.frontierspartnerships.org/journals/british-journal-of-biomedical-science/articles/10.3389/bjbs.2024.14048/pdf",
    "venue": "British Journal of Biomedical Science",
    "citation_count": 85,
    "fields_of_study": [
      "Generative grammar",
      "Generative model",
      "Psychology",
      "Computer science",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585330"
  },
  {
    "source": "openalex",
    "source_id": "W3119071838",
    "title": "Privacy protections to encourage use of health-relevant digital data in a learning health system",
    "authors": [
      "Deven McGraw",
      "Kenneth D. Mandl"
    ],
    "year": 2021,
    "abstract": null,
    "doi": "10.1038/s41746-020-00362-8",
    "url": "https://openalex.org/W3119071838",
    "pdf_url": "https://www.nature.com/articles/s41746-020-00362-8.pdf",
    "venue": "npj Digital Medicine",
    "citation_count": 192,
    "fields_of_study": [
      "Health care",
      "Internet privacy",
      "Information privacy",
      "Digital health",
      "Business"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585349"
  },
  {
    "source": "openalex",
    "source_id": "W4401667275",
    "title": "Artificial intelligence for literature reviews: opportunities and challenges",
    "authors": [
      "F. J. Bola\u00f1os",
      "Angelo A. Salatino",
      "Francesco Osborne",
      "Enrico Motta"
    ],
    "year": 2024,
    "abstract": "Abstract This paper presents a comprehensive review of the use of Artificial Intelligence (AI) in Systematic Literature Reviews (SLRs). A SLR is a rigorous and organised methodology that assesses and integrates prior research on a given topic. Numerous tools have been developed to assist and partially automate the SLR process. The increasing role of AI in this field shows great potential in providing more effective support for researchers, moving towards the semi-automatic creation of literature reviews. Our study focuses on how AI techniques are applied in the semi-automation of SLRs, specifically in the screening and extraction phases. We examine 21 leading SLR tools using a framework that combines 23 traditional features with 11 AI features. We also analyse 11 recent tools that leverage large language models for searching the literature and assisting academic writing. Finally, the paper discusses current trends in the field, outlines key research challenges, and suggests directions for future research. We highlight three primary research challenges: integrating advanced AI solutions, such as large language models and knowledge graphs, improving usability, and developing a standardised evaluation framework. We also propose best practices to ensure more robust evaluations in terms of performance, usability, and transparency. Overall, this review offers a detailed overview of AI-enhanced SLR tools for researchers and practitioners, providing a foundation for the development of next-generation AI solutions in this field.",
    "doi": "10.1007/s10462-024-10902-3",
    "url": "https://openalex.org/W4401667275",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10462-024-10902-3.pdf",
    "venue": "Artificial Intelligence Review",
    "citation_count": 128,
    "fields_of_study": [
      "Computer science",
      "Usability",
      "Leverage (statistics)",
      "Systematic review",
      "Field (mathematics)"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585351"
  },
  {
    "source": "openalex",
    "source_id": "W4392162455",
    "title": "Managing the race to the moon: Global policy and governance in Artificial Intelligence regulation\u2014A contemporary overview and an analysis of socioeconomic consequences",
    "authors": [
      "Yoshija Walter"
    ],
    "year": 2024,
    "abstract": "Abstract This paper delves into the complexities of global AI regulation and governance, emphasizing the socio-economic repercussions of rapid AI development. It scrutinizes the challenges in creating effective governance structures amidst the AI race, considering diverse global perspectives and policies. The discourse moves beyond specific corporate examples, addressing broader implications and sector-wide impacts of AI on employment, truth discernment, and democratic stability. The analysis focuses on contrasting regulatory approaches across key regions\u2014the United States, European Union, Asia, Africa, and the Americas and thus highlighting the variations and commonalities in strategies and implementations. This comparative study reveals the intricacies and hurdles in formulating a cohesive global policy for AI regulation. Central to the paper is the examination of the dynamic between rapid AI innovation and the slower pace of regulatory and ethical standard-setting. It critically evaluates the advantages and drawbacks of shifting regulatory responsibilities between government bodies and the private sector. In response to these challenges, the discussion proposes an innovative and integrated regulatory model. The model advocates for a collaborative network that blends governmental authority with industry expertise, aiming to establish adaptive, responsive regulations (called \u201cdynamic laws\u201d) that can evolve with technological advancements. The novel approach aims to bridge the gap between rapid AI advancements in the industry and the essential democratic processes of law-making.",
    "doi": "10.1007/s44163-024-00109-4",
    "url": "https://openalex.org/W4392162455",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s44163-024-00109-4.pdf",
    "venue": "Discover Artificial Intelligence",
    "citation_count": 92,
    "fields_of_study": [
      "Race (biology)",
      "Socioeconomic status",
      "Corporate governance",
      "Political science",
      "Sociology"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585369"
  },
  {
    "source": "openalex",
    "source_id": "W3161310076",
    "title": "Predicting sex from retinal fundus photographs using automated deep learning",
    "authors": [
      "Edward Korot",
      "Nikolas Pontikos",
      "Xiaoxuan Liu",
      "Siegfried K. Wagner",
      "Livia Faes",
      "Josef Huemer",
      "Konstantinos Balaskas",
      "Alastair K. Denniston",
      "Anthony P. Khawaja",
      "Pearse A. Keane"
    ],
    "year": 2021,
    "abstract": "Abstract Deep learning may transform health care, but model development has largely been dependent on availability of advanced technical expertise. Herein we present the development of a deep learning model by clinicians without coding, which predicts reported sex from retinal fundus photographs. A model was trained on 84,743 retinal fundus photos from the UK Biobank dataset. External validation was performed on 252 fundus photos from a tertiary ophthalmic referral center. For internal validation, the area under the receiver operating characteristic curve (AUROC) of the code free deep learning (CFDL) model was 0.93. Sensitivity, specificity, positive predictive value (PPV) and accuracy (ACC) were 88.8%, 83.6%, 87.3% and 86.5%, and for external validation were 83.9%, 72.2%, 78.2% and 78.6% respectively. Clinicians are currently unaware of distinct retinal feature variations between males and females, highlighting the importance of model explainability for this task. The model performed significantly worse when foveal pathology was present in the external validation dataset, ACC: 69.4%, compared to 85.4% in healthy eyes, suggesting the fovea is a salient region for model performance OR (95% CI): 0.36 (0.19, 0.70) p = 0.0022. Automated machine learning (AutoML) may enable clinician-driven automated discovery of novel insights and disease biomarkers.",
    "doi": "10.1038/s41598-021-89743-x",
    "url": "https://openalex.org/W3161310076",
    "pdf_url": "https://www.nature.com/articles/s41598-021-89743-x.pdf",
    "venue": "Scientific Reports",
    "citation_count": 133,
    "fields_of_study": [
      "Fundus (uterus)",
      "Deep learning",
      "Artificial intelligence",
      "Retinal",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585388"
  },
  {
    "source": "openalex",
    "source_id": "W4385571411",
    "title": "Is GPT-3 a Good Data Annotator?",
    "authors": [
      "Bosheng Ding",
      "Chengwei Qin",
      "Linlin Liu",
      "Yew Ken Chia",
      "Boyang Li",
      "Shafiq Joty",
      "Lidong Bing"
    ],
    "year": 2023,
    "abstract": "Bosheng Ding, Chengwei Qin, Linlin Liu, Yew Ken Chia, Boyang Li, Shafiq Joty, Lidong Bing. Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2023.",
    "doi": "10.18653/v1/2023.acl-long.626",
    "url": "https://openalex.org/W4385571411",
    "pdf_url": "https://aclanthology.org/2023.acl-long.626.pdf",
    "venue": null,
    "citation_count": 127,
    "fields_of_study": [
      "Volume (thermodynamics)",
      "Computational linguistics",
      "Computer science",
      "Natural language processing",
      "Library science"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585405"
  },
  {
    "source": "openalex",
    "source_id": "W4284891135",
    "title": "The Landscape of Teaching Resources for AI Education",
    "authors": [
      "Stefania Druga",
      "Nancy Otero",
      "Amy J. Ko"
    ],
    "year": 2022,
    "abstract": "Artificial Intelligence (AI) educational resources such as training tools, interactive demos, and dedicated curriculum are increasingly popular among educators and learners. While prior work has examined pedagogies for promoting AI literacy, it has yet to examine how well technology resources support these pedagogies. To address this gap, we conducted a systematic analysis of existing online resources for AI education, investigating what learning and teaching affordances these resources have to support AI education. We used the Technological Pedagogical Content Knowledge (TPACK) framework to analyze a final corpus of 50 AI resources. We found that most resources support active learning, have digital or physical dependencies, do not include all the five big ideas defined by AI4K12 guidelines, and do not offer built-in support for assessment or feedback. Teaching guides are hard to find or require technical knowledge. Based on our findings, we propose that future AI curricula move from singular activities and demos to more holistic designs that include support, guidance, and flexibility for how AI technology, concepts, and pedagogy play out in the classroom.",
    "doi": "10.1145/3502718.3524782",
    "url": "https://openalex.org/W4284891135",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3502718.3524782",
    "venue": null,
    "citation_count": 81,
    "fields_of_study": [
      "Affordance",
      "Curriculum",
      "Computer science",
      "Flexibility (engineering)",
      "Literacy"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585410"
  },
  {
    "source": "openalex",
    "source_id": "W4394806371",
    "title": "The TESCREAL bundle: Eugenics and the promise of utopia through artificial general intelligence",
    "authors": [
      "Timnit Gebru",
      "\u00c9mile P. Torres"
    ],
    "year": 2024,
    "abstract": "The stated goal of many organizations in the field of artificial intelligence (AI) is to develop artificial general intelligence (AGI), an imagined system with more intelligence than anything we have ever seen. Without seriously questioning whether such a system can and should be built, researchers are working to create \u201csafe AGI\u201d that is \u201cbeneficial for all of humanity.\u201d We argue that, unlike systems with specific applications which can be evaluated following standard engineering principles, undefined systems like \u201cAGI\u201d cannot be appropriately tested for safety. Why, then, is building AGI often framed as an unquestioned goal in the field of AI? In this paper, we argue that the normative framework that motivates much of this goal is rooted in the Anglo-American eugenics tradition of the twentieth century. As a result, many of the very same discriminatory attitudes that animated eugenicists in the past (e.g., racism, xenophobia, classism, ableism, and sexism) remain widespread within the movement to build AGI, resulting in systems that harm marginalized groups and centralize power, while using the language of \u201csafety\u201d and \u201cbenefiting humanity\u201d to evade accountability. We conclude by urging researchers to work on defined tasks for which we can develop safety protocols, rather than attempting to build a presumably all-knowing system such as AGI.",
    "doi": "10.5210/fm.v29i4.13636",
    "url": "https://openalex.org/W4394806371",
    "pdf_url": "https://firstmonday.org/ojs/index.php/fm/article/download/13636/11606",
    "venue": "First Monday",
    "citation_count": 107,
    "fields_of_study": [
      "Eugenics",
      "Utopia",
      "Dystopia",
      "Transhumanism",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585425"
  },
  {
    "source": "openalex",
    "source_id": "W4221001772",
    "title": "How artificial intelligence might change academic library work: Applying the competencies literature and the theory of the professions",
    "authors": [
      "Andrew Cox"
    ],
    "year": 2022,
    "abstract": "Abstract The probable impact of artificial intelligence (AI) on work, including professional work, is contested, but it is unlikely to leave them untouched. The purpose of this conceptual paper is to consider the likelihood of the adoption of different approaches to AI in academic libraries. As theoretical lenses to guide the analysis the paper draws on both the library and information science (LIS) literature on librarians' competencies and the notions of jurisdiction and hybrid logics drawn from the sociological theory of the professions. The paper starts by outlining these theories and then reviews the nature of AI and the range of its potential uses in academic libraries. The main focus of the paper is on the application of AI to knowledge discovery. Eleven different potential approaches libraries might adopt to such AI applications are analyzed and their likelihood evaluated. Then it is considered how a range of internal and external factors might influence the adoption of AI. In addition to reflecting on the possible impact of AI on librarianship the paper contributes to understanding how to synthesize the competencies literature with the theory of the profession and presents a new understanding of librarians as hybrid.",
    "doi": "10.1002/asi.24635",
    "url": "https://openalex.org/W4221001772",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/asi.24635",
    "venue": "Journal of the Association for Information Science and Technology",
    "citation_count": 124,
    "fields_of_study": [
      "Sociology",
      "Computer science",
      "Work (physics)",
      "Jurisdiction",
      "Knowledge management"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585442"
  },
  {
    "source": "openalex",
    "source_id": "W4287218595",
    "title": "Is AI recruiting (un)ethical? A human rights perspective on the use of AI for hiring",
    "authors": [
      "Anna Lena Hunkenschroer",
      "Alexander Kriebitz"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1007/s43681-022-00166-4",
    "url": "https://openalex.org/W4287218595",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s43681-022-00166-4.pdf",
    "venue": "AI and Ethics",
    "citation_count": 69,
    "fields_of_study": [
      "Perspective (graphical)",
      "Human rights",
      "Engineering ethics",
      "Political science",
      "Environmental ethics"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585458"
  },
  {
    "source": "openalex",
    "source_id": "W4382246267",
    "title": "Exploring the Transformative Role of Artificial Intelligence and Metaverse in Education: A Comprehensive Review",
    "authors": [
      "Devanshu Kumar",
      "Md. Alimul Haque",
      "Khushboo Mishra",
      "Farheen Islam",
      "Binay Kumar Mishra",
      "Sultan Ahmad"
    ],
    "year": 2023,
    "abstract": "Introduction: this review paper provides a comprehensive examination of the applications and impact of artificial intelligence (AI) in the field of education. With advancements in AI technologies, the educational landscape has witnessed significant transformations. This review aims to explore the diverse AI techniques employed in education and their potential contributions to teaching, learning, assessment, and educational support. Objective: this research article aims to tracing the development of AI in education from its early beginnings to its current state. It highlights key milestones and breakthroughs that have shaped the field, including the emergence of intelligent tutoring systems and expert systems. Methods: the article provides a comprehensive overview of the various AI techniques utilized in education, such as machine learning, natural language processing, computer vision, and data mining. Each technique is discussed in detail, showcasing the algorithms, models, and methodologies used within each approach. Results: while the benefits of AI in education are substantial, the paper also addresses the challenges associated with its integration. Ethical considerations, privacy concerns, and the need for effective human-AI collaboration are discussed in-depth. Conclusion: this review underscores the transformative potential of AI in education. By harnessing AI technologies effectively and responsibly, educators and policymakers can unlock new possibilities for enhancing teaching and learning experiences, fostering personalized instruction, and driving educational advancement.",
    "doi": "10.56294/mr202355",
    "url": "https://openalex.org/W4382246267",
    "pdf_url": "https://mr.saludcyt.ar/index.php/mr/article/download/55/126",
    "venue": "Metaverse Basic and Applied Research",
    "citation_count": 104,
    "fields_of_study": [
      "Transformative learning",
      "Metaverse",
      "Psychology",
      "Engineering ethics",
      "Sociology"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585461"
  },
  {
    "source": "openalex",
    "source_id": "W4391609543",
    "title": "Does AI-Driven Technostress Promote or Hinder Employees\u2019 Artificial Intelligence Adoption Intention? A Moderated Mediation Model of Affective Reactions and Technical Self-Efficacy",
    "authors": [
      "Po\u2010Chien Chang",
      "Wenhui Zhang",
      "Qihai Cai",
      "Hongchi Guo"
    ],
    "year": 2024,
    "abstract": "Overall, our study suggests that AI-driven challenge technology stressors positively impact AI adoption intention through the cultivation of positive affect, while hindrance technology stressors impede AI adoption intention by triggering AI anxiety. Additionally, technical self-efficacy emerges as a crucial moderator in shaping these relationships. This research has the potential to make a meaningful contribution to the literature on AI adoption intention, deepening our holistic understanding of the influential mechanisms involved. Furthermore, the study affirms the applicability and relevance of Affective Events Theory (AET) and the Challenge-Hindrance Stressor Framework (CHSF). In practical terms, the research provides actionable insights for organizations to effectively manage employees' AI adoption intention.",
    "doi": "10.2147/prbm.s441444",
    "url": "https://openalex.org/W4391609543",
    "pdf_url": "https://www.dovepress.com/getfile.php?fileID=96570",
    "venue": "Psychology Research and Behavior Management",
    "citation_count": 111,
    "fields_of_study": [
      "Stressor",
      "Psychology",
      "Technostress",
      "Snowball sampling",
      "Affect (linguistics)"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585487"
  },
  {
    "source": "openalex",
    "source_id": "W4388725733",
    "title": "Large Language Models: A Comprehensive Survey of its Applications, Challenges, Limitations, and Future Prospects",
    "authors": [
      "Muhammad Usman Hadi",
      "qasem al tashi",
      "Rizwan Qureshi",
      "Abbas Shah",
      "Amgad Muneer",
      "Muhammad Irfan",
      "Anas Zafar",
      "Muhammad Bilal Shaikh",
      "Naveed Akhtar",
      "Jia Wu",
      "Seyedali Mirjalili"
    ],
    "year": 2023,
    "abstract": "&lt;p&gt;Within the vast expanse of computerized language processing, a revolutionary entity known as Large Language Models (LLMs) has emerged, wielding immense power in its capacity to comprehend intricate linguistic patterns and conjure coherent and contextually fitting responses. Large language models (LLMs) are a type of artificial intelligence (AI) that have emerged as powerful tools for a wide range of tasks, including natural language processing (NLP), machine translation, and question-answering. This survey paper provides a comprehensive overview of LLMs, including their history, architecture, training methods, applications, and challenges. The paper begins by discussing the fundamental concepts of generative AI and the architecture of generative pre- trained transformers (GPT). It then provides an overview of the history of LLMs, their evolution over time, and the different training methods that have been used to train them. The paper then discusses the wide range of applications of LLMs, including medical, education, finance, and engineering. It also discusses how LLMs are shaping the future of AI and how they can be used to solve real-world problems. The paper then discusses the challenges associated with deploying LLMs in real-world scenarios, including ethical considerations, model biases, interpretability, and computational resource requirements. It also highlights techniques for enhancing the robustness and controllability of LLMs, and addressing bias, fairness, and generation quality issues. Finally, the paper concludes by highlighting the future of LLM research and the challenges that need to be addressed in order to make LLMs more reliable and useful. This survey paper is intended to provide researchers, practitioners, and enthusiasts with a comprehensive understanding of LLMs, their evolution, applications, and challenges. By consolidating the state-of-the-art knowledge in the field, this survey serves as a valuable resource for further advancements in the development and utilization of LLMs for a wide range of real-world applications. The GitHub repo for this project is available at https://github.com/anas-zafar/LLM-Survey&lt;/p&gt;",
    "doi": "10.36227/techrxiv.23589741.v4",
    "url": "https://openalex.org/W4388725733",
    "pdf_url": "https://doi.org/10.36227/techrxiv.23589741.v4",
    "venue": null,
    "citation_count": 101,
    "fields_of_study": [
      "Interpretability",
      "Computer science",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585502"
  },
  {
    "source": "openalex",
    "source_id": "W4394964316",
    "title": "Higher Education\u2019s Generative Artificial Intelligence Paradox: The Meaning of Chatbot Mania",
    "authors": [
      "Juergen Rudolph",
      "Fadhil Mohamed Mohamed Ismail",
      "\u015etefan Popenici"
    ],
    "year": 2024,
    "abstract": "Higher education is currently under a significant transformation due to the emergence of generative artificial intelligence (GenAI) technologies, the hype surrounding GenAI and the increasing influence of educational technology business groups over tertiary education. This commentary, prepared for the Special Issue of the Journal of University Teaching &amp; Learning Practice (JUTLP) on \u201cEnhancing student engagement using Artificial Intelligence (AI) and chatbots,\u201d delves into the complex landscape of opportunities and threats that AI chatbots, including ChatGPT, introduce to the realm of higher education. We argue that while GenAI offers promise in enhancing pedagogy, research, administration, and student support, concerns around academic integrity, labour displacement, embedded biases, environmental sustainability, increased commercialisation, and regulatory gaps necessitate a critical approach. Our commentary advocates for the development of critical AI literacy among educators and students, emphasising the necessity to foster an environment of responsible innovation and informed use of AI. We posit that the successful integration of AI in higher education must be grounded in the principles of ethics, equity, and the prioritisation of educational aims and human values. By offering a critical and nuanced exploration of these issues, our commentary aims to contribute to the ongoing discourse on how higher education institutions can navigate the rise of GenAI, ensuring that technological advancements benefit all stakeholders while upholding core academic values.",
    "doi": "10.53761/54fs5e77",
    "url": "https://openalex.org/W4394964316",
    "pdf_url": "https://open-publishing.org/journals/index.php/jutlp/article/download/744/754",
    "venue": "Journal of University Teaching and Learning Practice",
    "citation_count": 88,
    "fields_of_study": [
      "Chatbot",
      "Generative grammar",
      "Meaning (existential)",
      "Mania",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585529"
  },
  {
    "source": "openalex",
    "source_id": "W4394949392",
    "title": "The Artificial Intelligence Assessment Scale (AIAS): A Framework for Ethical Integration of Generative AI in Educational Assessment",
    "authors": [
      "Mike Perkins",
      "Leon Furze",
      "Jasper Roe",
      "Jason MacVaugh"
    ],
    "year": 2024,
    "abstract": "Recent developments in Generative Artificial Intelligence (GenAI) have created a paradigm shift in multiple areas of society, and the use of these technologies is likely to become a defining feature of education in coming decades. GenAI offers transformative pedagogical opportunities, while simultaneously posing ethical and academic challenges. Against this backdrop, we outline a practical, simple, and sufficiently comprehensive tool to allow for the integration of GenAI tools into educational assessment: the AI Assessment Scale (AIAS). The AIAS empowers educators to select the appropriate level of GenAI usage in assessments based on the learning outcomes they seek to address. The AIAS offers greater clarity and transparency for students and educators, provides a fair and equitable policy tool for institutions to work with, and offers a nuanced approach which embraces the opportunities of GenAI while recognising that there are instances where such tools may not be pedagogically appropriate or necessary. By adopting a practical, flexible approach that can be implemented quickly, the AIAS can form a much-needed starting point to address the current uncertainty and anxiety regarding GenAI in education. As a secondary objective, we engage with the current literature and advocate for a refocused discourse on GenAI tools in education, one which foregrounds how technologies can help support and enhance teaching and learning, which contrasts with the current focus on GenAI as a facilitator of academic misconduct.",
    "doi": "10.53761/q3azde36",
    "url": "https://openalex.org/W4394949392",
    "pdf_url": "https://open-publishing.org/journals/index.php/jutlp/article/download/810/769",
    "venue": "Journal of University Teaching and Learning Practice",
    "citation_count": 103,
    "fields_of_study": [
      "Generative grammar",
      "Scale (ratio)",
      "Artificial intelligence",
      "Computer science",
      "Geography"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585549"
  },
  {
    "source": "openalex",
    "source_id": "W4281877842",
    "title": "STUDYING HUMAN ROBOT INTERACTION AND ITS CHARACTERISTICS",
    "authors": [
      "Maged Farouk"
    ],
    "year": 2022,
    "abstract": "The process of human-robot interaction focuses on the analysis of different forms of communication between humans and the robots through the application of technologies like artificial intelligence and machine learning. However, there can be different challenges associated with the process like security risks and challenges related to mapping environment and manufacturing procedures. For analysis of the process of mitigation of the challenges, secondary qualitative data have been collected from different journals and websites. Theoretical analysis has been done for the collected data and the application of a cognitive modelling model has been done for this study. The main results include that application of a cognitive model can help in simulating the human problem-solving process and can help to improve the human cognition techniques.",
    "doi": "10.54489/ijcim.v2i1.73",
    "url": "https://openalex.org/W4281877842",
    "pdf_url": "https://journals.gaftim.com/index.php/ijcim/article/download/73/34",
    "venue": "International Journal of Computations Information and Manufacturing (IJCIM)",
    "citation_count": 109,
    "fields_of_study": [
      "Process (computing)",
      "Computer science",
      "Robot",
      "Human\u2013computer interaction",
      "Cognition"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585567"
  },
  {
    "source": "openalex",
    "source_id": "W4386486000",
    "title": "Examining the Impact of Artificial Intelligence and Internet of Things on Smart Tourism Destinations: A Comprehensive Study",
    "authors": [
      "Aliyah",
      "Chandra Lukita",
      "Greian April Pangilinan",
      "Mochamad Heru Riza Chakim",
      "Dimas Bagus Saputra"
    ],
    "year": 2023,
    "abstract": "This research focuses on the high urgency of utilizing Artificial Intelligence (AI) and the Internet of Things (IoT) to enhance Smart Tourism Destinations (STDs). The integration of AI and IoT technologies offers unprecedented opportunities to revolutionize various aspects of tourism, from personalized recommendations to real-time data collection. The research aims to provide a comprehensive analysis of the current state, challenges, and future direction of STDs in the context of AI and IoT integration. It explores various AI techniques and IoT-enabled data collection mechanisms that can enrich the traveler experience and improve destination management. However, challenges such as privacy and data security issues need to be addressed. The research also provides foresight into future technologies like Augmented Reality (AR) and Virtual Reality (VR) that can further enhance STDs. The ultimate goal is to contribute to the development of smarter, visitor-oriented tourism destinations. The research highlights the significance of AI in shaping STDs and emphasizes the importance of addressing ethical considerations, data quality, interpretability, and human-AI collaboration to ensure responsible and effective use of AI in the tourism industry.",
    "doi": "10.34306/att.v5i2sp.332",
    "url": "https://openalex.org/W4386486000",
    "pdf_url": "https://att.aptisi.or.id/index.php/att/article/download/332/220",
    "venue": "Aptisi Transactions On Technopreneurship (ATT)",
    "citation_count": 82,
    "fields_of_study": [
      "Tourism",
      "Futures studies",
      "Context (archaeology)",
      "Visitor pattern",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585579"
  },
  {
    "source": "openalex",
    "source_id": "W4280598345",
    "title": "Incorporating <scp>AI</scp> and learning analytics to build trustworthy peer assessment systems",
    "authors": [
      "Ali Darvishi",
      "Hassan Khosravi",
      "Shazia Sadiq",
      "Dragan Ga\u0161evi\u0107"
    ],
    "year": 2022,
    "abstract": "Abstract Peer assessment has been recognised as a sustainable and scalable assessment method that promotes higher\u2010order learning and provides students with fast and detailed feedback on their work. Despite these benefits, some common concerns and criticisms are associated with the use of peer assessments (eg, scarcity of high\u2010quality feedback from peer student\u2010assessors and lack of accuracy in assigning a grade to the assessee) that raise questions about their trustworthiness. Consequently, many instructors and educational institutions have been anxious about incorporating peer assessment into their teaching. This paper aims to contribute to the growing literature on how AI and learning analytics may be incorporated to address some of the common concerns associated with peer assessment systems, which in turn can increase their trustworthiness and adoption. In particular, we present and evaluate our AI\u2010assisted and analytical approaches that aim to (1) offer guidelines and assistance to student\u2010assessors during individual reviews to provide better feedback, (2) integrate probabilistic and text analysis inference models to improve the accuracy of the assigned grades, (3) develop feedback on reviews strategies that enable peer assessors to review the work of each other, and (4) employ a spot\u2010checking mechanism to assist instructors in optimally overseeing the peer assessment process. Practitioner notes What is already known about this topic Engaging students in peer assessment has been demonstrated to have various benefits. However, there are some common concerns associated with employing peer assessment that raise questions about their trustworthiness as an assessment item. What this paper adds Methods and processes on how AI and learning analytics may be incorporated to address some of the common concerns associated with peer assessment systems, which in turn, can increase their trustworthiness and adoption. Implications for practice Presentation of a systematic approach for development, deployment and evaluation of AI and analytics approaches in peer assessment systems.",
    "doi": "10.1111/bjet.13233",
    "url": "https://openalex.org/W4280598345",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/bjet.13233",
    "venue": "British Journal of Educational Technology",
    "citation_count": 86,
    "fields_of_study": [
      "Peer assessment",
      "Computer science",
      "Peer review",
      "Peer feedback",
      "Scarcity"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585595"
  },
  {
    "source": "openalex",
    "source_id": "W4288077582",
    "title": "The Metaverse as a virtual form of data-driven smart cities: the ethics of the hyper-connectivity, datafication, algorithmization, and platformization of urban society",
    "authors": [
      "Simon Elias Bibri",
      "Zaheer Allam"
    ],
    "year": 2022,
    "abstract": "Abstract Recent advances in computing and immersive technologies have provided Meta (formerly Facebook) with the opportunity to leapfrog or expedite its way of thinking and devising a global computing platform called the \u201cMetaverse\u201d. This hypothetical 3D network of virtual spaces is increasingly shaping alternatives to the imaginaries of data-driven smart cities, as it represents ways of living in virtually inhabitable cities. At the heart of the Metaverse is a computational understanding of human users\u2019 cognition, emotion, motivation, and behavior that reduces the experience of everyday life to logic and calculative rules and procedures. This implies that human users become more knowable and manageable and their behavior more predictable and controllable, thereby serving as passive data points feeding the AI and analytics system that they have no interchange with or influence on. This paper examines the forms, practices, and ethics of the Metaverse as a virtual form of data-driven smart cities, paying particular attention to: privacy, surveillance capitalism, dataveillance, geosurveillance, human health and wellness, and collective and cognitive echo-chambers. Achieving this aim will provide the answer to the main research question driving this study: What ethical implications will the Metaverse have on the experience of everyday life in post-pandemic urban society? In terms of methodology, this paper deploys a thorough review of the current status of the Metaverse, urban informatics, urban science, and data-driven smart cities literature, as well as trends, research, and developments. We argue that the Metaverse will do more harm than good to human users due to the massive misuse of the hyper-connectivity, datafication, algorithmization, and platformization underlying the associated global architecture of computer mediation. It follows that the Metaverse needs to be re-cast in ways that re-orientate in how users are conceived; recognize their human characteristics; and take into account the moral values and principles designed to realize the benefits of socially disruptive technologies while mitigating their pernicious effects. This paper contributes to the academic debates in the emerging field of data-driven smart urbanism by highlighting the ethical implications posed by the Metaverse as speculative fiction that illustrates the concerns raised by the pervasive and massive use of advanced technologies in data-driven smart cities. In doing so, it seeks to aid policy-makers in better understanding the pitfalls of the Metaverse and their repercussions upon the wellbeing of human users and the core values of urban society. It also stimulates prospective research and further critical perspectives on this timely topic.",
    "doi": "10.1007/s43762-022-00050-1",
    "url": "https://openalex.org/W4288077582",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s43762-022-00050-1.pdf",
    "venue": "Computational Urban Science",
    "citation_count": 134,
    "fields_of_study": [
      "Metaverse",
      "Computer science",
      "Sociology",
      "Data science",
      "Smart city"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585620"
  },
  {
    "source": "openalex",
    "source_id": "W4366989571",
    "title": "Algorithmic inclusion: Shaping the predictive algorithms of artificial intelligence in hiring",
    "authors": [
      "Elisabeth Kelan"
    ],
    "year": 2023,
    "abstract": "Abstract Despite frequent claims that increased use of artificial intelligence (AI) in hiring will reduce the human bias that has long plagued recruitment and selection, AI may equally replicate and amplify such bias and embed it in technology. This article explores exclusion and inclusion in AI\u2010supported hiring, focusing on three interrelated areas: data, design and decisions. It is suggested that in terms of data, organisational fit, categorisations and intersectionality require consideration in relation to exclusion. As various stakeholders collaborate to create AI, it is essential to explore which groups are dominant and how subjective assessments are encoded in technology. Although AI\u2010supported hiring should enhance recruitment decisions, evidence is lacking on how humans and machines interact in decision\u2010making, and how algorithms can be audited and regulated effectively for inclusion. This article recommends areas for interrogation through further research, and contributes to understanding how algorithmic inclusion can be achieved in AI\u2010supported hiring.",
    "doi": "10.1111/1748-8583.12511",
    "url": "https://openalex.org/W4366989571",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/1748-8583.12511",
    "venue": "Human Resource Management Journal",
    "citation_count": 66,
    "fields_of_study": [
      "Inclusion (mineral)",
      "Replicate",
      "Audit",
      "Computer science",
      "Selection (genetic algorithm)"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585653"
  },
  {
    "source": "openalex",
    "source_id": "W4367556998",
    "title": "ChatGPT in Dentistry: A Comprehensive Review",
    "authors": [
      "Hind M Alhaidry",
      "Bader Fatani",
      "Jenan O Alrayes",
      "Aljowhara M Almana",
      "Nawaf K Alfhaed"
    ],
    "year": 2023,
    "abstract": "Chat generative pre-trained transformer (ChatGPT) is an artificial intelligence chatbot that uses natural language processing that can respond to human input in a conversational manner. ChatGPT has numerous applications in the health care system including dentistry; it is used in diagnoses and for assessing disease risk and scheduling appointments. It also has a role in scientific research. In the dental field, it has provided many benefits such as detecting dental and maxillofacial abnormalities on panoramic radiographs and identifying different dental restorations. Therefore, it helps in decreasing the workload. But even with these benefits, one should take into consideration the risks and limitations of this chatbot. Few articles mentioned the use of ChatGPT in dentistry. This comprehensive review represents data collected from 66 relevant articles using PubMed and Google Scholar as databases. This review aims to discuss all relevant published articles on the use of ChatGPT in dentistry.",
    "doi": "10.7759/cureus.38317",
    "url": "https://openalex.org/W4367556998",
    "pdf_url": "https://assets.cureus.com/uploads/review_article/pdf/154683/20230531-32312-1iw73sz.pdf",
    "venue": "Cureus",
    "citation_count": 119,
    "fields_of_study": [
      "Medicine",
      "Workload",
      "Dentistry",
      "Documentation",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585667"
  },
  {
    "source": "openalex",
    "source_id": "W4224250711",
    "title": "Toward AI Governance: Identifying Best Practices and Potential Barriers and Outcomes",
    "authors": [
      "Emmanouil Papagiannidis",
      "Ida Merete Enholm",
      "Chirstian Dremel",
      "Patrick Mikalef",
      "John Krogstie"
    ],
    "year": 2022,
    "abstract": "Abstract In recent years artificial intelligence (AI) has been seen as a technology with tremendous potential for enabling companies to gain an operational and competitive advantage. However, despite the use of AI, businesses continue to face challenges and are unable to immediately realize performance gains. Furthermore, firms need to introduce robust AI systems and mitigate AI risks, which emphasizes the importance of creating suitable AI governance practices. This study, explores how AI governance is applied to promote the development of robust AI applications that do not introduce negative effects, based on a comparative case analysis of three firms in the energy sector. The study illustrates which practices are placed to produce knowledge that assists with decision making while at the same time overcoming barriers with recommended actions leading to desired outcomes. The study contributes by exploring the main dimensions relevant to AI\u2019s governance in organizations and by uncovering the practices that underpin them.",
    "doi": "10.1007/s10796-022-10251-y",
    "url": "https://openalex.org/W4224250711",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10796-022-10251-y.pdf",
    "venue": "Information Systems Frontiers",
    "citation_count": 111,
    "fields_of_study": [
      "Corporate governance",
      "Best practice",
      "Competitive advantage",
      "Knowledge management",
      "Face (sociological concept)"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585680"
  },
  {
    "source": "openalex",
    "source_id": "W4392106982",
    "title": "AI hype as a cyber security risk: the moral responsibility of implementing generative AI in business",
    "authors": [
      "Declan Humphreys",
      "Abigail Koay",
      "Dennis Desmond",
      "Erica Mealy"
    ],
    "year": 2024,
    "abstract": "Abstract This paper examines the ethical obligations companies have when implementing generative Artificial Intelligence (AI). We point to the potential cyber security risks companies are exposed to when rushing to adopt generative AI solutions or buying into \u201cAI hype\u201d. While the benefits of implementing generative AI solutions for business have been widely touted, the inherent risks associated have been less well publicised. There are growing concerns that the race to integrate generative AI is not being accompanied by adequate safety measures. The rush to buy into the hype of generative AI and not fall behind the competition is potentially exposing companies to broad and possibly catastrophic cyber-attacks or breaches. In this paper, we outline significant cyber security threats generative AI models pose, including potential \u2018backdoors\u2019 in AI models that could compromise user data or the risk of \u2018poisoned\u2019 AI models producing false results. In light of these the cyber security concerns, we discuss the moral obligations of implementing generative AI into business by considering the ethical principles of beneficence, non-maleficence, autonomy, justice, and explicability. We identify two examples of ethical concern, overreliance and over-trust in generative AI, both of which can negatively influence business decisions, leaving companies vulnerable to cyber security threats. This paper concludes by recommending a set of checklists for ethical implementation of generative AI in business environment to minimise cyber security risk based on the discussed moral responsibilities and ethical concern.",
    "doi": "10.1007/s43681-024-00443-4",
    "url": "https://openalex.org/W4392106982",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s43681-024-00443-4.pdf",
    "venue": "AI and Ethics",
    "citation_count": 71,
    "fields_of_study": [
      "Generative grammar",
      "Business",
      "Moral responsibility",
      "Engineering ethics",
      "Political science"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585693"
  },
  {
    "source": "openalex",
    "source_id": "W4383227059",
    "title": "The State of the Art in Deep Learning Applications, Challenges, and Future Prospects: A Comprehensive Review of Flood Forecasting and Management",
    "authors": [
      "Vijendra Kumar",
      "Hazi Mohammad Azamathulla",
      "Kul Vaibhav Sharma",
      "Darshan Mehta",
      "Kiran Tota\u2010Maharaj"
    ],
    "year": 2023,
    "abstract": "Floods are a devastating natural calamity that may seriously harm both infrastructure and people. Accurate flood forecasts and control are essential to lessen these effects and safeguard populations. By utilizing its capacity to handle massive amounts of data and provide accurate forecasts, deep learning has emerged as a potent tool for improving flood prediction and control. The current state of deep learning applications in flood forecasting and management is thoroughly reviewed in this work. The review discusses a variety of subjects, such as the data sources utilized, the deep learning models used, and the assessment measures adopted to judge their efficacy. It assesses current approaches critically and points out their advantages and disadvantages. The article also examines challenges with data accessibility, the interpretability of deep learning models, and ethical considerations in flood prediction. The report also describes potential directions for deep-learning research to enhance flood predictions and control. Incorporating uncertainty estimates into forecasts, integrating many data sources, developing hybrid models that mix deep learning with other methodologies, and enhancing the interpretability of deep learning models are a few of these. These research goals can help deep learning models become more precise and effective, which will result in better flood control plans and forecasts. Overall, this review is a useful resource for academics and professionals working on the topic of flood forecasting and management. By reviewing the current state of the art, emphasizing difficulties, and outlining potential areas for future study, it lays a solid basis. Communities may better prepare for and lessen the destructive effects of floods by implementing cutting-edge deep learning algorithms, thereby protecting people and infrastructure.",
    "doi": "10.3390/su151310543",
    "url": "https://openalex.org/W4383227059",
    "pdf_url": "https://www.mdpi.com/2071-1050/15/13/10543/pdf?version=1688475575",
    "venue": "Sustainability",
    "citation_count": 156,
    "fields_of_study": [
      "Interpretability",
      "Deep learning",
      "Flood myth",
      "Computer science",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585713"
  },
  {
    "source": "openalex",
    "source_id": "W3199921441",
    "title": "Ethics of artificial intelligence in global health: Explainability, algorithmic bias and trust",
    "authors": [
      "Angeliki Kerasidou"
    ],
    "year": 2021,
    "abstract": null,
    "doi": "10.1016/j.jobcr.2021.09.004",
    "url": "https://openalex.org/W3199921441",
    "pdf_url": "https://www.sciencedirect.com/science/article/pii/S2212426821000920",
    "venue": "Journal of Oral Biology and Craniofacial Research",
    "citation_count": 67,
    "fields_of_study": [
      "Context (archaeology)",
      "Health care",
      "Set (abstract data type)",
      "Medical diagnosis",
      "Economic Justice"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585734"
  },
  {
    "source": "openalex",
    "source_id": "W3014636188",
    "title": "Ensuring trustworthy use of artificial intelligence and big data analytics in health insurance",
    "authors": [
      "Calvin Wai-Loon Ho",
      "Joseph Ali",
      "Karel Caals"
    ],
    "year": 2020,
    "abstract": "Technological advances in big data (large amounts of highly varied data from many different sources that may be processed rapidly), data sciences and artificial intelligence can improve health-system functions and promote personalized care and public good. However, these technologies will not replace the fundamental components of the health system, such as ethical leadership and governance, or avoid the need for a robust ethical and regulatory environment. In this paper, we discuss what a robust ethical and regulatory environment might look like for big data analytics in health insurance, and describe examples of safeguards and participatory mechanisms that should be established. First, a clear and effective data governance framework is critical. Legal standards need to be enacted and insurers should be encouraged and given incentives to adopt a human-centred approach in the design and use of big data analytics and artificial intelligence. Second, a clear and accountable process is necessary to explain what information can be used and how it can be used. Third, people whose data may be used should be empowered through their active involvement in determining how their personal data may be managed and governed. Fourth, insurers and governance bodies, including regulators and policy-makers, need to work together to ensure that the big data analytics based on artificial intelligence that are developed are transparent and accurate. Unless an enabling ethical environment is in place, the use of such analytics will likely contribute to the proliferation of unconnected data systems, worsen existing inequalities, and erode trustworthiness and trust.",
    "doi": "10.2471/blt.19.234732",
    "url": "https://openalex.org/W3014636188",
    "pdf_url": "https://doi.org/10.2471/blt.19.234732",
    "venue": "Bulletin of the World Health Organization",
    "citation_count": 75,
    "fields_of_study": [
      "Big data",
      "Data governance",
      "Corporate governance",
      "Analytics",
      "Data science"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585738"
  },
  {
    "source": "openalex",
    "source_id": "W4389055737",
    "title": "Defining medical liability when artificial intelligence is applied on diagnostic algorithms: a systematic review",
    "authors": [
      "Clara Cestonaro",
      "Arianna Delicati",
      "Beatrice Marcante",
      "Luciana Caenazzo",
      "Pamela Tozzo"
    ],
    "year": 2023,
    "abstract": "Artificial intelligence (AI) in medicine is an increasingly studied and widespread phenomenon, applied in multiple clinical settings. Alongside its many potential advantages, such as easing clinicians\u2019 workload and improving diagnostic accuracy, the use of AI raises ethical and legal concerns, to which there is still no unanimous response. A systematic literature review on medical professional liability related to the use of AI-based diagnostic algorithms was conducted using the public electronic database PubMed selecting studies published from 2020 to 2023. The systematic review was performed according to 2020 PRISMA guidelines. The literature review highlights how the issue of liability in case of AI-related error and patient\u2019s damage has received growing attention in recent years. The application of AI and diagnostic algorithm moreover raises questions about the risks of using unrepresentative populations during the development and about the completeness of information given to the patient. Concerns about the impact on the fiduciary relationship between physician and patient and on the subject of empathy have also been raised. The use of AI in medical field and the application of diagnostic algorithms introduced a revolution in the doctor\u2013patient relationship resulting in multiple possible medico-legal consequences. The regulatory framework on medical liability when AI is applied is therefore inadequate and requires urgent intervention, as there is no single and specific regulation governing the liability of various parties involved in the AI supply chain, nor on end-users. Greater attention should be paid to inherent risk in AI and the consequent need for regulations regarding product safety as well as the maintenance of minimum safety standards through appropriate updates.",
    "doi": "10.3389/fmed.2023.1305756",
    "url": "https://openalex.org/W4389055737",
    "pdf_url": "https://www.frontiersin.org/articles/10.3389/fmed.2023.1305756/pdf?isPublishedV2=False",
    "venue": "Frontiers in Medicine",
    "citation_count": 118,
    "fields_of_study": [
      "Systematic review",
      "Liability",
      "Intervention (counseling)",
      "Risk analysis (engineering)",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585757"
  },
  {
    "source": "openalex",
    "source_id": "W4288855525",
    "title": "Future of Business Culture: An Artificial Intelligence\u2010Driven Digital Framework for Organization Decision\u2010Making Process",
    "authors": [
      "Navaneetha Krishnan Rajagopal",
      "Naila Iqbal Qureshi",
      "S. Durga",
      "Edwin Ramirez-As\u00eds",
      "Rosario Huerta-Soto",
      "Shashi Kant Gupta",
      "Sukheja Deepak"
    ],
    "year": 2022,
    "abstract": "Technological efforts are currently being used across a broad array of industries. Through the combination of consumer choice and matching principle, the goal of this paper is to investigate the prospective implications of artificial intelligence systems on businesses\u2019 outcomes. From an entrepreneurship standpoint, the research revealed that artificial intelligence systems can help with better decision\u2010making. What impact does the introduction of AI\u2010based decision\u2010making technologies have on organizational policymaking? The quirks of human and AI\u2010based policymaking are identified in this research based on five important contextual factors: precision of the choice search area, contribution to the innovation of the policymaking process and result, volume of the replacement collection, policymaking pace, and generalizability. We create a novel paradigm comparative analysis of conventional and automation judgment along these criteria, demonstrating how both judgment modalities can be used to improve organizational judgment efficiency. Furthermore, the research shows that, by involving internal stakeholders, they can manage the correlation among AI technologies and improve decision for businessmen. Furthermore, the research shows that customer preferences and industry norms can moderate the link between AI systems and superior entrepreneurial judgment. The goal of this work is to conduct a thorough literature analysis examining the confluence of AI and marketing philosophy, as well as construct a theoretical model that incorporates concerns based on established studies in the areas. This research shows that, in a setting with artificial intelligence systems, customer expectation, industry standards, and participative management, entrepreneurial strategic decisions are enhanced. This research provides entrepreneurs with technology means for enhancing decision\u2010making, illustrating the limitless possibilities given by AI systems. A conceptual approach is also formed, which discusses the four factors of profit maximization: relationship of AI tools and IT with corporate objectives; AI, organizational learning, and decision\u2010making methodology; and AI, service development, and value. This study proposes a way to exploit this innovative innovation without destroying society. We show real\u2010world examples of each of these frameworks, indicate circumstances in which they are likely to improve decision\u2010making performance in organizations, and provide actionable implications into their constraints. These observations have a wide variety of implications for establishing new management methods and practices from both academic and conceptual viewpoints.",
    "doi": "10.1155/2022/7796507",
    "url": "https://openalex.org/W4288855525",
    "pdf_url": "https://downloads.hindawi.com/journals/complexity/2022/7796507.pdf",
    "venue": "Complexity",
    "citation_count": 119,
    "fields_of_study": [
      "Process (computing)",
      "Computer science",
      "Process management",
      "Decision-making",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585778"
  },
  {
    "source": "openalex",
    "source_id": "W4362693892",
    "title": "A guide to formulating fairness in an optimization model",
    "authors": [
      "Violet Xinying Chen",
      "John Hooker"
    ],
    "year": 2023,
    "abstract": null,
    "doi": "10.1007/s10479-023-05264-y",
    "url": "https://openalex.org/W4362693892",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10479-023-05264-y.pdf",
    "venue": "Annals of Operations Research",
    "citation_count": 86,
    "fields_of_study": [
      "Minimax",
      "Comparability",
      "Computer science",
      "Theory of computation",
      "Axiom"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585818"
  },
  {
    "source": "openalex",
    "source_id": "W3166568332",
    "title": "A roadmap for the Human Developmental Cell Atlas",
    "authors": [
      "Muzlifah Haniffa",
      "Deanne Taylor",
      "Sten Linnarsson",
      "Bruce J. Aronow",
      "Gary D. Bader",
      "Roger A. Barker",
      "Pablo G. C\u00e1mara",
      "J. Gray Camp",
      "Alain Ch\u00e9dotal",
      "Andrew J. Copp",
      "Heather Etchevers",
      "Paolo Giacobini",
      "Berthold G\u00f6ttgens",
      "Guoji Guo",
      "Ania Hupalowska",
      "Kylie R. James",
      "Emily Kirby",
      "Arnold R. Kriegstein",
      "Joakim Lundeberg",
      "John C. Marioni",
      "Kerstin B. Meyer",
      "Kathy K. Niakan",
      "Mats Nilsson",
      "Bayanne Olabi",
      "Dana Pe\u2019er",
      "Aviv Regev",
      "Jennifer Rood",
      "Orit Rozenblatt\u2013Rosen",
      "Rahul Satija",
      "Sarah A. Teichmann",
      "Barbara Treutlein",
      "Roser Vento\u2010Tormo",
      "Simone Webb",
      "Pascal Barbry",
      "Omer Ali Bayraktar",
      "Sam Behjati",
      "Andreas Bosio",
      "Bruno Canque",
      "Fr\u00e9d\u00e9ric Chalmel",
      "Yorick Gitton",
      "Deborah J. Henderson",
      "Anne J\u00f8rgensen",
      "Steven Lisgo",
      "Jinyue Liu",
      "Emma Lundberg",
      "Jean\u2010L\u00e9on Ma\u00eetre",
      "S\u00e9verine Mazaud\u2010Guittot",
      "Elizabeth Robertson",
      "Antoine D. Rolland",
      "Rapha\u00ebl Scharfmann",
      "Mich\u00e8le Souyri",
      "Erik Sundstr\u00f6m",
      "St\u00e9phane Zaffran",
      "Matthias Zilbauer",
      "Matthias Zilbauer"
    ],
    "year": 2021,
    "abstract": null,
    "doi": "10.1038/s41586-021-03620-1",
    "url": "https://openalex.org/W3166568332",
    "pdf_url": "https://www.nature.com/articles/s41586-021-03620-1.pdf",
    "venue": "Nature",
    "citation_count": 179,
    "fields_of_study": [
      "Atlas (anatomy)",
      "Human cell",
      "Human Protein Atlas",
      "Biology",
      "Organogenesis"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585832"
  },
  {
    "source": "openalex",
    "source_id": "W2907164391",
    "title": "Big data governance of personal health information and challenges to contextual integrity",
    "authors": [
      "Jenifer Sunrise Winter",
      "Elizabeth Davidson"
    ],
    "year": 2018,
    "abstract": "Pervasive digitization and aggregation of personal health information (PHI), along with artificial intelligence (AI) and other advanced analytical techniques, hold promise of improved health and healthcare services. These advances also pose significant data governance challenges for ensuring value for individual, organizational, and societal stakeholders as well as individual privacy and autonomy. Through a case study of a controversial public-private partnership between Royal Free Trust, a National Health Service hospital system in the United Kingdom, and Alphabet\u2019s AI venture DeepMind Health, we investigate how forms of data governance were adapted, as PHI data flowed into new use contexts, to address concerns of contextual integrity, which is violated when personal information collected in one use context moves to another use&#13;\\ncontext with different norms of appropriateness.",
    "doi": "10.1080/01972243.2018.1542648",
    "url": "https://openalex.org/W2907164391",
    "pdf_url": "https://scholarspace.manoa.hawaii.edu/bitstreams/c3e18526-7fbb-4437-b9d3-2952800c9bc5/download",
    "venue": "The Information Society",
    "citation_count": 121,
    "fields_of_study": [
      "Corporate governance",
      "Data governance",
      "Information governance",
      "Autonomy",
      "Context (archaeology)"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585834"
  },
  {
    "source": "openalex",
    "source_id": "W4388103298",
    "title": "Ethical implications of artificial intelligence in accounting: A framework for responsible ai adoption in multinational corporations in Jordan",
    "authors": [
      "Ahmad Y. A. Bani Ahmad"
    ],
    "year": 2023,
    "abstract": "The accelerated progress of Artificial Intelligence (AI) within the accounting field has resulted in a heightened use of this technology in international enterprises, therefore generating noteworthy ethical concerns. This research investigates the ethical implications that arise from the use of AI in accounting practices, focusing on international corporations operating in Jordan. The objective of this research is to provide a comprehensive framework for the ethical and responsible integration of AI within the accounting domain. The research used a survey methods approach while 379 respondents were selected using cluster and proportional sampling. The qualitative component of the research investigates the viewpoints and concerns of persons pertaining to the use of AI. The study results provide significant contributions to the development of a context-specific paradigm for AI ethics that prioritizes concepts such as transparency, fairness, and accountability. The findings of this study have substantial value for multinational corporations engaged in commercial operations in Jordan and similar regions. The results provide organizations with the necessary tools to proficiently address the ethical dilemmas that emerge as a result of using artificial intelligence in accounting procedures.",
    "doi": "10.5267/j.ijdns.2023.9.014",
    "url": "https://openalex.org/W4388103298",
    "pdf_url": "https://doi.org/10.5267/j.ijdns.2023.9.014",
    "venue": "International Journal of Data and Network Science",
    "citation_count": 67,
    "fields_of_study": [
      "Multinational corporation",
      "Accountability",
      "Viewpoints",
      "Accounting",
      "Transparency (behavior)"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585847"
  },
  {
    "source": "openalex",
    "source_id": "W4317952105",
    "title": "Seeing Like a Toolkit: How Toolkits Envision the Work of AI Ethics",
    "authors": [
      "Richmond Y. Wong",
      "Michael Madaio",
      "Nick Merrill"
    ],
    "year": 2023,
    "abstract": "Numerous toolkits have been developed to support ethical AI development. However, toolkits, like all tools, encode assumptions in their design about what work should be done and how. In this paper, we conduct a qualitative analysis of 27 AI ethics toolkits to critically examine how the work of ethics is imagined and how it is supported by these toolkits. Specifically, we examine the discourses toolkits rely on when talking about ethical issues, who they imagine should do the work of ethics, and how they envision the work practices involved in addressing ethics. Among the toolkits, we identify a mismatch between the imagined work of ethics and the support the toolkits provide for doing that work. In particular, we identify a lack of guidance around how to navigate labor, organizational, and institutional power dynamics as they relate to performing ethical work. We use these omissions to chart future work for researchers and designers of AI ethics toolkits.",
    "doi": "10.1145/3579621",
    "url": "https://openalex.org/W4317952105",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3579621",
    "venue": "Proceedings of the ACM on Human-Computer Interaction",
    "citation_count": 86,
    "fields_of_study": [
      "Work (physics)",
      "Engineering ethics",
      "Information ethics",
      "Sociology",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585862"
  },
  {
    "source": "openalex",
    "source_id": "W4312621205",
    "title": "Artificial Intelligence in Emergency Medicine: Viewpoint of Current Applications and Foreseeable Opportunities and Challenges",
    "authors": [
      "Gabrielle Chenais",
      "Emmanuel Lagarde",
      "C\u00e9dric Gil\u2010Jardine"
    ],
    "year": 2022,
    "abstract": "Emergency medicine and its services have reached a breaking point during the COVID-19 pandemic. This pandemic has highlighted the failures of a system that needs to be reconsidered, and novel approaches need to be considered. Artificial intelligence (AI) has matured to the point where it is poised to fundamentally transform health care, and applications within the emergency field are particularly promising. In this viewpoint, we first attempt to depict the landscape of AI-based applications currently in use in the daily emergency field. We review the existing AI systems; their algorithms; and their derivation, validation, and impact studies. We also propose future directions and perspectives. Second, we examine the ethics and risk specificities of the use of AI in the emergency field.",
    "doi": "10.2196/40031",
    "url": "https://openalex.org/W4312621205",
    "pdf_url": "https://www.jmir.org/2023/1/e40031/PDF",
    "venue": "Journal of Medical Internet Research",
    "citation_count": 101,
    "fields_of_study": [
      "Field (mathematics)",
      "Pandemic",
      "Applications of artificial intelligence",
      "Coronavirus disease 2019 (COVID-19)",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585876"
  },
  {
    "source": "openalex",
    "source_id": "W2301623411",
    "title": "The STM Report: An overview of scientific and scholarly journal publishing",
    "authors": [
      "Mark Ware",
      "Michael Mabe"
    ],
    "year": 2015,
    "abstract": "Contents Executive summary \u25cf Scholarly communication \u25cf The research cycle \u25cf Types of scholarly communication \u25cf Changes in scholarly communication system \u25cf The journal \u25cf What is a journal? \u25cf The journals publishing cycle \u25cf Sales channels and models \u25cf Journal economics and market size \u25cf Journal and articles numbers and trends \u25cf Global trends in scientific output \u25cf Authors and readers \u25cf Publishers \u25cf Peer review. \u25cf Reading patterns \u25cf Disciplinary differences \u25cf Citations and the Impact Factor \u25cf Costs of journal publishing \u25cf Authors\u2019 behaviour, perceptions and attitudes \u25cf Publishing ethics \u25cf Copyright and licensing \u25cf Long term preservation \u25cf TRANSFER code \u25cf Researchers\u2019 access to journals \u25cf Open access \u25cf Drivers of open access \u25cf Open access business models \u25cf Types of open access journal \u25cf Delayed open access \u25cf Open access via self-archiving (\"Green\" OA) \u25cf Other open access variants \u25cf SCOAP3 \u25cf Open access to scholarly books \u25cf Public access \u25cf System-wide and economic perspectives \u25cf Other developments in open access \u25cf Transition and sustainability issues \u25cf Effect of self-archiving on journals. \u25cf Open access impacts on use \u25cf New developments in scholarly communication \u25cf \u201cScience 2.0\u201d or \"Open Science\" \u25cf FORCE11 and \u201cScience in Transition\u201d \u25cf Publishing platforms and APIs \u25cf Social media \u25cf Mobile access and apps \u25cf Research data \u25cf Semantic web and semantic enrichment \u25cf New article formats and features. \u25cf Text and data mining \u25cf Reproducibility \u25cf Big data & analytics \u25cf Identity and disambiguation \u25cf Research management and analytics \u25cf FundRef \u25cf Library publishing \u25cf Open Annotation \u25cf Learned societies \u25cf Author services and tools \u25cf Collaborative writing and sharing tools \u25cf Open notebook science \u25cf Conclusions \u25cf Information sources \u25cf Publisher organisations \u25cf Global statistics and trends \u25cf Open access \u25cf Publishing industry research and analysis \u25cf References 180pp",
    "doi": null,
    "url": "https://openalex.org/W2301623411",
    "pdf_url": "http://digitalcommons.unl.edu/scholcom/9",
    "venue": "Lincoln (University of Nebraska)",
    "citation_count": 405,
    "fields_of_study": [
      "Publishing",
      "Scientific publishing",
      "Library science",
      "Scholarly communication",
      "Political science"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585888"
  },
  {
    "source": "openalex",
    "source_id": "W4381250863",
    "title": "A Survey of Privacy Risks and Mitigation Strategies in the Artificial Intelligence Life Cycle",
    "authors": [
      "Sakib Shahriar",
      "Sonal Allana",
      "Seyed Mehdi Hazratifard",
      "Rozita Dara"
    ],
    "year": 2023,
    "abstract": "Over the decades, Artificial Intelligence (AI) and machine learning has become a transformative solution in many sectors, services, and technology platforms in a wide range of applications, such as in smart healthcare, financial, political, and surveillance systems. In such applications, a large amount of data is generated about diverse aspects of our life. Although utilizing AI in real-world applications provides numerous opportunities for societies and industries, it raises concerns regarding data privacy. Data used in an AI system are cleaned, integrated, and processed throughout the AI life cycle. Each of these stages can introduce unique threats to individual&#x2019;s privacy and have an impact on ethical processing and protection of data. In this paper, we examine privacy risks in different phases of the AI life cycle and review the existing privacy-enhancing solutions. We introduce four different categories of privacy risk, including (i) risk of identification, (ii) risk of making an inaccurate decision, (iii) risk of non-transparency in AI systems, and (iv) risk of non-compliance with privacy regulations and best practices. We then examined the potential privacy risks in each AI life cycle phase, evaluated concerns, and reviewed privacy-enhancing technologies, requirements, and process solutions to countermeasure these risks. We also reviewed some of the existing privacy protection policies and the need for compliance with available privacy regulations in AI-based systems. The main contribution of this survey is examining privacy challenges and solutions, including technology, process, and privacy legislation in the entire AI life cycle. In each phase of the AI life cycle, open challenges have been identified.",
    "doi": "10.1109/access.2023.3287195",
    "url": "https://openalex.org/W4381250863",
    "pdf_url": "https://ieeexplore.ieee.org/ielx7/6287639/10005208/10155147.pdf",
    "venue": "IEEE Access",
    "citation_count": 86,
    "fields_of_study": [
      "Information privacy",
      "Computer science",
      "Privacy by Design",
      "Transparency (behavior)",
      "Legislation"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585913"
  },
  {
    "source": "openalex",
    "source_id": "W4395676198",
    "title": "Artificial Intelligence and Healthcare: A Journey through History, Present Innovations, and Future Possibilities",
    "authors": [
      "Rahim Hirani",
      "Kaleb Noruzi",
      "Hassan Khuram",
      "Anum S. Hussaini",
      "Esewi Aifuwa",
      "Kencie Ely",
      "Joshua M. Lewis",
      "Ahmed E. Gabr",
      "Abbas Smiley",
      "Raj K. Tiwari",
      "Mill Etienne"
    ],
    "year": 2024,
    "abstract": "Artificial intelligence (AI) has emerged as a powerful tool in healthcare significantly impacting practices from diagnostics to treatment delivery and patient management. This article examines the progress of AI in healthcare, starting from the field\u2019s inception in the 1960s to present-day innovative applications in areas such as precision medicine, robotic surgery, and drug development. In addition, the impact of the COVID-19 pandemic on the acceleration of the use of AI in technologies such as telemedicine and chatbots to enhance accessibility and improve medical education is also explored. Looking forward, the paper speculates on the promising future of AI in healthcare while critically addressing the ethical and societal considerations that accompany the integration of AI technologies. Furthermore, the potential to mitigate health disparities and the ethical implications surrounding data usage and patient privacy are discussed, emphasizing the need for evolving guidelines to govern AI\u2019s application in healthcare.",
    "doi": "10.3390/life14050557",
    "url": "https://openalex.org/W4395676198",
    "pdf_url": "https://www.mdpi.com/2075-1729/14/5/557/pdf?version=1714114729",
    "venue": "Life",
    "citation_count": 134,
    "fields_of_study": [
      "Health care",
      "Telemedicine",
      "Pandemic",
      "Coronavirus disease 2019 (COVID-19)",
      "Applications of artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585933"
  },
  {
    "source": "openalex",
    "source_id": "W4388835050",
    "title": "Machine culture",
    "authors": [
      "Levin Brinkmann",
      "Fabian Baumann",
      "Jean\u2010Fran\u00e7ois Bonnefon",
      "Maxime Derex",
      "Thomas M\u00fcller",
      "Anne-Marie Nu\u00dfberger",
      "Agnieszka Czaplicka",
      "Alberto Acerbi",
      "Thomas L. Griffiths",
      "Joseph Henrich",
      "Joel Z. Leibo",
      "Richard McElreath",
      "Pierre-Yves Oudeyer",
      "Jonathan Stray",
      "Iyad Rahwan"
    ],
    "year": 2023,
    "abstract": null,
    "doi": "10.1038/s41562-023-01742-2",
    "url": "https://openalex.org/W4388835050",
    "pdf_url": "https://arxiv.org/pdf/2311.11388",
    "venue": "Nature Human Behaviour",
    "citation_count": 83,
    "fields_of_study": [
      "Cultural transmission in animals",
      "Computer science",
      "Variation (astronomy)",
      "Perspective (graphical)",
      "Selection (genetic algorithm)"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585949"
  },
  {
    "source": "openalex",
    "source_id": "W2889858158",
    "title": "Rapid developments in Artificial Intelligence: how might the New Zealand government respond?",
    "authors": [
      "Matthew Boyd",
      "Nick Wilson"
    ],
    "year": 2017,
    "abstract": "Advances in artificial intelligence (AI) have opened opportunities in a range of human endeavours (NSTC Committee on Technology, 2016). In response to the speed of these developments there has been a burst of analysis and dialogue in New Zealand. The New Zealand Institute of Directors commissioned a white paper (Chapman Tripp, 2016); the Ministry of Business, Innovation and Employment published Building a Digital Nation and the Strategic Science Investment Fund 2017\u201324 business plan (Ministry of Business, Innovation and Employment, 2017, 2016), and supports the new Artificial Intelligence Forum of New Zealand.",
    "doi": "10.26686/pq.v13i4.4619",
    "url": "https://openalex.org/W2889858158",
    "pdf_url": "https://ojs.victoria.ac.nz/pq/article/download/4619/4105",
    "venue": "Policy Quarterly",
    "citation_count": 75,
    "fields_of_study": [
      "Christian ministry",
      "White paper",
      "Government (linguistics)",
      "Management",
      "Political science"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585952"
  },
  {
    "source": "openalex",
    "source_id": "W2740983644",
    "title": "Gender as a Variable in Natural-Language Processing: Ethical Considerations",
    "authors": [
      "Brian Larson"
    ],
    "year": 2017,
    "abstract": "Researchers and practitioners in natural-language processing (NLP) and related fields should attend to ethical principles in study design, ascription of categories/variables to study participants, and reporting of findings or results. This paper discusses theoretical and ethical frameworks for using gender as a variable in NLP studies and proposes four guidelines for researchers and practitioners. The principles outlined here should guide practitioners, researchers, and peer reviewers, and they may be applicable to other social categories, such as race, applied to human beings connected to NLP research.",
    "doi": "10.18653/v1/w17-1601",
    "url": "https://openalex.org/W2740983644",
    "pdf_url": "https://www.aclweb.org/anthology/W17-1601.pdf",
    "venue": null,
    "citation_count": 108,
    "fields_of_study": [
      "Ascription",
      "Variable (mathematics)",
      "Race (biology)",
      "Computer science",
      "Natural (archaeology)"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585962"
  },
  {
    "source": "openalex",
    "source_id": "W4387886075",
    "title": "Exploring ChatGPT Capabilities and Limitations: A Survey",
    "authors": [
      "Anis Koub\u00e2a",
      "Wadii Boulila",
      "Lahouari Ghouti",
      "Ayyub Alzahem",
      "Shahid Latif"
    ],
    "year": 2023,
    "abstract": "ChatGPT, a groundbreaking natural language processing technology released a few months ago, has attracted significant attention due to its remarkable capabilities. This AI milestone has urged researchers, industry, decision-makers, and governments to examine this technology, including its implications, threats, and benefits. Despite the short period since its release, several researchers have examined ChatGPT from different perspectives. This paper presents a comprehensive review of ChatGPT, highlighting its technical novelties compared to previous models and analyzing existing research from various perspectives. We followed a rigorous methodology to conduct a critical review of existing research on ChatGPT and developed a taxonomy for the different areas of study. Additionally, we identify future challenges and research trends associated with ChatGPT. Our paper is the first critical review of ChatGPT literature, providing valuable insights for practitioners and policymakers. This paper is a reference for researchers seeking to advance research on ChatGPT, including its applications and development.",
    "doi": "10.1109/access.2023.3326474",
    "url": "https://openalex.org/W4387886075",
    "pdf_url": "https://ieeexplore.ieee.org/ielx7/6287639/6514899/10290719.pdf",
    "venue": "IEEE Access",
    "citation_count": 76,
    "fields_of_study": [
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585972"
  },
  {
    "source": "openalex",
    "source_id": "W4395007039",
    "title": "Green and sustainable AI research: an integrated thematic and topic modeling analysis",
    "authors": [
      "Raghu Raman",
      "Debidutta Pattnaik",
      "Hiran H. Lathabai",
      "Chandan Kumar",
      "Kannan Govindan",
      "Prema Nedungadi"
    ],
    "year": 2024,
    "abstract": "Abstract This investigation delves into Green AI and Sustainable AI literature through a dual-analytical approach, combining thematic analysis with BERTopic modeling to reveal both broad thematic clusters and nuanced emerging topics. It identifies three major thematic clusters: (1) Responsible AI for Sustainable Development, focusing on integrating sustainability and ethics within AI technologies; (2) Advancements in Green AI for Energy Optimization, centering on energy efficiency; and (3) Big Data-Driven Computational Advances, emphasizing AI\u2019s influence on socio-economic and environmental aspects. Concurrently, BERTopic modeling uncovers five emerging topics: Ethical Eco-Intelligence, Sustainable Neural Computing, Ethical Healthcare Intelligence, AI Learning Quest, and Cognitive AI Innovation, indicating a trend toward embedding ethical and sustainability considerations into AI research. The study reveals novel intersections between Sustainable and Ethical AI and Green Computing, indicating significant research trends and identifying Ethical Healthcare Intelligence and AI Learning Quest as evolving areas within AI\u2019s socio-economic and societal impacts. The study advocates for a unified approach to innovation in AI, promoting environmental sustainability and ethical integrity to foster responsible AI development. This aligns with the Sustainable Development Goals, emphasizing the need for ecological balance, societal welfare, and responsible innovation. This refined focus underscores the critical need for integrating ethical and environmental considerations into the AI development lifecycle, offering insights for future research directions and policy interventions.",
    "doi": "10.1186/s40537-024-00920-x",
    "url": "https://openalex.org/W4395007039",
    "pdf_url": "https://journalofbigdata.springeropen.com/counter/pdf/10.1186/s40537-024-00920-x",
    "venue": "Journal Of Big Data",
    "citation_count": 85,
    "fields_of_study": [
      "Computer science",
      "Thematic map",
      "Computational Science and Engineering",
      "Data science",
      "Thematic analysis"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585986"
  },
  {
    "source": "openalex",
    "source_id": "W4224241629",
    "title": "Dismantling AI capitalism: the commons as an alternative to the power concentration of Big Tech",
    "authors": [
      "Pieter Verdegem"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1007/s00146-022-01437-8",
    "url": "https://openalex.org/W4224241629",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s00146-022-01437-8.pdf",
    "venue": "AI & Society",
    "citation_count": 89,
    "fields_of_study": [
      "Capitalism",
      "Commons",
      "Performing arts",
      "Power (physics)",
      "Big data"
    ],
    "retrieved_at": "2026-02-02T16:58:14.586004"
  },
  {
    "source": "openalex",
    "source_id": "W4200290977",
    "title": "Cognitive computing based ethical principles for improving organisational reputation: A B2B digital marketing perspective",
    "authors": [
      "Rajat Kumar Behera",
      "Pradip Kumar Bala",
      "Nripendra P. Rana",
      "Hatice Kizgin"
    ],
    "year": 2021,
    "abstract": "Cognitive computing is ushering in the fourth industrial revolution through its promises of improved accuracy, scalability and personalisation. Therefore, business-to-business (B2B) organisations are wavering in the decision for adoption into their digital marketing initiatives. However, embracing moral rules and/or moral judgments in their digital marketing innovation can be challenging, since making mistakes could damage reputations. Therefore, this study applies the ethical principles of cognitive computing in B2B digital marketing business-centric ethical challenges. An integrated theoretical framework grounded on multidisciplinary studies is proposed. The primary data were collected from 300 respondents within B2B businesses. The results of this research led to the conclusion that good ethical practices are essential for the improvement of both organisational effectiveness and organisational reputation. Increased organisational reputation delivers a competitive edge in fast-growing marketplaces. B2B businesses need to look for proactive ways to achieve continuous improvement.",
    "doi": "10.1016/j.jbusres.2021.11.070",
    "url": "https://openalex.org/W4200290977",
    "pdf_url": "https://research.utwente.nl/en/publications/fcdde10b-d0c4-43b4-822e-98b4c8a21e56",
    "venue": "Journal of Business Research",
    "citation_count": 74,
    "fields_of_study": [
      "Reputation",
      "Multidisciplinary approach",
      "Personalization",
      "Perspective (graphical)",
      "Business"
    ],
    "retrieved_at": "2026-02-02T16:58:14.586007"
  },
  {
    "source": "openalex",
    "source_id": "W4282920034",
    "title": "Artificial Intelligence Decision-Making Transparency and Employees\u2019 Trust: The Parallel Multiple Mediating Effect of Effectiveness and Discomfort",
    "authors": [
      "Liangru Yu",
      "Yi Li"
    ],
    "year": 2022,
    "abstract": "The purpose of this paper is to investigate how Artificial Intelligence (AI) decision-making transparency affects humans\u2019 trust in AI. Previous studies have shown inconsistent conclusions about the relationship between AI transparency and humans\u2019 trust in AI (i.e., a positive correlation, non-correlation, or an inverted U-shaped relationship). Based on the stimulus-organism-response (SOR) model, algorithmic reductionism, and social identity theory, this paper explores the impact of AI decision-making transparency on humans\u2019 trust in AI from cognitive and emotional perspectives. A total of 235 participants with previous work experience were recruited online to complete the experimental vignette. The results showed that employees\u2019 perceived transparency, employees\u2019 perceived effectiveness of AI, and employees\u2019 discomfort with AI played mediating roles in the relationship between AI decision-making transparency and employees\u2019 trust in AI. Specifically, AI decision-making transparency (vs. non-transparency) led to higher perceived transparency, which in turn increased both effectiveness (which promoted trust) and discomfort (which inhibited trust). This parallel multiple mediating effect can partly explain the inconsistent findings in previous studies on the relationship between AI transparency and humans\u2019 trust in AI. This research has practical significance because it puts forward suggestions for enterprises to improve employees\u2019 trust in AI, so that employees can better collaborate with AI.",
    "doi": "10.3390/bs12050127",
    "url": "https://openalex.org/W4282920034",
    "pdf_url": "https://www.mdpi.com/2076-328X/12/5/127/pdf?version=1651056638",
    "venue": "Behavioral Sciences",
    "citation_count": 85,
    "fields_of_study": [
      "Transparency (behavior)",
      "Psychology",
      "Artificial intelligence",
      "Computer science",
      "Business"
    ],
    "retrieved_at": "2026-02-02T16:58:14.586024"
  },
  {
    "source": "openalex",
    "source_id": "W4382520149",
    "title": "The Impact of AI on Recruitment and Selection Processes: Analysing the role of AI in automating and enhancing recruitment and selection procedures",
    "authors": [
      "Saurabh Pratap Singh Rathore"
    ],
    "year": 2023,
    "abstract": "Human resource management is the process of identifying, recruiting, hiring, and training talented individuals, as well as providing them with career advancement possibilities and critical feedback on their performance. The purpose of this study was to investigate the function of AI in HRM practises using qualitative bibliometric analysis. Scopus, emerald, and the Jstore library are used as data sources. This analysis contains adjustments to data spanning 18 years. It also showed that there is a constant improvement and introduction of new technological conveniences. In accordance with the present market climate, which promotes and celebrates process management and people management practises targeted at making the organisation economically viable and different from the competition, this is a positive development. This work advances the theoretical understanding of AI's growth in the HR sector in light of this reality. Articles and proceedings examined in this research reveal that different authors and academic institutions provide different perspectives on the problem.",
    "doi": "10.55938/ijgasr.v2i2.50",
    "url": "https://openalex.org/W4382520149",
    "pdf_url": "https://journals.icapsr.com/index.php/ijgasr/article/download/50/115",
    "venue": "International Journal for Global Academic & Scientific Research",
    "citation_count": 85,
    "fields_of_study": [
      "Scopus",
      "Selection (genetic algorithm)",
      "Human resource management",
      "Competition (biology)",
      "Process (computing)"
    ],
    "retrieved_at": "2026-02-02T16:58:14.586045"
  },
  {
    "source": "openalex",
    "source_id": "W3127194607",
    "title": "The Threats of Artificial Intelligence Scale (TAI)",
    "authors": [
      "Kimon Kieslich",
      "Marco L\u00fcnich",
      "Frank Marcinkowski"
    ],
    "year": 2021,
    "abstract": "Abstract In recent years Artificial Intelligence (AI) has gained much popularity, with the scientific community as well as with the public. Often, AI is ascribed many positive impacts for different social domains such as medicine and the economy. On the other side, there is also growing concern about its precarious impact on society and individuals, respectively. Several opinion polls frequently query the public fear of autonomous robots and artificial intelligence, a phenomenon coming also into scholarly focus. As potential threat perceptions arguably vary with regard to the reach and consequences of AI functionalities and the domain of application, research still lacks necessary precision of a respective measurement that allows for wide-spread research applicability. We propose a fine-grained scale to measure threat perceptions of AI that accounts for four functional classes of AI systems and is applicable to various domains of AI applications. Using a standardized questionnaire in a survey study (N = 891), we evaluate the scale over three distinct AI domains (medical treatment, job recruitment, and loan origination). The data support the dimensional structure of the proposed Threats of AI (TAI) scale as well as the internal consistency and factoral validity of the indicators. Implications of the results and the empirical application of the scale are discussed in detail. Recommendations for further empirical use of the TAI scale are provided.",
    "doi": "10.1007/s12369-020-00734-w",
    "url": "https://openalex.org/W3127194607",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s12369-020-00734-w.pdf",
    "venue": "International Journal of Social Robotics",
    "citation_count": 91,
    "fields_of_study": [
      "Scale (ratio)",
      "Popularity",
      "Artificial intelligence",
      "Computer science",
      "Perception"
    ],
    "retrieved_at": "2026-02-02T16:58:14.586060"
  },
  {
    "source": "openalex",
    "source_id": "W4384824281",
    "title": "Responsible artificial intelligence in human resources management: a review of the empirical literature",
    "authors": [
      "Antoine Bujold",
      "Isabelle Roberge\u2010Maltais",
      "Xavier Parent\u2010Rocheleau",
      "Jared Boasen",
      "Sylvain S\u00e9n\u00e9cal",
      "Pierre\u2010Majorique L\u00e9ger"
    ],
    "year": 2023,
    "abstract": "Abstract As it is the case for many business processes and activities disciplines, artificial intelligence (AI) is increasingly integrated in human resources management (HRM). While AI has great potential to augment the HRM activities in organizations, automating the management of humans is not without risks and limitations. The identification of these risks is fundamental to promote responsible use of AI in HRM. We thus conducted a review of the empirical academic literature across disciplines on the affordances and responsible principles of AI in HRM. This is the first review of responsible AI in HRM that focuses solely on studies containing observations, measurements, and tests about this phenomenon. The multi-domain and multidisciplinary approach and empirical focus provides a better understanding of the reality of the development, study, and deployment of AI in HRM and sheds light on how these are conducted responsibly. We conclude with a call for research based on what we identified as the most needed and promising avenues.",
    "doi": "10.1007/s43681-023-00325-1",
    "url": "https://openalex.org/W4384824281",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s43681-023-00325-1.pdf",
    "venue": "AI and Ethics",
    "citation_count": 57,
    "fields_of_study": [
      "Knowledge management",
      "Empirical research",
      "Multidisciplinary approach",
      "Affordance",
      "Identification (biology)"
    ],
    "retrieved_at": "2026-02-02T16:58:14.586081"
  },
  {
    "source": "openalex",
    "source_id": "W4378901262",
    "title": "Artificial intelligence technology, public trust, and effective governance",
    "authors": [
      "Pedro Robles",
      "Daniel J. Mallinson"
    ],
    "year": 2023,
    "abstract": "Abstract Advancement in information technology continues to evolve especially in the field of artificial intelligence (AI). Research studies have been conducted to evaluate the perceptions of Americans on the development and utilization of AI technology and if it is appropriate to use AI in public administrative duties. The research revealed that society is fragmented regarding the acceptance of AI, and whether AI decisions could have long\u2010term effects on the labor industry, legal system, and national security. The 2018 AI Public Opinion Survey revealed significant concerns among the American public regarding AI, yet also a recognition of its promise. The goal of this article is to further develop a governance framework for AI that considers the importance of public trust in AI policy. First, it discusses the necessity of public trust for the effective governance of emergent technology. Then, it evaluates public opinion on AI technology that specifically pertains to governance. The article concludes with a discussion of why public trust is central to good AI governance.",
    "doi": "10.1111/ropr.12555",
    "url": "https://openalex.org/W4378901262",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/ropr.12555",
    "venue": "Review of Policy Research",
    "citation_count": 73,
    "fields_of_study": [
      "Corporate governance",
      "Public opinion",
      "Field (mathematics)",
      "Public trust",
      "Public relations"
    ],
    "retrieved_at": "2026-02-02T16:58:14.586096"
  },
  {
    "source": "openalex",
    "source_id": "W3045898680",
    "title": "Tackling COVID-19 through Responsible AI Innovation: Five Steps in the Right Direction",
    "authors": [
      "David Leslie"
    ],
    "year": 2020,
    "abstract": "Innovations in data science and artificial intelligence/machine learning (AI/ML) have a central role to play in supporting global efforts to combat COVID-19. The versatility of AI/ML technologies enables scientists and technologists to address an impressively broad range of biomedical, epidemiological, and socioeconomic challenges. This wide-reaching scientific capacity, however, also raises a diverse array of ethical challenges. The need for researchers to act quickly and globally in tackling SARS-CoV-2 demands unprecedented practices of open research and responsible data sharing at a time when innovation ecosystems are hobbled by proprietary protectionism, inequality, and a lack of public trust. Moreover, societally impactful interventions like digital contact tracing are raising fears of 'surveillance creep' and are challenging widely held commitments to privacy, autonomy, and civil liberties. Prepandemic concerns that data-driven innovations may function to reinforce entrenched dynamics of societal inequity have likewise intensified given the disparate impact of the virus on vulnerable social groups and the life-and-death consequences of biased and discriminatory public health outcomes. To address these concerns, I offer five steps that need to be taken to encourage responsible research and innovation. These provide a practice-based path to responsible AI/ML design and discovery centered on open, accountable, equitable, and democratically governed processes and products. When taken from the start, these steps will not only enhance the capacity of innovators to tackle COVID-19 responsibly, they will, more broadly, help to better equip the data science and AI/ML community to cope with future pandemics and to support a more humane, rational, and just society.",
    "doi": "10.1162/99608f92.4bb9d7a7",
    "url": "https://openalex.org/W3045898680",
    "pdf_url": "https://hdsr.mitpress.mit.edu/pub/as1p81um/download/pdf",
    "venue": "Harvard Data Science Review",
    "citation_count": 74,
    "fields_of_study": [
      "Public relations",
      "Data sharing",
      "Political science",
      "Autonomy",
      "Citizen science"
    ],
    "retrieved_at": "2026-02-02T16:58:14.586111"
  },
  {
    "source": "openalex",
    "source_id": "W4285819700",
    "title": "Artificial Intelligence Crime: An Overview of Malicious Use and Abuse of AI",
    "authors": [
      "Ta\u00eds Fernanda Blauth",
      "Oskar Josef Gstrein",
      "Andrej Zwitter"
    ],
    "year": 2022,
    "abstract": "The capabilities of Artificial Intelligence (AI) evolve rapidly and affect almost all sectors of society. AI has been increasingly integrated into criminal and harmful activities, expanding existing vulnerabilities, and introducing new threats. This article reviews the relevant literature, reports, and representative incidents which allows to construct a typology of the malicious use and abuse of systems with AI capabilities. The main objective is to clarify the types of activities and corresponding risks. Our starting point is to identify the vulnerabilities of AI models and outline how malicious actors can abuse them. Subsequently, we explore AI-enabled and AI-enhanced attacks. While we present a comprehensive overview, we do not aim for a conclusive and exhaustive classification. Rather, we provide an overview of the risks of enhanced AI application, that contributes to the growing body of knowledge on the issue. Specifically, we suggest four types of malicious abuse of AI (integrity attacks, unintended AI outcomes, algorithmic trading, membership inference attacks) and four types of malicious use of AI (social engineering, misinformation/fake news, hacking, autonomous weapon systems). Mapping these threats enables advanced reflection of governance strategies, policies, and activities that can be developed or improved to minimize risks and avoid harmful consequences. Enhanced collaboration among governments, industries, and civil society actors is vital to increase preparedness and resilience against malicious use and abuse of AI.",
    "doi": "10.1109/access.2022.3191790",
    "url": "https://openalex.org/W4285819700",
    "pdf_url": "https://ieeexplore.ieee.org/ielx7/6287639/6514899/09831441.pdf",
    "venue": "IEEE Access",
    "citation_count": 124,
    "fields_of_study": [
      "Computer security",
      "Computer science",
      "Resilience (materials science)",
      "Misinformation",
      "Hacker"
    ],
    "retrieved_at": "2026-02-02T16:58:14.586130"
  },
  {
    "source": "openalex",
    "source_id": "W4392894584",
    "title": "A critical review towards artificial general intelligence: Challenges, ethical considerations, and the path forward",
    "authors": [
      "Sedat Sonko",
      "Adebunmi Okechukwu Adewusi",
      "Ogugua Chimezie",
      "Shedrack Onwusinkwue",
      "Akoh Atadoga"
    ],
    "year": 2024,
    "abstract": "The pursuit of Artificial General Intelligence (AGI) has captivated researchers and industry leaders alike, promising a future where machines possess human-like cognitive abilities. However, this ambitious endeavor is fraught with multifaceted challenges and ethical dilemmas that necessitate careful examination. This critical review surveys the landscape of AGI research, identifying key hurdles and ethical considerations while outlining potential pathways forward. Firstly, technical challenges loom large on the path to AGI. These encompass fundamental problems such as developing robust learning algorithms capable of generalizing across diverse domains, as well as engineering systems that can exhibit adaptive and autonomous behavior akin to human intelligence. Additionally, ensuring the safety and reliability of AGI systems presents a formidable obstacle, with concerns ranging from algorithmic bias to the potential for catastrophic outcomes in unanticipated scenarios. Ethical considerations permeate every facet of AGI development and deployment. Questions of accountability, transparency, and control surface as central concerns, as the implications of relinquishing decision-making authority to autonomous systems raise profound ethical dilemmas. Moreover, the socio-economic ramifications of widespread AGI adoption, including job displacement and inequality, demand careful scrutiny and proactive mitigation strategies. Navigating these challenges requires a concerted effort from interdisciplinary stakeholders. Collaboration between computer scientists, ethicists, policymakers, and the public is essential to establish robust frameworks for the responsible development and deployment of AGI. Moreover, fostering an inclusive dialogue that prioritizes ethical principles and societal values is paramount in shaping a future where AGI augments human capabilities while safeguarding against potential risks. While the pursuit of AGI holds immense promise, its realization demands a holistic approach that addresses technical challenges alongside ethical considerations. By charting a path forward that prioritizes safety, transparency, and ethical governance, we can harness the transformative potential of AGI while ensuring its alignment with human values and interests.",
    "doi": "10.30574/wjarr.2024.21.3.0817",
    "url": "https://openalex.org/W4392894584",
    "pdf_url": "https://wjarr.com/sites/default/files/WJARR-2024-0817.pdf",
    "venue": "World Journal of Advanced Research and Reviews",
    "citation_count": 65,
    "fields_of_study": [
      "Transparency (behavior)",
      "Accountability",
      "Engineering ethics",
      "Computer science",
      "Scrutiny"
    ],
    "retrieved_at": "2026-02-02T16:58:14.586155"
  },
  {
    "source": "openalex",
    "source_id": "W4318566811",
    "title": "Is ChatGPT Leading Generative AI? What is Beyond Expectations?",
    "authors": [
      "\u00d6mer Ayd\u0131n",
      "Enis Karaarslan"
    ],
    "year": 2023,
    "abstract": null,
    "doi": "10.2139/ssrn.4341500",
    "url": "https://openalex.org/W4318566811",
    "pdf_url": "https://doi.org/10.2139/ssrn.4341500",
    "venue": "SSRN Electronic Journal",
    "citation_count": 124,
    "fields_of_study": [
      "Generative grammar",
      "Computer science",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:14.586183"
  },
  {
    "source": "openalex",
    "source_id": "W3215043243",
    "title": "Artificial intelligence in local governments: perceptions of city managers on prospects, constraints and choices",
    "authors": [
      "Tan Yi\u011fitcanlar",
      "Duzgun Agdas",
      "Kenan Degirmenci"
    ],
    "year": 2022,
    "abstract": "Abstract Highly sophisticated capabilities of artificial intelligence (AI) have skyrocketed its popularity across many industry sectors globally. The public sector is one of these. Many cities around the world are trying to position themselves as leaders of urban innovation through the development and deployment of AI systems. Likewise, increasing numbers of local government agencies are attempting to utilise AI technologies in their operations to deliver policy and generate efficiencies in highly uncertain and complex urban environments. While the popularity of AI is on the rise in urban policy circles, there is limited understanding and lack of empirical studies on the city manager perceptions concerning urban AI systems. Bridging this gap is the rationale of this study. The methodological approach adopted in this study is twofold. First, the study collects data through semi-structured interviews with city managers from Australia and the US. Then, the study analyses the data using the summative content analysis technique with two data analysis software. The analysis identifies the following themes and generates insights into local government services: AI adoption areas, cautionary areas, challenges, effects, impacts, knowledge basis, plans, preparedness, roadblocks, technologies, deployment timeframes, and usefulness. The study findings inform city managers in their efforts to deploy AI in their local government operations, and offer directions for prospective research.",
    "doi": "10.1007/s00146-022-01450-x",
    "url": "https://openalex.org/W3215043243",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s00146-022-01450-x.pdf",
    "venue": "AI & Society",
    "citation_count": 94,
    "fields_of_study": [
      "Software deployment",
      "Popularity",
      "Local government",
      "Preparedness",
      "Public sector"
    ],
    "retrieved_at": "2026-02-02T16:58:14.586186"
  },
  {
    "source": "openalex",
    "source_id": "W4392956046",
    "title": "Heterogeneity and predictors of the effects of AI assistance on radiologists",
    "authors": [
      "Feiyang Yu",
      "Alex Moehring",
      "Oishi Banerjee",
      "Tobias Salz",
      "Nikhil Agarwal",
      "Pranav Rajpurkar"
    ],
    "year": 2024,
    "abstract": null,
    "doi": "10.1038/s41591-024-02850-w",
    "url": "https://openalex.org/W4392956046",
    "pdf_url": "https://www.nature.com/articles/s41591-024-02850-w.pdf",
    "venue": "Nature Medicine",
    "citation_count": 125,
    "fields_of_study": [
      "Subspecialty",
      "Artificial intelligence",
      "Applications of artificial intelligence",
      "Medicine",
      "Machine learning"
    ],
    "retrieved_at": "2026-02-02T16:58:14.586210"
  },
  {
    "source": "openalex",
    "source_id": "W4362468036",
    "title": "Sustainability of the Metaverse: A Transition to Industry 5.0",
    "authors": [
      "Pietro De Giovanni"
    ],
    "year": 2023,
    "abstract": "This study analyzes the sustainability of the metaverse technology by adopting a responsible digitalization perspective to drive the transition to Industry 5.0. This is motivated by the current experiences of digital transformation paths, which appear careless regarding the side effects induced when adopting digital technologies\u2014for example, the energy consumption associated with blockchain, the jobs lost due to 3D printing, and the continuous payments required by artificial intelligence systems. While very few sustainable solutions are currently available to properly address these issues, similar effects might materialize when adopting metaverse technology. Therefore, this study provides tools to undertake a responsible digital transformation path through the metaverse to properly manage the transition to Industry 5.0. Specifically, it offers a set of frameworks to analyze the metaverse either from the perspective of the triple bottom line or by adopting an environmental, social, and governance (ESG) perspective and linking it to the most impacted business strategies or by connecting the technology to the sustainable development goals (SDGs). These tools enable readers to understand how society at large can responsibly implement, adopt, and manage a metaverse. By utilizing these frameworks, businesses can identify the most impacted strategies and take action to address any potential negative impacts.",
    "doi": "10.3390/su15076079",
    "url": "https://openalex.org/W4362468036",
    "pdf_url": "https://www.mdpi.com/2071-1050/15/7/6079/pdf?version=1680265695",
    "venue": "Sustainability",
    "citation_count": 208,
    "fields_of_study": [
      "Sustainability",
      "Metaverse",
      "Perspective (graphical)",
      "Computer science",
      "Business model"
    ],
    "retrieved_at": "2026-02-02T16:58:14.586213"
  },
  {
    "source": "openalex",
    "source_id": "W4385952733",
    "title": "Age-related bias and artificial intelligence: a scoping review",
    "authors": [
      "Charlene H. Chu",
      "Simon Donato\u2010Woodger",
      "Shehroz S. Khan",
      "Rune Nyrup",
      "Kathleen Leslie",
      "Alexandra Lyn",
      "Tianyu Shi",
      "Andria Bianchi",
      "Samira Abbasgholizadeh Rahimi",
      "Amanda Grenier"
    ],
    "year": 2023,
    "abstract": null,
    "doi": "10.1057/s41599-023-01999-y",
    "url": "https://openalex.org/W4385952733",
    "pdf_url": "https://www.nature.com/articles/s41599-023-01999-y.pdf",
    "venue": "Humanities and Social Sciences Communications",
    "citation_count": 70,
    "fields_of_study": [
      "Artificial intelligence",
      "Grey literature",
      "Gender bias",
      "Computer science",
      "Machine learning"
    ],
    "retrieved_at": "2026-02-02T16:58:14.586234"
  },
  {
    "source": "openalex",
    "source_id": "W2966881923",
    "title": "Bots at the Gate: A Human Rights Analysis of Automated Decision-Making in Canada\u2019s Immigration and Refugee System",
    "authors": [
      "Petra Molnar",
      "Lex Gill"
    ],
    "year": 2018,
    "abstract": "The report finds that use of automated decision-making technologies to augment or replace human judgment threatens to violate domestic and international human rights law, with alarming implications for the fundamental human rights of those subjected to these technologies.",
    "doi": null,
    "url": "https://openalex.org/W2966881923",
    "pdf_url": "http://hdl.handle.net/1807/94802",
    "venue": "Belarusian State Pedagogical University repository (Belarusian State Pedagogical University)",
    "citation_count": 81,
    "fields_of_study": [
      "Refugee",
      "Immigration",
      "Foundation (evidence)",
      "Human rights",
      "Political science"
    ],
    "retrieved_at": "2026-02-02T16:58:14.586237"
  },
  {
    "source": "openalex",
    "source_id": "W4390837884",
    "title": "The deep learning applications in IoT-based bio- and medical informatics: a systematic literature review",
    "authors": [
      "Zahra Mohtasham\u2010Amiri",
      "Arash Heidari",
      "Nima Jafari Navimipour",
      "Mansour Esmaeilpour",
      "Yalda Yazdani"
    ],
    "year": 2024,
    "abstract": "Abstract Nowadays, machine learning (ML) has attained a high level of achievement in many contexts. Considering the significance of ML in medical and bioinformatics owing to its accuracy, many investigators discussed multiple solutions for developing the function of medical and bioinformatics challenges using deep learning (DL) techniques. The importance of DL in Internet of Things (IoT)-based bio- and medical informatics lies in its ability to analyze and interpret large amounts of complex and diverse data in real time, providing insights that can improve healthcare outcomes and increase efficiency in the healthcare industry. Several applications of DL in IoT-based bio- and medical informatics include diagnosis, treatment recommendation, clinical decision support, image analysis, wearable monitoring, and drug discovery. The review aims to comprehensively evaluate and synthesize the existing body of the literature on applying deep learning in the intersection of the IoT with bio- and medical informatics. In this paper, we categorized the most cutting-edge DL solutions for medical and bioinformatics issues into five categories based on the DL technique utilized: convolutional neural network , recurrent neural network , generative adversarial network , multilayer perception , and hybrid methods. A systematic literature review was applied to study each one in terms of effective properties, like the main idea, benefits, drawbacks, methods, simulation environment, and datasets. After that, cutting-edge research on DL approaches and applications for bioinformatics concerns was emphasized. In addition, several challenges that contributed to DL implementation for medical and bioinformatics have been addressed, which are predicted to motivate more studies to develop medical and bioinformatics research progressively. According to the findings, most articles are evaluated using features like accuracy, sensitivity, specificity, F -score, latency, adaptability, and scalability.",
    "doi": "10.1007/s00521-023-09366-3",
    "url": "https://openalex.org/W4390837884",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s00521-023-09366-3.pdf",
    "venue": "Neural Computing and Applications",
    "citation_count": 146,
    "fields_of_study": [
      "Computer science",
      "Artificial intelligence",
      "Health informatics",
      "Machine learning",
      "Deep learning"
    ],
    "retrieved_at": "2026-02-02T16:58:14.586243"
  },
  {
    "source": "openalex",
    "source_id": "W4386526807",
    "title": "Strategic Framework for Leveraging Artificial Intelligence in Future Marketing Decision-Making",
    "authors": [
      "Nouri Hicham",
      "Habbat Nassera",
      "Sabri Karim"
    ],
    "year": 2023,
    "abstract": "Disruptive technologies such as the big data analytics, blockchain, Internet of Things, and artificial intelligence have each impacted how businesses operate. The most recent example of disruptive technology is artificial intelligence (AI), which has the most potential to revolutionize marketing completely. Practitioners worldwide are searching for artificial intelligence (AI) solutions most suited for their marketing functions. Artificial intelligence can provide marketers with assistance in a variety of ways to boost client satisfaction. This article looks at the exciting new developments in artificial intelligence (AI) and marketing that have been occurring recently, it examines the latest developments in marketing using artificial intelligence (AI). These breakthroughs encompass predictive analytics for analyzing customer behaviour, integrating chatbots to enhance customer support, and implementing AI-driven content personalization tactics. This article also covers the horizons and problems of artificial intelligence and marketing, the precise applications of AI in a range of marketing segments, and their impact on marketing sectors. Additionally, this article examines the particular applications of AI in marketing.",
    "doi": "10.56578/jimd020304",
    "url": "https://openalex.org/W4386526807",
    "pdf_url": "https://library.acadlore.com/JIMD/2023/2/3/JIMD_02.03_04.pdf",
    "venue": "Journal of Intelligent Management Decision",
    "citation_count": 112,
    "fields_of_study": [
      "Marketing and artificial intelligence",
      "Personalization",
      "Analytics",
      "Big data",
      "Variety (cybernetics)"
    ],
    "retrieved_at": "2026-02-02T16:58:14.586265"
  },
  {
    "source": "openalex",
    "source_id": "W4288758404",
    "title": "In-Processing Modeling Techniques for Machine Learning Fairness: A Survey",
    "authors": [
      "Mingyang Wan",
      "Daochen Zha",
      "Ninghao Liu",
      "Na Zou"
    ],
    "year": 2022,
    "abstract": "Machine learning models are becoming pervasive in high-stakes applications. Despite their clear benefits in terms of performance, the models could show discrimination against minority groups and result in fairness issues in a decision-making process, leading to severe negative impacts on the individuals and the society. In recent years, various techniques have been developed to mitigate the unfairness for machine learning models. Among them, in-processing methods have drawn increasing attention from the community, where fairness is directly taken into consideration during model design to induce intrinsically fair models and fundamentally mitigate fairness issues in outputs and representations. In this survey, we review the current progress of in-processing fairness mitigation techniques. Based on where the fairness is achieved in the model, we categorize them into explicit and implicit methods, where the former directly incorporates fairness metrics in training objectives, and the latter focuses on refining latent representation learning. Finally, we conclude the survey with a discussion of the research challenges in this community to motivate future exploration.",
    "doi": "10.1145/3551390",
    "url": "https://openalex.org/W4288758404",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3551390",
    "venue": "ACM Transactions on Knowledge Discovery from Data",
    "citation_count": 84,
    "fields_of_study": [
      "Computer science",
      "Categorization",
      "Machine learning",
      "Process (computing)",
      "Representation (politics)"
    ],
    "retrieved_at": "2026-02-02T16:58:14.586280"
  },
  {
    "source": "openalex",
    "source_id": "W4362458937",
    "title": "A vision transformer for decoding surgeon activity from surgical videos",
    "authors": [
      "Dani Kiyasseh",
      "Runzhuo Ma",
      "Taseen F. Haque",
      "Brian J. Miles",
      "Christian von Wagner",
      "Daniel A. Donoho",
      "Animashree Anandkumar",
      "Andrew J. Hung"
    ],
    "year": 2023,
    "abstract": null,
    "doi": "10.1038/s41551-023-01010-8",
    "url": "https://openalex.org/W4362458937",
    "pdf_url": "https://www.nature.com/articles/s41551-023-01010-8.pdf",
    "venue": "Nature Biomedical Engineering",
    "citation_count": 114,
    "fields_of_study": [
      "Decoding methods",
      "Gesture",
      "Surgical procedures",
      "Medicine",
      "Identification (biology)"
    ],
    "retrieved_at": "2026-02-02T16:58:14.586295"
  },
  {
    "source": "openalex",
    "source_id": "W4398177139",
    "title": "Exploring the Role of Artificial Intelligence in Mental Healthcare: Current Trends and Future Directions \u2013 A Narrative Review for a Comprehensive Insight",
    "authors": [
      "Ahmed M. Alhuwaydi"
    ],
    "year": 2024,
    "abstract": "Mental health is an essential component of the health and well-being of a person and community, and it is critical for the individual, society, and socio-economic development of any country. Mental healthcare is currently in the health sector transformation era, with emerging technologies such as artificial intelligence (AI) reshaping the screening, diagnosis, and treatment modalities of psychiatric illnesses. The present narrative review is aimed at discussing the current landscape and the role of AI in mental healthcare, including screening, diagnosis, and treatment. Furthermore, this review attempted to highlight the key challenges, limitations, and prospects of AI in providing mental healthcare based on existing works of literature. The literature search for this narrative review was obtained from PubMed, Saudi Digital Library (SDL), Google Scholar, Web of Science, and IEEE Xplore, and we included only English-language articles published in the last five years. Keywords used in combination with Boolean operators (\"AND\" and \"OR\") were the following: \"Artificial intelligence\", \"Machine learning\", Deep learning\", \"Early diagnosis\", \"Treatment\", \"interventions\", \"ethical consideration\", and \"mental Healthcare\". Our literature review revealed that, equipped with predictive analytics capabilities, AI can improve treatment planning by predicting an individual's response to various interventions. Predictive analytics, which uses historical data to formulate preventative interventions, aligns with the move toward individualized and preventive mental healthcare. In the screening and diagnostic domains, a subset of AI, such as machine learning and deep learning, has been proven to analyze various mental health data sets and predict the patterns associated with various mental health problems. However, limited studies have evaluated the collaboration between healthcare professionals and AI in delivering mental healthcare, as these sensitive problems require empathy, human connections, and holistic, personalized, and multidisciplinary approaches. Ethical issues, cybersecurity, a lack of data analytics diversity, cultural sensitivity, and language barriers remain concerns for implementing this futuristic approach in mental healthcare. Considering these sensitive problems require empathy, human connections, and holistic, personalized, and multidisciplinary approaches, it is imperative to explore these aspects. Therefore, future comparative trials with larger sample sizes and data sets are warranted to evaluate different AI models used in mental healthcare across regions to fill the existing knowledge gaps.",
    "doi": "10.2147/rmhp.s461562",
    "url": "https://openalex.org/W4398177139",
    "pdf_url": "https://www.dovepress.com/getfile.php?fileID=99286",
    "venue": "Risk Management and Healthcare Policy",
    "citation_count": 82,
    "fields_of_study": [
      "Narrative",
      "Narrative review",
      "Mental health",
      "Mental healthcare",
      "Health care"
    ],
    "retrieved_at": "2026-02-02T16:58:14.586297"
  },
  {
    "source": "openalex",
    "source_id": "W4283157638",
    "title": "It\u2019s Just Not That Simple: An Empirical Study of the Accuracy-Explainability Trade-off in Machine Learning for Public Policy",
    "authors": [
      "Andrew Bell",
      "Ian Ren\u00e9 Solano-Kamaiko",
      "Oded Nov",
      "Julia Stoyanovich"
    ],
    "year": 2022,
    "abstract": "To achieve high accuracy in machine learning (ML) systems, practitioners often use complex \"black-box\" models that are not easily understood by humans. The opacity of such models has resulted in public concerns about their use in high-stakes contexts and given rise to two conflicting arguments about the nature \u2014 and even the existence \u2014 of the accuracy-explainability trade-off. One side postulates that model accuracy and explainability are inversely related, leading practitioners to use black-box models when high accuracy is important. The other side of this argument holds that the accuracy-explainability trade-off is rarely observed in practice and consequently, that simpler interpretable models should always be preferred. Both sides of the argument operate under the assumption that some types of models, such as low-depth decision trees and linear regression are more explainable, while others such as neural networks and random forests, are inherently opaque.",
    "doi": "10.1145/3531146.3533090",
    "url": "https://openalex.org/W4283157638",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3531146.3533090",
    "venue": "2022 ACM Conference on Fairness, Accountability, and Transparency",
    "citation_count": 74,
    "fields_of_study": [
      "Simple (philosophy)",
      "Computer science",
      "Empirical research",
      "Machine learning",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:14.586327"
  },
  {
    "source": "openalex",
    "source_id": "W4327993492",
    "title": "Data-centric Artificial Intelligence: A Survey",
    "authors": [
      "Daochen Zha",
      "Zaid Pervaiz Bhat",
      "Kwei-Herng Lai",
      "Fan Yang",
      "Zhimeng Jiang",
      "Shaochen Zhong",
      "Xia Hu"
    ],
    "year": 2023,
    "abstract": "Artificial Intelligence (AI) is making a profound impact in almost every domain. A vital enabler of its great success is the availability of abundant and high-quality data for building machine learning models. Recently, the role of data in AI has been significantly magnified, giving rise to the emerging concept of data-centric AI. The attention of researchers and practitioners has gradually shifted from advancing model design to enhancing the quality and quantity of the data. In this survey, we discuss the necessity of data-centric AI, followed by a holistic view of three general data-centric goals (training data development, inference data development, and data maintenance) and the representative methods. We also organize the existing literature from automation and collaboration perspectives, discuss the challenges, and tabulate the benchmarks for various tasks. We believe this is the first comprehensive survey that provides a global view of a spectrum of tasks across various stages of the data lifecycle. We hope it can help the readers efficiently grasp a broad picture of this field, and equip them with the techniques and further research ideas to systematically engineer data for building AI systems. A companion list of data-centric AI resources will be regularly updated on https://github.com/daochenzha/data-centric-AI",
    "doi": "10.48550/arxiv.2303.10158",
    "url": "https://openalex.org/W4327993492",
    "pdf_url": "https://arxiv.org/pdf/2303.10158",
    "venue": "arXiv (Cornell University)",
    "citation_count": 97,
    "fields_of_study": [
      "Computer science",
      "Data science",
      "Enabling",
      "Data quality",
      "Field (mathematics)"
    ],
    "retrieved_at": "2026-02-02T16:58:14.586341"
  },
  {
    "source": "openalex",
    "source_id": "W4225105833",
    "title": "Environment of Peace: Security in a New Era of Risk",
    "authors": [
      "Richard Black",
      "Joshua W. Busby",
      "Geoffrey D. Dabelko",
      "Cedric de Coning",
      "Hafsa Maalim",
      "Claire McAllister",
      "Melvis Ndiloseh",
      "D. J. B. Smith",
      "Jos\u00e9 Francisco Alvarado C\u00f3bar",
      "Anniek Barnhoorn",
      "Noah Bell",
      "Daniel Bell-Moran",
      "Emilie Broek",
      "Alexis Eberlein",
      "Karolina Ekl\u00f6w",
      "Jakob Faller",
      "Andrea Gadnert",
      "Farah Hegazi",
      "Kyungmee Kim",
      "Florian Krampe",
      "David Michel",
      "Corey Pattison",
      "Caleb Ray",
      "Elise Remling",
      "Evelyn Salas Alfaro",
      "Elizabeth Smith",
      "J\u00fcrg Staudenmann"
    ],
    "year": 2022,
    "abstract": "The environmental crisis is increasing risks to security and peace worldwide, notably in countries that are already fragile. Indicators of insecurity such as the number of conflicts, the number of hungry people and military expenditure are rising; so are indicators of environmental decline, in climate change, biodiversity, pollution and other areas. In combination, the security and environmental crises are creating compound, cascading, emergent, systemic and existential risks. Without profound changes of approach by institutions of authority, risks will inevitably proliferate quickly. Environment of Peace surveys the evolving risk landscape and documents a number of developments that indicate a pathway to solutions\u2013\u2013in international law and policy, in peacekeeping operations and among non-governmental organizations. It finds that two principal avenues need to be developed: (a) combining peace-building and environmental restoration, and (b) effectively addressing the underlying environmental issues. It also analyses the potential of existing and emerging pro-environment measures for exacerbating risks to peace and security. The findings demonstrate that only just and peaceful transitions to more sustainable practices can be effective\u2013\u2013and show that these transitions also need to be rapid.",
    "doi": "10.55163/lcls7037",
    "url": "https://openalex.org/W4225105833",
    "pdf_url": "https://www.sipri.org/sites/default/files/2022-05/environment_of_peace_security_in_a_new_era_of_risk_0.pdf",
    "venue": null,
    "citation_count": 207,
    "fields_of_study": [
      "Peacekeeping",
      "Environmental security",
      "Principal (computer security)",
      "Political science",
      "Human security"
    ],
    "retrieved_at": "2026-02-02T16:58:14.586359"
  },
  {
    "source": "openalex",
    "source_id": "W4384464462",
    "title": "Creation of the algorithmic management questionnaire: A six\u2010phase scale development process",
    "authors": [
      "Xavier Parent\u2010Rocheleau",
      "Sharon K. Parker",
      "Antoine Bujold",
      "Marie\u2010Claude Gaudet"
    ],
    "year": 2023,
    "abstract": "Abstract There is an increasing body of research on algorithmic management (AM), but the field lacks measurement tools to capture workers' experiences of this phenomenon. Based on existing literature, we developed and validated the algorithmic management questionnaire (AMQ) to measure the perceptions of workers regarding their level of exposure to AM. Across three samples (overall n = 1332 gig workers), we show the content, factorial, discriminant, convergent, and predictive validity of the scale. The final 20\u2010item scale assesses workers' perceived level of exposure to algorithmic: monitoring, goal setting, scheduling, performance rating, and compensation. These dimensions formed a higher order construct assessing overall exposure to algorithmic management, which was found to be, as expected, negatively related to the work characteristics of job autonomy and job complexity and, indirectly, to work engagement. Supplementary analyses revealed that perceptions of exposure to AM reflect the objective presence of AM dimensions beyond individual variations in exposure. Overall, the results suggest the suitability of the AMQ to assess workers' perceived exposure to algorithmic management, which paves the way for further research on the impacts of these rapidly accelerating systems.",
    "doi": "10.1002/hrm.22185",
    "url": "https://openalex.org/W4384464462",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/hrm.22185",
    "venue": "Human Resource Management",
    "citation_count": 71,
    "fields_of_study": [
      "Scale (ratio)",
      "Discriminant validity",
      "Autonomy",
      "Applied psychology",
      "Psychology"
    ],
    "retrieved_at": "2026-02-02T16:58:14.586379"
  },
  {
    "source": "openalex",
    "source_id": "W4285155368",
    "title": "Challenges and Strategies in Cross-Cultural NLP",
    "authors": [
      "Daniel Hershcovich",
      "Stella Frank",
      "Heather Lent",
      "Miryam de Lhoneux",
      "Mostafa Abdou",
      "Stephanie Brandl",
      "Emanuele Bugliarello",
      "Laura Cabello Piqueras",
      "Ilias Chalkidis",
      "Ruixiang Cui",
      "Constanza Fierro",
      "Katerina Margatina",
      "Phillip Rust",
      "Anders S\u00f8gaard"
    ],
    "year": 2022,
    "abstract": "Various efforts in the Natural Language Processing (NLP) community have been made to accommodate linguistic diversity and serve speakers of many different languages. However, it is important to acknowledge that speakers and the content they produce and require, vary not just by language, but also by culture. Although language and culture are tightly linked, there are important differences. Analogous to cross-lingual and multilingual NLP, cross-cultural and multicultural NLP considers these differences in order to better serve users of NLP systems. We propose a principled framework to frame these efforts, and survey existing and potential strategies.",
    "doi": "10.18653/v1/2022.acl-long.482",
    "url": "https://openalex.org/W4285155368",
    "pdf_url": "https://aclanthology.org/2022.acl-long.482.pdf",
    "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "citation_count": 74,
    "fields_of_study": [
      "Computer science",
      "Natural language processing",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:14.586396"
  }
]