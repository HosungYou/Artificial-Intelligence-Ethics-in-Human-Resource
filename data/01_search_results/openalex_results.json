[
  {
    "source": "openalex",
    "source_id": "W4206346145",
    "title": "Can HR adapt to the paradoxes of artificial intelligence?",
    "authors": [
      "Andy Charlwood",
      "Nigel Guenole"
    ],
    "year": 2022,
    "abstract": "Abstract Artificial intelligence (AI) is widely heralded as a new and revolutionary technology that will transform the world of work. While the impact of AI on human resource (HR) and people management is difficult to predict, the article considers potential scenarios for how AI will affect our field. We argue that although popular accounts of AI stress the risks of bias and unfairness, these problems are eminently solvable. However, the way that the AI industry is currently constituted and wider trends in the use of technology for organising work mean that there is a significant risk that AI use will degrade the quality of work. Viewing different scenarios through a paradox lens, we argue that both positive and negative visions of the future are likely to coexist. The HR profession has a degree of agency to shape the future if it chooses to use it; HR professionals need to develop the skills to ensure that ethics and fairness are at the centre of AI development for HR and people management.",
    "doi": "10.1111/1748-8583.12433",
    "url": "https://openalex.org/W4206346145",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/1748-8583.12433",
    "venue": "Human Resource Management Journal",
    "citation_count": 199,
    "fields_of_study": [
      "Vision",
      "Agency (philosophy)",
      "Work (physics)",
      "Field (mathematics)",
      "Quality (philosophy)"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768317"
  },
  {
    "source": "openalex",
    "source_id": "W4236357753",
    "title": "The ARRIVE guidelines 2.0: Updated guidelines for reporting animal research",
    "authors": [
      "Nathalie Percie du Sert",
      "Viki Hurst",
      "Amrita Ahluwalia",
      "Sabina Alam",
      "Marc T. Avey",
      "Monya Baker",
      "William J. Browne",
      "Alejandra Clark",
      "Innes C. Cuthill",
      "Ulrich Dirnagl",
      "Michael Emerson",
      "Paul Garner",
      "Stephen T. Holgate",
      "David W. Howells",
      "Natasha A. Karp",
      "Stanley E. Lazic",
      "Katie Lidster",
      "Catriona MacCallum",
      "Malcolm Macleod",
      "Esther J. Pearl",
      "Ole H. Petersen",
      "Frances Rawle",
      "Penny S. Reynolds",
      "Kieron Rooney",
      "Emily S. Sena",
      "Shai D. Silberberg",
      "Thomas Steckler",
      "Hanno W\u00fcrbel"
    ],
    "year": 2020,
    "abstract": "Reproducible science requires transparent reporting. The ARRIVE guidelines (Animal Research: Reporting of In Vivo Experiments) were originally developed in 2010 to improve the reporting of animal research. They consist of a checklist of information to include in publications describing in vivo experiments to enable others to scrutinise the work adequately, evaluate its methodological rigour, and reproduce the methods and results. Despite considerable levels of endorsement by funders and journals over the years, adherence to the guidelines has been inconsistent, and the anticipated improvements in the quality of reporting in animal research publications have not been achieved. Here, we introduce ARRIVE 2.0. The guidelines have been updated and information reorganised to facilitate their use in practice. We used a Delphi exercise to prioritise and divide the items of the guidelines into 2 sets, the \"ARRIVE Essential 10,\" which constitutes the minimum requirement, and the \"Recommended Set,\" which describes the research context. This division facilitates improved reporting of animal research by supporting a stepwise approach to implementation. This helps journal editors and reviewers verify that the most important items are being reported in manuscripts. We have also developed the accompanying Explanation and Elaboration (E&E) document, which serves (1) to explain the rationale behind each item in the guidelines, (2) to clarify key concepts, and (3) to provide illustrative examples. We aim, through these changes, to help ensure that researchers, reviewers, and journal editors are better equipped to improve the rigour and transparency of the scientific process and thus reproducibility.",
    "doi": "10.1371/journal.pbio.3000410",
    "url": "https://openalex.org/W4236357753",
    "pdf_url": "https://journals.plos.org/plosbiology/article/file?id=10.1371/journal.pbio.3000410&type=printable",
    "venue": "PLoS Biology",
    "citation_count": 5017,
    "fields_of_study": [
      "Rigour",
      "Checklist",
      "Context (archaeology)",
      "Transparency (behavior)",
      "Set (abstract data type)"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768356"
  },
  {
    "source": "openalex",
    "source_id": "W2902634493",
    "title": "AI4People\u2014An Ethical Framework for a Good AI Society: Opportunities, Risks, Principles, and Recommendations",
    "authors": [
      "Luciano Floridi",
      "Josh Cowls",
      "Monica Beltrametti",
      "Raja Chatila",
      "Patrice Chazerand",
      "Virginia Dignum",
      "Christoph Luetge",
      "Robert Madelin",
      "Ugo Pagallo",
      "Francesca Rossi",
      "Burkhard Sch\u00e4fer",
      "Peggy Valcke",
      "Effy Vayena"
    ],
    "year": 2018,
    "abstract": null,
    "doi": "10.1007/s11023-018-9482-5",
    "url": "https://openalex.org/W2902634493",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s11023-018-9482-5.pdf",
    "venue": "Minds and Machines",
    "citation_count": 2813,
    "fields_of_study": [
      "Philosophy of science",
      "Foundation (evidence)",
      "Engineering ethics",
      "Responsible Research and Innovation",
      "Philosophy of mind"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768382"
  },
  {
    "source": "openalex",
    "source_id": "W2969625533",
    "title": "Artificial Intelligence (AI): Multidisciplinary perspectives on emerging challenges, opportunities, and agenda for research, practice and policy",
    "authors": [
      "Yogesh K. Dwivedi",
      "Laurie Hughes",
      "Elvira Ismagilova",
      "Gert Aarts",
      "Crispin Coombs",
      "Tom Crick",
      "Yanqing Duan",
      "Rohita Dwivedi",
      "John S. Edwards",
      "Aled Eirug",
      "Vassilis Galanos",
      "P. Vigneswara Ilavarasan",
      "Marijn Janssen",
      "Paul Jones",
      "Arpan Kumar Kar",
      "Hatice Kizgin",
      "Bianca Kronemann",
      "Banita Lal",
      "Biagio Lucini",
      "Rony Medaglia",
      "Kenneth Le Meunier\u2010FitzHugh",
      "Leslie Caroline Le Meunier-FitzHugh",
      "Santosh K. Misra",
      "Emmanuel Mogaji",
      "Sujeet Kumar Sharma",
      "Jang Bahadur Singh",
      "Vishnupriya Raghavan",
      "Ramakrishnan Raman",
      "Nripendra P. Rana",
      "Spyridon Samothrakis",
      "Jak Spencer",
      "Kuttimani Tamilmani",
      "Annie Tubadji",
      "Paul Walton",
      "Michael D. Williams"
    ],
    "year": 2019,
    "abstract": "&lt;p&gt;As far back as the industrial revolution, significant development in technical innovation has succeeded in transforming numerous manual tasks and processes that had been in existence for decades where humans had reached the limits of physical capacity. Artificial Intelligence (AI) offers this same transformative potential for the augmentation and potential replacement of human tasks and activities within a wide range of industrial, intellectual and social applications. The pace of change for this new AI technological age is staggering, with new breakthroughs in algorithmic machine learning and autonomous decision-making, engendering new opportunities for continued innovation. The impact of AI could be significant, with industries ranging from: finance, healthcare, manufacturing, retail, supply chain, logistics and utilities, all potentially disrupted by the onset of AI technologies. The study brings together the collective insight from a number of leading expert contributors to highlight the significant opportunities, realistic assessment of impact, challenges and potential research agenda posed by the rapid emergence of AI within a number of domains: business and management, government, public sector, and science and technology. This research offers significant and timely insight to AI technology and its impact on the future of industry and society in general, whilst recognising the societal and industrial influence on pace and direction of AI development.&lt;/p&gt;",
    "doi": "10.1016/j.ijinfomgt.2019.08.002",
    "url": "https://openalex.org/W2969625533",
    "pdf_url": "https://www.sciencedirect.com/science/article/pii/S026840121930917X",
    "venue": "International Journal of Information Management",
    "citation_count": 3635,
    "fields_of_study": [
      "Pace",
      "Transformative learning",
      "Government (linguistics)",
      "Multidisciplinary approach",
      "Supply chain"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768388"
  },
  {
    "source": "openalex",
    "source_id": "W4360620450",
    "title": "Opinion Paper: \u201cSo what if ChatGPT wrote it?\u201d Multidisciplinary perspectives on opportunities, challenges and implications of generative conversational AI for research, practice and policy",
    "authors": [
      "Yogesh K. Dwivedi",
      "Nir Kshetri",
      "Laurie Hughes",
      "Emma Slade",
      "Anand Jeyaraj",
      "Arpan Kumar Kar",
      "Abdullah M. Baabdullah",
      "Alex Koohang",
      "Vishnupriya Raghavan",
      "Manju Ahuja",
      "Hanaa Albanna",
      "Mousa Ahmad Albashrawi",
      "Adil S. Al-Busaidi",
      "Janarthanan Balakrishnan",
      "Yves Barlette",
      "Sriparna Basu",
      "Indranil Bose",
      "Laurence Brooks",
      "Dimitrios Buhalis",
      "Lemuria Carter",
      "Soumyadeb Chowdhury",
      "Tom Crick",
      "Scott W. Cunningham",
      "Gareth H. Davies",
      "Robert M. Davison",
      "Rahul D\u00e9",
      "Denis Dennehy",
      "Yanqing Duan",
      "Rameshwar Dubey",
      "Rohita Dwivedi",
      "John S. Edwards",
      "Carlos Flavi\u00e1n",
      "Robin Gauld",
      "Varun Grover",
      "Mei\u2010Chih Hu",
      "Marijn Janssen",
      "Paul Jones",
      "Iris Junglas",
      "Sangeeta Khorana",
      "Sascha Kraus",
      "Kai R. Larsen",
      "Paul Latreille",
      "Sven Laumer",
      "Tegwen Malik",
      "Abbas Mardani",
      "Marcello Mariani",
      "Sunil Mithas",
      "Emmanuel Mogaji",
      "Jeretta Horn Nord",
      "Siobh\u00e1n O\u2019Connor",
      "Fevzi Okumus",
      "Margherita Pagani",
      "Neeraj Pandey",
      "Savvas Papagiannidis",
      "Ilias O. Pappas",
      "Nishith Pathak",
      "Jan Pries\u2010Heje",
      "Ramakrishnan Raman",
      "Nripendra P. Rana",
      "Sven\u2010Volker Rehm",
      "Samuel Ribeiro\u2010Navarrete",
      "Alexander Richter",
      "Frantz Rowe",
      "Suprateek Sarker",
      "Bernd Carsten Stahl",
      "Manoj Tiwari",
      "Wil van der Aalst",
      "Viswanath Venkatesh",
      "Giampaolo Viglia",
      "Michael Wade",
      "Paul Walton",
      "Jochen Wirtz",
      "Ryan Wright"
    ],
    "year": 2023,
    "abstract": "Transformative artificially intelligent tools, such as ChatGPT, designed to generate sophisticated text indistinguishable from that produced by a human, are applicable across a wide range of contexts. The technology presents opportunities as well as, often ethical and legal, challenges, and has the potential for both positive and negative impacts for organisations, society, and individuals. Offering multi-disciplinary insight into some of these, this article brings together 43 contributions from experts in fields such as computer science, marketing, information systems, education, policy, hospitality and tourism, management, publishing, and nursing. The contributors acknowledge ChatGPT's capabilities to enhance productivity and suggest that it is likely to offer significant gains in the banking, hospitality and tourism, and information technology industries, and enhance business activities, such as management and marketing. Nevertheless, they also consider its limitations, disruptions to practices, threats to privacy and security, and consequences of biases, misuse, and misinformation. However, opinion is split on whether ChatGPT's use should be restricted or legislated. Drawing on these contributions, the article identifies questions requiring further research across three thematic areas: knowledge, transparency, and ethics; digital transformation of organisations and societies; and teaching, learning, and scholarly research. The avenues for further research include: identifying skills, resources, and capabilities needed to handle generative AI; examining biases of generative AI attributable to training datasets and processes; exploring business and societal contexts best suited for generative AI implementation; determining optimal combinations of human and generative AI for various tasks; identifying ways to assess accuracy of text produced by generative AI; and uncovering the ethical and legal issues in using generative AI across different contexts. 2023 The Authors",
    "doi": "10.1016/j.ijinfomgt.2023.102642",
    "url": "https://openalex.org/W4360620450",
    "pdf_url": "https://linkinghub.elsevier.com/science/article/pii/S0268401223000233/pdfft?md5=492895056a2fa29b1cb81876a1c57544&pid=1-s2.0-S0268401223000233-main.pdf",
    "venue": "International Journal of Information Management",
    "citation_count": 3140,
    "fields_of_study": [
      "Transformative learning",
      "Generative grammar",
      "Knowledge management",
      "Hospitality",
      "Engineering ethics"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768414"
  },
  {
    "source": "openalex",
    "source_id": "W4205372944",
    "title": "Ethics Guidelines for Using AI-based Algorithms in Recruiting: Learnings from a Systematic Literature Review",
    "authors": [
      "Lennart Hofeditz",
      "Milad Mirbabaie",
      "Audrey Luther",
      "Riccarda Mauth",
      "Ina Rentemeister"
    ],
    "year": 2022,
    "abstract": "To reduce the workload of employees working in Human Resource departments and to avoid bias in pre-selection of applicants, an increasing number of companies deploy Artificial Intelligence (AI)-based algorithms. Some examples such as Amazon\u2019s discriminating recruiting algorithm showed that algorithms are not free of unethical decision making. Although there already exists a variety of ethics principles for AI-based systems, those are usually hardly being applicable to specific use cases such as using AI-based algorithms in recruiting processes. To address this issue and to provide guidance for researchers and practitioners, we conducted a systematic literature review (keyword and backwards search) on existing ethics guidelines and principles for AI and extracted aspects that seemed applicable to guide recruiting processed. Based on 28 relevant papers we derived actionable guidelines for using AI-based algorithms in recruiting processes. We categorized our guidelines into the aspects of fairness, avoidance of discrimination and avoidance of bias.",
    "doi": "10.24251/hicss.2022.018",
    "url": "https://openalex.org/W4205372944",
    "pdf_url": "https://doi.org/10.24251/hicss.2022.018",
    "venue": "Proceedings of the ... Annual Hawaii International Conference on System Sciences/Proceedings of the Annual Hawaii International Conference on System Sciences",
    "citation_count": 18,
    "fields_of_study": [
      "Computer science",
      "Algorithm",
      "Management science",
      "Engineering"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768437"
  },
  {
    "source": "openalex",
    "source_id": "W4384071683",
    "title": "Large language models encode clinical knowledge",
    "authors": [
      "Karan Singhal",
      "Shekoofeh Azizi",
      "Tao Tu",
      "S. Sara Mahdavi",
      "Jason Lee",
      "Hyung Won Chung",
      "Nathan Scales",
      "Ajay Kumar Tanwani",
      "Heather Cole-Lewis",
      "Stephen Pfohl",
      "Perry W. Payne",
      "Martin Seneviratne",
      "Paul Gamble",
      "Christopher Kelly",
      "Abubakr Babiker",
      "Nathanael Sch\u00e4rli",
      "Aakanksha Chowdhery",
      "P. Mansfield",
      "Dina Demner\u2010Fushman",
      "Blaise Ag\u00fcera y Arcas",
      "Dale R. Webster",
      "Greg S. Corrado",
      "Yossi Matias",
      "Katherine Chou",
      "Juraj Gottweis",
      "Nenad Toma\u0161ev",
      "Yun Liu",
      "Alvin Rajkomar",
      "Jo\u00eblle Barral",
      "Christopher Semturs",
      "Alan Karthikesalingam",
      "Vivek Natarajan"
    ],
    "year": 2023,
    "abstract": null,
    "doi": "10.1038/s41586-023-06291-2",
    "url": "https://openalex.org/W4384071683",
    "pdf_url": "https://www.nature.com/articles/s41586-023-06291-2.pdf",
    "venue": "Nature",
    "citation_count": 2503,
    "fields_of_study": [
      "Computer science",
      "Benchmark (surveying)",
      "Language model",
      "Comprehension",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768457"
  },
  {
    "source": "openalex",
    "source_id": "W4386958277",
    "title": "Revolutionizing healthcare: the role of artificial intelligence in clinical practice",
    "authors": [
      "Shuroug A. Alowais",
      "Sahar S. Alghamdi",
      "Nada Alsuhebany",
      "Tariq Alqahtani",
      "Abdulrahman Alshaya",
      "Sumaya N. Almohareb",
      "Atheer Aldairem",
      "Mohammed Alrashed",
      "Khalid Bin Saleh",
      "Hisham A. Badreldin",
      "Majed S. Al Yami",
      "Shmeylan Al Harbi",
      "Abdulkareem Albekairy"
    ],
    "year": 2023,
    "abstract": null,
    "doi": "10.1186/s12909-023-04698-z",
    "url": "https://openalex.org/W4386958277",
    "pdf_url": "https://bmcmededuc.biomedcentral.com/counter/pdf/10.1186/s12909-023-04698-z",
    "venue": "BMC Medical Education",
    "citation_count": 2386,
    "fields_of_study": [
      "Health care",
      "MEDLINE",
      "Applications of artificial intelligence",
      "Medicine",
      "Leverage (statistics)"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768461"
  },
  {
    "source": "openalex",
    "source_id": "W4247155454",
    "title": "Artificial Intelligence and Management: The Automation\u2013Augmentation Paradox",
    "authors": [
      "Sebastian Raisch",
      "Sebastian Krakowski"
    ],
    "year": 2021,
    "abstract": "Taking three recent business books on artificial intelligence (AI) as a starting point, we explore the automation and augmentation concepts in the management domain. Whereas automation implies that machines take over a human task, augmentation means that humans collaborate closely with machines to perform a task. Taking a normative stance, the three books advise organizations to prioritize augmentation, which they relate to superior performance. Using a more comprehensive paradox theory perspective, we argue that, in the management domain, augmentation cannot be neatly separated from automation. These dual AI applications are interdependent across time and space, creating a paradoxical tension. Overemphasizing either augmentation or automation fuels reinforcing cycles with negative organizational and societal outcomes. However, if organizations adopt a broader perspective comprising both automation and augmentation, they could deal with the tension and achieve complementarities that benefit business and society. Drawing on our insights, we conclude that management scholars need to be involved in research on the use of AI in organizations. We also argue that a substantial change is required in how AI research is currently conducted in order to develop meaningful theory and to provide practice with sound advice.",
    "doi": "10.5465/amr.2018.0072",
    "url": "https://openalex.org/W4247155454",
    "pdf_url": "https://journals.aom.org/doi/full/10.5465/amr.2018.0072",
    "venue": "Academy of Management Review",
    "citation_count": 1382,
    "fields_of_study": [
      "Automation",
      "Task (project management)",
      "Interdependence",
      "Normative",
      "Knowledge management"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768464"
  },
  {
    "source": "openalex",
    "source_id": "W4386142022",
    "title": "Interpreting Black-Box Models: A Review on Explainable Artificial Intelligence",
    "authors": [
      "Vikas Hassija",
      "Vinay Chamola",
      "A. Mahapatra",
      "Abhinandan Singal",
      "Divyansh Goel",
      "Kaizhu Huang",
      "Simone Scardapane",
      "Indro Spinelli",
      "Mufti Mahmud",
      "Amir Hussain"
    ],
    "year": 2023,
    "abstract": "Abstract Recent years have seen a tremendous growth in Artificial Intelligence (AI)-based methodological development in a broad range of domains. In this rapidly evolving field, large number of methods are being reported using machine learning (ML) and Deep Learning (DL) models. Majority of these models are inherently complex and lacks explanations of the decision making process causing these models to be termed as 'Black-Box'. One of the major bottlenecks to adopt such models in mission-critical application domains, such as banking, e-commerce, healthcare, and public services and safety, is the difficulty in interpreting them. Due to the rapid proleferation of these AI models, explaining their learning and decision making process are getting harder which require transparency and easy predictability. Aiming to collate the current state-of-the-art in interpreting the black-box models, this study provides a comprehensive analysis of the explainable AI (XAI) models. To reduce false negative and false positive outcomes of these back-box models, finding flaws in them is still difficult and inefficient. In this paper, the development of XAI is reviewed meticulously through careful selection and analysis of the current state-of-the-art of XAI research. It also provides a comprehensive and in-depth evaluation of the XAI frameworks and their efficacy to serve as a starting point of XAI for applied and theoretical researchers. Towards the end, it highlights emerging and critical issues pertaining to XAI research to showcase major, model-specific trends for better explanation, enhanced transparency, and improved prediction accuracy.",
    "doi": "10.1007/s12559-023-10179-8",
    "url": "https://openalex.org/W4386142022",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s12559-023-10179-8.pdf",
    "venue": "Cognitive Computation",
    "citation_count": 1280,
    "fields_of_study": [
      "Transparency (behavior)",
      "Computer science",
      "Black box",
      "Process (computing)",
      "Predictability"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768486"
  },
  {
    "source": "openalex",
    "source_id": "W3199189488",
    "title": "Artificial intelligence in education: Addressing ethical challenges in K-12 settings",
    "authors": [
      "Selin Akg\u00fcn",
      "Christine Greenhow"
    ],
    "year": 2021,
    "abstract": null,
    "doi": "10.1007/s43681-021-00096-7",
    "url": "https://openalex.org/W3199189488",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s43681-021-00096-7.pdf",
    "venue": "AI and Ethics",
    "citation_count": 1028,
    "fields_of_study": [
      "Artificial intelligence",
      "Variety (cybernetics)",
      "Computer science",
      "Field (mathematics)",
      "Mathematics"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768508"
  },
  {
    "source": "openalex",
    "source_id": "W4317910584",
    "title": "ChatGPT: Bullshit spewer or the end of traditional assessments in higher education?",
    "authors": [
      "J\u00fcrgen Rudolph",
      "Samson Tan",
      "Shannon Tan"
    ],
    "year": 2023,
    "abstract": "ChatGPT is the world\u2019s most advanced chatbot thus far. Unlike other chatbots, it can create impressive prose within seconds, and it has created much hype and doomsday predictions when it comes to student assessment in higher education and a host of other matters. ChatGPT is a state-of-the-art language model (a variant of OpenAI\u2019s Generative Pretrained Transformer (GPT) language model) designed to generate text that can be indistinguishable from text written by humans. It can engage in conversation with users in a seemingly natural and intuitive way. In this article, we briefly tell the story of OpenAI, the organisation behind ChatGPT. We highlight the fundamental change from a not-for-profit organisation to a commercial business model. In terms of our methods, we conducted an extensive literature review and experimented with this artificial intelligence (AI) software. Our literature review shows our review to be amongst the first peer-reviewed academic journal articles to explore ChatGPT and its relevance for higher education (especially assessment, learning and teaching). After a description of ChatGPT\u2019s functionality and a summary of its strengths and limitations, we focus on the technology\u2019s implications for higher education and discuss what is the future of learning, teaching and assessment in higher education in the context of AI chatbots such as ChatGPT. We position ChatGPT in the context of current Artificial Intelligence in Education (AIEd) research, discuss student-facing, teacher-facing and system-facing applications, and analyse opportunities and threats. We conclude the article with recommendations for students, teachers and higher education institutions. Many of them focus on assessment.",
    "doi": "10.37074/jalt.2023.6.1.9",
    "url": "https://openalex.org/W4317910584",
    "pdf_url": "https://journals.sfu.ca/jalt/index.php/jalt/article/download/689/539",
    "venue": "Journal of Applied Learning & Teaching",
    "citation_count": 1549,
    "fields_of_study": [
      "Chatbot",
      "Conversation",
      "Relevance (law)",
      "Context (archaeology)",
      "Higher education"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768511"
  },
  {
    "source": "openalex",
    "source_id": "W4304943299",
    "title": "Ethical principles for artificial intelligence in education",
    "authors": [
      "Andy Nguyen",
      "Ha Ngan Ngo",
      "Yvonne Hong",
      "Belle Dang",
      "Bich\u2010Phuong Thi Nguyen"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1007/s10639-022-11316-w",
    "url": "https://openalex.org/W4304943299",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10639-022-11316-w.pdf",
    "venue": "Education and Information Technologies",
    "citation_count": 861,
    "fields_of_study": [
      "Autonomy",
      "Engineering ethics",
      "Underpinning",
      "Trustworthiness",
      "Set (abstract data type)"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768538"
  },
  {
    "source": "openalex",
    "source_id": "W4383312437",
    "title": "A comprehensive AI policy education framework for university teaching and learning",
    "authors": [
      "Cecilia Ka Yuk Chan"
    ],
    "year": 2023,
    "abstract": "Abstract This study aims to develop an AI education policy for higher education by examining the perceptions and implications of text generative AI technologies. Data was collected from 457 students and 180 teachers and staff across various disciplines in Hong Kong universities, using both quantitative and qualitative research methods. Based on the findings, the study proposes an AI Ecological Education Policy Framework to address the multifaceted implications of AI integration in university teaching and learning. This framework is organized into three dimensions: Pedagogical, Governance, and Operational. The Pedagogical dimension concentrates on using AI to improve teaching and learning outcomes, while the Governance dimension tackles issues related to privacy, security, and accountability. The Operational dimension addresses matters concerning infrastructure and training. The framework fosters a nuanced understanding of the implications of AI integration in academic settings, ensuring that stakeholders are aware of their responsibilities and can take appropriate actions accordingly.",
    "doi": "10.1186/s41239-023-00408-3",
    "url": "https://openalex.org/W4383312437",
    "pdf_url": "https://educationaltechnologyjournal.springeropen.com/counter/pdf/10.1186/s41239-023-00408-3",
    "venue": "International Journal of Educational Technology in Higher Education",
    "citation_count": 976,
    "fields_of_study": [
      "Dimension (graph theory)",
      "Accountability",
      "Corporate governance",
      "Higher education",
      "Sociology"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768541"
  },
  {
    "source": "openalex",
    "source_id": "W3033511014",
    "title": "Secure, privacy-preserving and federated machine learning in medical imaging",
    "authors": [
      "Georgios Kaissis",
      "Marcus R. Makowski",
      "Daniel R\u00fcckert",
      "Rickmer Braren"
    ],
    "year": 2020,
    "abstract": null,
    "doi": "10.1038/s42256-020-0186-1",
    "url": "https://openalex.org/W3033511014",
    "pdf_url": "https://www.nature.com/articles/s42256-020-0186-1.pdf",
    "venue": "Nature Machine Intelligence",
    "citation_count": 1148,
    "fields_of_study": [
      "Compromise",
      "Computer science",
      "Information privacy",
      "Computer security",
      "Bridge (graph theory)"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768556"
  },
  {
    "source": "openalex",
    "source_id": "W3155263273",
    "title": "Ethics of AI in Education: Towards a Community-Wide Framework",
    "authors": [
      "W. Holmes",
      "Ka\u015bka Porayska\u2010Pomsta",
      "Ken Holstein",
      "Emma Sutherland",
      "Toby T. Baker",
      "Simon Buckingham Shum",
      "Olga C. Santos",
      "Ma. Mercedes T. Rodrigo",
      "Mutlu Cukurova",
      "Ig Ibert Bittencourt",
      "Kenneth R. Koedinger"
    ],
    "year": 2021,
    "abstract": "Abstract While Artificial Intelligence in Education (AIED) research has at its core the desire to support student learning, experience from other AI domains suggest that such ethical intentions are not by themselves sufficient. There is also the need to consider explicitly issues such as fairness, accountability, transparency, bias, autonomy, agency, and inclusion. At a more general level, there is also a need to differentiate between doing ethical things and doing things ethically , to understand and to make pedagogical choices that are ethical, and to account for the ever-present possibility of unintended consequences. However, addressing these and related questions is far from trivial. As a first step towards addressing this critical gap, we invited 60 of the AIED community\u2019s leading researchers to respond to a survey of questions about ethics and the application of AI in educational contexts. In this paper, we first introduce issues around the ethics of AI in education. Next, we summarise the contributions of the 17 respondents, and discuss the complex issues that they raised. Specific outcomes include the recognition that most AIED researchers are not trained to tackle the emerging ethical questions. A well-designed framework for engaging with ethics of AIED that combined a multidisciplinary approach and a set of robust guidelines seems vital in this context.",
    "doi": "10.1007/s40593-021-00239-1",
    "url": "https://openalex.org/W3155263273",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s40593-021-00239-1.pdf",
    "venue": "International Journal of Artificial Intelligence in Education",
    "citation_count": 840,
    "fields_of_study": [
      "Accountability",
      "Autonomy",
      "Transparency (behavior)",
      "Engineering ethics",
      "Information ethics"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768559"
  },
  {
    "source": "openalex",
    "source_id": "W4385878593",
    "title": "New Era of Artificial Intelligence in Education: Towards a Sustainable Multifaceted Revolution",
    "authors": [
      "Firuz Kamalov",
      "David Santandreu Calonge",
      "Ikhlaas Gurrib"
    ],
    "year": 2023,
    "abstract": "The recent high performance of ChatGPT on several standardized academic tests has thrust the topic of artificial intelligence (AI) into the mainstream conversation about the future of education. As deep learning is poised to shift the teaching paradigm, it is essential to have a clear understanding of its effects on the current education system to ensure sustainable development and deployment of AI-driven technologies at schools and universities. This research aims to investigate the potential impact of AI on education through review and analysis of the existing literature across three major axes: applications, advantages, and challenges. Our review focuses on the use of artificial intelligence in collaborative teacher\u2013student learning, intelligent tutoring systems, automated assessment, and personalized learning. We also report on the potential negative aspects, ethical issues, and possible future routes for AI implementation in education. Ultimately, we find that the only way forward is to embrace the new technology, while implementing guardrails to prevent its abuse.",
    "doi": "10.3390/su151612451",
    "url": "https://openalex.org/W4385878593",
    "pdf_url": "https://www.mdpi.com/2071-1050/15/16/12451/pdf?version=1692181759",
    "venue": "Sustainability",
    "citation_count": 771,
    "fields_of_study": [
      "Mainstream",
      "Software deployment",
      "Applications of artificial intelligence",
      "Computer science",
      "Conversation"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768578"
  },
  {
    "source": "openalex",
    "source_id": "W3001807593",
    "title": "Closing the AI accountability gap",
    "authors": [
      "Inioluwa Deborah Raji",
      "Andrew Smart",
      "Rebecca N. White",
      "Margaret Mitchell",
      "Timnit Gebru",
      "Ben Hutchinson",
      "Jamila Smith-Loud",
      "Daniel Theron",
      "Parker Barnes"
    ],
    "year": 2020,
    "abstract": "Rising concern for the societal implications of artificial intelligence systems has inspired a wave of academic and journalistic literature in which deployed systems are audited for harm by investigators from outside the organizations deploying the algorithms. However, it remains challenging for practitioners to identify the harmful repercussions of their own systems prior to deployment, and, once deployed, emergent issues can become difficult or impossible to trace back to their source.",
    "doi": "10.1145/3351095.3372873",
    "url": "https://openalex.org/W3001807593",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3351095.3372873",
    "venue": null,
    "citation_count": 773,
    "fields_of_study": [
      "Software deployment",
      "Closing (real estate)",
      "Accountability",
      "Harm",
      "TRACE (psycholinguistics)"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768594"
  },
  {
    "source": "openalex",
    "source_id": "W4242918116",
    "title": "Data Feminism",
    "authors": [
      "Catherine D\u2019Ignazio",
      "Lauren Klein"
    ],
    "year": 2020,
    "abstract": "A new way of thinking about data science and data ethics that is informed by the ideas of intersectional feminism. Today, data science is a form of power. It has been used to expose injustice, improve health outcomes, and topple governments. But it has also been used to discriminate, police, and surveil. This potential for good, on the one hand, and harm, on the other, makes it essential to ask: Data science by whom? Data science for whom? Data science with whose interests in mind? The narratives around big data and data science are overwhelmingly white, male, and techno-heroic. In Data Feminism, Catherine D'Ignazio and Lauren Klein present a new way of thinking about data science and data ethics\u2014one that is informed by intersectional feminist thought. Illustrating data feminism in action, D'Ignazio and Klein show how challenges to the male/female binary can help challenge other hierarchical (and empirically wrong) classification systems. They explain how, for example, an understanding of emotion can expand our ideas about effective data visualization, and how the concept of invisible labor can expose the significant human efforts required by our automated systems. And they show why the data never, ever \u201cspeak for themselves.\u201d Data Feminism offers strategies for data scientists seeking to learn how feminism can help them work toward justice, and for feminists who want to focus their efforts on the growing field of data science. But Data Feminism is about much more than gender. It is about power, about who has it and who doesn't, and about how those differentials of power can be challenged and changed. The open access edition of this book was made possible by generous funding from the MIT Libraries.",
    "doi": "10.7551/mitpress/11805.001.0001",
    "url": "https://openalex.org/W4242918116",
    "pdf_url": "https://direct.mit.edu/books/book-pdf/2390355/book_9780262358521.pdf",
    "venue": "The MIT Press eBooks",
    "citation_count": 1306,
    "fields_of_study": [
      "Feminism",
      "Big data",
      "Injustice",
      "Sociology",
      "Engineering ethics"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768603"
  },
  {
    "source": "openalex",
    "source_id": "W4221106857",
    "title": "Legal and Ethical Consideration in Artificial Intelligence in Healthcare: Who Takes Responsibility?",
    "authors": [
      "Nithesh Naik",
      "B. M. Zeeshan Hameed",
      "Dasharathraj K Shetty",
      "Dishant Swain",
      "Milap Shah",
      "Rahul Paul",
      "Kaivalya Aggarwal",
      "Sufyan Ibrahim",
      "Vathsala Patil",
      "Komal Smriti",
      "Suyog Shetty",
      "Bhavan Prasad",
      "P. Ch\u0142osta",
      "Bhaskar Somani"
    ],
    "year": 2022,
    "abstract": "The legal and ethical issues that confront society due to Artificial Intelligence (AI) include privacy and surveillance, bias or discrimination, and potentially the philosophical challenge is the role of human judgment. Concerns about newer digital technologies becoming a new source of inaccuracy and data breaches have arisen as a result of its use. Mistakes in the procedure or protocol in the field of healthcare can have devastating consequences for the patient who is the victim of the error. Because patients come into contact with physicians at moments in their lives when they are most vulnerable, it is crucial to remember this. Currently, there are no well-defined regulations in place to address the legal and ethical issues that may arise due to the use of artificial intelligence in healthcare settings. This review attempts to address these pertinent issues highlighting the need for algorithmic transparency, privacy, and protection of all the beneficiaries involved and cybersecurity of associated vulnerabilities.",
    "doi": "10.3389/fsurg.2022.862322",
    "url": "https://openalex.org/W4221106857",
    "pdf_url": "https://www.frontiersin.org/articles/10.3389/fsurg.2022.862322/pdf",
    "venue": "Frontiers in Surgery",
    "citation_count": 792,
    "fields_of_study": [
      "Transparency (behavior)",
      "Health care",
      "Ethical issues",
      "Internet privacy",
      "Engineering ethics"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768628"
  },
  {
    "source": "openalex",
    "source_id": "W1598829572",
    "title": "Social Science Research: Principles, Methods and Practices",
    "authors": [
      "Anol Bhattacherjee",
      "Toleman, Mark",
      "Rowling, Samara",
      "Frederiks, Anita",
      "Andersen, Nikki"
    ],
    "year": 2019,
    "abstract": "This book is designed to introduce doctoral and postgraduate students to the process of conducting scientific research in the social sciences, business, education, public health, and related disciplines. It is a one-stop, comprehensive, and compact source for foundational concepts in behavioural research, and can serve as a standalone text or as a supplement to research readings in any doctoral seminar or research methods class. This book is currently being used as a research text at universities in 216 countries, across six continents and has been translated into seven different languages. To receive updates on this book, including the translated versions, please follow the author on Facebook or Twitter @Anol_B.",
    "doi": "10.26192/q7w89",
    "url": "https://openalex.org/W1598829572",
    "pdf_url": "https://digitalcommons.usf.edu/oa_textbooks/3",
    "venue": "University of Southern Queensland ePrints (University of Southern Queensland)",
    "citation_count": 2049,
    "fields_of_study": [
      "Management science",
      "Sociology",
      "Engineering ethics",
      "Data science",
      "Social science"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768643"
  },
  {
    "source": "openalex",
    "source_id": "W3135539146",
    "title": "Sustainable AI: AI for sustainability and the sustainability of AI",
    "authors": [
      "Aimee van Wynsberghe"
    ],
    "year": 2021,
    "abstract": "Abstract While there is a growing effort towards AI for Sustainability (e.g. towards the sustainable development goals) it is time to move beyond that and to address the sustainability of developing and using AI systems. In this paper I propose a definition of Sustainable AI; Sustainable AI is a movement to foster change in the entire lifecycle of AI products (i.e. idea generation, training, re-tuning, implementation, governance) towards greater ecological integrity and social justice. As such, Sustainable AI is focused on more than AI applications; rather, it addresses the whole sociotechnical system of AI. I have suggested here that Sustainable AI is not about how to sustain the development of AI per say but it is about how to develop AI that is compatible with sustaining environmental resources for current and future generations; economic models for societies; and societal values that are fundamental to a given society. I have articulated that the phrase Sustainable AI be understood as having two branches; AI for sustainability and sustainability of AI (e.g. reduction of carbon emissions and computing power). I propose that Sustainable AI take sustainable development at the core of its definition with three accompanying tensions between AI innovation and equitable resource distribution; inter and intra-generational justice; and, between environment, society, and economy. This paper is not meant to engage with each of the three pillars of sustainability (i.e. social, economic, environment), and as such the pillars of sustainable AI. Rather, this paper is meant to inspire the reader, the policy maker, the AI ethicist, the AI developer to connect with the environment\u2014to remember that there are environmental costs to AI. Further, to direct funding towards sustainable methods of AI.",
    "doi": "10.1007/s43681-021-00043-6",
    "url": "https://openalex.org/W3135539146",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s43681-021-00043-6.pdf",
    "venue": "AI and Ethics",
    "citation_count": 717,
    "fields_of_study": [
      "Sustainability",
      "Sustainable development",
      "Social sustainability",
      "Corporate governance",
      "Business"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768656"
  },
  {
    "source": "openalex",
    "source_id": "W2954266614",
    "title": "A Unified Framework of Five Principles for AI in Society",
    "authors": [
      "Luciano Floridi",
      "Josh Cowls"
    ],
    "year": 2019,
    "abstract": "Artificial Intelligence (AI) is already having a major impact on society. As a result, many organizations have launched a wide range of initiatives to establish ethical principles for the adoption of socially beneficial AI. Unfortunately, the sheer volume of proposed principles threatens to overwhelm and confuse. How might this problem of 'principle proliferation' be solved? In this paper, we report the results of a fine-grained analysis of several of the highest-profile sets of ethical principles for AI. We assess whether these principles converge upon a set of agreed-upon principles, or diverge, with significant disagreement over what constitutes 'ethical AI.' Our analysis finds a high degree of overlap among the sets of principles we analyze. We then identify an overarching framework consisting of five core principles for ethical AI. Four of them are core principles commonly used in bioethics: beneficence, non-maleficence, autonomy, and justice. On the basis of our comparative analysis, we argue that a new principle is needed in addition: explicability, understood as incorporating both the epistemological sense of intelligibility (as an answer to the question 'how does it work?') and in the ethical sense of accountability (as an answer to the question: 'who is responsible for the way it works?'). In the ensuing discussion, we note the limitations and assess the implications of this ethical framework for future efforts to create laws, rules, technical standards, and best practices for ethical AI in a wide range of contexts.",
    "doi": "10.1162/99608f92.8cd550d1",
    "url": "https://openalex.org/W2954266614",
    "pdf_url": "https://assets.pubpub.org/ukqte8ry/c8d3cba5-8f10-4a00-894c-3a3b886ad844.pdf",
    "venue": "Harvard Data Science Review",
    "citation_count": 868,
    "fields_of_study": [
      "Management science",
      "Epistemology",
      "Computer science",
      "Philosophy",
      "Engineering"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768681"
  },
  {
    "source": "openalex",
    "source_id": "W4383913712",
    "title": "Human resource management in the age of generative artificial intelligence: Perspectives and research directions on ChatGPT",
    "authors": [
      "Pawan Budhwar",
      "Soumyadeb Chowdhury",
      "Geoffrey Wood",
      "Herman Aguinis",
      "Greg J. Bamber",
      "Jose R. Beltran",
      "Paul Boselie",
      "Fang Lee Cooke",
      "Stephanie Decker",
      "Angelo S. DeNisi",
      "Prasanta Kumar Dey",
      "David Guest",
      "Andrew J. Knoblich",
      "Ashish Malik",
      "Jaap Paauwe",
      "Savvas Papagiannidis",
      "Charmi Patel",
      "Vijay Pereira",
      "Shuang Ren",
      "Steven G. Rogelberg",
      "Mark N. K. Saunders",
      "Rosalie L. Tung",
      "Arup Varma"
    ],
    "year": 2023,
    "abstract": "Abstract ChatGPT and its variants that use generative artificial intelligence (AI) models have rapidly become a focal point in academic and media discussions about their potential benefits and drawbacks across various sectors of the economy, democracy, society, and environment. It remains unclear whether these technologies result in job displacement or creation, or if they merely shift human labour by generating new, potentially trivial or practically irrelevant, information and decisions. According to the CEO of ChatGPT, the potential impact of this new family of AI technology could be as big as \u201cthe printing press\u201d, with significant implications for employment, stakeholder relationships, business models, and academic research, and its full consequences are largely undiscovered and uncertain. The introduction of more advanced and potent generative AI tools in the AI market, following the launch of ChatGPT, has ramped up the \u201cAI arms race\u201d, creating continuing uncertainty for workers, expanding their business applications, while heightening risks related to well\u2010being, bias, misinformation, context insensitivity, privacy issues, ethical dilemmas, and security. Given these developments, this perspectives editorial offers a collection of perspectives and research pathways to extend HRM scholarship in the realm of generative AI. In doing so, the discussion synthesizes the literature on AI and generative AI, connecting it to various aspects of HRM processes, practices, relationships, and outcomes, thereby contributing to shaping the future of HRM research.",
    "doi": "10.1111/1748-8583.12524",
    "url": "https://openalex.org/W4383913712",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/1748-8583.12524",
    "venue": "Human Resource Management Journal",
    "citation_count": 652,
    "fields_of_study": [
      "Generative grammar",
      "Context (archaeology)",
      "Stakeholder",
      "Scholarship",
      "Realm"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768719"
  },
  {
    "source": "openalex",
    "source_id": "W4389681782",
    "title": "Assessment of the bias of artificial intelligence generated images and large language models on their depiction of a surgeon",
    "authors": [
      "Jevan Cevik",
      "Bryan Lim",
      "Ishith Seth",
      "Foti Sofiadellis",
      "Richard J. Ross",
      "Roberto Cuomo",
      "Warren M. Rozen"
    ],
    "year": 2023,
    "abstract": "The increasing integration of artificial intelligence (AI) into domains like medicine, surgery, and research, has brought unparalleled advancements, and changed how doctors, particularly surgeons, are perceived.1-9 The advent of AI-generated images using generative adversarial networks (GANs) and increased reliance on large language models (LLMs), have raised concerns regarding biases. Bias in AI models can be gender, racial, or cultural, which pertain to the systematic and unfair preferences or discrimination of certain demographics in the behaviour and outcomes of AI systems. For instance, AI-generated images may disproportionately represent surgeons of a specific gender or race.10 These biases often originate from their training data.10 The consequences of such biases include skewed public perception, discrimination, and potential loss of trust in healthcare professionals and AI systems. Certain demographics may also find greater difficulty in entering certain specialities of medicine or attaining promotions due to unconscious bias against them. The investigation of biases in AI-generated images and descriptions, of surgeons, provides insights into potential inaccuracies and emphasizes the ethical implications of technology's role in shaping public opinion. Understanding these biases is critical for developing more equitable and accurate AI models, for educational, clinical, and public usage. This paper systematically analyses AI-generated images and descriptions from various GANs and LLMs to identify and characterize biases in the representation of surgeons. We discuss the underlying factors contributing to these biases, examine their impact on public perception, and propose mitigation strategies. Four generative AI tools, comprising two LLMs (ChatGPT-3.5 and BARD) and two GANs (Dall-E2 and Midjourney), were prompted to describe and illustrate characteristics of eight types of surgeons. Twenty-four descriptions and 64 images were extracted from them, which were then independently analysed by three reviewers (J.C., I.S., and B.L.) for presumed skin tone (Massey Martin NIS Skin Scale Score), age, gender, and Body Silhouette Scale Score.11, 12 Light and dark-skin-toned surgeons were classified with Massey scores of 1-2 and 3-10, respectively. Any discrepancies were discussed by all authors until consensus was achieved. No ethics had to be acquired as all data was generated by the AI tools. DALL-E2 generated 71.9% male and 28.1% female representations. They showed a balanced age representation: 43.8% depicted surgeons under 50 years, while 56.2% showed over 50. Furthermore, DALL-E2 has a balanced skin tone distribution with 50% being light-skinned, and 50% dark-skinned. Regarding Body Silhouette Scale Scores, 73.1% scored between 1 and 5, whereas 26.9% scored 6 or above (Table 1; Figs. 1-8). Midjourney displayed more biased results, producing 87.5% male and 12.5% female images. Based on the Massey Martin NIS Skin Scale Score, 100% of the surgeons were of skin scale scores of 1 or 2 which were categorized as light skin colours. Most surgeons appeared to be above 50 years of age (71.9%), more than DALL-E2's representation. Moreover, 96.4% had smaller body silhouettes between 1 and 5 on the Body Silhouette Scale (Table 1; Figs. 1-8). BARD stresses that no single trait defines a surgeon despite acknowledging a trend of white male surgeons in their 50s, often possessing sufficient strength to endure the physically demanding work. It then discusses exceptions, especially women of colour across different ages with varying personalities. BARD also underscores qualities like intellect, intrinsic motivation, and compassion as typically desirable attributes. While it occasionally provides detailed surgeon exemplars, it concludes its responses by reiterating the diversity of surgeons beyond stereotypes (Figs. 1-8). ChatGPT-3.5 recurrently highlights the inconsequentiality of physical attributes in determining a surgeon's proficiency, instead stressing their competence and compassion. Three of its replies allude to the typically upper age range of surgeons due to the long medical training they undertake. ChatGPT-3.5 occasionally describes the characteristics of a surgeon, narrating their behaviours and attitudes within and outside the professional milieu (Figs. 1-8). The LLMs demonstrated a nuanced understanding of surgeons' diverse backgrounds without significant bias, indicating their quality design and equitable training. In contrast, the AI-generated images of surgeons from the GANs demonstrated notable gender and skin-tone biases. While the current data indicates a male-dominated surgical population in Australia, it raises the question of whether AI should reflect these disparities or present a more equal representation.13 Failure to address the underlying inequalities could perpetuate bias, and conflating the current proportions with aspirational goals of diversity and inclusivity can complicate the issue. It is crucial to recognize this difference, assess these proportions and work towards a fairer and more equitable representation of surgeons, representing both current and desired realities. Ultimately, we argue that AI models should depict medical personnel such as surgeons in a more equitable manner. Dall-E2 evenly represented light and dark skin tones, whereas Midjourney exclusively depicted lighter skin tones. This indicates Dall-E2's training data or data processing maintains diversity, while Midjourney's outputs reveal a clear bias. Such a pattern in Midjourney raises questions about its training data and possible post-training adjustments. The marked underrepresentation of surgeons presumed to be female, in the results from both GANs, stands out as a significant issue. This disparity may not be a random occurrence but perhaps has roots due to historical bias. As a result, the GANs' outputs, presenting more male surgeons, may reflect past imbalances in gender demographics within medical education and practice. The reason GANs might produce more male surgeons when prompted to create a 'surgeon' image ties back to their foundational reliance on training data. These systems learn from vast datasets of images, and if the majority of 'surgeon' images in their training data are of men, the GANs will learn the bias that a 'typical' surgeon appears as a male. This learning process lacks an innate moral compass, so it mirrors and perpetuates existing biases in data. For instance, if in the past few decades, 80% of surgeons were male, the dataset will likely contain more images of male surgeons, teaching the GANs that 'surgeon' equates more often to a male figure. This problem underscores the importance of curating diverse and balanced training datasets and continuously updating them to reflect current realities and aspirations for equality. It also highlights the need for interventions in the training of these AI models, such as introducing algorithms to detect and mitigate bias or employing fairness criteria, ensuring that the outputs do not continue historical biases but instead represent a more equitable vision of society. The consequences of such biases are multiple.14 Misrepresentation in AI outputs can reinforce stereotypes, skew perceptions, delay promotions, lead to poorer evaluations, and even influence decision-making processes in real-world clinical settings.15, 16 For instance, if an AI system associates surgical expertise with a specific gender or ethnicity, it may inadvertently influence hiring decisions or patient trust. These biases can erode trust in healthcare systems, as patients may develop preferences for certain surgeons based on AI-generated information, which can affect a surgeon's reputation and career development. For decades, certain professions, including surgery, have been associated predominantly with specific genders or backgrounds.17, 18 Age bias can skew representation of certain age groups, whilst body silhouette bias can perpetuate detrimental beauty standards. In this study, Midjourney mainly demonstrated surgeons as older individuals with narrower body silhouettes. DALL-E2 demonstrated less bias in its depictions than Midjourney but such bias was also present. Bias can manifest at various stages of AI model development, often stemming from their training data which might reflect real-world prejudices and inadvertently perpetuate these notions in its outputs.19 For example, an AI image generator's dataset predominantly comprising lighter-skinned individuals might underrepresent darker skin tones. Understanding biases in AI is essential. AI GANs and LLMs are trained on pre-existing online data. If this data underrepresents a certain demographic, the output will likely be skewed.20-24 Despite using unbiased algorithms, research shows gender biases persist.25, 26 Another concern is 'Programmer Bias', where non-representative developer demographics might introduce biases into software.27 The 'Black Box' issue further complicates matters, as AI algorithms' inner workings are often hard to interpret.20, 28 Some AI tools lack real-time internet connectivity, risking outdated references and potential reporting bias, especially in fields like healthcare. Machine biases often echoes their human developers'. However, without clear datasets information, current AI findings are mostly speculative based on observed outputs. Several strategies can help address these biases. Firstly, using diverse and representative sample data, incorporating images and descriptions of surgeons from various genders, ethnicities, and backgrounds ensures a holistic view of the profession.29, 30 Another strategy is adopting a continuous feedback loop, allowing users and experts to flag potential biases and identify nuances that might have been overlooked during the model's development phase. Moreover, incorporating expert reviews can provide a depth of analysis that general feedback might not capture.29 Iterative model improvements are crucial. In the fast-evolving world of AI, a model that remains static is one that will inevitably become obsolete or problematic. By incorporating feedback and continuously refining the model, developers ensure that the AI system remains relevant, accurate, and free from perpetuating harmful stereotypes. In addition to these strategies, transparency in model development, methodologies, and data sources can also foster trust.29 When users understand the mechanisms behind the AI outputs, they can engage more critically and constructively, further enhancing the model's credibility and performance. The primary constraint of this study stems from its dependence on a limited group of plastic surgery residents and plastic surgeons to assess the biases inherent in the GANs. This narrow scope may impede the broader applicability of the findings, potentially infusing the results with subjectivity and individual biases. However, this research represents, to the authors' understanding, an initial endeavour in exploring the biased representations of different surgical specialties within GAN outputs. Subsequent studies would benefit from extending this scrutiny to biases present in other AI systems, thereby offering a more holistic understanding of these pervasive limitations. This study sheds light on the biases present in some of the latest popular AI models. As AI models continue to permeate the medical field, it becomes imperative to assess these biases rigorously. Only through collective and informed action can we ensure that AI serves as an equitable, effective, and reliable resource in advancing global healthcare. The broader scientific community should engage in ongoing discourse on defining acceptable bias thresholds and establishing standardized bias evaluation metrics. Open access publishing facilitated by Monash University, as part of the Wiley - Monash University agreement via the Council of Australian University Librarians. Jevan Cevik: Conceptualization; writing \u2013 original draft; writing \u2013 review and editing. Bryan Lim: Conceptualization; writing \u2013 original draft; writing \u2013 review and editing. Ishith Seth: Conceptualization; writing \u2013 original draft; writing \u2013 review and editing. Foti Sofiadellis: Conceptualization; supervision. Richard J. Ross: Conceptualization; supervision. Roberto Cuomo: Supervision. Warren M. Rozen: Conceptualization; supervision.",
    "doi": "10.1111/ans.18792",
    "url": "https://openalex.org/W4389681782",
    "pdf_url": "https://doi.org/10.1111/ans.18792",
    "venue": "ANZ Journal of Surgery",
    "citation_count": 29,
    "fields_of_study": [
      "Perception",
      "Generative grammar",
      "Artificial intelligence",
      "Demographics",
      "Psychology"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768739"
  },
  {
    "source": "openalex",
    "source_id": "W3041968715",
    "title": "Decolonial AI: Decolonial Theory as Sociotechnical Foresight in Artificial Intelligence",
    "authors": [
      "Shakir Mohamed",
      "Marie-Th\u00e9r\u00e8se Png",
      "William Isaac"
    ],
    "year": 2020,
    "abstract": null,
    "doi": "10.1007/s13347-020-00405-8",
    "url": "https://openalex.org/W3041968715",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s13347-020-00405-8.pdf",
    "venue": "Philosophy & Technology",
    "citation_count": 589,
    "fields_of_study": [
      "Futures studies",
      "Philosophy of technology",
      "Sociotechnical system",
      "Sociology",
      "Politics"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768907"
  },
  {
    "source": "openalex",
    "source_id": "W2099531439",
    "title": "How Technology Is Changing Work and Organizations",
    "authors": [
      "Wayne F. Cascio",
      "Ramiro Montealegre"
    ],
    "year": 2016,
    "abstract": "Given the rapid advances and the increased reliance on technology, the question of how it is changing work and employment is highly salient for scholars of organizational psychology and organizational behavior (OP/OB). This article attempts to interpret the progress, direction, and purpose of current research on the effects of technology on work and organizations. After a review of key breakthroughs in the evolution of technology, we consider the disruptive effects of emerging information and communication technologies. We then examine numbers and types of jobs affected by developments in technology, and how this will lead to significant worker dislocation. To illustrate technology's impact on work, work systems, and organizations, we present four popular technologies: electronic monitoring systems, robots, teleconferencing, and wearable computing devices. To provide insights regarding what we know about the effects of technology for OP/OB scholars, we consider the results of research conducted from four different perspectives on the role of technology in management. We also examine how that role is changing in the emerging world of technology. We conclude by considering approaches to six human resources (HR) areas supported by traditional and emerging technologies, identifying related research questions that should have profound implications both for research and for practice, and providing guidance for future research.",
    "doi": "10.1146/annurev-orgpsych-041015-062352",
    "url": "https://openalex.org/W2099531439",
    "pdf_url": "https://www.annualreviews.org/doi/pdf/10.1146/annurev-orgpsych-041015-062352",
    "venue": "Annual Review of Organizational Psychology and Organizational Behavior",
    "citation_count": 1030,
    "fields_of_study": [
      "Salient",
      "Work (physics)",
      "Emerging technologies",
      "Knowledge management",
      "Information technology"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768910"
  },
  {
    "source": "openalex",
    "source_id": "W4380685454",
    "title": "Re-Thinking Data Strategy and Integration for Artificial Intelligence: Concepts, Opportunities, and Challenges",
    "authors": [
      "Abdulaziz Aldoseri",
      "Khalifa N. Al\u2010Khalifa",
      "A.M.S. Hamouda"
    ],
    "year": 2023,
    "abstract": "The use of artificial intelligence (AI) is becoming more prevalent across industries such as healthcare, finance, and transportation. Artificial intelligence is based on the analysis of large datasets and requires a continuous supply of high-quality data. However, using data for AI is not without challenges. This paper comprehensively reviews and critically examines the challenges of using data for AI, including data quality, data volume, privacy and security, bias and fairness, interpretability and explainability, ethical concerns, and technical expertise and skills. This paper examines these challenges in detail and offers recommendations on how companies and organizations can address them. By understanding and addressing these challenges, organizations can harness the power of AI to make smarter decisions and gain competitive advantage in the digital age. It is expected, since this review article provides and discusses various strategies for data challenges for AI over the last decade, that it will be very helpful to the scientific research community to create new and novel ideas to rethink our approaches to data strategies for AI.",
    "doi": "10.3390/app13127082",
    "url": "https://openalex.org/W4380685454",
    "pdf_url": "https://www.mdpi.com/2076-3417/13/12/7082/pdf?version=1686659661",
    "venue": "Applied Sciences",
    "citation_count": 522,
    "fields_of_study": [
      "Interpretability",
      "Big data",
      "Computer science",
      "Quality (philosophy)",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768929"
  },
  {
    "source": "openalex",
    "source_id": "W4393353064",
    "title": "The Role of AI in Hospitals and Clinics: Transforming Healthcare in the 21st Century",
    "authors": [
      "Shiva Maleki Varnosfaderani",
      "Mohamad Forouzanfar"
    ],
    "year": 2024,
    "abstract": "As healthcare systems around the world face challenges such as escalating costs, limited access, and growing demand for personalized care, artificial intelligence (AI) is emerging as a key force for transformation. This review is motivated by the urgent need to harness AI\u2019s potential to mitigate these issues and aims to critically assess AI\u2019s integration in different healthcare domains. We explore how AI empowers clinical decision-making, optimizes hospital operation and management, refines medical image analysis, and revolutionizes patient care and monitoring through AI-powered wearables. Through several case studies, we review how AI has transformed specific healthcare domains and discuss the remaining challenges and possible solutions. Additionally, we will discuss methodologies for assessing AI healthcare solutions, ethical challenges of AI deployment, and the importance of data privacy and bias mitigation for responsible technology use. By presenting a critical assessment of AI\u2019s transformative potential, this review equips researchers with a deeper understanding of AI\u2019s current and future impact on healthcare. It encourages an interdisciplinary dialogue between researchers, clinicians, and technologists to navigate the complexities of AI implementation, fostering the development of AI-driven solutions that prioritize ethical standards, equity, and a patient-centered approach.",
    "doi": "10.3390/bioengineering11040337",
    "url": "https://openalex.org/W4393353064",
    "pdf_url": "https://www.mdpi.com/2306-5354/11/4/337/pdf?version=1711712822",
    "venue": "Bioengineering",
    "citation_count": 607,
    "fields_of_study": [
      "Health care",
      "Medicine",
      "Computer science",
      "Political science",
      "Law"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768945"
  },
  {
    "source": "openalex",
    "source_id": "W4362581834",
    "title": "Revolutionizing education with AI: Exploring the transformative potential of ChatGPT",
    "authors": [
      "Tufan Ad\u0131g\u00fczel",
      "Mehmet Haldun Kaya",
      "Fatih K\u00fcr\u015fat Cansu"
    ],
    "year": 2023,
    "abstract": "Artificial intelligence (AI) introduces new tools to the educational environment with the potential to transform conventional teaching and learning processes. This study offers a comprehensive overview of AI technologies, their potential applications in education, and the difficulties involved. Chatbots and related algorithms that can simulate human interactions and generate human-like text based on input from natural language are discussed. In addition to the advantages of cutting-edge chatbots like ChatGPT, their use in education raises important ethical and practical challenges. The authors aim to provide insightful information on how AI may be successfully incorporated into the educational setting to benefit teachers and students, while promoting responsible and ethical use.",
    "doi": "10.30935/cedtech/13152",
    "url": "https://openalex.org/W4362581834",
    "pdf_url": "https://www.cedtech.net/download/revolutionizing-education-with-ai-exploring-the-transformative-potential-of-chatgpt-13152.pdf",
    "venue": "Contemporary Educational Technology",
    "citation_count": 755,
    "fields_of_study": [
      "Transformative learning",
      "Computer science",
      "Artificial intelligence",
      "Psychology",
      "Pedagogy"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768962"
  },
  {
    "source": "openalex",
    "source_id": "W3090117266",
    "title": "Trustworthy artificial intelligence",
    "authors": [
      "Scott Thiebes",
      "Sebastian Lins",
      "Ali Sunyaev"
    ],
    "year": 2020,
    "abstract": null,
    "doi": "10.1007/s12525-020-00441-4",
    "url": "https://openalex.org/W3090117266",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s12525-020-00441-4.pdf",
    "venue": "Electronic Markets",
    "citation_count": 505,
    "fields_of_study": [
      "Beneficence",
      "Variety (cybernetics)",
      "Autonomy",
      "Software deployment",
      "Economic Justice"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768977"
  },
  {
    "source": "openalex",
    "source_id": "W4386098991",
    "title": "Challenges and Opportunities of Generative AI for Higher Education as Explained by ChatGPT",
    "authors": [
      "Rosario Michel\u2010Villarreal",
      "Eliseo Luis Vilalta-perdomo",
      "David Ernesto Salinas-Navarro",
      "Ricardo Thierry-Aguilera",
      "Flor Silvestre Gerardou"
    ],
    "year": 2023,
    "abstract": "ChatGPT is revolutionizing the field of higher education by leveraging deep learning models to generate human-like content. However, its integration into academic settings raises concerns regarding academic integrity, plagiarism detection, and the potential impact on critical thinking skills. This article presents a study that adopts a thing ethnography approach to understand ChatGPT\u2019s perspective on the challenges and opportunities it represents for higher education. The research explores the potential benefits and limitations of ChatGPT, as well as mitigation strategies for addressing the identified challenges. Findings emphasize the urgent need for clear policies, guidelines, and frameworks to responsibly integrate ChatGPT in higher education. It also highlights the need for empirical research to understand user experiences and perceptions. The findings provide insights that can guide future research efforts in understanding the implications of ChatGPT and similar Artificial Intelligence (AI) systems in higher education. The study concludes by highlighting the importance of thing ethnography as an innovative approach for engaging with intelligent AI systems and calls for further research to explore best practices and strategies in utilizing Generative AI for educational purposes.",
    "doi": "10.3390/educsci13090856",
    "url": "https://openalex.org/W4386098991",
    "pdf_url": "https://www.mdpi.com/2227-7102/13/9/856/pdf?version=1692771591",
    "venue": "Education Sciences",
    "citation_count": 633,
    "fields_of_study": [
      "Generative grammar",
      "Engineering ethics",
      "Perspective (graphical)",
      "Higher education",
      "Field (mathematics)"
    ],
    "retrieved_at": "2026-02-02T16:58:10.768980"
  },
  {
    "source": "openalex",
    "source_id": "W4385632485",
    "title": "Practical and ethical challenges of large language models in education: A systematic scoping review",
    "authors": [
      "Lixiang Yan",
      "Lele Sha",
      "Linxuan Zhao",
      "Yuheng Li",
      "Roberto Mart\u00ednez\u2010Maldonado",
      "Guanliang Chen",
      "Xinyu Li",
      "Yueqiao Jin",
      "Dragan Ga\u0161evi\u0107"
    ],
    "year": 2023,
    "abstract": "Abstract Educational technology innovations leveraging large language models (LLMs) have shown the potential to automate the laborious process of generating and analysing textual content. While various innovations have been developed to automate a range of educational tasks (eg, question generation, feedback provision, and essay grading), there are concerns regarding the practicality and ethicality of these innovations. Such concerns may hinder future research and the adoption of LLMs\u2010based innovations in authentic educational contexts. To address this, we conducted a systematic scoping review of 118 peer\u2010reviewed papers published since 2017 to pinpoint the current state of research on using LLMs to automate and support educational tasks. The findings revealed 53 use cases for LLMs in automating education tasks, categorised into nine main categories: profiling/labelling, detection, grading, teaching support, prediction, knowledge representation, feedback, content generation, and recommendation. Additionally, we also identified several practical and ethical challenges, including low technological readiness, lack of replicability and transparency and insufficient privacy and beneficence considerations. The findings were summarised into three recommendations for future studies, including updating existing innovations with state\u2010of\u2010the\u2010art models (eg, GPT\u20103/4), embracing the initiative of open\u2010sourcing models/systems, and adopting a human\u2010centred approach throughout the developmental process. As the intersection of AI and education is continuously evolving, the findings of this study can serve as an essential reference point for researchers, allowing them to leverage the strengths, learn from the limitations, and uncover potential research opportunities enabled by ChatGPT and other generative AI models. Practitioner notes What is currently known about this topic Generating and analysing text\u2010based content are time\u2010consuming and laborious tasks. Large language models are capable of efficiently analysing an unprecedented amount of textual content and completing complex natural language processing and generation tasks. Large language models have been increasingly used to develop educational technologies that aim to automate the generation and analysis of textual content, such as automated question generation and essay scoring. What this paper adds A comprehensive list of different educational tasks that could potentially benefit from LLMs\u2010based innovations through automation. A structured assessment of the practicality and ethicality of existing LLMs\u2010based innovations from seven important aspects using established frameworks. Three recommendations that could potentially support future studies to develop LLMs\u2010based innovations that are practical and ethical to implement in authentic educational contexts. Implications for practice and/or policy Updating existing innovations with state\u2010of\u2010the\u2010art models may further reduce the amount of manual effort required for adapting existing models to different educational tasks. The reporting standards of empirical research that aims to develop educational technologies using large language models need to be improved. Adopting a human\u2010centred approach throughout the developmental process could contribute to resolving the practical and ethical challenges of large language models in education.",
    "doi": "10.1111/bjet.13370",
    "url": "https://openalex.org/W4385632485",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/bjet.13370",
    "venue": "British Journal of Educational Technology",
    "citation_count": 523,
    "fields_of_study": [
      "Computer science",
      "Grading (engineering)",
      "Systematic review",
      "Engineering ethics",
      "Knowledge management"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769002"
  },
  {
    "source": "openalex",
    "source_id": "W3131457744",
    "title": "What do we want from Explainable Artificial Intelligence (XAI)? \u2013 A stakeholder perspective on XAI and a conceptual model guiding interdisciplinary XAI research",
    "authors": [
      "Markus Langer",
      "Daniel Oster",
      "Timo Speith",
      "Holger Hermanns",
      "Lena K\u00e4stner",
      "Eva Schmidt",
      "Andreas Sesing-Wagenpfeil",
      "Kevin Baum"
    ],
    "year": 2021,
    "abstract": null,
    "doi": "10.1016/j.artint.2021.103473",
    "url": "https://openalex.org/W3131457744",
    "pdf_url": "https://www.sciencedirect.com/science/article/pii/S0004370221000242",
    "venue": "Artificial Intelligence",
    "citation_count": 524,
    "fields_of_study": [
      "Perspective (graphical)",
      "Stakeholder",
      "Knowledge management",
      "Management science",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769043"
  },
  {
    "source": "openalex",
    "source_id": "W4381982883",
    "title": "ChatGPT for Education and Research: Opportunities, Threats, and Strategies",
    "authors": [
      "Md. Mostafizer Rahman",
      "Yutaka Watanobe"
    ],
    "year": 2023,
    "abstract": "In recent years, the rise of advanced artificial intelligence technologies has had a profound impact on many fields, including education and research. One such technology is ChatGPT, a powerful large language model developed by OpenAI. This technology offers exciting opportunities for students and educators, including personalized feedback, increased accessibility, interactive conversations, lesson preparation, evaluation, and new ways to teach complex concepts. However, ChatGPT poses different threats to the traditional education and research system, including the possibility of cheating on online exams, human-like text generation, diminished critical thinking skills, and difficulties in evaluating information generated by ChatGPT. This study explores the potential opportunities and threats that ChatGPT poses to overall education from the perspective of students and educators. Furthermore, for programming learning, we explore how ChatGPT helps students improve their programming skills. To demonstrate this, we conducted different coding-related experiments with ChatGPT, including code generation from problem descriptions, pseudocode generation of algorithms from texts, and code correction. The generated codes are validated with an online judge system to evaluate their accuracy. In addition, we conducted several surveys with students and teachers to find out how ChatGPT supports programming learning and teaching. Finally, we present the survey results and analysis.",
    "doi": "10.3390/app13095783",
    "url": "https://openalex.org/W4381982883",
    "pdf_url": "https://www.mdpi.com/2076-3417/13/9/5783/pdf?version=1683532719",
    "venue": "Applied Sciences",
    "citation_count": 820,
    "fields_of_study": [
      "Cheating",
      "Computer science",
      "Coding (social sciences)",
      "Perspective (graphical)",
      "Mathematics education"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769045"
  },
  {
    "source": "openalex",
    "source_id": "W3172362366",
    "title": "Current Challenges and Future Opportunities for XAI in Machine Learning-Based Clinical Decision Support Systems: A Systematic Review",
    "authors": [
      "Anna Markella Antoniadi",
      "Yuhan Du",
      "Yasmine Guendouz",
      "Lan Wei",
      "Claudia Mazo",
      "Brett A. Becker",
      "Catherine Mooney"
    ],
    "year": 2021,
    "abstract": "Machine Learning and Artificial Intelligence (AI) more broadly have great immediate and future potential for transforming almost all aspects of medicine. However, in many applications, even outside medicine, a lack of transparency in AI applications has become increasingly problematic. This is particularly pronounced where users need to interpret the output of AI systems. Explainable AI (XAI) provides a rationale that allows users to understand why a system has produced a given output. The output can then be interpreted within a given context. One area that is in great need of XAI is that of Clinical Decision Support Systems (CDSSs). These systems support medical practitioners in their clinic decision-making and in the absence of explainability may lead to issues of under or over-reliance. Providing explanations for how recommendations are arrived at will allow practitioners to make more nuanced, and in some cases, life-saving decisions. The need for XAI in CDSS, and the medical field in general, is amplified by the need for ethical and fair decision-making and the fact that AI trained with historical data can be a reinforcement agent of historical actions and biases that should be uncovered. We performed a systematic literature review of work to-date in the application of XAI in CDSS. Tabular data processing XAI-enabled systems are the most common, while XAI-enabled CDSS for text analysis are the least common in literature. There is more interest in developers for the provision of local explanations, while there was almost a balance between post-hoc and ante-hoc explanations, as well as between model-specific and model-agnostic techniques. Studies reported benefits of the use of XAI such as the fact that it could enhance decision confidence for clinicians, or generate the hypothesis about causality, which ultimately leads to increased trustworthiness and acceptability of the system and potential for its incorporation in the clinical workflow. However, we found an overall distinct lack of application of XAI in the context of CDSS and, in particular, a lack of user studies exploring the needs of clinicians. We propose some guidelines for the implementation of XAI in CDSS and explore some opportunities, challenges, and future research needs.",
    "doi": "10.3390/app11115088",
    "url": "https://openalex.org/W3172362366",
    "pdf_url": "https://www.mdpi.com/2076-3417/11/11/5088/pdf?version=1622439587",
    "venue": "Applied Sciences",
    "citation_count": 525,
    "fields_of_study": [
      "Transparency (behavior)",
      "Computer science",
      "Context (archaeology)",
      "Clinical decision support system",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769064"
  },
  {
    "source": "openalex",
    "source_id": "W4381716616",
    "title": "Bias in artificial intelligence algorithms and recommendations for mitigation",
    "authors": [
      "Lama Nazer",
      "Razan Zatarah",
      "Shai Waldrip",
      "Janny Xue Chen Ke",
      "Mira Moukheiber",
      "Ashish K. Khanna",
      "Rachel Hicklen",
      "Lama Moukheiber",
      "Dana Moukheiber",
      "Haobo Ma",
      "Piyush Mathur"
    ],
    "year": 2023,
    "abstract": "The adoption of artificial intelligence (AI) algorithms is rapidly increasing in healthcare. Such algorithms may be shaped by various factors such as social determinants of health that can influence health outcomes. While AI algorithms have been proposed as a tool to expand the reach of quality healthcare to underserved communities and improve health equity, recent literature has raised concerns about the propagation of biases and healthcare disparities through implementation of these algorithms. Thus, it is critical to understand the sources of bias inherent in AI-based algorithms. This review aims to highlight the potential sources of bias within each step of developing AI algorithms in healthcare, starting from framing the problem, data collection, preprocessing, development, and validation, as well as their full implementation. For each of these steps, we also discuss strategies to mitigate the bias and disparities. A checklist was developed with recommendations for reducing bias during the development and implementation stages. It is important for developers and users of AI-based algorithms to keep these important considerations in mind to advance health equity for all populations.",
    "doi": "10.1371/journal.pdig.0000278",
    "url": "https://openalex.org/W4381716616",
    "pdf_url": "https://journals.plos.org/digitalhealth/article/file?id=10.1371/journal.pdig.0000278&type=printable",
    "venue": "PLOS Digital Health",
    "citation_count": 468,
    "fields_of_study": [
      "Health care",
      "Computer science",
      "Preprocessor",
      "Artificial intelligence",
      "Data science"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769101"
  },
  {
    "source": "openalex",
    "source_id": "W4221045317",
    "title": "Towards a standard for identifying and managing bias in artificial intelligence",
    "authors": [
      "Reva Schwartz",
      "Apostol Vassilev",
      "Kristen Greene",
      "Lori Perine",
      "Andrew Burt",
      "Patrick Hall"
    ],
    "year": 2022,
    "abstract": "As individuals and communities interact in and with an environment that is increasingly virtual they are often vulnerable to the commodification of their digital exhaust. Concepts and behavior that are ambiguous in nature are captured in this environment, quantified, and used to categorize, sort, recommend, or make decisions about people's lives. While many organizations seek to utilize this information in a responsible manner, biases remain endemic across technology processes and can lead to harmful impacts regardless of intent. These harmful outcomes, even if inadvertent, create significant challenges for cultivating public trust in artificial intelligence (AI). SP 1270 is a NIST Artificial Intelligence publication and should be read in conjunction with all publications in the NIST AI Series, which was established in January 2023.",
    "doi": "10.6028/nist.sp.1270",
    "url": "https://openalex.org/W4221045317",
    "pdf_url": "https://doi.org/10.6028/nist.sp.1270",
    "venue": null,
    "citation_count": 455,
    "fields_of_study": [
      "Categorization",
      "NIST",
      "sort",
      "Computer science",
      "Data science"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769121"
  },
  {
    "source": "openalex",
    "source_id": "W4385484319",
    "title": "A multilevel review of artificial intelligence in organizations: Implications for organizational behavior research and practice",
    "authors": [
      "Sarah Bankins",
      "Anna Carmella Ocampo",
      "Mauricio Marrone",
      "Simon Lloyd D. Restubog",
      "Sang Eun Woo"
    ],
    "year": 2023,
    "abstract": "Summary The rising use of artificially intelligent (AI) technologies, including generative AI tools, in organizations is undeniable. As these systems become increasingly integrated into organizational practices and processes, understanding their impact on workers' experiences and job designs is critical. However, the ongoing discourse surrounding AI use in the workplace remains divided. Proponents of the technology extol its benefits for enhancing efficiency and productivity, while others voice concerns about the potential harm to human workers. To provide greater clarity on this pressing issue, this article presents a systematic review of empirical research that sheds light on the implications of AI use at work. Organized under five inductively generated themes within a multilevel framework, we uncover individual, group, and organizational factors that shape the interplay between humans and AI. Specifically, the themes are: (1) human\u2013AI collaboration; (2) perceptions of algorithmic and human capabilities; (3) worker attitudes towards AI; (4) AI as a control mechanism in algorithmic management of platform\u2010based work; and (5) labor market implications of AI use. Our review offers insights into these themes and identifies five pathways for future research. Finally, we provide practical recommendations for organizational leaders seeking to implement AI technologies while prioritizing their employees' well\u2010being.",
    "doi": "10.1002/job.2735",
    "url": "https://openalex.org/W4385484319",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/job.2735",
    "venue": "Journal of Organizational Behavior",
    "citation_count": 391,
    "fields_of_study": [
      "CLARITY",
      "Knowledge management",
      "Generative grammar",
      "Harm",
      "Perception"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769134"
  },
  {
    "source": "openalex",
    "source_id": "W3104128335",
    "title": "Challenges in Deploying Machine Learning: A Survey of Case Studies",
    "authors": [
      "Andrei Paleyes",
      "Raoul-Gabriel Urma",
      "Neil D. Lawrence"
    ],
    "year": 2022,
    "abstract": "In recent years, machine learning has transitioned from a field of academic research interest to a field capable of solving real-world business problems. However, the deployment of machine learning models in production systems can present a number of issues and concerns. This survey reviews published reports of deploying machine learning solutions in a variety of use cases, industries, and applications and extracts practical considerations corresponding to stages of the machine learning deployment workflow. By mapping found challenges to the steps of the machine learning deployment workflow, we show that practitioners face issues at each stage of the deployment process. The goal of this article is to lay out a research agenda to explore approaches addressing these challenges.",
    "doi": "10.1145/3533378",
    "url": "https://openalex.org/W3104128335",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3533378",
    "venue": "ACM Computing Surveys",
    "citation_count": 487,
    "fields_of_study": [
      "Software deployment",
      "Workflow",
      "Computer science",
      "Artificial intelligence",
      "Machine learning"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769153"
  },
  {
    "source": "openalex",
    "source_id": "W4383959108",
    "title": "The dark side of generative artificial intelligence: A critical analysis of controversies and risks of ChatGPT",
    "authors": [
      "Krzysztof Wach",
      "Cong Doanh Duong",
      "Joanna Ejdys",
      "R\u016bta Kazlauskait\u0117",
      "Pawe\u0142 Korzy\u0144ski",
      "Grzegorz Mazurek",
      "Joanna Paliszkiewicz",
      "Ewa Ziemba"
    ],
    "year": 2023,
    "abstract": "Objective: The objective of the article is to provide a comprehensive identification and understanding of the challenges and opportunities associated with the use of generative artificial intelligence (GAI) in business. This study sought to develop a conceptual framework that gathers the negative aspects of GAI development in management and economics, with a focus on ChatGPT. Research Design & Methods: The study employed a narrative and critical literature review and developed a conceptual framework based on prior literature. We used a line of deductive reasoning in formulating our theoretical framework to make the study's overall structure rational and productive. Therefore, this article should be viewed as a conceptual article that highlights the controversies and threats of GAI in management and economics, with ChatGPT as a case study. Findings: Based on the conducted deep and extensive query of academic literature on the subject as well as professional press and Internet portals, we identified various controversies, threats, defects, and disadvantages of GAI, in particular ChatGPT. Next, we grouped the identified threats into clusters to summarize the seven main threats we see. In our opinion they are as follows: (i) no regulation of the AI market and urgent need for regulation, (ii) poor quality, lack of quality control, disinformation, deepfake content, algorithmic bias, (iii) automation-spurred job losses, (iv) personal data violation, social surveillance, and privacy violation, (v) social manipulation, weakening ethics and goodwill, (vi) widening socio-economic inequalities, and (vii) AI technostress. Implications & Recommendations: It is important to regulate the AI/GAI market. Advocating for the regulation of the AI market is crucial to ensure a level playing field, promote fair competition, protect intellectual property rights and privacy, and prevent potential geopolitical risks. The changing job market requires workers to continuously acquire new (digital) skills through education and retraining. As the training of AI systems becomes a prominent job category, it is important to adapt and take advantage of new opportunities. To mitigate the risks related to personal data violation, social surveillance, and privacy violation, GAI developers must prioritize ethical considerations and work to develop systems that prioritize user privacy and security. To avoid social manipulation and weaken ethics and goodwill, it is important to implement responsible AI practices and ethical guidelines: transparency in data usage, bias mitigation techniques, and monitoring of generated content for harmful or misleading information. Contribution & Value Added: This article may aid in bringing attention to the significance of resolving the ethical and legal considerations that arise from the use of GAI and ChatGPT by drawing attention to the controversies and hazards associated with these technologies.",
    "doi": "10.15678/eber.2023.110201",
    "url": "https://openalex.org/W4383959108",
    "pdf_url": "https://eber.uek.krakow.pl/index.php/eber/article/view/2113/852",
    "venue": "Entrepreneurial Business and Economics Review",
    "citation_count": 438,
    "fields_of_study": [
      "Great Rift",
      "Generative grammar",
      "Psychology",
      "Artificial intelligence",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769165"
  },
  {
    "source": "openalex",
    "source_id": "W4385564466",
    "title": "Fairness of artificial intelligence in healthcare: review and recommendations",
    "authors": [
      "Daiju Ueda",
      "Taichi Kakinuma",
      "Shohei Fujita",
      "Koji Kamagata",
      "Yasutaka Fushimi",
      "Rintaro Ito",
      "Yusuke Matsui",
      "Taiki Nozaki",
      "Takeshi Nakaura",
      "Noriyuki Fujima",
      "Fuminari Tatsugami",
      "Masahiro Yanagawa",
      "Kenji Hirata",
      "Akira Yamada",
      "Takahiro Tsuboyama",
      "Mariko Kawamura",
      "Tomoyuki Fujioka",
      "Shinji Naganawa"
    ],
    "year": 2023,
    "abstract": "Abstract In this review, we address the issue of fairness in the clinical integration of artificial intelligence (AI) in the medical field. As the clinical adoption of deep learning algorithms, a subfield of AI, progresses, concerns have arisen regarding the impact of AI biases and discrimination on patient health. This review aims to provide a comprehensive overview of concerns associated with AI fairness; discuss strategies to mitigate AI biases; and emphasize the need for cooperation among physicians, AI researchers, AI developers, policymakers, and patients to ensure equitable AI integration. First, we define and introduce the concept of fairness in AI applications in healthcare and radiology, emphasizing the benefits and challenges of incorporating AI into clinical practice. Next, we delve into concerns regarding fairness in healthcare, addressing the various causes of biases in AI and potential concerns such as misdiagnosis, unequal access to treatment, and ethical considerations. We then outline strategies for addressing fairness, such as the importance of diverse and representative data and algorithm audits. Additionally, we discuss ethical and legal considerations such as data privacy, responsibility, accountability, transparency, and explainability in AI. Finally, we present the Fairness of Artificial Intelligence Recommendations in healthcare (FAIR) statement to offer best practices. Through these efforts, we aim to provide a foundation for discussing the responsible and equitable implementation and deployment of AI in healthcare.",
    "doi": "10.1007/s11604-023-01474-3",
    "url": "https://openalex.org/W4385564466",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s11604-023-01474-3.pdf",
    "venue": "Japanese Journal of Radiology",
    "citation_count": 430,
    "fields_of_study": [
      "Accountability",
      "Health care",
      "Transparency (behavior)",
      "Computer science",
      "Software deployment"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769204"
  },
  {
    "source": "openalex",
    "source_id": "W4233435953",
    "title": "The ARRIVE guidelines 2.0: Updated guidelines for reporting animal research",
    "authors": [
      "Nathalie Percie du Sert",
      "Viki Hurst",
      "Amrita Ahluwalia",
      "Sabina Alam",
      "Marc T. Avey",
      "Monya Baker",
      "William J. Browne",
      "Alejandra Clark",
      "Innes C. Cuthill",
      "Ulrich Dirnagl",
      "Michael Emerson",
      "Paul Garner",
      "Stephen T. Holgate",
      "David W. Howells",
      "Natasha A. Karp",
      "Stanley E. Lazic",
      "Katie Lidster",
      "Catriona MacCallum",
      "Malcolm Macleod",
      "Esther J. Pearl",
      "Ole H. Petersen",
      "Frances Rawle",
      "Penny S. Reynolds",
      "Kieron Rooney",
      "Emily S. Sena",
      "Shai D. Silberberg",
      "Thomas Steckler",
      "Hanno W\u00fcrbel"
    ],
    "year": 2020,
    "abstract": "Reproducible science requires transparent reporting. The ARRIVE guidelines (Animal Research: Reporting of In Vivo Experiments) were originally developed in 2010 to improve the reporting of animal research. They consist of a checklist of information to include in publications describing in vivo experiments to enable others to scrutinise the work adequately, evaluate its methodological rigour, and reproduce the methods and results. Despite considerable levels of endorsement by funders and journals over the years, adherence to the guidelines has been inconsistent, and the anticipated improvements in the quality of reporting in animal research publications have not been achieved. Here, we introduce ARRIVE 2.0. The guidelines have been updated and information reorganised to facilitate their use in practice. We used a Delphi exercise to prioritise and divide the items of the guidelines into 2 sets, the \u201cARRIVE Essential 10,\u201d which constitutes the minimum requirement, and the \u201cRecommended Set,\u201d which describes the research context. This division facilitates improved reporting of animal research by supporting a stepwise approach to implementation. This helps journal editors and reviewers verify that the most important items are being reported in manuscripts. We have also developed the accompanying Explanation and Elaboration (E&amp;E) document, which serves (1) to explain the rationale behind each item in the guidelines, (2) to clarify key concepts, and (3) to provide illustrative examples. We aim, through these changes, to help ensure that researchers, reviewers, and journal editors are better equipped to improve the rigour and transparency of the scientific process and thus reproducibility.",
    "doi": "10.1111/bph.15193",
    "url": "https://openalex.org/W4233435953",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/bph.15193",
    "venue": "British Journal of Pharmacology",
    "citation_count": 884,
    "fields_of_study": [
      "Rigour",
      "Checklist",
      "Context (archaeology)",
      "Transparency (behavior)",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769225"
  },
  {
    "source": "openalex",
    "source_id": "W4223430324",
    "title": "Machine learning for medical imaging: methodological failures and recommendations for the future",
    "authors": [
      "Ga\u00ebl Varoquaux",
      "Veronika Cheplygina"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1038/s41746-022-00592-y",
    "url": "https://openalex.org/W4223430324",
    "pdf_url": "https://www.nature.com/articles/s41746-022-00592-y.pdf",
    "venue": "npj Digital Medicine",
    "citation_count": 524,
    "fields_of_study": [
      "Medical imaging",
      "Psychology",
      "Computer science",
      "Data science",
      "Engineering ethics"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769248"
  },
  {
    "source": "openalex",
    "source_id": "W2786242872",
    "title": "Fairness and Accountability Design Needs for Algorithmic Support in High-Stakes Public Sector Decision-Making",
    "authors": [
      "Michael Veale",
      "Max Van Kleek",
      "Reuben Binns"
    ],
    "year": 2018,
    "abstract": "Calls for heightened consideration of fairness and accountability in\\nalgorithmically-informed public decisions---like taxation, justice, and child\\nprotection---are now commonplace. How might designers support such human\\nvalues? We interviewed 27 public sector machine learning practitioners across 5\\nOECD countries regarding challenges understanding and imbuing public values\\ninto their work. The results suggest a disconnect between organisational and\\ninstitutional realities, constraints and needs, and those addressed by current\\nresearch into usable, transparent and 'discrimination-aware' machine\\nlearning---absences likely to undermine practical initiatives unless addressed.\\nWe see design opportunities in this disconnect, such as in supporting the\\ntracking of concept drift in secondary data sources, and in building usable\\ntransparency tools to identify risks and incorporate domain knowledge, aimed\\nboth at managers and at the 'street-level bureaucrats' on the frontlines of\\npublic service. We conclude by outlining ethical challenges and future\\ndirections for collaboration in these high-stakes applications.\\n",
    "doi": "10.1145/3173574.3174014",
    "url": "https://openalex.org/W2786242872",
    "pdf_url": "http://dl.acm.org/ft_gateway.cfm?id=3174014&type=pdf",
    "venue": null,
    "citation_count": 418,
    "fields_of_study": [
      "Accountability",
      "USable",
      "Transparency (behavior)",
      "Public sector",
      "Public relations"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769251"
  },
  {
    "source": "openalex",
    "source_id": "W4392773210",
    "title": "Embracing the future of Artificial Intelligence in the classroom: the relevance of AI literacy, prompt engineering, and critical thinking in modern education",
    "authors": [
      "Yoshija Walter"
    ],
    "year": 2024,
    "abstract": "Abstract The present discussion examines the transformative impact of Artificial Intelligence (AI) in educational settings, focusing on the necessity for AI literacy, prompt engineering proficiency, and enhanced critical thinking skills. The introduction of AI into education marks a significant departure from conventional teaching methods, offering personalized learning and support for diverse educational requirements, including students with special needs. However, this integration presents challenges, including the need for comprehensive educator training and curriculum adaptation to align with societal structures. AI literacy is identified as crucial, encompassing an understanding of AI technologies and their broader societal impacts. Prompt engineering is highlighted as a key skill for eliciting specific responses from AI systems, thereby enriching educational experiences and promoting critical thinking. There is detailed analysis of strategies for embedding these skills within educational curricula and pedagogical practices. This is discussed through a case-study based on a Swiss university and a narrative literature review, followed by practical suggestions of how to implement AI in the classroom.",
    "doi": "10.1186/s41239-024-00448-3",
    "url": "https://openalex.org/W4392773210",
    "pdf_url": "https://educationaltechnologyjournal.springeropen.com/counter/pdf/10.1186/s41239-024-00448-3",
    "venue": "International Journal of Educational Technology in Higher Education",
    "citation_count": 576,
    "fields_of_study": [
      "Relevance (law)",
      "Critical thinking",
      "Literacy",
      "Higher education",
      "Mathematics education"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769264"
  },
  {
    "source": "openalex",
    "source_id": "W4386285839",
    "title": "Managing the Strategic Transformation of Higher Education through Artificial Intelligence",
    "authors": [
      "Babu George",
      "Ontario S. Wooden"
    ],
    "year": 2023,
    "abstract": "Considering the rapid advancements in artificial intelligence (AI) and their potential implications for the higher education sector, this article seeks to critically evaluate the strategic adoption of AI in the framework of \u201csmart universities\u201d. We envisage these innovative institutions as the imminent evolution in higher education, harnessing AI and quantum technologies to reshape academic and administrative processes. The core presumption is that through such integration, universities can achieve personalized learning trajectories, enhanced accessibility, economic efficiency, and a boost in overall operational performance. However, venturing into this new educational paradigm necessitates a thorough exploration of potential pitfalls, including questions surrounding educational quality, potential job losses, risks of bias, privacy breaches, and safety concerns. Our primary objective is to offer a balanced assessment to aid stakeholders in making informed strategic decisions about endorsing and advancing the smart university model. A pivotal factor in this discourse is the acceptance of qualifications from AI-enriched institutions by employers, a variable that may drastically redefine the education sector\u2019s trajectory. Within the context of a comprehensive analysis of its broader societal impact, this article also delves into the ramifications of AI-driven innovations for historically Black colleges and universities (HBCUs).",
    "doi": "10.3390/admsci13090196",
    "url": "https://openalex.org/W4386285839",
    "pdf_url": "https://www.mdpi.com/2076-3387/13/9/196/pdf?version=1693319334",
    "venue": "Administrative Sciences",
    "citation_count": 380,
    "fields_of_study": [
      "Presumption",
      "Context (archaeology)",
      "Higher education",
      "Strategic intelligence",
      "Quality (philosophy)"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769279"
  },
  {
    "source": "openalex",
    "source_id": "W4390829176",
    "title": "Balancing Privacy and Progress: A Review of Privacy Challenges, Systemic Oversight, and Patient Perceptions in AI-Driven Healthcare",
    "authors": [
      "S. Williamson",
      "Victor R. Prybutok"
    ],
    "year": 2024,
    "abstract": "Integrating Artificial Intelligence (AI) in healthcare represents a transformative shift with substantial potential for enhancing patient care. This paper critically examines this integration, confronting significant ethical, legal, and technological challenges, particularly in patient privacy, decision-making autonomy, and data integrity. A structured exploration of these issues focuses on Differential Privacy as a critical method for preserving patient confidentiality in AI-driven healthcare systems. We analyze the balance between privacy preservation and the practical utility of healthcare data, emphasizing the effectiveness of encryption, Differential Privacy, and mixed-model approaches. The paper navigates the complex ethical and legal frameworks essential for AI integration in healthcare. We comprehensively examine patient rights and the nuances of informed consent, along with the challenges of harmonizing advanced technologies like blockchain with the General Data Protection Regulation (GDPR). The issue of algorithmic bias in healthcare is also explored, underscoring the urgent need for effective bias detection and mitigation strategies to build patient trust. The evolving roles of decentralized data sharing, regulatory frameworks, and patient agency are discussed in depth. Advocating for an interdisciplinary, multi-stakeholder approach and responsive governance, the paper aims to align healthcare AI with ethical principles, prioritize patient-centered outcomes, and steer AI towards responsible and equitable enhancements in patient care.",
    "doi": "10.3390/app14020675",
    "url": "https://openalex.org/W4390829176",
    "pdf_url": "https://www.mdpi.com/2076-3417/14/2/675/pdf?version=1705396255",
    "venue": "Applied Sciences",
    "citation_count": 390,
    "fields_of_study": [
      "Health care",
      "Autonomy",
      "Confidentiality",
      "Transformative learning",
      "Information privacy"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769298"
  },
  {
    "source": "openalex",
    "source_id": "W4283170666",
    "title": "Taxonomy of Risks posed by Language Models",
    "authors": [
      "Laura Weidinger",
      "Jonathan Uesato",
      "Maribeth Rauh",
      "Conor Griffin",
      "Po-Sen Huang",
      "John Mellor",
      "Amelia Glaese",
      "Myra Cheng",
      "Borja Balle",
      "Atoosa Kasirzadeh",
      "Courtney Biles",
      "Sasha Brown",
      "Zac Kenton",
      "Will Hawkins",
      "Tom Stepleton",
      "Abeba Birhane",
      "Lisa Anne Hendricks",
      "Laura Rimell",
      "William Isaac",
      "Julia Haas",
      "Sean Legassick",
      "Geoffrey Irving",
      "Iason Gabriel"
    ],
    "year": 2022,
    "abstract": "Responsible innovation on large-scale Language Models (LMs) re- quires foresight into and in-depth understanding of the risks these models may pose. This paper develops a comprehensive taxon- omy of ethical and social risks associated with LMs. We identify twenty-one risks, drawing on expertise and literature from com- puter science, linguistics, and the social sciences. We situate these risks in our taxonomy of six risk areas: I. Discrimination, Hate speech and Exclusion, II. Information Hazards, III. Misinformation Harms, IV. Malicious Uses, V. Human-Computer Interaction Harms, and VI. Environmental and Socioeconomic harms. For risks that have already been observed in LMs, the causal mechanism leading to harm, evidence of the risk, and approaches to risk mitigation are discussed. We further describe and analyse risks that have not yet been observed but are anticipated based on assessments of other language technologies, and situate these in the same taxonomy. We underscore that it is the responsibility of organizations to engage with the mitigations we discuss throughout the paper. We close by highlighting challenges and directions for further research on risk evaluation and mitigation with the goal of ensuring that language models are developed responsibly.",
    "doi": "10.1145/3531146.3533088",
    "url": "https://openalex.org/W4283170666",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3531146.3533088",
    "venue": "2022 ACM Conference on Fairness, Accountability, and Transparency",
    "citation_count": 482,
    "fields_of_study": [
      "Misinformation",
      "Taxonomy (biology)",
      "Harm",
      "Risk analysis (engineering)",
      "Futures studies"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769322"
  },
  {
    "source": "openalex",
    "source_id": "W3101981467",
    "title": "A Survey on the Explainability of Supervised Machine Learning",
    "authors": [
      "Nadia Burkart",
      "Marco F. Huber"
    ],
    "year": 2021,
    "abstract": "Predictions obtained by, e.g., artificial neural networks have a high accuracy but humans often perceive the models as black boxes. Insights about the decision making are mostly opaque for humans. Particularly understanding the decision making in highly sensitive areas such as healthcare or finance, is of paramount importance. The decision-making behind the black boxes requires it to be more transparent, accountable, and understandable for humans. This survey paper provides essential definitions, an overview of the different principles and methodologies of explainable Supervised Machine Learning (SML). We conduct a state-of-the-art survey that reviews past and recent explainable SML approaches and classifies them according to the introduced definitions. Finally, we illustrate principles by means of an explanatory case study and discuss important future directions.",
    "doi": "10.1613/jair.1.12228",
    "url": "https://openalex.org/W3101981467",
    "pdf_url": "https://jair.org/index.php/jair/article/download/12228/26647",
    "venue": "Journal of Artificial Intelligence Research",
    "citation_count": 900,
    "fields_of_study": [
      "Computer science",
      "Machine learning",
      "Artificial intelligence",
      "Supervised learning",
      "Artificial neural network"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769339"
  },
  {
    "source": "openalex",
    "source_id": "W4392669753",
    "title": "A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity",
    "authors": [
      "Yejin Bang",
      "Samuel Cahyawijaya",
      "Nayeon Lee",
      "Wenliang Dai",
      "Dan Su",
      "Bryan Wilie",
      "Holy Lovenia",
      "Ziwei Ji",
      "Tiezheng Yu",
      "Willy Chung",
      "V. Quyet",
      "Yan Xu",
      "Pascale Fung"
    ],
    "year": 2023,
    "abstract": "Yejin Bang, Samuel Cahyawijaya, Nayeon Lee, Wenliang Dai, Dan Su, Bryan Wilie, Holy Lovenia, Ziwei Ji, Tiezheng Yu, Willy Chung, Quyet V. Do, Yan Xu, Pascale Fung. Proceedings of the 13th International Joint Conference on Natural Language Processing and the 3rd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics (Volume 1: Long Papers). 2023.",
    "doi": "10.18653/v1/2023.ijcnlp-main.45",
    "url": "https://openalex.org/W4392669753",
    "pdf_url": "https://aclanthology.org/2023.ijcnlp-main.45.pdf",
    "venue": null,
    "citation_count": 569,
    "fields_of_study": [
      "Interactivity",
      "Computer science",
      "Natural language processing",
      "Multimodal interaction",
      "Multimodal therapy"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769353"
  },
  {
    "source": "openalex",
    "source_id": "W4378574344",
    "title": "ChatGPT and Open-AI Models: A Preliminary Review",
    "authors": [
      "Konstantinos I. Roumeliotis",
      "Nikolaos D. Tselikas"
    ],
    "year": 2023,
    "abstract": "According to numerous reports, ChatGPT represents a significant breakthrough in the field of artificial intelligence. ChatGPT is a pre-trained AI model designed to engage in natural language conversations, utilizing sophisticated techniques from Natural Language Processing (NLP), Supervised Learning, and Reinforcement Learning to comprehend and generate text comparable to human-generated text. This article provides an overview of the training process and fundamental functionality of ChatGPT, accompanied by a preliminary review of the relevant literature. Notably, this article presents the first comprehensive literature review of this technology at the time of publication, aiming to aggregate all the available pertinent articles to facilitate further developments in the field. Ultimately, the authors aim to offer an appraisal of the technology\u2019s potential implications on existing knowledge and technology, along with potential challenges that must be addressed.",
    "doi": "10.3390/fi15060192",
    "url": "https://openalex.org/W4378574344",
    "pdf_url": "https://www.mdpi.com/1999-5903/15/6/192/pdf?version=1685089354",
    "venue": "Future Internet",
    "citation_count": 618,
    "fields_of_study": [
      "Computer science",
      "Field (mathematics)",
      "Artificial intelligence",
      "Process (computing)",
      "Reinforcement learning"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769362"
  },
  {
    "source": "openalex",
    "source_id": "W2162057064",
    "title": "Climate Clubs: Overcoming Free-riding in International Climate Policy",
    "authors": [
      "William D. Nordhaus"
    ],
    "year": 2015,
    "abstract": "Notwithstanding great progress in scientific and economic understanding of climate change, it has proven difficult to forge international agreements because of free-riding, as seen in the defunct Kyoto Protocol. This study examines the club as a model for international climate policy. Based on economic theory and empirical modeling, it finds that without sanctions against non-participants there are no stable coalitions other than those with minimal abatement. By contrast, a regime with small trade penalties on non-participants, a Climate Club, can induce a large stable coalition with high levels of abatement. (JEL Q54, Q58, K32, K33)",
    "doi": "10.1257/aer.15000001",
    "url": "https://openalex.org/W2162057064",
    "pdf_url": "https://www.aeaweb.org/articles/pdf/doi/10.1257/aer.15000001",
    "venue": "American Economic Review",
    "citation_count": 1275,
    "fields_of_study": [
      "Sanctions",
      "Club",
      "Climate change",
      "Climate policy",
      "Kyoto Protocol"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769378"
  },
  {
    "source": "openalex",
    "source_id": "W2991184684",
    "title": "Artificial Intelligence and its role in surgical care in low-income and middle-income countries",
    "authors": [
      "Ch\u00e9 L. Reddy",
      "Shivani Mitra",
      "John G. Meara",
      "Rifat Atun",
      "Salim Afshar"
    ],
    "year": 2019,
    "abstract": "The barriers that prevent access to safe, affordable, and timely surgical care for 5 billion people are myriad, including shortfalls in workforce, infrastructure, and financing. These barriers mainly affect health systems in low-income and middle-income countries.1Meara JG Leather AJM Hagander L et al.Global Surgery 2030: evidence and solutions for achieving health, welfare, and economic development.Lancet. 2015; 386: 569-624Summary Full Text Full Text PDF PubMed Scopus (1818) Google Scholar In many high-income countries, artificial intelligence (AI) is viewed as a promising tool for transforming health systems.2Panch T Pearson-Stuttard J Greaves F Atun R Artificial intelligence: opportunities and risks for public health.Lancet Digital Health. 2019; 1: e13-e14Summary Full Text Full Text PDF Scopus (39) Google Scholar AI has a role to play in optimising health systems and supporting clinical judgement, because it can be used to search for patterns and insights across a patient population when human cognition alone is limited. However, is AI a luxury in low-resourced settings, or a required tool? Low-income and middle-income countries are a heterogeneous group of countries when it comes to data and technological expertise. Countries such as Brazil, China, India, Turkey, and South Africa have large datasets at the institutional and national levels and have the technological capacity to implement the technology. Exploring the possible use of AI could be considered a distraction, especially when major barriers to health-care delivery exist, but we argue that precisely because of these barriers, AI presents an exciting opportunity for some low-income and middle-income countries. We believe that the potential of AI to build more robust surgical systems lies in appropriately applying it to health system processes, to augment clinical judgment. In 2015, WHO member states adopted a resolution that emphasised the crucial role of surgery in Universal Health Coverage.368th World Health AssemblyWHA 68.15 Strengthening emergency and essential surgical care and anaesthesia as a component of universal health coverage.https://apps.who.int/gb/ebwha/pdf_files/WHA68/A68_R15-en.pdfDate: 2015Date accessed: November 12, 2019Google Scholar Surgically treatable conditions contribute to more deaths each year than HIV, tuberculosis, and malaria combined (appendix)1Meara JG Leather AJM Hagander L et al.Global Surgery 2030: evidence and solutions for achieving health, welfare, and economic development.Lancet. 2015; 386: 569-624Summary Full Text Full Text PDF PubMed Scopus (1818) Google Scholar\u2014a burden inequitably borne by low-income and middle-income countries. AI tools could help augment clinical judgment regarding patients and will probably eventually improve surgical care through stronger surgical diagnostics, prognostics, and therapeutics.4Hashimoto DA Rosman G Rus D Meireles OR Artificial Intelligence in surgery: promises and perils.Real Estate Econ. 2010; 38: 57-90Google Scholar However, for low-income and middle-income countries, we believe that AI tools should be developed to target the most substantial factor limiting surgical care: weak health systems with severe resource shortages and operational challenges, all of which undermine patient-level surgical care. The core problems in many low-income and middle-income countries are operational, managerial, and process challenges that reflect faults in the surgical system, rather than poor decision making by clinicians. Faulty supply chains result in inadequate surgical supplies; poor infrastructure\u2014for example, electricity blackouts\u2014causes delays in operating theatre lists; insufficient workforce foments physician burnout, inattention, and clinical errors; and weak governance and management results in impaired service delivery and overall institutional decay. Ineffective management of processes can be made more efficient within this realm of system function through AI systematically applied to answer questions within the domains of the National Surgical, Obstetric, and Anesthesia Planning (NSOAP) framework.5WHOSurgical care systems strengthening: developing national surgical, obstetric and anaesthesia plans.http://apps.who.int/iris/bitstream/10665/255566/1/9789241512244-eng.pdf?ua=1Date: 2017Date accessed: November 5, 2019Google Scholar Low-income and middle-income countries have implemented NSOAPs to develop country-specific strategies to improve their surgical system within six functional domains of a health system\u2014governance, financing, workforce, infrastructure, service delivery, and information management. NSOAPs are integrated into country national health strategic plans and within the other strategic health objectives of the Ministry of Health. For each country, data drives strategic decisions within each NSOAP domain, to which AI can be applied to data to answer process-related questions and reveal inferences that help policy makers and administrators advance surgical systems. The application of AI could overcome bureaucratic inefficiency for more efficient surgical system development in these countries, helping to optimise the production, distribution, and use of the health workforce and infrastructure; allocate system resources more efficiently; and streamline care pathways and supply chains. However, how can the issue of low-quality data in low-income and middle-income countries be addressed? With regards to data, not all low-income and middle-income countries are the same. Many countries, including South Africa, have large sets of data that pertain to both the health system and the broader context that together influence health service delivery at the national and sub-national levels.6World BankCentral Data Catalog. Microdata Library.https://microdata.worldbank.org/index.php/catalogDate accessed: October 5, 2019Google Scholar Countries with targeted national programmes have rich datasets to which AI could be applied to help policy makers gain insights into the provinces and challenges that should be prioritised. In addition to government data, dedicated networks of health-care providers offer specialised surgical care with comprehensive data repositories in both the private and public sectors. With appropriate data cleaning, rigorous coding, and transfer from one format to another to produce reliable and interoperable databases, growing surgical systems can leverage the large datasets they already possess. Most data in low-income and middle-income countries are not of low quality\u2014they are more frequently asymmetric, asynchronous, varied in type, and spread across locations. These datasets are dormant and underutilised in these countries. Expert-driven AI using smaller data sets that are combined\u2014for example, at the institutional level\u2014can be equally as powerful as large amounts of data.7Wilson HJ Daugherty PR Davenport C The future of AI will be about less data, not more.https://hbr.org/2019/01/the-future-of-ai-will-be-about-less-data-not-moreDate: 2019Date accessed: October 6, 2019Google Scholar Data scientists working closely with clinicians have already applied this approach in AI to address specific clinical questions.8Cho J Lee K Shin E Choy G Do S How much data is needed to train a medical image deep learning system to achieve necessary high accuracy?.https://arxiv.org/abs/1511.06348Date: 2015Date accessed: November 5, 2019Google Scholar Experts in health service delivery in low-income and middle-income countries can navigate asynchronous and asymmetric data sets through different applications of AI instead of relying only on bottom-up methodologies, although this has not yet been applied to health systems to answer questions on the inputs and outputs that determine the state of their health system. Developing transparent AI is possible through leveraging a combination of small data sets. When developers and experts are aware of the algorithms, its biases, and the results produced at each step in the application process, the AI algorithm becomes explainable9Lee H Yune S Mansouri M et al.An explainable deep-learning algorithm for the detection of acute intracranial haemorrhage from small datasets.Nat Biomed Eng. 2019; 3: 173-182Crossref PubMed Scopus (211) Google Scholar and therefore minimises the ethical and functional issues caused by blind results. Although the method holds promise, AI is not a panacea for improved surgical care. Broader challenges affecting AI policy include concerns around employment; ethics; privacy; and whether countries ought to immediately invest in other proven, cost-effective interventions before seeking out AI solutions. More specifically, regulatory and ethics boards will be needed to uphold the principles of transparency, accountability, privacy, and fairness in the use of data. This will require a careful assessment of both the challenges and potential benefit at institutional and national levels. Although the return on investment is unclear, the magnitude of the potential impact warrants the development of a receptive environment for AI adoption. This entails evaluating the AI innovation itself (AI utilised via the NSOAP framework), the adoption system (including stakeholders), and the broader health system context (appendix). The adoption system must encompass individuals and institutions that implement AI within the health system and those entities that influence or create the AI technology itself, each of which is crucial for successful adoption and scale-up. The potential for AI to improve access to effective and efficient surgical care in low-income and middle-income countries could be substantial. Urgent action is needed to develop the required technical skills for appropriate AI technologies and to create a receptive environment to test and scale AI. These countries must nurture local talent, bringing together a triad of AI developers, policy makers and clinicians, to understand the potential of AI that leverages asynchronous data sets; improve the pooling of data; develop context-appropriate regulatory and ethical frameworks; and apply appropriate AI technologies to answer questions within the domains of a surgical system. Failing to do so will almost guarantee the passive transfer of clinical AI tools to low-income and middle-income countries not ready to adopt and implement them in the contextual reality of a weak health system. Through a fair and inclusive process and method of analysis framed by NSOAPs, these countries could make substantial improvements in the application of AI to help expand surgical services to those who require it the most. SA declares patents pending in relation to software unrelated to the submitted work. Download .pdf (.24 MB) Help with pdf files Supplementary appendix",
    "doi": "10.1016/s2589-7500(19)30200-6",
    "url": "https://openalex.org/W2991184684",
    "pdf_url": "http://www.thelancet.com/article/S2589750019302006/pdf",
    "venue": "The Lancet Digital Health",
    "citation_count": 23,
    "fields_of_study": [
      "Low and middle income countries",
      "Middle income",
      "Demographic economics",
      "Economics",
      "Business"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769392"
  },
  {
    "source": "openalex",
    "source_id": "W4288391568",
    "title": "An Overview of Artificial Intelligence Ethics",
    "authors": [
      "Changwu Huang",
      "Zeqi Zhang",
      "Bifei Mao",
      "Xin Yao"
    ],
    "year": 2022,
    "abstract": "Artificial intelligence (AI) has profoundly changed and will continue to change our lives. AI is being applied in more and more fields and scenarios such as autonomous driving, medical care, media, finance, industrial robots, and internet services. The widespread application of AI and its deep integration with the economy and society have improved efficiency and produced benefits. At the same time, it will inevitably impact the existing social order and raise ethical concerns. Ethical issues, such as privacy leakage, discrimination, unemployment, and security risks, brought about by AI systems have caused great trouble to people. Therefore, AI ethics, which is a field related to the study of ethical issues in AI, has become not only an important research topic in academia, but also an important topic of common concern for individuals, organizations, countries, and society. This paper will give a comprehensive overview of this field by summarizing and analyzing the ethical risks and issues raised by AI, ethical guidelines and principles issued by different organizations, approaches for addressing ethical issues in AI, methods for evaluating the ethics of AI. Additionally, challenges in implementing ethics in AI and some future perspectives are pointed out. We hope our work will provide a systematic and comprehensive overview of AI ethics for researchers and practitioners in this field, especially the beginners of this research discipline.",
    "doi": "10.1109/tai.2022.3194503",
    "url": "https://openalex.org/W4288391568",
    "pdf_url": "https://ieeexplore.ieee.org/ielx7/9078688/9184921/09844014.pdf",
    "venue": "IEEE Transactions on Artificial Intelligence",
    "citation_count": 354,
    "fields_of_study": [
      "Engineering ethics",
      "Ethical issues",
      "Field (mathematics)",
      "Ethics of technology",
      "Political science"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769513"
  },
  {
    "source": "openalex",
    "source_id": "W4206484811",
    "title": "A Metaverse: Taxonomy, Components, Applications, and Open Challenges",
    "authors": [
      "Sangmin Park",
      "Young\u2010Gab Kim"
    ],
    "year": 2022,
    "abstract": "Unlike previous studies on the Metaverse based on Second Life, the current Metaverse is based on the social value of Generation Z that online and offline selves are not different. With the technological development of deep learning-based high-precision recognition models and natural generation models, Metaverse is being strengthened with various factors, from mobile-based always-on access to connectivity with reality using virtual currency. The integration of enhanced social activities and neural-net methods requires a new definition of Metaverse suitable for the present, different from the previous Metaverse. This paper divides the concepts and essential techniques necessary for realizing the Metaverse into three components (i.e., hardware, software, and contents) and three approaches (i.e., user interaction, implementation, and application) rather than marketing or hardware approach to conduct a comprehensive analysis. Furthermore, we describe essential methods based on three components and techniques to Metaverse&#x2019;s representative Ready Player One, Roblox, and Facebook research in the domain of films, games, and studies. Finally, we summarize the limitations and directions for implementing the immersive Metaverse as social influences, constraints, and open challenges.",
    "doi": "10.1109/access.2021.3140175",
    "url": "https://openalex.org/W4206484811",
    "pdf_url": "https://ieeexplore.ieee.org/ielx7/6287639/9668973/09667507.pdf",
    "venue": "IEEE Access",
    "citation_count": 1664,
    "fields_of_study": [
      "Computer science",
      "Taxonomy (biology)",
      "Metaverse",
      "Data science",
      "World Wide Web"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769531"
  },
  {
    "source": "openalex",
    "source_id": "W3032875465",
    "title": "Re-examining Whether, Why, and How Human-AI Interaction Is Uniquely Difficult to Design",
    "authors": [
      "Qian Yang",
      "Aaron Steinfeld",
      "Carolyn Penstein Ros\u00e9",
      "John Zimmerman"
    ],
    "year": 2020,
    "abstract": "Artificial Intelligence (AI) plays an increasingly important role in improving HCI and user experience. Yet many challenges persist in designing and innovating valuable human-AI interactions. For example, AI systems can make unpredictable errors, and these errors damage UX and even lead to undesired societal impact. However, HCI routinely grapples with complex technologies and mitigates their unintended consequences. What makes AI different? What makes human-AI interaction appear particularly difficult to design? This paper investigates these questions. We synthesize prior research, our own design and research experience, and our observations when teaching human-AI interaction. We identify two sources of AI's distinctive design challenges: 1) uncertainty surrounding AI's capabilities, 2) AI's output complexity, spanning from simple to adaptive complex. We identify four levels of AI systems. On each level, designers encounter a different subset of the design challenges. We demonstrate how these findings reveal new insights for designers, researchers, and design tool makers in productively addressing the challenges of human-AI interaction going forward.",
    "doi": "10.1145/3313831.3376301",
    "url": "https://openalex.org/W3032875465",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3313831.3376301",
    "venue": null,
    "citation_count": 495,
    "fields_of_study": [
      "Computer science",
      "Unintended consequences",
      "Human\u2013computer interaction",
      "Data science",
      "Interaction design"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769547"
  },
  {
    "source": "openalex",
    "source_id": "W4292289324",
    "title": "Human-in-the-loop machine learning: a state of the art",
    "authors": [
      "Eduardo Mosqueira-Rey",
      "Elena Hern\u00e1ndez-Pereira",
      "David Alonso-R\u00edos",
      "Jos\u00e9 Bobes-Bascar\u00e1n",
      "\u00c1ngel Fern\u00e1ndez-Leal"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1007/s10462-022-10246-w",
    "url": "https://openalex.org/W4292289324",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10462-022-10246-w.pdf",
    "venue": "Artificial Intelligence Review",
    "citation_count": 666,
    "fields_of_study": [
      "Computer science",
      "Artificial intelligence",
      "Machine learning",
      "Process (computing)",
      "Active learning (machine learning)"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769560"
  },
  {
    "source": "openalex",
    "source_id": "W4391855109",
    "title": "A Review on Large Language Models: Architectures, Applications, Taxonomies, Open Issues and Challenges",
    "authors": [
      "Mohaimenul Azam Khan Raiaan",
      "Md. Saddam Hossain Mukta",
      "Kaniz Fatema",
      "Nur Mohammad Fahad",
      "Sadman Sakib",
      "Most. Marufatul Jannat Mim",
      "Jubaer Ahmad",
      "Mohammed Eunus Ali",
      "Sami Azam"
    ],
    "year": 2024,
    "abstract": "Large Language Models (LLMs) recently demonstrated extraordinary capability in various natural language processing (NLP) tasks including language translation, text generation, question answering, etc. Moreover, LLMs are new and essential part of computerized language processing, having the ability to understand complex verbal patterns and generate coherent and appropriate replies in a given context. Though this success of LLMs has prompted a substantial increase in research contributions, rapid growth has made it difficult to understand the overall impact of these improvements. Since a plethora of research on LLMs have been appeared within a short time, it is quite impossible to track all of these and get an overview of the current state of research in this area. Consequently, the research community would benefit from a short but thorough review of the recent changes in this area. This article thoroughly overviews LLMs, including their history, architectures, transformers, resources, training methods, applications, impacts, challenges, etc. This paper begins by discussing the fundamental concepts of LLMs with its traditional pipeline of the LLMs training phase. Then the paper provides an overview of the existing works, the history of LLMs, their evolution over time, the architecture of transformers in LLMs, the different resources of LLMs, and the different training methods that have been used to train them. The paper also demonstrates the datasets utilized in the studies. After that, the paper discusses the wide range of applications of LLMs, including biomedical and healthcare, education, social, business, and agriculture. The study also illustrates how LLMs create an impact on society and shape the future of AI and how they can be used to solve real-world problems. Finally, the paper also explores open issues and challenges to deploy LLMs in real-world scenario. Our review paper aims to help practitioners, researchers, and experts thoroughly understand the evolution of LLMs, pre-trained architectures, applications, challenges, and future goals.",
    "doi": "10.1109/access.2024.3365742",
    "url": "https://openalex.org/W4391855109",
    "pdf_url": "https://ieeexplore.ieee.org/ielx7/6287639/6514899/10433480.pdf",
    "venue": "IEEE Access",
    "citation_count": 517,
    "fields_of_study": [
      "Computer science",
      "Open research",
      "Data science",
      "Natural language processing",
      "World Wide Web"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769564"
  },
  {
    "source": "openalex",
    "source_id": "W3046653923",
    "title": "Federated Learning: A Survey on Enabling Technologies, Protocols, and Applications",
    "authors": [
      "Mohammed Aledhari",
      "Rehma Razzak",
      "Reza M. Parizi",
      "Fahad Saeed"
    ],
    "year": 2020,
    "abstract": "This paper provides a comprehensive study of Federated Learning (FL) with an emphasis on enabling software and hardware platforms, protocols, real-life applications and use-cases. FL can be applicable to multiple domains but applying it to different industries has its own set of obstacles. FL is known as collaborative learning, where algorithm(s) get trained across multiple devices or servers with decentralized data samples without having to exchange the actual data. This approach is radically different from other more established techniques such as getting the data samples uploaded to servers or having data in some form of distributed infrastructure. FL on the other hand generates more robust models without sharing data, leading to privacy-preserved solutions with higher security and access privileges to data. This paper starts by providing an overview of FL. Then, it gives an overview of technical details that pertain to FL enabling technologies, protocols, and applications. Compared to other survey papers in the field, our objective is to provide a more thorough summary of the most relevant protocols, platforms, and real-life use-cases of FL to enable data scientists to build better privacy-preserving solutions for industries in critical need of FL. We also provide an overview of key challenges presented in the recent literature and provide a summary of related research work. Moreover, we explore both the challenges and advantages of FL and present detailed service use-cases to illustrate how different architectures and protocols that use FL can fit together to deliver desired results.",
    "doi": "10.1109/access.2020.3013541",
    "url": "https://openalex.org/W3046653923",
    "pdf_url": "https://ieeexplore.ieee.org/ielx7/6287639/8948470/09153560.pdf",
    "venue": "IEEE Access",
    "citation_count": 666,
    "fields_of_study": [
      "Computer science",
      "Upload",
      "Server",
      "Field (mathematics)",
      "Key (lock)"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769587"
  },
  {
    "source": "openalex",
    "source_id": "W3200742808",
    "title": "Chatbot for Health Care and Oncology Applications Using Artificial Intelligence and Machine Learning: Systematic Review",
    "authors": [
      "Lu Xu",
      "Leslie Sanders",
      "Kay Li",
      "James C. L. Chow"
    ],
    "year": 2021,
    "abstract": "Background Chatbot is a timely topic applied in various fields, including medicine and health care, for human-like knowledge transfer and communication. Machine learning, a subset of artificial intelligence, has been proven particularly applicable in health care, with the ability for complex dialog management and conversational flexibility. Objective This review article aims to report on the recent advances and current trends in chatbot technology in medicine. A brief historical overview, along with the developmental progress and design characteristics, is first introduced. The focus will be on cancer therapy, with in-depth discussions and examples of diagnosis, treatment, monitoring, patient support, workflow efficiency, and health promotion. In addition, this paper will explore the limitations and areas of concern, highlighting ethical, moral, security, technical, and regulatory standards and evaluation issues to explain the hesitancy in implementation. Methods A search of the literature published in the past 20 years was conducted using the IEEE Xplore, PubMed, Web of Science, Scopus, and OVID databases. The screening of chatbots was guided by the open-access Botlist directory for health care components and further divided according to the following criteria: diagnosis, treatment, monitoring, support, workflow, and health promotion. Results Even after addressing these issues and establishing the safety or efficacy of chatbots, human elements in health care will not be replaceable. Therefore, chatbots have the potential to be integrated into clinical practice by working alongside health practitioners to reduce costs, refine workflow efficiencies, and improve patient outcomes. Other applications in pandemic support, global health, and education are yet to be fully explored. Conclusions Further research and interdisciplinary collaboration could advance this technology to dramatically improve the quality of care for patients, rebalance the workload for clinicians, and revolutionize the practice of medicine.",
    "doi": "10.2196/27850",
    "url": "https://openalex.org/W3200742808",
    "pdf_url": "https://cancer.jmir.org/2021/4/e27850/PDF",
    "venue": "JMIR Cancer",
    "citation_count": 474,
    "fields_of_study": [
      "Chatbot",
      "Workflow",
      "Health care",
      "Safeguarding",
      "Clinical decision support system"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769613"
  },
  {
    "source": "openalex",
    "source_id": "W3006754301",
    "title": "A future for the world's children? A WHO\u2013UNICEF\u2013Lancet Commission",
    "authors": [
      "Helen Clark",
      "Awa Marie Coll\u2010Seck",
      "Anshu Banerjee",
      "Stefan Peterson",
      "Sarah L Dalglish",
      "Shanthi Ameratunga",
      "Dina Balabanova",
      "Maharaj Kishan Bhan",
      "Zulfiqar A Bhutta",
      "John Borrazzo",
      "M Claeson",
      "Tanya Doherty",
      "Fadi El\u2010Jardali",
      "Asha George",
      "Angela Gichaga",
      "Lu Gram",
      "David Hipgrave",
      "Aku Kwamie",
      "Qingyue Meng",
      "Ra\u00fal Mercer",
      "Sunita Narain",
      "Jesca Nsungwa\u2010Sabiiti",
      "Adesola Olumide",
      "David Osrin",
      "Timothy Powell\u2010Jackson",
      "Kumanan Rasanathan",
      "Imran Rasul",
      "Papaarangi Reid",
      "Jennifer Requejo",
      "Sarah Rohde",
      "Nigel Rollins",
      "Magali Romedenne",
      "Harshpal Singh Sachdev",
      "Rana Saleh",
      "Yusra Ribhi Shawar",
      "Jeremy Shiffman",
      "Jonathon Simon",
      "Peter D. Sly",
      "Karin Stenberg",
      "Mark Tomlinson",
      "Rajani Ved",
      "Anthony Costello"
    ],
    "year": 2020,
    "abstract": "Despite dramatic improvements in survival, nutrition, and education over recent decades, today's children face an uncertain future. Climate change, ecological degradation, migrating populations, conflict, pervasive inequalities, and predatory commercial practices threaten the health and future of children in every country. In 2015, the world's countries agreed on the Sustainable Development Goals (SDGs), yet nearly 5 years later, few countries have recorded much progress towards achieving them. This Commission presents the case for placing children, aged 0\u201318 years, at the centre of the SDGs: at the heart of the concept of sustainability and our shared human endeavour. Governments must harness coalitions across sectors to overcome ecological and commercial pressures to ensure children receive their rights and entitlements now and a liveable planet in the years to come. The evidence is clear: early investments in children's health, education, and development have benefits that compound throughout the child's lifetime, for their future children, and society as a whole. Successful societies invest in their children and protect their rights, as is evident from countries that have done well on health and economic measures over the past few decades. Yet many politicians still do not prioritise investing in children, nor see it as the foundation for broader societal improvements. Even in rich countries, many children go hungry or live in conditions of absolute poverty, especially those belonging to marginalised social groups\u2014including indigenous populations and ethnic minorities. Too often, the potential of children with developmental disabilities is neglected, restricting their contributions to society. Additionally, many millions of children grow up scarred by war or insecurity, excluded from receiving the most basic health, educational, and developmental services. Decision makers need a long-term vision. Just as good health and nutrition in the prenatal period and early years lay the foundation for a healthy life course, the learning and social skills we acquire at a young age provide the basis for later development and support a strong national polity and economy. High-quality services with universal health-care coverage must be a top priority. The benefits of investing in children would be enormous, and the costs are not prohibitive: an analysis of the SDGs suggests a financing gap of US$195 per person. To ensure stronger economic and human development, each government must assess how to mobilise funding using instruments that help the poorest proportion of the population to meet this gap for children, and frame these as the most powerful investments a society can make. But investments are not just monetary: citizen participation and community action, including the voices of children themselves, are powerful forces for change that must be mobilised to reach the SDGs. Social movements must play a transformational role in demanding the rights that communities need to care for children and provide for families. Countries that support future generations put a high priority on ensuring all children's needs are met, by delivering entitlements, such as paid parental leave, free primary health care at the point of delivery, access to healthy\u2014and sufficient amounts of\u2014food, state-funded or subsidised education, and other social protection measures. These countries make sure children grow up in safe and healthy environments, with clean water and air and safe spaces to play. They respect the equal rights of girls, boys, and those with non-conforming gender identities. Policy makers in these countries are concerned with the effect of all policies on all children, but especially those in poorer families and marginalised populations, starting by ensuring birth registration so that the government can provide for children across the life course, and help them to become engaged and productive adult citizens. The rights and entitlements of children are enshrined within the UN Convention on the Rights of the Child (CRC) ratified by all countries, except the USA. Countries might provide these entitlements in different ways, but their realisation is the only pathway for countries to achieve the SDGs for children's health and wellbeing, and requires decisive and strong public action. Since threats to child health and wellbeing originate in all sectors, a deliberately multisectoral approach is needed to ensure children and adolescents survive and thrive from the ages of 0\u201318 years, today and in the future. Investment in sectors beyond health and education\u2014such as housing, agriculture, energy, and transport\u2014are needed to address the greatest threats to child health and wellbeing. Political commitment at executive level is needed to coordinate across sectors and leverage synergies across the life course, ensuring universal health coverage; good nutrition and food security for all; thoughtful urban planning; safe and affordable housing and transport; clean energy for all; and equitable social welfare policies. Multisectoral governance might take different forms in each country, but it will require strategic partnerships, cabinet-level coordination across ministries, and management of diverse partners, with clear roles for each, including for non-state actors and the private sector. Heads of state or prime ministers must designate a cross-cutting government ministry or equivalent to ensure joined-up action and budgeting for pro-child policies and to demand harmonised assistance from global stakeholders, whose support is currently fragmented and inefficient. Wealthy countries generally have better child health and development outcomes, but their historic and current greenhouse gas emissions threaten the lives of all children. The ecological damage unleashed today endangers the future of children's lives on our planet, their only home. As a result, our understanding of progress on child health and wellbeing must give priority to measures of ecological sustainability and equity to ensure we protect all children, including the most vulnerable. We assessed the feasibility of monitoring countries' progress through a new child flourishing and futures profile, developed on the basis of survive and thrive SDG indicators reported by 180 countries, territories, and areas (hereafter referred to as countries), and future threats to children's wellbeing using the proxy of greenhouse gas emissions by country. We also complemented the profile with existing measures of economic equity. The poorest countries have a long way to go towards supporting their children's ability to live healthy lives, but wealthier countries threaten the future of all children through carbon pollution, on course to cause runaway climate change and environmental disaster. Not a single country performed well on all three measures of child flourishing, sustainability, and equity. The SDG indicators already provide a strong foundation for monitoring progress. However, we only found a very small amount of country data for the indicators used to track child health and wellbeing, which all countries agreed to collect. SDG monitoring needs a strong boost in investment to bridge the large data gaps in key indicators (with <50% of countries reporting data for many indicators), to allow for subnational disaggregation if governments are to monitor, review, and act. To ensure our children grow and flourish, we require timely and accurate population data on health, nutrition, educational access and performance, housing, and environmental security, among other entitlements. Harnessing the power of citizen accountability mechanisms will be essential to fill the data gaps. We also propose the development of user-friendly country dashboards to assess the effects on children's wellbeing and sustainable development. Given the urgency for action, regular reports on the SDGs to the UN General Assembly must be the anchor of strong advocacy on action for children everywhere. Although we recognise the role business plays in wealth and job creation, the commercial sector's profit motive poses many threats to child health and wellbeing, not least the environmental damage unleashed by unregulated industry. More immediately, children around the world are enormously exposed to advertising from business, whose marketing techniques exploit their developmental vulnerability and whose products can harm their health and wellbeing. Companies make huge profits from marketing products directly to children and promoting addictive or unhealthy commodities, including fast foods, sugar-sweetened beverages, alcohol, and tobacco, all of which are major causes of non-communicable diseases. Children's large and growing online exposure, while bringing benefits in terms of information access and social support, also exposes them to exploitation, as well as to bullying, gambling, and grooming by criminals and sexual abusers. Industry self-regulation does not work, and the existing global frameworks are not sufficient. A far stronger and more comprehensive approach to regulation is required. We call for the development of an Optional Protocol to the CRC (ie, an additional component to the treaty that must be independently ratified), to protect children from the marketing of tobacco, alcohol, formula milk, sugar-sweetened beverages, gambling, and potentially damaging social media, and the inappropriate use of their personal data. Countries who have led the way in protecting children from the harms of commercial marketing, supported by civil society, can support a protocol for adoption by the UN General Assembly, providing impetus for further legal and constitutional protections for children at national level. Children and young people are full of energy, ideas, and hope for the future. They are also angry at the state of the world. Worldwide, school-children and young people are protesting about environmental threats from fossil fuel economies. We must find better ways to amplify their voices and skills for the planet's sustainable and healthy future. The SDGs require governments to place children at the very centre of their plans to address this crisis. This Commission makes positive and optimistic recommendations\u2013but we have no time to lose, and no excuses if we fail. A new global movement for child and adolescent health is today an urgent necessity.",
    "doi": "10.1016/s0140-6736(19)32540-1",
    "url": "https://openalex.org/W3006754301",
    "pdf_url": "http://www.thelancet.com/article/S0140673619325401/pdf",
    "venue": "The Lancet",
    "citation_count": 1018,
    "fields_of_study": [
      "Commission",
      "Political science",
      "Medicine",
      "Family medicine",
      "Law"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769647"
  },
  {
    "source": "openalex",
    "source_id": "W4210867863",
    "title": "Ethics of AI-Enabled Recruiting and Selection: A Review and Research Agenda",
    "authors": [
      "Anna Lena Hunkenschroer",
      "Christoph Luetge"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1007/s10551-022-05049-6",
    "url": "https://openalex.org/W4210867863",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10551-022-05049-6.pdf",
    "venue": "Journal of Business Ethics",
    "citation_count": 320,
    "fields_of_study": [
      "Business ethics",
      "Novelty",
      "Extant taxon",
      "Process (computing)",
      "Engineering ethics"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769779"
  },
  {
    "source": "openalex",
    "source_id": "W2998691503",
    "title": "Automation, Algorithms, and Beyond: Why Work Design Matters More Than Ever in a Digital World",
    "authors": [
      "Sharon K. Parker",
      "Gudela Grote"
    ],
    "year": 2019,
    "abstract": "Abstract We propose a central role for work design in understanding the effects of digital technologies. We give examples of how new technologies can\u2014depending on various factors\u2014positively and negatively affect job resources (autonomy/control, skill use, job feedback, relational aspects) and job demands (e.g., performance monitoring), with consequences for employee well\u2010being, safety, and performance. We identify four intervention strategies. First, work design choices need to be proactively considered during technology implementation, consistent with the sociotechnical systems principle of joint optimization. Second, human\u2010centred design principles should be explicitly considered in the design and procurement of new technologies. Third, organizationally oriented intervention strategies need to be supported by macro\u2010level policies. Fourth, there is a need to go beyond a focus on upskilling employees to help them adapt to technology change, to also focus on training employees, as well as other stakeholders, in work design and related topics. Finally, we identify directions for moving the field forward, including new research questions (e.g., job autonomy in the context of machine learning; understanding designers\u2019 work design mindsets; investigating how job crafting applies to technology); a reorientation of methods (e.g., interdisciplinary, intervention studies); and steps for achieving practical impact.",
    "doi": "10.1111/apps.12241",
    "url": "https://openalex.org/W2998691503",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/apps.12241",
    "venue": "Applied Psychology",
    "citation_count": 659,
    "fields_of_study": [
      "Job design",
      "Sociotechnical system",
      "Autonomy",
      "Computer science",
      "Knowledge management"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769781"
  },
  {
    "source": "openalex",
    "source_id": "W2990290777",
    "title": "Artificial intelligence in clinical and genomic diagnostics",
    "authors": [
      "Raquel Dias",
      "Ali Torkamani"
    ],
    "year": 2019,
    "abstract": null,
    "doi": "10.1186/s13073-019-0689-8",
    "url": "https://openalex.org/W2990290777",
    "pdf_url": "https://genomemedicine.biomedcentral.com/track/pdf/10.1186/s13073-019-0689-8",
    "venue": "Genome Medicine",
    "citation_count": 425,
    "fields_of_study": [
      "Artificial intelligence",
      "Computer science",
      "Deep learning",
      "Precision medicine",
      "Genomics"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769798"
  },
  {
    "source": "openalex",
    "source_id": "W4223899585",
    "title": "Transfer learning for medical image classification: a literature review",
    "authors": [
      "Kim Eun Hee",
      "Alejandro Cosa\u2010Linan",
      "Nandhini Santhanam",
      "Mahboubeh Jannesari",
      "M\u00e1t\u00e9 E. Maros",
      "Thomas Ganslandt"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1186/s12880-022-00793-7",
    "url": "https://openalex.org/W4223899585",
    "pdf_url": "https://bmcmedimaging.biomedcentral.com/track/pdf/10.1186/s12880-022-00793-7",
    "venue": "BMC Medical Imaging",
    "citation_count": 807,
    "fields_of_study": [
      "Computer science",
      "Extractor",
      "Transfer of learning",
      "Artificial intelligence",
      "Task (project management)"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769802"
  },
  {
    "source": "openalex",
    "source_id": "W4376139682",
    "title": "The role of ChatGPT in higher education: Benefits, challenges, and future research directions",
    "authors": [
      "Tareq Rasul",
      "Sumesh Nair",
      "Diane Robyn Kalendra",
      "Mulyadi Robin",
      "Fernando de Oliveira Santini",
      "Wagner J\u00fanior Ladeira",
      "Mingwei Sun",
      "Ingrid Day",
      "Raouf Ahmad Rather",
      "Liz Heathcote"
    ],
    "year": 2023,
    "abstract": "This paper examines the potential benefits and challenges of using the generative AI model, ChatGPT, in higher education, in the backdrop of the constructivist theory of learning. This perspective-type study presents five benefits of ChatGPT: the potential to facilitate adaptive learning, provide personalised feedback, support research and data analysis, offer automated administrative services, and aid in developing innovative assessments. Additionally, the paper identifies five challenges: academic integrity concerns, reliability issues, inability to evaluate and reinforce graduate skill sets, limitations in assessing learning outcomes, and potential biases and falsified information in information processing. The paper argues that tertiary educators and students must exercise caution when using ChatGPT for academic purposes to ensure its ethical, reliable, and effective use. To achieve this, the paper proposes various propositions, such as prioritising education on the responsible and ethical use of ChatGPT, devising new assessment strategies, addressing bias and falsified information, and including AI literacy as part of graduate skills. By balancing the potential benefits and challenges, ChatGPT can enhance students\u2019 learning experiences in higher education.",
    "doi": "10.37074/jalt.2023.6.1.29",
    "url": "https://openalex.org/W4376139682",
    "pdf_url": "https://journals.sfu.ca/jalt/index.php/jalt/article/download/787/583",
    "venue": "Journal of Applied Learning & Teaching",
    "citation_count": 486,
    "fields_of_study": [
      "Perspective (graphical)",
      "Higher education",
      "Engineering ethics",
      "Reliability (semiconductor)",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769805"
  },
  {
    "source": "openalex",
    "source_id": "W3115247823",
    "title": "Artificial intelligence for good health: a scoping review of the ethics literature",
    "authors": [
      "Kathleen Murphy",
      "Erica Di Ruggiero",
      "Ross Upshur",
      "Donald J. Willison",
      "Neha Malhotra",
      "Jia Cai",
      "Nakul Malhotra",
      "Vincci Lui",
      "Jennifer Gibson"
    ],
    "year": 2021,
    "abstract": "Abstract Background Artificial intelligence (AI) has been described as the \u201cfourth industrial revolution\u201d with transformative and global implications, including in healthcare, public health, and global health. AI approaches hold promise for improving health systems worldwide, as well as individual and population health outcomes. While AI may have potential for advancing health equity within and between countries, we must consider the ethical implications of its deployment in order to mitigate its potential harms, particularly for the most vulnerable. This scoping review addresses the following question: What ethical issues have been identified in relation to AI in the field of health, including from a global health perspective? Methods Eight electronic databases were searched for peer reviewed and grey literature published before April 2018 using the concepts of health, ethics, and AI, and their related terms. Records were independently screened by two reviewers and were included if they reported on AI in relation to health and ethics and were written in the English language. Data was charted on a piloted data charting form, and a descriptive and thematic analysis was performed. Results Upon reviewing 12,722 articles, 103 met the predetermined inclusion criteria. The literature was primarily focused on the ethics of AI in health care, particularly on carer robots, diagnostics, and precision medicine, but was largely silent on ethics of AI in public and population health. The literature highlighted a number of common ethical concerns related to privacy, trust, accountability and responsibility, and bias. Largely missing from the literature was the ethics of AI in global health, particularly in the context of low- and middle-income countries (LMICs). Conclusions The ethical issues surrounding AI in the field of health are both vast and complex. While AI holds the potential to improve health and health systems, our analysis suggests that its introduction should be approached with cautious optimism. The dearth of literature on the ethics of AI within LMICs, as well as in public health, also points to a critical need for further research into the ethical implications of AI within both global and public health, to ensure that its development and implementation is ethical for everyone, everywhere.",
    "doi": "10.1186/s12910-021-00577-8",
    "url": "https://openalex.org/W3115247823",
    "pdf_url": "https://bmcmedethics.biomedcentral.com/track/pdf/10.1186/s12910-021-00577-8",
    "venue": "BMC Medical Ethics",
    "citation_count": 367,
    "fields_of_study": [
      "Philosophy of medicine",
      "Public health",
      "Health care",
      "Population health",
      "Accountability"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769822"
  },
  {
    "source": "openalex",
    "source_id": "W3197232629",
    "title": "The growing field of digital psychiatry: current evidence and the future of apps, social media, chatbots, and virtual reality",
    "authors": [
      "John Torous",
      "Sandra Bucci",
      "Imogen Bell",
      "Lars Vedel Kessing",
      "Maria Faurholt\u2010Jepsen",
      "Pauline Whelan",
      "Andr\u00e9 F. Carvalho",
      "Matcheri S. Keshavan",
      "Jake Linardon",
      "Joseph Firth"
    ],
    "year": 2021,
    "abstract": "As the COVID\u201019 pandemic has largely increased the utilization of telehealth, mobile mental health technologies \u2013 such as smartphone apps, vir\u00adtual reality, chatbots, and social media \u2013 have also gained attention. These digital health technologies offer the potential of accessible and scalable interventions that can augment traditional care. In this paper, we provide a comprehensive update on the overall field of digital psychiatry, covering three areas. First, we outline the relevance of recent technological advances to mental health research and care, by detailing how smartphones, social media, artificial intelligence and virtual reality present new opportunities for \u201cdigital phenotyping\u201d and remote intervention. Second, we review the current evidence for the use of these new technological approaches across different mental health contexts, covering their emerging efficacy in self\u2010management of psychological well\u2010being and early intervention, along with more nascent research supporting their use in clinical management of long\u2010term psychiatric conditions \u2013 including major depression; anxiety, bipolar and psychotic disorders; and eating and substance use disorders \u2013 as well as in child and adolescent mental health care. Third, we discuss the most pressing challenges and opportunities towards real\u2010world implementation, using the Integrated Promoting Action on Research Implementation in Health Services (i\u2010PARIHS) framework to explain how the innovations themselves, the recipients of these innovations, and the context surrounding innovations all must be considered to facilitate their adoption and use in mental health care systems. We conclude that the new technological capabilities of smartphones, artificial intelligence, social media and virtual reality are already changing mental health care in unforeseen and exciting ways, each accompanied by an early but promising evidence base. We point out that further efforts towards strengthening implementation are needed, and detail the key issues at the patient, provider and policy levels which must now be addressed for digital health technologies to truly improve mental health research and treatment in the future.",
    "doi": "10.1002/wps.20883",
    "url": "https://openalex.org/W3197232629",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/wps.20883",
    "venue": "World Psychiatry",
    "citation_count": 956,
    "fields_of_study": [
      "Mental health",
      "Social media",
      "Context (archaeology)",
      "Psychological intervention",
      "Telemedicine"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769851"
  },
  {
    "source": "openalex",
    "source_id": "W4386714740",
    "title": "Ethics and discrimination in artificial intelligence-enabled recruitment practices",
    "authors": [
      "Zhisheng Chen"
    ],
    "year": 2023,
    "abstract": "Abstract This study aims to address the research gap on algorithmic discrimination caused by AI-enabled recruitment and explore technical and managerial solutions. The primary research approach used is a literature review. The findings suggest that AI-enabled recruitment has the potential to enhance recruitment quality, increase efficiency, and reduce transactional work. However, algorithmic bias results in discriminatory hiring practices based on gender, race, color, and personality traits. The study indicates that algorithmic bias stems from limited raw data sets and biased algorithm designers. To mitigate this issue, it is recommended to implement technical measures, such as unbiased dataset frameworks and improved algorithmic transparency, as well as management measures like internal corporate ethical governance and external oversight. Employing Grounded Theory, the study conducted survey analysis to collect firsthand data on respondents\u2019 experiences and perceptions of AI-driven recruitment applications and discrimination.",
    "doi": "10.1057/s41599-023-02079-x",
    "url": "https://openalex.org/W4386714740",
    "pdf_url": "https://www.nature.com/articles/s41599-023-02079-x.pdf",
    "venue": "Humanities and Social Sciences Communications",
    "citation_count": 277,
    "fields_of_study": [
      "Transparency (behavior)",
      "Computer science",
      "Corporate governance",
      "Big Five personality traits",
      "Raw data"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769875"
  },
  {
    "source": "openalex",
    "source_id": "W2988293491",
    "title": "The Chinese approach to artificial intelligence: an analysis of policy, ethics, and regulation",
    "authors": [
      "Huw Roberts",
      "Josh Cowls",
      "Jessica Morley",
      "Mariarosaria Taddeo",
      "Vincent Wang",
      "Luciano Floridi"
    ],
    "year": 2020,
    "abstract": "Abstract In July 2017, China\u2019s State Council released the country\u2019s strategy for developing artificial intelligence (AI), entitled \u2018New Generation Artificial Intelligence Development Plan\u2019 (\u65b0\u4e00\u4ee3\u4eba\u5de5\u667a\u80fd\u53d1\u5c55\u89c4\u5212). This strategy outlined China\u2019s aims to become the world leader in AI by 2030, to monetise AI into a trillion-yuan (ca. 150 billion dollars) industry, and to emerge as the driving force in defining ethical norms and standards for AI. Several reports have analysed specific aspects of China\u2019s AI policies or have assessed the country\u2019s technical capabilities. Instead, in this article, we focus on the socio-political background and policy debates that are shaping China\u2019s AI strategy. In particular, we analyse the main strategic areas in which China is investing in AI and the concurrent ethical debates that are delimiting its use. By focusing on the policy backdrop, we seek to provide a more comprehensive and critical understanding of China\u2019s AI policy by bringing together debates and analyses of a wide array of policy documents.",
    "doi": "10.1007/s00146-020-00992-2",
    "url": "https://openalex.org/W2988293491",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s00146-020-00992-2.pdf",
    "venue": "AI & Society",
    "citation_count": 485,
    "fields_of_study": [
      "China",
      "Politics",
      "State (computer science)",
      "Political science",
      "Applications of artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769888"
  },
  {
    "source": "openalex",
    "source_id": "W3161181201",
    "title": "Algorithms as work designers: How algorithmic management influences the design of jobs",
    "authors": [
      "Xavier Parent\u2010Rocheleau",
      "Sharon K. Parker"
    ],
    "year": 2021,
    "abstract": null,
    "doi": "10.1016/j.hrmr.2021.100838",
    "url": "https://openalex.org/W3161181201",
    "pdf_url": "https://www.sciencedirect.com/science/article/pii/S1053482221000176",
    "venue": "Human Resource Management Review",
    "citation_count": 285,
    "fields_of_study": [
      "Job design",
      "Computer science",
      "Sociotechnical system",
      "Workload",
      "Bridge (graph theory)"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769902"
  },
  {
    "source": "openalex",
    "source_id": "W4320040080",
    "title": "The Ethical Implications of Artificial Intelligence (AI) For Meaningful Work",
    "authors": [
      "Sarah Bankins",
      "Paul Formosa"
    ],
    "year": 2023,
    "abstract": "Abstract The increasing workplace use of artificially intelligent (AI) technologies has implications for the experience of meaningful human work. Meaningful work refers to the perception that one\u2019s work has worth, significance, or a higher purpose. The development and organisational deployment of AI is accelerating, but the ways in which this will support or diminish opportunities for meaningful work and the ethical implications of these changes remain under-explored. This conceptual paper is positioned at the intersection of the meaningful work and ethical AI literatures and offers a detailed assessment of the ways in which the deployment of AI can enhance or diminish employees\u2019 experiences of meaningful work. We first outline the nature of meaningful work and draw on philosophical and business ethics accounts to establish its ethical importance. We then explore the impacts of three paths of AI deployment (replacing some tasks, \u2018tending the machine\u2019, and amplifying human skills) across five dimensions constituting a holistic account of meaningful work, and finally assess the ethical implications. In doing so we help to contextualise the meaningful work literature for the era of AI, extend the ethical AI literature into the workplace, and conclude with a range of practical implications and future research directions.",
    "doi": "10.1007/s10551-023-05339-7",
    "url": "https://openalex.org/W4320040080",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10551-023-05339-7.pdf",
    "venue": "Journal of Business Ethics",
    "citation_count": 280,
    "fields_of_study": [
      "Business ethics",
      "Software deployment",
      "Work (physics)",
      "Engineering ethics",
      "Perception"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769904"
  },
  {
    "source": "openalex",
    "source_id": "W3014499801",
    "title": "How to Design AI for Social Good: Seven Essential Factors",
    "authors": [
      "Luciano Floridi",
      "Josh Cowls",
      "Thomas C. King",
      "Mariarosaria Taddeo"
    ],
    "year": 2020,
    "abstract": "Abstract The idea of artificial intelligence for social good (henceforth AI4SG) is gaining traction within information societies in general and the AI community in particular. It has the potential to tackle social problems through the development of AI-based solutions. Yet, to date, there is only limited understanding of what makes AI socially good in theory, what counts as AI4SG in practice, and how to reproduce its initial successes in terms of policies. This article addresses this gap by identifying seven ethical factors that are essential for future AI4SG initiatives. The analysis is supported by 27 case examples of AI4SG projects. Some of these factors are almost entirely novel to AI, while the significance of other factors is heightened by the use of AI. From each of these factors, corresponding best practices are formulated which, subject to context and balance, may serve as preliminary guidelines to ensure that well-designed AI is more likely to serve the social good.",
    "doi": "10.1007/s11948-020-00213-5",
    "url": "https://openalex.org/W3014499801",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s11948-020-00213-5.pdf",
    "venue": "Science and Engineering Ethics",
    "citation_count": 348,
    "fields_of_study": [
      "Philosophy of science",
      "Context (archaeology)",
      "Subject (documents)",
      "Engineering ethics",
      "Management science"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769922"
  },
  {
    "source": "openalex",
    "source_id": "W3046399757",
    "title": "A Research Agenda for Hybrid Intelligence: Augmenting Human Intellect With Collaborative, Adaptive, Responsible, and Explainable Artificial Intelligence",
    "authors": [
      "Zeynep Akata",
      "Dan Balliet",
      "Maarten de Rijke",
      "Frank Dignum",
      "Virginia Dignum",
      "Guszti Eiben",
      "Antske Fokkens",
      "Davide Grossi",
      "Koen V. Hindriks",
      "Holger H. Hoos",
      "Hayley Hung",
      "Catholijn M. Jonker",
      "Christof Monz",
      "Mark A. Neerincx",
      "Frans A. Oliehoek",
      "Henry Prakken",
      "Stefan Schlobach",
      "Linda van der Gaag",
      "Frank van Harmelen",
      "Herke van Hoof",
      "M. Birna van Riemsdijk",
      "Aimee van Wynsberghe",
      "Rineke Verbrugge",
      "Bart Verheij",
      "Piek Vossen",
      "Max Welling"
    ],
    "year": 2020,
    "abstract": "We define hybrid intelligence (HI) as the combination of human and machine intelligence, augmenting human intellect and capabilities instead of replacing them and achieving goals that were unreachable by either humans or machines. HI is an important new research focus for artificial intelligence, and we set a research agenda for HI by formulating four challenges.",
    "doi": "10.1109/mc.2020.2996587",
    "url": "https://openalex.org/W3046399757",
    "pdf_url": "https://ieeexplore.ieee.org/ielx7/2/9153282/09153877.pdf",
    "venue": "Computer",
    "citation_count": 335,
    "fields_of_study": [
      "Intellect",
      "Computer science",
      "Human intelligence",
      "Artificial intelligence",
      "Set (abstract data type)"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769942"
  },
  {
    "source": "openalex",
    "source_id": "W3014972121",
    "title": "Co-Designing Checklists to Understand Organizational Challenges and Opportunities around Fairness in AI",
    "authors": [
      "Michael Madaio",
      "Luke Stark",
      "Jennifer Wortman Vaughan",
      "Hanna Wallach"
    ],
    "year": 2020,
    "abstract": "Many organizations have published principles intended to guide the ethical development and deployment of AI systems; however, their abstract nature makes them difficult to operationalize. Some organizations have therefore produced AI ethics checklists, as well as checklists for more specific concepts, such as fairness, as applied to AI systems. But unless checklists are grounded in practitioners' needs, they may be misused. To understand the role of checklists in AI ethics, we conducted an iterative co-design process with 48 practitioners, focusing on fairness. We co-designed an AI fairness checklist and identified desiderata and concerns for AI fairness checklists in general. We found that AI fairness checklists could provide organizational infrastructure for formalizing ad-hoc processes and empowering individual advocates. We highlight aspects of organizational culture that may impact the efficacy of AI fairness checklists, and suggest future design directions.",
    "doi": "10.1145/3313831.3376445",
    "url": "https://openalex.org/W3014972121",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3313831.3376445",
    "venue": null,
    "citation_count": 370,
    "fields_of_study": [
      "Operationalization",
      "Checklist",
      "Knowledge management",
      "Process (computing)",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769950"
  },
  {
    "source": "openalex",
    "source_id": "W3129794348",
    "title": "The ethics of algorithms: key problems and solutions",
    "authors": [
      "Andreas Tsamados",
      "Nikita Aggarwal",
      "Josh Cowls",
      "Jessica Morley",
      "Huw Roberts",
      "Mariarosaria Taddeo",
      "Luciano Floridi"
    ],
    "year": 2021,
    "abstract": "Abstract Research on the ethics of algorithms has grown substantially over the past decade. Alongside the exponential development and application of machine learning algorithms, new ethical problems and solutions relating to their ubiquitous use in society have been proposed. This article builds on a review of the ethics of algorithms published in 2016 (Mittelstadt et al. Big Data Soc 3(2), 2016). The goals are to contribute to the debate on the identification and analysis of the ethical implications of algorithms, to provide an updated analysis of epistemic and normative concerns, and to offer actionable guidance for the governance of the design, development and deployment of algorithms.",
    "doi": "10.1007/s00146-021-01154-8",
    "url": "https://openalex.org/W3129794348",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s00146-021-01154-8.pdf",
    "venue": "AI & Society",
    "citation_count": 299,
    "fields_of_study": [
      "Normative",
      "Key (lock)",
      "Computer science",
      "Software deployment",
      "Corporate governance"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769963"
  },
  {
    "source": "openalex",
    "source_id": "W3164960502",
    "title": "Leveraging Artificial Intelligence in Marketing for Social Good\u2014An Ethical Perspective",
    "authors": [
      "Erik Hermann"
    ],
    "year": 2021,
    "abstract": null,
    "doi": "10.1007/s10551-021-04843-y",
    "url": "https://openalex.org/W3164960502",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10551-021-04843-y.pdf",
    "venue": "Journal of Business Ethics",
    "citation_count": 302,
    "fields_of_study": [
      "Business ethics",
      "Perspective (graphical)",
      "Interdependence",
      "Stakeholder",
      "Sociology"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769974"
  },
  {
    "source": "openalex",
    "source_id": "W4379010216",
    "title": "Reflection on whether Chat GPT should be banned by academia from the perspective of education and teaching",
    "authors": [
      "Hao Yu"
    ],
    "year": 2023,
    "abstract": "OPINION article Front. Psychol., 01 June 2023Sec. Educational Psychology Volume 14 - 2023 | https://doi.org/10.3389/fpsyg.2023.1181712",
    "doi": "10.3389/fpsyg.2023.1181712",
    "url": "https://openalex.org/W4379010216",
    "pdf_url": "https://www.frontiersin.org/articles/10.3389/fpsyg.2023.1181712/pdf",
    "venue": "Frontiers in Psychology",
    "citation_count": 357,
    "fields_of_study": [
      "Perspective (graphical)",
      "Psychology",
      "Reflection (computer programming)",
      "Medical education",
      "Engineering ethics"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769977"
  },
  {
    "source": "openalex",
    "source_id": "W2919720720",
    "title": "From Big Data to Precision Medicine",
    "authors": [
      "Tim Hulsen",
      "Saumya Shekhar Jamuar",
      "Alan R. Moody",
      "Jason H. Karnes",
      "Orsolya Varga",
      "Stine Hedensted",
      "Roberto Spreafico",
      "D Hafler",
      "Eoin McKinney"
    ],
    "year": 2019,
    "abstract": "For over a decade the term \"Big data\" has been used to describe the rapid increase in volume, variety and velocity of information available, not just in medical research but in almost every aspect of our lives. As scientists, we now have the capacity to rapidly generate, store and analyse data that, only a few years ago, would have taken many years to compile. However, \"Big data\" no longer means what it once did. The term has expanded and now refers not to just large data volume, but to our increasing ability to analyse and interpret those data. Tautologies such as \"data analytics\" and \"data science\" have emerged to describe approaches to the volume of available information as it grows ever larger. New methods dedicated to improving data collection, storage, cleaning, processing and interpretation continue to be developed, although not always by, or for, medical researchers. Exploiting new tools to extract meaning from large volume information has the potential to drive real change in clinical practice, from personalized therapy and intelligent drug design to population screening and electronic health record mining. As ever, where new technology promises \"Big Advances,\" significant challenges remain. Here we discuss both the opportunities and challenges posed to biomedical research by our increasing ability to tackle large datasets. Important challenges include the need for standardization of data content, format, and clinical definitions, a heightened need for collaborative networks with sharing of both data and expertise and, perhaps most importantly, a need to reconsider how and when analytic methodology is taught to medical researchers. We also set \"Big data\" analytics in context: recent advances may appear to promise a revolution, sweeping away conventional approaches to medical science. However, their real promise lies in their synergy with, not replacement of, classical hypothesis-driven methods. The generation of novel, data-driven hypotheses based on interpretable models will always require stringent validation and experimental testing. Thus, hypothesis-generating research founded on large datasets adds to, rather than replaces, traditional hypothesis driven science. Each can benefit from the other and it is through using both that we can improve clinical practice.",
    "doi": "10.3389/fmed.2019.00034",
    "url": "https://openalex.org/W2919720720",
    "pdf_url": "https://www.frontiersin.org/articles/10.3389/fmed.2019.00034/pdf",
    "venue": "Frontiers in Medicine",
    "citation_count": 449,
    "fields_of_study": [
      "Big data",
      "Data science",
      "Standardization",
      "Variety (cybernetics)",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:10.769981"
  },
  {
    "source": "openalex",
    "source_id": "W4361002760",
    "title": "The Role of ChatGPT in Data Science: How AI-Assisted Conversational Interfaces Are Revolutionizing the Field",
    "authors": [
      "Hossein Hassani",
      "Emmanuel Sirimal Silva"
    ],
    "year": 2023,
    "abstract": "ChatGPT, a conversational AI interface that utilizes natural language processing and machine learning algorithms, is taking the world by storm and is the buzzword across many sectors today. Given the likely impact of this model on data science, through this perspective article, we seek to provide an overview of the potential opportunities and challenges associated with using ChatGPT in data science, provide readers with a snapshot of its advantages, and stimulate interest in its use for data science projects. The paper discusses how ChatGPT can assist data scientists in automating various aspects of their workflow, including data cleaning and preprocessing, model training, and result interpretation. It also highlights how ChatGPT has the potential to provide new insights and improve decision-making processes by analyzing unstructured data. We then examine the advantages of ChatGPT\u2019s architecture, including its ability to be fine-tuned for a wide range of language-related tasks and generate synthetic data. Limitations and issues are also addressed, particularly around concerns about bias and plagiarism when using ChatGPT. Overall, the paper concludes that the benefits outweigh the costs and ChatGPT has the potential to greatly enhance the productivity and accuracy of data science workflows and is likely to become an increasingly important tool for intelligence augmentation in the field of data science. ChatGPT can assist with a wide range of natural language processing tasks in data science, including language translation, sentiment analysis, and text classification. However, while ChatGPT can save time and resources compared to training a model from scratch, and can be fine-tuned for specific use cases, it may not perform well on certain tasks if it has not been specifically trained for them. Additionally, the output of ChatGPT may be difficult to interpret, which could pose challenges for decision-making in data science applications.",
    "doi": "10.3390/bdcc7020062",
    "url": "https://openalex.org/W4361002760",
    "pdf_url": "https://www.mdpi.com/2504-2289/7/2/62/pdf?version=1679985158",
    "venue": "Big Data and Cognitive Computing",
    "citation_count": 358,
    "fields_of_study": [
      "Computer science",
      "Data science",
      "Workflow",
      "Field (mathematics)",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:10.770018"
  },
  {
    "source": "openalex",
    "source_id": "W4253545088",
    "title": "The ARRIVE guidelines 2.0: updated guidelines for reporting animal research",
    "authors": [
      "Nathalie Percie du Sert",
      "Viki Hurst",
      "Amrita Ahluwalia",
      "Sabina Alam",
      "Marc T. Avey",
      "Monya Baker",
      "William J. Browne",
      "Alejandra Clark",
      "Innes C. Cuthill",
      "Ulrich Dirnagl",
      "Michael Emerson",
      "Paul Garner",
      "Stephen T. Holgate",
      "David W. Howells",
      "Natasha A. Karp",
      "Stanley E. Lazic",
      "Katie Lidster",
      "Catriona MacCallum",
      "Malcolm Macleod",
      "Esther J. Pearl",
      "Ole H. Petersen",
      "Frances Rawle",
      "Penny S. Reynolds",
      "Kieron Rooney",
      "Emily S. Sena",
      "Shai D. Silberberg",
      "Thomas Steckler",
      "Hanno W\u00fcrbel"
    ],
    "year": 2020,
    "abstract": "Abstract Reproducible science requires transparent reporting. The ARRIVE guidelines (Animal Research: Reporting of In Vivo Experiments) were originally developed in 2010 to improve the reporting of animal research. They consist of a checklist of information to include in publications describing in vivo experiments to enable others to scrutinise the work adequately, evaluate its methodological rigour, and reproduce the methods and results. Despite considerable levels of endorsement by funders and journals over the years, adherence to the guidelines has been inconsistent, and the anticipated improvements in the quality of reporting in animal research publications have not been achieved. Here, we introduce ARRIVE 2.0. The guidelines have been updated and information reorganised to facilitate their use in practice. We used a Delphi exercise to prioritise and divide the items of the guidelines into 2 sets, the \u2018ARRIVE Essential 10,\u2019 which constitutes the minimum requirement, and the \u2018Recommended Set,\u2019 which describes the research context. This division facilitates improved reporting of animal research by supporting a stepwise approach to implementation. This helps journal editors and reviewers verify that the most important items are being reported in manuscripts. We have also developed the accompanying Explanation and Elaboration document, which serves (1) to explain the rationale behind each item in the guidelines, (2) to clarify key concepts, and (3) to provide illustrative examples. We aim, through these changes, to help ensure that researchers, reviewers, and journal editors are better equipped to improve the rigour and transparency of the scientific process and thus reproducibility.",
    "doi": "10.1113/jp280389",
    "url": "https://openalex.org/W4253545088",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1113/JP280389",
    "venue": "The Journal of Physiology",
    "citation_count": 615,
    "fields_of_study": [
      "Rigour",
      "Checklist",
      "Transparency (behavior)",
      "Context (archaeology)",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:10.770050"
  },
  {
    "source": "openalex",
    "source_id": "W4386697749",
    "title": "A foundation model for generalizable disease detection from retinal images",
    "authors": [
      "Yukun Zhou",
      "Mark A. Chia",
      "Siegfried K. Wagner",
      "Murat Se\u00e7kin Ayhan",
      "Dominic J. Williamson",
      "Robbert Struyven",
      "Timing Liu",
      "Moucheng Xu",
      "Mateo Gende",
      "Peter Woodward-Court",
      "Yuka Kihara",
      "Naomi E. Allen",
      "John Gallacher",
      "Thomas J. Littlejohns",
      "Tariq Aslam",
      "Richard D. Unwin",
      "Graeme C. Black",
      "Panagiotis I. Sergouniotis",
      "Denize Atan",
      "Andrew D. Dick",
      "Cathy Williams",
      "Sarah Barman",
      "Jennifer H. Barrett",
      "Sarah Mackie",
      "Tasanee Braithwaite",
      "Roxana O. Carare",
      "Sarah Ennis",
      "Jane Whitney Gibson",
      "Andrew Lotery",
      "Jay Self",
      "Usha Chakravarthy",
      "Ruth Hogg",
      "Euan Paterson",
      "Jayne V. Woodside",
      "T\u00fcnde Pet\u0151",
      "Gareth J. McKay",
      "Bernadette McGuinness",
      "Paul J. Foster",
      "Konstantinos Balaskas",
      "Anthony P. Khawaja",
      "Nikolas Pontikos",
      "Jugnoo S. Rahi",
      "Gerassimos Lascaratos",
      "Praveen J. Patel",
      "Michelle Chan",
      "Sharon Chua",
      "Alexander Day",
      "Parul Desai",
      "Cathy Egan",
      "Marcus Fruttiger",
      "David F. Garway\u2010Heath",
      "Alison J. Hardcastle",
      "Peng T. Khaw",
      "Tony Moore",
      "Sobha Sivaprasad",
      "Nicholas G. Strouthidis",
      "Dhanes Thomas",
      "Adnan Tufail",
      "Ananth C. Viswanathan",
      "Bal Dhillon",
      "Tom MacGillivray",
      "Cathie Sudlow",
      "V\u00e9ronique Vitart",
      "Alex S. F. Doney",
      "Emanuele Trucco",
      "Jeremy A. Guggeinheim",
      "James P. Morgan",
      "Christopher J. Hammond",
      "Katie Williams",
      "Pirro G. Hysi",
      "Simon Harding",
      "Yalin Zheng",
      "Robert Luben",
      "Philip J. Luthert",
      "Zihan Sun",
      "Martin McKibbin",
      "Eoin O\u2019Sullivan",
      "Richard A. Oram",
      "Mike Weedon",
      "Christopher G. Owen",
      "Alicja R. Rudnicka",
      "Naveed Sattar",
      "David Steel",
      "Irene Stratton",
      "Robyn J. Tapp",
      "Max Yates",
      "Axel Petzold",
      "Savita Madhusudhan",
      "Andr\u00e9 Altmann",
      "Aaron Lee",
      "Eric J. Topol",
      "Alastair K. Denniston",
      "Daniel C. Alexander",
      "Pearse A. Keane"
    ],
    "year": 2023,
    "abstract": "Abstract Medical artificial intelligence (AI) offers great potential for recognizing signs of health conditions in retinal images and expediting the diagnosis of eye diseases and systemic disorders 1 . However, the development of AI models requires substantial annotation and models are usually task-specific with limited generalizability to different clinical applications 2 . Here, we present RETFound, a foundation model for retinal images that learns generalizable representations from unlabelled retinal images and provides a basis for label-efficient model adaptation in several applications. Specifically, RETFound is trained on 1.6 million unlabelled retinal images by means of self-supervised learning and then adapted to disease detection tasks with explicit labels. We show that adapted RETFound consistently outperforms several comparison models in the diagnosis and prognosis of sight-threatening eye diseases, as well as incident prediction of complex systemic disorders such as heart failure and myocardial infarction with fewer labelled data. RETFound provides a generalizable solution to improve model performance and alleviate the annotation workload of experts to enable broad clinical AI applications from retinal imaging.",
    "doi": "10.1038/s41586-023-06555-x",
    "url": "https://openalex.org/W4386697749",
    "pdf_url": "https://www.nature.com/articles/s41586-023-06555-x.pdf",
    "venue": "Nature",
    "citation_count": 663,
    "fields_of_study": [
      "Computer science",
      "Artificial intelligence",
      "Generalizability theory",
      "Retinal",
      "Machine learning"
    ],
    "retrieved_at": "2026-02-02T16:58:10.770099"
  },
  {
    "source": "openalex",
    "source_id": "W3011648816",
    "title": "Contributions and Risks of Artificial Intelligence (AI) in Building Smarter Cities: Insights from a Systematic Review of the Literature",
    "authors": [
      "Tan Yi\u011fitcanlar",
      "Kevin C. Desouza",
      "Luke Butler",
      "Farnoosh Roozkhosh"
    ],
    "year": 2020,
    "abstract": "Artificial intelligence (AI) is one of the most disruptive technologies of our time. Interest in the use of AI for urban innovation continues to grow. Particularly, the rise of smart cities\u2014urban locations that are enabled by community, technology, and policy to deliver productivity, innovation, livability, wellbeing, sustainability, accessibility, good governance, and good planning\u2014has increased the demand for AI-enabled innovations. There is, nevertheless, no scholarly work that provides a comprehensive review on the topic. This paper generates insights into how AI can contribute to the development of smarter cities. A systematic review of the literature is selected as the methodologic approach. Results are categorized under the main smart city development dimensions, i.e., economy, society, environment, and governance. The findings of the systematic review containing 93 articles disclose that: (a) AI in the context of smart cities is an emerging field of research and practice. (b) The central focus of the literature is on AI technologies, algorithms, and their current and prospective applications. (c) AI applications in the context of smart cities mainly concentrate on business efficiency, data analytics, education, energy, environmental sustainability, health, land use, security, transport, and urban management areas. (d) There is limited scholarly research investigating the risks of wider AI utilization. (e) Upcoming disruptions of AI in cities and societies have not been adequately examined. Current and potential contributions of AI to the development of smarter cities are outlined in this paper to inform scholars of prospective areas for further research.",
    "doi": "10.3390/en13061473",
    "url": "https://openalex.org/W3011648816",
    "pdf_url": "https://www.mdpi.com/1996-1073/13/6/1473/pdf?version=1585797303",
    "venue": "Energies",
    "citation_count": 474,
    "fields_of_study": [
      "Context (archaeology)",
      "Corporate governance",
      "Sustainability",
      "Smart city",
      "Systematic review"
    ],
    "retrieved_at": "2026-02-02T16:58:10.770131"
  },
  {
    "source": "openalex",
    "source_id": "W2972413052",
    "title": "Algorithmic management and app\u2010work in the gig economy: A research agenda for employment relations and HRM",
    "authors": [
      "James Duggan",
      "Ultan Sherman",
      "Ronan Carbery",
      "Anthony McDonnell"
    ],
    "year": 2019,
    "abstract": "Abstract Current understanding of what constitutes work in the growing gig economy is heavily conflated, ranging from conceptualisations of independent contracting to other forms of contingent labour. This article calls for a move away from problematic aggregations by proposing a classification of gig work into three variants, all based strongly upon key technological features: app\u2010work, crowdwork, and capital platform work. Focusing specifically on the app\u2010work variant, this article's more delineated focus on the textured dimensions of this work proposes new lines of enquiry into employment relationships and human resource management. Examining the crucial role of algorithmic management, we critically discuss the impact of this novel mediation tool used by gig organisations for the nature of employment relations within app\u2010work, work assignment processes, and performance management. In so doing, we propose a series of research questions that can serve as a guide for future research in this increasingly important field.",
    "doi": "10.1111/1748-8583.12258",
    "url": "https://openalex.org/W2972413052",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/1748-8583.12258",
    "venue": "Human Resource Management Journal",
    "citation_count": 780,
    "fields_of_study": [
      "Gig economy",
      "Work (physics)",
      "Conflation",
      "Mediation",
      "Human resource management"
    ],
    "retrieved_at": "2026-02-02T16:58:10.770181"
  },
  {
    "source": "openalex",
    "source_id": "W2973871066",
    "title": "Machine learning for clinical decision support in infectious diseases: a narrative review of current applications",
    "authors": [
      "Nathan Peiffer\u2010Smadja",
      "Timothy M. Rawson",
      "Raheelah Ahmad",
      "Albert Buchard",
      "Pantelis Georgiou",
      "Fran\u00e7ois-Xavier Lescure",
      "Gabriel Birgand",
      "Alison Holmes"
    ],
    "year": 2019,
    "abstract": "Considering comprehensive patient data from socioeconomically diverse healthcare settings, including primary care and LMICs, may improve the ability of ML-CDSS to suggest decisions adapted to various clinical contexts. Currents gaps identified in the evaluation of ML-CDSS must also be addressed in order to know the potential impact of such tools for clinicians and patients.",
    "doi": "10.1016/j.cmi.2019.09.009",
    "url": "https://openalex.org/W2973871066",
    "pdf_url": "http://www.clinicalmicrobiologyandinfection.com/article/S1198743X1930494X/pdf",
    "venue": "Clinical Microbiology and Infection",
    "citation_count": 505,
    "fields_of_study": [
      "Antimicrobial stewardship",
      "Clinical decision support system",
      "Medicine",
      "MEDLINE",
      "Sepsis"
    ],
    "retrieved_at": "2026-02-02T16:58:10.770210"
  },
  {
    "source": "openalex",
    "source_id": "W2969896603",
    "title": "A Survey on Bias and Fairness in Machine Learning",
    "authors": [
      "Ninareh Mehrabi",
      "Fred Morstatter",
      "Nripsuta Ani Saxena",
      "Kristina Lerman",
      "Aram Galstyan"
    ],
    "year": 2021,
    "abstract": "With the widespread use of artificial intelligence (AI) systems and applications in our everyday lives, accounting for fairness has gained significant importance in designing and engineering of such systems. AI systems can be used in many sensitive environments to make important and life-changing decisions; thus, it is crucial to ensure that these decisions do not reflect discriminatory behavior toward certain groups or populations. More recently some work has been developed in traditional machine learning and deep learning that address such challenges in different subdomains. With the commercialization of these systems, researchers are becoming more aware of the biases that these applications can contain and are attempting to address them. In this survey, we investigated different real-world applications that have shown biases in various ways, and we listed different sources of biases that can affect AI applications. We then created a taxonomy for fairness definitions that machine learning researchers have defined to avoid the existing bias in AI systems. In addition to that, we examined different domains and subdomains in AI showing what researchers have observed with regard to unfair outcomes in the state-of-the-art methods and ways they have tried to address them. There are still many future directions and solutions that can be taken to mitigate the problem of bias in AI systems. We are hoping that this survey will motivate researchers to tackle these issues in the near future by observing existing work in their respective fields.",
    "doi": "10.1145/3457607",
    "url": "https://openalex.org/W2969896603",
    "pdf_url": "https://arxiv.org/pdf/1908.09635",
    "venue": "ACM Computing Surveys",
    "citation_count": 316,
    "fields_of_study": [
      "Computer science",
      "Artificial intelligence",
      "Commercialization",
      "Data science",
      "Taxonomy (biology)"
    ],
    "retrieved_at": "2026-02-02T16:58:10.770220"
  },
  {
    "source": "openalex",
    "source_id": "W4386637335",
    "title": "Considerations for addressing bias in artificial intelligence for health equity",
    "authors": [
      "Michael D. Abr\u00e0moff",
      "Michelle E. Tarver",
      "Nilsa Loyo\u2010Berr\u00edos",
      "Sylvia Trujillo",
      "Danton Char",
      "Ziad Obermeyer",
      "Malvina Eydelman",
      "William H. Maisel"
    ],
    "year": 2023,
    "abstract": null,
    "doi": "10.1038/s41746-023-00913-9",
    "url": "https://openalex.org/W4386637335",
    "pdf_url": "https://www.nature.com/articles/s41746-023-00913-9.pdf",
    "venue": "npj Digital Medicine",
    "citation_count": 258,
    "fields_of_study": [
      "Equity (law)",
      "Health care",
      "Health equity",
      "Business",
      "Digital health"
    ],
    "retrieved_at": "2026-02-02T16:58:10.770243"
  },
  {
    "source": "openalex",
    "source_id": "W3026607820",
    "title": "Artificial intelligence ethics guidelines for developers and users: clarifying their content and normative implications",
    "authors": [
      "Mark Ryan",
      "Bernd Carsten Stahl"
    ],
    "year": 2020,
    "abstract": "Purpose The purpose of this paper is clearly illustrate this convergence and the prescriptive recommendations that such documents entail. There is a significant amount of research into the ethical consequences of artificial intelligence (AI). This is reflected by many outputs across academia, policy and the media. Many of these outputs aim to provide guidance to particular stakeholder groups. It has recently been shown that there is a large degree of convergence in terms of the principles upon which these guidance documents are based. Despite this convergence, it is not always clear how these principles are to be translated into practice. Design/methodology/approach In this paper, the authors move beyond the high-level ethical principles that are common across the AI ethics guidance literature and provide a description of the normative content that is covered by these principles. The outcome is a comprehensive compilation of normative requirements arising from existing guidance documents. This is not only required for a deeper theoretical understanding of AI ethics discussions but also for the creation of practical and implementable guidance for developers and users of AI. Findings In this paper, the authors therefore provide a detailed explanation of the normative implications of existing AI ethics guidelines but directed towards developers and organisational users of AI. The authors believe that the paper provides the most comprehensive account of ethical requirements in AI currently available, which is of interest not only to the research and policy communities engaged in the topic but also to the user communities that require guidance when developing or deploying AI systems. Originality/value The authors believe that they have managed to compile the most comprehensive document collecting existing guidance which can guide practical action but will hopefully also support the consolidation of the guidelines landscape. The authors\u2019 findings should also be of academic interest and inspire philosophical research on the consistency and justification of the various normative statements that can be found in the literature.",
    "doi": "10.1108/jices-12-2019-0138",
    "url": "https://openalex.org/W3026607820",
    "pdf_url": "https://www.emerald.com/insight/content/doi/10.1108/JICES-12-2019-0138/full/pdf?title=artificial-intelligence-ethics-guidelines-for-developers-and-users-clarifying-their-content-and-normative-implications",
    "venue": "Journal of Information Communication and Ethics in Society",
    "citation_count": 253,
    "fields_of_study": [
      "Normative",
      "Stakeholder",
      "Computer science",
      "Engineering ethics",
      "Convergence (economics)"
    ],
    "retrieved_at": "2026-02-02T16:58:10.770247"
  },
  {
    "source": "openalex",
    "source_id": "W4376643691",
    "title": "Biases in Large Language Models: Origins, Inventory, and Discussion",
    "authors": [
      "Roberto Navigli",
      "Simone Conia",
      "Bj\u00f6rn Ro\u00df"
    ],
    "year": 2023,
    "abstract": "In this article, we introduce and discuss the pervasive issue of bias in the large language models that are currently at the core of mainstream approaches to Natural Language Processing (NLP). We first introduce data selection bias, that is, the bias caused by the choice of texts that make up a training corpus. Then, we survey the different types of social bias evidenced in the text generated by language models trained on such corpora, ranging from gender to age, from sexual orientation to ethnicity, and from religion to culture. We conclude with directions focused on measuring, reducing, and tackling the aforementioned types of bias.",
    "doi": "10.1145/3597307",
    "url": "https://openalex.org/W4376643691",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3597307",
    "venue": "Journal of Data and Information Quality",
    "citation_count": 267,
    "fields_of_study": [
      "Computer science",
      "Mainstream",
      "Natural language processing",
      "Gender bias",
      "Selection (genetic algorithm)"
    ],
    "retrieved_at": "2026-02-02T16:58:10.770276"
  },
  {
    "source": "openalex",
    "source_id": "W4292731246",
    "title": "The uselessness of AI ethics",
    "authors": [
      "Luke Munn"
    ],
    "year": 2022,
    "abstract": "Abstract As the awareness of AI\u2019s power and danger has risen, the dominant response has been a turn to ethical principles. A flood of AI guidelines and codes of ethics have been released in both the public and private sector in the last several years. However, these are meaningless principles which are contested or incoherent, making them difficult to apply; they are isolated principles situated in an industry and education system which largely ignores ethics; and they are toothless principles which lack consequences and adhere to corporate agendas. For these reasons, I argue that AI ethical principles are useless, failing to mitigate the racial, social, and environmental damages of AI technologies in any meaningful sense. The result is a gap between high-minded principles and technological practice. Even when this gap is acknowledged and principles seek to be \u201coperationalized,\u201d the translation from complex social concepts to technical rulesets is non-trivial. In a zero-sum world, the dominant turn to AI principles is not just fruitless but a dangerous distraction, diverting immense financial and human resources away from potentially more effective activity. I conclude by highlighting alternative approaches to AI justice that go beyond ethical principles: thinking more broadly about systems of oppression and more narrowly about accuracy and auditing.",
    "doi": "10.1007/s43681-022-00209-w",
    "url": "https://openalex.org/W4292731246",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s43681-022-00209-w.pdf",
    "venue": "AI and Ethics",
    "citation_count": 271,
    "fields_of_study": [
      "Operationalization",
      "Oppression",
      "Engineering ethics",
      "Sociology",
      "Environmental ethics"
    ],
    "retrieved_at": "2026-02-02T16:58:10.770287"
  },
  {
    "source": "openalex",
    "source_id": "W3020975691",
    "title": "Explainable Deep Learning: A Field Guide for the Uninitiated",
    "authors": [
      "Gabri\u00eblle Ras",
      "Ning Xie",
      "Marcel van Gerven",
      "Derek Doran"
    ],
    "year": 2022,
    "abstract": "Deep neural networks (DNNs) are an indispensable machine learning tool despite the difficulty of diagnosing what aspects of a model\u2019s input drive its decisions. In countless real-world domains, from legislation and law enforcement to healthcare, such diagnosis is essential to ensure that DNN decisions are driven by aspects appropriate in the context of its use. The development of methods and studies enabling the explanation of a DNN\u2019s decisions has thus blossomed into an active and broad area of research. The field\u2019s complexity is exacerbated by competing definitions of what it means \u201cto explain\u201d the actions of a DNN and to evaluate an approach\u2019s \u201cability to explain\u201d. This article offers a field guide to explore the space of explainable deep learning for those in the AI/ML field who are uninitiated. The field guide: i) Introduces three simple dimensions defining the space of foundational methods that contribute to explainable deep learning, ii) discusses the evaluations for model explanations, iii) places explainability in the context of other related deep learning research areas, and iv) discusses user-oriented explanation design and future directions. We hope the guide is seen as a starting point for those embarking on this research field.",
    "doi": "10.1613/jair.1.13200",
    "url": "https://openalex.org/W3020975691",
    "pdf_url": "https://www.jair.org/index.php/jair/article/download/13200/26763",
    "venue": "Journal of Artificial Intelligence Research",
    "citation_count": 383,
    "fields_of_study": [
      "Field (mathematics)",
      "Deep learning",
      "Context (archaeology)",
      "Artificial intelligence",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:10.770306"
  },
  {
    "source": "openalex",
    "source_id": "W3025490408",
    "title": "AI for social good: unlocking the opportunity for positive impact",
    "authors": [
      "Nenad Toma\u0161ev",
      "Julien Cornebise",
      "Frank Hutter",
      "Shakir Mohamed",
      "Angela Picciariello",
      "Bec Connelly",
      "Danielle Belgrave",
      "Daphne Ezer",
      "Fanny Cachat van der Haert",
      "Frank Mugisha",
      "Gerald Abila",
      "Hiromi Arai",
      "Hisham Almiraat",
      "Julia Proskurnia",
      "Kyle Snyder",
      "Mihoko Otake",
      "Mustafa Othman",
      "Tobias Glasmachers",
      "Wilfried De Wever",
      "Yee Whye Teh",
      "Mohammad Emtiyaz Khan",
      "Ruben De Winne",
      "Tom Schaul",
      "Claudia Clopath"
    ],
    "year": 2020,
    "abstract": null,
    "doi": "10.1038/s41467-020-15871-z",
    "url": "https://openalex.org/W3025490408",
    "pdf_url": "https://www.nature.com/articles/s41467-020-15871-z.pdf",
    "venue": "Nature Communications",
    "citation_count": 313,
    "fields_of_study": [
      "Computer science",
      "Domain (mathematical analysis)",
      "Set (abstract data type)",
      "Sustainable development",
      "Key (lock)"
    ],
    "retrieved_at": "2026-02-02T16:58:10.770326"
  },
  {
    "source": "openalex",
    "source_id": "W4380319827",
    "title": "Regulating ChatGPT and other Large Generative AI Models",
    "authors": [
      "Philipp Hacker",
      "Andreas Engel",
      "Marco Mauer"
    ],
    "year": 2023,
    "abstract": "Large generative AI models (LGAIMs), such as ChatGPT, GPT-4 or Stable Diffusion, are rapidly transforming the way we communicate, illustrate, and create. However, AI regulation, in the EU and beyond, has primarily focused on conventional AI models, not LGAIMs. This paper will situate these new generative models in the current debate on trustworthy AI regulation, and ask how the law can be tailored to their capabilities. After laying technical foundations, the legal part of the paper proceeds in four steps, covering (1) direct regulation, (2) data protection, (3) content moderation, and (4) policy proposals. It suggests a novel terminology to capture the AI value chain in LGAIM settings by differentiating between LGAIM developers, deployers, professional and non-professional users, as well as recipients of LGAIM output. We tailor regulatory duties to these different actors along the value chain and suggest strategies to ensure that LGAIMs are trustworthy and deployed for the benefit of society at large. Rules in the AI Act and other direct regulation must match the specificities of pre-trained models. The paper argues for three layers of obligations concerning LGAIMs (minimum standards for all LGAIMs; high-risk obligations for high-risk use cases; collaborations along the AI value chain). In general, regulation should focus on concrete high-risk applications, and not the pre-trained model itself, and should include (i) obligations regarding transparency and (ii) risk management. Non-discrimination provisions (iii) may, however, apply to LGAIM developers. Lastly, (iv) the core of the DSA's content moderation rules should be expanded to cover LGAIMs. This includes notice and action mechanisms, and trusted flaggers.",
    "doi": "10.1145/3593013.3594067",
    "url": "https://openalex.org/W4380319827",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3593013.3594067",
    "venue": null,
    "citation_count": 376,
    "fields_of_study": [
      "Transparency (behavior)",
      "Generative grammar",
      "Computer science",
      "Terminology",
      "Generative model"
    ],
    "retrieved_at": "2026-02-02T16:58:10.770329"
  },
  {
    "source": "openalex",
    "source_id": "W3092843175",
    "title": "The Sustainability of Artificial Intelligence: An Urbanistic Viewpoint from the Lens of Smart and Sustainable Cities",
    "authors": [
      "Tan Yi\u011fitcanlar",
      "Federico Cugurullo"
    ],
    "year": 2020,
    "abstract": "The popularity and application of artificial intelligence (AI) are increasing rapidly all around the world\u2014where, in simple terms, AI is a technology which mimics the behaviors commonly associated with human intelligence. Today, various AI applications are being used in areas ranging from marketing to banking and finance, from agriculture to healthcare and security, from space exploration to robotics and transport, and from chatbots to artificial creativity and manufacturing. More recently, AI applications have also started to become an integral part of many urban services. Urban artificial intelligences manage the transport systems of cities, run restaurants and shops where every day urbanity is expressed, repair urban infrastructure, and govern multiple urban domains such as traffic, air quality monitoring, garbage collection, and energy. In the age of uncertainty and complexity that is upon us, the increasing adoption of AI is expected to continue, and so its impact on the sustainability of our cities. This viewpoint explores and questions the sustainability of AI from the lens of smart and sustainable cities, and generates insights into emerging urban artificial intelligences and the potential symbiosis between AI and a smart and sustainable urbanism. In terms of methodology, this viewpoint deploys a thorough review of the current status of AI and smart and sustainable cities literature, research, developments, trends, and applications. In so doing, it contributes to existing academic debates in the fields of smart and sustainable cities and AI. In addition, by shedding light on the uptake of AI in cities, the viewpoint seeks to help urban policymakers, planners, and citizens make informed decisions about a sustainable adoption of AI.",
    "doi": "10.3390/su12208548",
    "url": "https://openalex.org/W3092843175",
    "pdf_url": "https://www.mdpi.com/2071-1050/12/20/8548/pdf?version=1602816385",
    "venue": "Sustainability",
    "citation_count": 289,
    "fields_of_study": [
      "Sustainability",
      "Popularity",
      "Creativity",
      "Smart city",
      "Sustainable city"
    ],
    "retrieved_at": "2026-02-02T16:58:10.770351"
  },
  {
    "source": "openalex",
    "source_id": "W4229441880",
    "title": "Integrating Ethics and Career Futures with Technical Learning to Promote AI Literacy for Middle School Students: An Exploratory Study",
    "authors": [
      "Helen Zhang",
      "Irene Lee",
      "Safinah Ali",
      "Daniella DiPaola",
      "Yihong Cheng",
      "Cynthia Breazeal"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1007/s40593-022-00293-3",
    "url": "https://openalex.org/W4229441880",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s40593-022-00293-3.pdf",
    "venue": "International Journal of Artificial Intelligence in Education",
    "citation_count": 290,
    "fields_of_study": [
      "Futures contract",
      "Educational technology",
      "Exploratory research",
      "Literacy",
      "Mathematics education"
    ],
    "retrieved_at": "2026-02-02T16:58:10.770374"
  },
  {
    "source": "openalex",
    "source_id": "W4389359039",
    "title": "Generative artificial intelligence",
    "authors": [
      "Leonardo Banh",
      "Gero Strobel"
    ],
    "year": 2023,
    "abstract": null,
    "doi": "10.1007/s12525-023-00680-1",
    "url": "https://openalex.org/W4389359039",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s12525-023-00680-1.pdf",
    "venue": "Electronic Markets",
    "citation_count": 312,
    "fields_of_study": [
      "Generative grammar",
      "Computer science",
      "Artificial intelligence",
      "Field (mathematics)",
      "Generative model"
    ],
    "retrieved_at": "2026-02-02T16:58:10.770377"
  },
  {
    "source": "openalex",
    "source_id": "W4390608362",
    "title": "Transformative Potential of AI in Healthcare: Definitions, Applications, and Navigating the Ethical Landscape and Public Perspectives",
    "authors": [
      "Molly Bekbolatova",
      "Jonathan Mayer",
      "Chi Wei Ong",
      "Milan Toma"
    ],
    "year": 2024,
    "abstract": "Artificial intelligence (AI) has emerged as a crucial tool in healthcare with the primary aim of improving patient outcomes and optimizing healthcare delivery. By harnessing machine learning algorithms, natural language processing, and computer vision, AI enables the analysis of complex medical data. The integration of AI into healthcare systems aims to support clinicians, personalize patient care, and enhance population health, all while addressing the challenges posed by rising costs and limited resources. As a subdivision of computer science, AI focuses on the development of advanced algorithms capable of performing complex tasks that were once reliant on human intelligence. The ultimate goal is to achieve human-level performance with improved efficiency and accuracy in problem-solving and task execution, thereby reducing the need for human intervention. Various industries, including engineering, media/entertainment, finance, and education, have already reaped significant benefits by incorporating AI systems into their operations. Notably, the healthcare sector has witnessed rapid growth in the utilization of AI technology. Nevertheless, there remains untapped potential for AI to truly revolutionize the industry. It is important to note that despite concerns about job displacement, AI in healthcare should not be viewed as a threat to human workers. Instead, AI systems are designed to augment and support healthcare professionals, freeing up their time to focus on more complex and critical tasks. By automating routine and repetitive tasks, AI can alleviate the burden on healthcare professionals, allowing them to dedicate more attention to patient care and meaningful interactions. However, legal and ethical challenges must be addressed when embracing AI technology in medicine, alongside comprehensive public education to ensure widespread acceptance.",
    "doi": "10.3390/healthcare12020125",
    "url": "https://openalex.org/W4390608362",
    "pdf_url": "https://www.mdpi.com/2227-9032/12/2/125/pdf?version=1704440667",
    "venue": "Healthcare",
    "citation_count": 309,
    "fields_of_study": [
      "Transformative learning",
      "Health care",
      "Computer science",
      "Artificial intelligence",
      "Knowledge management"
    ],
    "retrieved_at": "2026-02-02T16:58:10.770380"
  },
  {
    "source": "openalex",
    "source_id": "W4386223224",
    "title": "Artificial intelligence in intelligent tutoring systems toward sustainable education: a systematic review",
    "authors": [
      "Chien-Chang Lin",
      "Anna Y.Q. Huang",
      "Owen H.T. Lu"
    ],
    "year": 2023,
    "abstract": null,
    "doi": "10.1186/s40561-023-00260-y",
    "url": "https://openalex.org/W4386223224",
    "pdf_url": "https://slejournal.springeropen.com/counter/pdf/10.1186/s40561-023-00260-y",
    "venue": "Smart Learning Environments",
    "citation_count": 359,
    "fields_of_study": [
      "Software deployment",
      "Computer science",
      "Knowledge management",
      "Sustainable development",
      "Political science"
    ],
    "retrieved_at": "2026-02-02T16:58:10.770402"
  },
  {
    "source": "openalex",
    "source_id": "W3037647569",
    "title": "Artificial intelligence in health care: laying the Foundation for Responsible, sustainable, and inclusive innovation in low- and middle-income countries",
    "authors": [
      "Hassane Alami",
      "Lysanne Rivard",
      "Pascale Lehoux",
      "Steven J. Hoffman",
      "St\u00e9phanie B.M. Cadeddu",
      "Mathilde Savoldelli",
      "M. Samri",
      "Mohamed Ali Ag Ahmed",
      "Richard Fleet",
      "Jean\u2010Paul Fortin"
    ],
    "year": 2020,
    "abstract": "Abstract The World Health Organization and other institutions are considering Artificial Intelligence (AI) as a technology that can potentially address some health system gaps, especially the reduction of global health inequalities in low- and middle-income countries (LMICs). However, because most AI-based health applications are developed and implemented in high-income countries, their use in LMICs contexts is recent and there is a lack of robust local evaluations to guide decision-making in low-resource settings. After discussing the potential benefits as well as the risks and challenges raised by AI-based health care, we propose five building blocks to guide the development and implementation of more responsible, sustainable, and inclusive AI health care technologies in LMICs.",
    "doi": "10.1186/s12992-020-00584-1",
    "url": "https://openalex.org/W3037647569",
    "pdf_url": "https://globalizationandhealth.biomedcentral.com/track/pdf/10.1186/s12992-020-00584-1",
    "venue": "Globalization and Health",
    "citation_count": 241,
    "fields_of_study": [
      "Low and middle income countries",
      "Health care",
      "Health services research",
      "Public health",
      "Global health"
    ],
    "retrieved_at": "2026-02-02T16:58:10.770406"
  },
  {
    "source": "openalex",
    "source_id": "W2948100573",
    "title": "The Challenges of Algorithm-Based HR Decision-Making for Personal Integrity",
    "authors": [
      "Ulrich Leicht\u2010Deobald",
      "Thorsten Busch",
      "Christoph Schank",
      "Antoinette Weibel",
      "Simon Daniel Schafheitle",
      "Isabelle Wildhaber",
      "Gabriel Kasper"
    ],
    "year": 2019,
    "abstract": null,
    "doi": "10.1007/s10551-019-04204-w",
    "url": "https://openalex.org/W2948100573",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10551-019-04204-w.pdf",
    "venue": "Journal of Business Ethics",
    "citation_count": 252,
    "fields_of_study": [
      "Business ethics",
      "Quality of Life Research",
      "Intersection (aeronautics)",
      "Compliance (psychology)",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:11.621954"
  },
  {
    "source": "openalex",
    "source_id": "W3207559276",
    "title": "The AI gambit: leveraging artificial intelligence to combat climate change\u2014opportunities, challenges, and recommendations",
    "authors": [
      "Josh Cowls",
      "Andreas Tsamados",
      "Mariarosaria Taddeo",
      "Luciano Floridi"
    ],
    "year": 2021,
    "abstract": null,
    "doi": "10.1007/s00146-021-01294-x",
    "url": "https://openalex.org/W3207559276",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s00146-021-01294-x.pdf",
    "venue": "AI & Society",
    "citation_count": 376,
    "fields_of_study": [
      "Greenhouse gas",
      "Climate change",
      "Carbon footprint",
      "European union",
      "Corporate governance"
    ],
    "retrieved_at": "2026-02-02T16:58:11.621968"
  },
  {
    "source": "openalex",
    "source_id": "W4387397415",
    "title": "Artificial intelligence \u2010 driven sustainable development: Examining organizational, technical, and processing approaches to achieving global goals",
    "authors": [
      "Ignat Kulkov",
      "Julia Kulkova",
      "Ren\u00e9 Rohrbeck",
      "Lo\u00efck Menvielle",
      "Valtteri Kaartemo",
      "Hannu Makkonen"
    ],
    "year": 2023,
    "abstract": "Abstract This study presents a comprehensive literature review using a systematic approach to explore the role of artificial intelligence (AI) in promoting sustainable development in line with the United Nations Sustainable Development Goals (SDGs). The systematic review approach was applied to collect and analyze topics, and the literature search was conducted in two stages, encompassing 57 articles that met the research requirements. Our analysis reveals that AI's contribution to sustainability is concentrated within three key areas: organizational, technical, and processing aspects. The organizational aspect focuses on the integration of AI in companies and industries, addressing barriers to implementation and the relationship between companies, partners, and customers. The technical aspect highlights the development of AI algorithms that can address global challenges and contribute to the growth of stability and development in society. The processing aspect emphasizes the internal transformation of companies, their business models, and strategies in response to AI integration. Our proposed conceptual model outlines the essential elements organizations must consider when incorporating AI into their sustainability efforts, such as strategic alignment, infrastructure development, change management, and continuous improvement. By addressing these critical aspects, organizations can harness the potential of AI to drive positive social, environmental, and economic outcomes, ultimately contributing to the achievement of the SDGs. The model serves as a comprehensive framework for organizations seeking to leverage AI for sustainable development, but it should be adapted to individual contexts to ensure its relevance and effectiveness.",
    "doi": "10.1002/sd.2773",
    "url": "https://openalex.org/W4387397415",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/sd.2773",
    "venue": "Sustainable Development",
    "citation_count": 264,
    "fields_of_study": [
      "Sustainable development",
      "Sustainability",
      "Leverage (statistics)",
      "Knowledge management",
      "Process management"
    ],
    "retrieved_at": "2026-02-02T16:58:11.621972"
  },
  {
    "source": "openalex",
    "source_id": "W3049452588",
    "title": "The National COVID Cohort Collaborative (N3C): Rationale, design, infrastructure, and deployment",
    "authors": [
      "Melissa Haendel",
      "Christopher G. Chute",
      "Tellen D. Bennett",
      "David Eichmann",
      "Justin Guinney",
      "Warren A. Kibbe",
      "Philip Payne",
      "Emily Pfaff",
      "Peter N. Robinson",
      "Joel Saltz",
      "Heidi Spratt",
      "Christine Suver",
      "John Wilbanks",
      "Adam Wilcox",
      "Andrew E. Williams",
      "Chunlei Wu",
      "Clair Blacketer",
      "Robert L. Bradford",
      "James J. Cimino",
      "Marshall Clark",
      "Evan W Colmenares",
      "Patricia A. Francis",
      "Davera Gabriel",
      "Alexis Graves",
      "Raju Hemadri",
      "Stephanie Hong",
      "George Hripscak",
      "Dazhi Jiao",
      "Jeffrey G. Klann",
      "Kristin Kostka",
      "Adam M Lee",
      "Harold P. Lehmann",
      "Lora Lingrey",
      "Robert Miller",
      "Michele Morris",
      "Shawn N. Murphy",
      "Karthik Natarajan",
      "Matvey B. Palchuk",
      "Usman Ullah Sheikh",
      "Harold R. Solbrig",
      "Shyam Visweswaran",
      "Anita Walden",
      "Kellie M Walters",
      "Griffin M. Weber",
      "Xiaohan Tanner Zhang",
      "Richard L. Zhu",
      "Benjamin Amor",
      "Andrew T. Girvin",
      "Amin Manna",
      "Nabeel Qureshi",
      "Michael G. Kurilla",
      "Sam Michael",
      "Lili Portilla",
      "Joni L. Rutter",
      "Christopher P. Austin",
      "Kenneth Gersing"
    ],
    "year": 2020,
    "abstract": "Abstract Objective Coronavirus disease 2019 (COVID-19) poses societal challenges that require expeditious data and knowledge sharing. Though organizational clinical data are abundant, these are largely inaccessible to outside researchers. Statistical, machine learning, and causal analyses are most successful with large-scale data beyond what is available in any given organization. Here, we introduce the National COVID Cohort Collaborative (N3C), an open science community focused on analyzing patient-level data from many centers. Materials and Methods The Clinical and Translational Science Award Program and scientific community created N3C to overcome technical, regulatory, policy, and governance barriers to sharing and harmonizing individual-level clinical data. We developed solutions to extract, aggregate, and harmonize data across organizations and data models, and created a secure data enclave to enable efficient, transparent, and reproducible collaborative analytics. Results Organized in inclusive workstreams, we created legal agreements and governance for organizations and researchers; data extraction scripts to identify and ingest positive, negative, and possible COVID-19 cases; a data quality assurance and harmonization pipeline to create a single harmonized dataset; population of the secure data enclave with data, machine learning, and statistical analytics tools; dissemination mechanisms; and a synthetic data pilot to democratize data access. Conclusions The N3C has demonstrated that a multisite collaborative learning health network can overcome barriers to rapidly build a scalable infrastructure incorporating multiorganizational clinical data for COVID-19 analytics. We expect this effort to save lives by enabling rapid collaboration among clinicians, researchers, and data scientists to identify treatments and specialized care and thereby reduce the immediate and long-term impacts of COVID-19.",
    "doi": "10.1093/jamia/ocaa196",
    "url": "https://openalex.org/W3049452588",
    "pdf_url": "https://academic.oup.com/jamia/article-pdf/28/3/427/37306721/ocaa196.pdf",
    "venue": "Journal of the American Medical Informatics Association",
    "citation_count": 565,
    "fields_of_study": [
      "Computer science",
      "Analytics",
      "Data governance",
      "Data sharing",
      "Data science"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622015"
  },
  {
    "source": "openalex",
    "source_id": "W4387457231",
    "title": "Harnessing the power of synthetic data in healthcare: innovation, application, and privacy",
    "authors": [
      "Mauro Giuffr\u00e8",
      "Dennis Shung"
    ],
    "year": 2023,
    "abstract": null,
    "doi": "10.1038/s41746-023-00927-3",
    "url": "https://openalex.org/W4387457231",
    "pdf_url": "https://www.nature.com/articles/s41746-023-00927-3.pdf",
    "venue": "npj Digital Medicine",
    "citation_count": 283,
    "fields_of_study": [
      "Big data",
      "Distrust",
      "Accountability",
      "Context (archaeology)",
      "Health care"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622041"
  },
  {
    "source": "openalex",
    "source_id": "W4220980752",
    "title": "The Role of Artificial Intelligence in Early Cancer Diagnosis",
    "authors": [
      "Benjamin Hunter",
      "Sumeet Hindocha",
      "Richard W. Lee"
    ],
    "year": 2022,
    "abstract": "Improving the proportion of patients diagnosed with early-stage cancer is a key priority of the World Health Organisation. In many tumour groups, screening programmes have led to improvements in survival, but patient selection and risk stratification are key challenges. In addition, there are concerns about limited diagnostic workforces, particularly in light of the COVID-19 pandemic, placing a strain on pathology and radiology services. In this review, we discuss how artificial intelligence algorithms could assist clinicians in (1) screening asymptomatic patients at risk of cancer, (2) investigating and triaging symptomatic patients, and (3) more effectively diagnosing cancer recurrence. We provide an overview of the main artificial intelligence approaches, including historical models such as logistic regression, as well as deep learning and neural networks, and highlight their early diagnosis applications. Many data types are suitable for computational analysis, including electronic healthcare records, diagnostic images, pathology slides and peripheral blood, and we provide examples of how these data can be utilised to diagnose cancer. We also discuss the potential clinical implications for artificial intelligence algorithms, including an overview of models currently used in clinical practice. Finally, we discuss the potential limitations and pitfalls, including ethical concerns, resource demands, data security and reporting standards.",
    "doi": "10.3390/cancers14061524",
    "url": "https://openalex.org/W4220980752",
    "pdf_url": "https://www.mdpi.com/2072-6694/14/6/1524/pdf?version=1647426117",
    "venue": "Cancers",
    "citation_count": 297,
    "fields_of_study": [
      "Artificial intelligence",
      "Medicine",
      "Computer science",
      "Data science",
      "Intensive care medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622043"
  },
  {
    "source": "openalex",
    "source_id": "W4392772072",
    "title": "AI in education: A review of personalized learning and educational technology",
    "authors": [
      "Oyebola Olusola Ayeni",
      "Nancy Mohd Al Hamad",
      "Onyebuchi Nneamaka Chisom",
      "Blessing Osawaru",
      "Ololade Elizabeth Adewusi"
    ],
    "year": 2024,
    "abstract": "The integration of Artificial Intelligence (AI) in education has ushered in a transformative era, redefining traditional teaching and learning methods. This review explores the multifaceted role of AI in education, with a particular focus on personalized learning and educational technology. The synergy between AI and education promises to address individualized needs, enhance student engagement, and optimize learning outcomes. Personalized learning, enabled by AI algorithms, tailors educational experiences to the unique needs, preferences, and pace of each student. This approach goes beyond a one-size-fits-all model, fostering a more inclusive and effective learning environment. The review delves into the diverse applications of AI-driven personalized learning, ranging from adaptive content delivery and real-time feedback to intelligent tutoring systems. It analyzes the impact of these technologies on student performance, highlighting the potential to narrow educational gaps and cater to diverse learning styles. Educational technology, powered by AI, extends beyond the classroom, encompassing online platforms, virtual reality, and interactive tools. The review explores the integration of AI in curriculum development, content creation, and assessment methods, offering insights into how these technologies augment the teaching and learning experience. Furthermore, the review examines the role of AI in automating administrative tasks, allowing educators to redirect their focus towards personalized instruction. Challenges and ethical considerations associated with the adoption of AI in education are also scrutinized. Privacy concerns, algorithmic biases, and the digital divide are discussed, emphasizing the importance of responsible AI implementation. The review underscores the need for collaborative efforts among educators, policymakers, and technologists to establish ethical guidelines and ensure the equitable distribution of AI-enhanced educational resources. This review provides a comprehensive examination of the evolving landscape of AI in education, with a spotlight on personalized learning and educational technology. As the symbiosis between AI and education continues to evolve, this synthesis of current research and trends aims to guide future developments, fostering an informed and progressive approach to the integration of AI in the educational sphere.",
    "doi": "10.30574/gscarr.2024.18.2.0062",
    "url": "https://openalex.org/W4392772072",
    "pdf_url": "https://gsconlinepress.com/journals/gscarr/sites/default/files/GSCARR-2024-0062.pdf",
    "venue": "GSC Advanced Research and Reviews",
    "citation_count": 276,
    "fields_of_study": [
      "Personalized learning",
      "Mathematics education",
      "Educational technology",
      "Computer science",
      "Psychology"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622060"
  },
  {
    "source": "openalex",
    "source_id": "W3081423662",
    "title": "Artificial intelligence in radiation oncology",
    "authors": [
      "Elizabeth Huynh",
      "Ahmed Hosny",
      "Christian V. Guthier",
      "Danielle S. Bitterman",
      "Steven Petit",
      "Daphne A. Haas\u2010Kogan",
      "Benjamin H. Kann",
      "Hugo J.W.L. Aerts",
      "Raymond H. Mak"
    ],
    "year": 2020,
    "abstract": null,
    "doi": "10.1038/s41571-020-0417-8",
    "url": "https://openalex.org/W3081423662",
    "pdf_url": "https://www.nature.com/articles/s41571-020-0417-8.pdf",
    "venue": "Nature Reviews Clinical Oncology",
    "citation_count": 373,
    "fields_of_study": [
      "Radiation oncology",
      "Medical physics",
      "Medicine",
      "Oncology",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622087"
  },
  {
    "source": "openalex",
    "source_id": "W4387340031",
    "title": "A Systematic Review of the Barriers to the Implementation of Artificial Intelligence in Healthcare",
    "authors": [
      "Molla Imaduddin Ahmed",
      "Brendan Spooner",
      "John Isherwood",
      "Mark A. Lane",
      "Emma Orrock",
      "Ashley R. Dennison"
    ],
    "year": 2023,
    "abstract": null,
    "doi": "10.7759/cureus.46454",
    "url": "https://openalex.org/W4387340031",
    "pdf_url": "https://assets.cureus.com/uploads/review_article/pdf/170025/20231004-24282-g79tke.pdf",
    "venue": "Cureus",
    "citation_count": 255,
    "fields_of_study": [
      "Health care",
      "Medicine",
      "Covert",
      "Healthcare delivery",
      "Workforce"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622090"
  },
  {
    "source": "openalex",
    "source_id": "W4200045082",
    "title": "AI in marketing, consumer research and psychology: A systematic literature review and research agenda",
    "authors": [
      "Marcello M. Mariani",
      "Rodrigo Perez\u2010Vega",
      "Jochen Wirtz"
    ],
    "year": 2021,
    "abstract": "Abstract This study is the first to provide an integrated view on the body of knowledge of artificial intelligence (AI) published in the marketing, consumer research, and psychology literature. By leveraging a systematic literature review using a data\u2010driven approach and quantitative methodology (including bibliographic coupling), this study provides an overview of the emerging intellectual structure of AI research in the three bodies of literature examined. We identified eight topical clusters: (1) memory and computational logic; (2) decision making and cognitive processes; (3) neural networks; (4) machine learning and linguistic analysis; (5) social media and text mining; (6) social media content analytics; (7) technology acceptance and adoption; and (8) big data and robots. Furthermore, we identified a total of 412 theoretical lenses used in these studies with the most frequently used being: (1) the unified theory of acceptance and use of technology; (2) game theory; (3) theory of mind; (4) theory of planned behavior; (5) computational theories; (6) behavioral reasoning theory; (7) decision theories; and (8) evolutionary theory. Finally, we propose a research agenda to advance the scholarly debate on AI in the three literatures studied with an emphasis on cross\u2010fertilization of theories used across fields, and neglected research topics.",
    "doi": "10.1002/mar.21619",
    "url": "https://openalex.org/W4200045082",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/mar.21619",
    "venue": "Psychology and Marketing",
    "citation_count": 484,
    "fields_of_study": [
      "Big data",
      "Consumer behaviour",
      "Social media",
      "Psychology",
      "Cognition"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622093"
  },
  {
    "source": "openalex",
    "source_id": "W4389636360",
    "title": "Can Large Language Models Transform Computational Social Science?",
    "authors": [
      "Caleb Ziems",
      "William A. Held",
      "Omar Ahmed Shaikh",
      "Jiaao Chen",
      "Zhehao Zhang",
      "Diyi Yang"
    ],
    "year": 2023,
    "abstract": "Abstract Large language models (LLMs) are capable of successfully performing many language processing tasks zero-shot (without training data). If zero-shot LLMs can also reliably classify and explain social phenomena like persuasiveness and political ideology, then LLMs could augment the computational social science (CSS) pipeline in important ways. This work provides a road map for using LLMs as CSS tools. Towards this end, we contribute a set of prompting best practices and an extensive evaluation pipeline to measure the zero-shot performance of 13 language models on 25 representative English CSS benchmarks. On taxonomic labeling tasks (classification), LLMs fail to outperform the best fine-tuned models but still achieve fair levels of agreement with humans. On free-form coding tasks (generation), LLMs produce explanations that often exceed the quality of crowdworkers\u2019 gold references. We conclude that the performance of today\u2019s LLMs can augment the CSS research pipeline in two ways: (1) serving as zero-shot data annotators on human annotation teams, and (2) bootstrapping challenging creative generation tasks (e.g., explaining the underlying attributes of a text). In summary, LLMs are posed to meaningfully participate in social science analysis in partnership with humans.",
    "doi": "10.1162/coli_a_00502",
    "url": "https://openalex.org/W4389636360",
    "pdf_url": "https://direct.mit.edu/coli/article-pdf/doi/10.1162/coli_a_00502/2191886/coli_a_00502.pdf",
    "venue": "Computational Linguistics",
    "citation_count": 354,
    "fields_of_study": [
      "Pipeline (software)",
      "Computer science",
      "Bootstrapping (finance)",
      "Set (abstract data type)",
      "Data science"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622110"
  },
  {
    "source": "openalex",
    "source_id": "W4319348251",
    "title": "Accountability in artificial intelligence: what it is and how it works",
    "authors": [
      "Claudio Novelli",
      "Mariarosaria Taddeo",
      "Luciano Floridi"
    ],
    "year": 2023,
    "abstract": "Abstract Accountability is a cornerstone of the governance of artificial intelligence (AI). However, it is often defined too imprecisely because its multifaceted nature and the sociotechnical structure of AI systems imply a variety of values, practices, and measures to which accountability in AI can refer. We address this lack of clarity by defining accountability in terms of answerability, identifying three conditions of possibility (authority recognition, interrogation, and limitation of power), and an architecture of seven features (context, range, agent, forum, standards, process, and implications). We analyze this architecture through four accountability goals (compliance, report, oversight, and enforcement). We argue that these goals are often complementary and that policy-makers emphasize or prioritize some over others depending on the proactive or reactive use of accountability and the missions of AI governance.",
    "doi": "10.1007/s00146-023-01635-y",
    "url": "https://openalex.org/W4319348251",
    "pdf_url": "https://doi.org/10.1007/s00146-023-01635-y",
    "venue": "AI & Society",
    "citation_count": 264,
    "fields_of_study": [
      "Accountability",
      "CLARITY",
      "Cornerstone",
      "Variety (cybernetics)",
      "Corporate governance"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622126"
  },
  {
    "source": "openalex",
    "source_id": "W4365504037",
    "title": "A survey on deep learning tools dealing with data scarcity: definitions, challenges, solutions, tips, and applications",
    "authors": [
      "Laith Alzubaidi",
      "Jinshuai Bai",
      "Aiman Al-Sabaawi",
      "Jos\u00e9 Santamar\u00eda",
      "A. S. Albahri",
      "Bashar Sami Nayyef Al-dabbagh",
      "Mohammed A. Fadhel",
      "Mohamed Manoufali",
      "Jinglan Zhang",
      "Ali H. Al\u2010Timemy",
      "Ye Duan",
      "Amjed Abdullah",
      "Laith Farhan",
      "Yi Lu",
      "Ashish Gupta",
      "Felix Albu",
      "Amin Abbosh",
      "Yuantong Gu"
    ],
    "year": 2023,
    "abstract": null,
    "doi": "10.1186/s40537-023-00727-2",
    "url": "https://openalex.org/W4365504037",
    "pdf_url": "https://journalofbigdata.springeropen.com/counter/pdf/10.1186/s40537-023-00727-2",
    "venue": "Journal Of Big Data",
    "citation_count": 658,
    "fields_of_study": [
      "Computer science",
      "Deep learning",
      "Artificial intelligence",
      "Machine learning",
      "Generalization"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622139"
  },
  {
    "source": "openalex",
    "source_id": "W3135354507",
    "title": "Developing Middle School Students' AI Literacy",
    "authors": [
      "Irene Lee",
      "Safinah Ali",
      "Baiyu Zhang",
      "Daniella DiPaola",
      "Cynthia Breazeal"
    ],
    "year": 2021,
    "abstract": "In this experience report, we describe an AI summer workshop designed to prepare middle school students to become informed citizens and critical consumers of AI technology and to develop their foundational knowledge and skills to support future endeavors as AI-empowered workers. The workshop featured the 30-hour \"Developing AI Literacy\" or DAILy curriculum that is grounded in literature on child development, ethics education, and career development. The participants in the workshop were students between the ages of 10 and 14; 87% were from underrepresented groups in STEM and Computing. In this paper we describe the online curriculum, its implementation during synchronous online workshop sessions in summer of 2020, and preliminary findings on student outcomes. We reflect on the successes and lessons we learned in terms of supporting students' engagement and conceptual learning of AI, shifting attitudes toward AI, and fostering conceptions of future selves as AI-enabled workers. We conclude with discussions of the affordances and barriers to bringing AI education to students from underrepresented groups in STEM and Computing.",
    "doi": "10.1145/3408877.3432513",
    "url": "https://openalex.org/W3135354507",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3408877.3432513",
    "venue": null,
    "citation_count": 223,
    "fields_of_study": [
      "Affordance",
      "Curriculum",
      "Literacy",
      "Mathematics education",
      "Pedagogy"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622142"
  },
  {
    "source": "openalex",
    "source_id": "W3009563704",
    "title": "Deep Learning for Cardiac Image Segmentation: A Review",
    "authors": [
      "Chen Chen",
      "Chen Qin",
      "Huaqi Qiu",
      "Giacomo Tarroni",
      "Jinming Duan",
      "Wenjia Bai",
      "Daniel Rueckert"
    ],
    "year": 2020,
    "abstract": "Deep learning has become the most widely used approach for cardiac image segmentation in recent years. In this paper, we provide a review of over 100 cardiac image segmentation papers using deep learning, which covers common imaging modalities including magnetic resonance imaging (MRI), computed tomography (CT), and ultrasound and major anatomical structures of interest (ventricles, atria, and vessels). In addition, a summary of publicly available cardiac image datasets and code repositories are included to provide a base for encouraging reproducible research. Finally, we discuss the challenges and limitations with current deep learning-based approaches (scarcity of labels, model generalizability across different domains, interpretability) and suggest potential directions for future research.",
    "doi": "10.3389/fcvm.2020.00025",
    "url": "https://openalex.org/W3009563704",
    "pdf_url": "https://www.frontiersin.org/articles/10.3389/fcvm.2020.00025/pdf",
    "venue": "Frontiers in Cardiovascular Medicine",
    "citation_count": 790,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:11.622156"
  },
  {
    "source": "openalex",
    "source_id": "W4308885870",
    "title": "Multimodal machine learning in precision health: A scoping review",
    "authors": [
      "Adrienne Kline",
      "Hanyin Wang",
      "Yikuan Li",
      "Saya R Dennis",
      "Meghan R. Hutch",
      "Zhenxing Xu",
      "Fei Wang",
      "Feixiong Cheng",
      "Yuan Luo"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1038/s41746-022-00712-8",
    "url": "https://openalex.org/W4308885870",
    "pdf_url": "https://www.nature.com/articles/s41746-022-00712-8.pdf",
    "venue": "npj Digital Medicine",
    "citation_count": 370,
    "fields_of_study": [
      "Computer science",
      "Artificial intelligence",
      "Machine learning",
      "Multimodal therapy",
      "Psychology"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622167"
  },
  {
    "source": "openalex",
    "source_id": "W2995872180",
    "title": "Medical education trends for future physicians in the era of advanced technology and artificial intelligence: an integrative review",
    "authors": [
      "Eui\u2010Ryoung Han",
      "Sanghee Yeo",
      "Min Jeong Kim",
      "Young\u2010Hee Lee",
      "Kwi Hwa Park",
      "HyeRin Roh"
    ],
    "year": 2019,
    "abstract": "Abstract Background Medical education must adapt to different health care contexts, including digitalized health care systems and a digital generation of students in a hyper-connected world. The aims of this study are to identify and synthesize the values that medical educators need to implement in the curricula and to introduce representative educational programs. Methods An integrative review was conducted to combine data from various research designs. We searched for articles on PubMed, Scopus, Web of Science, and EBSCO ERIC between 2011 and 2017. Key search terms were \u201cundergraduate medical education,\u201d \u201cfuture,\u201d \u201ctwenty-first century,\u201d \u201cmillennium,\u201d \u201ccurriculum,\u201d \u201cteaching,\u201d \u201clearning,\u201d and \u201cassessment.\u201d We screened and extracted them according to inclusion and exclusion criteria from titles and abstracts. All authors read the full texts and discussed them to reach a consensus about the themes and subthemes. Data appraisal was performed using a modified Hawker \u2018s evaluation form. Results Among the 7616 abstracts initially identified, 28 full-text articles were selected to reflect medical education trends and suggest suitable educational programs. The integrative themes and subthemes of future medical education are as follows: 1) a humanistic approach to patient safety that involves encouraging humanistic doctors and facilitating collaboration; 2) early experience and longitudinal integration by early exposure to patient-oriented integration and longitudinal integrated clerkships; 3) going beyond hospitals toward society by responding to changing community needs and showing respect for diversity; and 4) student-driven learning with advanced technology through active learning with individualization, social interaction, and resource accessibility. Conclusions This review integrated the trends in undergraduate medical education in readiness for the anticipated changes in medical environments. The detailed programs introduced in this study could be useful for medical educators in the development of curricula. Further research is required to integrate the educational trends into graduate and continuing medical education, and to investigate the status or effects of innovative educational programs in each medical school or environment.",
    "doi": "10.1186/s12909-019-1891-5",
    "url": "https://openalex.org/W2995872180",
    "pdf_url": "https://bmcmededuc.biomedcentral.com/track/pdf/10.1186/s12909-019-1891-5",
    "venue": "BMC Medical Education",
    "citation_count": 364,
    "fields_of_study": [
      "Curriculum",
      "Medical education",
      "Inclusion (mineral)",
      "Scopus",
      "Diversity (politics)"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622169"
  },
  {
    "source": "openalex",
    "source_id": "W3029725182",
    "title": "Ethical principles in machine learning and artificial intelligence: cases from the field and possible ways forward",
    "authors": [
      "Samuele Lo Piano"
    ],
    "year": 2020,
    "abstract": "Abstract Decision-making on numerous aspects of our daily lives is being outsourced to machine-learning (ML) algorithms and artificial intelligence (AI), motivated by speed and efficiency in the decision process. ML approaches\u2014one of the typologies of algorithms underpinning artificial intelligence\u2014are typically developed as black boxes. The implication is that ML code scripts are rarely scrutinised; interpretability is usually sacrificed in favour of usability and effectiveness. Room for improvement in practices associated with programme development have also been flagged along other dimensions, including inter alia fairness, accuracy, accountability, and transparency. In this contribution, the production of guidelines and dedicated documents around these themes is discussed. The following applications of AI-driven decision-making are outlined: (a) risk assessment in the criminal justice system, and (b) autonomous vehicles, highlighting points of friction across ethical principles. Possible ways forward towards the implementation of governance on AI are finally examined.",
    "doi": "10.1057/s41599-020-0501-9",
    "url": "https://openalex.org/W3029725182",
    "pdf_url": "https://www.nature.com/articles/s41599-020-0501-9.pdf",
    "venue": "Humanities and Social Sciences Communications",
    "citation_count": 216,
    "fields_of_study": [
      "Accountability",
      "Interpretability",
      "Transparency (behavior)",
      "Underpinning",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622195"
  },
  {
    "source": "openalex",
    "source_id": "W4388333366",
    "title": "Generative Artificial Intelligence: Implications and Considerations for Higher Education Practice",
    "authors": [
      "Tom Farrelly",
      "Nick Baker"
    ],
    "year": 2023,
    "abstract": "Generative Artificial Intelligence (GAI) has emerged as a transformative force in higher education, offering both challenges and opportunities. This paper explores the multifaceted impact of GAI on academic work, with a focus on student life and, in particular, the implications for international students. While GAI, exemplified by models like ChatGPT, has the potential to revolutionize education, concerns about academic integrity have arisen, leading to debates on the use of AI detection tools. This essay highlights the difficulties in reliably detecting AI-generated content, raising concerns about potential false accusations against students. It also discusses biases within AI models, emphasizing the need for fairness and equity in AI-based assessments with a particular emphasis on the disproportionate impact of GAI on international students, who already face biases and discrimination. It also highlights the potential for AI to mitigate some of these challenges by providing language support and accessibility features. Finally, this essay acknowledges the disruptive potential of GAI in higher education and calls for a balanced approach that addresses both the challenges and opportunities it presents by emphasizing the importance of AI literacy and ethical considerations in adopting AI technologies to ensure equitable access and positive outcomes for all students. We offer a coda to Ng et al.\u2019s AI competency framework, mapped to the Revised Bloom\u2019s Taxonomy, through a lens of cultural competence with AI as a means of supporting educators to use these tools equitably in their teaching.",
    "doi": "10.3390/educsci13111109",
    "url": "https://openalex.org/W4388333366",
    "pdf_url": "https://www.mdpi.com/2227-7102/13/11/1109/pdf?version=1699079828",
    "venue": "Education Sciences",
    "citation_count": 294,
    "fields_of_study": [
      "Transformative learning",
      "Generative grammar",
      "Engineering ethics",
      "Competence (human resources)",
      "Equity (law)"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622209"
  },
  {
    "source": "openalex",
    "source_id": "W4392769984",
    "title": "A scoping review of artificial intelligence in medical education: BEME Guide No. 84",
    "authors": [
      "Morris Gordon",
      "Michelle Daniel",
      "Aderonke Ajiboye",
      "Hussein Uraiby",
      "Nicole Y. Xu",
      "Rangana Bartlett",
      "Janice L. Hanson",
      "Mary R. Haas",
      "Maxwell Spadafore",
      "Ciaran Grafton\u2010Clarke",
      "Rayhan Yousef Gasiea",
      "Colin Michie",
      "Janet Corral",
      "Brian Kwan",
      "Diana Dolmans",
      "Satid Thammasitboon"
    ],
    "year": 2024,
    "abstract": "The current literature has been charted. The findings underscore the need for ongoing research to explore uncharted areas and address potential risks associated with AI use in medical education. This work serves as a foundational resource for educators, policymakers, and researchers in navigating AI's evolving role in medical education. A framework to support future high utility reporting is proposed, the FACETS framework.",
    "doi": "10.1080/0142159x.2024.2314198",
    "url": "https://openalex.org/W4392769984",
    "pdf_url": "https://www.tandfonline.com/doi/pdf/10.1080/0142159X.2024.2314198?needAccess=true",
    "venue": "Medical Teacher",
    "citation_count": 289,
    "fields_of_study": [
      "MEDLINE",
      "Medical education",
      "Thematic analysis",
      "Systematic review",
      "Psychology"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622229"
  },
  {
    "source": "openalex",
    "source_id": "W4296405185",
    "title": "Power to the People? Opportunities and Challenges for Participatory AI",
    "authors": [
      "Abeba Birhane",
      "William M. Isaac",
      "Vinodkumar Prabhakaran",
      "Mark D\u00edaz",
      "Madeleine Clare Elish",
      "Iason Gabriel",
      "Shakir Mohamed"
    ],
    "year": 2022,
    "abstract": "Participatory approaches to artificial intelligence (AI) and machine learning\\n(ML) are gaining momentum: the increased attention comes partly with the view\\nthat participation opens the gateway to an inclusive, equitable, robust,\\nresponsible and trustworthy AI.Among other benefits, participatory approaches\\nare essential to understanding and adequately representing the needs, desires\\nand perspectives of historically marginalized communities. However, there\\ncurrently exists lack of clarity on what meaningful participation entails and\\nwhat it is expected to do. In this paper we first review participatory\\napproaches as situated in historical contexts as well as participatory methods\\nand practices within the AI and ML pipeline. We then introduce three case\\nstudies in participatory AI.Participation holds the potential for beneficial,\\nemancipatory and empowering technology design, development and deployment while\\nalso being at risk for concerns such as cooptation and conflation with other\\nactivities. We lay out these limitations and concerns and argue that as\\nparticipatory AI/ML becomes in vogue, a contextual and nuanced understanding of\\nthe term as well as consideration of who the primary beneficiaries of\\nparticipatory activities ought to be constitute crucial factors to realizing\\nthe benefits and opportunities that participation brings.\\n",
    "doi": "10.1145/3551624.3555290",
    "url": "https://openalex.org/W4296405185",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3551624.3555290",
    "venue": null,
    "citation_count": 233,
    "fields_of_study": [
      "Citizen journalism",
      "Participatory GIS",
      "Sociology",
      "Software deployment",
      "Participatory evaluation"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622237"
  },
  {
    "source": "openalex",
    "source_id": "W3164718925",
    "title": "Considering the possibilities and pitfalls of Generative Pre-trained Transformer 3 (GPT-3) in healthcare delivery",
    "authors": [
      "Diane M. Korngiebel",
      "Sean D. Mooney"
    ],
    "year": 2021,
    "abstract": "Natural language computer applications are becoming increasingly sophisticated and, with the recent release of Generative Pre-trained Transformer 3, they could be deployed in healthcare-related contexts that have historically comprised human-to-human interaction. However, for GPT-3 and similar applications to be considered for use in health-related contexts, possibilities and pitfalls need thoughtful exploration. In this article, we briefly introduce some opportunities and cautions that would accompany advanced Natural Language Processing applications deployed in eHealth.",
    "doi": "10.1038/s41746-021-00464-x",
    "url": "https://openalex.org/W3164718925",
    "pdf_url": "https://www.nature.com/articles/s41746-021-00464-x.pdf",
    "venue": "npj Digital Medicine",
    "citation_count": 253,
    "fields_of_study": [
      "Generative grammar",
      "Transformer",
      "eHealth",
      "Computer science",
      "Health care"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622252"
  },
  {
    "source": "openalex",
    "source_id": "W4391006361",
    "title": "A meta systematic review of artificial intelligence in higher education: a call for increased ethics, collaboration, and rigour",
    "authors": [
      "Melissa Bond",
      "Hassan Khosravi",
      "Maarten de Laat",
      "Nina Bergdahl",
      "Violeta Negrea",
      "Emily Oxley",
      "Phuong Pham",
      "Sin Wang Chong",
      "George Siemens"
    ],
    "year": 2024,
    "abstract": null,
    "doi": "10.1186/s41239-023-00436-z",
    "url": "https://openalex.org/W4391006361",
    "pdf_url": "https://educationaltechnologyjournal.springeropen.com/counter/pdf/10.1186/s41239-023-00436-z",
    "venue": "International Journal of Educational Technology in Higher Education",
    "citation_count": 381,
    "fields_of_study": [
      "Systematic review",
      "Rigour",
      "Higher education",
      "Profiling (computer programming)",
      "Scopus"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622260"
  },
  {
    "source": "openalex",
    "source_id": "W4410381134",
    "title": "Human Rights and Artificial Intelligence in Healthcare-Related Settings: A Grammar of Human Rights Approach",
    "authors": [
      "Helga Molb\u00e6k-Steensig",
      "Martin Scheinin"
    ],
    "year": 2025,
    "abstract": "Abstract This article examines the expanding role of Artificial Intelligence ( AI ) in healthcare and associated human rights concerns, including whether new EU legislation takes all relevant human rights concerns into account. AI presents promising ways to fulfil the right to health through improving diagnostics, treatments, and resource allocation, but its use also comes with risks concerning privacy, bias, discrimination, and human dignity. Existing literature often relies on the rather vague FATE (Fairness, Accountability, Transparency, Ethics) principles, but recent calls have been made for a human-rights-based approach more broadly to ensure the legality and ethics of AI applications. This article responds to that call by proposing a structured methodology for reconciling rights, considering both the different structures of civil and political versus economic, social and cultural human rights, the negative and positive obligations of the state, and the interplay with different AI design choices.",
    "doi": "10.1163/15718093-bja10146",
    "url": "https://openalex.org/W4410381134",
    "pdf_url": "https://hdl.handle.net/1814/93650",
    "venue": "European Journal of Health Law",
    "citation_count": 1,
    "fields_of_study": [
      "Human rights",
      "Dignity",
      "Principle of legality",
      "Accountability",
      "Law and economics"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622262"
  },
  {
    "source": "openalex",
    "source_id": "W3094948551",
    "title": "CatBoost for big data: an interdisciplinary review",
    "authors": [
      "John Hancock",
      "Taghi M. Khoshgoftaar"
    ],
    "year": 2020,
    "abstract": null,
    "doi": "10.1186/s40537-020-00369-8",
    "url": "https://openalex.org/W3094948551",
    "pdf_url": "https://journalofbigdata.springeropen.com/track/pdf/10.1186/s40537-020-00369-8",
    "venue": "Journal Of Big Data",
    "citation_count": 1435,
    "fields_of_study": [
      "Computer science",
      "Machine learning",
      "Artificial intelligence",
      "Decision tree",
      "Categorical variable"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622275"
  },
  {
    "source": "openalex",
    "source_id": "W4387966489",
    "title": "The value of standards for health datasets in artificial intelligence-based applications",
    "authors": [
      "Anmol Arora",
      "Joseph Alderman",
      "Joanne Palmer",
      "Shaswath Ganapathi",
      "Elinor Laws",
      "Melissa D. McCradden",
      "Lauren Oakden\u2010Rayner",
      "Stephen Pfohl",
      "Marzyeh Ghassemi",
      "Francis McKay",
      "Darren Treanor",
      "Negar Rostamzadeh",
      "Bilal A. Mateen",
      "Jacqui Gath",
      "Adewole O. Adebajo",
      "Stephanie Kuku",
      "Rubeta Matin",
      "Katherine Heller",
      "Elizabeth Sapey",
      "Neil J. Sebire",
      "Heather Cole-Lewis",
      "Melanie Calvert",
      "Alastair K. Denniston",
      "Xiaoxuan Liu"
    ],
    "year": 2023,
    "abstract": null,
    "doi": "10.1038/s41591-023-02608-w",
    "url": "https://openalex.org/W4387966489",
    "pdf_url": "https://www.nature.com/articles/s41591-023-02608-w.pdf",
    "venue": "Nature Medicine",
    "citation_count": 223,
    "fields_of_study": [
      "Best practice",
      "Data science",
      "Diversity (politics)",
      "Health care",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622279"
  },
  {
    "source": "openalex",
    "source_id": "W3131580611",
    "title": "Responsible Urban Innovation with Local Government Artificial Intelligence (AI): A Conceptual Framework and Research Agenda",
    "authors": [
      "Tan Yi\u011fitcanlar",
      "Juan M. Corchado",
      "Rashid Mehmood",
      "Rita Yi Man Li",
      "Karen Mossberger",
      "Kevin C. Desouza"
    ],
    "year": 2021,
    "abstract": null,
    "doi": "10.3390/joitmc7010071",
    "url": "https://openalex.org/W3131580611",
    "pdf_url": "https://www.mdpi.com/2199-8531/7/1/71/pdf",
    "venue": "Journal of Open Innovation Technology Market and Complexity",
    "citation_count": 212,
    "fields_of_study": [
      "Government (linguistics)",
      "Urbanization",
      "Futures contract",
      "Conceptual framework",
      "Management science"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622281"
  },
  {
    "source": "openalex",
    "source_id": "W3168386798",
    "title": "A panoramic view and swot analysis of artificial intelligence for achieving the sustainable development goals by 2030: progress and prospects",
    "authors": [
      "Iv\u00e1n Palomares",
      "Eugenio Mart\u00ednez\u2010C\u00e1mara",
      "Rosana Montes",
      "Pablo Garc\u00eda-Moral",
      "Manuel Chiach\u00edo",
      "Juan Chiach\u00edo",
      "Sergio Alonso",
      "Francisco Javier Melero",
      "Daniel Molina",
      "B\u00e1rbara Cables Fern\u00e1ndez",
      "Cristina Moral Santaella",
      "Rosario Marchena",
      "Javier P\u00e9rez de Vargas",
      "Francisco Herrera"
    ],
    "year": 2021,
    "abstract": null,
    "doi": "10.1007/s10489-021-02264-y",
    "url": "https://openalex.org/W3168386798",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10489-021-02264-y.pdf",
    "venue": "Applied Intelligence",
    "citation_count": 235,
    "fields_of_study": [
      "SWOT analysis",
      "Blueprint",
      "Prosperity",
      "Sustainable development",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622285"
  },
  {
    "source": "openalex",
    "source_id": "W4282027681",
    "title": "A Survey on the Fairness of Recommender Systems",
    "authors": [
      "Yifan Wang",
      "Weizhi Ma",
      "Min Zhang",
      "Yiqun Liu",
      "Shaoping Ma"
    ],
    "year": 2022,
    "abstract": "Recommender systems are an essential tool to relieve the information overload challenge and play an important role in people\u2019s daily lives. Since recommendations involve allocations of social resources (e.g., job recommendation), an important issue is whether recommendations are fair. Unfair recommendations are not only unethical but also harm the long-term interests of the recommender system itself. As a result, fairness issues in recommender systems have recently attracted increasing attention. However, due to multiple complex resource allocation processes and various fairness definitions, the research on fairness in recommendation is scattered. To fill this gap, we review over 60 papers published in top conferences/journals, including TOIS, SIGIR, and WWW. First, we summarize fairness definitions in the recommendation and provide several views to classify fairness issues. Then, we review recommendation datasets and measurements in fairness studies and provide an elaborate taxonomy of fairness methods in the recommendation. Finally, we conclude this survey by outlining some promising future directions.",
    "doi": "10.1145/3547333",
    "url": "https://openalex.org/W4282027681",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3547333",
    "venue": "ACM Transactions on Information Systems",
    "citation_count": 286,
    "fields_of_study": [
      "Recommender system",
      "Computer science",
      "Information retrieval",
      "World Wide Web"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622287"
  },
  {
    "source": "openalex",
    "source_id": "W3135371071",
    "title": "Towards Accountability for Machine Learning Datasets: Practices from Software Engineering and Infrastructure",
    "authors": [
      "Ben Hutchinson",
      "Andrew Smart",
      "Alex Hanna",
      "Emily Denton",
      "Christina Greer",
      "Oddur Kjartansson",
      "Parker Barnes",
      "Margaret Mitchell"
    ],
    "year": 2021,
    "abstract": "Datasets that power machine learning are often used, shared, and reused with little visibility into the processes of deliberation that led to their creation. As artificial intelligence systems are increasingly used in high-stakes tasks, system development and deployment practices must be adapted to address the very real consequences of how model development data is constructed and used in practice. This includes greater transparency about data, and accountability for decisions made when developing it. In this paper, we introduce a rigorous framework for dataset development transparency that supports decision-making and accountability. The framework uses the cyclical, infrastructural and engineering nature of dataset development to draw on best practices from the software development lifecycle. Each stage of the data development lifecycle yields documents that facilitate improved communication and decision-making, as well as drawing attention to the value and necessity of careful data work. The proposed framework makes visible the often overlooked work and decisions that go into dataset creation, a critical step in closing the accountability gap in artificial intelligence and a critical/necessary resource aligned with recent work on auditing processes.",
    "doi": "10.1145/3442188.3445918",
    "url": "https://openalex.org/W3135371071",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3442188.3445918",
    "venue": null,
    "citation_count": 222,
    "fields_of_study": [
      "Accountability",
      "Computer science",
      "Transparency (behavior)",
      "Software deployment",
      "Deliberation"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622301"
  },
  {
    "source": "openalex",
    "source_id": "W3199196172",
    "title": "Putting AI ethics to work: are the tools fit for purpose?",
    "authors": [
      "Jacqui Ayling",
      "Adriane Chapman"
    ],
    "year": 2021,
    "abstract": "Abstract Bias, unfairness and lack of transparency and accountability in Artificial Intelligence (AI) systems, and the potential for the misuse of predictive models for decision-making have raised concerns about the ethical impact and unintended consequences of new technologies for society across every sector where data-driven innovation is taking place. This paper reviews the landscape of suggested ethical frameworks with a focus on those which go beyond high-level statements of principles and offer practical tools for application of these principles in the production and deployment of systems. This work provides an assessment of these practical frameworks with the lens of known best practices for impact assessment and audit of technology. We review other historical uses of risk assessments and audits and create a typology that allows us to compare current AI ethics tools to Best Practices found in previous methodologies from technology, environment, privacy, finance and engineering. We analyse current AI ethics tools and their support for diverse stakeholders and components of the AI development and deployment lifecycle as well as the types of tools used to facilitate use. From this, we identify gaps in current AI ethics tools in auditing and risk assessment that should be considered going forward.",
    "doi": "10.1007/s43681-021-00084-x",
    "url": "https://openalex.org/W3199196172",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s43681-021-00084-x.pdf",
    "venue": "AI and Ethics",
    "citation_count": 209,
    "fields_of_study": [
      "Audit",
      "Transparency (behavior)",
      "Software deployment",
      "Accountability",
      "Unintended consequences"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622316"
  },
  {
    "source": "openalex",
    "source_id": "W4383737134",
    "title": "A Survey on Large Language Models: Applications, Challenges, Limitations, and Practical Usage",
    "authors": [
      "Muhammad Usman Hadi",
      "qasem al tashi",
      "Rizwan Qureshi",
      "Abbas Shah",
      "Amgad Muneer",
      "Muhammad Irfan",
      "Anas Zafar",
      "Muhammad Bilal Shaikh",
      "Naveed Akhtar",
      "Jia Wu",
      "Seyedali Mirjalili"
    ],
    "year": 2023,
    "abstract": "&lt;p&gt;Within the vast expanse of computerized language processing, a revolutionary entity known as Large Language Models (LLMs) has emerged, wielding immense power in its capacity to comprehend intricate linguistic patterns and conjure coherent and contextually fitting responses. Large language models (LLMs) are a type of artificial intelligence (AI) that have emerged as powerful tools for a wide range of tasks, including natural language processing (NLP), machine translation, and question-answering. This survey paper provides a comprehensive overview of LLMs, including their history, architecture, training methods, applications, and challenges. The paper begins by discussing the fundamental concepts of generative AI and the architecture of generative pre- trained transformers (GPT). It then provides an overview of the history of LLMs, their evolution over time, and the different training methods that have been used to train them. The paper then discusses the wide range of applications of LLMs, including medical, education, finance, and engineering. It also discusses how LLMs are shaping the future of AI and how they can be used to solve real-world problems. The paper then discusses the challenges associated with deploying LLMs in real-world scenarios, including ethical considerations, model biases, interpretability, and computational resource requirements. It also highlights techniques for enhancing the robustness and controllability of LLMs, and addressing bias, fairness, and generation quality issues. Finally, the paper concludes by highlighting the future of LLM research and the challenges that need to be addressed in order to make LLMs more reliable and useful. This survey paper is intended to provide researchers, practitioners, and enthusiasts with a comprehensive understanding of LLMs, their evolution, applications, and challenges. By consolidating the state-of-the-art knowledge in the field, this survey serves as a valuable resource for further advancements in the development and utilization of LLMs for a wide range of real-world applications. The GitHub repo for this project is available at https://github.com/anas-zafar/LLM-Survey&lt;/p&gt;",
    "doi": "10.36227/techrxiv.23589741.v1",
    "url": "https://openalex.org/W4383737134",
    "pdf_url": "https://www.techrxiv.org/doi/pdf/10.36227/techrxiv.23589741.v1",
    "venue": null,
    "citation_count": 327,
    "fields_of_study": [
      "Interpretability",
      "Computer science",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622332"
  },
  {
    "source": "openalex",
    "source_id": "W4327672398",
    "title": "Speculative futures on ChatGPT and generative artificial intelligence (AI): A collective reflection from the educational landscape",
    "authors": [
      "Aras Bozkurt",
      "J. Xiao",
      "Steven Imanuel Lambert",
      "A. Pazurek",
      "H. Crompton",
      "S. Koseoglu",
      "Robert Farrow",
      "Melissa Bond",
      "Chrissi Nerantzi",
      "Selina Honeychurch",
      "Maha Bali",
      "Jon Dron",
      "Kamran Mir",
      "Bonnie Stewart",
      "Eamon Costello",
      "Jon Mason",
      "Christian M. Stracke",
      "E. Romero-Hall",
      "A. Koutropoulos",
      "C. M. Toquero",
      "L. Singh",
      "A. Tlili",
      "Kyungmee Lee",
      "Mark Nichols",
      "E. Ossiannilsson",
      "M. Brown",
      "V. Irvine",
      "Juliana Elisa Raffaghelli",
      "G. Santos-Hermosa",
      "Orna Farrell",
      "T. Adam",
      "Y. L. Thong",
      "S. Sani-Bozkurt",
      "R. C. Sharma",
      "Stefan Hrastinski",
      "Petar Jandri\u0107"
    ],
    "year": 2023,
    "abstract": "While ChatGPT has recently become very popular, AI has a long history and philosophy. This paper intends to explore the promises and pitfalls of the Generative Pre-trained Transformer (GPT) AI and potentially future technologies by adopting a speculative methodology. Speculative future narratives with a specific focus on educational contexts are provided in an attempt to identify emerging themes and discuss their implications for education in the 21st century. Affordances of (using) AI in Education (AIEd) and possible adverse effects are identified and discussed which emerge from the narratives. It is argued that now is the best of times to define human vs AI contribution to education because AI can accomplish more and more educational activities that used to be the prerogative of human educators. Therefore, it is imperative to rethink the respective roles of technology and human educators in education with a future-oriented mindset.",
    "doi": "10.5281/zenodo.7636568",
    "url": "https://openalex.org/W4327672398",
    "pdf_url": "https://eprints.gla.ac.uk/294292/1/294292.pdf",
    "venue": "Enlighten: Publications (The University of Glasgow)",
    "citation_count": 315,
    "fields_of_study": [
      "Futures contract",
      "Reflection (computer programming)",
      "Generative grammar",
      "Collective intelligence",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622359"
  },
  {
    "source": "openalex",
    "source_id": "W4389794809",
    "title": "Guiding Principles to Address the Impact of Algorithm Bias on Racial and Ethnic Disparities in Health and Health Care",
    "authors": [
      "Marshall H. Chin",
      "Nasim Afsarmanesh",
      "Arlene S. Bierman",
      "Christine Chang",
      "Caleb J. Col\u00f3n-Rodr\u00edguez",
      "Prashila Dullabh",
      "Deborah Duran",
      "Malika Fair",
      "Tina Hernandez\u2010Boussard",
      "Maia Hightower",
      "Anjali Jain",
      "William B. Jordan",
      "Stephen Konya",
      "Roslyn Holliday Moore",
      "Tamra Tyree Moore",
      "Richard Rodriguez",
      "Gauher Shaheen",
      "Lynne Page Snyder",
      "Mithuna Srinivasan",
      "Craig A. Umscheid",
      "Lucila Ohno\u2010Machado"
    ],
    "year": 2023,
    "abstract": "Importance Health care algorithms are used for diagnosis, treatment, prognosis, risk stratification, and allocation of resources. Bias in the development and use of algorithms can lead to worse outcomes for racial and ethnic minoritized groups and other historically marginalized populations such as individuals with lower income. Objective To provide a conceptual framework and guiding principles for mitigating and preventing bias in health care algorithms to promote health and health care equity. Evidence Review The Agency for Healthcare Research and Quality and the National Institute for Minority Health and Health Disparities convened a diverse panel of experts to review evidence, hear from stakeholders, and receive community feedback. Findings The panel developed a conceptual framework to apply guiding principles across an algorithm\u2019s life cycle, centering health and health care equity for patients and communities as the goal, within the wider context of structural racism and discrimination. Multiple stakeholders can mitigate and prevent bias at each phase of the algorithm life cycle, including problem formulation (phase 1); data selection, assessment, and management (phase 2); algorithm development, training, and validation (phase 3); deployment and integration of algorithms in intended settings (phase 4); and algorithm monitoring, maintenance, updating, or deimplementation (phase 5). Five principles should guide these efforts: (1) promote health and health care equity during all phases of the health care algorithm life cycle; (2) ensure health care algorithms and their use are transparent and explainable; (3) authentically engage patients and communities during all phases of the health care algorithm life cycle and earn trustworthiness; (4) explicitly identify health care algorithmic fairness issues and trade-offs; and (5) establish accountability for equity and fairness in outcomes from health care algorithms. Conclusions and Relevance Multiple stakeholders must partner to create systems, processes, regulations, incentives, standards, and policies to mitigate and prevent algorithmic bias. Reforms should implement guiding principles that support promotion of health and health care equity in all phases of the algorithm life cycle as well as transparency and explainability, authentic community engagement and ethical partnerships, explicit identification of fairness issues and trade-offs, and accountability for equity and fairness.",
    "doi": "10.1001/jamanetworkopen.2023.45050",
    "url": "https://openalex.org/W4389794809",
    "pdf_url": "https://jamanetwork.com/journals/jamanetworkopen/articlepdf/2812958/chin_2023_sc_230007_1702050468.82841.pdf",
    "venue": "JAMA Network Open",
    "citation_count": 176,
    "fields_of_study": [
      "Health equity",
      "Health care",
      "Algorithm",
      "Ethnic group",
      "Health policy"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622373"
  },
  {
    "source": "openalex",
    "source_id": "W3196248941",
    "title": "Five sources of bias in natural language processing",
    "authors": [
      "Dirk Hovy",
      "Shrimai Prabhumoye"
    ],
    "year": 2021,
    "abstract": "Abstract Recently, there has been an increased interest in demographically grounded bias in natural language processing (NLP) applications. Much of the recent work has focused on describing bias and providing an overview of bias in a larger context. Here, we provide a simple, actionable summary of this recent work. We outline five sources where bias can occur in NLP systems: (1) the data, (2) the annotation process, (3) the input representations, (4) the models, and finally (5) the research design (or how we conceptualize our research). We explore each of the bias sources in detail in this article, including examples and links to related work, as well as potential counter\u2010measures.",
    "doi": "10.1111/lnc3.12432",
    "url": "https://openalex.org/W3196248941",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/lnc3.12432",
    "venue": "Language and Linguistics Compass",
    "citation_count": 253,
    "fields_of_study": [
      "Computer science",
      "Context (archaeology)",
      "Natural language processing",
      "Natural (archaeology)",
      "Process (computing)"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622402"
  },
  {
    "source": "openalex",
    "source_id": "W4280488363",
    "title": "Reporting guideline for the early stage clinical evaluation of decision support systems driven by artificial intelligence: DECIDE-AI",
    "authors": [
      "Baptiste Vasey",
      "Myura Nagendran",
      "Bruce Campbell",
      "David A. Clifton",
      "Gary S. Collins",
      "Spiros Denaxas",
      "Alastair K. Denniston",
      "Livia Faes",
      "Bart Geerts",
      "Mudathir Ibrahim",
      "Xiaoxuan Liu",
      "Bilal A. Mateen",
      "Piyush Mathur",
      "Melissa D. McCradden",
      "Lauren Morgan",
      "Johan Ordish",
      "Campbell Rogers",
      "Suchi Saria",
      "Daniel Shu Wei Ting",
      "Peter Watkinson",
      "Wim Weber",
      "Peter Wheatstone",
      "Peter McCulloch"
    ],
    "year": 2022,
    "abstract": "A growing number of artificial intelligence (AI)-based clinical decision support systems are showing promising performance in preclinical, in silico evaluation, but few have yet demonstrated real benefit to patient care. Early-stage clinical evaluation is important to assess an AI system's actual clinical performance at small scale, ensure its safety, evaluate the human factors surrounding its use and pave the way to further large-scale trials. However, the reporting of these early studies remains inadequate. The present statement provides a multi-stakeholder, consensus-based reporting guideline for the Developmental and Exploratory Clinical Investigations of DEcision support systems driven by Artificial Intelligence (DECIDE-AI). We conducted a two-round, modified Delphi process to collect and analyze expert opinion on the reporting of early clinical evaluation of AI systems. Experts were recruited from 20 pre-defined stakeholder categories. The final composition and wording of the guideline was determined at a virtual consensus meeting. The checklist and the Explanation &amp; Elaboration (E&amp;E) sections were refined based on feedback from a qualitative evaluation process. In total, 123 experts participated in the first round of Delphi, 138 in the second round, 16 in the consensus meeting and 16 in the qualitative evaluation. The DECIDE-AI reporting guideline comprises 17 AI-specific reporting items (made of 28 subitems) and ten generic reporting items, with an E&amp;E paragraph provided for each. Through consultation and consensus with a range of stakeholders, we developed a guideline comprising key items that should be reported in early-stage clinical studies of AI-based decision support systems in healthcare. By providing an actionable checklist of minimal reporting items, the DECIDE-AI guideline will facilitate the appraisal of these studies and replicability of their findings.",
    "doi": "10.1136/bmj-2022-070904",
    "url": "https://openalex.org/W4280488363",
    "pdf_url": "https://www.bmj.com/content/bmj/377/bmj-2022-070904.full.pdf",
    "venue": "BMJ",
    "citation_count": 269,
    "fields_of_study": [
      "Guideline",
      "Checklist",
      "Delphi method",
      "Decision support system",
      "Clinical decision support system"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622415"
  },
  {
    "source": "openalex",
    "source_id": "W4386711999",
    "title": "The GenAI is out of the bottle: generative artificial intelligence from a business model innovation perspective",
    "authors": [
      "Dominik K. Kanbach",
      "Louisa Heiduk",
      "Georg Blueher",
      "Maximilian Schreiter",
      "Alexander Lahmann"
    ],
    "year": 2023,
    "abstract": null,
    "doi": "10.1007/s11846-023-00696-z",
    "url": "https://openalex.org/W4386711999",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s11846-023-00696-z.pdf",
    "venue": "Review of Managerial Science",
    "citation_count": 328,
    "fields_of_study": [
      "Variety (cybernetics)",
      "Perspective (graphical)",
      "Generative grammar",
      "Business model",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622436"
  },
  {
    "source": "openalex",
    "source_id": "W4295854586",
    "title": "Explainable Artificial Intelligence Applications in Cyber Security: State-of-the-Art in Research",
    "authors": [
      "Zhibo Zhang",
      "Hussam Al Hamadi",
      "Ernesto Damiani",
      "Chan Yeob Yeun",
      "Fatma Taher"
    ],
    "year": 2022,
    "abstract": "This survey presents a comprehensive review of current literature on\\nExplainable Artificial Intelligence (XAI) methods for cyber security\\napplications. Due to the rapid development of Internet-connected systems and\\nArtificial Intelligence in recent years, Artificial Intelligence including\\nMachine Learning (ML) and Deep Learning (DL) has been widely utilized in the\\nfields of cyber security including intrusion detection, malware detection, and\\nspam filtering. However, although Artificial Intelligence-based approaches for\\nthe detection and defense of cyber attacks and threats are more advanced and\\nefficient compared to the conventional signature-based and rule-based cyber\\nsecurity strategies, most ML-based techniques and DL-based techniques are\\ndeployed in the black-box manner, meaning that security experts and customers\\nare unable to explain how such procedures reach particular conclusions. The\\ndeficiencies of transparency and interpretability of existing Artificial\\nIntelligence techniques would decrease human users' confidence in the models\\nutilized for the defense against cyber attacks, especially in current\\nsituations where cyber attacks become increasingly diverse and complicated.\\nTherefore, it is essential to apply XAI in the establishment of cyber security\\nmodels to create more explainable models while maintaining high accuracy and\\nallowing human users to comprehend, trust, and manage the next generation of\\ncyber defense mechanisms. Although there are papers reviewing Artificial\\nIntelligence applications in cyber security areas and the vast literature on\\napplying XAI in many fields including healthcare, financial services, and\\ncriminal justice, the surprising fact is that there are currently no survey\\nresearch articles that concentrate on XAI applications in cyber security.\\n",
    "doi": "10.1109/access.2022.3204051",
    "url": "https://openalex.org/W4295854586",
    "pdf_url": "https://ieeexplore.ieee.org/ielx7/6287639/6514899/09875264.pdf",
    "venue": "IEEE Access",
    "citation_count": 322,
    "fields_of_study": [
      "Computer science",
      "Computer security",
      "State (computer science)",
      "Artificial intelligence",
      "Data science"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622439"
  },
  {
    "source": "openalex",
    "source_id": "W4283156811",
    "title": "The Fallacy of AI Functionality",
    "authors": [
      "Inioluwa Deborah Raji",
      "I. Elizabeth Kumar",
      "Aaron Horowitz",
      "Andrew D. Selbst"
    ],
    "year": 2022,
    "abstract": "Deployed AI systems often do not work. They can be constructed haphazardly,\\ndeployed indiscriminately, and promoted deceptively. However, despite this\\nreality, scholars, the press, and policymakers pay too little attention to\\nfunctionality. This leads to technical and policy solutions focused on\\n\"ethical\" or value-aligned deployments, often skipping over the prior question\\nof whether a given system functions, or provides any benefits at all. To\\ndescribe the harms of various types of functionality failures, we analyze a set\\nof case studies to create a taxonomy of known AI functionality issues. We then\\npoint to policy and organizational responses that are often overlooked and\\nbecome more readily available once functionality is drawn into focus. We argue\\nthat functionality is a meaningful AI policy challenge, operating as a\\nnecessary first step towards protecting affected communities from algorithmic\\nharm.\\n",
    "doi": "10.1145/3531146.3533158",
    "url": "https://openalex.org/W4283156811",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3531146.3533158",
    "venue": "2022 ACM Conference on Fairness, Accountability, and Transparency",
    "citation_count": 197,
    "fields_of_study": [
      "Fallacy",
      "Harm",
      "Computer science",
      "Set (abstract data type)",
      "Value (mathematics)"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622457"
  },
  {
    "source": "openalex",
    "source_id": "W4313313935",
    "title": "Engineering Education in the Era of ChatGPT: Promise and Pitfalls of Generative AI for Education",
    "authors": [
      "Junaid Qadir"
    ],
    "year": 2022,
    "abstract": "&lt;p&gt;Engineering education is constantly evolving to keep up with the latest technological developments and meet the changing needs of the engineering industry. One promising development in this field is the use of generative artificial intelligence technology, such as the ChatGPT conversational agent. ChatGPT has the potential to offer personalized and effective learning experiences by providing students with customized feedback and explanations, as well as creating realistic virtual simulations for hands-on learning. However, it is important to also consider the limitations of this technology. ChatGPT and other generative AI systems are only as good as their training data and may perpetuate biases or even generate and spread misinformation. Additionally, the use of generative AI in education raises ethical concerns such as the potential for unethical or dishonest use by students and the potential unemployment of humans who are made redundant by technology. While the current state of generative AI technology represented by ChatGPT is impressive but flawed, it is only a preview of what is to come. It is important for engineering educators to understand the implications of this technology and study how to adapt the engineering education ecosystem to ensure that the next generation of engineers can take advantage of the benefits offered by generative AI while minimizing any negative consequences.&lt;/p&gt;",
    "doi": "10.36227/techrxiv.21789434.v1",
    "url": "https://openalex.org/W4313313935",
    "pdf_url": "https://www.techrxiv.org/articles/preprint/Engineering_Education_in_the_Era_of_ChatGPT_Promise_and_Pitfalls_of_Generative_AI_for_Education/21789434/1/files/38676764.pdf",
    "venue": null,
    "citation_count": 258,
    "fields_of_study": [
      "Generative grammar",
      "Misinformation",
      "Computer science",
      "Artificial intelligence",
      "Generative model"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622468"
  },
  {
    "source": "openalex",
    "source_id": "W4240644295",
    "title": "The ARRIVE guidelines 2.0: Updated guidelines for reporting animal research",
    "authors": [
      "Nathalie Percie du Sert",
      "Viki Hurst",
      "Amrita Ahluwalia",
      "Sabina Alam",
      "Marc T. Avey",
      "Monya Baker",
      "William J. Browne",
      "Alejandra Clark",
      "Innes C. Cuthill",
      "Ulrich Dirnagl",
      "Michael Emerson",
      "Paul Garner",
      "Stephen T. Holgate",
      "David W. Howells",
      "Natasha A. Karp",
      "Stanley E. Lazic",
      "Katie Lidster",
      "Catriona MacCallum",
      "Malcolm Macleod",
      "Esther J. Pearl",
      "Ole H. Petersen",
      "Frances Rawle",
      "Penny S. Reynolds",
      "Kieron Rooney",
      "Emily S. Sena",
      "Shai D. Silberberg",
      "Thomas Steckler",
      "Hanno W\u00fcrbel"
    ],
    "year": 2020,
    "abstract": null,
    "doi": "10.1186/s12917-020-02451-y",
    "url": "https://openalex.org/W4240644295",
    "pdf_url": "https://bmcvetres.biomedcentral.com/track/pdf/10.1186/s12917-020-02451-y",
    "venue": "BMC Veterinary Research",
    "citation_count": 399,
    "fields_of_study": [
      "Rigour",
      "Checklist",
      "Transparency (behavior)",
      "Context (archaeology)",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622487"
  },
  {
    "source": "openalex",
    "source_id": "W3111333805",
    "title": "The Recent Progress and Applications of Digital Technologies in Healthcare: A Review",
    "authors": [
      "Maksut Senbekov",
      "Timur Saliev",
      "Zhanar Bukeyeva",
      "Aigul Almabayeva",
      "Marina Zhanaliyeva",
      "Nazym Aitenova",
      "Yerzhan Toishibekov",
      "Ildar Fakhradiyev"
    ],
    "year": 2020,
    "abstract": "Background. The implementation of medical digital technologies can provide better accessibility and flexibility of healthcare for the public. It encompasses the availability of open information on the health, treatment, complications, and recent progress on biomedical research. At present, even in low-income countries, diagnostic and medical services are becoming more accessible and available. However, many issues related to digital health technologies remain unmet, including the reliability, safety, testing, and ethical aspects. Purpose. The aim of the review is to discuss and analyze the recent progress on the application of big data, artificial intelligence, telemedicine, block-chain platforms, smart devices in healthcare, and medical education. Basic Design. The publication search was carried out using Google Scholar, PubMed, Web of Sciences, Medline, Wiley Online Library, and CrossRef databases. The review highlights the applications of artificial intelligence, \u201cbig data,\u201d telemedicine and block-chain technologies, and smart devices (internet of things) for solving the real problems in healthcare and medical education. Major Findings. We identified 252 papers related to the digital health area. However, the number of papers discussed in the review was limited to 152 due to the exclusion criteria. The literature search demonstrated that digital health technologies became highly sought due to recent pandemics, including COVID-19. The disastrous dissemination of COVID-19 through all continents triggered the need for fast and effective solutions to localize, manage, and treat the viral infection. In this regard, the use of telemedicine and other e-health technologies might help to lessen the pressure on healthcare systems. Summary. Digital platforms can help optimize diagnosis, consulting, and treatment of patients. However, due to the lack of official regulations and recommendations, the stakeholders, including private and governmental organizations, are facing the problem with adequate validation and approbation of novel digital health technologies. In this regard, proper scientific research is required before a digital product is deployed for the healthcare sector.",
    "doi": "10.1155/2020/8830200",
    "url": "https://openalex.org/W3111333805",
    "pdf_url": "https://downloads.hindawi.com/journals/ijta/2020/8830200.pdf",
    "venue": "International Journal of Telemedicine and Applications",
    "citation_count": 388,
    "fields_of_study": [
      "Telemedicine",
      "Digital health",
      "Health care",
      "Flexibility (engineering)",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622490"
  },
  {
    "source": "openalex",
    "source_id": "W4224288650",
    "title": "Priorities for cancer research in low- and middle-income countries: a global perspective",
    "authors": [
      "C.S. Pramesh",
      "Rajendra Badwe",
      "Nirmala Bhoo\u2010Pathy",
      "Christopher M. Booth",
      "Girish Chinnaswamy",
      "Anna Dare",
      "Victor Piana de Andrade",
      "David J. Hunter",
      "Satish Gopal",
      "Mary Gospodarowicz",
      "Sanjeeva Gunasekera",
      "Andr\u00e8 Ilbawi",
      "Sharon Kapambwe",
      "T. Peter Kingham",
      "Tezer Kutluk",
      "Nirmal Lamichhane",
      "Miriam Mutebi",
      "Jackson Orem",
      "Groesbeck P. Parham",
      "Priya Ranganathan",
      "Manju Sengar",
      "Richard Sullivan",
      "Soumya Swaminathan",
      "Ian F. Tannock",
      "Vivek Tomar",
      "Verna Vanderpuye",
      "Cherian Varghese",
      "Elisabete Weiderpass"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1038/s41591-022-01738-x",
    "url": "https://openalex.org/W4224288650",
    "pdf_url": "https://www.nature.com/articles/s41591-022-01738-x.pdf",
    "venue": "Nature Medicine",
    "citation_count": 362,
    "fields_of_study": [
      "Low and middle income countries",
      "Perspective (graphical)",
      "Business",
      "Control (management)",
      "Cancer"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622517"
  },
  {
    "source": "openalex",
    "source_id": "W3048335295",
    "title": "Out of the laboratory and into the classroom: the future of artificial intelligence in education",
    "authors": [
      "Daniel Schiff"
    ],
    "year": 2020,
    "abstract": null,
    "doi": "10.1007/s00146-020-01033-8",
    "url": "https://openalex.org/W3048335295",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s00146-020-01033-8.pdf",
    "venue": "AI & Society",
    "citation_count": 280,
    "fields_of_study": [
      "Sociotechnical system",
      "Status quo",
      "Skepticism",
      "Alienation",
      "Democratization"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622519"
  },
  {
    "source": "openalex",
    "source_id": "W3082604781",
    "title": "HyperKvasir, a comprehensive multi-class image and video dataset for gastrointestinal endoscopy",
    "authors": [
      "Hanna Borgli",
      "Vajira Thambawita",
      "Pia H. Smedsrud",
      "Steven A. Hicks",
      "Debesh Jha",
      "Sigrun Losada Eskeland",
      "Kristin Ranheim Randel",
      "Konstantin Pogorelov",
      "Mathias Lux",
      "Duc Tien Dang Nguyen",
      "Dag Johansen",
      "Carsten Griwodz",
      "H\u00e5kon Kvale Stensland",
      "Enrique Garcia-Ceja",
      "Peter T. Schmidt",
      "Hugo L. Hammer",
      "Michael A. Riegler",
      "P\u00e5l Halvorsen",
      "Thomas de Lange"
    ],
    "year": 2020,
    "abstract": "Abstract Artificial intelligence is currently a hot topic in medicine. However, medical data is often sparse and hard to obtain due to legal restrictions and lack of medical personnel for the cumbersome and tedious process to manually label training data. These constraints make it difficult to develop systems for automatic analysis, like detecting disease or other lesions. In this respect, this article presents HyperKvasir , the largest image and video dataset of the gastrointestinal tract available today. The data is collected during real gastro- and colonoscopy examinations at B\u00e6rum Hospital in Norway and partly labeled by experienced gastrointestinal endoscopists. The dataset contains 110,079 images and 374 videos, and represents anatomical landmarks as well as pathological and normal findings. The total number of images and video frames together is around 1 million. Initial experiments demonstrate the potential benefits of artificial intelligence-based computer-assisted diagnosis systems. The HyperKvasir dataset can play a valuable role in developing better algorithms and computer-assisted examination systems not only for gastro- and colonoscopy, but also for other fields in medicine.",
    "doi": "10.1038/s41597-020-00622-y",
    "url": "https://openalex.org/W3082604781",
    "pdf_url": "https://www.nature.com/articles/s41597-020-00622-y.pdf",
    "venue": "Scientific Data",
    "citation_count": 458,
    "fields_of_study": [
      "Computer science",
      "Colonoscopy",
      "Artificial intelligence",
      "Class (philosophy)",
      "Process (computing)"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622523"
  },
  {
    "source": "openalex",
    "source_id": "W4388488349",
    "title": "Should ChatGPT be biased? Challenges and risks of bias in large language models",
    "authors": [
      "Emilio Ferrara"
    ],
    "year": 2023,
    "abstract": "As generative language models, exemplified by ChatGPT, continue to advance in their capabilities, the spotlight on biases inherent in these models intensifies. This paper delves into the distinctive challenges and risks associated with biases specifically in large-scale language models. We explore the origins of biases, stemming from factors such as training data, model specifications, algorithmic constraints, product design, and policy decisions. Our examination extends to the ethical implications arising from the unintended consequences of biased model outputs. In addition, we analyze the intricacies of mitigating biases, acknowledging the inevitable persistence of some biases, and consider the consequences of deploying these models across diverse applications, including virtual assistants, content generation, and chatbots. Finally, we provide an overview of current approaches for identifying, quantifying, and mitigating biases in language models, underscoring the need for a collaborative, multidisciplinary effort to craft AI systems that embody equity, transparency, and responsibility. This article aims to catalyze a thoughtful discourse within the AI community, prompting researchers and developers to consider the unique role of biases in the domain of generative language models and the ongoing quest for ethical AI.",
    "doi": "10.5210/fm.v28i11.13346",
    "url": "https://openalex.org/W4388488349",
    "pdf_url": "https://firstmonday.org/ojs/index.php/fm/article/download/13346/11369",
    "venue": "First Monday",
    "citation_count": 181,
    "fields_of_study": [
      "Unintended consequences",
      "Transparency (behavior)",
      "Computer science",
      "Generative grammar",
      "Language model"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622538"
  },
  {
    "source": "openalex",
    "source_id": "W4386619339",
    "title": "Deep Learning and Artificial Intelligence in Sustainability: A Review of SDGs, Renewable Energy, and Environmental Health",
    "authors": [
      "Zhencheng Fan",
      "Zheng Yan",
      "Shiping Wen"
    ],
    "year": 2023,
    "abstract": "Artificial intelligence (AI) and deep learning (DL) have shown tremendous potential in driving sustainability across various sectors. This paper reviews recent advancements in AI and DL and explores their applications in achieving sustainable development goals (SDGs), renewable energy, environmental health, and smart building energy management. AI has the potential to contribute to 134 of the 169 targets across all SDGs, but the rapid development of these technologies necessitates comprehensive regulatory oversight to ensure transparency, safety, and ethical standards. In the renewable energy sector, AI and DL have been effectively utilized in optimizing energy management, fault detection, and power grid stability. They have also demonstrated promise in enhancing waste management and predictive analysis in photovoltaic power plants. In the field of environmental health, the integration of AI and DL has facilitated the analysis of complex spatial data, improving exposure modeling and disease prediction. However, challenges such as the explainability and transparency of AI and DL models, the scalability and high dimensionality of data, the integration with next-generation wireless networks, and ethics and privacy concerns need to be addressed. Future research should focus on enhancing the explainability and transparency of AI and DL models, developing scalable algorithms for processing large datasets, exploring the integration of AI with next-generation wireless networks, and addressing ethical and privacy considerations. Additionally, improving the energy efficiency of AI and DL models is crucial to ensure the sustainable use of these technologies. By addressing these challenges and fostering responsible and innovative use, AI and DL can significantly contribute to a more sustainable future.",
    "doi": "10.3390/su151813493",
    "url": "https://openalex.org/W4386619339",
    "pdf_url": "https://www.mdpi.com/2071-1050/15/18/13493/pdf?version=1694397493",
    "venue": "Sustainability",
    "citation_count": 236,
    "fields_of_study": [
      "Transparency (behavior)",
      "Sustainability",
      "Renewable energy",
      "Computer science",
      "Scalability"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622553"
  },
  {
    "source": "openalex",
    "source_id": "W4234956358",
    "title": "Artificial Intelligence for a Better Future",
    "authors": [
      "Bernd Carsten Stahl"
    ],
    "year": 2021,
    "abstract": "This open access book proposes a novel approach to Artificial Intelligence (AI) ethics. AI offers many advantages: better and faster medical diagnoses, improved business processes and efficiency, and the automation of boring work. But undesirable and ethically problematic consequences are possible too: biases and discrimination, breaches of privacy and security, and societal distortions such as unemployment, economic exploitation and weakened democratic processes. There is even a prospect, ultimately, of super-intelligent machines replacing humans. The key question, then, is: how can we benefit from AI while addressing its ethical problems? This book presents an innovative answer to the question by presenting a different perspective on AI and its ethical consequences. Instead of looking at individual AI techniques, applications or ethical issues, we can understand AI as a system of ecosystems, consisting of numerous interdependent technologies, applications and stakeholders. Developing this idea, the book explores how AI ecosystems can be shaped to foster human flourishing. Drawing on rich empirical insights and detailed conceptual analysis, it suggests practical measures to ensure that AI is used to make the world a better place.",
    "doi": "10.1007/978-3-030-69978-9",
    "url": "https://openalex.org/W4234956358",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/978-3-030-69978-9.pdf",
    "venue": "SpringerBriefs in research and innovation governance",
    "citation_count": 238,
    "fields_of_study": [
      "Computer science",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622572"
  },
  {
    "source": "openalex",
    "source_id": "W2995382404",
    "title": "Roles for computing in social change",
    "authors": [
      "Rediet Abebe",
      "Solon Barocas",
      "Jon Kleinberg",
      "Karen Levy",
      "Manish Raghavan",
      "David G. Robinson"
    ],
    "year": 2020,
    "abstract": "A recent normative turn in computer science has brought concerns about fairness, bias, and accountability to the core of the field. Yet recent scholarship has warned that much of this technical work treats problematic features of the status quo as fixed, and fails to address deeper patterns of injustice and inequality. While acknowledging these critiques, we posit that computational research has valuable roles to play in addressing social problems -- roles whose value can be recognized even from a perspective that aspires toward fundamental social change. In this paper, we articulate four such roles, through an analysis that considers the opportunities as well as the significant risks inherent in such work. Computing research can serve as a diagnostic, helping us to understand and measure social problems with precision and clarity. As a formalizer, computing shapes how social problems are explicitly defined --- changing how those problems, and possible responses to them, are understood. Computing serves as rebuttal when it illuminates the boundaries of what is possible through technical means. And computing acts as synecdoche when it makes long-standing social problems newly salient in the public eye. We offer these paths forward as modalities that leverage the particular strengths of computational work in the service of social change, without overclaiming computing's capacity to solve social problems on its own.",
    "doi": "10.1145/3351095.3372871",
    "url": "https://openalex.org/W2995382404",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3351095.3372871",
    "venue": null,
    "citation_count": 196,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:11.622587"
  },
  {
    "source": "openalex",
    "source_id": "W4312000342",
    "title": "Economics of Artificial Intelligence in Healthcare: Diagnosis vs. Treatment",
    "authors": [
      "Narendra N. Khanna",
      "Mahesh Maindarkar",
      "Vijay Viswanathan",
      "Jos\u00e9 Fernandes e Fernandes",
      "Sudip Paul",
      "Mrinalini Bhagawati",
      "Puneet Ahluwalia",
      "Zolt\u00e1n Ruzsa",
      "Aditya Sharma",
      "Raghu Kolluri",
      "Inder M. Singh",
      "John R. Laird",
      "Mostafa Fatemi",
      "Azra Alizad",
      "Luca Saba",
      "Vikas Agarwal",
      "Aman Sharma",
      "Jagjit S. Teji",
      "Mustafa Al-Maini",
      "Vijay Rathore",
      "Subbaram Naidu",
      "Kiera Liblik",
      "Amer M. Johri",
      "Monika Turk",
      "Lopamudra Mohanty",
      "David Sobel",
      "Martin Miner",
      "Klaudija Vi\u0161kovi\u0107",
      "George Tsoulfas",
      "Athanase D. Protogerou",
      "George D. Kitas",
      "Mostafa M. Fouda",
      "Seemant Chaturvedi",
      "Mannudeep K. Kalra",
      "Jasjit S. Suri"
    ],
    "year": 2022,
    "abstract": "Motivation: The price of medical treatment continues to rise due to (i) an increasing population; (ii) an aging human growth; (iii) disease prevalence; (iv) a rise in the frequency of patients that utilize health care services; and (v) increase in the price. Objective: Artificial Intelligence (AI) is already well-known for its superiority in various healthcare applications, including the segmentation of lesions in images, speech recognition, smartphone personal assistants, navigation, ride-sharing apps, and many more. Our study is based on two hypotheses: (i) AI offers more economic solutions compared to conventional methods; (ii) AI treatment offers stronger economics compared to AI diagnosis. This novel study aims to evaluate AI technology in the context of healthcare costs, namely in the areas of diagnosis and treatment, and then compare it to the traditional or non-AI-based approaches. Methodology: PRISMA was used to select the best 200 studies for AI in healthcare with a primary focus on cost reduction, especially towards diagnosis and treatment. We defined the diagnosis and treatment architectures, investigated their characteristics, and categorized the roles that AI plays in the diagnostic and therapeutic paradigms. We experimented with various combinations of different assumptions by integrating AI and then comparing it against conventional costs. Lastly, we dwell on three powerful future concepts of AI, namely, pruning, bias, explainability, and regulatory approvals of AI systems. Conclusions: The model shows tremendous cost savings using AI tools in diagnosis and treatment. The economics of AI can be improved by incorporating pruning, reduction in AI bias, explainability, and regulatory approvals.",
    "doi": "10.3390/healthcare10122493",
    "url": "https://openalex.org/W4312000342",
    "pdf_url": "https://www.mdpi.com/2227-9032/10/12/2493/pdf?version=1670894037",
    "venue": "Healthcare",
    "citation_count": 290,
    "fields_of_study": [
      "Health care",
      "Population ageing",
      "Population",
      "Artificial intelligence",
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622608"
  },
  {
    "source": "openalex",
    "source_id": "W2884074583",
    "title": "AI and Big Data: A blueprint for a human rights, social and ethical impact assessment",
    "authors": [
      "Alessandro Mantelero"
    ],
    "year": 2018,
    "abstract": "The use of algorithms in modern data processing techniques, as well as data-intensive technological trends, suggests the adoption of a broader view of the data protection impact assessment. This will force data controllers to go beyond the traditional focus on data quality and security, and consider the impact of data processing on fundamental rights and collective social and ethical values. Building on studies of the collective dimension of data protection, this article sets out to embed this new perspective in an assessment model centred on human rights (Human Rights, Ethical and Social Impact Assessment-HRESIA). This self-assessment model intends to overcome the limitations of the existing assessment models, which are either too closely focused on data processing or have an extent and granularity that make them too complicated to evaluate the consequences of a given use of data. In terms of architecture, the HRESIA has two main elements: a self-assessment questionnaire and an ad hoc expert committee. As a blueprint, this contribution focuses mainly on the nature of the proposed model, its architecture and its challenges; a more detailed description of the model and the content of the questionnaire will be discussed in a future publication drawing on the ongoing research.",
    "doi": "10.1016/j.clsr.2018.05.017",
    "url": "https://openalex.org/W2884074583",
    "pdf_url": "https://www.sciencedirect.com/science/article/pii/S0267364918302012?via%3Dihub",
    "venue": "Computer law & security review",
    "citation_count": 263,
    "fields_of_study": [
      "Blueprint",
      "Computer science",
      "Social impact assessment",
      "Data quality",
      "Data science"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622627"
  },
  {
    "source": "openalex",
    "source_id": "W4399518864",
    "title": "The impact of generative artificial intelligence on socioeconomic inequalities and policy making",
    "authors": [
      "Valerio Capraro",
      "Austin Lentsch",
      "Daron Acemo\u011flu",
      "Selin Akg\u00fcn",
      "Aisel Akhmedova",
      "Ennio Bilancini",
      "Jean\u2010Fran\u00e7ois Bonnefon",
      "Pablo Bra\u00f1as\u2010Garza",
      "Luigi Butera",
      "Karen M. Douglas",
      "Jim A. C. Everett",
      "Gerd Gigerenzer",
      "Christine Greenhow",
      "Daniel A. Hashimoto",
      "Julianne Holt\u2010Lunstad",
      "Jolanda Jetten",
      "Simon Johnson",
      "Werner H. Kunz",
      "Chiara Longoni",
      "Pete Lunn",
      "Simone Natale",
      "Stefanie Paluch",
      "Iyad Rahwan",
      "Neil Selwyn",
      "Vivek Singh",
      "Siddharth Suri",
      "Jennifer Sutcliffe",
      "Joe Tomlinson",
      "Sander van der Linden",
      "Paul A. M. Van Lange",
      "Friederike Wall",
      "Jay Joseph Van Bavel",
      "Riccardo Viale"
    ],
    "year": 2024,
    "abstract": "Abstract Generative artificial intelligence (AI) has the potential to both exacerbate and ameliorate existing socioeconomic inequalities. In this article, we provide a state-of-the-art interdisciplinary overview of the potential impacts of generative AI on (mis)information and three information-intensive domains: work, education, and healthcare. Our goal is to highlight how generative AI could worsen existing inequalities while illuminating how AI may help mitigate pervasive social problems. In the information domain, generative AI can democratize content creation and access but may dramatically expand the production and proliferation of misinformation. In the workplace, it can boost productivity and create new jobs, but the benefits will likely be distributed unevenly. In education, it offers personalized learning, but may widen the digital divide. In healthcare, it might improve diagnostics and accessibility, but could deepen pre-existing inequalities. In each section, we cover a specific topic, evaluate existing research, identify critical gaps, and recommend research directions, including explicit trade-offs that complicate the derivation of a priori hypotheses. We conclude with a section highlighting the role of policymaking to maximize generative AI's potential to reduce inequalities while mitigating its harmful effects. We discuss strengths and weaknesses of existing policy frameworks in the European Union, the United States, and the United Kingdom, observing that each fails to fully confront the socioeconomic challenges we have identified. We propose several concrete policies that could promote shared prosperity through the advancement of generative AI. This article emphasizes the need for interdisciplinary collaborations to understand and address the complex challenges of generative AI.",
    "doi": "10.1093/pnasnexus/pgae191",
    "url": "https://openalex.org/W4399518864",
    "pdf_url": "https://academic.oup.com/pnasnexus/article-pdf/3/6/pgae191/58184311/pgae191.pdf",
    "venue": "PNAS Nexus",
    "citation_count": 217,
    "fields_of_study": [
      "Generative grammar",
      "Inequality",
      "Socioeconomic status",
      "Computer science",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622646"
  },
  {
    "source": "openalex",
    "source_id": "W3161588210",
    "title": "Replicability, Robustness, and Reproducibility in Psychological Science",
    "authors": [
      "Brian A. Nosek",
      "Tom E Hardwicke",
      "Hannah Moshontz",
      "Aur\u00e9lien Allard",
      "Katherine S. Corker",
      "Anna Dreber",
      "Fiona Fidler",
      "Joe Hilgard",
      "Melissa Kline Struhl",
      "Mich\u00e8le B. Nuijten",
      "Julia M. Rohrer",
      "Felipe Romero",
      "Anne M. Scheel",
      "Laura D. Scherer",
      "Felix D. Sch\u00f6nbrodt",
      "Simine Vazire"
    ],
    "year": 2021,
    "abstract": "Replication\u2014an important, uncommon, and misunderstood practice\u2014is gaining appreciation in psychology. Achieving replicability is important for making research progress. If findings are not replicable, then prediction and theory development are stifled. If findings are replicable, then interrogation of their meaning and validity can advance knowledge. Assessing replicability can be productive for generating and testing hypotheses by actively confronting current understandings to identify weaknesses and spur innovation. For psychology, the 2010s might be characterized as a decade of active confrontation. Systematic and multi-site replication projects assessed current understandings and observed surprising failures to replicate many published findings. Replication efforts highlighted sociocultural challenges such as disincentives to conduct replications and a tendency to frame replication as a personal attack rather than a healthy scientific practice, and they raised awareness that replication contributes to self-correction. Nevertheless, innovation in doing and understanding replication and its cousins, reproducibility and robustness, has positioned psychology to improve research practices and accelerate progress.",
    "doi": "10.1146/annurev-psych-020821-114157",
    "url": "https://openalex.org/W3161588210",
    "pdf_url": "https://www.annualreviews.org/doi/pdf/10.1146/annurev-psych-020821-114157",
    "venue": "Annual Review of Psychology",
    "citation_count": 676,
    "fields_of_study": [
      "Psychology",
      "Replication (statistics)",
      "Sociocultural evolution",
      "Social psychology",
      "Psychological science"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622667"
  },
  {
    "source": "openalex",
    "source_id": "W4220921529",
    "title": "Digital transformation, for better or worse: a critical multi\u2010level research agenda",
    "authors": [
      "Justyna D\u0105browska",
      "Argyro Almpanopoulou",
      "Alexander Brem",
      "Henry Chesbrough",
      "Valentina Cucino",
      "Alberto Di Minin",
      "Ferran Giones",
      "Henri Hakala",
      "Cristina Marullo",
      "Anne\u2010Laure Mention",
      "Letizia Mortara",
      "Sladjana N\u00f8rskov",
      "Petra A. Nylund",
      "Calogero Maria Oddo",
      "Agnieszka Radziwon",
      "Paavo Ritala"
    ],
    "year": 2022,
    "abstract": "For better or worse, digital technologies are reshaping everything, from customer behaviors and expectations to organizational and manufacturing systems, business models, markets, and ultimately society. To understand this overarching transformation, this paper extends the previous literature which has focused mostly on the organizational level by developing a multi\u2010level research agenda for digital transformation (DT). In this regard, we propose an extended definition of DT as \u201ca socioeconomic change across individuals, organizations, ecosystems, and societies that are shaped by the adoption and utilization of digital technologies.\u201d We suggest four lenses to interpret the DT phenomenon: individuals (utilizing and adopting digital technologies), organizations (strategizing and coordinating both internal and external transformation), ecosystems (harnessing digital technologies in governance and co\u2010producing value propositions), and geopolitical frameworks (regulating the environments in which individuals and organizations are embedded). Based on these lenses, we build a multi\u2010level research agenda at the intersection between the bright and dark sides of DT and introduce the PIAI framework, which captures a process of perception , interpretation , and action that ultimately leads to possible impact . The PIAI framework identifies a critical research agenda consisting of a non\u2010exhaustive list of topics that can assist researchers to deepen their understanding of the DT phenomenon and provide guidance to managers and policymakers when making strategic decisions that seek to shape and guide the DT.",
    "doi": "10.1111/radm.12531",
    "url": "https://openalex.org/W4220921529",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/radm.12531",
    "venue": "R and D Management",
    "citation_count": 278,
    "fields_of_study": [
      "Transformation (genetics)",
      "Digital transformation",
      "Computer science",
      "Political science",
      "World Wide Web"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622682"
  },
  {
    "source": "openalex",
    "source_id": "W4381587418",
    "title": "Opportunities and challenges for ChatGPT and large language models in biomedicine and health",
    "authors": [
      "Shubo Tian",
      "Qiao Jin",
      "Lana Yeganova",
      "Po\u2010Ting Lai",
      "Qingqing Zhu",
      "Xiuying Chen",
      "Yifan Yang",
      "Qingyu Chen",
      "Won Bae Kim",
      "Donald C. Comeau",
      "Rezarta Islamaj",
      "Aadit Kapoor",
      "Xin Gao",
      "Zhiyong Lu"
    ],
    "year": 2023,
    "abstract": "Abstract ChatGPT has drawn considerable attention from both the general public and domain experts with its remarkable text generation capabilities. This has subsequently led to the emergence of diverse applications in the field of biomedicine and health. In this work, we examine the diverse applications of large language models (LLMs), such as ChatGPT, in biomedicine and health. Specifically, we explore the areas of biomedical information retrieval, question answering, medical text summarization, information extraction and medical education and investigate whether LLMs possess the transformative power to revolutionize these tasks or whether the distinct complexities of biomedical domain presents unique challenges. Following an extensive literature survey, we find that significant advances have been made in the field of text generation tasks, surpassing the previous state-of-the-art methods. For other applications, the advances have been modest. Overall, LLMs have not yet revolutionized biomedicine, but recent rapid progress indicates that such methods hold great potential to provide valuable means for accelerating discovery and improving health. We also find that the use of LLMs, like ChatGPT, in the fields of biomedicine and health entails various risks and challenges, including fabricated information in its generated responses, as well as legal and privacy concerns associated with sensitive patient data. We believe this survey can provide a comprehensive and timely overview to biomedical researchers and healthcare practitioners on the opportunities and challenges associated with using ChatGPT and other LLMs for transforming biomedicine and health.",
    "doi": "10.1093/bib/bbad493",
    "url": "https://openalex.org/W4381587418",
    "pdf_url": "https://academic.oup.com/bib/article-pdf/25/1/bbad493/54942208/bbad493.pdf",
    "venue": "Briefings in Bioinformatics",
    "citation_count": 305,
    "fields_of_study": [
      "Biomedicine",
      "Computer science",
      "Data science",
      "Natural language processing",
      "Bioinformatics"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622702"
  },
  {
    "source": "openalex",
    "source_id": "W4293231014",
    "title": "Citizen science in environmental and ecological sciences",
    "authors": [
      "Dilek Fraisl",
      "Gerid Hager",
      "Baptiste Bedessem",
      "Margaret M. Gold",
      "Pen\u2010Yuan Hsing",
      "Finn Danielsen",
      "Colleen Hitchcock",
      "Joseph M. Hulbert",
      "Jaume Piera",
      "Helen Spiers",
      "Mart\u00edn Thiel",
      "Muki Haklay"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1038/s43586-022-00144-4",
    "url": "https://openalex.org/W4293231014",
    "pdf_url": "https://www.nature.com/articles/s43586-022-00144-4.pdf",
    "venue": "Nature Reviews Methods Primers",
    "citation_count": 413,
    "fields_of_study": [
      "Citizen science",
      "Data sharing",
      "Open science",
      "Engineering ethics",
      "Data collection"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622728"
  },
  {
    "source": "openalex",
    "source_id": "W4388895516",
    "title": "Harnessing the Power of AI: A Comprehensive Review of Its Impact and Challenges in Nursing Science and Healthcare",
    "authors": [
      "Seema Yelne",
      "Minakshi Chaudhary",
      "Karishma Dod",
      "Akhtaribano Sayyad",
      "Ranjana Sharma"
    ],
    "year": 2023,
    "abstract": "This comprehensive review delves into the impact and challenges of Artificial Intelligence (AI) in nursing science and healthcare. AI has already demonstrated its transformative potential in these fields, with applications spanning from personalized care and diagnostic accuracy to predictive analytics and telemedicine. However, the integration of AI has its complexities, including concerns related to data privacy, ethical considerations, and biases in algorithms and datasets. The future of healthcare appears promising, with AI poised to advance diagnostics, treatment, and healthcare practices. Nevertheless, it is crucial to remember that AI should complement, not replace, healthcare professionals, preserving the essential human element of care. To maximize AI's potential in healthcare, interdisciplinary collaboration, ethical guidelines, and the protection of patient rights are essential. This review concludes with a call to action, emphasizing the need for ongoing research and collective efforts to ensure that AI contributes to improved healthcare outcomes while upholding the highest standards of ethics and patient-centered care.",
    "doi": "10.7759/cureus.49252",
    "url": "https://openalex.org/W4388895516",
    "pdf_url": "https://assets.cureus.com/uploads/review_article/pdf/206741/20231122-10807-1n3hf8c.pdf",
    "venue": "Cureus",
    "citation_count": 159,
    "fields_of_study": [
      "Transformative learning",
      "Health care",
      "Medicine",
      "Engineering ethics",
      "Applications of artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622731"
  },
  {
    "source": "openalex",
    "source_id": "W3014246070",
    "title": "Primer on an ethics of AI-based decision support systems in the clinic",
    "authors": [
      "Matthias Braun",
      "Patrik Hummel",
      "Susanne Beck",
      "Peter Dabrock"
    ],
    "year": 2020,
    "abstract": "Making good decisions in extremely complex and difficult processes and situations has always been both a key task as well as a challenge in the clinic and has led to a large amount of clinical, legal and ethical routines, protocols and reflections in order to guarantee fair, participatory and up-to-date pathways for clinical decision-making. Nevertheless, the complexity of processes and physical phenomena, time as well as economic constraints and not least further endeavours as well as achievements in medicine and healthcare continuously raise the need to evaluate and to improve clinical decision-making. This article scrutinises if and how clinical decision-making processes are challenged by the rise of so-called artificial intelligence-driven decision support systems (AI-DSS). In a first step, this article analyses how the rise of AI-DSS will affect and transform the modes of interaction between different agents in the clinic. In a second step, we point out how these changing modes of interaction also imply shifts in the conditions of trustworthiness, epistemic challenges regarding transparency, the underlying normative concepts of agency and its embedding into concrete contexts of deployment and, finally, the consequences for (possible) ascriptions of responsibility. Third, we draw first conclusions for further steps regarding a \u2018meaningful human control\u2019 of clinical AI-DSS.",
    "doi": "10.1136/medethics-2019-105860",
    "url": "https://openalex.org/W3014246070",
    "pdf_url": "https://jme.bmj.com/content/medethics/47/12/e3.full.pdf",
    "venue": "Journal of Medical Ethics",
    "citation_count": 211,
    "fields_of_study": [
      "Normative",
      "Transparency (behavior)",
      "Agency (philosophy)",
      "Computer science",
      "Decision support system"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622746"
  },
  {
    "source": "openalex",
    "source_id": "W2972211076",
    "title": "Toward clinical digital phenotyping: a timely opportunity to consider purpose, quality, and safety",
    "authors": [
      "Kit Huckvale",
      "Svetha Venkatesh",
      "Helen Christensen"
    ],
    "year": 2019,
    "abstract": null,
    "doi": "10.1038/s41746-019-0166-1",
    "url": "https://openalex.org/W2972211076",
    "pdf_url": "https://www.nature.com/articles/s41746-019-0166-1.pdf",
    "venue": "npj Digital Medicine",
    "citation_count": 411,
    "fields_of_study": [
      "Multidisciplinary approach",
      "Digital health",
      "Psychological intervention",
      "Quality (philosophy)",
      "Relevance (law)"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622768"
  },
  {
    "source": "openalex",
    "source_id": "W3184865800",
    "title": "Machine learning and algorithmic fairness in public and population health",
    "authors": [
      "Vishwali Mhasawade",
      "Yuan Zhao",
      "Rumi Chunara"
    ],
    "year": 2021,
    "abstract": null,
    "doi": "10.1038/s42256-021-00373-4",
    "url": "https://openalex.org/W3184865800",
    "pdf_url": "https://www.nature.com/articles/s42256-021-00373-4.pdf",
    "venue": "Nature Machine Intelligence",
    "citation_count": 193,
    "fields_of_study": [
      "Health equity",
      "Public health",
      "Population health",
      "Artificial intelligence",
      "Machine learning"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622772"
  },
  {
    "source": "openalex",
    "source_id": "W4381570295",
    "title": "Navigating the Ethical Challenges of Artificial Intelligence in Higher Education: An Analysis of Seven Global AI Ethics Policies",
    "authors": [
      "Zouhaier Slimi",
      "Beatriz Villarejo-Carballido"
    ],
    "year": 2023,
    "abstract": "AI use in higher education raises ethical concerns that must be addressed. Biased algorithms pose a significant threat, especially if used in admission or grading processes, as they could have devastating effects on students. Another issue is the displacement of human educators by AI systems, and there are concerns about transparency and accountability as AI becomes more integrated into decision-making processes. This paper examined three AI objectives related higher education: biased algorithms, AI and decision-making, and human displacement. Discourse analysis of seven AI ethics policies was conducted, including those from UNESCO, China, the European Commission, Google, MIT, Sanford HAI, and Carnegie Mellon. The findings indicate that stakeholders must work together to address these challenges and ensure responsible AI deployment in higher education while maximizing its benefits. Fair use and protecting individuals, especially those with vulnerable characteristics, are crucial. Gender bias must be avoided in algorithm development, learning data sets, and AI decision-making. Data collection, labeling, and algorithm documentation must be of the highest quality to ensure traceability and openness. Universities must study the ethical, social, and policy implications of AI to ensure responsible development and deployment. The AI ethics policies stress responsible AI development and deployment, with a focus on transparency and accountability. Making AI systems more transparent and answerable may reduce the adverse effects of displacement. In conclusion, AI must be considered ethically in higher education, and stakeholders must ensure that AI is used responsibly, fairly, and in a way that maximizes its benefits while minimizing its risks.",
    "doi": "10.18421/tem122-02",
    "url": "https://openalex.org/W4381570295",
    "pdf_url": "https://www.temjournal.com/content/122/TEMJournalMay2023_590_602.pdf",
    "venue": "TEM Journal",
    "citation_count": 145,
    "fields_of_study": [
      "Accountability",
      "Transparency (behavior)",
      "Software deployment",
      "Openness to experience",
      "Documentation"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622774"
  },
  {
    "source": "openalex",
    "source_id": "W4288083800",
    "title": "Lessons from archives",
    "authors": [
      "Eun Seo Jo",
      "Timnit Gebru"
    ],
    "year": 2020,
    "abstract": "A growing body of work shows that many problems in fairness, accountability, transparency, and ethics in machine learning systems are rooted in decisions surrounding the data collection and annotation process. In spite of its fundamental nature however, data collection remains an overlooked part of the machine learning (ML) pipeline. In this paper, we argue that a new specialization should be formed within ML that is focused on methodologies for data collection and annotation: efforts that require institutional frameworks and procedures. Specifically for sociocultural data, parallels can be drawn from archives and libraries. Archives are the longest standing communal effort to gather human information and archive scholars have already developed the language and procedures to address and discuss many challenges pertaining to data collection such as consent, power, inclusivity, transparency, and ethics & privacy. We discuss these five key approaches in document collection practices in archives that can inform data collection in sociocultural ML. By showing data collection practices from another field, we encourage ML research to be more cognizant and systematic in data collection and draw from interdisciplinary expertise.",
    "doi": "10.1145/3351095.3372829",
    "url": "https://openalex.org/W4288083800",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3351095.3372829",
    "venue": null,
    "citation_count": 211,
    "fields_of_study": [
      "Transparency (behavior)",
      "Data collection",
      "Accountability",
      "Sociocultural evolution",
      "Parallels"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622796"
  },
  {
    "source": "openalex",
    "source_id": "W3097060730",
    "title": "Federated Learning in Smart City Sensing: Challenges and Opportunities",
    "authors": [
      "Ji Chu Jiang",
      "Burak Kantarc\u0131",
      "Sema Oktu\u011f",
      "Tolga Soyata"
    ],
    "year": 2020,
    "abstract": "Smart Cities sensing is an emerging paradigm to facilitate the transition into smart city services. The advent of the Internet of Things (IoT) and the widespread use of mobile devices with computing and sensing capabilities has motivated applications that require data acquisition at a societal scale. These valuable data can be leveraged to train advanced Artificial Intelligence (AI) models that serve various smart services that benefit society in all aspects. Despite their effectiveness, legacy data acquisition models backed with centralized Machine Learning models entail security and privacy concerns, and lead to less participation in large-scale sensing and data provision for smart city services. To overcome these challenges, Federated Learning is a novel concept that can serve as a solution to the privacy and security issues encountered within the process of data collection. This survey article presents an overview of smart city sensing and its current challenges followed by the potential of Federated Learning in addressing those challenges. A comprehensive discussion of the state-of-the-art methods for Federated Learning is provided along with an in-depth discussion on the applicability of Federated Learning in smart city sensing; clear insights on open issues, challenges, and opportunities in this field are provided as guidance for the researchers studying this subject matter.",
    "doi": "10.3390/s20216230",
    "url": "https://openalex.org/W3097060730",
    "pdf_url": "https://www.mdpi.com/1424-8220/20/21/6230/pdf?version=1604998232",
    "venue": "Sensors",
    "citation_count": 283,
    "fields_of_study": [
      "Computer science",
      "Process (computing)",
      "Smart city",
      "Data science",
      "Field (mathematics)"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622814"
  },
  {
    "source": "openalex",
    "source_id": "W4392293571",
    "title": "Global Regulatory Frameworks for the Use of Artificial Intelligence (AI) in the Healthcare Services Sector",
    "authors": [
      "Kavitha Palaniappan",
      "Elaine Yan Ting Lin",
      "Silke Vogel"
    ],
    "year": 2024,
    "abstract": "The healthcare sector is faced with challenges due to a shrinking healthcare workforce and a rise in chronic diseases that are worsening with demographic and epidemiological shifts. Digital health interventions that include artificial intelligence (AI) are being identified as some of the potential solutions to these challenges. The ultimate aim of these AI systems is to improve the patient\u2019s health outcomes and satisfaction, the overall population\u2019s health, and the well-being of healthcare professionals. The applications of AI in healthcare services are vast and are expected to assist, automate, and augment several healthcare services. Like any other emerging innovation, AI in healthcare also comes with its own risks and requires regulatory controls. A review of the literature was undertaken to study the existing regulatory landscape for AI in the healthcare services sector in developed nations. In the global regulatory landscape, most of the regulations for AI revolve around Software as a Medical Device (SaMD) and are regulated under digital health products. However, it is necessary to note that the current regulations may not suffice as AI-based technologies are capable of working autonomously, adapting their algorithms, and improving their performance over time based on the new real-world data that they have encountered. Hence, a global regulatory convergence for AI in healthcare, similar to the voluntary AI code of conduct that is being developed by the US-EU Trade and Technology Council, would be beneficial to all nations, be it developing or developed.",
    "doi": "10.3390/healthcare12050562",
    "url": "https://openalex.org/W4392293571",
    "pdf_url": "https://www.mdpi.com/2227-9032/12/5/562/pdf?version=1709256793",
    "venue": "Healthcare",
    "citation_count": 207,
    "fields_of_study": [
      "Health care",
      "Workforce",
      "Digital health",
      "Business",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622832"
  },
  {
    "source": "openalex",
    "source_id": "W4386242492",
    "title": "AI Art and its Impact on Artists",
    "authors": [
      "Harry H. Jiang",
      "Lauren T. Brown",
      "Jessica Yi-Yun Cheng",
      "Mehtab Khan",
      "Abhishek Gupta",
      "Deja Workman",
      "Alex Hanna",
      "Johnathan Flowers",
      "Timnit Gebru"
    ],
    "year": 2023,
    "abstract": "The last 3 years have resulted in machine learning (ML)-based image generators with the ability to output consistently higher quality images based on natural language prompts as inputs. As a result, many popular commercial \"generative AI Art\" products have entered the market, making generative AI an estimated $48B industry [125]. However, many professional artists have spoken up about the harms they have experienced due to the proliferation of large scale image generators trained on image/text pairs from the Internet. In this paper, we review some of these harms which include reputational damage, economic loss, plagiarism and copyright infringement. To guard against these issues while reaping the potential benefits of image generators, we provide recommendations such as regulation that forces organizations to disclose their training data, and tools that help artists prevent using their content as training data without their consent.",
    "doi": "10.1145/3600211.3604681",
    "url": "https://openalex.org/W4386242492",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3600211.3604681",
    "venue": null,
    "citation_count": 204,
    "fields_of_study": [
      "Guard (computer science)",
      "Generative grammar",
      "Computer science",
      "The Internet",
      "Quality (philosophy)"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622853"
  },
  {
    "source": "openalex",
    "source_id": "W4379508361",
    "title": "The Advent of Generative Language Models in Medical Education",
    "authors": [
      "Mert Karabacak",
      "Burak Berksu Ozkara",
      "Konstantinos Margetis",
      "Max Wintermark",
      "Sotirios Bisdas"
    ],
    "year": 2023,
    "abstract": "Artificial intelligence (AI) and generative language models (GLMs) present significant opportunities for enhancing medical education, including the provision of realistic simulations, digital patients, personalized feedback, evaluation methods, and the elimination of language barriers. These advanced technologies can facilitate immersive learning environments and enhance medical students' educational outcomes. However, ensuring content quality, addressing biases, and managing ethical and legal concerns present obstacles. To mitigate these challenges, it is necessary to evaluate the accuracy and relevance of AI-generated content, address potential biases, and develop guidelines and policies governing the use of AI-generated content in medical education. Collaboration among educators, researchers, and practitioners is essential for developing best practices, guidelines, and transparent AI models that encourage the ethical and responsible use of GLMs and AI in medical education. By sharing information about the data used for training, obstacles encountered, and evaluation methods, developers can increase their credibility and trustworthiness within the medical community. In order to realize the full potential of AI and GLMs in medical education while mitigating potential risks and obstacles, ongoing research and interdisciplinary collaboration are necessary. By collaborating, medical professionals can ensure that these technologies are effectively and responsibly integrated, contributing to enhanced learning experiences and patient care.",
    "doi": "10.2196/48163",
    "url": "https://openalex.org/W4379508361",
    "pdf_url": "https://mededu.jmir.org/2023/1/e48163/PDF",
    "venue": "JMIR Medical Education",
    "citation_count": 186,
    "fields_of_study": [
      "Credibility",
      "Relevance (law)",
      "Computer science",
      "Quality (philosophy)",
      "Knowledge management"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622866"
  },
  {
    "source": "openalex",
    "source_id": "W4302305162",
    "title": "Ethics and diversity in artificial intelligence policies, strategies and initiatives",
    "authors": [
      "Cathy Roche",
      "P. J. Wall",
      "David Lewis"
    ],
    "year": 2022,
    "abstract": "Abstract A burgeoning of Artificial Intelligence (AI) technologies in recent years has led to increased discussion about its potential to address many issues considered otherwise intractable, including those highlighted by the United Nations 2030 Agenda for Sustainable Development and associated Sustainable Development Goals. In tandem with this growth in AI is an expanding body of documentation regarding how such advanced technologies should be governed and managed. Issued by a variety of sources and comprising frameworks, policies and guidelines, this body of work encompasses the legal, social, ethical and policy issues around AI. With at least 470 such documents identified, as of May 2021, in the Council of Europe\u2019s tracker of AI initiatives, questions are emerging around the diversity of views expressed, especially regarding the influence of the Global North or Euro-American perspectives. Our previous analysis of a corpus of largely grey literature discovered blind spots regarding both gender representation and perspectives from the Global South. Expanding on that work, this paper examines a significantly extended corpus, with a focus on the role of underrepresented groups in the wider AI discourse. We find that voices from the Global South and consideration of alternative ethical approaches are largely absent from the conversation. In light of the prominence of social, cultural and ethical perspectives from the Global North, this paper explores implications for the development of standards for ethical AI. Concluding by offering approaches to incorporate more diverse ethical viewpoints and beliefs, we call for increased consideration of power structures when developing AI ethics policies and standards within these alternative socio-cultural and socio-economic contexts.",
    "doi": "10.1007/s43681-022-00218-9",
    "url": "https://openalex.org/W4302305162",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s43681-022-00218-9.pdf",
    "venue": "AI and Ethics",
    "citation_count": 144,
    "fields_of_study": [
      "Viewpoints",
      "Conversation",
      "Diversity (politics)",
      "Political science",
      "Engineering ethics"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622885"
  },
  {
    "source": "openalex",
    "source_id": "W4385469325",
    "title": "A Survey on ChatGPT: AI\u2013Generated Contents, Challenges, and Solutions",
    "authors": [
      "Yuntao Wang",
      "Yanghe Pan",
      "Miao Yan",
      "Zhou Su",
      "Tom H. Luan"
    ],
    "year": 2023,
    "abstract": "With the widespread use of large artificial intelligence (AI) models such as ChatGPT, AI-generated content (AIGC) has garnered increasing attention and is leading a paradigm shift in content creation and knowledge representation. AIGC uses generative large AI algorithms to assist or replace humans in creating massive, high-quality, and human-like content at a faster pace and lower cost, based on user-provided prompts. Despite the recent significant progress in AIGC, security, privacy, ethical, and legal challenges still need to be addressed. This paper presents an in-depth survey of working principles, security and privacy threats, state-of-the-art solutions, and future challenges of the AIGC paradigm. Specifically, we first explore the enabling technologies, general architecture of AIGC, and discuss its working modes and key characteristics. Then, we investigate the taxonomy of security and privacy threats to AIGC and highlight the ethical and societal implications of GPT and AIGC technologies. Furthermore, we review the state-of-the-art AIGC watermarking approaches for regulatable AIGC paradigms regarding the AIGC model and its produced content. Finally, we identify future challenges and open research directions related to AIGC.",
    "doi": "10.1109/ojcs.2023.3300321",
    "url": "https://openalex.org/W4385469325",
    "pdf_url": "https://ieeexplore.ieee.org/ielx7/8782664/9024218/10221755.pdf",
    "venue": "IEEE Open Journal of the Computer Society",
    "citation_count": 273,
    "fields_of_study": [
      "Pace",
      "Computer science",
      "Key (lock)",
      "Data science",
      "Generative grammar"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622911"
  },
  {
    "source": "openalex",
    "source_id": "W2786522954",
    "title": "Patiency is not a virtue: the design of intelligent systems and systems of ethics",
    "authors": [
      "Joanna J. Bryson"
    ],
    "year": 2018,
    "abstract": "The question of whether AI systems such as robots can or should be afforded moral agency or patiency is not one amenable either to discovery or simple reasoning, because we as societies constantly reconstruct our artefacts, including our ethical systems. Consequently, the place of AI systems in society is a matter of normative, not descriptive ethics. Here I start from a functionalist assumption, that ethics is the set of behaviour that maintains a society. This assumption allows me to exploit the theoretical biology of sociality and autonomy to explain our moral intuitions. From this grounding I extend to consider possible ethics for maintaining either human- or of artefact-centred societies. I conclude that while constructing AI systems as either moral agents or patients is possible, neither is desirable. In particular, I argue that we are unlikely to construct a coherent ethics in which it it is ethical to afford AI moral subjectivity. We are therefore obliged not to build AI we are obliged to.",
    "doi": "10.1007/s10676-018-9448-6",
    "url": "https://openalex.org/W2786522954",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007%2Fs10676-018-9448-6.pdf",
    "venue": "Ethics and Information Technology",
    "citation_count": 234,
    "fields_of_study": [
      "Autonomy",
      "Epistemology",
      "Sociology",
      "Exploit",
      "Normative"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622927"
  },
  {
    "source": "openalex",
    "source_id": "W4318483790",
    "title": "Evaluation of artificial intelligence techniques in disease diagnosis and prediction",
    "authors": [
      "Nafiseh Ghaffar Nia",
      "Erkan Kaplano\u011flu",
      "Ahad Nasab"
    ],
    "year": 2023,
    "abstract": "Abstract A broad range of medical diagnoses is based on analyzing disease images obtained through high-tech digital devices. The application of artificial intelligence (AI) in the assessment of medical images has led to accurate evaluations being performed automatically, which in turn has reduced the workload of physicians, decreased errors and times in diagnosis, and improved performance in the prediction and detection of various diseases. AI techniques based on medical image processing are an essential area of research that uses advanced computer algorithms for prediction, diagnosis, and treatment planning, leading to a remarkable impact on decision-making procedures. Machine Learning (ML) and Deep Learning (DL) as advanced AI techniques are two main subfields applied in the healthcare system to diagnose diseases, discover medication, and identify patient risk factors. The advancement of electronic medical records and big data technologies in recent years has accompanied the success of ML and DL algorithms. ML includes neural networks and fuzzy logic algorithms with various applications in automating forecasting and diagnosis processes. DL algorithm is an ML technique that does not rely on expert feature extraction, unlike classical neural network algorithms. DL algorithms with high-performance calculations give promising results in medical image analysis, such as fusion, segmentation, recording, and classification. Support Vector Machine (SVM) as an ML method and Convolutional Neural Network (CNN) as a DL method is usually the most widely used techniques for analyzing and diagnosing diseases. This review study aims to cover recent AI techniques in diagnosing and predicting numerous diseases such as cancers, heart, lung, skin, genetic, and neural disorders, which perform more precisely compared to specialists without human error. Also, AI's existing challenges and limitations in the medical area are discussed and highlighted.",
    "doi": "10.1007/s44163-023-00049-5",
    "url": "https://openalex.org/W4318483790",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s44163-023-00049-5.pdf",
    "venue": "Discover Artificial Intelligence",
    "citation_count": 321,
    "fields_of_study": [
      "Artificial intelligence",
      "Computer science",
      "Medical diagnosis",
      "Machine learning",
      "Artificial neural network"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622941"
  },
  {
    "source": "openalex",
    "source_id": "W4386293515",
    "title": "Artificial intelligence in clinical medicine: catalyzing a sustainable global healthcare paradigm",
    "authors": [
      "Gokul Krishnan",
      "Shiana Singh",
      "Monika Pathania",
      "Siddharth Gosavi",
      "Shuchi Abhishek",
      "Ashwin Parchani",
      "Minakshi Dhar"
    ],
    "year": 2023,
    "abstract": "As the demand for quality healthcare increases, healthcare systems worldwide are grappling with time constraints and excessive workloads, which can compromise the quality of patient care. Artificial intelligence (AI) has emerged as a powerful tool in clinical medicine, revolutionizing various aspects of patient care and medical research. The integration of AI in clinical medicine has not only improved diagnostic accuracy and treatment outcomes, but also contributed to more efficient healthcare delivery, reduced costs, and facilitated better patient experiences. This review article provides an extensive overview of AI applications in history taking, clinical examination, imaging, therapeutics, prognosis and research. Furthermore, it highlights the critical role AI has played in transforming healthcare in developing nations.",
    "doi": "10.3389/frai.2023.1227091",
    "url": "https://openalex.org/W4386293515",
    "pdf_url": "https://www.frontiersin.org/articles/10.3389/frai.2023.1227091/pdf",
    "venue": "Frontiers in Artificial Intelligence",
    "citation_count": 241,
    "fields_of_study": [
      "Health care",
      "Compromise",
      "Healthcare delivery",
      "Healthcare system",
      "Quality (philosophy)"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622964"
  },
  {
    "source": "openalex",
    "source_id": "W3037473845",
    "title": "A typology of circular economy discourses: Navigating the diverse visions of a contested paradigm",
    "authors": [
      "Martin Calisto Friant",
      "Walter J.V. Vermeulen",
      "Roberta Salomone"
    ],
    "year": 2020,
    "abstract": "The circular economy (CE) has recently become a popular discourse especially in government and corporate sectors. Given the socio-ecological challenges of the Anthropocene, the concept of CE could indeed help the transition to a sustainable, just and resilient future. However, the actual definition, objectives and forms of implementation of the CE are still unclear, inconsistent, and contested. Different actors and sectors are thus articulating circular discourses which align with their interests, and which often do not sufficiently examine the ecological, social and political implications of circularity. In this context, this research asks how to better navigate and analyse the history, complexity and plurality of circularity discourses by conceptually differentiating them in a comprehensive discourse typology. To answer this question a critical literature review has been carried out, which first, examines and reflects on the core challenges, gaps and limitations of the CE concept. Second, this research develops a comprehensive timeline of circularity thinking, which identifies and conceptually classifies 72 different CE-related concepts from the Global North and South (such as Gandhian and steady-state economics, buen vivir, doughnut economics and degrowth). This leads to the development of a typology of circularity discourses, which classifies circularity visions according to their position on fundamental social, technological, political and ecological issues. This research thus seeks to provide a basis for a more inclusive and comprehensive discussion on the topic, which opens the imaginary regarding the many circular futures that can exist and allows for a cross-pollination of ideas, policy options, strategies, practices and solutions.",
    "doi": "10.1016/j.resconrec.2020.104917",
    "url": "https://openalex.org/W3037473845",
    "pdf_url": "https://ars.els-cdn.com/content/image/1-s2.0-S0921344920302354-fx1_lrg.jpg",
    "venue": "Resources Conservation and Recycling",
    "citation_count": 549,
    "fields_of_study": [
      "Vision",
      "Typology",
      "Circular economy",
      "Degrowth",
      "Context (archaeology)"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622975"
  },
  {
    "source": "openalex",
    "source_id": "W4392621828",
    "title": "E-commerce and consumer behavior: A review of AI-powered personalization and market trends",
    "authors": [
      "Mustafa Ayobami Raji",
      "Hameedat Bukola Olodo",
      "Timothy Tolulope Oke",
      "Wilhelmina Afua Addy",
      "Onyeka Chrisanctus Ofodile",
      "Adedoyin Tolulope Oyewole"
    ],
    "year": 2024,
    "abstract": "In the dynamic landscape of electronic commerce (e-commerce), understanding and adapting to evolving consumer behavior is critical for the sustained success of online businesses. This review delves into the intersection of e-commerce and consumer behavior, focusing on the transformative role of Artificial Intelligence (AI)-powered personalization and its impact on market trends. The advent of AI has revolutionized the way e-commerce platforms engage with and cater to individual consumer preferences. AI-powered personalization techniques leverage advanced algorithms to analyze vast datasets, enabling the delivery of highly tailored and relevant content, product recommendations, and user experiences. This review explores the intricate mechanisms of AI-driven personalization, examining how it enhances customer engagement, satisfaction, and loyalty. Furthermore, the study investigates the prominent market trends shaped by AI in e-commerce. From chatbots and virtual assistants facilitating seamless customer interactions to predictive analytics optimizing inventory management, AI is driving innovation across various facets of the online retail landscape. The analysis delves into the integration of machine learning algorithms in predicting consumer preferences, streamlining the purchasing process, and fostering a more personalized shopping journey. As e-commerce continues to evolve, the review also explores the challenges and ethical considerations associated with AI-powered personalization. Issues such as data privacy, algorithmic bias, and the delicate balance between customization and intrusiveness are examined to provide a comprehensive understanding of the broader implications of AI in shaping consumer behavior. Ultimately, this review offers valuable insights into the symbiotic relationship between e-commerce and consumer behavior, shedding light on the transformative power of AI-powered personalization and its influence on emerging market trends. As businesses navigate the digital landscape, understanding and harnessing the potential of AI-driven strategies become imperative for staying competitive and meeting the evolving expectations of tech-savvy consumers.",
    "doi": "10.30574/gscarr.2024.18.3.0090",
    "url": "https://openalex.org/W4392621828",
    "pdf_url": "https://gsconlinepress.com/journals/gscarr/sites/default/files/GSCARR-2024-0090.pdf",
    "venue": "GSC Advanced Research and Reviews",
    "citation_count": 181,
    "fields_of_study": [
      "Personalization",
      "E-commerce",
      "Business",
      "Advertising",
      "Commerce"
    ],
    "retrieved_at": "2026-02-02T16:58:11.622996"
  },
  {
    "source": "openalex",
    "source_id": "W4394688113",
    "title": "REVOLUTIONIZING EDUCATION THROUGH AI: A COMPREHENSIVE REVIEW OF ENHANCING LEARNING EXPERIENCES",
    "authors": [
      "Oseremi Onesi-Ozigagun",
      "Yinka James Ololade",
      "Nsisong Louis Eyo-Udo",
      "Damilola Oluwaseun Ogundipe"
    ],
    "year": 2024,
    "abstract": "Artificial Intelligence (AI) is transforming the landscape of education, offering innovative solutions to enhance learning experiences. This review provides a comprehensive overview of how AI is revolutionizing education, focusing on its impact on learning outcomes, teaching methodologies, and the overall educational ecosystem. The adoption of AI in education has led to personalized learning experiences tailored to individual student needs. AI-powered adaptive learning systems analyze student performance data to create customized learning paths, ensuring that students receive content at their pace and level of understanding. This personalized approach improves student engagement and academic performance. AI is also reshaping teaching methodologies, providing educators with tools to streamline administrative tasks and enhance instructional strategies. AI-powered tools can automate grading, create interactive lessons, and provide real-time feedback to students. This allows teachers to focus more on facilitating learning and developing critical thinking skills in students. Furthermore, AI is revolutionizing the assessment process, moving beyond traditional exams to more dynamic and insightful evaluation methods. AI-powered assessment tools can analyze student responses in real-time, providing immediate feedback and insights into student comprehension and learning progress. The integration of AI in education also extends to administrative functions, such as student enrollment, scheduling, and resource allocation. AI-powered systems can optimize these processes, leading to more efficient and effective management of educational institutions. Despite the numerous benefits of AI in education, challenges remain, including concerns about data privacy, algorithmic bias, and the need for teacher training. Addressing these challenges will be crucial to maximizing the potential of AI in education and ensuring equitable access to quality education for all. In conclusion, AI is revolutionizing education by enhancing learning experiences, transforming teaching methodologies, and optimizing administrative processes. As AI continues to evolve, its impact on education is expected to grow, offering new opportunities to improve learning outcomes and prepare students for success in the digital age. Keywords: Revolutionizing, AI, Enhancing, Learning, Experiences.",
    "doi": "10.51594/ijarss.v6i4.1011",
    "url": "https://openalex.org/W4394688113",
    "pdf_url": "https://fepbl.com/index.php/ijarss/article/download/1011/1233",
    "venue": "International Journal of Applied Research in Social Sciences",
    "citation_count": 211,
    "fields_of_study": [
      "Engineering ethics",
      "Psychology",
      "Engineering"
    ],
    "retrieved_at": "2026-02-02T16:58:11.623019"
  },
  {
    "source": "openalex",
    "source_id": "W2784070037",
    "title": "Big healthcare data: preserving security and privacy",
    "authors": [
      "Karim Abouelmehdi",
      "Abderrahim Beni-Hessane",
      "Hayat Khaloufi"
    ],
    "year": 2018,
    "abstract": "Abstract Big data has fundamentally changed the way organizations manage, analyze and leverage data in any industry. One of the most promising fields where big data can be applied to make a change is healthcare. Big healthcare data has considerable potential to improve patient outcomes, predict outbreaks of epidemics, gain valuable insights, avoid preventable diseases, reduce the cost of healthcare delivery and improve the quality of life in general. However, deciding on the allowable uses of data while preserving security and patient\u2019s right to privacy is a difficult task. Big data, no matter how useful for the advancement of medical science and vital to the success of all healthcare organizations, can only be used if security and privacy issues are addressed. To ensure a secure and trustworthy big data environment, it is essential to identify the limitations of existing solutions and envision directions for future research. In this paper, we have surveyed the state-of-the-art security and privacy challenges in big data as applied to healthcare industry, assessed how security and privacy issues occur in case of big healthcare data and discussed ways in which they may be addressed. We mainly focused on the recently proposed methods based on anonymization and encryption, compared their strengths and limitations, and envisioned future research directions.",
    "doi": "10.1186/s40537-017-0110-7",
    "url": "https://openalex.org/W2784070037",
    "pdf_url": "https://journalofbigdata.springeropen.com/track/pdf/10.1186/s40537-017-0110-7",
    "venue": "Journal Of Big Data",
    "citation_count": 705,
    "fields_of_study": [
      "Big data",
      "Computer science",
      "Health care",
      "Leverage (statistics)",
      "Encryption"
    ],
    "retrieved_at": "2026-02-02T16:58:11.623043"
  },
  {
    "source": "openalex",
    "source_id": "W3001824711",
    "title": "Security and the smart city: A systematic review",
    "authors": [
      "Julian Laufs",
      "Herv\u00e9 Borrion",
      "Ben Bradford"
    ],
    "year": 2020,
    "abstract": null,
    "doi": "10.1016/j.scs.2020.102023",
    "url": "https://openalex.org/W3001824711",
    "pdf_url": "https://www.sciencedirect.com/science/article/pii/S221067072030010X",
    "venue": "Sustainable Cities and Society",
    "citation_count": 278,
    "fields_of_study": [
      "Smart city",
      "Architectural engineering",
      "Engineering",
      "Computer security",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:11.623061"
  },
  {
    "source": "openalex",
    "source_id": "W2989347311",
    "title": "The Organizational Reproduction of Inequality",
    "authors": [
      "John Amis",
      "Johanna Mair",
      "Kamal A. Munir"
    ],
    "year": 2019,
    "abstract": "With societal inequalities continuing to increase and organizations providing the vast majority of people with their income, we wanted to assess the ways in which organizational practices are implicated in the burgeoning of social and economic inequality. Following an integrative review of the literature drawn from across the social sciences, we found that the multiple ways in which five major organizational practices \u2013 hiring, role allocation, promotion, compensation and structuring \u2013 are enacted emerged as being central to the reproduction of inequality. We also uncovered how the persistence of these practices, and the inequality they induce, can be largely attributed to a constellation of three highly institutionalized myths, efficiency, meritocracy and positive globalization. Our analysis further reveals how, as scholars, we bear a corresponding responsibility to reconsider how we engage in research on and teaching about organizations. The implications of this for our future work are discussed.",
    "doi": "10.5465/annals.2017.0033",
    "url": "https://openalex.org/W2989347311",
    "pdf_url": "https://www.research.ed.ac.uk/en/publications/ffe6689d-f349-4603-94d7-1ba5552e923f",
    "venue": "Academy of Management Annals",
    "citation_count": 416,
    "fields_of_study": [
      "Meritocracy",
      "Reproduction",
      "Inequality",
      "Social inequality",
      "Globalization"
    ],
    "retrieved_at": "2026-02-02T16:58:11.623063"
  },
  {
    "source": "openalex",
    "source_id": "W4391898528",
    "title": "REVIEWING THE ETHICAL IMPLICATIONS OF AI IN DECISION MAKING PROCESSES",
    "authors": [
      "Femi Osasona",
      "Olukunle Oladipupo Amoo",
      "Akoh Atadoga",
      "Temitayo Oluwaseun Abrahams",
      "Oluwatoyin Ajoke Farayola",
      "Benjamin Samson Ayinla"
    ],
    "year": 2024,
    "abstract": "Artificial Intelligence (AI) has rapidly become an integral part of decision-making processes across various industries, revolutionizing the way choices are made. This Review delves into the ethical considerations associated with the use of AI in decision-making, exploring the implications of algorithms, automation, and machine learning. The incorporation of AI in decision-making introduces a myriad of ethical concerns that demand careful scrutiny. The opacity of algorithms raises questions about transparency, accountability, and bias. Decision-making processes driven by AI can be complex and difficult to interpret, leading to challenges in understanding how and why specific choices are made. As a result, ethical concerns emerge regarding the potential lack of transparency and accountability, especially when these decisions impact individuals or societal groups. Bias in AI algorithms poses a critical ethical challenge. Machine learning models learn from historical data, and if that data is biased, the AI system may perpetuate and even exacerbate existing biases. Addressing this challenge requires meticulous examination of training data, algorithmic design, and ongoing monitoring to ensure fairness and mitigate discrimination. The increased reliance on AI in decision-making processes also raises concerns about accountability and responsibility. When AI systems make decisions, determining who is ultimately responsible for those decisions becomes a complex ethical issue. Establishing a framework for accountability is crucial to ensure that individuals, organizations, and developers share responsibility for the outcomes of AI-driven decisions. Moreover, ethical considerations extend to the broader societal impact of AI in decision-making. Issues such as job displacement, economic inequality, and the potential concentration of power in the hands of a few require careful ethical examination. Striking a balance between technological advancement and social responsibility is paramount to ensuring that AI benefits society as a whole. In conclusion, this review highlights the ethical implications of integrating AI into decision-making processes. It underscores the need for transparency, fairness, and accountability to address concerns related to bias, responsibility, and the broader societal impact of AI-driven decisions. Ethical frameworks must evolve alongside technological advancements to foster a responsible and equitable integration of AI in decision-making processes. Keywords: Ethical, Implications, AI, Decision Making, Process.",
    "doi": "10.51594/ijmer.v6i2.773",
    "url": "https://openalex.org/W4391898528",
    "pdf_url": "https://fepbl.com/index.php/ijmer/article/download/773/967",
    "venue": "International Journal of Management & Entrepreneurship Research",
    "citation_count": 141,
    "fields_of_study": [
      "Engineering ethics",
      "Ethical decision",
      "Management science",
      "Political science",
      "Psychology"
    ],
    "retrieved_at": "2026-02-02T16:58:11.623077"
  },
  {
    "source": "openalex",
    "source_id": "W3137761476",
    "title": "Does \u201cAI\u201d stand for augmenting inequality in the era of covid-19 healthcare?",
    "authors": [
      "David Leslie",
      "Anjali Mazumder",
      "Aidan Peppin",
      "Maria K Wolters",
      "Alexa Hagerty"
    ],
    "year": 2021,
    "abstract": "Among the most damaging characteristics of the covid-19 pandemic has been its\\ndisproportionate effect on disadvantaged communities. As the outbreak has\\nspread globally, factors such as systemic racism, marginalisation, and\\nstructural inequality have created path dependencies that have led to poor\\nhealth outcomes. These social determinants of infectious disease and\\nvulnerability to disaster have converged to affect already disadvantaged\\ncommunities with higher levels of economic instability, disease exposure,\\ninfection severity, and death. Artificial intelligence (AI) technologies are an\\nimportant part of the health informatics toolkit used to fight contagious\\ndisease. AI is well known, however, to be susceptible to algorithmic biases\\nthat can entrench and augment existing inequality. Uncritically deploying AI in\\nthe fight against covid-19 thus risks amplifying the pandemic's adverse effects\\non vulnerable groups, exacerbating health inequity. In this paper, we claim\\nthat AI systems can introduce or reflect bias and discrimination in three ways:\\nin patterns of health discrimination that become entrenched in datasets, in\\ndata representativeness, and in human choices made during the design,\\ndevelopment, and deployment of these systems. We highlight how the use of AI\\ntechnologies threaten to exacerbate the disparate effect of covid-19 on\\nmarginalised, under-represented, and vulnerable groups, particularly black,\\nAsian, and other minoritised ethnic people, older populations, and those of\\nlower socioeconomic status. We conclude that, to mitigate the compounding\\neffects of AI on inequalities associated with covid-19, decision makers,\\ntechnology developers, and health officials must account for the potential\\nbiases and inequities at all stages of the AI process.\\n",
    "doi": "10.1136/bmj.n304",
    "url": "https://openalex.org/W3137761476",
    "pdf_url": "https://www.bmj.com/content/bmj/372/bmj.n304.full.pdf",
    "venue": "BMJ",
    "citation_count": 155,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:11.623106"
  },
  {
    "source": "openalex",
    "source_id": "W4385059984",
    "title": "A Review of Trustworthy and Explainable Artificial Intelligence (XAI)",
    "authors": [
      "Vinay Chamola",
      "Vikas Hassija",
      "A. Razia Sulthana",
      "Debshishu Ghosh",
      "Divyansh Dhingra",
      "Biplab Sikdar"
    ],
    "year": 2023,
    "abstract": "The advancement of Artificial Intelligence (AI) technology has accelerated the development of several systems that are elicited from it. This boom has made the systems vulnerable to security attacks and allows considerable bias in order to handle errors in the system. This puts humans at risk and leaves machines, robots, and data defenseless. Trustworthy AI (TAI) guarantees human value and the environment. In this paper, we present a comprehensive review of the state-of-the-art on how to build a Trustworthy and eXplainable AI, taking into account that AI is a black box with little insight into its underlying structure. The paper also discusses various TAI components, their corresponding bias, and inclinations that make the system unreliable. The study also discusses the necessity for TAI in many verticals, including banking, healthcare, autonomous system, and IoT. We unite the ways of building trust in all fragmented areas of data protection, pricing, expense, reliability, assurance, and decision-making processes utilizing TAI in several diverse industries and to differing degrees. It also emphasizes the importance of transparent and post hoc explanation models in the construction of an eXplainable AI and lists the potential drawbacks and pitfalls of building eXplainable AI. Finally, the policies for developing TAI in the autonomous vehicle construction sectors are thoroughly examined and eclectic ways of building a reliable, interpretable, eXplainable, and Trustworthy AI systems are explained to guarantee safe autonomous vehicle systems.",
    "doi": "10.1109/access.2023.3294569",
    "url": "https://openalex.org/W4385059984",
    "pdf_url": "https://ieeexplore.ieee.org/ielx7/6287639/6514899/10188681.pdf",
    "venue": "IEEE Access",
    "citation_count": 220,
    "fields_of_study": [
      "Computer science",
      "Trustworthiness",
      "Boom",
      "Order (exchange)",
      "Computer security"
    ],
    "retrieved_at": "2026-02-02T16:58:11.623125"
  },
  {
    "source": "openalex",
    "source_id": "W4394009485",
    "title": "AI-Driven Clinical Decision Support Systems: An Ongoing Pursuit of Potential",
    "authors": [
      "Malek Elhaddad",
      "Sara Hamam"
    ],
    "year": 2024,
    "abstract": "Clinical Decision Support Systems (CDSS) are essential tools in contemporary healthcare, enhancing clinicians' decisions and patient outcomes. The integration of artificial intelligence (AI) is now revolutionizing CDSS even further. This review delves into AI technologies transforming CDSS, their applications in healthcare decision-making, associated challenges, and the potential trajectory toward fully realizing AI-CDSS's potential. The review begins by laying the groundwork with a definition of CDSS and its function within the healthcare field. It then highlights the increasingly significant role that AI is playing in enhancing CDSS effectiveness and efficiency, underlining its evolving prominence in shaping healthcare practices. It examines the integration of AI technologies into CDSS, including machine learning algorithms like neural networks and decision trees, natural language processing, and deep learning. It also addresses the challenges associated with AI integration, such as interpretability and bias. We then shift to AI applications within CDSS, with real-life examples of AI-driven diagnostics, personalized treatment recommendations, risk prediction, early intervention, and AI-assisted clinical documentation. The review emphasizes user-centered design in AI-CDSS integration, addressing usability, trust, workflow, and ethical and legal considerations. It acknowledges prevailing obstacles and suggests strategies for successful AI-CDSS adoption, highlighting the need for workflow alignment and interdisciplinary collaboration. The review concludes by summarizing key findings, underscoring AI's transformative potential in CDSS, and advocating for continued research and innovation. It emphasizes the need for collaborative efforts to realize a future where AI-powered CDSS optimizes healthcare delivery and improves patient outcomes.",
    "doi": "10.7759/cureus.57728",
    "url": "https://openalex.org/W4394009485",
    "pdf_url": "https://assets.cureus.com/uploads/review_article/pdf/244463/20240406-13366-1bzxzru.pdf",
    "venue": "Cureus",
    "citation_count": 168,
    "fields_of_study": [
      "Clinical decision support system",
      "Workflow",
      "Interpretability",
      "Usability",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:11.623143"
  },
  {
    "source": "openalex",
    "source_id": "W3178786669",
    "title": "Ethics-Based Auditing of Automated Decision-Making Systems: Nature, Scope, and Limitations",
    "authors": [
      "Jakob M\u00f6kander",
      "Jessica Morley",
      "Mariarosaria Taddeo",
      "Luciano Floridi"
    ],
    "year": 2021,
    "abstract": null,
    "doi": "10.1007/s11948-021-00319-4",
    "url": "https://openalex.org/W3178786669",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s11948-021-00319-4.pdf",
    "venue": "Science and Engineering Ethics",
    "citation_count": 151,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:11.623162"
  },
  {
    "source": "openalex",
    "source_id": "W4388424540",
    "title": "Artificial intelligence in language instruction: impact on English learning achievement, L2 motivation, and self-regulated learning",
    "authors": [
      "Ling Wei"
    ],
    "year": 2023,
    "abstract": "Introduction This mixed methods study examines the effects of AI-mediated language instruction on English learning achievement, L2 motivation, and self-regulated learning among English as a Foreign Language (EFL) learners. It addresses the increasing interest in AI-driven educational technologies and their potential to revolutionize language instruction. Methods Two intact classes, consisting of a total of 60 university students, participated in this study. The experimental group received AI-mediated instruction, while the control group received traditional language instruction. Pre-tests and post-tests were administered to evaluate English learning achievement across various domains, including grammar, vocabulary, reading comprehension, and writing skills. Additionally, self-report questionnaires were employed to assess L2 motivation and self-regulated learning. Results Quantitative analysis revealed that the experimental group achieved significantly higher English learning outcomes in all assessed areas compared to the control group. Furthermore, they exhibited greater L2 motivation and more extensive utilization of self-regulated learning strategies. These results suggest that AI-mediated instruction positively impacts English learning achievement, L2 motivation, and self-regulated learning. Discussion Qualitative analysis of semi-structured interviews with 14 students from the experimental group shed light on the transformative effects of the AI platform. It was found to enhance engagement and offer personalized learning experiences, ultimately boosting motivation and fostering self-regulated learning. These findings emphasize the potential of AI-mediated language instruction to improve language learning outcomes, motivate learners, and promote autonomy. Conclusion This study contributes to evidence-based language pedagogy, offering valuable insights to educators and researchers interested in incorporating AI-powered platforms into language classrooms. The results support the notion that AI-mediated language instruction holds promise in revolutionizing language learning, and it highlights the positive impact of AI-driven educational technologies in the realm of language education.",
    "doi": "10.3389/fpsyg.2023.1261955",
    "url": "https://openalex.org/W4388424540",
    "pdf_url": "https://www.frontiersin.org/articles/10.3389/fpsyg.2023.1261955/pdf?isPublishedV2=False",
    "venue": "Frontiers in Psychology",
    "citation_count": 325,
    "fields_of_study": [
      "Psychology",
      "Mathematics education",
      "Learner autonomy",
      "Language learning strategies",
      "Language acquisition"
    ],
    "retrieved_at": "2026-02-02T16:58:11.623164"
  },
  {
    "source": "openalex",
    "source_id": "W4327952037",
    "title": "How to Bell the Cat? A Theoretical Review of Generative Artificial Intelligence towards Digital Disruption in All Walks of Life",
    "authors": [
      "Subhra R. Mondal",
      "Subhankar Das",
      "Vasiliki Vrana"
    ],
    "year": 2023,
    "abstract": "Generative Artificial Intelligence (GAI) has brought revolutionary changes to the world, enabling businesses to create new experiences by combining virtual and physical worlds. As the use of GAI grows along with the Metaverse, it is explored by academics, researchers, and industry communities for its endless possibilities. From ChatGPT by OpenAI to Bard AI by Google, GAI is a leading technology in physical and virtual business platforms. This paper focuses on GAI\u2019s economic and societal impact and the challenges it poses. Businesses must rethink their operations and strategies to create hybrid physical and virtual experiences using GAI. This study proposes a framework that can help business managers develop effective strategies to enhance their operations. It analyzes the initial applications of GAI in multiple sectors to promote the development of future customer solutions and explores how GAI can help businesses create new value propositions and experiences for their customers, and the possibilities of digital communication and information technology. A research agenda is proposed for developing GAI for business management to enhance organizational efficiency. The results highlight a healthy conversation on the potential of GAI in various business sectors to improve customer experience.",
    "doi": "10.3390/technologies11020044",
    "url": "https://openalex.org/W4327952037",
    "pdf_url": "https://www.mdpi.com/2227-7080/11/2/44/pdf?version=1679053742",
    "venue": "Technologies",
    "citation_count": 230,
    "fields_of_study": [
      "Metaverse",
      "Conversation",
      "Generative grammar",
      "Knowledge management",
      "Value (mathematics)"
    ],
    "retrieved_at": "2026-02-02T16:58:11.623186"
  },
  {
    "source": "openalex",
    "source_id": "W3213019454",
    "title": "Bosses without a heart: socio-demographic and cross-cultural determinants of attitude toward Emotional AI in the workplace",
    "authors": [
      "Peter Mantello",
      "Tung Manh Ho",
      "Minh\u2010Hoang Nguyen",
      "Quan\u2010Hoang Vuong"
    ],
    "year": 2021,
    "abstract": null,
    "doi": "10.1007/s00146-021-01290-1",
    "url": "https://openalex.org/W3213019454",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s00146-021-01290-1.pdf",
    "venue": "AI & Society",
    "citation_count": 173,
    "fields_of_study": [
      "Performing arts",
      "Psychology",
      "Social psychology",
      "Applied psychology",
      "Visual arts"
    ],
    "retrieved_at": "2026-02-02T16:58:11.623203"
  },
  {
    "source": "openalex",
    "source_id": "W4210739840",
    "title": "Embedded ethics: a proposal for integrating ethics into the development of medical AI",
    "authors": [
      "Stuart McLennan",
      "Amelia Fiske",
      "Daniel W. Tigard",
      "Ruth M\u00fcller",
      "Sami Haddadin",
      "Alena Buyx"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1186/s12910-022-00746-3",
    "url": "https://openalex.org/W4210739840",
    "pdf_url": "https://bmcmedethics.biomedcentral.com/track/pdf/10.1186/s12910-022-00746-3",
    "venue": "BMC Medical Ethics",
    "citation_count": 176,
    "fields_of_study": [
      "Philosophy of medicine",
      "Engineering ethics",
      "Medical law",
      "Information ethics",
      "Nursing ethics"
    ],
    "retrieved_at": "2026-02-02T16:58:11.623206"
  },
  {
    "source": "openalex",
    "source_id": "W3014487746",
    "title": "Directions in abusive language training data, a systematic review: Garbage in, garbage out",
    "authors": [
      "Bertie Vidgen",
      "Leon Derczynski"
    ],
    "year": 2020,
    "abstract": "Data-driven and machine learning based approaches for detecting, categorising and measuring abusive content such as hate speech and harassment have gained traction due to their scalability, robustness and increasingly high performance. Making effective detection systems for abusive content relies on having the right training datasets, reflecting a widely accepted mantra in computer science: Garbage In, Garbage Out. However, creating training datasets which are large, varied, theoretically-informed and that minimize biases is difficult, laborious and requires deep expertise. This paper systematically reviews 63 publicly available training datasets which have been created to train abusive language classifiers. It also reports on creation of a dedicated website for cataloguing abusive language data hatespeechdata.com . We discuss the challenges and opportunities of open science in this field, and argue that although more dataset sharing would bring many benefits it also poses social and ethical risks which need careful consideration. Finally, we provide evidence-based recommendations for practitioners creating new abusive content training datasets.",
    "doi": "10.1371/journal.pone.0243300",
    "url": "https://openalex.org/W3014487746",
    "pdf_url": "https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0243300&type=printable",
    "venue": "PLoS ONE",
    "citation_count": 269,
    "fields_of_study": [
      "Garbage",
      "Computer science",
      "Programming language"
    ],
    "retrieved_at": "2026-02-02T16:58:11.623208"
  },
  {
    "source": "openalex",
    "source_id": "W4383605161",
    "title": "A Survey on Evaluation of Large Language Models",
    "authors": [
      "Yupeng Chang",
      "Xu Wang",
      "Jindong Wang",
      "Yuan-Hsuan Wu",
      "Kaijie Zhu",
      "Hao Chen",
      "Linyi Yang",
      "Xiaoyuan Yi",
      "Cunxiang Wang",
      "Yidong Wang",
      "Wei Ye",
      "Yue Zhang",
      "Yi Chang",
      "Philip S. Yu",
      "Qiang Yang",
      "Xing Xie"
    ],
    "year": 2023,
    "abstract": "Large language models (LLMs) are gaining increasing popularity in both academia and industry, owing to their unprecedented performance in various applications. As LLMs continue to play a vital role in both research and daily use, their evaluation becomes increasingly critical, not only at the task level, but also at the society level for better understanding of their potential risks. Over the past years, significant efforts have been made to examine LLMs from various perspectives. This paper presents a comprehensive review of these evaluation methods for LLMs, focusing on three key dimensions: what to evaluate, where to evaluate, and how to evaluate. Firstly, we provide an overview from the perspective of evaluation tasks, encompassing general natural language processing tasks, reasoning, medical usage, ethics, educations, natural and social sciences, agent applications, and other areas. Secondly, we answer the `where' and `how' questions by diving into the evaluation methods and benchmarks, which serve as crucial components in assessing performance of LLMs. Then, we summarize the success and failure cases of LLMs in different tasks. Finally, we shed light on several future challenges that lie ahead in LLMs evaluation. Our aim is to offer invaluable insights to researchers in the realm of LLMs evaluation, thereby aiding the development of more proficient LLMs. Our key point is that evaluation should be treated as an essential discipline to better assist the development of LLMs. We consistently maintain the related open-source materials at: https://github.com/MLGroupJLU/LLM-eval-survey.",
    "doi": "10.48550/arxiv.2307.03109",
    "url": "https://openalex.org/W4383605161",
    "pdf_url": "https://arxiv.org/pdf/2307.03109",
    "venue": "arXiv (Cornell University)",
    "citation_count": 193,
    "fields_of_study": [
      "Popularity",
      "Engineering ethics",
      "Psychology",
      "Engineering",
      "Social psychology"
    ],
    "retrieved_at": "2026-02-02T16:58:11.623223"
  },
  {
    "source": "openalex",
    "source_id": "W2897037622",
    "title": "Considerations for ethics review of big data health research: A scoping review",
    "authors": [
      "Marcello Ienca",
      "Agata Ferretti",
      "Samia Hurst",
      "Milo A. Puhan",
      "Christian Lovis",
      "Effy Vayena"
    ],
    "year": 2018,
    "abstract": "Big data trends in biomedical and health research enable large-scale and multi-dimensional aggregation and analysis of heterogeneous data sources, which could ultimately result in preventive, diagnostic and therapeutic benefit. The methodological novelty and computational complexity of big data health research raises novel challenges for ethics review. In this study, we conducted a scoping review of the literature using five databases to identify and map the major challenges of health-related big data for Ethics Review Committees (ERCs) or analogous institutional review boards. A total of 1093 publications were initially identified, 263 of which were included in the final synthesis after abstract and full-text screening performed independently by two researchers. Both a descriptive numerical summary and a thematic analysis were performed on the full-texts of all articles included in the synthesis. Our findings suggest that while big data trends in biomedicine hold the potential for advancing clinical research, improving prevention and optimizing healthcare delivery, yet several epistemic, scientific and normative challenges need careful consideration. These challenges have relevance for both the composition of ERCs and the evaluation criteria that should be employed by ERC members when assessing the methodological and ethical viability of health-related big data studies. Based on this analysis, we provide some preliminary recommendations on how ERCs could adaptively respond to those challenges. This exploration is designed to synthesize useful information for researchers, ERCs and relevant institutional bodies involved in the conduction and/or assessment of health-related big data research.",
    "doi": "10.1371/journal.pone.0204937",
    "url": "https://openalex.org/W2897037622",
    "pdf_url": "https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0204937&type=printable",
    "venue": "PLoS ONE",
    "citation_count": 247,
    "fields_of_study": [
      "Big data",
      "Biomedicine",
      "Novelty",
      "Data science",
      "Thematic analysis"
    ],
    "retrieved_at": "2026-02-02T16:58:11.623242"
  },
  {
    "source": "openalex",
    "source_id": "W4377197101",
    "title": "Embracing Large Language Models for Medical Applications: Opportunities and Challenges",
    "authors": [
      "Mert Karabacak",
      "Konstantinos Margetis"
    ],
    "year": 2023,
    "abstract": "Large language models (LLMs) have the potential to revolutionize the field of medicine by, among other applications, improving diagnostic accuracy and supporting clinical decision-making. However, the successful integration of LLMs in medicine requires addressing challenges and considerations specific to the medical domain. This viewpoint article provides a comprehensive overview of key aspects for the successful implementation of LLMs in medicine, including transfer learning, domain-specific fine-tuning, domain adaptation, reinforcement learning with expert input, dynamic training, interdisciplinary collaboration, education and training, evaluation metrics, clinical validation, ethical considerations, data privacy, and regulatory frameworks. By adopting a multifaceted approach and fostering interdisciplinary collaboration, LLMs can be developed, validated, and integrated into medical practice responsibly, effectively, and ethically, addressing the needs of various medical disciplines and diverse patient populations. Ultimately, this approach will ensure that LLMs enhance patient care and improve overall health outcomes for all.",
    "doi": "10.7759/cureus.39305",
    "url": "https://openalex.org/W4377197101",
    "pdf_url": "https://assets.cureus.com/uploads/editorial/pdf/149797/20230521-25813-1nibw3l.pdf",
    "venue": "Cureus",
    "citation_count": 178,
    "fields_of_study": [
      "Adaptation (eye)",
      "Medicine",
      "Domain (mathematical analysis)",
      "Health care",
      "Engineering ethics"
    ],
    "retrieved_at": "2026-02-02T16:58:11.623261"
  },
  {
    "source": "openalex",
    "source_id": "W4223506650",
    "title": "The medical algorithmic audit",
    "authors": [
      "Xiaoxuan Liu",
      "Ben Glocker",
      "Melissa D. McCradden",
      "Marzyeh Ghassemi",
      "Alastair K. Denniston",
      "Lauren Oakden\u2010Rayner"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1016/s2589-7500(22)00003-6",
    "url": "https://openalex.org/W4223506650",
    "pdf_url": "http://www.thelancet.com/article/S2589750022000036/pdf",
    "venue": "The Lancet Digital Health",
    "citation_count": 195,
    "fields_of_study": [
      "Computer science",
      "Audit",
      "Software deployment",
      "Context (archaeology)",
      "Task (project management)"
    ],
    "retrieved_at": "2026-02-02T16:58:11.623274"
  },
  {
    "source": "openalex",
    "source_id": "W4386497355",
    "title": "Deep learning: systematic review, models, challenges, and research directions",
    "authors": [
      "Tala Talaei Khoei",
      "Hadjar Ould Slimane",
      "Naima Kaabouch"
    ],
    "year": 2023,
    "abstract": "Abstract The current development in deep learning is witnessing an exponential transition into automation applications. This automation transition can provide a promising framework for higher performance and lower complexity. This ongoing transition undergoes several rapid changes, resulting in the processing of the data by several studies, while it may lead to time-consuming and costly models. Thus, to address these challenges, several studies have been conducted to investigate deep learning techniques; however, they mostly focused on specific learning approaches, such as supervised deep learning. In addition, these studies did not comprehensively investigate other deep learning techniques, such as deep unsupervised and deep reinforcement learning techniques. Moreover, the majority of these studies neglect to discuss some main methodologies in deep learning, such as transfer learning, federated learning, and online learning. Therefore, motivated by the limitations of the existing studies, this study summarizes the deep learning techniques into supervised, unsupervised, reinforcement, and hybrid learning-based models. In addition to address each category, a brief description of these categories and their models is provided. Some of the critical topics in deep learning, namely, transfer, federated, and online learning models, are explored and discussed in detail. Finally, challenges and future directions are outlined to provide wider outlooks for future researchers.",
    "doi": "10.1007/s00521-023-08957-4",
    "url": "https://openalex.org/W4386497355",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s00521-023-08957-4.pdf",
    "venue": "Neural Computing and Applications",
    "citation_count": 301,
    "fields_of_study": [
      "Deep learning",
      "Artificial intelligence",
      "Computer science",
      "Transfer of learning",
      "Machine learning"
    ],
    "retrieved_at": "2026-02-02T16:58:11.623276"
  },
  {
    "source": "openalex",
    "source_id": "W3192526842",
    "title": "How Artificial Intelligence affords digital innovation: A cross-case analysis of Scandinavian companies",
    "authors": [
      "Cristina Trocin",
      "Ingrid V\u00e5ge Hovland",
      "Patrick Mikalef",
      "Christian Dremel"
    ],
    "year": 2021,
    "abstract": "Artificial Intelligence (AI) is fuelling a new breed of digital innovation in Human Resource Management (HRM) by creating new opportunities for complying with General Data Protection Regulation (GDPR) during data collection and analysis, decreasing biases, and offering targeted recommendations. However, AI is also posing challenges to organisations and key assumptions about digital innovation processes and outcomes, making it unclear how to combine AI affordances with actors, goals, and tasks. We conducted a qualitative multiple-case study in Scandinavian organisations offering HR services. Grounded theory guided our data collection and analysis. Input-Process-Output framework and affordance theory supported the analysis of specific information processing constraints and enablers. We developed a framework to explain how AI affordances enable digital innovation and address the calls about definitional boundaries between innovation processes and outcomes. We showed how AI affordances are actualised and how this leads to reontologising decision-making and providing data driven legitimisation. Our study contributes to digital innovation research by elucidating AI affordances and their actualisation in organisations. We conclude with the implications to theory and practice, limitations, and suggestions for future research.",
    "doi": "10.1016/j.techfore.2021.121081",
    "url": "https://openalex.org/W3192526842",
    "pdf_url": "https://linkinghub.elsevier.com/science/article/pii/S0040162521005138/pdfft?md5=f79a148995ffa4224f45831a4d28f6da&pid=1-s2.0-S0040162521005138-main.pdf",
    "venue": "Technological Forecasting and Social Change",
    "citation_count": 166,
    "fields_of_study": [
      "Affordance",
      "Knowledge management",
      "Process (computing)",
      "Computer science",
      "Data science"
    ],
    "retrieved_at": "2026-02-02T16:58:11.623293"
  },
  {
    "source": "openalex",
    "source_id": "W2999472659",
    "title": "A Survey on the Internet of Things (IoT) Forensics: Challenges, Approaches, and Open Issues",
    "authors": [
      "Maria Stoyanova",
      "Yannis Nikoloudakis",
      "Spyros Panagiotakis",
      "Evangelos Pallis",
      "Evangelos Markakis"
    ],
    "year": 2020,
    "abstract": "&lt;p&gt;Today is the era of the Internet of Things (IoT). The recent advances in hardware and information technology have accelerated the deployment of billions of interconnected, smart and adaptive devices in critical infrastructures like health, transportation, environmental control, and home automation. Transferring data over a network without requiring any kind of human-to-computer or human-to-human interaction, brings reliability and convenience to consumers, but also opens a new world of opportunity for intruders, and introduces a whole set of unique and complicated questions to the field of Digital Forensics. Although IoT data could be a rich source of evidence, forensics professionals cope with diverse problems, starting from the huge variety of IoT devices and non-standard formats, to the multi-tenant cloud infrastructure and the resulting multi-jurisdictional litigations. A further challenge is the end-to-end encryption which represents a trade-off between users&#39; right to privacy and the success of the forensics investigation. Due to its volatile nature, digital evidence has to be acquired and analyzed using validated tools and techniques that ensure the maintenance of the Chain of Custody. Therefore, the purpose of this paper is to identify and discuss the main issues involved in the complex process of IoT-based investigations, particularly all legal, privacy and cloud security challenges. Furthermore, this work provides an overview of the past and current theoretical models in the digital forensics science. Special attention is paid to frameworks that aim to extract data in a privacy-preserving manner or secure the evidence integrity using decentralized blockchain-based solutions. In addition, the present paper addresses the ongoing Forensics-as-a-Service (FaaS) paradigm, as well as some promising cross-cutting data reduction and forensics intelligence techniques. Finally, several other research trends and open issues are presented, with emphasis on the need for proactive Forensics Readiness strategies and generally agreed-upon standards.&lt;/p&gt;",
    "doi": "10.1109/comst.2019.2962586",
    "url": "https://openalex.org/W2999472659",
    "pdf_url": "https://ieeexplore.ieee.org/ielx7/9739/9102343/08950109.pdf",
    "venue": "IEEE Communications Surveys & Tutorials",
    "citation_count": 799,
    "fields_of_study": [
      "Computer science",
      "Digital forensics",
      "Computer security",
      "Digital evidence",
      "Cloud computing"
    ],
    "retrieved_at": "2026-02-02T16:58:11.623309"
  },
  {
    "source": "openalex",
    "source_id": "W3048672457",
    "title": "An Introduction to Ethics in Robotics and AI",
    "authors": [
      "Christoph Bartneck",
      "Christoph L\u00fctge",
      "Alan R. Wagner",
      "Sean Welsh"
    ],
    "year": 2020,
    "abstract": null,
    "doi": "10.1007/978-3-030-51110-4",
    "url": "https://openalex.org/W3048672457",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007%2F978-3-030-51110-4.pdf",
    "venue": "SpringerBriefs in ethics",
    "citation_count": 194,
    "fields_of_study": [
      "Artificial intelligence",
      "Robotics",
      "Engineering ethics",
      "Cognitive science",
      "Psychology"
    ],
    "retrieved_at": "2026-02-02T16:58:11.623332"
  },
  {
    "source": "openalex",
    "source_id": "W4300484403",
    "title": "Artificial Intelligence and Learning Analytics in Teacher Education: A Systematic Review",
    "authors": [
      "Sdenka Zobeida Salas\u2010Pilco",
      "Kejiang Xiao",
      "Xinyun Hu"
    ],
    "year": 2022,
    "abstract": "In recent years, artificial intelligence (AI) and learning analytics (LA) have been introduced into the field of education, where their use has great potential to enhance the teaching and learning processes. Researchers have focused on applying these technologies to teacher education, as they see the value of technology for educating. Therefore, a systematic review of the literature on AI and LA in teacher education is necessary to understand their impact in the field. Our methodology follows the PRISMA guidelines, and 30 studies related to teacher education were identified. This review analyzes and discusses the several ways in which AI and LA are being integrated in teacher education based on the studies\u2019 goals, participants, data sources, and the tools used to enhance teaching and learning activities. The findings indicate that (a) there is a focus on studying the behaviors, perceptions, and digital competence of pre- and in-service teachers regarding the use of AI and LA in their teaching practices; (b) the main data sources are behavioral data, discourse data, and statistical data; (c) machine learning algorithms are employed in most of the studies; and (d) the ethical clearance is mentioned by few studies. The implications will be valuable for teachers and educational authorities, informing their decisions regarding the effective use of AI and LA technologies to support teacher education.",
    "doi": "10.3390/educsci12080569",
    "url": "https://openalex.org/W4300484403",
    "pdf_url": "https://www.mdpi.com/2227-7102/12/8/569/pdf?version=1660996643",
    "venue": "Education Sciences",
    "citation_count": 216,
    "fields_of_study": [
      "Competence (human resources)",
      "Teacher education",
      "Computer science",
      "Learning analytics",
      "Analytics"
    ],
    "retrieved_at": "2026-02-02T16:58:11.623335"
  },
  {
    "source": "openalex",
    "source_id": "W2990170714",
    "title": "Artificial intelligence supported patient self-care in chronic heart failure: a paradigm shift from reactive to predictive, preventive and personalised care",
    "authors": [
      "Matthew Barrett",
      "Josiane Boyne",
      "Julia Brandts",
      "Hans\u2010Peter Brunner\u2010La Rocca",
      "Lieven De Maesschalck",
      "Kurt De Wit",
      "Lana Dixon",
      "Casper Eurlings",
      "Donna Fitzsimons",
      "Olga Golubnitschaja",
      "Arjan Hageman",
      "Frank Heemskerk",
      "Andr\u00e9 Hintzen",
      "Thomas M. Helms",
      "Loreena Hill",
      "Thom Hoedemakers",
      "Nikolaus Marx",
      "Kenneth McDonald",
      "Marc Mertens",
      "Dirk M\u00fcller\u2010Wieland",
      "Alexander Palant",
      "Jens Piesk",
      "Andrew Pomazanskyi",
      "Jan Ramaekers",
      "Peter Ruff",
      "Katharina Sch\u00fctt",
      "Yash Shekhawat",
      "Chantal F. Ski",
      "David R. Thompson",
      "Andrew Tsirkin",
      "Kay van der Mierden",
      "Chris Watson",
      "Bettina Zippel\u2010Schultz"
    ],
    "year": 2019,
    "abstract": "Abstract Heart failure (HF) is one of the most complex chronic disorders with high prevalence, mainly due to the ageing population and better treatment of underlying diseases. Prevalence will continue to rise and is estimated to reach 3% of the population in Western countries by 2025. It is the most important cause of hospitalisation in subjects aged 65 years or more, resulting in high costs and major social impact. The current \u201cone-size-fits-all\u201d approach in the treatment of HF does not result in best outcome for all patients. These facts are an imminent threat to good quality management of patients with HF. An unorthodox approach from a new vision on care is required. We propose a novel predictive, preventive and personalised medicine approach where patients are truly leading their management, supported by an easily accessible online application that takes advantage of artificial intelligence. This strategy paper describes the needs in HF care, the needed paradigm shift and the elements that are required to achieve this shift. Through the inspiring collaboration of clinical and high-tech partners from North-West Europe combining state of the art HF care, artificial intelligence, serious gaming and patient coaching, a virtual doctor is being created. The results are expected to advance and personalise self-care, where standard care tasks are performed by the patients themselves, in principle without involvement of healthcare professionals, the latter being able to focus on complex conditions. This new vision on care will significantly reduce costs per patient while improving outcomes to enable long-term sustainability of top-level HF care.",
    "doi": "10.1007/s13167-019-00188-9",
    "url": "https://openalex.org/W2990170714",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s13167-019-00188-9.pdf",
    "venue": "The EPMA Journal",
    "citation_count": 186,
    "fields_of_study": [
      "Paradigm shift",
      "Heart failure",
      "Medicine",
      "Intensive care medicine",
      "Internal medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:11.623357"
  },
  {
    "source": "openalex",
    "source_id": "W4285799063",
    "title": "Operationalising ethics in artificial intelligence for healthcare: a framework for AI developers",
    "authors": [
      "Pravik Solanki",
      "John Grundy",
      "Waqar Hussain"
    ],
    "year": 2022,
    "abstract": "Abstract Artificial intelligence (AI) offers much promise for improving healthcare. However, it runs the looming risk of causing individual and societal harms; for instance, exacerbating inequalities amongst minority groups, or enabling compromises in the confidentiality of patients\u2019 sensitive data. As such, there is an expanding, unmet need for ensuring AI for healthcare is developed in concordance with human values and ethics. Augmenting \u201cprinciple-based\u201d guidance that highlight adherence to ethical ideals (without necessarily offering translation into actionable practices), we offer a solution-based framework for operationalising ethics in AI for healthcare. Our framework is built from a scoping review of existing solutions of ethical AI guidelines, frameworks and technical solutions to address human values such as self-direction in healthcare. Our view spans the entire length of the AI lifecycle: data management, model development, deployment and monitoring. Our focus in this paper is to collate actionable solutions (whether technical or non-technical in nature), which can be steps that enable and empower developers in their daily practice to ensuring ethical practices in the broader picture. Our framework is intended to be adopted by AI developers, with recommendations that are accessible and driven by the existing literature. We endorse the recognised need for \u2018ethical AI checklists\u2019 co-designed with health AI practitioners, which could further operationalise the technical solutions we have collated. Since the risks to health and wellbeing are so large, we believe a proactive approach is necessary for ensuring human values and ethics are appropriately respected in AI for healthcare.",
    "doi": "10.1007/s43681-022-00195-z",
    "url": "https://openalex.org/W4285799063",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s43681-022-00195-z.pdf",
    "venue": "AI and Ethics",
    "citation_count": 134,
    "fields_of_study": [
      "Health care",
      "Confidentiality",
      "Engineering ethics",
      "Knowledge management",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:11.623377"
  },
  {
    "source": "openalex",
    "source_id": "W4387956898",
    "title": "Using artificial intelligence to improve public health: a narrative review",
    "authors": [
      "David B. Olawade",
      "Ojima J. Wada",
      "Aanuoluwapo Clement David-Olawade",
      "Edward Kunonga",
      "Olawale J. Abaire",
      "Jonathan Ling"
    ],
    "year": 2023,
    "abstract": "Artificial intelligence (AI) is a rapidly evolving tool revolutionizing many aspects of healthcare. AI has been predominantly employed in medicine and healthcare administration. However, in public health, the widespread employment of AI only began recently, with the advent of COVID-19. This review examines the advances of AI in public health and the potential challenges that lie ahead. Some of the ways AI has aided public health delivery are via spatial modeling, risk prediction, misinformation control, public health surveillance, disease forecasting, pandemic/epidemic modeling, and health diagnosis. However, the implementation of AI in public health is not universal due to factors including limited infrastructure, lack of technical understanding, data paucity, and ethical/privacy issues.",
    "doi": "10.3389/fpubh.2023.1196397",
    "url": "https://openalex.org/W4387956898",
    "pdf_url": "https://www.frontiersin.org/articles/10.3389/fpubh.2023.1196397/pdf?isPublishedV2=False",
    "venue": "Frontiers in Public Health",
    "citation_count": 194,
    "fields_of_study": [
      "Misinformation",
      "Public health",
      "Health care",
      "Pandemic",
      "Data science"
    ],
    "retrieved_at": "2026-02-02T16:58:11.623398"
  },
  {
    "source": "openalex",
    "source_id": "W4381572755",
    "title": "Auditing large language models: a three-layered approach",
    "authors": [
      "Jakob M\u00f6kander",
      "Jonas Schuett",
      "Hannah Rose Kirk",
      "Luciano Floridi"
    ],
    "year": 2023,
    "abstract": "Abstract Large language models (LLMs) represent a major advance in artificial intelligence (AI) research. However, the widespread use of LLMs is also coupled with significant ethical and social challenges. Previous research has pointed towards auditing as a promising governance mechanism to help ensure that AI systems are designed and deployed in ways that are ethical, legal, and technically robust. However, existing auditing procedures fail to address the governance challenges posed by LLMs, which display emergent capabilities and are adaptable to a wide range of downstream tasks. In this article, we address that gap by outlining a novel blueprint for how to audit LLMs. Specifically, we propose a three-layered approach, whereby governance audits (of technology providers that design and disseminate LLMs), model audits (of LLMs after pre-training but prior to their release), and application audits (of applications based on LLMs) complement and inform each other. We show how audits, when conducted in a structured and coordinated manner on all three levels, can be a feasible and effective mechanism for identifying and managing some of the ethical and social risks posed by LLMs. However, it is important to remain realistic about what auditing can reasonably be expected to achieve. Therefore, we discuss the limitations not only of our three-layered approach but also of the prospect of auditing LLMs at all. Ultimately, this article seeks to expand the methodological toolkit available to technology providers and policymakers who wish to analyse and evaluate LLMs from technical, ethical, and legal perspectives.",
    "doi": "10.1007/s43681-023-00289-2",
    "url": "https://openalex.org/W4381572755",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s43681-023-00289-2.pdf",
    "venue": "AI and Ethics",
    "citation_count": 155,
    "fields_of_study": [
      "Audit",
      "Corporate governance",
      "Blueprint",
      "Public relations",
      "Business"
    ],
    "retrieved_at": "2026-02-02T16:58:11.623408"
  },
  {
    "source": "openalex",
    "source_id": "W3112134271",
    "title": "The Future of Sensitivity Analysis: An essential discipline for systems modeling and policy support",
    "authors": [
      "Saman Razavi",
      "Anthony J. Jakeman",
      "Andrea Saltelli",
      "Cl\u00e9mentine Prieur",
      "Bertrand Iooss",
      "Emanuele Borgonovo",
      "Elmar Plischke",
      "Samuele Lo Piano",
      "Takuya Iwanaga",
      "William E. Becker",
      "Stefano Tarantola",
      "Joseph H. A. Guillaume",
      "John Jakeman",
      "Hoshin V. Gupta",
      "Nicola Melillo",
      "Giovanni Rabitti",
      "Vincent Chabridon",
      "Qingyun Duan",
      "Xifu Sun",
      "Stef\u00e1n Thor Smith",
      "Razi Sheikholeslami",
      "Nasim Hosseini",
      "Masoud Asadzadeh",
      "Arnald Puy",
      "Sergei Kucherenko",
      "Holger R. Maier"
    ],
    "year": 2020,
    "abstract": null,
    "doi": "10.1016/j.envsoft.2020.104954",
    "url": "https://openalex.org/W3112134271",
    "pdf_url": "https://www.sciencedirect.com/science/article/pii/S1364815220310112?via%3Dihub",
    "venue": "Environmental Modelling & Software",
    "citation_count": 543,
    "fields_of_study": [
      "Warrant",
      "Multidisciplinary approach",
      "Variety (cybernetics)",
      "Structuring",
      "Management science"
    ],
    "retrieved_at": "2026-02-02T16:58:12.547494"
  },
  {
    "source": "openalex",
    "source_id": "W3137784937",
    "title": "The ethics of people analytics: risks, opportunities and recommendations",
    "authors": [
      "Aizhan Tursunbayeva",
      "Claudia Pagliari",
      "Stefano Di Lauro",
      "Gilda Antonelli"
    ],
    "year": 2021,
    "abstract": "Purpose This research analyzed the existing academic and grey literature concerning the technologies and practices of people analytics (PA), to understand how ethical considerations are being discussed by researchers, industry experts and practitioners, and to identify gaps, priorities and recommendations for ethical practice. Design/methodology/approach An iterative \u201cscoping review\u201d method was used to capture and synthesize relevant academic and grey literature. This is suited to emerging areas of innovation where formal research lags behind evidence from professional or technical sources. Findings Although the grey literature contains a growing stream of publications aimed at helping PA practitioners to \u201cbe ethical,\u201d overall, research on ethical issues in PA is still at an early stage. Optimistic and technocentric perspectives dominate the PA discourse, although key themes seen in the wider literature on digital/data ethics are also evident. Risks and recommendations for PA projects concerned transparency and diverse stakeholder inclusion, respecting privacy rights, fair and proportionate use of data, fostering a systemic culture of ethical practice, delivering benefits for employees, including ethical outcomes in business models, ensuring legal compliance and using ethical charters. Research limitations/implications This research adds to current debates over the future of work and employment in a digitized, algorithm-driven society. Practical implications The research provides an accessible summary of the risks, opportunities, trade-offs and regulatory issues for PA, as well as a framework for integrating ethical strategies and practices. Originality/value By using a scoping methodology to surface and analyze diverse literatures, this study fills a gap in existing knowledge on ethical aspects of PA. The findings can inform future academic research, organizations using or considering PA products, professional associations developing relevant guidelines and policymakers adapting regulations. It is also timely, given the increase in digital monitoring of employees working from home during the Covid-19 pandemic.",
    "doi": "10.1108/pr-12-2019-0680",
    "url": "https://openalex.org/W3137784937",
    "pdf_url": "https://www.emerald.com/insight/content/doi/10.1108/PR-12-2019-0680/full/pdf?title=the-ethics-of-people-analytics-risks-opportunities-and-recommendations",
    "venue": "Personnel Review",
    "citation_count": 139,
    "fields_of_study": [
      "Originality",
      "Transparency (behavior)",
      "Grey literature",
      "Stakeholder",
      "Responsible Research and Innovation"
    ],
    "retrieved_at": "2026-02-02T16:58:12.547513"
  },
  {
    "source": "openalex",
    "source_id": "W2959327140",
    "title": "The Ethics of Digital Well-Being: A Thematic Review",
    "authors": [
      "Christopher Burr",
      "Mariarosaria Taddeo",
      "Luciano Floridi"
    ],
    "year": 2020,
    "abstract": "Abstract This article presents the first thematic review of the literature on the ethical issues concerning digital well-being. The term \u2018digital well-being\u2019 is used to refer to the impact of digital technologies on what it means to live a life that is good for a human being. The review explores the existing literature on the ethics of digital well-being, with the goal of mapping the current debate and identifying open questions for future research. The review identifies major issues related to several key social domains: healthcare, education, governance and social development, and media and entertainment. It also highlights three broader themes: positive computing, personalised human\u2013computer interaction, and autonomy and self-determination. The review argues that three themes will be central to ongoing discussions and research by showing how they can be used to identify open questions related to the ethics of digital well-being.",
    "doi": "10.1007/s11948-020-00175-8",
    "url": "https://openalex.org/W2959327140",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s11948-020-00175-8.pdf",
    "venue": "Science and Engineering Ethics",
    "citation_count": 277,
    "fields_of_study": [
      "Philosophy of science",
      "Engineering ethics",
      "Thematic map",
      "Thematic analysis",
      "Epistemology"
    ],
    "retrieved_at": "2026-02-02T16:58:12.547559"
  },
  {
    "source": "openalex",
    "source_id": "W3088155791",
    "title": "Human-centered AI: The role of Human-centered Design Research in the development of AI",
    "authors": [
      "Jan Auernhammer"
    ],
    "year": 2020,
    "abstract": "Artificial Intelligence has the tremendous potential to produce progress and innovation in society. Designing AI for people has been expressed as essential for societal well-being and the common good. However, human-centered is often used generically without any commitment to a philosophy or overarching approach. This paper outlines different philosophical perspectives and several Human-centered Design approaches and discusses their contribution to the development of Artificial Intelligence. The paper argues that humanistic design research should play a vital role in the pan-disciplinary collaboration with technologists and policymakers to mitigate the impact of AI. Ultimately, Human-centered Artificial Intelligence incorporates involving people and designing Artificial Intelligence systems for people through a genuine human-centered philosophy and approach.",
    "doi": "10.21606/drs.2020.282",
    "url": "https://openalex.org/W3088155791",
    "pdf_url": "https://dl.designresearchsociety.org/cgi/viewcontent.cgi?article=1178&context=drs-conference-papers",
    "venue": "Proceedings of DRS",
    "citation_count": 170,
    "fields_of_study": [
      "Humanism",
      "Engineering ethics",
      "Artificial intelligence",
      "Discipline",
      "Human development (humanity)"
    ],
    "retrieved_at": "2026-02-02T16:58:12.547575"
  },
  {
    "source": "openalex",
    "source_id": "W3208914105",
    "title": "Discriminating Data",
    "authors": [
      "Wendy Hui Kyong Chun",
      "Alex Barnett"
    ],
    "year": 2021,
    "abstract": "How big data and machine learning encode discrimination and create agitated clusters of comforting rage. In Discriminating Data, Wendy Hui Kyong Chun reveals how polarization is a goal\u2014not an error\u2014within big data and machine learning. These methods, she argues, encode segregation, eugenics, and identity politics through their default assumptions and conditions. Correlation, which grounds big data's predictive potential, stems from twentieth-century eugenic attempts to \u201cbreed\u201d a better future. Recommender systems foster angry clusters of sameness through homophily. Users are \u201ctrained\u201d to become authentically predictable via a politics and technology of recognition. Machine learning and data analytics thus seek to disrupt the future by making disruption impossible. Chun, who has a background in systems design engineering as well as media studies and cultural theory, explains that although machine learning algorithms may not officially include race as a category, they embed whiteness as a default. Facial recognition technology, for example, relies on the faces of Hollywood celebrities and university undergraduates\u2014groups not famous for their diversity. Homophily emerged as a concept to describe white U.S. resident attitudes to living in biracial yet segregated public housing. Predictive policing technology deploys models trained on studies of predominantly underserved neighborhoods. Trained on selected and often discriminatory or dirty data, these algorithms are only validated if they mirror this data. How can we release ourselves from the vice-like grip of discriminatory data? Chun calls for alternative algorithms, defaults, and interdisciplinary coalitions in order to desegregate networks and foster a more democratic big data.",
    "doi": "10.7551/mitpress/14050.001.0001",
    "url": "https://openalex.org/W3208914105",
    "pdf_url": "https://direct.mit.edu/books/monograph/5237/bookpreview-pdf/2236528",
    "venue": "The MIT Press eBooks",
    "citation_count": 341,
    "fields_of_study": [
      "Big data",
      "Homophily",
      "Artificial intelligence",
      "Computer science",
      "Politics"
    ],
    "retrieved_at": "2026-02-02T16:58:12.547588"
  },
  {
    "source": "openalex",
    "source_id": "W4281254423",
    "title": "Beyond bias and discrimination: redefining the AI ethics principle of fairness in healthcare machine-learning algorithms",
    "authors": [
      "Benedetta Giovanola",
      "Simona Tiribelli"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1007/s00146-022-01455-6",
    "url": "https://openalex.org/W4281254423",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s00146-022-01455-6.pdf",
    "venue": "AI & Society",
    "citation_count": 143,
    "fields_of_study": [
      "Framing (construction)",
      "Value (mathematics)",
      "Computer science",
      "Health care",
      "Distributive property"
    ],
    "retrieved_at": "2026-02-02T16:58:12.547611"
  },
  {
    "source": "openalex",
    "source_id": "W4205154488",
    "title": "A review of Earth Artificial Intelligence",
    "authors": [
      "Ziheng Sun",
      "L. Sandoval",
      "Robert Crystal\u2010Ornelas",
      "S. Mostafa Mousavi",
      "Jinbo Wang",
      "Cindy Lin",
      "Nicoleta Cristea",
      "Daniel Tong",
      "Wendy Hawley Carande",
      "Xiaogang Ma",
      "Yuhan Rao",
      "James A. Bednar",
      "Amanda Tan",
      "Jianwu Wang",
      "Sanjay Purushotham",
      "Thomas E. Gill",
      "Julien Chastang",
      "Daniel L. Howard",
      "Benjamin Holt",
      "Chandana Gangodagamage",
      "Peisheng Zhao",
      "Pablo Rivas",
      "Zachary Chester",
      "Javier Orduz",
      "Aji John"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1016/j.cageo.2022.105034",
    "url": "https://openalex.org/W4205154488",
    "pdf_url": "https://www.sciencedirect.com/science/article/am/pii/S0098300422000036?via%3Dihub",
    "venue": "Computers & Geosciences",
    "citation_count": 245,
    "fields_of_study": [
      "Earth (classical element)",
      "Geology",
      "Computer science",
      "Artificial intelligence",
      "Mathematics"
    ],
    "retrieved_at": "2026-02-02T16:58:12.547617"
  },
  {
    "source": "openalex",
    "source_id": "W4386390931",
    "title": "Future of education in the era of generative artificial intelligence: Consensus among Chinese scholars on applications of ChatGPT in schools",
    "authors": [
      "Ming Liu",
      "Yiling Ren",
      "Lucy Michael Nyagoga",
      "Francis Stonier",
      "Zhongming Wu",
      "Liang Yu"
    ],
    "year": 2023,
    "abstract": "Abstract ChatGPT is an artificial intelligence chatbot that utilizes advanced natural language processing technologies, including large language models, to produce human\u2010like responses to user queries spanning a wide range of topics from programming to mathematics. As an emerging generative artificial intelligence (GAI) tool, it presents novel opportunities and challenges to the ongoing digital transformation of education. This article employs a systematic review approach to summarize the viewpoints of Chinese scholars and experts regarding the implementation of GAI in education. The research findings indicate that a majority of Chinese scholars support the cautious integration of GAI into education as it serves as a learning tool that offers personalized educational experiences for students. However, it also raises concerns related to academic integrity and the potential hindrance to students' critical thinking skills. Consequently, a framework called DATS, which outlines an optimization path for future GAI applications in schools, is proposed. The framework takes into account the perspectives of four key stakeholders: developers, administrators, teachers, and students.",
    "doi": "10.1002/fer3.10",
    "url": "https://openalex.org/W4386390931",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/fer3.10",
    "venue": "Future in Educational Research",
    "citation_count": 197,
    "fields_of_study": [
      "Viewpoints",
      "Chatbot",
      "Generative grammar",
      "Computer science",
      "Knowledge management"
    ],
    "retrieved_at": "2026-02-02T16:58:12.547621"
  },
  {
    "source": "openalex",
    "source_id": "W3110910775",
    "title": "Artificial intelligence for human flourishing \u2013 Beyond principles for machine learning",
    "authors": [
      "Bernd Carsten Stahl",
      "Andreas G. Andreou",
      "Philip Brey",
      "Tally Hatzakis",
      "A. S. Kirichenko",
      "Kevin Macnish",
      "St\u00e9phanie Laulh\u00e9 Shaelou",
      "Alpesh Patel",
      "Mark Ryan",
      "David Wright"
    ],
    "year": 2020,
    "abstract": "The technical and economic benefits of artificial intelligence (AI) are counterbalanced by legal, social and ethical issues. It is challenging to conceptually capture and empirically measure both benefits and downsides. We therefore provide an account of the findings and implications of a multi-dimensional study of AI, comprising 10 case studies, five scenarios, an ethical impact analysis of AI, a human rights analysis of AI and a technical analysis of known and potential threats and vulnerabilities. Based on our findings, we separate AI ethics discourse into three streams: (1) specific issues related to the application of machine learning, (2) social and political questions arising in a digitally enabled society and (3) metaphysical questions about the nature of reality and humanity. Human rights principles and legislation have a key role to play in addressing the ethics of AI. This work helps to steer AI to contribute to human flourishing.",
    "doi": "10.1016/j.jbusres.2020.11.030",
    "url": "https://openalex.org/W3110910775",
    "pdf_url": "https://www.sciencedirect.com/science/article/pii/S0148296320307839?via%3Dihub",
    "venue": "Journal of Business Research",
    "citation_count": 161,
    "fields_of_study": [
      "Flourishing",
      "Humanity",
      "Legislation",
      "Politics",
      "Metaphysics"
    ],
    "retrieved_at": "2026-02-02T16:58:12.547638"
  },
  {
    "source": "openalex",
    "source_id": "W3207360334",
    "title": "Application Scenarios for Artificial Intelligence in Nursing Care: Rapid Review",
    "authors": [
      "Kathrin Seibert",
      "Dominik Domhoff",
      "Dominik Bruch",
      "Matthias Schulte\u2010Althoff",
      "Daniel F\u00fcrstenau",
      "Felix Bie\u00dfmann",
      "Karin Wolf\u2010Ostermann"
    ],
    "year": 2021,
    "abstract": "Background Artificial intelligence (AI) holds the promise of supporting nurses\u2019 clinical decision-making in complex care situations or conducting tasks that are remote from direct patient interaction, such as documentation processes. There has been an increase in the research and development of AI applications for nursing care, but there is a persistent lack of an extensive overview covering the evidence base for promising application scenarios. Objective This study synthesizes literature on application scenarios for AI in nursing care settings as well as highlights adjacent aspects in the ethical, legal, and social discourse surrounding the application of AI in nursing care. Methods Following a rapid review design, PubMed, CINAHL, Association for Computing Machinery Digital Library, Institute of Electrical and Electronics Engineers Xplore, Digital Bibliography &amp; Library Project, and Association for Information Systems Library, as well as the libraries of leading AI conferences, were searched in June 2020. Publications of original quantitative and qualitative research, systematic reviews, discussion papers, and essays on the ethical, legal, and social implications published in English were included. Eligible studies were analyzed on the basis of predetermined selection criteria. Results The titles and abstracts of 7016 publications and 704 full texts were screened, and 292 publications were included. Hospitals were the most prominent study setting, followed by independent living at home; fewer application scenarios were identified for nursing homes or home care. Most studies used machine learning algorithms, whereas expert or hybrid systems were entailed in less than every 10th publication. The application context of focusing on image and signal processing with tracking, monitoring, or the classification of activity and health followed by care coordination and communication, as well as fall detection, was the main purpose of AI applications. Few studies have reported the effects of AI applications on clinical or organizational outcomes, lacking particularly in data gathered outside laboratory conditions. In addition to technological requirements, the reporting and inclusion of certain requirements capture more overarching topics, such as data privacy, safety, and technology acceptance. Ethical, legal, and social implications reflect the discourse on technology use in health care but have mostly not been discussed in meaningful and potentially encompassing detail. Conclusions The results highlight the potential for the application of AI systems in different nursing care settings. Considering the lack of findings on the effectiveness and application of AI systems in real-world scenarios, future research should reflect on a more nursing care\u2013specific perspective toward objectives, outcomes, and benefits. We identify that, crucially, an advancement in technological-societal discourse that surrounds the ethical and legal implications of AI applications in nursing care is a necessary next step. Further, we outline the need for greater participation among all of the stakeholders involved.",
    "doi": "10.2196/26522",
    "url": "https://openalex.org/W3207360334",
    "pdf_url": "https://www.jmir.org/2021/11/e26522/PDF",
    "venue": "Journal of Medical Internet Research",
    "citation_count": 250,
    "fields_of_study": [
      "Nursing",
      "Nursing care",
      "Psychology",
      "Computer science",
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:12.547653"
  },
  {
    "source": "openalex",
    "source_id": "W3138924974",
    "title": "Enabling Technologies for Urban Smart Mobility: Recent Trends, Opportunities and Challenges",
    "authors": [
      "Sara Paiva",
      "Mohd Abdul Ahad",
      "Gautami Tripathi",
      "Noushaba Feroz",
      "Gabriella Casalino"
    ],
    "year": 2021,
    "abstract": "The increasing population across the globe makes it essential to link smart and sustainable city planning with the logistics of transporting people and goods, which will significantly contribute to how societies will face mobility in the coming years. The concept of smart mobility emerged with the popularity of smart cities and is aligned with the sustainable development goals defined by the United Nations. A reduction in traffic congestion and new route optimizations with reduced ecological footprint are some of the essential factors of smart mobility; however, other aspects must also be taken into account, such as the promotion of active mobility and inclusive mobility, encouraging the use of other types of environmentally friendly fuels and engagement with citizens. The Internet of Things (IoT), Artificial Intelligence (AI), Blockchain and Big Data technology will serve as the main entry points and fundamental pillars to promote the rise of new innovative solutions that will change the current paradigm for cities and their citizens. Mobility-as-a-service, traffic flow optimization, the optimization of logistics and autonomous vehicles are some of the services and applications that will encompass several changes in the coming years with the transition of existing cities into smart cities. This paper provides an extensive review of the current trends and solutions presented in the scope of smart mobility and enabling technologies that support it. An overview of how smart mobility fits into smart cities is provided by characterizing its main attributes and the key benefits of using smart mobility in a smart city ecosystem. Further, this paper highlights other various opportunities and challenges related to smart mobility. Lastly, the major services and applications that are expected to arise in the coming years within smart mobility are explored with the prospective future trends and scope.",
    "doi": "10.3390/s21062143",
    "url": "https://openalex.org/W3138924974",
    "pdf_url": "https://www.mdpi.com/1424-8220/21/6/2143/pdf?version=1620823207",
    "venue": "Sensors",
    "citation_count": 337,
    "fields_of_study": [
      "Smart city",
      "Population",
      "Popularity",
      "Scope (computer science)",
      "Sustainable transport"
    ],
    "retrieved_at": "2026-02-02T16:58:12.547693"
  },
  {
    "source": "openalex",
    "source_id": "W4287266177",
    "title": "A practical guide to multi-objective reinforcement learning and planning",
    "authors": [
      "Conor F. Hayes",
      "Roxana R\u0103dulescu",
      "Eugenio Bargiacchi",
      "Johan K\u00e4llstr\u00f6m",
      "Matthew D Macfarlane",
      "Mathieu Reymond",
      "Timothy Verstraeten",
      "Luisa Zintgraf",
      "Richard Dazeley",
      "Fredrik Heintz",
      "Enda Howley",
      "Athirai A. Irissappane",
      "Patrick Mannion",
      "Ann Now\u00e9",
      "Gabriel de Oliveira Ramos",
      "Marcello Restelli",
      "Peter Vamplew",
      "Diederik M. Roijers"
    ],
    "year": 2022,
    "abstract": "Real-world sequential decision-making tasks are generally complex, requiring trade-offs between multiple, often conflicting, objectives. Despite this, the majority of research in reinforcement learning and decision-theoretic planning either assumes only a single objective, or that multiple objectives can be adequately handled via a simple linear combination. Such approaches may oversimplify the underlying problem and hence produce suboptimal results. This paper serves as a guide to the application of multi-objective methods to difficult problems, and is aimed at researchers who are already familiar with single-objective reinforcement learning and planning methods who wish to adopt a multi-objective perspective on their research, as well as practitioners who encounter multi-objective decision problems in practice. It identifies the factors that may influence the nature of the desired solution, and illustrates by example how these influence the design of multi-objective decision-making systems for complex problems.",
    "doi": "10.1007/s10458-022-09552-y",
    "url": "https://openalex.org/W4287266177",
    "pdf_url": "https://hdl.handle.net/11311/1231792",
    "venue": "Virtual Community of Pathological Anatomy (University of Castilla La Mancha)",
    "citation_count": 277,
    "fields_of_study": [
      "Reinforcement learning",
      "Computer science",
      "Perspective (graphical)",
      "Management science",
      "Simple (philosophy)"
    ],
    "retrieved_at": "2026-02-02T16:58:12.547718"
  },
  {
    "source": "openalex",
    "source_id": "W4392922283",
    "title": "Artificial intelligence in positive mental health: a narrative review",
    "authors": [
      "Anoushka Thakkar",
      "Ankita Gupta",
      "Avinash De Sousa"
    ],
    "year": 2024,
    "abstract": "The paper reviews the entire spectrum of Artificial Intelligence (AI) in mental health and its positive role in mental health. AI has a huge number of promises to offer mental health care and this paper looks at multiple facets of the same. The paper first defines AI and its scope in the area of mental health. It then looks at various facets of AI like machine learning, supervised machine learning and unsupervised machine learning and other facets of AI. The role of AI in various psychiatric disorders like neurodegenerative disorders, intellectual disability and seizures are discussed along with the role of AI in awareness, diagnosis and intervention in mental health disorders. The role of AI in positive emotional regulation and its impact in schizophrenia, autism spectrum disorders and mood disorders is also highlighted. The article also discusses the limitations of AI based approaches and the need for AI based approaches in mental health to be culturally aware, with structured flexible algorithms and an awareness of biases that can arise in AI. The ethical issues that may arise with the use of AI in mental health are also visited.",
    "doi": "10.3389/fdgth.2024.1280235",
    "url": "https://openalex.org/W4392922283",
    "pdf_url": "https://www.frontiersin.org/journals/digital-health/articles/10.3389/fdgth.2024.1280235/pdf",
    "venue": "Frontiers in Digital Health",
    "citation_count": 159,
    "fields_of_study": [
      "Mental health",
      "Psychology",
      "Schizophrenia (object-oriented programming)",
      "Intervention (counseling)",
      "Autism"
    ],
    "retrieved_at": "2026-02-02T16:58:12.547732"
  },
  {
    "source": "openalex",
    "source_id": "W4294243134",
    "title": "Experimental evidence of effective human\u2013AI collaboration in medical decision-making",
    "authors": [
      "Carlo Reverberi",
      "Tommaso Rigon",
      "Aldo Solari",
      "Cesare Hassan",
      "Paolo Cherubini",
      "Giulio Antonelli",
      "Halim Awadie",
      "Sebastian Bernhofer",
      "Sabela Carballal",
      "M\u00e1rio Dinis\u2010Ribeiro",
      "A Fern\u00e1ndez-Clotet",
      "Gl\u00f2ria Fern\u00e1ndez\u2010Esparrach",
      "Ian M. Gralnek",
      "Yuta Higasa",
      "Taku Hirabayashi",
      "Tatsuki Hirai",
      "Mineo Iwatate",
      "Miki Kawano",
      "Markus Mader",
      "A Maieron",
      "Sebastian Mattes",
      "Tastuya Nakai",
      "\u00cdngrid Ord\u00e1s",
      "Raquel Ortig\u00e3o",
      "Oswaldo Ort\u00edz",
      "Mar\u00eda Pellis\u00e9",
      "Cl\u00e1udia L\u00facia de Oliveira Pinto",
      "Florian Riedl",
      "Ariadna S\u00e1nchez",
      "Emanuel Steiner",
      "Yukari Tanaka",
      "Andrea Cherubini",
      "Andrea Cherubini"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1038/s41598-022-18751-2",
    "url": "https://openalex.org/W4294243134",
    "pdf_url": "https://www.nature.com/articles/s41598-022-18751-2.pdf",
    "venue": "Scientific Reports",
    "citation_count": 172,
    "fields_of_study": [
      "Medical decision making",
      "Clinical decision making",
      "Data science",
      "Computer science",
      "MEDLINE"
    ],
    "retrieved_at": "2026-02-02T16:58:12.547753"
  },
  {
    "source": "openalex",
    "source_id": "W4385156372",
    "title": "AI governance: themes, knowledge gaps and future agendas",
    "authors": [
      "Teemu Birkstedt",
      "Matti Minkkinen",
      "Anushree Tandon",
      "Matti M\u00e4ntym\u00e4ki"
    ],
    "year": 2023,
    "abstract": "Purpose Following the surge of documents laying out organizations' ethical principles for their use of artificial intelligence (AI), there is a growing demand for translating ethical principles to practice through AI governance (AIG). AIG has emerged as a rapidly growing, yet fragmented, research area. This paper synthesizes the organizational AIG literature by outlining research themes and knowledge gaps as well as putting forward future agendas. Design/methodology/approach The authors undertake a systematic literature review on AIG, addressing the current state of its conceptualization and suggesting future directions for AIG scholarship and practice. The review protocol was developed following recommended guidelines for systematic reviews and the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA). Findings The results of the authors\u2019 review confirmed the assumption that AIG is an emerging research topic with few explicit definitions. Moreover, the authors\u2019 review identified four themes in the AIG literature: technology, stakeholders and context, regulation and processes. The central knowledge gaps revealed were the limited understanding of AIG implementation, lack of attention to the AIG context, uncertain effectiveness of ethical principles and regulation, and insufficient operationalization of AIG processes. To address these gaps, the authors present four future AIG agendas: technical, stakeholder and contextual, regulatory, and process. Going forward, the authors propose focused empirical research on organizational AIG processes, the establishment of an AI oversight unit and collaborative governance as a research approach. Research limitations/implications To address the identified knowledge gaps, the authors present the following working definition of AIG: AI governance is a system of rules, practices and processes employed to ensure an organization's use of AI technologies aligns with its strategies, objectives, and values, complete with legal requirements, ethical principles and the requirements set by stakeholders. Going forward, the authors propose focused empirical research on organizational AIG processes, the establishment of an AI oversight unit and collaborative governance as a research approach. Practical implications For practitioners, the authors highlight training and awareness, stakeholder management and the crucial role of organizational culture, including senior management commitment. Social implications For society, the authors review elucidates the multitude of stakeholders involved in AI governance activities and complexities related to balancing the needs of different stakeholders. Originality/value By delineating the AIG concept and the associated research themes, knowledge gaps and future agendas, the authors review builds a foundation for organizational AIG research, calling for broad contextual investigations and a deep understanding of AIG mechanisms. For practitioners, the authors highlight training and awareness, stakeholder management and the crucial role of organizational culture, including senior management commitment.",
    "doi": "10.1108/intr-01-2022-0042",
    "url": "https://openalex.org/W4385156372",
    "pdf_url": "https://www.emerald.com/insight/content/doi/10.1108/INTR-01-2022-0042/full/pdf?title=ai-governance-themes-knowledge-gaps-and-future-agendas",
    "venue": "Internet Research",
    "citation_count": 152,
    "fields_of_study": [
      "Conceptualization",
      "Operationalization",
      "Corporate governance",
      "Systematic review",
      "Scholarship"
    ],
    "retrieved_at": "2026-02-02T16:58:12.547757"
  },
  {
    "source": "openalex",
    "source_id": "W3156728378",
    "title": "Conversational commerce: entering the next stage of AI-powered digital assistants",
    "authors": [
      "Janarthanan Balakrishnan",
      "Yogesh K. Dwivedi"
    ],
    "year": 2021,
    "abstract": "Abstract Digital assistant is a recent advancement benefited through data-driven innovation. Though digital assistants have become an integral member of user conversations, but there is no theory that relates user perception towards this AI powered technology. The purpose of the research is to investigate the role of technology attitude and AI attributes in enhancing purchase intention through digital assistants. A conceptual model is proposed after identifying three major AI factors namely, perceived anthropomorphism, perceived intelligence, and perceived animacy. To test the model, the study employed structural equation modeling using 440 sample. The results indicated that perceived anthropomorphism plays the most significant role in building a positive attitude and purchase intention through digital assistants. Though the study is built using technology-related variables, the hypotheses are proposed based on various psychology-related theories such as uncanny valley theory, the theory of mind, developmental psychology, and cognitive psychology theory. The study\u2019s theoretical contributions are discussed within the scope of these theories. Besides the theoretical contribution, the study also offers illuminating practical implications for developers and marketers\u2019 benefit.",
    "doi": "10.1007/s10479-021-04049-5",
    "url": "https://openalex.org/W3156728378",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10479-021-04049-5.pdf",
    "venue": "Annals of Operations Research",
    "citation_count": 230,
    "fields_of_study": [
      "Uncanny valley",
      "Perception",
      "Scope (computer science)",
      "Structural equation modeling",
      "Theory of planned behavior"
    ],
    "retrieved_at": "2026-02-02T16:58:12.547800"
  },
  {
    "source": "openalex",
    "source_id": "W4384827671",
    "title": "Artificial intelligence governance: Ethical considerations and implications for social responsibility",
    "authors": [
      "Mark Anthony Camilleri"
    ],
    "year": 2023,
    "abstract": "Abstract A number of articles are increasingly raising awareness on the different uses of artificial intelligence (AI) technologies for customers and businesses. Many authors discuss about their benefits and possible challenges. However, for the time being, there is still limited research focused on AI principles and regulatory guidelines for the developers of expert systems like machine learning (ML) and/or deep learning (DL) technologies. This research addresses this knowledge gap in the academic literature. The objectives of this contribution are threefold: (i) It describes AI governance frameworks that were put forward by technology conglomerates, policy makers and by intergovernmental organizations, (ii) It sheds light on the extant literature on \u2018AI governance\u2019 as well as on the intersection of \u2018AI\u2019 and \u2018corporate social responsibility\u2019 (CSR), (iii) It identifies key dimensions of AI governance, and elaborates about the promotion of accountability and transparency; explainability, interpretability and reproducibility; fairness and inclusiveness; privacy and safety of end users, as well as on the prevention of risks and of cyber security issues from AI systems. This research implies that all those who are involved in the research, development and maintenance of AI systems, have social and ethical responsibilities to bear toward their consumers as well as to other stakeholders in society.",
    "doi": "10.1111/exsy.13406",
    "url": "https://openalex.org/W4384827671",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/exsy.13406",
    "venue": "Expert Systems",
    "citation_count": 141,
    "fields_of_study": [
      "Accountability",
      "Transparency (behavior)",
      "Interpretability",
      "Corporate governance",
      "Extant taxon"
    ],
    "retrieved_at": "2026-02-02T16:58:12.547818"
  },
  {
    "source": "openalex",
    "source_id": "W4386712902",
    "title": "AI Fairness in Data Management and Analytics: A Review on Challenges, Methodologies and Applications",
    "authors": [
      "Pu Chen",
      "Linna Wu",
      "Lei Wang"
    ],
    "year": 2023,
    "abstract": "This article provides a comprehensive overview of the fairness issues in artificial intelligence (AI) systems, delving into its background, definition, and development process. The article explores the fairness problem in AI through practical applications and current advances and focuses on bias analysis and fairness training as key research directions. The paper explains in detail the concept, implementation, characteristics, and use cases of each method. The paper explores strategies to reduce bias and improve fairness in AI systems, reviews challenges and solutions to real-world AI fairness applications, and proposes future research directions. In addition, this study provides an in-depth comparative analysis of the various approaches, utilizing cutting-edge research information to elucidate their different characteristics, strengths, and weaknesses. The results of the comparison provide guidance for future research. The paper concludes with an overview of existing challenges in practical applications and suggests priorities and solutions for future research. The conclusions provide insights for promoting fairness in AI systems. The information reviewed in this paper is drawn from reputable sources, including leading academic journals, prominent conference proceedings, and well-established online repositories dedicated to AI fairness. However, it is important to recognize that research nuances, sample sizes, and contextual factors may create limitations that affect the generalizability of the findings.",
    "doi": "10.3390/app131810258",
    "url": "https://openalex.org/W4386712902",
    "pdf_url": "https://www.mdpi.com/2076-3417/13/18/10258/pdf?version=1694597295",
    "venue": "Applied Sciences",
    "citation_count": 123,
    "fields_of_study": [
      "Generalizability theory",
      "Computer science",
      "Strengths and weaknesses",
      "Data science",
      "Management science"
    ],
    "retrieved_at": "2026-02-02T16:58:12.547840"
  },
  {
    "source": "openalex",
    "source_id": "W4296776307",
    "title": "Integrated multimodal artificial intelligence framework for healthcare applications",
    "authors": [
      "Luis R. Soenksen",
      "Yu Ma",
      "Cynthia Zeng",
      "L\u00e9onard Boussioux",
      "Kimberly Villalobos Carballo",
      "Liangyuan Na",
      "Holly Wiberg",
      "Michael Lingzhi Li",
      "Ignacio Fuentes",
      "Dimitris Bertsimas"
    ],
    "year": 2022,
    "abstract": "Abstract Artificial intelligence (AI) systems hold great promise to improve healthcare over the next decades. Specifically, AI systems leveraging multiple data sources and input modalities are poised to become a viable method to deliver more accurate results and deployable pipelines across a wide range of applications. In this work, we propose and evaluate a unified Holistic AI in Medicine (HAIM) framework to facilitate the generation and testing of AI systems that leverage multimodal inputs. Our approach uses generalizable data pre-processing and machine learning modeling stages that can be readily adapted for research and deployment in healthcare environments. We evaluate our HAIM framework by training and characterizing 14,324 independent models based on HAIM-MIMIC-MM, a multimodal clinical database ( N = 34,537 samples) containing 7279 unique hospitalizations and 6485 patients, spanning all possible input combinations of 4 data modalities (i.e., tabular, time-series, text, and images), 11 unique data sources and 12 predictive tasks. We show that this framework can consistently and robustly produce models that outperform similar single-source approaches across various healthcare demonstrations (by 6\u201333%), including 10 distinct chest pathology diagnoses, along with length-of-stay and 48 h mortality predictions. We also quantify the contribution of each modality and data source using Shapley values, which demonstrates the heterogeneity in data modality importance and the necessity of multimodal inputs across different healthcare-relevant tasks. The generalizable properties and flexibility of our Holistic AI in Medicine (HAIM) framework could offer a promising pathway for future multimodal predictive systems in clinical and operational healthcare settings.",
    "doi": "10.1038/s41746-022-00689-4",
    "url": "https://openalex.org/W4296776307",
    "pdf_url": "https://www.nature.com/articles/s41746-022-00689-4.pdf",
    "venue": "npj Digital Medicine",
    "citation_count": 244,
    "fields_of_study": [
      "Computer science",
      "Leverage (statistics)",
      "Artificial intelligence",
      "Modalities",
      "Machine learning"
    ],
    "retrieved_at": "2026-02-02T16:58:12.547861"
  },
  {
    "source": "openalex",
    "source_id": "W4385757151",
    "title": "Using ChatGPT in academic writing is (not) a form of plagiarism: What does the literature say?",
    "authors": [
      "Adeeb M. Jarrah",
      "Yousef Wardat",
      "Patr\u00edcia Fidalgo"
    ],
    "year": 2023,
    "abstract": "This study aims to review the existing literature on using ChatGPT in academic writing and its implications regarding plagiarism. Various databases, including Scopus, Google Scholar, ScienceDirect, and ProQuest, were searched using specific keywords related to ChatGPT in academia, academic research, higher education, academic publishing, and ethical challenges. The review provides an overview of studies investigating the use of ChatGPT in academic writing and its potential association with plagiarism. The results of this study contribute to our understanding of the use and misuse of ChatGPT in academic writing, considering the growing concern regarding plagiarism in higher education. The findings suggest that ChatGPT can be a valuable writing tool; however, it is crucial to follow responsible practices to uphold academic integrity and ensure ethical use. Properly citing and attributing ChatGPT\u2019s contribution is essential in recognizing its role, preventing plagiarism, and upholding the principles of scholarly writing. By adhering to established citation guidelines, authors can maximize ChatGPT\u2019s benefits while maintaining responsible usage.",
    "doi": "10.30935/ojcmt/13572",
    "url": "https://openalex.org/W4385757151",
    "pdf_url": "https://www.ojcmt.net/download/using-chatgpt-in-academic-writing-is-not-a-form-of-plagiarism-what-does-the-literature-say-13572.pdf",
    "venue": "Online Journal of Communication and Media Technologies",
    "citation_count": 188,
    "fields_of_study": [
      "Academic writing",
      "Scopus",
      "Academic integrity",
      "Citation",
      "Publishing"
    ],
    "retrieved_at": "2026-02-02T16:58:12.547882"
  },
  {
    "source": "openalex",
    "source_id": "W3212259563",
    "title": "Operationalising AI ethics: barriers, enablers and next steps",
    "authors": [
      "Jessica Morley",
      "Libby Kinsey",
      "Anat Elhalal",
      "Francesca Garcia",
      "Marta Ziosi",
      "Luciano Floridi"
    ],
    "year": 2021,
    "abstract": "Abstract By mid-2019 there were more than 80 AI ethics guides available in the public domain. Despite this, 2020 saw numerous news stories break related to ethically questionable uses of AI. In part, this is because AI ethics theory remains highly abstract, and of limited practical applicability to those actually responsible for designing algorithms and AI systems. Our previous research sought to start closing this gap between the \u2018what\u2019 and the \u2018how\u2019 of AI ethics through the creation of a searchable typology of tools and methods designed to translate between the five most common AI ethics principles and implementable design practices. Whilst a useful starting point, that research rested on the assumption that all AI practitioners are aware of the ethical implications of AI, understand their importance, and are actively seeking to respond to them. In reality, it is unclear whether this is the case. It is this limitation that we seek to overcome here by conducting a mixed-methods qualitative analysis to answer the following four questions: what do AI practitioners understand about the need to translate ethical principles into practice? What motivates AI practitioners to embed ethical principles into design practices? What barriers do AI practitioners face when attempting to translate ethical principles into practice? And finally, what assistance do AI practitioners want and need when translating ethical principles into practice?",
    "doi": "10.1007/s00146-021-01308-8",
    "url": "https://openalex.org/W3212259563",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s00146-021-01308-8.pdf",
    "venue": "AI & Society",
    "citation_count": 173,
    "fields_of_study": [
      "Typology",
      "Engineering ethics",
      "Point (geometry)",
      "Face (sociological concept)",
      "Closing (real estate)"
    ],
    "retrieved_at": "2026-02-02T16:58:12.547898"
  },
  {
    "source": "openalex",
    "source_id": "W3209760672",
    "title": "The Lancet and Financial Times Commission on governing health futures 2030: growing up in a digital world",
    "authors": [
      "Ilona Kickbusch",
      "Dario Piselli",
      "Anurag Agrawal",
      "Ran D. Balicer",
      "Olivia Banner",
      "M Adelhardt",
      "Emanuele Capobianco",
      "Christopher Fabian",
      "Amandeep S. Gill",
      "Deborah Lupton",
      "Rohinton Medhora",
      "Njide Ndili",
      "Andrzej Ry\u015b",
      "Nanjira Sambuli",
      "Dykki Settle",
      "Soumya Swaminathan",
      "Jeanette Vega Morales",
      "Miranda Wolpert",
      "Andrew Wyckoff",
      "Lan Xue",
      "Aferdita Bytyqi",
      "Christian Franz",
      "Whitney Gray",
      "Louise Holly",
      "Micaela Neumann",
      "Lipsa Panda",
      "Robert D. Smith",
      "Enow Awah Georges Stevens",
      "Brian Li Han Wong"
    ],
    "year": 2021,
    "abstract": null,
    "doi": "10.1016/s0140-6736(21)01824-9",
    "url": "https://openalex.org/W3209760672",
    "pdf_url": "http://www.thelancet.com/article/S0140673621018249/pdf",
    "venue": "The Lancet",
    "citation_count": 356,
    "fields_of_study": [
      "Digital health",
      "Digital transformation",
      "Futures contract",
      "Health care",
      "Political science"
    ],
    "retrieved_at": "2026-02-02T16:58:12.547921"
  },
  {
    "source": "openalex",
    "source_id": "W4393993191",
    "title": "Generative AI for Customizable Learning Experiences",
    "authors": [
      "Ivica Pesovski",
      "Ricardo Santos",
      "Roberto Henriques",
      "Vladimir Trajkovik"
    ],
    "year": 2024,
    "abstract": "The introduction of accessible generative artificial intelligence opens promising opportunities for the implementation of personalized learning methods in any educational environment. Personalized learning has been conceptualized for a long time, but it has only recently become realistic and truly achievable. In this paper, we propose an affordable and sustainable approach toward personalizing learning materials as part of the complete educational process. We have created a tool within a pre-existing learning management system at a software engineering college that automatically generates learning materials based on the learning outcomes provided by the professor for a particular class. The learning materials were composed in three distinct styles, the initial one being the traditional professor style and the other two variations adopting a pop-culture influence, namely Batman and Wednesday Addams. Each lesson, besides being delivered in three different formats, contained automatically generated multiple-choice questions that students could use to check their progress. This paper contains complete instructions for developing such a tool with the help of large language models using OpenAI\u2019s API and an analysis of the preliminary experiment of its usage performed with the help of 20 college students studying software engineering at a European university. Participation in the study was optional and on voluntary basis. Each student\u2019s tool usage was quantified, and two questionnaires were conducted: one immediately after subject completion and another 6 months later to assess both immediate and long-term effects, perceptions, and preferences. The results indicate that students found the multiple variants of the learning materials really engaging. While predominantly utilizing the traditional variant of the learning materials, they found this approach inspiring, would recommend it to other students, and would like to see it more in classes. The most popular feature were the automatically generated quiz-style tests that they used to assess their understanding. Preliminary evidence suggests that the use of various versions of learning materials leads to an increase in students\u2019 study time, especially for students who have not mastered the topic otherwise. The study\u2019s small sample size of 20 students restricts its ability to generalize its findings, but its results provide useful early insights and lay the groundwork for future research on AI-supported educational strategies.",
    "doi": "10.3390/su16073034",
    "url": "https://openalex.org/W4393993191",
    "pdf_url": "https://www.mdpi.com/2071-1050/16/7/3034/pdf?version=1712310661",
    "venue": "Sustainability",
    "citation_count": 176,
    "fields_of_study": [
      "Generative grammar",
      "Generative Design",
      "Computer science",
      "Generative model",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:12.547924"
  },
  {
    "source": "openalex",
    "source_id": "W4381550225",
    "title": "ChatGPT and the Future of Digital Health: A Study on Healthcare Workers\u2019 Perceptions and Expectations",
    "authors": [
      "Mohamad\u2010Hani Temsah",
      "Fadi Aljamaan",
      "Khalid H. Malki",
      "Khalid Alhasan",
      "Ibraheem Altamimi",
      "Razan Aljarbou",
      "Faisal Bazuhair",
      "Abdulmajeed AlSubaihin",
      "Naif Abdulmajeed",
      "Fatimah Alshahrani",
      "Reem Temsah",
      "Turki Alshahrani",
      "Lama Al-Eyadhy",
      "Serin Mohammed Alkhateeb",
      "Basema Saddik",
      "Rabih Halwani",
      "Amr Jamal",
      "Jaffar A. Al\u2010Tawfiq",
      "Ayman Al\u2010Eyadhy"
    ],
    "year": 2023,
    "abstract": "This study aimed to assess the knowledge, attitudes, and intended practices of healthcare workers (HCWs) in Saudi Arabia towards ChatGPT, an artificial intelligence (AI) Chatbot, within the first three months after its launch. We also aimed to identify potential barriers to AI Chatbot adoption among healthcare professionals. A cross-sectional survey was conducted among 1057 HCWs in Saudi Arabia, distributed electronically via social media channels from 21 February to 6 March 2023. The survey evaluated HCWs\u2019 familiarity with ChatGPT-3.5, their satisfaction, intended future use, and perceived usefulness in healthcare practice. Of the respondents, 18.4% had used ChatGPT for healthcare purposes, while 84.1% of non-users expressed interest in utilizing AI Chatbots in the future. Most participants (75.1%) were comfortable with incorporating ChatGPT into their healthcare practice. HCWs perceived the Chatbot to be useful in various aspects of healthcare, such as medical decision-making (39.5%), patient and family support (44.7%), medical literature appraisal (48.5%), and medical research assistance (65.9%). A majority (76.7%) believed ChatGPT could positively impact the future of healthcare systems. Nevertheless, concerns about credibility and the source of information provided by AI Chatbots (46.9%) were identified as the main barriers. Although HCWs recognize ChatGPT as a valuable addition to digital health in the early stages of adoption, addressing concerns regarding accuracy, reliability, and medicolegal implications is crucial. Therefore, due to their unreliability, the current forms of ChatGPT and other Chatbots should not be used for diagnostic or treatment purposes without human expert oversight. Ensuring the trustworthiness and dependability of AI Chatbots is essential for successful implementation in healthcare settings. Future research should focus on evaluating the clinical outcomes of ChatGPT and benchmarking its performance against other AI Chatbots.",
    "doi": "10.3390/healthcare11131812",
    "url": "https://openalex.org/W4381550225",
    "pdf_url": "https://www.mdpi.com/2227-9032/11/13/1812/pdf?version=1687515031",
    "venue": "Healthcare",
    "citation_count": 164,
    "fields_of_study": [
      "Health care",
      "Chatbot",
      "Credibility",
      "Medicine",
      "Digital health"
    ],
    "retrieved_at": "2026-02-02T16:58:12.547958"
  },
  {
    "source": "openalex",
    "source_id": "W4309604980",
    "title": "Ethical Conundrums in the Application of Artificial Intelligence (AI) in Healthcare\u2014A Scoping Review of Reviews",
    "authors": [
      "Sreenidhi Prakash",
      "Jyotsna Needamangalam Balaji",
      "Ashish Joshi",
      "Krishna Mohan Surapaneni"
    ],
    "year": 2022,
    "abstract": "Background: With the availability of extensive health data, artificial intelligence has an inordinate capability to expedite medical explorations and revamp healthcare.Artificial intelligence is set to reform the practice of medicine soon. Despite the mammoth advantages of artificial intelligence in the medical field, there exists inconsistency in the ethical and legal framework for the application of AI in healthcare. Although research has been conducted by various medical disciplines investigating the ethical implications of artificial intelligence in the healthcare setting, the literature lacks a holistic approach. Objective: The purpose of this review is to ascertain the ethical concerns of AI applications in healthcare, to identify the knowledge gaps and provide recommendations for an ethical and legal framework. Methodology: Electronic databases Pub Med and Google Scholar were extensively searched based on the search strategy pertaining to the purpose of this review. Further screening of the included articles was done on the grounds of the inclusion and exclusion criteria. Results: The search yielded a total of 1238 articles, out of which 16 articles were identified to be eligible for this review. The selection was strictly based on the inclusion and exclusion criteria mentioned in the manuscript. Conclusion: Artificial intelligence (AI) is an exceedingly puissant technology, with the prospect of advancing medical practice in the years to come. Nevertheless, AI brings with it a colossally abundant number of ethical and legal problems associated with its application in healthcare. There are manifold stakeholders in the legal and ethical issues revolving around AI and medicine. Thus, a multifaceted approach involving policymakers, developers, healthcare providers and patients is crucial to arrive at a feasible solution for mitigating the legal and ethical problems pertaining to AI in healthcare.",
    "doi": "10.3390/jpm12111914",
    "url": "https://openalex.org/W4309604980",
    "pdf_url": "https://www.mdpi.com/2075-4426/12/11/1914/pdf?version=1668597688",
    "venue": "Journal of Personalized Medicine",
    "citation_count": 134,
    "fields_of_study": [
      "Health care",
      "Inclusion (mineral)",
      "Artificial intelligence",
      "Applications of artificial intelligence",
      "Engineering ethics"
    ],
    "retrieved_at": "2026-02-02T16:58:12.547983"
  },
  {
    "source": "openalex",
    "source_id": "W2976689229",
    "title": "Big Data and Human Resources Management: The Rise of Talent Analytics",
    "authors": [
      "Manuela Nocker",
      "Vania Sena"
    ],
    "year": 2019,
    "abstract": "The purpose of this paper is to discuss the opportunities talent analytics offers HR practitioners. As the availability of methodologies for the analysis of large volumes of data has substantially improved over the last ten years, talent analytics has started to be used by organizations to manage their workforce. This paper discusses the benefits and costs associated with the use of talent analytics within an organization as well as to highlight the differences between talent analytics and other sub-fields of business analytics. It will discuss a number of case studies on how talent analytics can improve organizational decision-making. From the case studies, we will identify key channels through which the adoption of talent analytics can improve the performance of the HR function and eventually of the whole organization. While discussing the opportunities that talent analytics offer organizations, this paper highlights the costs (in terms of data governance and ethics) that the widespread use of talent analytics can generate. Finally, it highlights the importance of trust in supporting the successful implementation of talent analytics projects.",
    "doi": "10.3390/socsci8100273",
    "url": "https://openalex.org/W2976689229",
    "pdf_url": "https://www.mdpi.com/2076-0760/8/10/273/pdf?version=1570869084",
    "venue": "Social Sciences",
    "citation_count": 173,
    "fields_of_study": [
      "Analytics",
      "Business analytics",
      "Big data",
      "Business intelligence",
      "Data science"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548011"
  },
  {
    "source": "openalex",
    "source_id": "W4390587679",
    "title": "A Systematic Review and Meta-Analysis of Artificial Intelligence Tools in Medicine and Healthcare: Applications, Considerations, Limitations, Motivation and Challenges",
    "authors": [
      "Hussain A. Younis",
      "Taiseer Abdalla Elfadil Eisa",
      "Maged Nasser",
      "Thaeer Mueen Sahib",
      "Ameen A. Noor",
      "Osamah Mohammed Alyasiri",
      "Sani Salisu",
      "Israa M. Hayder",
      "Hameed A. Younis",
      "Hameed AbdulKareem Younis",
      "Hameed AbdulKareem Younis"
    ],
    "year": 2024,
    "abstract": "Artificial intelligence (AI) has emerged as a transformative force in various sectors, including medicine and healthcare. Large language models like ChatGPT showcase AI\u2019s potential by generating human-like text through prompts. ChatGPT\u2019s adaptability holds promise for reshaping medical practices, improving patient care, and enhancing interactions among healthcare professionals, patients, and data. In pandemic management, ChatGPT rapidly disseminates vital information. It serves as a virtual assistant in surgical consultations, aids dental practices, simplifies medical education, and aids in disease diagnosis. A total of 82 papers were categorised into eight major areas, which are G1: treatment and medicine, G2: buildings and equipment, G3: parts of the human body and areas of the disease, G4: patients, G5: citizens, G6: cellular imaging, radiology, pulse and medical images, G7: doctors and nurses, and G8: tools, devices and administration. Balancing AI\u2019s role with human judgment remains a challenge. A systematic literature review using the PRISMA approach explored AI\u2019s transformative potential in healthcare, highlighting ChatGPT\u2019s versatile applications, limitations, motivation, and challenges. In conclusion, ChatGPT\u2019s diverse medical applications demonstrate its potential for innovation, serving as a valuable resource for students, academics, and researchers in healthcare. Additionally, this study serves as a guide, assisting students, academics, and researchers in the field of medicine and healthcare alike.",
    "doi": "10.3390/diagnostics14010109",
    "url": "https://openalex.org/W4390587679",
    "pdf_url": "https://www.mdpi.com/2075-4418/14/1/109/pdf?version=1704340606",
    "venue": "Diagnostics",
    "citation_count": 185,
    "fields_of_study": [
      "Transformative learning",
      "Health care",
      "Medical education",
      "Applications of artificial intelligence",
      "Knowledge management"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548032"
  },
  {
    "source": "openalex",
    "source_id": "W3212538456",
    "title": "Characteristics of publicly available skin cancer image datasets: a systematic review",
    "authors": [
      "David Wen",
      "Saad M Khan",
      "Antonio Ji Xu",
      "Hussein Ibrahim",
      "Luke Smith",
      "Jose Caballero",
      "Luis Zepeda",
      "Carlos de Blas Perez",
      "Alastair K Denniston",
      "Xiaoxuan Liu",
      "Rubeta N Matin"
    ],
    "year": 2021,
    "abstract": "Publicly available skin image datasets are increasingly used to develop machine learning algorithms for skin cancer diagnosis. However, the total number of datasets and their respective content is currently unclear. This systematic review aimed to identify and evaluate all publicly available skin image datasets used for skin cancer diagnosis by exploring their characteristics, data access requirements, and associated image metadata. A combined MEDLINE, Google, and Google Dataset search identified 21 open access datasets containing 106 950 skin lesion images, 17 open access atlases, eight regulated access datasets, and three regulated access atlases. Images and accompanying data from open access datasets were evaluated by two independent reviewers. Among the 14 datasets that reported country of origin, most (11 [79%]) originated from Europe, North America, and Oceania exclusively. Most datasets (19 [91%]) contained dermoscopic images or macroscopic photographs only. Clinical information was available regarding age for 81 662 images (76\u00b74%), sex for 82 848 (77\u00b75%), and body site for 79 561 (74\u00b74%). Subject ethnicity data were available for 1415 images (1\u00b73%), and Fitzpatrick skin type data for 2236 (2\u00b71%). There was limited and variable reporting of characteristics and metadata among datasets, with substantial under-representation of darker skin types. This is the first systematic review to characterise publicly available skin image datasets, highlighting limited applicability to real-life clinical settings and restricted population representation, precluding generalisability. Quality standards for characteristics and metadata reporting for skin image datasets are needed.",
    "doi": "10.1016/s2589-7500(21)00252-1",
    "url": "https://openalex.org/W3212538456",
    "pdf_url": "http://www.thelancet.com/article/S2589750021002521/pdf",
    "venue": "The Lancet Digital Health",
    "citation_count": 196,
    "fields_of_study": [],
    "retrieved_at": "2026-02-02T16:58:12.548054"
  },
  {
    "source": "openalex",
    "source_id": "W2940105172",
    "title": "INTERNATIONAL HUMAN RIGHTS LAW AS A FRAMEWORK FOR ALGORITHMIC ACCOUNTABILITY",
    "authors": [
      "Lorna McGregor",
      "Daragh Murray",
      "Vivian Ng"
    ],
    "year": 2019,
    "abstract": "Abstract Existing approaches to \u2018algorithmic accountability\u2019, such as transparency, provide an important baseline, but are insufficient to address the (potential) harm to human rights caused by the use of algorithms in decision-making. In order to effectively address the impact on human rights, we argue that a framework that sets out a shared understanding and means of assessing harm; is capable of dealing with multiple actors and different forms of responsibility; and applies across the full algorithmic life cycle, from conception to deployment, is needed. While generally overlooked in debates on algorithmic accountability, in this article, we suggest that international human rights law already provides this framework. We apply this framework to illustrate the effect it has on the choices to employ algorithms in decision-making in the first place and the safeguards required. While our analysis indicates that in some circumstances, the use of algorithms may be restricted, we argue that these findings are not \u2018anti-innovation\u2019 but rather appropriate checks and balances to ensure that algorithms contribute to society, while safeguarding against risks.",
    "doi": "10.1017/s0020589319000046",
    "url": "https://openalex.org/W2940105172",
    "pdf_url": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/1D6D0A456B36BA7512A6AFF17F16E9B6/S0020589319000046a.pdf/div-class-title-international-human-rights-law-as-a-framework-for-algorithmic-accountability-div.pdf",
    "venue": "International and Comparative Law Quarterly",
    "citation_count": 175,
    "fields_of_study": [
      "Accountability",
      "Harm",
      "Transparency (behavior)",
      "Human rights",
      "Safeguarding"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548076"
  },
  {
    "source": "openalex",
    "source_id": "W4394580929",
    "title": "Autonomous Vehicles: Evolution of Artificial Intelligence and the Current Industry Landscape",
    "authors": [
      "Divya Garikapati",
      "Sneha Sudhir Shetiya"
    ],
    "year": 2024,
    "abstract": "The advent of autonomous vehicles has heralded a transformative era in transportation, reshaping the landscape of mobility through cutting-edge technologies. Central to this evolution is the integration of artificial intelligence (AI), propelling vehicles into realms of unprecedented autonomy. Commencing with an overview of the current industry landscape with respect to Operational Design Domain (ODD), this paper delves into the fundamental role of AI in shaping the autonomous decision-making capabilities of vehicles. It elucidates the steps involved in the AI-powered development life cycle in vehicles, addressing various challenges such as safety, security, privacy, and ethical considerations in AI-driven software development for autonomous vehicles. The study presents statistical insights into the usage and types of AI algorithms over the years, showcasing the evolving research landscape within the automotive industry. Furthermore, the paper highlights the pivotal role of parameters in refining algorithms for both trucks and cars, facilitating vehicles to adapt, learn, and improve performance over time. It concludes by outlining different levels of autonomy, elucidating the nuanced usage of AI algorithms, and discussing the automation of key tasks and the software package size at each level. Overall, the paper provides a comprehensive analysis of the current industry landscape, focusing on several critical aspects.",
    "doi": "10.3390/bdcc8040042",
    "url": "https://openalex.org/W4394580929",
    "pdf_url": "https://www.mdpi.com/2504-2289/8/4/42/pdf?version=1712549668",
    "venue": "Big Data and Cognitive Computing",
    "citation_count": 144,
    "fields_of_study": [
      "Current (fluid)",
      "Engineering",
      "Business",
      "Electrical engineering"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548093"
  },
  {
    "source": "openalex",
    "source_id": "W2986660526",
    "title": "Personnel selection in the digital age: a review of validity and applicant reactions, and future research challenges",
    "authors": [
      "Stephen A. Woods",
      "Sara Ahmed",
      "Ioannis Nikolaou",
      "Ana Cristina Costa",
      "Neil Anderson"
    ],
    "year": 2019,
    "abstract": "We present a targeted review of recent developments and advances in digital selection procedures (DSPs) with particular attention to advances in internet-based techniques. By reviewing the emergence of DSPs in selection research and practice, we highlight five main categories of methods (online applications, online psychometric testing, digital interviews, gamified assessment and social media). We discuss the evidence base for each of these DSP groups, focusing on construct and criterion validity, and applicant reactions to their use in organizations. Based on the findings of our review, we present a critique of the evidence base for DSPs in industrial, work and organizational psychology and set out an agenda for advancing research. We identify pressing gaps in our understanding of DSPs, and ten key questions to be answered. Given that DSPs are likely to depart further from traditional non-digital selection procedures in the future, a theme in this agenda is the need to establish a distinct and specific literature on DSPs, and to do so at a pace that reflects the speed of the underlying technological advancement. In concluding, we, therefore, issue a call to action for selection researchers in work and organizational psychology to commence a new and rigorous multidisciplinary programme of scientific study of DSPs.",
    "doi": "10.1080/1359432x.2019.1681401",
    "url": "https://openalex.org/W2986660526",
    "pdf_url": "https://bradscholars.brad.ac.uk/bitstreams/f18b4768-85c8-45d5-b629-825fe1c199ea/download",
    "venue": "European Journal of Work and Organizational Psychology",
    "citation_count": 191,
    "fields_of_study": [
      "Selection (genetic algorithm)",
      "Pace",
      "Set (abstract data type)",
      "Construct (python library)",
      "The Internet"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548113"
  },
  {
    "source": "openalex",
    "source_id": "W3008345757",
    "title": "Global value chains: A review of the multi-disciplinary literature",
    "authors": [
      "Liena Kano",
      "Eric W. K. Tsang",
      "Henry Wai\u2010chung Yeung"
    ],
    "year": 2020,
    "abstract": "Abstract This article reviews the rapidly growing domain of global value chain (GVC) research by analyzing several highly cited conceptual frameworks and then appraising GVC studies published in such disciplines as international business, general management, supply chain management, operations management, economic geography, regional and development studies, and international political economy. Building on GVC conceptual frameworks, we conducted the review based on a comparative institutional perspective that encompasses critical governance issues at the micro-, GVC, and macro-levels. Our results indicate that some of these issues have garnered significantly more scholarly attention than others. We suggest several future research topics such as microfoundations of GVC governance, GVC mapping, learning, impact of lead firm ownership and strategy, dynamics of GVC arrangements, value creation and distribution, financialization, digitization, the impact of renewed protectionism, the impact of GVCs on their macro-environment, and chain-level performance management.",
    "doi": "10.1057/s41267-020-00304-2",
    "url": "https://openalex.org/W3008345757",
    "pdf_url": "https://link.springer.com/content/pdf/10.1057/s41267-020-00304-2.pdf",
    "venue": "Journal of International Business Studies",
    "citation_count": 621,
    "fields_of_study": [
      "Microfoundations",
      "Protectionism",
      "Corporate governance",
      "Global value chain",
      "Value (mathematics)"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548135"
  },
  {
    "source": "openalex",
    "source_id": "W4206698631",
    "title": "Trustworthy Augmented Intelligence in Health Care",
    "authors": [
      "Elliott Crigger",
      "Karen Reinbold",
      "Chelsea Hanson",
      "Audiey Kao",
      "Kathleen Blake",
      "Mira Irons"
    ],
    "year": 2022,
    "abstract": "Abstract Augmented Intelligence (AI) systems have the power to transform health care and bring us closer to the quadruple aim: enhancing patient experience, improving population health, reducing costs, and improving the work life of health care providers. Earning physicians' trust is critical for accelerating adoption of AI into patient care. As technology evolves, the medical community will need to develop standards for these innovative technologies and re-visit current regulatory systems that physicians and patients rely on to ensure that health care AI is responsible, evidence-based, free from bias, and designed and deployed to promote equity. To develop actionable guidance for trustworthy AI in health care, the AMA reviewed literature on the challenges health care AI poses and reflected on existing guidance as a starting point for addressing those challenges (including models for regulating the introduction of innovative technologies into clinical care).",
    "doi": "10.1007/s10916-021-01790-z",
    "url": "https://openalex.org/W4206698631",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10916-021-01790-z.pdf",
    "venue": "Journal of Medical Systems",
    "citation_count": 118,
    "fields_of_study": [
      "Health informatics",
      "Trustworthiness",
      "Health care",
      "Computer science",
      "Internet privacy"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548153"
  },
  {
    "source": "openalex",
    "source_id": "W3116658655",
    "title": "Framing governance for a contested emerging technology:insights from AI policy",
    "authors": [
      "Inga Ulnicane",
      "William Knight",
      "Tonii Leach",
      "Bernd Carsten Stahl",
      "Winter-Gladys Wanjiku"
    ],
    "year": 2020,
    "abstract": "ABSTRACT This paper examines how the governance in AI policy documents have been framed as way to resolve public controversies surrounding AI. It draws on the studies of governance of emerging technologies, the concept of policy framing, and analysis of 49 recent policy documents dedicated to AI which have been prepared in the context of technological hype expecting fast advances of AI that will fundamentally change economy and society. The hype about AI is accompanied by major public controversy about positive and negative effects of AI. Against the backdrop of this policy controversy, governance emerges as one of the frames that diagnoses the problems and offers prescriptions. Accordingly, the current governance characterized by oligopoly of a small number of large companies is indicated as one of the reasons for problems such as lack of consideration of societal needs and concerns. To address these problems, governance frame in AI policy documents assigns more active and collaborative roles to the state and society. Amid public controversies, the state is assigned the roles of promoting and facilitating AI development while at the same time being a guarantor of risk mitigation and enabler of societal engagement. High expectations are assigned to public engagement with multiple publics as a way to increase diversity, representation and equality in AI development and use. While this governance frame might have a normative appeal, it is not specific about addressing some well-known challenges of the proposed governance mode such as risks of capture by vested interests or difficulties to achieve consensus.",
    "doi": "10.1080/14494035.2020.1855800",
    "url": "https://openalex.org/W3116658655",
    "pdf_url": "https://academic.oup.com/policyandsociety/article-pdf/40/2/158/42564407/14494035.2020.1855800.pdf",
    "venue": "Policy and Society",
    "citation_count": 193,
    "fields_of_study": [
      "Framing (construction)",
      "Corporate governance",
      "Public policy",
      "Normative",
      "Appeal"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548168"
  },
  {
    "source": "openalex",
    "source_id": "W2808048733",
    "title": "Understanding and Resolving Failures in Human-Robot Interaction: Literature Review and Model Development",
    "authors": [
      "Shanee Honig",
      "Tal Oron-Gilad"
    ],
    "year": 2018,
    "abstract": "While substantial effort has been invested in making robots more reliable, experience demonstrates that robots operating in unstructured environments are often challenged by frequent failures. Despite this, robots have not yet reached a level of design that allows effective management of faulty or unexpected behavior by untrained users. To understand why this may be the case, an in-depth literature review was done to explore when people perceive and resolve robot failures, how robots communicate failure, how failures influence people's perceptions and feelings toward robots, and how these effects can be mitigated. Fifty-two studies were identified relating to communicating failures and their causes, the influence of failures on human-robot interaction (HRI), and mitigating failures. Since little research has been done on these topics within the HRI community, insights from the fields of human computer interaction (HCI), human factors engineering, cognitive engineering and experimental psychology are presented and discussed. Based on the literature, we developed a model of information processing for robotic failures (Robot Failure Human Information Processing, RF-HIP), that guides the discussion of our findings. The model describes the way people perceive, process, and act on failures in human robot interaction. The model includes three main parts: (1) communicating failures, (2) perception and comprehension of failures, and (3) solving failures. Each part contains several stages, all influenced by contextual considerations and mitigation strategies. Several gaps in the literature have become evident as a result of this evaluation. More focus has been given to technical failures than interaction failures. Few studies focused on human errors, on communicating failures, or the cognitive, psychological, and social determinants that impact the design of mitigation strategies. By providing the stages of human information processing, RF-HIP can be used as a tool to promote the development of user-centered failure-handling strategies for HRIs.",
    "doi": "10.3389/fpsyg.2018.00861",
    "url": "https://openalex.org/W2808048733",
    "pdf_url": "https://www.frontiersin.org/articles/10.3389/fpsyg.2018.00861/pdf",
    "venue": "Frontiers in Psychology",
    "citation_count": 294,
    "fields_of_study": [
      "Psychology",
      "Cognitive science",
      "Cognitive psychology",
      "Human\u2013computer interaction",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548190"
  },
  {
    "source": "openalex",
    "source_id": "W4362611851",
    "title": "Environmentally sustainable smart cities and their converging AI, IoT, and big data technologies and solutions: an integrated approach to an extensive literature review",
    "authors": [
      "Simon Elias Bibri",
      "Alexandre Alahi",
      "Ayyoob Sharifi",
      "John Krogstie"
    ],
    "year": 2023,
    "abstract": "Abstract There have recently been intensive efforts aimed at addressing the challenges of environmental degradation and climate change through the applied innovative solutions of AI, IoT, and Big Data. Given the synergistic potential of these advanced technologies, their convergence is being embraced and leveraged by smart cities in an attempt to make progress toward reaching the environmental targets of sustainable development goals under what has been termed \u201cenvironmentally sustainable smart cities.\u201d This new paradigm of urbanism represents a significant research gap in and of itself. To fill this gap, this study explores the key research trends and driving factors of environmentally sustainable smart cities and maps their thematic evolution. Further, it examines the fragmentation, amalgamation, and transition of their underlying models of urbanism as well as their converging AI, IoT, and Big Data technologies and solutions. It employs and combines bibliometric analysis and evidence synthesis methods. A total of 2,574 documents were collected from the Web of Science database and compartmentalized into three sub-periods: 1991\u20132015, 2016\u20132019, and 2020\u20132021. The results show that environmentally sustainable smart cities are a rapidly growing trend that markedly escalated during the second and third periods\u2014due to the acceleration of the digitalization and decarbonization agendas\u2014thanks to COVID-19 and the rapid advancement of data-driven technologies. The analysis also reveals that, while the overall priority research topics have been dynamic over time\u2014some AI models and techniques and environmental sustainability areas have received more attention than others. The evidence synthesized indicates that the increasing criticism of the fragmentation of smart cities and sustainable cities, the widespread diffusion of the SDGs agenda, and the dominance of advanced ICT have significantly impacted the materialization of environmentally sustainable smart cities, thereby influencing the landscape and dynamics of smart cities. It also suggests that the convergence of AI, IoT, and Big Data technologies provides new approaches to tackling the challenges of environmental sustainability. However, these technologies involve environmental costs and pose ethical risks and regulatory conundrums. The findings can inform scholars and practitioners of the emerging data-driven technology solutions of smart cities, as well as assist policymakers in designing and implementing responsive environmental policies.",
    "doi": "10.1186/s42162-023-00259-2",
    "url": "https://openalex.org/W4362611851",
    "pdf_url": "https://energyinformatics.springeropen.com/counter/pdf/10.1186/s42162-023-00259-2",
    "venue": "Energy Informatics",
    "citation_count": 206,
    "fields_of_study": [
      "Internet of Things",
      "Big data",
      "Computer science",
      "Environmentally friendly",
      "Smart city"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548217"
  },
  {
    "source": "openalex",
    "source_id": "W4390906507",
    "title": "Artificial Intelligence Alone Will Not Democratise Education: On Educational Inequality, Techno-Solutionism and Inclusive Tools",
    "authors": [
      "Sahan Bulathwela",
      "Mar\u00eda P\u00e9rez\u2010Ortiz",
      "Catherine Holloway",
      "Mutlu Cukurova",
      "John Shawe\u2010Taylor"
    ],
    "year": 2024,
    "abstract": "Artificial Intelligence (AI) in Education claims to have the potential for building personalised curricula, as well as bringing opportunities for democratising education and creating a renaissance of new ways of teaching and learning. Millions of students are starting to benefit from the use of these technologies, but millions more around the world are not, due to the digital divide and deep pre-existing social and educational inequalities. If this trend continues, the first large-scale delivery of AI in Education could lead to greater educational inequality, along with a global misallocation of educational resources motivated by the current techno-solutionist narrative, which proposes technological solutions as a quick and flawless way to solve complex real-world problems. This work focuses on posing questions about the future of AI in Education, intending to initiate the pressing conversation that could set the right foundations (e.g., inclusion and diversity) for a new generation of education that is permeated with AI technology. The main goal of our opinion piece is to conceptualise a sustainable, large-scale and inclusive AI for the education ecosystem that facilitates equitable, high-quality lifelong learning opportunities for all. The contribution starts by synthesising how AI might change how we learn and teach, focusing on the case of personalised learning companions and assistive technology for disability. Then, we move on to discuss some socio-technical features that will be crucial to avoiding the perils of these AI systems worldwide (and perhaps ensuring their success by leveraging more inclusive education). This work also discusses the potential of using AI together with free, participatory and democratic resources, such as Wikipedia, Open Educational Resources and open-source tools. We emphasise the need for collectively designing human-centred, transparent, interactive and collaborative AI-based algorithms that empower and give complete agency to stakeholders, as well as supporting new emerging pedagogies. Finally, we ask what it would take for this educational revolution to provide egalitarian and empowering access to education that transcends any political, cultural, language, geographical and learning-ability barriers, so that educational systems can be responsive to all learners\u2019 needs.",
    "doi": "10.3390/su16020781",
    "url": "https://openalex.org/W4390906507",
    "pdf_url": "https://www.mdpi.com/2071-1050/16/2/781/pdf?version=1705417242",
    "venue": "Sustainability",
    "citation_count": 149,
    "fields_of_study": [
      "Curriculum",
      "Inclusion (mineral)",
      "Conversation",
      "Scale (ratio)",
      "Engineering ethics"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548253"
  },
  {
    "source": "openalex",
    "source_id": "W4210402525",
    "title": "From Greenwashing to Machinewashing: A Model and Future Directions Derived from Reasoning by Analogy",
    "authors": [
      "Peter Seele",
      "Mario D. Schultz"
    ],
    "year": 2022,
    "abstract": "Abstract This article proposes a conceptual mapping to outline salient properties and relations that allow for a knowledge transfer from the well-established greenwashing phenomenon to the more recent machinewashing. We account for relevant dissimilarities, indicating where conceptual boundaries may be drawn. Guided by a \u201creasoning by analogy\u201d approach, the article addresses the structural analogy and machinewashing idiosyncrasies leading to a novel and theoretically informed model of machinewashing. Consequently, machinewashing is defined as a strategy that organizations adopt to engage in misleading behavior (communication and/or action) about ethical Artificial Intelligence (AI)/algorithmic systems. Machinewashing involves misleading information about ethical AI communicated or omitted via words, visuals, or the underlying algorithm of AI itself. Furthermore, and going beyond greenwashing, machinewashing may be used for symbolic actions such as (covert) lobbying and prevention of stricter regulation. By outlining diverse theoretical foundations of the established greenwashing domain and their relation to specific research questions, the article proposes a machinewashing model and a set of theory-related research questions on the macro, meso, and micro-level for future machinewashing research. We conclude by stressing limitations and by outlining practical implications for organizations and policymakers.",
    "doi": "10.1007/s10551-022-05054-9",
    "url": "https://openalex.org/W4210402525",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10551-022-05054-9.pdf",
    "venue": "Journal of Business Ethics",
    "citation_count": 137,
    "fields_of_study": [
      "Analogy",
      "Greenwashing",
      "Action (physics)",
      "Salient",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548286"
  },
  {
    "source": "openalex",
    "source_id": "W4379743664",
    "title": "A systematic review of Green <scp>AI</scp>",
    "authors": [
      "Roberto Verdecchia",
      "June Sallou",
      "Lu\u00eds Cruz"
    ],
    "year": 2023,
    "abstract": "Abstract With the ever\u2010growing adoption of artificial intelligence (AI)\u2010based systems, the carbon footprint of AI is no longer negligible. AI researchers and practitioners are therefore urged to hold themselves accountable for the carbon emissions of the AI models they design and use. This led in recent years to the appearance of researches tackling AI environmental sustainability, a field referred to as Green AI. Despite the rapid growth of interest in the topic, a comprehensive overview of Green AI research is to date still missing. To address this gap, in this article, we present a systematic review of the Green AI literature. From the analysis of 98 primary studies, different patterns emerge. The topic experienced a considerable growth from 2020 onward. Most studies consider monitoring AI model footprint, tuning hyperparameters to improve model sustainability, or benchmarking models. A mix of position papers, observational studies, and solution papers are present. Most papers focus on the training phase, are algorithm\u2010agnostic or study neural networks, and use image data. Laboratory experiments are the most common research strategy. Reported Green AI energy savings go up to 115%, with savings over 50% being rather common. Industrial parties are involved in Green AI studies, albeit most target academic readers. Green AI tool provisioning is scarce. As a conclusion, the Green AI research field results to have reached a considerable level of maturity. Therefore, from this review emerges that the time is suitable to adopt other Green AI research strategies, and port the numerous promising academic results to industrial practice. This article is categorized under: Technologies &gt; Machine Learning",
    "doi": "10.1002/widm.1507",
    "url": "https://openalex.org/W4379743664",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/widm.1507",
    "venue": "Wiley Interdisciplinary Reviews Data Mining and Knowledge Discovery",
    "citation_count": 214,
    "fields_of_study": [
      "Artificial intelligence",
      "Sustainability",
      "Benchmarking",
      "Carbon footprint",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548311"
  },
  {
    "source": "openalex",
    "source_id": "W3083287224",
    "title": "Trust in Robots: Challenges and Opportunities",
    "authors": [
      "Bing Cai Kok",
      "Harold Soh"
    ],
    "year": 2020,
    "abstract": null,
    "doi": "10.1007/s43154-020-00029-y",
    "url": "https://openalex.org/W3083287224",
    "pdf_url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC7467858/",
    "venue": "Current Robotics Reports",
    "citation_count": 188,
    "fields_of_study": [
      "Robot",
      "Trustworthiness",
      "Computer science",
      "Robotics",
      "Human\u2013computer interaction"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548336"
  },
  {
    "source": "openalex",
    "source_id": "W3174417986",
    "title": "Accelerating AI Adoption with Responsible AI Signals and Employee Engagement Mechanisms in Health Care",
    "authors": [
      "Weisha Wang",
      "Long Chen",
      "Mengran Xiong",
      "Yichuan Wang"
    ],
    "year": 2021,
    "abstract": null,
    "doi": "10.1007/s10796-021-10154-4",
    "url": "https://openalex.org/W3174417986",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10796-021-10154-4.pdf",
    "venue": "Information Systems Frontiers",
    "citation_count": 122,
    "fields_of_study": [
      "Autonomy",
      "Beneficence",
      "Economic Justice",
      "Health care",
      "Psychology"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548339"
  },
  {
    "source": "openalex",
    "source_id": "W4393335480",
    "title": "Foundation metrics for evaluating effectiveness of healthcare conversations powered by generative AI",
    "authors": [
      "Mahyar Abbasian",
      "Elahe Khatibi",
      "Iman Azimi",
      "David Oniani",
      "Zahra Shakeri Hossein Abad",
      "Alexander Thieme",
      "Ram D. Sriram",
      "Zhongqi Yang",
      "Yanshan Wang",
      "Bryant Lin",
      "Olivier Gevaert",
      "Li-Jia Li",
      "Ramesh Jain",
      "Amir M. Rahmani"
    ],
    "year": 2024,
    "abstract": "Abstract Generative Artificial Intelligence is set to revolutionize healthcare delivery by transforming traditional patient care into a more personalized, efficient, and proactive process. Chatbots, serving as interactive conversational models, will probably drive this patient-centered transformation in healthcare. Through the provision of various services, including diagnosis, personalized lifestyle recommendations, dynamic scheduling of follow-ups, and mental health support, the objective is to substantially augment patient health outcomes, all the while mitigating the workload burden on healthcare providers. The life-critical nature of healthcare applications necessitates establishing a unified and comprehensive set of evaluation metrics for conversational models. Existing evaluation metrics proposed for various generic large language models (LLMs) demonstrate a lack of comprehension regarding medical and health concepts and their significance in promoting patients\u2019 well-being. Moreover, these metrics neglect pivotal user-centered aspects, including trust-building, ethics, personalization, empathy, user comprehension, and emotional support. The purpose of this paper is to explore state-of-the-art LLM-based evaluation metrics that are specifically applicable to the assessment of interactive conversational models in healthcare. Subsequently, we present a comprehensive set of evaluation metrics designed to thoroughly assess the performance of healthcare chatbots from an end-user perspective. These metrics encompass an evaluation of language processing abilities, impact on real-world clinical tasks, and effectiveness in user-interactive conversations. Finally, we engage in a discussion concerning the challenges associated with defining and implementing these metrics, with particular emphasis on confounding factors such as the target audience, evaluation methods, and prompt techniques involved in the evaluation process.",
    "doi": "10.1038/s41746-024-01074-z",
    "url": "https://openalex.org/W4393335480",
    "pdf_url": "https://www.nature.com/articles/s41746-024-01074-z.pdf",
    "venue": "npj Digital Medicine",
    "citation_count": 141,
    "fields_of_study": [
      "Health care",
      "Computer science",
      "Personalization",
      "Set (abstract data type)",
      "Process (computing)"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548344"
  },
  {
    "source": "openalex",
    "source_id": "W2982915530",
    "title": "WeBuildAI",
    "authors": [
      "Min Kyung Lee",
      "Daniel Kusbit",
      "Anson Kahng",
      "Ji Tae Kim",
      "Xinran Yuan",
      "Allissa Chan",
      "Daniel See",
      "Ritesh Noothigattu",
      "Siheon Lee",
      "Alexandros Psomas",
      "Ariel D. Procaccia"
    ],
    "year": 2019,
    "abstract": "Algorithms increasingly govern societal functions, impacting multiple stakeholders and social groups. How can we design these algorithms to balance varying interests in a moral, legitimate way? As one answer to this question, we present WeBuildAI, a collective participatory framework that enables people to build algorithmic policy for their communities. The key idea of the framework is to enable stakeholders to construct a computational model that represents their views and to have those models vote on their behalf to create algorithmic policy. As a case study, we applied this framework to a matching algorithm that operates an on-demand food donation transportation service in order to adjudicate equity and efficiency trade-offs. The service's stakeholders--donors, volunteers, recipient organizations, and nonprofit employees--used the framework to design the algorithm through a series of studies in which we researched their experiences. Our findings suggest that the framework successfully enabled participants to build models that they felt confident represented their own beliefs. Participatory algorithm design also improved both procedural fairness and the distributive outcomes of the algorithm, raised participants' algorithmic awareness, and helped identify inconsistencies in human decision-making in the governing organization. Our work demonstrates the feasibility, potential and challenges of community involvement in algorithm design.",
    "doi": "10.1145/3359283",
    "url": "https://openalex.org/W2982915530",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3359283",
    "venue": "Proceedings of the ACM on Human-Computer Interaction",
    "citation_count": 174,
    "fields_of_study": [
      "Computer science",
      "Equity (law)",
      "Construct (python library)",
      "Participatory design",
      "Citizen journalism"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548368"
  },
  {
    "source": "openalex",
    "source_id": "W4281775820",
    "title": "Transparency of AI in Healthcare as a Multilayered System of Accountabilities: Between Legal Requirements and Technical Limitations",
    "authors": [
      "Anastasiya Kiseleva",
      "Dimitris Kotzinos",
      "Paul De Hert"
    ],
    "year": 2022,
    "abstract": "The lack of transparency is one of the artificial intelligence (AI)'s fundamental challenges, but the concept of transparency might be even more opaque than AI itself. Researchers in different fields who attempt to provide the solutions to improve AI's transparency articulate different but neighboring concepts that include, besides transparency, explainability and interpretability. Yet, there is no common taxonomy neither within one field (such as data science) nor between different fields (law and data science). In certain areas like healthcare, the requirements of transparency are crucial since the decisions directly affect people's lives. In this paper, we suggest an interdisciplinary vision on how to tackle the issue of AI's transparency in healthcare, and we propose a single point of reference for both legal scholars and data scientists on transparency and related concepts. Based on the analysis of the European Union (EU) legislation and literature in computer science, we submit that transparency shall be considered the \u201cway of thinking\u201d and umbrella concept characterizing the process of AI's development and use. Transparency shall be achieved through a set of measures such as interpretability and explainability, communication, auditability, traceability, information provision, record-keeping, data governance and management, and documentation. This approach to deal with transparency is of general nature, but transparency measures shall be always contextualized. By analyzing transparency in the healthcare context, we submit that it shall be viewed as a system of accountabilities of involved subjects (AI developers, healthcare professionals, and patients) distributed at different layers (insider, internal, and external layers, respectively). The transparency-related accountabilities shall be built-in into the existing accountability picture which justifies the need to investigate the relevant legal frameworks. These frameworks correspond to different layers of the transparency system. The requirement of informed medical consent correlates to the external layer of transparency and the Medical Devices Framework is relevant to the insider and internal layers. We investigate the said frameworks to inform AI developers on what is already expected from them with regards to transparency. We also discover the gaps in the existing legislative frameworks concerning AI's transparency in healthcare and suggest the solutions to fill them in.",
    "doi": "10.3389/frai.2022.879603",
    "url": "https://openalex.org/W4281775820",
    "pdf_url": "https://www.frontiersin.org/articles/10.3389/frai.2022.879603/pdf",
    "venue": "Frontiers in Artificial Intelligence",
    "citation_count": 200,
    "fields_of_study": [
      "Transparency (behavior)",
      "Health care",
      "Business",
      "Healthcare system",
      "Risk analysis (engineering)"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548387"
  },
  {
    "source": "openalex",
    "source_id": "W3142698583",
    "title": "Sociotechnical Envelopment of Artificial Intelligence: An Approach to Organizational Deployment of Inscrutable Artificial Intelligence Systems",
    "authors": [
      "Aleksandre Asatiani",
      "Pekka Malo",
      "Per R\u00e5dberg Nagb\u00f8l",
      "Esko Penttinen",
      "Tapani Rinta-Kahila",
      "Antti Salovaara"
    ],
    "year": 2021,
    "abstract": "The paper presents an approach for implementing inscrutable (i.e., nonexplainable) artificial intelligence (AI) such as neural networks in an accountable and safe manner in organizational settings. Drawing on an exploratory case study and the recently proposed concept of envelopment, it describes a case of an organization successfully \u201cenveloping\u201d its AI solutions to balance the performance benefits of flexible AI models with the risks that inscrutable models can entail. The authors present several envelopment methods\u2014establishing clear boundaries within which the AI is to interact with its surroundings, choosing and curating the training data well, and appropriately managing input and output sources\u2014alongside their influence on the choice of AI models within the organization. This work makes two key contributions: It introduces the concept of sociotechnical envelopment by demonstrating the ways in which an organization\u2019s successful AI envelopment depends on the interaction of social and technical factors, thus extending the literature\u2019s focus beyond mere technical issues. Secondly, the empirical examples illustrate how operationalizing a sociotechnical envelopment enables an organization to manage the trade-off between low explainability and high performance presented by inscrutable models. These contributions pave the way for more responsible, accountable AI implementations in organizations, whereby humans can gain better control of even inscrutable machine-learning models.",
    "doi": "10.17705/1jais.00664",
    "url": "https://openalex.org/W3142698583",
    "pdf_url": "https://aisel.aisnet.org/cgi/viewcontent.cgi?article=2001&context=jais",
    "venue": "Journal of the Association for Information Systems",
    "citation_count": 148,
    "fields_of_study": [
      "Sociotechnical system",
      "Operationalization",
      "Computer science",
      "Data envelopment analysis",
      "Management science"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548421"
  },
  {
    "source": "openalex",
    "source_id": "W3192184597",
    "title": "Data science and AI in FinTech: an overview",
    "authors": [
      "Longbing Cao",
      "Qiang Yang",
      "Philip S. Yu"
    ],
    "year": 2021,
    "abstract": null,
    "doi": "10.1007/s41060-021-00278-w",
    "url": "https://openalex.org/W3192184597",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s41060-021-00278-w.pdf",
    "venue": "International Journal of Data Science and Analytics",
    "citation_count": 158,
    "fields_of_study": [
      "Cryptocurrency",
      "Big data",
      "Financial services",
      "Data science",
      "Futures contract"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548441"
  },
  {
    "source": "openalex",
    "source_id": "W3027907822",
    "title": "Can Building \u201cArtificially Intelligent Cities\u201d Safeguard Humanity from Natural Disasters, Pandemics, and Other Catastrophes? An Urban Scholar\u2019s Perspective",
    "authors": [
      "Tan Yi\u011fitcanlar",
      "Luke Butler",
      "Emily Windle",
      "Kevin C. Desouza",
      "Rashid Mehmood",
      "Juan M. Corchado"
    ],
    "year": 2020,
    "abstract": "In recent years, artificial intelligence (AI) has started to manifest itself at an unprecedented pace. With highly sophisticated capabilities, AI has the potential to dramatically change our cities and societies. Despite its growing importance, the urban and social implications of AI are still an understudied area. In order to contribute to the ongoing efforts to address this research gap, this paper introduces the notion of an artificially intelligent city as the potential successor of the popular smart city brand\u2014where the smartness of a city has come to be strongly associated with the use of viable technological solutions, including AI. The study explores whether building artificially intelligent cities can safeguard humanity from natural disasters, pandemics, and other catastrophes. All of the statements in this viewpoint are based on a thorough review of the current status of AI literature, research, developments, trends, and applications. This paper generates insights and identifies prospective research questions by charting the evolution of AI and the potential impacts of the systematic adoption of AI in cities and societies. The generated insights inform urban policymakers, managers, and planners on how to ensure the correct uptake of AI in our cities, and the identified critical questions offer scholars directions for prospective research and development.",
    "doi": "10.3390/s20102988",
    "url": "https://openalex.org/W3027907822",
    "pdf_url": "https://www.mdpi.com/1424-8220/20/10/2988/pdf",
    "venue": "Sensors",
    "citation_count": 184,
    "fields_of_study": [
      "Pace",
      "Successor cardinal",
      "Humanity",
      "Safeguard",
      "Natural disaster"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548445"
  },
  {
    "source": "openalex",
    "source_id": "W4281627170",
    "title": "An AI-based Decision Support System for Predicting Mental Health Disorders",
    "authors": [
      "Salih Tutun",
      "Marina Johnson",
      "Abdulaziz Ahmed",
      "Abdullah Albizri",
      "Sedat Irgil",
      "Ilker Yesilkaya",
      "Esma Nur Ucar",
      "Tanalp Sengun",
      "Antoine Harfouche"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1007/s10796-022-10282-5",
    "url": "https://openalex.org/W4281627170",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10796-022-10282-5.pdf",
    "venue": "Information Systems Frontiers",
    "citation_count": 136,
    "fields_of_study": [
      "Mental health",
      "Medical diagnosis",
      "Computer science",
      "Anxiety",
      "Classification of mental disorders"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548466"
  },
  {
    "source": "openalex",
    "source_id": "W3134656840",
    "title": "Data preparation for artificial intelligence in medical imaging: A comprehensive guide to open-access platforms and tools",
    "authors": [
      "Oliver D\u00edaz",
      "Kaisar Kushibar",
      "Richard Osuala",
      "Akis Linardos",
      "Lidia Garrucho",
      "Laura Igual",
      "Petia Radeva",
      "Fred Prior",
      "Polyxeni Gkontra",
      "Karim Lekadir"
    ],
    "year": 2021,
    "abstract": "The vast amount of data produced by today's medical imaging systems has led medical professionals to turn to novel technologies in order to efficiently handle their data and exploit the rich information present in them. In this context, artificial intelligence (AI) is emerging as one of the most prominent solutions, promising to revolutionise every day clinical practice and medical research. The pillar supporting the development of reliable and robust AI algorithms is the appropriate preparation of the medical images to be used by the AI-driven solutions. Here, we provide a comprehensive guide for the necessary steps to prepare medical images prior to developing or applying AI algorithms. The main steps involved in a typical medical image preparation pipeline include: (i) image acquisition at clinical sites, (ii) image de-identification to remove personal information and protect patient privacy, (iii) data curation to control for image and associated information quality, (iv) image storage, and (v) image annotation. There exists a plethora of open access tools to perform each of the aforementioned tasks and are hereby reviewed. Furthermore, we detail medical image repositories covering different organs and diseases. Such repositories are constantly increasing and enriched with the advent of big data. Lastly, we offer directions for future work in this rapidly evolving field.",
    "doi": "10.1016/j.ejmp.2021.02.007",
    "url": "https://openalex.org/W3134656840",
    "pdf_url": "http://www.physicamedica.com/article/S1120179721000958/pdf",
    "venue": "Physica Medica",
    "citation_count": 134,
    "fields_of_study": [
      "Computer science",
      "Medical imaging",
      "Artificial intelligence",
      "Data science"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548470"
  },
  {
    "source": "openalex",
    "source_id": "W4362653910",
    "title": "Global Encyclopedia of Public Administration, Public Policy, and Governance",
    "authors": [
      "Ali Farazmand\ufeff"
    ],
    "year": 2022,
    "abstract": "This second edition serves as a comprehensive collection of global scholarship regarding the vast fields of public administration and public policy.",
    "doi": "10.1007/978-3-030-66252-3",
    "url": "https://openalex.org/W4362653910",
    "pdf_url": "https://link.springer.com/content/pdf/bfm:978-3-030-66252-3/1?pdf=chapter%20toc",
    "venue": null,
    "citation_count": 244,
    "fields_of_study": [
      "Scholarship",
      "Encyclopedia",
      "Public administration",
      "Administration (probate law)",
      "Corporate governance"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548490"
  },
  {
    "source": "openalex",
    "source_id": "W4229457720",
    "title": "Understanding and shaping the future of work with self-determination theory",
    "authors": [
      "Maryl\u00e8ne Gagn\u00e9",
      "Sharon K. Parker",
      "Mark Griffin",
      "Patrick D. Dunlop",
      "Caroline Knight",
      "Florian E. Klonek",
      "Xavier Parent\u2010Rocheleau"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1038/s44159-022-00056-w",
    "url": "https://openalex.org/W4229457720",
    "pdf_url": "https://www.nature.com/articles/s44159-022-00056-w.pdf",
    "venue": "Nature Reviews Psychology",
    "citation_count": 302,
    "fields_of_study": [
      "Self-determination theory",
      "Competence (human resources)",
      "Autonomy",
      "Work (physics)",
      "Work motivation"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548496"
  },
  {
    "source": "openalex",
    "source_id": "W3126217793",
    "title": "AI in Context and the Sustainable Development Goals: Factoring in the Unsustainability of the Sociotechnical System",
    "authors": [
      "Henrik Skaug S\u00e6tra"
    ],
    "year": 2021,
    "abstract": "Artificial intelligence (AI) is associated with both positive and negative impacts on both people and planet, and much attention is currently devoted to analyzing and evaluating these impacts. In 2015, the UN set 17 Sustainable Development Goals (SDGs), consisting of environmental, social, and economic goals. This article shows how the SDGs provide a novel and useful framework for analyzing and categorizing the benefits and harms of AI. AI is here considered in context as part of a sociotechnical system consisting of larger structures and economic and political systems, rather than as a simple tool that can be analyzed in isolation. This article distinguishes between direct and indirect effects of AI and divides the SDGs into five groups based on the kinds of impact AI has on them. While AI has great positive potential, it is also intimately linked to nonuniversal access to increasingly large data sets and the computing infrastructure required to make use of them. As a handful of nations and companies control the development and application of AI, this raises important questions regarding the potential negative implications of AI on the SDGs. The conceptual framework here presented helps structure the analysis of which of the SDGs AI might be useful in attaining and which goals are threatened by the increased use of AI.",
    "doi": "10.3390/su13041738",
    "url": "https://openalex.org/W3126217793",
    "pdf_url": "https://www.mdpi.com/2071-1050/13/4/1738/pdf?version=1612681180",
    "venue": "Sustainability",
    "citation_count": 133,
    "fields_of_study": [
      "Sociotechnical system",
      "Factoring",
      "Sustainable development",
      "Context (archaeology)",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548499"
  },
  {
    "source": "openalex",
    "source_id": "W2609656715",
    "title": "Job Insecurity and the Changing Workplace: Recent Developments and the Future Trends in Job Insecurity Research",
    "authors": [
      "Cynthia Lee",
      "Guohua Huang",
      "Susan J. Ashford"
    ],
    "year": 2017,
    "abstract": "This article updates our understanding of the field of job insecurity (JI) by incorporating studies across the globe since 2003, analyzes what we know, and offers ideas on how to move forward. We begin by reviewing the conceptualization and operationalization of job insecurity. We then review empirical studies of the antecedents, consequences, and moderators of JI effects, as well as the various theoretical perspectives used to explain the relationship of JI to various outcomes. Our analyses also consider JI research in different regions of the world, highlighting the cross-cultural differences. We conclude by identifying areas in need of future research. We propose that JI is and will continue to be a predominant employment issue, such that research into it will only increase in importance and relevance. In particular, we call for in-depth research that carefully considers the rapid changes in the workplace today and in the future.",
    "doi": "10.1146/annurev-orgpsych-032117-104651",
    "url": "https://openalex.org/W2609656715",
    "pdf_url": "https://www.annualreviews.org/doi/pdf/10.1146/annurev-orgpsych-032117-104651",
    "venue": "Annual Review of Organizational Psychology and Organizational Behavior",
    "citation_count": 356,
    "fields_of_study": [
      "Operationalization",
      "Globe",
      "Conceptualization",
      "Job insecurity",
      "Relevance (law)"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548519"
  },
  {
    "source": "openalex",
    "source_id": "W4385497937",
    "title": "What ChatGPT Tells Us about Gender: A Cautionary Tale about Performativity and Gender Biases in AI",
    "authors": [
      "Nicole Gross"
    ],
    "year": 2023,
    "abstract": "Large language models and generative AI, such as ChatGPT, have gained influence over people\u2019s personal lives and work since their launch, and are expected to scale even further. While the promises of generative artificial intelligence are compelling, this technology harbors significant biases, including those related to gender. Gender biases create patterns of behavior and stereotypes that put women, men and gender-diverse people at a disadvantage. Gender inequalities and injustices affect society as a whole. As a social practice, gendering is achieved through the repeated citation of rituals, expectations and norms. Shared understandings are often captured in scripts, including those emerging in and from generative AI, which means that gendered views and gender biases get grafted back into social, political and economic life. This paper\u2019s central argument is that large language models work performatively, which means that they perpetuate and perhaps even amplify old and non-inclusive understandings of gender. Examples from ChatGPT are used here to illustrate some gender biases in AI. However, this paper also puts forward that AI can work to mitigate biases and act to \u2018undo gender\u2019.",
    "doi": "10.3390/socsci12080435",
    "url": "https://openalex.org/W4385497937",
    "pdf_url": "https://www.mdpi.com/2076-0760/12/8/435/pdf?version=1690954844",
    "venue": "Social Sciences",
    "citation_count": 130,
    "fields_of_study": [
      "Performativity",
      "Generative grammar",
      "Argument (complex analysis)",
      "Disadvantage",
      "Sociology"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548534"
  },
  {
    "source": "openalex",
    "source_id": "W4386973901",
    "title": "Large AI Models in Health Informatics: Applications, Challenges, and the Future",
    "authors": [
      "Jianing Qiu",
      "Lin Li",
      "Jiankai Sun",
      "Jiachuan Peng",
      "Peilun Shi",
      "Ruiyang Zhang",
      "Yinzhao Dong",
      "Kyle Lam",
      "Frank P.-W. Lo",
      "Bo Xiao",
      "Wu Yuan",
      "Ningli Wang",
      "Dong Xu",
      "Benny Lo"
    ],
    "year": 2023,
    "abstract": "Large AI models, or foundation models, are models recently emerging with massive scales both parameter-wise and data-wise, the magnitudes of which can reach beyond billions. Once pretrained, large AI models demonstrate impressive performance in various downstream tasks. A prime example is ChatGPT, whose capability has compelled people's imagination about the far-reaching influence that large AI models can have and their potential to transform different domains of our lives. In health informatics, the advent of large AI models has brought new paradigms for the design of methodologies. The scale of multi-modal data in the biomedical and health domain has been ever-expanding especially since the community embraced the era of deep learning, which provides the ground to develop, validate, and advance large AI models for breakthroughs in health-related areas. This article presents a comprehensive review of large AI models, from background to their applications. We identify seven key sectors in which large AI models are applicable and might have substantial influence, including: 1) bioinformatics; 2) medical diagnosis; 3) medical imaging; 4) medical informatics; 5) medical education; 6) public health; and 7) medical robotics. We examine their challenges, followed by a critical discussion about potential future directions and pitfalls of large AI models in transforming the field of health informatics.",
    "doi": "10.1109/jbhi.2023.3316750",
    "url": "https://openalex.org/W4386973901",
    "pdf_url": "https://ieeexplore.ieee.org/ielx7/6221020/6363502/10261199.pdf",
    "venue": "IEEE Journal of Biomedical and Health Informatics",
    "citation_count": 193,
    "fields_of_study": [
      "Computer science",
      "Health informatics",
      "Informatics",
      "Data science",
      "Medicine"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548555"
  },
  {
    "source": "openalex",
    "source_id": "W3090868346",
    "title": "Artificial intelligence in the water domain: Opportunities for responsible use",
    "authors": [
      "Neelke Doorn"
    ],
    "year": 2020,
    "abstract": null,
    "doi": "10.1016/j.scitotenv.2020.142561",
    "url": "https://openalex.org/W3090868346",
    "pdf_url": "https://ars.els-cdn.com/content/image/1-s2.0-S0048969720360903-ga1_lrg.jpg",
    "venue": "The Science of The Total Environment",
    "citation_count": 118,
    "fields_of_study": [
      "Water sector",
      "Domain (mathematical analysis)",
      "Data science",
      "Citizen journalism",
      "Management science"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548576"
  },
  {
    "source": "openalex",
    "source_id": "W3005369330",
    "title": "Toward an Understanding of Responsible Artificial Intelligence Practices",
    "authors": [
      "Yichuan Wang",
      "Mengran Xiong",
      "Hossein Olya"
    ],
    "year": 2020,
    "abstract": "Artificial Intelligence (AI) is influencing all aspects of human and business activities nowadays. Although potential benefits emerged from AI technologies have been widely discussed in many current literature, there is an urgently need to understand how AI can be designed to operate responsibly and act in a manner meeting stakeholders\u2019 expectations and applicable regulations. We seek to fill the gap by exploring the practices of responsible AI and identifying the potential benefits when implementing responsible AI practices. In this study, 10 responsible AI cases were selected from different industries to better understand the use of responsible AI in practices. Four responsible AI practices are identified, including governance, ethically design solutions, risk control and training and education and five strategies for firms who are considering to adopt responsible AI practices are recommended.",
    "doi": "10.24251/hicss.2020.610",
    "url": "https://openalex.org/W3005369330",
    "pdf_url": "http://localhost:4000/bitstreams/b08af779-9e45-45ef-bc0d-1d1d8855364e/download",
    "venue": "Proceedings of the ... Annual Hawaii International Conference on System Sciences/Proceedings of the Annual Hawaii International Conference on System Sciences",
    "citation_count": 128,
    "fields_of_study": [
      "Corporate governance",
      "Applications of artificial intelligence",
      "Knowledge management",
      "Best practice",
      "Control (management)"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548580"
  },
  {
    "source": "openalex",
    "source_id": "W4283157303",
    "title": "Predictability and Surprise in Large Generative Models",
    "authors": [
      "Deep Ganguli",
      "Danny Hernandez",
      "Liane Lovitt",
      "Amanda Askell",
      "Yuntao Bai",
      "Anna Chen",
      "Tom Conerly",
      "Nova Dassarma",
      "Dawn Drain",
      "Nelson Elhage",
      "Sheer El Showk",
      "Stanislav Fort",
      "Zac Hatfield-Dodds",
      "Tom Henighan",
      "Scott G. Johnston",
      "Andy Jones",
      "Nicholas Joseph",
      "Jackson Kernian",
      "Shauna Kravec",
      "Ben Mann",
      "Neel Nanda",
      "Kamal Ndousse",
      "Catherine Olsson",
      "Daniela Amodei",
      "Tom Brown",
      "Jared Kaplan",
      "Sam McCandlish",
      "Christopher Olah",
      "Dario Amodei",
      "Jack Clark"
    ],
    "year": 2022,
    "abstract": "Large-scale pre-training has recently emerged as a technique for creating capable, general purpose, generative models such as GPT-3, Megatron-Turing NLG, Gopher, and many others. In this paper, we highlight a counterintuitive property of such models and discuss the policy implications of this property. Namely, these generative models have an unusual combination of predictable loss on a broad training distribution (as embodied in their \"scaling laws\"), and unpredictable specific capabilities, inputs, and outputs. We believe that the high-level predictability and appearance of useful capabilities drives rapid development of such models, while the unpredictable qualities make it difficult to anticipate the consequences of model deployment. We go through examples of how this combination can lead to socially harmful behavior with examples from the literature and real world observations, and we also perform two novel experiments to illustrate our point about harms from unpredictability. Furthermore, we analyze how these conflicting properties combine to give model developers various motivations for deploying these models, and challenges that can hinder deployment. We conclude with a list of possible interventions the AI community may take to increase the chance of these models having a beneficial impact. We intend this paper to be useful to policymakers who want to understand and regulate AI systems, technologists who care about the potential policy impact of their work, and academics who want to analyze, critique, and potentially develop large generative models.",
    "doi": "10.1145/3531146.3533229",
    "url": "https://openalex.org/W4283157303",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3531146.3533229",
    "venue": "2022 ACM Conference on Fairness, Accountability, and Transparency",
    "citation_count": 161,
    "fields_of_study": [
      "Counterintuitive",
      "Computer science",
      "Predictability",
      "Generative grammar",
      "Surprise"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548597"
  },
  {
    "source": "openalex",
    "source_id": "W4391974599",
    "title": "Generative AI for Transformative Healthcare: A Comprehensive Study of Emerging Models, Applications, Case Studies, and Limitations",
    "authors": [
      "Siva Sai",
      "Aanchal Gaur",
      "R Vijay Sai",
      "Vinay Chamola",
      "Mohsen Guizani",
      "Joel J. P. C. Rodrigues"
    ],
    "year": 2024,
    "abstract": "Generative artificial intelligence (GAI) can be broadly described as an artificial intelligence system capable of generating images, text, and other media types with human prompts. GAI models like ChatGPT, DALL-E, and Bard have recently caught the attention of industry and academia equally. GAI applications span various industries like art, gaming, fashion, and healthcare. In healthcare, GAI shows promise in medical research, diagnosis, treatment, and patient care and is already making strides in real-world deployments. There has yet to be any detailed study concerning the applications and scope of GAI in healthcare. Addressing this research gap, we explore several applications, real-world scenarios, and limitations of GAI in healthcare. We examine how GAI models like ChatGPT and DALL-E can be leveraged to aid in the applications of medical imaging, drug discovery, personalized patient treatment, medical simulation and training, clinical trial optimization, mental health support, healthcare operations and research, medical chatbots, human movement simulation, and a few more applications. Along with applications, we cover four real-world healthcare scenarios that employ GAI: visual snow syndrome diagnosis, molecular drug optimization, medical education, and dentistry. We also provide an elaborate discussion on seven healthcare-customized LLMs like Med-PaLM, BioGPT, DeepHealth, etc.,Since GAI is still evolving, it poses challenges like the lack of professional expertise in decision making, risk of patient data privacy, issues in integrating with existing healthcare systems, and the problem of data bias which are elaborated on in this work along with several other challenges. We also put forward multiple directions for future research in GAI for healthcare.",
    "doi": "10.1109/access.2024.3367715",
    "url": "https://openalex.org/W4391974599",
    "pdf_url": "https://ieeexplore.ieee.org/ielx7/6287639/6514899/10440330.pdf",
    "venue": "IEEE Access",
    "citation_count": 175,
    "fields_of_study": [
      "Transformative learning",
      "Generative grammar",
      "Computer science",
      "Health care",
      "Data science"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548626"
  },
  {
    "source": "openalex",
    "source_id": "W4288514369",
    "title": "Recommendations for ethical and responsible use of artificial intelligence in digital agriculture",
    "authors": [
      "Rozita Dara",
      "Seyed Mehdi Hazrati Fard",
      "Jasmin Kaur"
    ],
    "year": 2022,
    "abstract": "Artificial intelligence (AI) applications are an integral and emerging component of digital agriculture. AI can help ensure sustainable production in agriculture by enhancing agricultural operations and decision-making. Recommendations about soil condition and pesticides or automatic devices for milking and apple picking are examples of AI applications in digital agriculture. Although AI offers many benefits in farming, AI systems may raise ethical issues and risks that should be assessed and proactively managed. Poor design and configuration of intelligent systems may impose harm and unintended consequences on digital agriculture. Invasion of farmers' privacy, damaging animal welfare due to robotic technologies, and lack of accountability for issues resulting from the use of AI tools are only some examples of ethical challenges in digital agriculture. This paper examines the ethical challenges of the use of AI in agriculture in six categories including fairness, transparency, accountability, sustainability, privacy, and robustness. This study further provides recommendations for agriculture technology providers (ATPs) and policymakers on how to proactively mitigate ethical issues that may arise from the use of AI in farming. These recommendations cover a wide range of ethical considerations, such as addressing farmers' privacy concerns, ensuring reliable AI performance, enhancing sustainability in AI systems, and reducing AI bias.",
    "doi": "10.3389/frai.2022.884192",
    "url": "https://openalex.org/W4288514369",
    "pdf_url": "https://www.frontiersin.org/articles/10.3389/frai.2022.884192/pdf",
    "venue": "Frontiers in Artificial Intelligence",
    "citation_count": 119,
    "fields_of_study": [
      "Agriculture",
      "Sustainability",
      "Transparency (behavior)",
      "Accountability",
      "Harm"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548648"
  },
  {
    "source": "openalex",
    "source_id": "W3177473168",
    "title": "Emerging Consensus on \u2018Ethical AI\u2019: Human Rights Critique of Stakeholder Guidelines",
    "authors": [
      "Sakiko Fukuda\u2010Parr",
      "Elizabeth Gibbons"
    ],
    "year": 2021,
    "abstract": "Abstract Voluntary guidelines on \u2018ethical practices\u2019 have been the response by stakeholders to address the growing concern over harmful social consequences of artificial intelligence and digital technologies. Issued by dozens of actors from industry, government and professional associations, the guidelines are creating a consensus on core standards and principles for ethical design, development and deployment of artificial intelligence (AI). Using human rights principles (equality, participation and accountability) and attention to the right to privacy, this paper reviews 15 guidelines preselected to be strongest on human rights, and on global health. We find about half of these ground their guidelines in international human rights law and incorporate the key principles; even these could go further, especially in suggesting ways to operationalize them. Those that adopt the ethics framework are particularly weak in laying out standards for accountability, often focusing on \u2018transparency\u2019, and remaining silent on enforceability and participation which would effectively protect the social good. These guidelines mention human rights as a rhetorical device to obscure the absence of enforceable standards and accountability measures, and give their attention to the single right to privacy. These \u2018ethics\u2019 guidelines, disproportionately from corporations and other interest groups, are also weak on addressing inequalities and discrimination. We argue that voluntary guidelines are creating a set of de facto norms and re\u2010interpretation of the term \u2018human rights\u2019 for what would be considered \u2018ethical\u2019 practice in the field. This exposes an urgent need for action by governments and civil society to develop more rigorous standards and regulatory measures, grounded in international human rights frameworks, capable of holding Big Tech and other powerful actors to account.",
    "doi": "10.1111/1758-5899.12965",
    "url": "https://openalex.org/W3177473168",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/1758-5899.12965",
    "venue": "Global Policy",
    "citation_count": 106,
    "fields_of_study": [
      "Accountability",
      "Human rights",
      "Public relations",
      "Political science",
      "Operationalization"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548667"
  },
  {
    "source": "openalex",
    "source_id": "W3148438775",
    "title": "A Review on Explainability in Multimodal Deep Neural Nets",
    "authors": [
      "Gargi Joshi",
      "Rahee Walambe",
      "Ketan Kotecha"
    ],
    "year": 2021,
    "abstract": "Artificial Intelligence techniques powered by deep neural nets have achieved much success in several application domains, most significantly and notably in the Computer Vision applications and Natural Language Processing tasks. Surpassing human-level performance propelled the research in the applications where different modalities amongst language, vision, sensory, text play an important role in accurate predictions and identification. Several multimodal fusion methods employing deep learning models are proposed in the literature. Despite their outstanding performance, the complex, opaque and black-box nature of the deep neural nets limits their social acceptance and usability. This has given rise to the quest for model interpretability and explainability, more so in the complex tasks involving multimodal AI methods. This paper extensively reviews the present literature to present a comprehensive survey and commentary on the explainability in multimodal deep neural nets, especially for the vision and language tasks. Several topics on multimodal AI and its applications for generic domains have been covered in this paper, including the significance, datasets, fundamental building blocks of the methods and techniques, challenges, applications, and future trends in this domain",
    "doi": "10.1109/access.2021.3070212",
    "url": "https://openalex.org/W3148438775",
    "pdf_url": "https://ieeexplore.ieee.org/ielx7/6287639/9312710/09391727.pdf",
    "venue": "IEEE Access",
    "citation_count": 181,
    "fields_of_study": [
      "Computer science",
      "Artificial neural network",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548691"
  },
  {
    "source": "openalex",
    "source_id": "W4225323865",
    "title": "Interpretability and fairness evaluation of deep learning models on MIMIC-IV dataset",
    "authors": [
      "Chuizheng Meng",
      "Loc Trinh",
      "Nan Xu",
      "James Enouen",
      "Yan Liu"
    ],
    "year": 2022,
    "abstract": "Abstract The recent release of large-scale healthcare datasets has greatly propelled the research of data-driven deep learning models for healthcare applications. However, due to the nature of such deep black-boxed models, concerns about interpretability, fairness, and biases in healthcare scenarios where human lives are at stake call for a careful and thorough examination of both datasets and models. In this work, we focus on MIMIC-IV (Medical Information Mart for Intensive Care, version IV), the largest publicly available healthcare dataset, and conduct comprehensive analyses of interpretability as well as dataset representation bias and prediction fairness of deep learning models for in-hospital mortality prediction. First, we analyze the interpretability of deep learning mortality prediction models and observe that (1) the best-performing interpretability method successfully identifies critical features for mortality prediction on various prediction models as well as recognizing new important features that domain knowledge does not consider; (2) prediction models rely on demographic features, raising concerns in fairness. Therefore, we then evaluate the fairness of models and do observe the unfairness: (1) there exists disparate treatment in prescribing mechanical ventilation among patient groups across ethnicity, gender and age; (2) models often rely on racial attributes unequally across subgroups to generate their predictions. We further draw concrete connections between interpretability methods and fairness metrics by showing how feature importance from interpretability methods can be beneficial in quantifying potential disparities in mortality predictors. Our analysis demonstrates that the prediction performance is not the only factor to consider when evaluating models for healthcare applications, since high prediction performance might be the result of unfair utilization of demographic features. Our findings suggest that future research in AI models for healthcare applications can benefit from utilizing the analysis workflow of interpretability and fairness as well as verifying if models achieve superior performance at the cost of introducing bias.",
    "doi": "10.1038/s41598-022-11012-2",
    "url": "https://openalex.org/W4225323865",
    "pdf_url": "https://www.nature.com/articles/s41598-022-11012-2.pdf",
    "venue": "Scientific Reports",
    "citation_count": 159,
    "fields_of_study": [
      "Interpretability",
      "Computer science",
      "Machine learning",
      "Artificial intelligence",
      "Deep learning"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548709"
  },
  {
    "source": "openalex",
    "source_id": "W3024478970",
    "title": "Artificial Intelligence and Health Technology Assessment: Anticipating a New Level of Complexity",
    "authors": [
      "Hassane Alami",
      "Pascale Lehoux",
      "Yannick Auclair",
      "Mich\u00e8le de Guise",
      "Marie\u2010Pierre Gagnon",
      "James Shaw",
      "Denis Roy",
      "Richard Fleet",
      "Mohamed Ali Ag Ahmed",
      "Jean\u2010Paul Fortin"
    ],
    "year": 2020,
    "abstract": "Artificial intelligence (AI) is seen as a strategic lever to improve access, quality, and efficiency of care and services and to build learning and value-based health systems. Many studies have examined the technical performance of AI within an experimental context. These studies provide limited insights into the issues that its use in a real-world context of care and services raises. To help decision makers address these issues in a systemic and holistic manner, this viewpoint paper relies on the health technology assessment core model to contrast the expectations of the health sector toward the use of AI with the risks that should be mitigated for its responsible deployment. The analysis adopts the perspective of payers (ie, health system organizations and agencies) because of their central role in regulating, financing, and reimbursing novel technologies. This paper suggests that AI-based systems should be seen as a health system transformation lever, rather than a discrete set of technological devices. Their use could bring significant changes and impacts at several levels: technological, clinical, human and cognitive (patient and clinician), professional and organizational, economic, legal, and ethical. The assessment of AI\u2019s value proposition should thus go beyond technical performance and cost logic by performing a holistic analysis of its value in a real-world context of care and services. To guide AI development, generate knowledge, and draw lessons that can be translated into action, the right political, regulatory, organizational, clinical, and technological conditions for innovation should be created as a first step.",
    "doi": "10.2196/17707",
    "url": "https://openalex.org/W3024478970",
    "pdf_url": "https://www.jmir.org/2020/7/e17707/PDF",
    "venue": "Journal of Medical Internet Research",
    "citation_count": 146,
    "fields_of_study": [
      "Value proposition",
      "Context (archaeology)",
      "Knowledge management",
      "Health care",
      "Software deployment"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548738"
  },
  {
    "source": "openalex",
    "source_id": "W4393170828",
    "title": "Privacy and Security Concerns in Generative AI: A Comprehensive Survey",
    "authors": [
      "Abenezer Golda",
      "Kidus Abebe Mekonen",
      "Amit Pandey",
      "Anushka Singh",
      "Vikas Hassija",
      "Vinay Chamola",
      "Biplab Sikdar"
    ],
    "year": 2024,
    "abstract": "Generative Artificial Intelligence (GAI) has sparked a transformative wave across various domains, including machine learning, healthcare, business, and entertainment, owing to its remarkable ability to generate lifelike data. This comprehensive survey offers a meticulous examination of the privacy and security challenges inherent to GAI. It provides five pivotal perspectives essential for a comprehensive understanding of these intricacies. The paper encompasses discussions on GAI architectures, diverse generative model types, practical applications, and recent advancements within the field. In addition, it highlights current security strategies and proposes sustainable solutions, emphasizing user, developer, institutional, and policymaker involvement.",
    "doi": "10.1109/access.2024.3381611",
    "url": "https://openalex.org/W4393170828",
    "pdf_url": "https://ieeexplore.ieee.org/ielx7/6287639/6514899/10478883.pdf",
    "venue": "IEEE Access",
    "citation_count": 161,
    "fields_of_study": [
      "Computer science",
      "Computer security",
      "Internet privacy",
      "Information privacy",
      "Data science"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548762"
  },
  {
    "source": "openalex",
    "source_id": "W4385732922",
    "title": "Survey on Explainable AI: From Approaches, Limitations and Applications Aspects",
    "authors": [
      "Wenli Yang",
      "Yu-Chen Wei",
      "H. Wei",
      "Yanyu Chen",
      "Guan Huang",
      "Xiang Li",
      "Renjie Li",
      "Naimeng Yao",
      "Xinyi Wang",
      "Xiaotong Gu",
      "Muhammad Bilal Amin",
      "Byeong Ho Kang"
    ],
    "year": 2023,
    "abstract": null,
    "doi": "10.1007/s44230-023-00038-y",
    "url": "https://openalex.org/W4385732922",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s44230-023-00038-y.pdf",
    "venue": "Human-Centric Intelligent Systems",
    "citation_count": 160,
    "fields_of_study": [
      "Transparency (behavior)",
      "Computer science",
      "Process (computing)",
      "Data science",
      "Key (lock)"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548776"
  },
  {
    "source": "openalex",
    "source_id": "W3204423820",
    "title": "FairFed: Enabling Group Fairness in Federated Learning",
    "authors": [
      "Yahya H. Ezzeldin",
      "Shen Yan",
      "Chaoyang He",
      "Emilio Ferrara",
      "A. Salman Avestimehr"
    ],
    "year": 2023,
    "abstract": "Training ML models which are fair across different demographic groups is of critical importance due to the increased integration of ML in crucial decision-making scenarios such as healthcare and recruitment. Federated learning has been viewed as a promising solution for collaboratively training machine learning models among multiple parties while maintaining their local data privacy. However, federated learning also poses new challenges in mitigating the potential bias against certain populations (e.g., demographic groups), as this typically requires centralized access to the sensitive information (e.g., race, gender) of each datapoint. Motivated by the importance and challenges of group fairness in federated learning, in this work, we propose FairFed, a novel algorithm for fairness-aware aggregation to enhance group fairness in federated learning. Our proposed approach is server-side and agnostic to the applied local debiasing thus allowing for flexible use of different local debiasing methods across clients. We evaluate FairFed empirically versus common baselines for fair ML and federated learning and demonstrate that it provides fairer models, particularly under highly heterogeneous data distributions across clients. We also demonstrate the benefits of FairFed in scenarios involving naturally distributed real-life data collected from different geographical locations or departments within an organization.",
    "doi": "10.1609/aaai.v37i6.25911",
    "url": "https://openalex.org/W3204423820",
    "pdf_url": "https://ojs.aaai.org/index.php/AAAI/article/download/25911/25683",
    "venue": "Proceedings of the AAAI Conference on Artificial Intelligence",
    "citation_count": 147,
    "fields_of_study": [
      "Debiasing",
      "Federated learning",
      "Computer science",
      "Work (physics)",
      "Machine learning"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548780"
  },
  {
    "source": "openalex",
    "source_id": "W4297540759",
    "title": "Collaboration among recruiters and artificial intelligence: removing human prejudices in employment",
    "authors": [
      "Zhisheng Chen"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1007/s10111-022-00716-0",
    "url": "https://openalex.org/W4297540759",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10111-022-00716-0.pdf",
    "venue": "Cognition Technology & Work",
    "citation_count": 120,
    "fields_of_study": [
      "Interview",
      "Promotion (chess)",
      "Process (computing)",
      "Stakeholder",
      "Perception"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548799"
  },
  {
    "source": "openalex",
    "source_id": "W4397008103",
    "title": "The synergistic interplay of artificial intelligence and digital twin in environmentally planning sustainable smart cities: A comprehensive systematic review",
    "authors": [
      "Simon Elias Bibri",
      "Jeffrey Huang",
      "Senthil Kumar Jagatheesaperumal",
      "John Krogstie"
    ],
    "year": 2024,
    "abstract": "The dynamic landscape of sustainable smart cities is witnessing a significant transformation due to the integration of emerging computational technologies and innovative models. These advancements are reshaping data-driven planning strategies, practices, and approaches, thereby facilitating the achievement of environmental sustainability goals. This transformative wave signals a fundamental shift - marked by the synergistic operation of artificial intelligence (AI), artificial intelligence of things (AIoT), and urban digital twin (UDT) technologies. While previous research has largely explored urban AI, urban AIoT, and UDT in isolation, a significant knowledge gap exists regarding their synergistic interplay, collaborative integration, and collective impact on data-driven environmental planning in the dynamic context of sustainable smart cities. To address this gap, this study conducts a comprehensive systematic review to uncover the intricate interactions among these interconnected technologies, models, and domains while elucidating the nuanced dynamics and untapped synergies in the complex ecosystem of sustainable smart cities. Central to this study are four guiding research questions: 1. What theoretical and practical foundations underpin the convergence of AI, AIoT, UDT, data-driven planning, and environmental sustainability in sustainable smart cities, and how can these components be synthesized into a novel comprehensive framework? 2. How does integrating AI and AIoT reshape the landscape of data-driven planning to improve the environmental performance of sustainable smart cities? 3. How can AI and AIoT augment the capabilities of UDT to enhance data-driven environmental planning processes in sustainable smart cities? 4. What challenges and barriers arise in integrating and implementing AI, AIoT, and UDT in data-driven environmental urban planning, and what strategies can be devised to surmount or mitigate them? Methodologically, this study involves a rigorous analysis and synthesis of studies published between January 2019 and December 2023, comprising an extensive body of literature totaling 185 studies. The findings of this study surpass mere interdisciplinary theoretical enrichment, offering valuable insights into the transformative potential of integrating AI, AIoT, and UDT technologies to advance sustainable urban development practices. By enhancing data-driven environmental planning processes, these integrated technologies and models offer innovative solutions to address complex environmental challenges. However, this endeavor is fraught with formidable challenges and complexities that require careful navigation and mitigation to achieve desired outcomes. This study serves as a comprehensive reference guide, spurring groundbreaking research endeavors, stimulating practical implementations, informing strategic initiatives, and shaping policy formulations in sustainable urban development. These insights have profound implications for researchers, practitioners, and policymakers, providing a roadmap for fostering resiliently designed, technologically advanced, and environmentally conscious urban environments.",
    "doi": "10.1016/j.ese.2024.100433",
    "url": "https://openalex.org/W4397008103",
    "pdf_url": "https://ars.els-cdn.com/content/image/1-s2.0-S2666498424000474-ga1_lrg.jpg",
    "venue": "Environmental Science and Ecotechnology",
    "citation_count": 149,
    "fields_of_study": [
      "Sustainability",
      "Transformative learning",
      "Context (archaeology)",
      "Smart city",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548803"
  },
  {
    "source": "openalex",
    "source_id": "W3134214835",
    "title": "Algorithmic Impact Assessments and Accountability",
    "authors": [
      "Jacob Metcalf",
      "Emanuel Moss",
      "Elizabeth Anne Watkins",
      "Ranjit Singh",
      "Madeleine Clare Elish"
    ],
    "year": 2021,
    "abstract": "Algorithmic impact assessments (AIAs) are an emergent form of accountability for organizations that build and deploy automated decision-support systems. They are modeled after impact assessments in other domains. Our study of the history of impact assessments shows that \"impacts\" are an evaluative construct that enable actors to identify and ameliorate harms experienced because of a policy decision or system. Every domain has different expectations and norms around what constitutes impacts and harms, how potential harms are rendered as impacts of a particular undertaking, who is responsible for conducting such assessments, and who has the authority to act on them to demand changes to that undertaking. By examining proposals for AIAs in relation to other domains, we find that there is a distinct risk of constructing algorithmic impacts as organizationally understandable metrics that are nonetheless inappropriately distant from the harms experienced by people, and which fall short of building the relationships required for effective accountability. As impact assessments become a commonplace process for evaluating harms, the FAccT community, in its efforts to address this challenge, should A) understand impacts as objects that are co-constructed accountability relationships, B) attempt to construct impacts as close as possible to actual harms, and C) recognize that accountability governance requires the input of various types of expertise and affected communities. We conclude with lessons for assembling cross-expertise consensus for the co-construction of impacts and building robust accountability relationships.",
    "doi": "10.1145/3442188.3445935",
    "url": "https://openalex.org/W3134214835",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3442188.3445935",
    "venue": null,
    "citation_count": 137,
    "fields_of_study": [
      "Accountability",
      "Construct (python library)",
      "Process (computing)",
      "Corporate governance",
      "Risk analysis (engineering)"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548841"
  },
  {
    "source": "openalex",
    "source_id": "W4390056019",
    "title": "Advancing nursing practice with artificial intelligence: Enhancing preparedness for the future",
    "authors": [
      "Moustaq Karim Khan Rony",
      "Mst. Rina Parvin",
      "Silvia Ferdousi"
    ],
    "year": 2023,
    "abstract": "Abstract Aim This article aimed to explore the role of AI in advancing nursing practice, focusing on its impact on readiness for the future. Design and Methods A position paper, the methodology comprises three key steps. First, a comprehensive literature search using specific keywords in reputable databases was conducted to gather current information on AI in nursing. Second, data extraction and synthesis from selected articles were performed. Finally, a thematic analysis identifies recurring themes to provide insights into AI's impact on future nursing practice. Results The findings highlight the transformative role of AI in advancing nursing practice and preparing nurses for the future, including enhancing nursing practice with AI, preparing nurses for the future (AI education and training) and associated, ethical considerations and challenges. AI\u2010enabled robotics and telehealth solutions expand the reach of nursing care, improving accessibility of healthcare services and remote monitoring capabilities of patients' health conditions.",
    "doi": "10.1002/nop2.2070",
    "url": "https://openalex.org/W4390056019",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/nop2.2070",
    "venue": "Nursing Open",
    "citation_count": 145,
    "fields_of_study": [
      "Transformative learning",
      "Preparedness",
      "Nursing",
      "Thematic analysis",
      "Nursing practice"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548863"
  },
  {
    "source": "openalex",
    "source_id": "W4281728823",
    "title": "MACHINE LEARNING FOR INTELLIGENT ENERGY CONSUMPTION IN SMART HOMES",
    "authors": [
      "Asem S. Al\u2010Zoubi"
    ],
    "year": 2022,
    "abstract": "The growth of personal pleasure is a direct result of a person's ability to provide themselves with energy. Since people may construct and enhance their way of life more swiftly with current innovation, valuable energy has become a sought-after expansion for many years due to the utilization of smart houses and structures. The demand for energy is greater than the supply, resulting in a lack of energy. In order to keep up with the demand for energy, new strategies are being developed. Many areas' residential energy use is between 30 and 40 percent. There has been an increase in the need for intelligence in applications like as asset management, energy-efficient automating, safety, and healthcare monitoring as a result of smart homes coming into existence and expanding. Energy consumption optimization is being tackled with the use of an energy management approach in this study. There has been a recent surge in interest in data fusion in the context of building energy efficiency. Accuracy and miss rate of energy consumption predictions were calculated utilizing the data fusion technique presented by the proposed study. Simulated findings are being compared with those of previously reported methods. It also has a prediction accuracy of 92 percent, which is greater than that of any other technique that has been previously reported. It's becoming increasingly important for households to keep their power costs down as the amount of electricity they consume rises and dispersed new energy sources are introduced. The installation of a home energy management system is a practical solution to these issues.",
    "doi": "10.54489/ijcim.v2i1.75",
    "url": "https://openalex.org/W4281728823",
    "pdf_url": "https://journals.gaftim.com/index.php/ijcim/article/download/75/36",
    "venue": "International Journal of Computations Information and Manufacturing (IJCIM)",
    "citation_count": 171,
    "fields_of_study": [
      "Energy consumption",
      "Context (archaeology)",
      "Energy management",
      "Energy (signal processing)",
      "Efficient energy use"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548878"
  },
  {
    "source": "openalex",
    "source_id": "W4310118256",
    "title": "Artificial Intelligence and Sustainable Decisions",
    "authors": [
      "Jingchen Zhao",
      "Beatriz G\u00f3mez Fari\u00f1as"
    ],
    "year": 2022,
    "abstract": "Abstract When addressing corporate sustainability challenges, artificial intelligence (AI) is a double-edged sword. AI can make significant progress on the most complicated environmental and social problems faced by humans. On the other hand, the efficiencies and innovations generated by AI may also bring new risks, such as automated bias and conflicts with human ethics. We argue that companies and governments should make collective efforts to address sustainability challenges and risks brought by AI. Accountable and sustainable AI can be achieved through a proactive regulatory framework supported by rigorous corporate policies and reports. Given the rapidly evolving nature of this technology, we propose a harmonised and risk-based regulatory approach that accommodates diverse AI solutions to achieve the common good. Ensuring an adequate level of technological neutrality and proportionality of the regulation is the key to mitigating the wide range of potential risks inherent to the use of AI. Instead of promoting sustainability, unregulated AI would be a threat since it would not be possible to effectively monitor its effects on the economy, society and environment. Such a suitable regulatory framework would not only create a consensus concerning the risks to avoid and how to do so but also include enforcement mechanisms to ensure a trustworthy and ethical use of AI in the boardroom. Once this objective is achieved, it will be possible to refer to this technological development as a common good in itself that constitutes an essential asset to human development.",
    "doi": "10.1007/s40804-022-00262-2",
    "url": "https://openalex.org/W4310118256",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s40804-022-00262-2.pdf",
    "venue": "European Business Organization Law Review",
    "citation_count": 148,
    "fields_of_study": [
      "Sustainability",
      "Risk analysis (engineering)",
      "Precautionary principle",
      "Business",
      "Sustainable development"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548904"
  },
  {
    "source": "openalex",
    "source_id": "W4309702579",
    "title": "Priorities for successful use of artificial intelligence by public health organizations: a literature review",
    "authors": [
      "Stacey Fisher",
      "Laura C. Rosella"
    ],
    "year": 2022,
    "abstract": "Abstract Artificial intelligence (AI) has the potential to improve public health\u2019s ability to promote the health of all people in all communities. To successfully realize this potential and use AI for public health functions it is important for public health organizations to thoughtfully develop strategies for AI implementation. Six key priorities for successful use of AI technologies by public health organizations are discussed: 1) Contemporary data governance; 2) Investment in modernized data and analytic infrastructure and procedures; 3) Addressing the skills gap in the workforce; 4) Development of strategic collaborative partnerships; 5) Use of good AI practices for transparency and reproducibility, and; 6) Explicit consideration of equity and bias.",
    "doi": "10.1186/s12889-022-14422-z",
    "url": "https://openalex.org/W4309702579",
    "pdf_url": "https://bmcpublichealth.biomedcentral.com/counter/pdf/10.1186/s12889-022-14422-z",
    "venue": "BMC Public Health",
    "citation_count": 130,
    "fields_of_study": [
      "Biostatistics",
      "Medicine",
      "Public health",
      "Epidemiology",
      "Environmental health"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548926"
  },
  {
    "source": "openalex",
    "source_id": "W3182537641",
    "title": "Balancing skills in the digital transformation era: The future of jobs and the role of higher education",
    "authors": [
      "Vera G. Goulart",
      "Lara Bartocci Liboni",
      "Luciana Oranges Cezarino"
    ],
    "year": 2021,
    "abstract": "Developing human resources and matching job profiles are essential tasks to promote economic and social growth. The technology-related job market has undergone significant changes over recent years, mainly due to technological advances that have pushed industry toward new demands for skilled professionals. This change in required skills and competencies has led to a gap between what companies need and the professional profiles that are available in the job market. Technology companies are often unable to find an employee who meets the required profile, resulting in financial loss and extra training expenses. It is therefore essential that higher education in technology is reconsidered to address job market demands. Thus the goal of this work is to evaluate the relationship between the professional profile required by information technology (IT) companies and what students are taught on IT-related programs in higher education institutions (HEIs). The authors adopt a systemic perspective in three different qualitative approaches. They cross-check and link data on educational curricula acquired from interviews with IT human resource managers (HRMs) and student focus groups. The analysis reveals that HEIs must go beyond the transfer of knowledge and technical qualification in IT, promoting a comprehensive education that incorporates personal development goals, with a focus on developing social and emotional skills. The study focuses on the emerging economy of Brazil and presents findings from which other developing countries can learn. The results reveal the critical role of soft skills in the professional development and employability of students and the associated challenge for technical education. In conclusion, the authors also highlight the importance of partnerships between HEIs and HRMs as a fundamental strategy to fulfill the current skills gap.",
    "doi": "10.1177/09504222211029796",
    "url": "https://openalex.org/W3182537641",
    "pdf_url": "http://hdl.handle.net/10278/3742108",
    "venue": "Industry and Higher Education",
    "citation_count": 199,
    "fields_of_study": [
      "Employability",
      "Curriculum",
      "Higher education",
      "Human resources",
      "Business"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548939"
  },
  {
    "source": "openalex",
    "source_id": "W4384920712",
    "title": "Explainable AI for Bioinformatics: Methods, Tools and Applications",
    "authors": [
      "Md. Rezaul Karim",
      "Tanhim Islam",
      "Md Shajalal",
      "Oya Beyan",
      "Christoph Lange",
      "Michael Cochez",
      "Dietrich Rebholz\u2010Schuhmann",
      "Stefan Decker"
    ],
    "year": 2023,
    "abstract": "Abstract Artificial intelligence (AI) systems utilizing deep neural networks and machine learning (ML) algorithms are widely used for solving critical problems in bioinformatics, biomedical informatics and precision medicine. However, complex ML models that are often perceived as opaque and black-box methods make it difficult to understand the reasoning behind their decisions. This lack of transparency can be a challenge for both end-users and decision-makers, as well as AI developers. In sensitive areas such as healthcare, explainability and accountability are not only desirable properties but also legally required for AI systems that can have a significant impact on human lives. Fairness is another growing concern, as algorithmic decisions should not show bias or discrimination towards certain groups or individuals based on sensitive attributes. Explainable AI (XAI) aims to overcome the opaqueness of black-box models and to provide transparency in how AI systems make decisions. Interpretable ML models can explain how they make predictions and identify factors that influence their outcomes. However, the majority of the state-of-the-art interpretable ML methods are domain-agnostic and have evolved from fields such as computer vision, automated reasoning or statistics, making direct application to bioinformatics problems challenging without customization and domain adaptation. In this paper, we discuss the importance of explainability and algorithmic transparency in the context of bioinformatics. We provide an overview of model-specific and model-agnostic interpretable ML methods and tools and outline their potential limitations. We discuss how existing interpretable ML methods can be customized and fit to bioinformatics research problems. Further, through case studies in bioimaging, cancer genomics and text mining, we demonstrate how XAI methods can improve transparency and decision fairness. Our review aims at providing valuable insights and serving as a starting point for researchers wanting to enhance explainability and decision transparency while solving bioinformatics problems. GitHub: https://github.com/rezacsedu/XAI-for-bioinformatics.",
    "doi": "10.1093/bib/bbad236",
    "url": "https://openalex.org/W4384920712",
    "pdf_url": "https://academic.oup.com/bib/advance-article-pdf/doi/10.1093/bib/bbad236/50926106/bbad236.pdf",
    "venue": "Briefings in Bioinformatics",
    "citation_count": 134,
    "fields_of_study": [
      "Transparency (behavior)",
      "Computer science",
      "Artificial intelligence",
      "Context (archaeology)",
      "Domain (mathematical analysis)"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548966"
  },
  {
    "source": "openalex",
    "source_id": "W2903165924",
    "title": "Journalism, media and technology trends and predictions 2018",
    "authors": [
      "Nic Newman",
      "Cherubini, Federica"
    ],
    "year": 2023,
    "abstract": "2019 will be the year when the regulation of platform companies starts to become real following growing concern about misinformation, privacy, and market power. Something once considered unthinkable has become \u2018inevitable\u2019, in the words of Apple boss Tim Cook \u2013 though the details will be messy, hard-fought, and take time to play out. Meanwhile the spread of false, misleading and extreme content will continue to undermine democracies around the world with polarising elections in India, Indonesia and Europe likely flashpoints. Journalism will continue to be hollowed out by structural shifts that have already led to significant falls in advertising revenue. Publishers are looking to subscriptions to make up the difference but the limits of this approach are likely to become apparent in 2019. Taken together these trends are likely to lead to the biggest wave of journalistic lay-offs in years \u2013 weakening further the ability of publishers to hold populist politicians and powerful business leaders to account. This annual trends and predictions report explores key developments in the practice and business of journalism. It explores publishers\u2019 relationships with platforms, the boom in podcasting and voice activated technologies and the potential for Artificial Intelligence in the newsroom.",
    "doi": "10.5287/bodleian:nokoozeep",
    "url": "https://openalex.org/W2903165924",
    "pdf_url": "https://ora.ox.ac.uk/objects/uuid:0cc75001-5e8f-4143-bff7-cbb761a58ad6",
    "venue": "Oxford University Research Archive (ORA) (University of Oxford)",
    "citation_count": 274,
    "fields_of_study": [
      "Journalism",
      "Quality (philosophy)",
      "Computer science",
      "Public relations",
      "Multimedia"
    ],
    "retrieved_at": "2026-02-02T16:58:12.548994"
  },
  {
    "source": "openalex",
    "source_id": "W3198532692",
    "title": "Digital Mental Health for Young People: A Scoping Review of Ethical Promises and Challenges",
    "authors": [
      "Blanche Wies",
      "Constantin Landers",
      "Marcello Ienca"
    ],
    "year": 2021,
    "abstract": "Mental health disorders are complex disorders of the nervous system characterized by a behavioral or mental pattern that causes significant distress or impairment of personal functioning. Mental illness is of particular concern for younger people. The WHO estimates that around 20% of the world's children and adolescents have a mental health condition, a rate that is almost double compared to the general population. One approach toward mitigating the medical and socio-economic effects of mental health disorders is leveraging the power of digital health technology to deploy assistive, preventative, and therapeutic solutions for people in need. We define \u201cdigital mental health\u201d as any application of digital health technology for mental health assessment, support, prevention, and treatment. However, there is only limited evidence that digital mental health tools can be successfully implemented in clinical settings. Authors have pointed to a lack of technical and medical standards for digital mental health apps, personalized neurotechnology, and assistive cognitive technology as a possible cause of suboptimal adoption and implementation in the clinical setting. Further, ethical concerns have been raised related to insufficient effectiveness, lack of adequate clinical validation, and user-centered design as well as data privacy vulnerabilities of current digital mental health products. The aim of this paper is to report on a scoping review we conducted to capture and synthesize the growing literature on the promises and ethical challenges of digital mental health for young people aged 0\u201325. This review seeks to survey the scope and focus of the relevant literature, identify major benefits and opportunities of ethical significance (e.g., reducing suffering and improving well-being), and provide a comprehensive mapping of the emerging ethical challenges. Our findings provide a comprehensive synthesis of the current literature and offer a detailed informative basis for any stakeholder involved in the development, deployment, and management of ethically-aligned digital mental health solutions for young people.",
    "doi": "10.3389/fdgth.2021.697072",
    "url": "https://openalex.org/W3198532692",
    "pdf_url": "https://www.frontiersin.org/articles/10.3389/fdgth.2021.697072/pdf",
    "venue": "Frontiers in Digital Health",
    "citation_count": 216,
    "fields_of_study": [
      "Mental health",
      "Digital health",
      "Scope (computer science)",
      "Psychology",
      "Mental illness"
    ],
    "retrieved_at": "2026-02-02T16:58:12.549015"
  },
  {
    "source": "openalex",
    "source_id": "W4400118952",
    "title": "When large language models meet personalization: perspectives of challenges and opportunities",
    "authors": [
      "Jing Chen",
      "Zheng Liu",
      "Xu Huang",
      "Chenwang Wu",
      "Qi Liu",
      "Gangwei Jiang",
      "Yuanhao Pu",
      "Yuxuan Lei",
      "Xiaolong Chen",
      "Xingmei Wang",
      "Kai Zheng",
      "Defu Lian",
      "Enhong Chen"
    ],
    "year": 2024,
    "abstract": "Abstract The advent of large language models marks a revolutionary breakthrough in artificial intelligence. With the unprecedented scale of training and model parameters, the capability of large language models has been dramatically improved, leading to human-like performances in understanding, language synthesizing, common-sense reasoning, etc. Such a major leap forward in general AI capacity will fundamentally change the pattern of how personalization is conducted. For one thing, it will reform the way of interaction between humans and personalization systems. Instead of being a passive medium of information filtering, like conventional recommender systems and search engines, large language models present the foundation for active user engagement. On top of such a new foundation, users\u2019 requests can be proactively explored, and users\u2019 required information can be delivered in a natural, interactable, and explainable way. For another thing, it will also considerably expand the scope of personalization, making it grow from the sole function of collecting personalized information to the compound function of providing personalized services. By leveraging large language models as a general-purpose interface, the personalization systems may compile user\u2019s requests into plans, calls the functions of external tools (e.g., search engines, calculators, service APIs, etc.) to execute the plans, and integrate the tools\u2019 outputs to complete the end-to-end personalization tasks. Today, large language models are still being rapidly developed, whereas the application in personalization is largely unexplored. Therefore, we consider it to be right the time to review the challenges in personalization and the opportunities to address them with large language models. In particular, we dedicate this perspective paper to the discussion of the following aspects: the development and challenges for the existing personalization system, the newly emerged capabilities of large language models, and the potential ways of making use of large language models for personalization.",
    "doi": "10.1007/s11280-024-01276-1",
    "url": "https://openalex.org/W4400118952",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s11280-024-01276-1.pdf",
    "venue": "World Wide Web",
    "citation_count": 226,
    "fields_of_study": [
      "Personalization",
      "Computer science",
      "Function (biology)",
      "Scope (computer science)",
      "Language model"
    ],
    "retrieved_at": "2026-02-02T16:58:12.549046"
  },
  {
    "source": "openalex",
    "source_id": "W4392052182",
    "title": "AI-Powered Innovation in Digital Transformation: Key Pillars and Industry Impact",
    "authors": [
      "Abdulaziz Aldoseri",
      "Khalifa N. Al\u2010Khalifa",
      "A.M.S. Hamouda"
    ],
    "year": 2024,
    "abstract": "Digital transformation systems generate a substantial volume of data, creating opportunities for potential innovation, particularly those driven by artificial intelligence. This study focuses on the intricate relationship between artificial intelligence and innovation as foundational elements in the digital transformation framework for sustained growth and operational excellence. This study provides a holistic perspective on the cultivation and pillars of AI-powered innovation, highlighting their pivotal role in revolutionizing industries, including healthcare, education, finance, manufacturing, transportation, and agriculture. The work emphasizes the key pillars essential for fostering AI-powered innovation, including monitoring performance measurement to use the power of the present, continuous learning and innovation, data analytics and insights, predictive analytics, and innovative product development. This study investigates how these pillars serve as the foundation for groundbreaking advancements, driving efficiency, enhancing decision-making processes, and fostering creativity within organizations. This study explores the significance of continuous learning, interdisciplinary collaboration, and industry partnerships in nurturing a thriving AI-powered innovation ecosystem. By understanding and harnessing these fundamental elements, businesses can navigate the complexities of the digital age, fostering innovation that not only optimizes processes but also enhances the overall human experience, ushering in a new era of technological excellence and societal progress.",
    "doi": "10.3390/su16051790",
    "url": "https://openalex.org/W4392052182",
    "pdf_url": "https://www.mdpi.com/2071-1050/16/5/1790/pdf?version=1708581624",
    "venue": "Sustainability",
    "citation_count": 168,
    "fields_of_study": [
      "Key (lock)",
      "Digital transformation",
      "Transformation (genetics)",
      "Manufacturing engineering",
      "Business"
    ],
    "retrieved_at": "2026-02-02T16:58:12.549073"
  },
  {
    "source": "openalex",
    "source_id": "W4285740054",
    "title": "You Can\u2019t Have AI Both Ways: Balancing Health Data Privacy and Access Fairly",
    "authors": [
      "Marieke Bak",
      "Vince I. Madai",
      "Marie-Christine Fritzsche",
      "Michaela Th. Mayrhofer",
      "Stuart McLennan"
    ],
    "year": 2022,
    "abstract": "Artificial intelligence (AI) in healthcare promises to make healthcare safer, more accurate, and more cost-effective. Public and private actors have been investing significant amounts of resources into the field. However, to benefit from data-intensive medicine, particularly from AI technologies, one must first and foremost have access to data. It has been previously argued that the conventionally used \u201cconsent or anonymize approach\u201d undermines data-intensive medicine, and worse, may ultimately harm patients. Yet, this is still a dominant approach in European countries and framed as an either-or choice. In this paper, we contrast the different data governance approaches in the EU and their advantages and disadvantages in the context of healthcare AI. We detail the ethical trade-offs inherent to data-intensive medicine, particularly the balancing of data privacy and data access, and the subsequent prioritization between AI and other effective health interventions. If countries wish to allocate resources to AI, they also need to make corresponding efforts to improve (secure) data access. We conclude that it is unethical to invest significant amounts of public funds into AI development whilst at the same time limiting data access through strict privacy measures, as this constitutes a waste of public resources. The \u201cAI revolution\u201d in healthcare can only realise its full potential if a fair, inclusive engagement process spells out the values underlying (trans) national data governance policies and their impact on AI development, and priorities are set accordingly.",
    "doi": "10.3389/fgene.2022.929453",
    "url": "https://openalex.org/W4285740054",
    "pdf_url": "https://www.frontiersin.org/articles/10.3389/fgene.2022.929453/pdf",
    "venue": "Frontiers in Genetics",
    "citation_count": 103,
    "fields_of_study": [
      "Context (archaeology)",
      "Data governance",
      "Harm",
      "Health care",
      "Internet privacy"
    ],
    "retrieved_at": "2026-02-02T16:58:12.549095"
  },
  {
    "source": "openalex",
    "source_id": "W3001754608",
    "title": "Toward situated interventions for algorithmic equity",
    "authors": [
      "Michael Katell",
      "Meg Young",
      "Dharma Dailey",
      "Bernease Herman",
      "Vivian Guetler",
      "Aaron Tam",
      "Corinne Bintz",
      "Daniella Raz",
      "P. M. Krafft"
    ],
    "year": 2020,
    "abstract": "Research to date aimed at the fairness, accountability, and transparency of algorithmic systems has largely focused on topics such as identifying failures of current systems and on technical interventions intended to reduce bias in computational processes. Researchers have given less attention to methods that account for the social and political contexts of specific, situated technical systems at their points of use. Co-developing algorithmic accountability interventions in communities supports outcomes that are more likely to address problems in their situated context and re-center power with those most disparately affected by the harms of algorithmic systems. In this paper we report on our experiences using participatory and co-design methods for algorithmic accountability in a project called the Algorithmic Equity Toolkit. The main insights we gleaned from our experiences were: (i) many meaningful interventions toward equitable algorithmic systems are non-technical; (ii) community organizations derive the most value from localized materials as opposed to what is \"scalable\" beyond a particular policy context; (iii) framing harms around algorithmic bias suggests that more accurate data is the solution, at the risk of missing deeper questions about whether some technologies should be used at all. More broadly, we found that community-based methods are important inroads to addressing algorithmic harms in their situated contexts.",
    "doi": "10.1145/3351095.3372874",
    "url": "https://openalex.org/W3001754608",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3351095.3372874",
    "venue": null,
    "citation_count": 132,
    "fields_of_study": [
      "Situated",
      "Accountability",
      "Computer science",
      "Equity (law)",
      "Framing (construction)"
    ],
    "retrieved_at": "2026-02-02T16:58:12.549118"
  },
  {
    "source": "openalex",
    "source_id": "W4390315357",
    "title": "The Robots Are Here: Navigating the Generative AI Revolution in Computing Education",
    "authors": [
      "James Prather",
      "Paul Denny",
      "Juho Leinonen",
      "Brett A. Becker",
      "Ibrahim Albluwi",
      "Michelle Craig",
      "Hieke Keuning",
      "Natalie Kiesler",
      "Tobias Kohn",
      "Andrew Luxton-Reilly",
      "Stephen MacNeil",
      "Andrew Petersen",
      "Raymond Pettit",
      "Brent N. Reeves",
      "Jarom\u00edr \u0160avelka"
    ],
    "year": 2023,
    "abstract": "Recent advancements in artificial intelligence (AI) and specifically generative AI (GenAI) are threatening to fundamentally reshape computing and society. Largely driven by large language models (LLMs), many tools are now able to interpret and generate both natural language instructions and source code. These capabilities have sparked urgent questions in the computing education community around how educators should adapt their pedagogy to address the challenges and to leverage the opportunities presented by this new technology. In this working group report, we undertake a comprehensive exploration of generative AI in the context of computing education and make five significant contributions. First, we provide a detailed review of the literature on LLMs in computing education and synthesise findings from 71 primary articles, nearly 80% of which have been published in the first 8 months of 2023. Second, we report the findings of a survey of computing students and instructors from across 20 countries, capturing prevailing attitudes towards GenAI/LLMs and their use in computing education contexts. Third, to understand how pedagogy is already changing, we offer insights collected from in-depth interviews with 22 computing educators from five continents. Fourth, we use the ACM Code of Ethics to frame a discussion of ethical issues raised by the use of large language models in computing education, and we provide concrete advice for policy makers, educators, and students. Finally, we benchmark the performance of several current GenAI models/tools on various computing education datasets, and highlight the extent to which the capabilities of current models are rapidly improving.",
    "doi": "10.1145/3623762.3633499",
    "url": "https://openalex.org/W4390315357",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3623762.3633499",
    "venue": null,
    "citation_count": 260,
    "fields_of_study": [
      "Computer science",
      "Leverage (statistics)",
      "Context (archaeology)",
      "Generative grammar",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:12.549138"
  },
  {
    "source": "openalex",
    "source_id": "W2982867001",
    "title": "A multi-dimensional approach to disinformation: Report of the independent High level Group on fake news and online disinformation",
    "authors": [
      "Madeleine de Cock Buning"
    ],
    "year": 2018,
    "abstract": "In January 2018, the European Commission set up a highlevel group of experts (\u00abthe HLEG\u00bb) to advise on policy initiatives to counter fake news and disinformation spread online. The HLEG consisted of 39 members and was chaired by Prof. Dr. Madeleine de Cock Buning. Its members had different backgrounds, including academia and journalism, written press and broadcasting organizations, online platforms as well as civil society and fact-checking organizations. The HLEG\u2019s tasks were to advise the Commission on all issues arising in the context of false information spread across traditional and social media and on possible ways to cope with its social and political consequences. The main deliverable of the HLEG was a report designed to review best practices in the light of fundamental principles, and suitable responses stemming from such principles. The analysis presented in this Report starts from a shared understanding of disinformation as a phenomenon that goes well beyond the term \u00abfake news\u00bb. This term has been appropriated and used misleadingly by powerful actors to dismiss coverage that is simply found disagreeable. Disinformation as defined in this Report includes all forms of false, inaccurate, or misleading information designed, presented and promoted to intentionally cause public harm or for profit. It does not cover issues arising from the creation and dissemination online of illegal content (notably defamation, hate speech, incitement to violence), which are subject to regulatory remedies under EU or national laws. Nor does it cover other forms of deliberate but not misleading distortions of facts such a satire and parody. Problems of disinformation are deeply intertwined with the development of digital media. They are driven by actors \u2014 state or non-state political actors, for-profit actors, media, citizens, individually or in groups \u2014 and by manipulative uses of communication infrastructures that have been harnessed to produce, circulate and amplify disinformation on a larger scale than previously, often in new ways that are still poorly mapped and understood.",
    "doi": "10.2759/739290",
    "url": "https://openalex.org/W2982867001",
    "pdf_url": "https://hdl.handle.net/1814/70297",
    "venue": "Cadmus - EUI Research Repository (European University Institute)",
    "citation_count": 301,
    "fields_of_study": [
      "Disinformation",
      "Group (periodic table)",
      "Fake news",
      "Political science",
      "Internet privacy"
    ],
    "retrieved_at": "2026-02-02T16:58:12.549160"
  },
  {
    "source": "openalex",
    "source_id": "W3169231731",
    "title": "Federated Learning in a Medical Context: A Systematic Literature Review",
    "authors": [
      "Bjarne Pfitzner",
      "Nico Steckhan",
      "Bert Arnrich"
    ],
    "year": 2021,
    "abstract": "Data privacy is a very important issue. Especially in fields like medicine, it is paramount to abide by the existing privacy regulations to preserve patients\u2019 anonymity. However, data is required for research and training machine learning models that could help gain insight into complex correlations or personalised treatments that may otherwise stay undiscovered. Those models generally scale with the amount of data available, but the current situation often prohibits building large databases across sites. So it would be beneficial to be able to combine similar or related data from different sites all over the world while still preserving data privacy. Federated learning has been proposed as a solution for this, because it relies on the sharing of machine learning models, instead of the raw data itself. That means private data never leaves the site or device it was collected on. Federated learning is an emerging research area, and many domains have been identified for the application of those methods. This systematic literature review provides an extensive look at the concept of and research into federated learning and its applicability for confidential healthcare datasets.",
    "doi": "10.1145/3412357",
    "url": "https://openalex.org/W3169231731",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3412357",
    "venue": "ACM Transactions on Internet Technology",
    "citation_count": 243,
    "fields_of_study": [
      "Computer science",
      "Confidentiality",
      "Federated learning",
      "Context (archaeology)",
      "Data science"
    ],
    "retrieved_at": "2026-02-02T16:58:12.549194"
  },
  {
    "source": "openalex",
    "source_id": "W4389286730",
    "title": "ARTIFICIAL INTELLIGENCE IN DEVELOPING COUNTRIES: BRIDGING THE GAP BETWEEN POTENTIAL AND IMPLEMENTATION",
    "authors": [
      "Adebayo Olusegun Aderibigbe",
      "Peter Efosa Ohenhen",
      "Nwabueze Kelvin Nwaobia",
      "Joachim Osheyor Gidiagba",
      "Emmanuel Chigozie Ani"
    ],
    "year": 2023,
    "abstract": "This paper examines the role of Artificial Intelligence (AI) in developing countries, focusing on bridging the gap between its vast potential and effective implementation. As AI technologies advance globally, their impact on socio-economic development becomes increasingly critical, particularly in regions with diverse challenges and opportunities. The study investigates the current landscape of AI adoption in developing countries, analyzing the potential benefits, challenges, and ethical considerations. Through a comprehensive review of literature and case studies, the paper explores strategies and solutions for harnessing AI's transformative power in diverse sectors such as healthcare, agriculture, and education. The findings emphasize the importance of capacity building, public-private partnerships, and tailored policy frameworks to address infrastructure limitations and skill gaps. The research contributes to a nuanced understanding of the opportunities and complexities surrounding AI implementation in developing countries, providing insights for policymakers, practitioners, and scholars seeking to navigate this evolving technological landscape Keywords: Artificial Intelligence; Global Connectivity; Emerging Technologies; Organizational Resilience; Sustainable Growth; Developing Country.",
    "doi": "10.51594/csitrj.v4i3.629",
    "url": "https://openalex.org/W4389286730",
    "pdf_url": "https://fepbl.com/index.php/csitrj/article/download/629/799",
    "venue": "Computer Science & IT Research Journal",
    "citation_count": 105,
    "fields_of_study": [
      "Transformative learning",
      "Bridging (networking)",
      "Developing country",
      "Resilience (materials science)",
      "Emerging technologies"
    ],
    "retrieved_at": "2026-02-02T16:58:12.549214"
  },
  {
    "source": "openalex",
    "source_id": "W4213424378",
    "title": "Artificial Intelligence-Virtual Trainer: Innovative Didactics Aimed at Personalized Training Needs",
    "authors": [
      "Zhisheng Chen"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1007/s13132-022-00985-0",
    "url": "https://openalex.org/W4213424378",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s13132-022-00985-0.pdf",
    "venue": "Journal of the Knowledge Economy",
    "citation_count": 129,
    "fields_of_study": [
      "Trainer",
      "Training (meteorology)",
      "Process (computing)",
      "Computer science",
      "Knowledge management"
    ],
    "retrieved_at": "2026-02-02T16:58:12.549231"
  },
  {
    "source": "openalex",
    "source_id": "W3159204223",
    "title": "Responsible Artificial Intelligence (AI) for Value Formation and Market Performance in Healthcare: the Mediating Role of Patient\u2019s Cognitive Engagement",
    "authors": [
      "Pradeep Kumar",
      "Yogesh K. Dwivedi",
      "Ambuj Anand"
    ],
    "year": 2021,
    "abstract": null,
    "doi": "10.1007/s10796-021-10136-6",
    "url": "https://openalex.org/W3159204223",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10796-021-10136-6.pdf",
    "venue": "Information Systems Frontiers",
    "citation_count": 138,
    "fields_of_study": [
      "Mediation",
      "Health care",
      "Context (archaeology)",
      "Cognition",
      "Knowledge management"
    ],
    "retrieved_at": "2026-02-02T16:58:12.549234"
  },
  {
    "source": "openalex",
    "source_id": "W3156205870",
    "title": "Z-Inspection<sup>\u00ae</sup>: A Process to Assess Trustworthy AI",
    "authors": [
      "Roberto V. Zicari",
      "John Brodersen",
      "James Brusseau",
      "Boris D\u00fcdder",
      "Timo Eichhorn",
      "Todor Ivanov",
      "Georgios Kararigas",
      "Pedro Kringen",
      "Melissa McCullough",
      "Florian M\u00f6slein",
      "Naveed Mushtaq",
      "Gemma Roig",
      "Norman St\u00fcrtz",
      "Karsten Tolle",
      "Jesmin Jahan Tithi",
      "Irmhild van Halem",
      "Magnus Westerlund"
    ],
    "year": 2021,
    "abstract": "The ethical and societal implications of artificial intelligence systems raise concerns. In this article, we outline a novel process based on applied ethics, namely, Z-Inspection <sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\u00ae</sup> , to assess if an AI system is trustworthy. We use the definition of trustworthy AI given by the high-level European Commission's expert group on AI. Z-Inspection <sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\u00ae</sup> is a general inspection process that can be applied to a variety of domains where AI systems are used, such as business, healthcare, and public sector, among many others. To the best of our knowledge, Z-Inspection <sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\u00ae</sup> is the first process to assess trustworthy AI in practice.",
    "doi": "10.1109/tts.2021.3066209",
    "url": "https://openalex.org/W3156205870",
    "pdf_url": "https://ieeexplore.ieee.org/ielx7/8566059/9459493/09380498.pdf",
    "venue": "IEEE Transactions on Technology and Society",
    "citation_count": 109,
    "fields_of_study": [
      "Trustworthiness",
      "Process (computing)",
      "Artificial intelligence",
      "Computer science",
      "Computer security"
    ],
    "retrieved_at": "2026-02-02T16:58:12.549239"
  },
  {
    "source": "openalex",
    "source_id": "W4387652542",
    "title": "ESMO Guidance for Reporting Oncology real-World evidence (GROW)",
    "authors": [
      "Lu\u00eds Castelo-Branco",
      "Anna Pellat",
      "Diogo Martins-Branco",
      "Antonios Valachis",
      "Jeroen W. G. Derksen",
      "Karijn P.M. Suijkerbuijk",
      "Urania Dafni",
      "Tereza Dellaporta",
      "Arndt Vogel",
      "Arsela Prelaj",
      "Rolf H. H. Groenwold",
      "Henrique Martins",
      "Rolf A. Stahel",
      "Judith M. Bliss",
      "Jakob Nikolas Kather",
      "Nuria Ribelles",
      "Francesco Perrone",
      "Peter Hall",
      "Rodrigo Dienstmann",
      "Christopher M. Booth",
      "George Pentheroudakis",
      "Suzette Delaloge",
      "Miriam Koopman"
    ],
    "year": 2023,
    "abstract": null,
    "doi": "10.1016/j.annonc.2023.10.001",
    "url": "https://openalex.org/W4387652542",
    "pdf_url": "http://www.annalsofoncology.org/article/S0923753423040188/pdf",
    "venue": "Annals of Oncology",
    "citation_count": 173,
    "fields_of_study": [
      "Medicine",
      "Real world evidence",
      "Multidisciplinary approach",
      "Expert opinion",
      "Oncology"
    ],
    "retrieved_at": "2026-02-02T16:58:12.549254"
  },
  {
    "source": "openalex",
    "source_id": "W4207071830",
    "title": "Diffused responsibility: attributions of responsibility in the use of AI-driven clinical decision support systems",
    "authors": [
      "Hannah Bleher",
      "Matthias Braun"
    ],
    "year": 2022,
    "abstract": "Abstract Good decision-making is a complex endeavor, and particularly so in a health context. The possibilities for day-to-day clinical practice opened up by AI-driven clinical decision support systems (AI-CDSS) give rise to fundamental questions around responsibility. In causal, moral and legal terms the application of AI-CDSS is challenging existing attributions of responsibility. In this context, responsibility gaps are often identified as main problem. Mapping out the changing dynamics and levels of attributing responsibility, we argue in this article that the application of AI-CDSS causes diffusions of responsibility with respect to a causal, moral, and legal dimension. Responsibility diffusion describes the situation where multiple options and several agents can be considered for attributing responsibility. Using the example of an AI-driven \u2018digital tumor board\u2019, we illustrate how clinical decision-making is changed and diffusions of responsibility take place. Not denying or attempting to bridge responsibility gaps, we argue that dynamics and ambivalences are inherent in responsibility, which is based on normative considerations such as avoiding experiences of disregard and vulnerability of human life, which are inherently accompanied by a moment of uncertainty, and is characterized by revision openness. Against this background and to avoid responsibility gaps, the article concludes with suggestions for managing responsibility diffusions in clinical decision-making with AI-CDSS.",
    "doi": "10.1007/s43681-022-00135-x",
    "url": "https://openalex.org/W4207071830",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s43681-022-00135-x.pdf",
    "venue": "AI and Ethics",
    "citation_count": 120,
    "fields_of_study": [
      "Moral responsibility",
      "Normative",
      "Context (archaeology)",
      "Attribution",
      "Social responsibility"
    ],
    "retrieved_at": "2026-02-02T16:58:12.549258"
  },
  {
    "source": "openalex",
    "source_id": "W4312516176",
    "title": "Causal Inference in Natural Language Processing: Estimation, Prediction, Interpretation and Beyond",
    "authors": [
      "Amir Feder",
      "Katherine A. Keith",
      "Emaad Manzoor",
      "Reid Pryzant",
      "Dhanya Sridhar",
      "Zach Wood-Doughty",
      "Jacob Eisenstein",
      "Justin Grimmer",
      "Roi Reichart",
      "Margaret E. Roberts",
      "Brandon Stewart",
      "Victor Veitch",
      "Diyi Yang"
    ],
    "year": 2022,
    "abstract": "Abstract A fundamental goal of scientific research is to learn about causal relationships. However, despite its critical role in the life and social sciences, causality has not had the same importance in Natural Language Processing (NLP), which has traditionally placed more emphasis on predictive tasks. This distinction is beginning to fade, with an emerging area of interdisciplinary research at the convergence of causal inference and language processing. Still, research on causality in NLP remains scattered across domains without unified definitions, benchmark datasets and clear articulations of the challenges and opportunities in the application of causal inference to the textual domain, with its unique properties. In this survey, we consolidate research across academic areas and situate it in the broader NLP landscape. We introduce the statistical challenge of estimating causal effects with text, encompassing settings where text is used as an outcome, treatment, or to address confounding. In addition, we explore potential uses of causal inference to improve the robustness, fairness, and interpretability of NLP models. We thus provide a unified overview of causal inference for the NLP community.1",
    "doi": "10.1162/tacl_a_00511",
    "url": "https://openalex.org/W4312516176",
    "pdf_url": "https://direct.mit.edu/tacl/article-pdf/doi/10.1162/tacl_a_00511/2054690/tacl_a_00511.pdf",
    "venue": "Transactions of the Association for Computational Linguistics",
    "citation_count": 177,
    "fields_of_study": [
      "Causal inference",
      "Computer science",
      "Interpretability",
      "Inference",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:12.549279"
  },
  {
    "source": "openalex",
    "source_id": "W2998524378",
    "title": "Real-World Integration of a Sepsis Deep Learning Technology Into Routine Clinical Care: Implementation Study",
    "authors": [
      "Mark Sendak",
      "William Ratliff",
      "Dina Sarro",
      "Elizabeth Alderton",
      "Joseph Futoma",
      "Michael Gao",
      "Marshall Nichols",
      "Mike Revoir",
      "Faraz Yashar",
      "Corinne Miller",
      "Kelly Kester",
      "Sahil Sandhu",
      "Kristin Corey",
      "Nathan Brajer",
      "Christelle Tan",
      "Anthony Lin",
      "Tres Brown",
      "Susan Engelbosch",
      "Kevin J. Anstrom",
      "Madeleine Clare Elish",
      "Katherine Heller",
      "Rebecca Donohoe",
      "Jason Theiling",
      "Eric G. Poon",
      "Suresh Balu",
      "Armando Bedoya",
      "Cara O\u2019Brien"
    ],
    "year": 2019,
    "abstract": "Background Successful integrations of machine learning into routine clinical care are exceedingly rare, and barriers to its adoption are poorly characterized in the literature. Objective This study aims to report a quality improvement effort to integrate a deep learning sepsis detection and management platform, Sepsis Watch, into routine clinical care. Methods In 2016, a multidisciplinary team consisting of statisticians, data scientists, data engineers, and clinicians was assembled by the leadership of an academic health system to radically improve the detection and treatment of sepsis. This report of the quality improvement effort follows the learning health system framework to describe the problem assessment, design, development, implementation, and evaluation plan of Sepsis Watch. Results Sepsis Watch was successfully integrated into routine clinical care and reshaped how local machine learning projects are executed. Frontline clinical staff were highly engaged in the design and development of the workflow, machine learning model, and application. Novel machine learning methods were developed to detect sepsis early, and implementation of the model required robust infrastructure. Significant investment was required to align stakeholders, develop trusting relationships, define roles and responsibilities, and to train frontline staff, leading to the establishment of 3 partnerships with internal and external research groups to evaluate Sepsis Watch. Conclusions Machine learning models are commonly developed to enhance clinical decision making, but successful integrations of machine learning into routine clinical care are rare. Although there is no playbook for integrating deep learning into clinical care, learnings from the Sepsis Watch integration can inform efforts to develop machine learning technologies at other health care delivery systems.",
    "doi": "10.2196/15182",
    "url": "https://openalex.org/W2998524378",
    "pdf_url": "https://medinform.jmir.org/2020/7/e15182/PDF",
    "venue": "JMIR Medical Informatics",
    "citation_count": 192,
    "fields_of_study": [
      "Workflow",
      "Health care",
      "Artificial intelligence",
      "Quality management",
      "Multidisciplinary approach"
    ],
    "retrieved_at": "2026-02-02T16:58:12.549300"
  },
  {
    "source": "openalex",
    "source_id": "W4288083725",
    "title": "One Explanation Does Not Fit All",
    "authors": [
      "Kacper Sokol",
      "Peter Flach"
    ],
    "year": 2020,
    "abstract": null,
    "doi": "10.1007/s13218-020-00637-y",
    "url": "https://openalex.org/W4288083725",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s13218-020-00637-y.pdf",
    "venue": "KI - K\u00fcnstliche Intelligenz",
    "citation_count": 143,
    "fields_of_study": [
      "Transparency (behavior)",
      "Computer science",
      "Interpretability",
      "Counterfactual thinking",
      "Context (archaeology)"
    ],
    "retrieved_at": "2026-02-02T16:58:12.549325"
  },
  {
    "source": "openalex",
    "source_id": "W3133752603",
    "title": "The Ethics of Emotion in Artificial Intelligence Systems",
    "authors": [
      "Luke Stark",
      "Jesse Hoey"
    ],
    "year": 2021,
    "abstract": "In this paper, we develop a taxonomy of conceptual models and proxy data used for digital analysis of human emotional expression and outline how the combinations and permutations of these models and data impact their incorporation into artificial intelligence (AI) systems. We argue we should not take computer scientists at their word that the paradigms for human emotions they have developed internally and adapted from other disciplines can produce ground truth about human emotions; instead, we ask how different conceptualizations of what emotions are, and how they can be sensed, measured and transformed into data, shape the ethical and social implications of these AI systems.",
    "doi": "10.1145/3442188.3445939",
    "url": "https://openalex.org/W3133752603",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3442188.3445939",
    "venue": null,
    "citation_count": 142,
    "fields_of_study": [
      "Computer science",
      "Human intelligence",
      "Taxonomy (biology)",
      "Artificial intelligence",
      "Data science"
    ],
    "retrieved_at": "2026-02-02T16:58:12.549328"
  },
  {
    "source": "openalex",
    "source_id": "W4386913199",
    "title": "Generative AI and ChatGPT in School Children\u2019s Education: Evidence from a School Lesson",
    "authors": [
      "Jussi S. Jauhiainen",
      "Agust\u00edn Garagorry Guerra"
    ],
    "year": 2023,
    "abstract": "In 2023, the global use of generative AI, particularly ChatGPT-3.5 and -4, witnessed a significant surge, sparking discussions on its sustainable implementation across various domains, including education from primary schools to universities. However, practical testing and evaluation in school education are still relatively unexplored. This article examines the utilization of generative AI in primary school education. The study involved 110 pupils, aged 8\u201314 years old, studying in the 4th\u20136th grades across four classes in two schools. Using laptops, pupils participated in test lessons where content, text, figures, and exercises were generated and modified using generative AI, specifically ChatGPT-3.5. The results demonstrated that it was possible to use ChatGPT-3.5, as one example of generative AI, to personify learning material so that it would meet the knowledge and learning skills of pupils with different levels of knowledge. A clear majority of pupils enjoyed learning the generative AI-modified material. There is a promising potential of generative AI use in school education, supporting pupils\u2019 motivated learning and skills development. However, these tools need to be developed, refined and optimized to ensure proper adaptation and to create impactful, inclusive, and sustainable learning in schools to benefit pupils, teachers and education managers alike.",
    "doi": "10.3390/su151814025",
    "url": "https://openalex.org/W4386913199",
    "pdf_url": "https://www.mdpi.com/2071-1050/15/18/14025/pdf?version=1695347129",
    "venue": "Sustainability",
    "citation_count": 171,
    "fields_of_study": [
      "Generative grammar",
      "Mathematics education",
      "Test (biology)",
      "Generative model",
      "Adaptation (eye)"
    ],
    "retrieved_at": "2026-02-02T16:58:12.549340"
  },
  {
    "source": "openalex",
    "source_id": "W2972141736",
    "title": "Artificial Intelligence and Music: Open Questions of Copyright Law and Engineering Praxis",
    "authors": [
      "Bob L. Sturm",
      "Mar\u00eda Teresa Iglesias",
      "Oded Ben\u2010Tal",
      "Marius Miron",
      "Em\u00edlia G\u00f3mez"
    ],
    "year": 2019,
    "abstract": "The application of artificial intelligence (AI) to music stretches back many decades, and presents numerous unique opportunities for a variety of uses, such as the recommendation of recorded music from massive commercial archives, or the (semi-)automated creation of music. Due to unparalleled access to music data and effective learning algorithms running on high-powered computational hardware, AI is now producing surprising outcomes in a domain fully entrenched in human creativity\u2014not to mention a revenue source around the globe. These developments call for a close inspection of what is occurring, and consideration of how it is changing and can change our relationship with music for better and for worse. This article looks at AI applied to music from two perspectives: copyright law and engineering praxis. It grounds its discussion in the development and use of a specific application of AI in music creation, which raises further and unanticipated questions. Most of the questions collected in this article are open as their answers are not yet clear at this time, but they are nonetheless important to consider as AI technologies develop and are applied more widely to music, not to mention other domains centred on human creativity.",
    "doi": "10.3390/arts8030115",
    "url": "https://openalex.org/W2972141736",
    "pdf_url": "https://www.mdpi.com/2076-0752/8/3/115/pdf?version=1567732463",
    "venue": "Arts",
    "citation_count": 115,
    "fields_of_study": [
      "Creativity",
      "Praxis",
      "Globe",
      "Computer science",
      "Music and artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:12.549360"
  },
  {
    "source": "openalex",
    "source_id": "W3157651069",
    "title": "A Proposed Framework on Integrating Health Equity and Racial Justice into the Artificial Intelligence Development Lifecycle",
    "authors": [
      "Irene Dankwa\u2010Mullan",
      "Elisabeth Scheufele",
      "Michael E. Matheny",
      "Yuri Quintana",
      "Wendy W. Chapman",
      "Gretchen Purcell Jackson",
      "Brett R. South"
    ],
    "year": 2021,
    "abstract": "The COVID-19 pandemic has created multiple opportunities to deploy artificial intelligence (AI)-driven tools and applied interventions to understand, mitigate, and manage the pandemic and its consequences. The disproportionate impact of COVID-19 on racial/ethnic minority and socially disadvantaged populations underscores the need to anticipate and address social inequalities and health disparities in AI development and application. Before the pandemic, there was growing optimism about AI's role in addressing inequities and enhancing personalized care. Unfortunately, ethical and social issues that are encountered in scaling, developing, and applying advanced technologies in health care settings have intensified during the rapidly evolving public health crisis. Critical voices concerned with the disruptive potentials and risk for engineered inequities have called for reexamining ethical guidelines in the development and application of AI. This paper proposes a framework to incorporate ethical AI principles into the development process in ways that intentionally promote racial health equity and social justice. Without centering on equity, justice, and ethical AI, these tools may exacerbate structural inequities that can lead to disparate health outcomes.",
    "doi": "10.1353/hpu.2021.0065",
    "url": "https://openalex.org/W3157651069",
    "pdf_url": "https://muse.jhu.edu/pub/1/article/789672",
    "venue": "Journal of Health Care for the Poor and Underserved",
    "citation_count": 98,
    "fields_of_study": [
      "Health equity",
      "Disadvantaged",
      "Equity (law)",
      "Optimism",
      "Health care"
    ],
    "retrieved_at": "2026-02-02T16:58:12.549381"
  },
  {
    "source": "openalex",
    "source_id": "W3158393586",
    "title": "Ensuring that biomedical AI benefits diverse populations",
    "authors": [
      "James Zou",
      "Londa Schiebinger"
    ],
    "year": 2021,
    "abstract": null,
    "doi": "10.1016/j.ebiom.2021.103358",
    "url": "https://openalex.org/W3158393586",
    "pdf_url": "http://www.thelancet.com/article/S2352396421001511/pdf",
    "venue": "EBioMedicine",
    "citation_count": 109,
    "fields_of_study": [
      "Computational biology",
      "MEDLINE",
      "Data science",
      "Biology",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:12.549398"
  },
  {
    "source": "openalex",
    "source_id": "W3136853555",
    "title": "Implicit bias in healthcare: clinical practice, research and decision making",
    "authors": [
      "Dipesh P Gopal",
      "Ula Chetty",
      "Patrick O\u2019Donnell",
      "Camille Gajria",
      "Jodie Blackadder-Weinstein"
    ],
    "year": 2021,
    "abstract": null,
    "doi": "10.7861/fhj.2020-0233",
    "url": "https://openalex.org/W3136853555",
    "pdf_url": "https://www.rcpjournals.org/content/futurehosp/8/1/40.full.pdf",
    "venue": "Future Healthcare Journal",
    "citation_count": 251,
    "fields_of_study": [
      "Debiasing",
      "Prejudice (legal term)",
      "Cognitive bias",
      "Implicit bias",
      "Psychology"
    ],
    "retrieved_at": "2026-02-02T16:58:12.549402"
  },
  {
    "source": "openalex",
    "source_id": "W2609499779",
    "title": "What is open peer review? A systematic review",
    "authors": [
      "Tony Ross\u2010Hellauer"
    ],
    "year": 2017,
    "abstract": "<ns4:p><ns4:bold>Background</ns4:bold>: \u201cOpen peer review\u201d (OPR), despite being a major pillar of Open Science, has neither a standardized definition nor an agreed schema of its features and implementations. The literature reflects this, with numerous overlapping and contradictory definitions. While for some the term refers to peer review where the identities of both author and reviewer are disclosed to each other, for others it signifies systems where reviewer reports are published alongside articles. For others it signifies both of these conditions, and for yet others it describes systems where not only \u201cinvited experts\u201d are able to comment. For still others, it includes a variety of combinations of these and other novel methods.</ns4:p><ns4:p><ns4:bold>Methods</ns4:bold>: Recognising the absence of a consensus view on what open peer review is, this article undertakes a systematic review of definitions of \u201copen peer review\u201d or \u201copen review\u201d, to create a corpus of 122 definitions. These definitions are systematically analysed to build a coherent typology of the various innovations in peer review signified by the term, and hence provide the precise technical definition currently lacking.</ns4:p><ns4:p><ns4:bold>Results</ns4:bold>: This quantifiable data yields rich information on the range and extent of differing definitions over time and by broad subject area. Quantifying definitions in this way allows us to accurately portray exactly how ambiguously the phrase \u201copen peer review\u201d has been used thus far, for the literature offers 22 distinct configurations of seven traits, effectively meaning that there are 22 different definitions of OPR in the literature reviewed.</ns4:p><ns4:p><ns4:bold>Conclusions</ns4:bold>: I propose a pragmatic definition of open peer review as an umbrella term for a number of overlapping ways that peer review models can be adapted in line with the aims of Open Science, including making reviewer and author identities open, publishing review reports and enabling greater participation in the peer review process.</ns4:p>",
    "doi": "10.12688/f1000research.11369.2",
    "url": "https://openalex.org/W2609499779",
    "pdf_url": "https://f1000research.com/articles/6-588/v2/pdf",
    "venue": "F1000Research",
    "citation_count": 408,
    "fields_of_study": [
      "Open peer review",
      "Plant biology",
      "Open science",
      "Open data",
      "Peer review"
    ],
    "retrieved_at": "2026-02-02T16:58:13.386545"
  },
  {
    "source": "openalex",
    "source_id": "W4229079094",
    "title": "Rethinking Fairness: An Interdisciplinary Survey of Critiques of Hegemonic ML Fairness Approaches",
    "authors": [
      "Lindsay Weinberg"
    ],
    "year": 2022,
    "abstract": "This survey article assesses and compares existing critiques of current fairness-enhancing technical interventions in machine learning (ML) that draw from a range of non-computing disciplines, including philosophy, feminist studies, critical race and ethnic studies, legal studies, anthropology, and science and technology studies. It bridges epistemic divides in order to offer an interdisciplinary understanding of the possibilities and limits of hegemonic computational approaches to ML fairness for producing just outcomes for society\u2019s most marginalized. The article is organized according to nine major themes of critique wherein these different fields intersect: 1) how \"fairness\" in AI fairness research gets defined; 2) how problems for AI systems to address get formulated; 3) the impacts of abstraction on how AI tools function and its propensity to lead to technological solutionism; 4) how racial classification operates within AI fairness research; 5) the use of AI fairness measures to avoid regulation and engage in ethics washing; 6) an absence of participatory design and democratic deliberation in AI fairness considerations; 7) data collection practices that entrench \u201cbias,\u201d are non-consensual, and lack transparency; 8) the predatory inclusion of marginalized groups into AI systems; and 9) a lack of engagement with AI\u2019s long-term social and ethical outcomes. Drawing from these critiques, the article concludes by imagining future ML fairness research directions that actively disrupt entrenched power dynamics and structural injustices in society.",
    "doi": "10.1613/jair.1.13196",
    "url": "https://openalex.org/W4229079094",
    "pdf_url": "https://jair.org/index.php/jair/article/download/13196/26797",
    "venue": "Journal of Artificial Intelligence Research",
    "citation_count": 113,
    "fields_of_study": [
      "Sociology",
      "Deliberation",
      "Transparency (behavior)",
      "Hegemony",
      "Inclusion (mineral)"
    ],
    "retrieved_at": "2026-02-02T16:58:13.386601"
  },
  {
    "source": "openalex",
    "source_id": "W4378009112",
    "title": "AI-Augmented HRM: Literature review and a proposed multilevel framework for future research",
    "authors": [
      "Verma Prikshat",
      "Mohammad Islam",
      "Parth Patel",
      "Ashish Malik",
      "Pawan Budhwar",
      "Suraksha Gupta"
    ],
    "year": 2023,
    "abstract": null,
    "doi": "10.1016/j.techfore.2023.122645",
    "url": "https://openalex.org/W4378009112",
    "pdf_url": "https://www.sciencedirect.com/science/article/pii/S004016252300330X",
    "venue": "Technological Forecasting and Social Change",
    "citation_count": 113,
    "fields_of_study": [
      "Systematic review",
      "Context (archaeology)",
      "Hospitality",
      "Knowledge management",
      "Human resource management"
    ],
    "retrieved_at": "2026-02-02T16:58:13.386631"
  },
  {
    "source": "openalex",
    "source_id": "W3202196203",
    "title": "The European Commission\u2019s Proposal for an Artificial Intelligence Act\u2014A Critical Assessment by Members of the Robotics and AI Law Society (RAILS)",
    "authors": [
      "Martin Ebers",
      "Veronica R. S. Hoch",
      "Frank Rosenkranz",
      "Hannah Ruschemeier",
      "Bj\u00f6rn Steinr\u00f6tter"
    ],
    "year": 2021,
    "abstract": "On 21 April 2021, the European Commission presented its long-awaited proposal for a Regulation \u201claying down harmonized rules on Artificial Intelligence\u201d, the so-called \u201cArtificial Intelligence Act\u201d (AIA). This article takes a critical look at the proposed regulation. After an introduction (1), the paper analyzes the unclear preemptive effect of the AIA and EU competences (2), the scope of application (3), the prohibited uses of Artificial Intelligence (AI) (4), the provisions on high-risk AI systems (5), the obligations of providers and users (6), the requirements for AI systems with limited risks (7), the enforcement system (8), the relationship of the AIA with the existing legal framework (9), and the regulatory gaps (10). The last section draws some final conclusions (11).",
    "doi": "10.3390/j4040043",
    "url": "https://openalex.org/W3202196203",
    "pdf_url": "https://www.mdpi.com/2571-8800/4/4/43/pdf?version=1633664227",
    "venue": "J \u2014 Multidisciplinary Scientific Journal",
    "citation_count": 128,
    "fields_of_study": [
      "Scope (computer science)",
      "Commission",
      "European commission",
      "Artificial intelligence",
      "Enforcement"
    ],
    "retrieved_at": "2026-02-02T16:58:13.386636"
  },
  {
    "source": "openalex",
    "source_id": "W3109670077",
    "title": "The impact of using algorithms for managerial decisions on public employees' procedural justice",
    "authors": [
      "Rosanna Nagtegaal"
    ],
    "year": 2020,
    "abstract": null,
    "doi": "10.1016/j.giq.2020.101536",
    "url": "https://openalex.org/W3109670077",
    "pdf_url": "https://www.sciencedirect.com/science/article/pii/S0740624X20303154",
    "venue": "Government Information Quarterly",
    "citation_count": 128,
    "fields_of_study": [
      "Panacea (medicine)",
      "Procedural justice",
      "Perception",
      "Transparency (behavior)",
      "Economic Justice"
    ],
    "retrieved_at": "2026-02-02T16:58:13.386650"
  },
  {
    "source": "openalex",
    "source_id": "W4392691776",
    "title": "Assessing the research landscape and clinical utility of large language models: a scoping review",
    "authors": [
      "Ye\u2010Jean Park",
      "Abhinav Pillai",
      "Jiawen Deng",
      "Eddie Guo",
      "Mehul Gupta",
      "Mike Paget",
      "Christopher Naugler"
    ],
    "year": 2024,
    "abstract": "Abstract Importance Large language models (LLMs) like OpenAI\u2019s ChatGPT are powerful generative systems that rapidly synthesize natural language responses. Research on LLMs has revealed their potential and pitfalls, especially in clinical settings. However, the evolving landscape of LLM research in medicine has left several gaps regarding their evaluation, application, and evidence base. Objective This scoping review aims to (1) summarize current research evidence on the accuracy and efficacy of LLMs in medical applications, (2) discuss the ethical, legal, logistical, and socioeconomic implications of LLM use in clinical settings, (3) explore barriers and facilitators to LLM implementation in healthcare, (4) propose a standardized evaluation framework for assessing LLMs\u2019 clinical utility, and (5) identify evidence gaps and propose future research directions for LLMs in clinical applications. Evidence review We screened 4,036 records from MEDLINE, EMBASE, CINAHL, medRxiv, bioRxiv, and arXiv from January 2023 (inception of the search) to June 26, 2023 for English-language papers and analyzed findings from 55 worldwide studies. Quality of evidence was reported based on the Oxford Centre for Evidence-based Medicine recommendations. Findings Our results demonstrate that LLMs show promise in compiling patient notes, assisting patients in navigating the healthcare system, and to some extent, supporting clinical decision-making when combined with human oversight. However, their utilization is limited by biases in training data that may harm patients, the generation of inaccurate but convincing information, and ethical, legal, socioeconomic, and privacy concerns. We also identified a lack of standardized methods for evaluating LLMs\u2019 effectiveness and feasibility. Conclusions and relevance This review thus highlights potential future directions and questions to address these limitations and to further explore LLMs\u2019 potential in enhancing healthcare delivery.",
    "doi": "10.1186/s12911-024-02459-6",
    "url": "https://openalex.org/W4392691776",
    "pdf_url": "https://bmcmedinformdecismak.biomedcentral.com/counter/pdf/10.1186/s12911-024-02459-6",
    "venue": "BMC Medical Informatics and Decision Making",
    "citation_count": 135,
    "fields_of_study": [
      "CINAHL",
      "MEDLINE",
      "Health care",
      "Medicine",
      "Socioeconomic status"
    ],
    "retrieved_at": "2026-02-02T16:58:13.386654"
  },
  {
    "source": "openalex",
    "source_id": "W4385650719",
    "title": "Artificial Intelligence Ethics and Challenges in Healthcare Applications: A Comprehensive Review in the Context of the European GDPR Mandate",
    "authors": [
      "Mohammad Amini",
      "Marcia Jesus",
      "Davood Fanaei Sheikholeslami",
      "Paulo Alves",
      "Aliakbar Hassanzadeh Benam",
      "Fatemeh Hariri"
    ],
    "year": 2023,
    "abstract": "This study examines the ethical issues surrounding the use of Artificial Intelligence (AI) in healthcare, specifically nursing, under the European General Data Protection Regulation (GDPR). The analysis delves into how GDPR applies to healthcare AI projects, encompassing data collection and decision-making stages, to reveal the ethical implications at each step. A comprehensive review of the literature categorizes research investigations into three main categories: Ethical Considerations in AI; Practical Challenges and Solutions in AI Integration; and Legal and Policy Implications in AI. The analysis uncovers a significant research deficit in this field, with a particular focus on data owner rights and AI ethics within GDPR compliance. To address this gap, the study proposes new case studies that emphasize the importance of comprehending data owner rights and establishing ethical norms for AI use in medical applications, especially in nursing. This review makes a valuable contribution to the AI ethics debate and assists nursing and healthcare professionals in developing ethical AI practices. The insights provided help stakeholders navigate the intricate terrain of data protection, ethical considerations, and regulatory compliance in AI-driven healthcare. Lastly, the study introduces a case study of a real AI health-tech project named SENSOMATT, spotlighting GDPR and privacy issues.",
    "doi": "10.3390/make5030053",
    "url": "https://openalex.org/W4385650719",
    "pdf_url": "https://www.mdpi.com/2504-4990/5/3/53/pdf?version=1691412599",
    "venue": "Machine Learning and Knowledge Extraction",
    "citation_count": 104,
    "fields_of_study": [
      "Mandate",
      "Engineering ethics",
      "Health care",
      "General Data Protection Regulation",
      "Context (archaeology)"
    ],
    "retrieved_at": "2026-02-02T16:58:13.386681"
  },
  {
    "source": "openalex",
    "source_id": "W3201150582",
    "title": "Corporate digital responsibility (CDR) in construction engineering\u2014ethical guidelines for the application of digital transformation and artificial intelligence (AI) in user practice",
    "authors": [
      "Bianca Christina Weber-Lewerenz"
    ],
    "year": 2021,
    "abstract": null,
    "doi": "10.1007/s42452-021-04776-1",
    "url": "https://openalex.org/W3201150582",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s42452-021-04776-1.pdf",
    "venue": "SN Applied Sciences",
    "citation_count": 129,
    "fields_of_study": [
      "Digitization",
      "Digital transformation",
      "Process (computing)",
      "Government (linguistics)",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:13.386701"
  },
  {
    "source": "openalex",
    "source_id": "W2973057865",
    "title": "Platforms in the peer-to-peer sharing economy",
    "authors": [
      "Jochen Wirtz",
      "Kevin Kam Fung So",
      "Makarand Mody",
      "Stephanie Q. Liu",
      "HaeEun Helen Chun"
    ],
    "year": 2019,
    "abstract": "Purpose The purpose of this paper is to examine peer-to-peer sharing platform business models, their sources of competitive advantage, and the roles, motivations and behaviors of key actors in their ecosystems. Design/methodology/approach This paper uses a conceptual approach that is rooted in the service, tourism and hospitality, and strategy literature. Findings First, this paper defines key types of platform business models in the sharing economy anddescribes their characteristics. In particular, the authors propose the differentiation between sharing platforms of capacity-constrained vs capacity-unconstrained assets and advance five core properties of the former. Second, the authors contrast platform business models with their pipeline business model counterparts to understand the fundamental differences between them. One important conclusion is that platforms cater to vastly more heterogeneous assets and consumer needs and, therefore, require liquidity and analytics for high-quality matching. Third, the authors examine the competitive position of platforms and conclude that their widely taken \u201cwinner takes it all\u201d assumption is not valid. Primary network effects are less important once a critical level of liquidity has been reached and may even turn negative if increased listings raise friction in the form of search costs. Once a critical level of liquidity has been reached, a platform\u2019s competitive position depends on stakeholder trust and service provider and user loyalty. Fourth, the authors integrate and synthesize the literature on key platform stakeholders of platform businesses (i.e. users, service providers, and regulators) and their roles and motivations. Finally, directions for further research are advanced. Practical implications This paper helps platform owners, service providers and users understand better the implications of sharing platform business models and how to position themselves in such ecosystems. Originality/value This paper integrates the extant literature on sharing platforms, takes a novel approach in delineating their key properties and dimensions, and provides insights into the evolving and dynamic forms of sharing platforms including converging business models.",
    "doi": "10.1108/josm-11-2018-0369",
    "url": "https://openalex.org/W2973057865",
    "pdf_url": "https://www.emerald.com/insight/content/doi/10.1108/JOSM-11-2018-0369/full/pdf?title=platforms-in-the-peer-to-peer-sharing-economy",
    "venue": "Journal of service management",
    "citation_count": 378,
    "fields_of_study": [
      "Sharing economy",
      "Business model",
      "Business",
      "Industrial organization",
      "Key (lock)"
    ],
    "retrieved_at": "2026-02-02T16:58:13.386704"
  },
  {
    "source": "openalex",
    "source_id": "W2998535576",
    "title": "Detection of Suicide Ideation in Social Media Forums Using Deep Learning",
    "authors": [
      "Michael M. Tadesse",
      "Hongfei Lin",
      "Bo Xu",
      "Liang Yang"
    ],
    "year": 2019,
    "abstract": "Suicide ideation expressed in social media has an impact on language usage. Many at-risk individuals use social forum platforms to discuss their problems or get access to information on similar tasks. The key objective of our study is to present ongoing work on automatic recognition of suicidal posts. We address the early detection of suicide ideation through deep learning and machine learning-based classification approaches applied to Reddit social media. For such purpose, we employ an LSTM-CNN combined model to evaluate and compare to other classification models. Our experiment shows the combined neural network architecture with word embedding techniques can achieve the best relevance classification results. Additionally, our results support the strength and ability of deep learning architectures to build an effective model for a suicide risk assessment in various text classification tasks.",
    "doi": "10.3390/a13010007",
    "url": "https://openalex.org/W2998535576",
    "pdf_url": "https://www.mdpi.com/1999-4893/13/1/7/pdf?version=1577442085",
    "venue": "Algorithms",
    "citation_count": 227,
    "fields_of_study": [
      "Computer science",
      "Social media",
      "Deep learning",
      "Word embedding",
      "Suicidal ideation"
    ],
    "retrieved_at": "2026-02-02T16:58:13.386734"
  },
  {
    "source": "openalex",
    "source_id": "W3155872716",
    "title": "Spatiotemporal data mining: a survey on challenges and open problems",
    "authors": [
      "Ali Hamdi",
      "Khaled Shaban",
      "Abdelkarim Erradi",
      "Amr Mohamed",
      "Shakila Khan Rumi",
      "Flora D. Salim"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1007/s10462-021-09994-y",
    "url": "https://openalex.org/W3155872716",
    "pdf_url": null,
    "venue": null,
    "citation_count": 131,
    "fields_of_study": [
      "Computer science",
      "Data science",
      "Cluster analysis",
      "Data mining",
      "Visualization"
    ],
    "retrieved_at": "2026-02-02T16:58:13.386751"
  },
  {
    "source": "openalex",
    "source_id": "W4387970754",
    "title": "AI Chatbots in Digital Mental Health",
    "authors": [
      "Luke Balcombe"
    ],
    "year": 2023,
    "abstract": "Artificial intelligence (AI) chatbots have gained prominence since 2022. Powered by big data, natural language processing (NLP) and machine learning (ML) algorithms, they offer the potential to expand capabilities, improve productivity and provide guidance and support in various domains. Human\u2013Artificial Intelligence (HAI) is proposed to help with the integration of human values, empathy and ethical considerations into AI in order to address the limitations of AI chatbots and enhance their effectiveness. Mental health is a critical global concern, with a substantial impact on individuals, communities and economies. Digital mental health solutions, leveraging AI and ML, have emerged to address the challenges of access, stigma and cost in mental health care. Despite their potential, ethical and legal implications surrounding these technologies remain uncertain. This narrative literature review explores the potential of AI chatbots to revolutionize digital mental health while emphasizing the need for ethical, responsible and trustworthy AI algorithms. The review is guided by three key research questions: the impact of AI chatbots on technology integration, the balance between benefits and harms, and the mitigation of bias and prejudice in AI applications. Methodologically, the review involves extensive database and search engine searches, utilizing keywords related to AI chatbots and digital mental health. Peer-reviewed journal articles and media sources were purposively selected to address the research questions, resulting in a comprehensive analysis of the current state of knowledge on this evolving topic. In conclusion, AI chatbots hold promise in transforming digital mental health but must navigate complex ethical and practical challenges. The integration of HAI principles, responsible regulation and scoping reviews are crucial to maximizing their benefits while minimizing potential risks. Collaborative approaches and modern educational solutions may enhance responsible use and mitigate biases in AI applications, ensuring a more inclusive and effective digital mental health landscape.",
    "doi": "10.3390/informatics10040082",
    "url": "https://openalex.org/W4387970754",
    "pdf_url": "https://www.mdpi.com/2227-9709/10/4/82/pdf?version=1698398262",
    "venue": "Informatics",
    "citation_count": 99,
    "fields_of_study": [
      "Mental health",
      "Digital health",
      "Empathy",
      "Big data",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:13.386754"
  },
  {
    "source": "openalex",
    "source_id": "W3088512781",
    "title": "Transforming knowledge systems for life on Earth: Visions of future systems and how to get there",
    "authors": [
      "Ioan Fazey",
      "Niko Sch\u00e4pke",
      "Guido Caniglia",
      "Anthony Hodgson",
      "Ian Kendrick",
      "Christopher J. Lyon",
      "Glenn G. Page",
      "James Patterson",
      "Chris Riedy",
      "Tim Strasser",
      "S. Verveen",
      "David Adams",
      "Bruce Evan Goldstein",
      "Matthias Klaes",
      "Graham Leicester",
      "Alison Linyard",
      "Adrienne McCurdy",
      "Paul Ryan",
      "Bill Sharpe",
      "Giorgia Silvestri",
      "Ali Yansyah Abdurrahim",
      "David J. Abson",
      "Olufemi Adetunji",
      "Paulina Aldunce",
      "Carlos Alvarez-Pereira",
      "Jennifer Marie Amparo",
      "Helene Amundsen",
      "Lakin Anderson",
      "Lotta Andersson",
      "Michael Asquith",
      "Karoline Augenstein",
      "Jack Barrie",
      "David Bent",
      "Julia Bentz",
      "Arvid Bergsten",
      "Carol L. Berzonsky",
      "Ol\u00edvia Bina",
      "Kirsty Blackstock",
      "Joanna Boehnert",
      "Hilary Bradbury",
      "Christine Brand",
      "Jessica B\u00f6hme",
      "Marianne Mille B\u00f8jer",
      "Esther Carmen",
      "Lakshmi Charli-Joseph",
      "Sarah Choudhury",
      "Supot Chunhachoti-ananta",
      "Jessica Cockburn",
      "John Colvin",
      "Irena Leisbet Ceridwen Connon",
      "Rosalind Cornforth",
      "Robin S. Cox",
      "Nicholas A. Cradock-Henry",
      "Laura Cramer",
      "Almendra Cremaschi",
      "Halvor Dannevig",
      "Catherine T. Day",
      "Cathel de Lima Hutchison",
      "Anke de Vrieze",
      "Vikas Desai",
      "Jonathan Dolley",
      "Dominic Duckett",
      "Rachael Durrant",
      "Markus Egermann",
      "Emily Elsner",
      "Chris Fremantle",
      "Jessica Fullwood-Thomas",
      "Diego Galafassi",
      "Jen Gobby",
      "Ami Golland",
      "Shiara Kirana Gonz\u00e1lez-Padr\u00f3n",
      "Irmelin Gram-Hanssen",
      "Jakob Grandin",
      "Sara Grenni",
      "Jade Lauren Gunnell",
      "Felipe Gusm\u00e3o",
      "Maike Hamann",
      "Brian Harding",
      "Gavin Harper",
      "Mia Hesselgren",
      "Dina Hestad",
      "Cheryl Heykoop",
      "Johan Holm\u00e9n",
      "Kirsty Holstead",
      "Claire Hoolohan",
      "Andra\u2010Ioana Horcea\u2010Milcu",
      "Lummina Horlings",
      "Stuart Mark Howden",
      "Rachel Howell",
      "Sarah Huque",
      "Mirna Liz Inturias Canedo",
      "Chidinma Yvonne Iro",
      "Christopher D. Ives",
      "Beatrice John",
      "Rajiv Joshi",
      "Sadhbh Ju\u00e1rez-Bourke",
      "Dauglas Wafula Juma",
      "Bea Cecilie Karlsen",
      "Lea Kliem",
      "Andreas Kl\u00e4y"
    ],
    "year": 2020,
    "abstract": null,
    "doi": "10.1016/j.erss.2020.101724",
    "url": "https://openalex.org/W3088512781",
    "pdf_url": "https://www.sciencedirect.com/science/article/pii/S2214629620302991?via%3Dihub",
    "venue": "Energy Research & Social Science",
    "citation_count": 250,
    "fields_of_study": [
      "Vision",
      "Futures studies",
      "Engineering ethics",
      "Futures contract",
      "Enlightenment"
    ],
    "retrieved_at": "2026-02-02T16:58:13.386795"
  },
  {
    "source": "openalex",
    "source_id": "W4388354324",
    "title": "Better regulation for the green transition",
    "authors": [
      "Yola Th\u00fcrer"
    ],
    "year": 2023,
    "abstract": "Climate change and other environmental threats require urgent government action. This policy paper discusses how governments can use better regulation instruments (good regulatory practices, risk-based and agile approaches, regulatory delivery, international regulatory cooperation, economic regulators, and behavioural insights) to design, implement and evaluate efficient and effective regulations for the environment. It explores the challenges governments face and presents good practices for environmental and other regulations, to ensure that all policy instruments coherently pursue environmental goals. Finally, the paper suggests how regulatory policy systems can meet present and future environmental challenges. It argues that to fully exploit the potential of better regulation for the environment, governments should implement measures that ensure an inclusive, cooperative, outcome-based and global approach to regulating.",
    "doi": "10.1787/c91a04bc-en",
    "url": "https://openalex.org/W4388354324",
    "pdf_url": "https://www.oecd-ilibrary.org/deliver/c91a04bc-en.pdf?itemId=%2Fcontent%2Fpaper%2Fc91a04bc-en&mimeType=pdf",
    "venue": "Public governance policy papers",
    "citation_count": 397,
    "fields_of_study": [
      "Exploit",
      "Environmental regulation",
      "Government (linguistics)",
      "Business",
      "Action (physics)"
    ],
    "retrieved_at": "2026-02-02T16:58:13.386798"
  },
  {
    "source": "openalex",
    "source_id": "W4220863829",
    "title": "Deep Learning and Medical Image Analysis for COVID-19 Diagnosis and Prediction",
    "authors": [
      "Tianming Liu",
      "Eliot L. Siegel",
      "Dinggang Shen"
    ],
    "year": 2022,
    "abstract": "The coronavirus disease 2019 (COVID-19) pandemic has imposed dramatic challenges to health-care organizations worldwide. To combat the global crisis, the use of thoracic imaging has played a major role in the diagnosis, prediction, and management of COVID-19 patients with moderate to severe symptoms or with evidence of worsening respiratory status. In response, the medical image analysis community acted quickly to develop and disseminate deep learning models and tools to meet the urgent need of managing and interpreting large amounts of COVID-19 imaging data. This review aims to not only summarize existing deep learning and medical image analysis methods but also offer in-depth discussions and recommendations for future investigations. We believe that the wide availability of high-quality, curated, and benchmarked COVID-19 imaging data sets offers the great promise of a transformative test bed to develop, validate, and disseminate novel deep learning methods in the frontiers of data science and artificial intelligence.",
    "doi": "10.1146/annurev-bioeng-110220-012203",
    "url": "https://openalex.org/W4220863829",
    "pdf_url": "https://www.annualreviews.org/doi/pdf/10.1146/annurev-bioeng-110220-012203",
    "venue": "Annual Review of Biomedical Engineering",
    "citation_count": 115,
    "fields_of_study": [
      "Deep learning",
      "Dissemination",
      "Coronavirus disease 2019 (COVID-19)",
      "Transformative learning",
      "Pandemic"
    ],
    "retrieved_at": "2026-02-02T16:58:13.386811"
  },
  {
    "source": "openalex",
    "source_id": "W4283275376",
    "title": "Artificial intelligence and blockchain implementation in supply chains: a pathway to sustainability and data monetisation?",
    "authors": [
      "Naoum Tsolakis",
      "Roman Schumacher",
      "Manoj Dora",
      "Mukesh Kumar"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1007/s10479-022-04785-2",
    "url": "https://openalex.org/W4283275376",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10479-022-04785-2.pdf",
    "venue": "Annals of Operations Research",
    "citation_count": 249,
    "fields_of_study": [
      "Supply chain",
      "Sustainability",
      "Big data",
      "Fast fashion",
      "Process management"
    ],
    "retrieved_at": "2026-02-02T16:58:13.386827"
  },
  {
    "source": "openalex",
    "source_id": "W4391023377",
    "title": "The IDEAL framework for surgical robotics: development, comparative evaluation and long-term monitoring",
    "authors": [
      "Hani J. Marcus",
      "Pedro T. Ram\u00edrez",
      "Danyal Z. Khan",
      "Hugo Layard Horsfall",
      "John Hanrahan",
      "Simon C. Williams",
      "David Beard",
      "Rani Akhil Bhat",
      "Ken Catchpole",
      "Andrew Cook",
      "Katrina Hutchison",
      "Janet Martin",
      "Tom Melvin",
      "Danail Stoyanov",
      "Maroeska M. Rovers",
      "Nicholas Raison",
      "Prokar Dasgupta",
      "David Noonan",
      "Deborah Stocken",
      "Georgia Sturt",
      "Anne Vanhoestenberghe",
      "Baptiste Vasey",
      "Peter McCulloch",
      "Ajai Chari",
      "Fanny Ficuciello",
      "Effy Vayena",
      "Chris Baber",
      "Marco A. Zenati",
      "Alan Kuntz",
      "Karen Kerr",
      "Nigel Horwood",
      "Katherine Anderon",
      "Ka\u2010Wai Kwok",
      "Rich Mahoney",
      "Bill Peine",
      "Ferdinando Rodriquez Y. Baena",
      "Pietro Valdastri",
      "Richard Leparmentier",
      "Len Evans",
      "Rebecca Langley",
      "Garnette R. Sutherland",
      "Sanju Lama",
      "Naeem Soomro",
      "Justin Collins",
      "Mario M. Leit\u00e3o",
      "James Kinross",
      "Alvin C. Goh",
      "Bernard J. Park",
      "Matthias Weigl",
      "Rebecca Randell",
      "Steven Yule",
      "Duncan McPherson",
      "Laura Pickup",
      "Richard J. E. Skipworth",
      "Jennifer T. Anger",
      "Denny Yu",
      "Lora Cavuoto",
      "Ann M. Bisantz",
      "Tara Cohen",
      "Mirre Scholte",
      "Guy J. Maddern",
      "Laura Sampietro-Colom",
      "Alane Clark",
      "Tammy Clifford",
      "Bel\u00e9n Corbacho",
      "Cynthia P Iglesias",
      "Janneke P.C. Grutters",
      "Katrina Hutchinson",
      "Lesley Booth",
      "Heather Draper",
      "Len Evans",
      "Sarah Goering",
      "Alexander A. Kon",
      "Rebecca Langley",
      "Rob Sparrow",
      "Kamran Ahmed",
      "Deena Harji",
      "Teodor Grantcharov",
      "Lars Konge",
      "Art Sedrakyan",
      "Joel Horowitz",
      "Arsenio P\u00e1ez",
      "Kamran Ahmed",
      "Deena Harji",
      "Teodor Grantcharov",
      "Lars Konge",
      "Additional collaborators",
      "Art Sedrakyan",
      "Joel Horowitz",
      "Arsenio Paez"
    ],
    "year": 2024,
    "abstract": null,
    "doi": "10.1038/s41591-023-02732-7",
    "url": "https://openalex.org/W4391023377",
    "pdf_url": "https://www.nature.com/articles/s41591-023-02732-7.pdf",
    "venue": "Nature Medicine",
    "citation_count": 112,
    "fields_of_study": [
      "Robotics",
      "Artificial intelligence",
      "Context (archaeology)",
      "Robot",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:13.386843"
  },
  {
    "source": "openalex",
    "source_id": "W4312910656",
    "title": "Efficient Acceleration of Deep Learning Inference on Resource-Constrained Edge Devices: A Review",
    "authors": [
      "Md Maruf Hossain Shuvo",
      "Syed K. Islam",
      "Jianlin Cheng",
      "Bashir I. Morshed"
    ],
    "year": 2022,
    "abstract": "\u00a9 1963-2012 IEEE. cc-by",
    "doi": "10.1109/jproc.2022.3226481",
    "url": "https://openalex.org/W4312910656",
    "pdf_url": "https://ieeexplore.ieee.org/ielx7/5/10015202/09985008.pdf",
    "venue": "Proceedings of the IEEE",
    "citation_count": 268,
    "fields_of_study": [
      "Computer science",
      "Edge device",
      "Cloud computing",
      "Edge computing",
      "Software deployment"
    ],
    "retrieved_at": "2026-02-02T16:58:13.386846"
  },
  {
    "source": "openalex",
    "source_id": "W3134822068",
    "title": "You Can't Sit With Us",
    "authors": [
      "Inioluwa Deborah Raji",
      "Morgan Klaus Scheuerman",
      "Razvan Amironesei"
    ],
    "year": 2021,
    "abstract": "Given a growing concern about the lack of ethical consideration in the Artificial Intelligence (AI) field, many have begun to question how dominant approaches to the disciplinary education of computer science (CS)---and its implications for AI---has led to the current \"ethics crisis\". However, we claim that the current AI ethics education space relies on a form of \"exclusionary pedagogy,\" where ethics is distilled for computational approaches, but there is no deeper epistemological engagement with other ways of knowing that would benefit ethical thinking or an acknowledgement of the limitations of uni-vocal computational thinking. This results in indifference, devaluation, and a lack of mutual support between CS and humanistic social science (HSS), elevating the myth of technologists as \"ethical unicorns\" that can do it all, though their disciplinary tools are ultimately limited. Through an analysis of computer science education literature and a review of college-level course syllabi in AI ethics, we discuss the limitations of the epistemological assumptions and hierarchies of knowledge which dictate current attempts at including ethics education in CS training and explore evidence for the practical mechanisms through which this exclusion occurs. We then propose a shift towards a substantively collaborative, holistic, and ethically generative pedagogy in AI education.",
    "doi": "10.1145/3442188.3445914",
    "url": "https://openalex.org/W3134822068",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3442188.3445914",
    "venue": null,
    "citation_count": 128,
    "fields_of_study": [
      "Acknowledgement",
      "Discipline",
      "Engineering ethics",
      "Syllabus",
      "Philosophy of science"
    ],
    "retrieved_at": "2026-02-02T16:58:13.386851"
  },
  {
    "source": "openalex",
    "source_id": "W4393229110",
    "title": "Ethics and responsible AI deployment",
    "authors": [
      "Petar Radanliev",
      "Omar Santos",
      "Alistair Brandon\u2010Jones",
      "Adam Joinson"
    ],
    "year": 2024,
    "abstract": "As Artificial Intelligence (AI) becomes more prevalent, protecting personal privacy is a critical ethical issue that must be addressed. This article explores the need for ethical AI systems that safeguard individual privacy while complying with ethical standards. By taking a multidisciplinary approach, the research examines innovative algorithmic techniques such as differential privacy, homomorphic encryption, federated learning, international regulatory frameworks, and ethical guidelines. The study concludes that these algorithms effectively enhance privacy protection while balancing the utility of AI with the need to protect personal data. The article emphasises the importance of a comprehensive approach that combines technological innovation with ethical and regulatory strategies to harness the power of AI in a way that respects and protects individual privacy.",
    "doi": "10.3389/frai.2024.1377011",
    "url": "https://openalex.org/W4393229110",
    "pdf_url": "https://www.frontiersin.org/articles/10.3389/frai.2024.1377011/pdf?isPublishedV2=False",
    "venue": "Frontiers in Artificial Intelligence",
    "citation_count": 100,
    "fields_of_study": [
      "Software deployment",
      "Safeguard",
      "Multidisciplinary approach",
      "Engineering ethics",
      "Information privacy"
    ],
    "retrieved_at": "2026-02-02T16:58:13.386871"
  },
  {
    "source": "openalex",
    "source_id": "W4392153984",
    "title": "The potential of generative AI for personalized persuasion at scale",
    "authors": [
      "Sandra Matz",
      "Jacob D. Teeny",
      "Sumer S. Vaid",
      "H. Peters",
      "Gabriella M. Harari",
      "Moran Cerf"
    ],
    "year": 2024,
    "abstract": "Abstract Matching the language or content of a message to the psychological profile of its recipient (known as \u201cpersonalized persuasion\u201d) is widely considered to be one of the most effective messaging strategies. We demonstrate that the rapid advances in large language models (LLMs), like ChatGPT, could accelerate this influence by making personalized persuasion scalable. Across four studies (consisting of seven sub-studies; total N = 1788), we show that personalized messages crafted by ChatGPT exhibit significantly more influence than non-personalized messages. This was true across different domains of persuasion (e.g., marketing of consumer products, political appeals for climate action), psychological profiles (e.g., personality traits, political ideology, moral foundations), and when only providing the LLM with a single, short prompt naming or describing the targeted psychological dimension. Thus, our findings are among the first to demonstrate the potential for LLMs to automate, and thereby scale, the use of personalized persuasion in ways that enhance its effectiveness and efficiency. We discuss the implications for researchers, practitioners, and the general public.",
    "doi": "10.1038/s41598-024-53755-0",
    "url": "https://openalex.org/W4392153984",
    "pdf_url": "https://www.nature.com/articles/s41598-024-53755-0.pdf",
    "venue": "Scientific Reports",
    "citation_count": 160,
    "fields_of_study": [
      "Persuasion",
      "Dimension (graph theory)",
      "Matching (statistics)",
      "Scale (ratio)",
      "Politics"
    ],
    "retrieved_at": "2026-02-02T16:58:13.386885"
  },
  {
    "source": "openalex",
    "source_id": "W3121264940",
    "title": "The Rise and Decline of General Laws of Capitalism",
    "authors": [
      "Daron Acemo\u011flu",
      "James A. Robinson"
    ],
    "year": 2015,
    "abstract": "Thomas Piketty's (2013) book, Capital in the 21st Century, follows in the tradition of the great classical economists, like Marx and Ricardo, in formulating general laws of capitalism to diagnose and predict the dynamics of inequality. We argue that general economic laws are unhelpful as a guide to understanding the past or predicting the future because they ignore the central role of political and economic institutions, as well as the endogenous evolution of technology, in shaping the distribution of resources in society. We use regression evidence to show that the main economic force emphasized in Piketty's book, the gap between the interest rate and the growth rate, does not appear to explain historical patterns of inequality (especially, the share of income accruing to the upper tail of the distribution). We then use the histories of inequality of South Africa and Sweden to illustrate that inequality dynamics cannot be understood without embedding economic factors in the context of economic and political institutions, and also that the focus on the share of top incomes can give a misleading characterization of the true nature of inequality.",
    "doi": "10.1257/jep.29.1.3",
    "url": "https://openalex.org/W3121264940",
    "pdf_url": "https://www.aeaweb.org/articles/pdf/doi/10.1257/jep.29.1.3",
    "venue": "The Journal of Economic Perspectives",
    "citation_count": 313,
    "fields_of_study": [
      "Capitalism",
      "Inequality",
      "Economics",
      "Context (archaeology)",
      "Economic inequality"
    ],
    "retrieved_at": "2026-02-02T16:58:13.386903"
  },
  {
    "source": "openalex",
    "source_id": "W4361185690",
    "title": "ChatGPT for Education and Research: Opportunities, Threats, and Strategies",
    "authors": [
      "Md. Mostafizer Rahman",
      "Yutaka Watanobe"
    ],
    "year": 2023,
    "abstract": "In recent years, the rise of advanced artificial intelligence technologies has had a profound impact on many fields, including education and research. One such technology is ChatGPT, a powerful large language model developed by OpenAI. This technology offers exciting opportunities for students and educators, including personalized feedback, increased accessibility, interactive conversations, lesson preparation, evaluation, and new ways to teach complex concepts. However, ChatGPT poses different threats to the traditional education and research system, including the possibility of cheating on online exams, human-like text generation, diminished critical thinking skills, and difficulties in evaluating information generated by ChatGPT. This study explores potential opportunities and threats that ChatGPT poses to overall education from the perspective of students and educators. Furthermore, for programming learning, we explore how ChatGPT helps students improve their programming skills. To demonstrate this, we conducted different coding-related experiments with ChatGPT, including code generation from problem descriptions, pseudocode generation of algorithms from texts, and code correction. We also verified the generated codes with an online judge system to evaluate their accuracy.",
    "doi": "10.20944/preprints202303.0473.v1",
    "url": "https://openalex.org/W4361185690",
    "pdf_url": "https://www.preprints.org/manuscript/202303.0473/v1/download",
    "venue": "Preprints.org",
    "citation_count": 156,
    "fields_of_study": [
      "Cheating",
      "Computer science",
      "Perspective (graphical)",
      "Coding (social sciences)",
      "Code (set theory)"
    ],
    "retrieved_at": "2026-02-02T16:58:13.386922"
  },
  {
    "source": "openalex",
    "source_id": "W2983996708",
    "title": "Procedural Justice in Algorithmic Fairness",
    "authors": [
      "Min Kyung Lee",
      "Anuraag Jain",
      "Hea Jin",
      "Shashank Kumar Ojha",
      "Daniel Kusbit"
    ],
    "year": 2019,
    "abstract": "As algorithms increasingly take managerial and governance roles, it is ever more important to build them to be perceived as fair and adopted by people. With this goal, we propose a procedural justice framework in algorithmic decision-making drawing from procedural justice theory, which lays out elements that promote a sense of fairness among users. As a case study, we built an interface that leveraged two key elements of the framework---transparency and outcome control---and evaluated it in the context of goods division. Our interface explained the algorithm's allocative fairness properties (standards clarity) and outcomes through an input-output matrix (outcome explanation), then allowed people to interactively adjust the algorithmic allocations as a group (outcome control). The findings from our within-subjects laboratory study suggest that standards clarity alone did not increase perceived fairness; outcome explanation had mixed effects, increasing or decreasing perceived fairness and reducing algorithmic accountability; and outcome control universally improved perceived fairness by allowing people to realize the inherent limitations of decisions and redistribute the goods to better fit their contexts, and by bringing human elements into final decision-making.",
    "doi": "10.1145/3359284",
    "url": "https://openalex.org/W2983996708",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3359284",
    "venue": "Proceedings of the ACM on Human-Computer Interaction",
    "citation_count": 197,
    "fields_of_study": [
      "CLARITY",
      "Outcome (game theory)",
      "Allocative efficiency",
      "Accountability",
      "Transparency (behavior)"
    ],
    "retrieved_at": "2026-02-02T16:58:13.386943"
  },
  {
    "source": "openalex",
    "source_id": "W4391026828",
    "title": "The Challenges of Machine Learning: A Critical Review",
    "authors": [
      "Enrico Barbierato",
      "Alice Gatti"
    ],
    "year": 2024,
    "abstract": "The concept of learning has multiple interpretations, ranging from acquiring knowledge or skills to constructing meaning and social development. Machine Learning (ML) is considered a branch of Artificial Intelligence (AI) and develops algorithms that can learn from data and generalize their judgment to new observations by exploiting primarily statistical methods. The new millennium has seen the proliferation of Artificial Neural Networks (ANNs), a formalism able to reach extraordinary achievements in complex problems such as computer vision and natural language recognition. In particular, designers claim that this formalism has a strong resemblance to the way the biological neurons operate. This work argues that although ML has a mathematical/statistical foundation, it cannot be strictly regarded as a science, at least from a methodological perspective. The main reason is that ML algorithms have notable prediction power although they cannot necessarily provide a causal explanation about the achieved predictions. For example, an ANN could be trained on a large dataset of consumer financial information to predict creditworthiness. The model takes into account various factors like income, credit history, debt, spending patterns, and more. It then outputs a credit score or a decision on credit approval. However, the complex and multi-layered nature of the neural network makes it almost impossible to understand which specific factors or combinations of factors the model is using to arrive at its decision. This lack of transparency can be problematic, especially if the model denies credit and the applicant wants to know the specific reasons for the denial. The model\u2019s \u201cblack box\u201d nature means it cannot provide a clear explanation or breakdown of how it weighed the various factors in its decision-making process. Secondly, this work rejects the belief that a machine can simply learn from data, either in supervised or unsupervised mode, just by applying statistical methods. The process of learning is much more complex, as it requires the full comprehension of a learned ability or skill. In this sense, further ML advancements, such as reinforcement learning and imitation learning denote encouraging similarities to similar cognitive skills used in human learning.",
    "doi": "10.3390/electronics13020416",
    "url": "https://openalex.org/W4391026828",
    "pdf_url": "https://www.mdpi.com/2079-9292/13/2/416/pdf?version=1705653285",
    "venue": "Electronics",
    "citation_count": 131,
    "fields_of_study": [
      "Artificial intelligence",
      "Artificial neural network",
      "Machine learning",
      "Computer science",
      "Denial"
    ],
    "retrieved_at": "2026-02-02T16:58:13.386961"
  },
  {
    "source": "openalex",
    "source_id": "W3206204366",
    "title": "Enablers and Inhibitors of AI-Powered Voice Assistants: A Dual-Factor Approach by Integrating the Status Quo Bias and Technology Acceptance Model",
    "authors": [
      "Janarthanan Balakrishnan",
      "Yogesh K. Dwivedi",
      "Laurie Hughes",
      "Fr\u00e9d\u00e9ric Boy"
    ],
    "year": 2021,
    "abstract": null,
    "doi": "10.1007/s10796-021-10203-y",
    "url": "https://openalex.org/W3206204366",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10796-021-10203-y.pdf",
    "venue": "Information Systems Frontiers",
    "citation_count": 144,
    "fields_of_study": [
      "Status quo bias",
      "Status quo",
      "Regret",
      "Value (mathematics)",
      "Psychology"
    ],
    "retrieved_at": "2026-02-02T16:58:13.386996"
  },
  {
    "source": "openalex",
    "source_id": "W2900379068",
    "title": "Data Science as Political Action: Grounding Data Science in a Politics of Justice",
    "authors": [
      "Ben Green"
    ],
    "year": 2021,
    "abstract": "In response to public scrutiny of data-driven algorithms, the field of data science has adopted ethics training and principles. Although ethics can help data scientists reflect on certain normative aspects of their work, such efforts are ill-equipped to generate a data science that avoids social harms and promotes social justice. In this article, I argue that data science must embrace a political orientation. Data scientists must recognize themselves as political actors engaged in normative constructions of society and evaluate their work according to its downstream impacts on people's lives. I first articulate why data scientists must recognize themselves as political actors. In this section, I respond to three arguments that data scientists commonly invoke when challenged to take political positions regarding their work. In confronting these arguments, I describe why attempting to remain apolitical is itself a political stance--a fundamentally conservative one--and why data science's attempts to promote \"social good\" dangerously rely on unarticulated and incrementalist political assumptions. I then propose a framework for how data science can evolve toward a deliberative and rigorous politics of social justice. I conceptualize the process of developing a politically engaged data science as a sequence of four stages. Pursuing these new approaches will empower data scientists with new methods for thoughtfully and rigorously contributing to social justice.",
    "doi": "10.23919/jsc.2021.0029",
    "url": "https://openalex.org/W2900379068",
    "pdf_url": "https://ieeexplore.ieee.org/ielx7/8964404/9684739/09684742.pdf",
    "venue": "Journal of Social Computing",
    "citation_count": 114,
    "fields_of_study": [
      "Politics",
      "Scrutiny",
      "Normative",
      "Sociology",
      "Epistemology"
    ],
    "retrieved_at": "2026-02-02T16:58:13.386999"
  },
  {
    "source": "openalex",
    "source_id": "W4390584313",
    "title": "A Conceptual Model for Inclusive Technology: Advancing Disability Inclusion through Artificial Intelligence",
    "authors": [
      "Maram Fahaad Almufareh",
      "Sumaira Kausar",
      "Mamoona Humayun",
      "Samabia Tehsin"
    ],
    "year": 2024,
    "abstract": "Artificial intelligence (AI) has ushered in transformative changes, championing inclusion and accessibility for individuals with disabilities. This article delves into the remarkable AI-driven solutions that have revolutionized their lives across various domains. From assistive technologies such as voice recognition and AI-powered smart glasses catering to diverse needs, to healthcare benefiting from early disease detection algorithms and wearable devices that monitor vital signs and alert caregivers in emergencies, AI has steered in significant enhancements. Moreover, AI-driven prosthetics and exoskeletons have substantially improved mobility for those with limb impairments. The realm of education has not been left untouched, with AI tools creating inclusive learning environments that adapt to individual learning styles, paving the way for academic success among students with disabilities. However, the boundless potential of AI also presents ethical concerns and challenges. Issues like safeguarding data privacy, mitigating algorithmic bias, and bridging the digital divide must be thoughtfully addressed to fully harness AI\u2019s potential in empowering individuals with disabilities. To complement these achievements, a robust conceptual model for AI disability inclusion serves as the theoretical framework, guiding the development of tailored AI solutions. By striking a harmonious balance between innovation and ethics, AI has the power to significantly enhance the overall quality of life for individuals with disabilities across a spectrum of vital areas.",
    "doi": "10.57197/jdr-2023-0060",
    "url": "https://openalex.org/W4390584313",
    "pdf_url": "https://www.scienceopen.com/document_file/10696e8f-ab40-4c4f-be70-09fda6533ae8/ScienceOpen/jdr20230060.pdf",
    "venue": "Journal of Disability Research",
    "citation_count": 103,
    "fields_of_study": [
      "Inclusion (mineral)",
      "Safeguarding",
      "Transformative learning",
      "Realm",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387022"
  },
  {
    "source": "openalex",
    "source_id": "W3001779409",
    "title": "Stigma, biomarkers, and algorithmic bias: recommendations for precision behavioral health with artificial intelligence",
    "authors": [
      "Colin G. Walsh",
      "Beenish Moalla Chaudhry",
      "Prerna Dua",
      "Kenneth W. Goodman",
      "Bonnie J. Kaplan",
      "Ramakanth Kavuluru",
      "Anthony Solomonides",
      "Vignesh Subbian"
    ],
    "year": 2020,
    "abstract": "Abstract Effective implementation of artificial intelligence in behavioral healthcare delivery depends on overcoming challenges that are pronounced in this domain. Self and social stigma contribute to under-reported symptoms, and under-coding worsens ascertainment. Health disparities contribute to algorithmic bias. Lack of reliable biological and clinical markers hinders model development, and model explainability challenges impede trust among users. In this perspective, we describe these challenges and discuss design and implementation recommendations to overcome them in intelligent systems for behavioral and mental health.",
    "doi": "10.1093/jamiaopen/ooz054",
    "url": "https://openalex.org/W3001779409",
    "pdf_url": "https://academic.oup.com/jamiaopen/article-pdf/3/1/9/33419078/ooz054.pdf",
    "venue": "JAMIA Open",
    "citation_count": 111,
    "fields_of_study": [
      "Stigma (botany)",
      "Artificial intelligence",
      "Psychology",
      "Computer science",
      "Machine learning"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387045"
  },
  {
    "source": "openalex",
    "source_id": "W4380988459",
    "title": "Artificial Intelligence &amp; Creativity: A Manifesto for Collaboration",
    "authors": [
      "Florent Vinchon",
      "Todd Lubart",
      "Sabrina Bartolotta",
      "Valentin Gironnay",
      "Marion Botella",
      "Samira Bourgeois\u2010Bougrine",
      "Jean\u2010Marie Burkhardt",
      "Nathalie Bonnardel",
      "Giovanni Emanuele Corazza",
      "Vlad Petre Gl\u0103veanu",
      "Michael Hanchett Hanson",
      "Zorana Iv\u010devi\u0107",
      "Maciej Karwowski",
      "James C. Kaufman",
      "Takeshi Okada",
      "Roni Reiter\u2010Palmon",
      "Andrea Gaggioli"
    ],
    "year": 2023,
    "abstract": "ABSTRACT With the advent of artificial intelligence (AI), the field of creativity faces new opportunities and challenges. This manifesto explores several scenarios of human\u2013machine collaboration on creative tasks and proposes \u201cfundamental laws of generative AI\u201d to reinforce the responsible and ethical use of AI in the creativity field. Four scenarios are proposed and discussed: \u201cCo\u2010Cre\u2010AI\u2010tion,\u201d \u201cOrganic,\u201d \u201cPlagiarism 3.0,\u201d and \u201cShut down,\u201d each illustrating different possible futures based on the collaboration between humans and machines. In addition, we have incorporated an AI\u2010generated manifesto that also highlights important themes, ranging from accessibility and ethics to cultural sensitivity. The fundamental laws proposed aim to prevent AIs from generating harmful content and competing directly with humans. Creating labels and laws are also highlighted to ensure responsible use of AIs. The positive future of creativity and AI lies in a harmonious collaboration that can benefit everyone, potentially leading to a new level of creative productivity respecting ethical considerations and human values during the creative process.",
    "doi": "10.1002/jocb.597",
    "url": "https://openalex.org/W4380988459",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/jocb.597",
    "venue": "The Journal of Creative Behavior",
    "citation_count": 165,
    "fields_of_study": [
      "Manifesto",
      "Creativity",
      "Field (mathematics)",
      "Generative grammar",
      "Productivity"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387057"
  },
  {
    "source": "openalex",
    "source_id": "W4205865577",
    "title": "Operationalizing and Implementing Pretrained, Large Artificial Intelligence Linguistic Models in the US Health Care System: Outlook of Generative Pretrained Transformer 3 (GPT-3) as a Service Model",
    "authors": [
      "Emre Sezg\u0131n",
      "Joseph Sirrianni",
      "Simon Lin Linwood"
    ],
    "year": 2022,
    "abstract": "Generative pretrained transformer models have been popular recently due to their enhanced capabilities and performance. In contrast to many existing artificial intelligence models, generative pretrained transformer models can perform with very limited training data. Generative pretrained transformer 3 (GPT-3) is one of the latest releases in this pipeline, demonstrating human-like logical and intellectual responses to prompts. Some examples include writing essays, answering complex questions, matching pronouns to their nouns, and conducting sentiment analyses. However, questions remain with regard to its implementation in health care, specifically in terms of operationalization and its use in clinical practice and research. In this viewpoint paper, we briefly introduce GPT-3 and its capabilities and outline considerations for its implementation and operationalization in clinical practice through a use case. The implementation considerations include (1) processing needs and information systems infrastructure, (2) operating costs, (3) model biases, and (4) evaluation metrics. In addition, we outline the following three major operational factors that drive the adoption of GPT-3 in the US health care system: (1) ensuring Health Insurance Portability and Accountability Act compliance, (2) building trust with health care providers, and (3) establishing broader access to the GPT-3 tools. This viewpoint can inform health care practitioners, developers, clinicians, and decision makers toward understanding the use of the powerful artificial intelligence tools integrated into hospital systems and health care.",
    "doi": "10.2196/32875",
    "url": "https://openalex.org/W4205865577",
    "pdf_url": "https://medinform.jmir.org/2022/2/e32875/PDF",
    "venue": "JMIR Medical Informatics",
    "citation_count": 121,
    "fields_of_study": [
      "Operationalization",
      "Computer science",
      "Software portability",
      "Generative grammar",
      "Health Insurance Portability and Accountability Act"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387075"
  },
  {
    "source": "openalex",
    "source_id": "W3037207300",
    "title": "Should You Fine-Tune BERT for Automated Essay Scoring?",
    "authors": [
      "Elijah Mayfield",
      "Alan W. Black"
    ],
    "year": 2020,
    "abstract": "Most natural language processing research now recommends large Transformer-based models with fine-tuning for supervised classification tasks; older strategies like bag-of-words features and linear models have fallen out of favor. Here we investigate whether, in automated essay scoring (AES) research, deep neural models are an appropriate technological choice. We find that fine-tuning BERT produces similar performance to classical models at significant additional cost. We argue that while state-of-the-art strategies do match existing best results, they come with opportunity costs in computational resources. We conclude with a review of promising areas for research on student essays where the unique characteristics of Transformers may provide benefits over classical methods to justify the costs.",
    "doi": "10.18653/v1/2020.bea-1.15",
    "url": "https://openalex.org/W3037207300",
    "pdf_url": "https://www.aclweb.org/anthology/2020.bea-1.15.pdf",
    "venue": null,
    "citation_count": 119,
    "fields_of_study": [
      "Transformer",
      "Computer science",
      "Artificial intelligence",
      "Deep neural networks",
      "Machine learning"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387096"
  },
  {
    "source": "openalex",
    "source_id": "W3039283728",
    "title": "Inclusive Economic Sustainability: SDGs and Global Inequality",
    "authors": [
      "Arno J van Niekerk"
    ],
    "year": 2020,
    "abstract": "In view of the 2020 global health crisis and its repercussions on the global economy, the need to redirect conventional economic thinking towards securing global economic sustainability is most critical. The Sustainable Development Goals (SDGs) are a significant move in this direction. However, in the past few years, a clearer understanding of inclusive economics and sustainability indicators have progressed our ability to reduce economic exclusion, chiefly represented by global inequality. Collective wellbeing within the \u201cglobal village\u201d is shaped largely by these avenues/directions, thus presenting the question: can an improved combination of sustainability priorities be identified that would substantially enhance countries\u2019 adoption of the SDGs? New, inclusive paths to economic progress are essential to a world economy in crisis recovery mode. The aim of the paper is to qualitatively identify key indicators from these different directions to, collectively, address some of the most significant drivers of global inequality, thus improving the adoption rate of the SDGs. As its main contribution, the study found that for economic inclusivity to realistically reduce global inequality its full integration into three areas is necessary: business models, public policy and community development. This should also be supported by \u201csocial covenants\u201d to facilitate improved SDG adoption by countries.",
    "doi": "10.3390/su12135427",
    "url": "https://openalex.org/W3039283728",
    "pdf_url": "https://www.mdpi.com/2071-1050/12/13/5427/pdf?version=1594000965",
    "venue": "Sustainability",
    "citation_count": 175,
    "fields_of_study": [
      "Sustainability",
      "Inequality",
      "Sustainable development",
      "Social sustainability",
      "Economic inequality"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387111"
  },
  {
    "source": "openalex",
    "source_id": "W4388007985",
    "title": "The Participatory Turn in AI Design: Theoretical Foundations and the Current State of Practice",
    "authors": [
      "Fernando Delgado",
      "Stephen Yang",
      "Michael Madaio",
      "Qian Yang"
    ],
    "year": 2023,
    "abstract": "Despite the growing consensus that stakeholders affected by AI systems should participate in their design, enormous variation and implicit disagreements exist among current approaches. For researchers and practitioners who are interested in taking a participatory approach to AI design and development, it remains challenging to assess the extent to which any participatory approach grants substantive agency to stakeholders. This article thus aims to ground what we dub the \"participatory turn\" in AI design by synthesizing existing theoretical literature on participation and through empirical investigation and critique of its current practices. Specifically, we derive a conceptual framework through synthesis of literature across technology design, political theory, and the social sciences that researchers and practitioners can leverage to evaluate approaches to participation in AI design. Additionally, we articulate empirical findings concerning the current state of participatory practice in AI design based on an analysis of recently published research and semi-structured interviews with 12 AI researchers and practitioners. We use these empirical findings to understand the current state of participatory practice and subsequently provide guidance to better align participatory goals and methods in a way that accounts for practical constraints.",
    "doi": "10.1145/3617694.3623261",
    "url": "https://openalex.org/W4388007985",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3617694.3623261",
    "venue": null,
    "citation_count": 136,
    "fields_of_study": [
      "Current (fluid)",
      "Turn (biochemistry)",
      "State (computer science)",
      "Participatory design",
      "Citizen journalism"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387132"
  },
  {
    "source": "openalex",
    "source_id": "W4391579939",
    "title": "A CRITICAL REVIEW OF AI-DRIVEN STRATEGIES FOR ENTREPRENEURIAL SUCCESS",
    "authors": [
      "Favour Oluwadamilare Usman",
      "Nsisong Louis Eyo-Udo",
      "Emmanuel Augustine Etukudoh",
      "Beryl Odonkor",
      "Chidera Victoria Ibeh",
      "Ayodeji Adegbola"
    ],
    "year": 2024,
    "abstract": "In the rapidly evolving landscape of entrepreneurship, the integration of Artificial Intelligence (AI) has emerged as a transformative force, reshaping traditional business paradigms and offering unprecedented opportunities for success. This paper provides a comprehensive and critical review of AI-driven strategies employed by entrepreneurs to enhance their ventures. The review encompasses a thorough analysis of key AI applications, their impact on various aspects of entrepreneurship, and the potential benefits and challenges associated with their implementation. The first section explores the role of AI in market analysis, highlighting how advanced data analytics and predictive modelling contribute to informed decision-making and market forecasting. The discussion then extends to AI-driven innovations in product development, emphasizing the acceleration of ideation, prototyping, and customization through machine learning algorithms. Next, the paper scrutinizes the influence of AI on customer engagement and relationship management. It delves into the personalized customer experiences facilitated by chatbots, recommendation systems, and sentiment analysis, while also addressing ethical considerations surrounding data privacy and algorithmic biases. Entrepreneurial operations and efficiency gains are examined in the subsequent section, emphasizing AI's impact on supply chain management, logistics, and resource optimization. The review underscores the potential for increased productivity and cost-effectiveness through the implementation of AI-powered automation and smart systems. Despite the myriad advantages, the paper critically examines challenges such as ethical concerns, job displacement, and the digital divide. It emphasizes the need for a balanced approach that addresses the societal impact of AI adoption while fostering inclusive entrepreneurial ecosystems. In conclusion, this critical review not only provides a comprehensive overview of the current landscape of AI-driven strategies in entrepreneurship but also offers insights into the potential future developments and challenges. Entrepreneurs, policymakers, and researchers can leverage this analysis to navigate the evolving intersection of AI and entrepreneurship, fostering a sustainable and ethically sound environment for entrepreneurial success in the digital era. Keywords: Artificial Intelligence (AI), Entrepreneurship, Strategic Implementation, Innovation, Market Analysis, Predictive Modelling.",
    "doi": "10.51594/ijmer.v6i1.748",
    "url": "https://openalex.org/W4391579939",
    "pdf_url": "https://fepbl.com/index.php/ijmer/article/download/748/939",
    "venue": "International Journal of Management & Entrepreneurship Research",
    "citation_count": 95,
    "fields_of_study": [
      "Critical success factor",
      "Psychology",
      "Computer science",
      "Knowledge management"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387150"
  },
  {
    "source": "openalex",
    "source_id": "W4386525386",
    "title": "Perceptions and Acceptance of Artificial Intelligence: A Multi-Dimensional Study",
    "authors": [
      "Michael Gerlich"
    ],
    "year": 2023,
    "abstract": "In this comprehensive study, insights from 1389 scholars across the US, UK, Germany, and Switzerland shed light on the multifaceted perceptions of artificial intelligence (AI). AI\u2019s burgeoning integration into everyday life promises enhanced efficiency and innovation. The Trustworthy AI principles by the European Commission, emphasising data safeguarding, security, and judicious governance, serve as the linchpin for AI\u2019s widespread acceptance. A correlation emerged between societal interpretations of AI\u2019s impact and elements like trustworthiness, associated risks, and usage/acceptance. Those discerning AI\u2019s threats often view its prospective outcomes pessimistically, while proponents recognise its transformative potential. These inclinations resonate with trust and AI\u2019s perceived singularity. Consequently, factors such as trust, application breadth, and perceived vulnerabilities shape public consensus, depicting AI as humanity\u2019s boon or bane. The study also accentuates the public\u2019s divergent views on AI\u2019s evolution, underlining the malleability of opinions amidst polarising narratives.",
    "doi": "10.3390/socsci12090502",
    "url": "https://openalex.org/W4386525386",
    "pdf_url": "https://www.mdpi.com/2076-0760/12/9/502/pdf?version=1694056018",
    "venue": "Social Sciences",
    "citation_count": 125,
    "fields_of_study": [
      "Safeguarding",
      "Trustworthiness",
      "Transformative learning",
      "Perception",
      "Psychology"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387180"
  },
  {
    "source": "openalex",
    "source_id": "W2957812729",
    "title": "Beyond the hype of big data and artificial intelligence: building foundations for knowledge and wisdom",
    "authors": [
      "Josip Car",
      "Aziz Sheikh",
      "Paul Wicks",
      "Marc S. Williams"
    ],
    "year": 2019,
    "abstract": null,
    "doi": "10.1186/s12916-019-1382-x",
    "url": "https://openalex.org/W2957812729",
    "pdf_url": "https://bmcmedicine.biomedcentral.com/track/pdf/10.1186/s12916-019-1382-x",
    "venue": "BMC Medicine",
    "citation_count": 124,
    "fields_of_study": [
      "Big data",
      "Health care",
      "Medicine",
      "Data sharing",
      "Data science"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387199"
  },
  {
    "source": "openalex",
    "source_id": "W3197217312",
    "title": "Digitalization, accounting and accountability: A literature review and reflections on future research in public services",
    "authors": [
      "Deborah Agostino",
      "Iris Saliterer",
      "Ileana Steccolini"
    ],
    "year": 2021,
    "abstract": "Abstract This study discusses the current state of the art and future directions of research on digitalization, accountability, and accounting in public services. Through a systematic literature review, we investigate 232 articles published between 1998 and the first quarter of 2020. These studies are analyzed looking at the implications of the increasing digitalization of the public realm for the (i) production of data, (ii) consumption of data, and (iii) their subsequent effects. Based upon this analysis, we identify the following emerging critical digital accountability issues and related future research avenues: the potential for dialogic and horizontal, multicentric accountability; the blurring of accountability roles and boundaries; the increasing relevance of translation processes and translators\u2019 roles\u2014and the need to ensure accountability in such translations; the need to pay stronger attention to social equity and inclusivity implications of digitalization.",
    "doi": "10.1111/faam.12301",
    "url": "https://openalex.org/W3197217312",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/faam.12301",
    "venue": "Financial Accountability and Management",
    "citation_count": 226,
    "fields_of_study": [
      "Accountability",
      "Realm",
      "Social accounting",
      "Public relations",
      "Political science"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387202"
  },
  {
    "source": "openalex",
    "source_id": "W3153254740",
    "title": "Digitalization and AI in European Agriculture: A Strategy for Achieving Climate and Biodiversity Targets?",
    "authors": [
      "Beatrice Garske",
      "Antonia Bau",
      "Felix Ekardt"
    ],
    "year": 2021,
    "abstract": "This article analyzes the environmental opportunities and limitations of digitalization in the agricultural sector by applying qualitative governance analysis. Agriculture is recognized as a key application area for digital technologies, including artificial intelligence. This is not least because it faces major sustainability challenges, especially with regard to meeting the climate and biodiversity targets set out in the Paris Agreement and the Convention on Biological Diversity, as well as the water-related objectives of EU environmental legislation. Based on an overview of the possible applications of digital technologies in agriculture, the article offers a status quo analysis of legal acts with relevance to digitalization in the EU agricultural sector. It is found that a reliable legal framework with regard to product liability and product safety, as well as data privacy, data access, and data security is important in this context. In addition, the European Common Agricultural Policy, as the most important funding instrument for digital innovations in the agricultural sector, should be designed in such a way that it links digitalization-related objectives more closely with sustainability targets. So far, the existing EU governance does not fully exploit the potentials of digitalization for environmental protection, and sight is lost of possible negative side effects such as rebound and shifting effects. Therefore, the article also offers proposals for the optimization of EU governance.",
    "doi": "10.3390/su13094652",
    "url": "https://openalex.org/W3153254740",
    "pdf_url": "https://www.mdpi.com/2071-1050/13/9/4652/pdf?version=1619075255",
    "venue": "Sustainability",
    "citation_count": 121,
    "fields_of_study": [
      "Sustainability",
      "European union",
      "Business",
      "Context (archaeology)",
      "Agriculture"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387217"
  },
  {
    "source": "openalex",
    "source_id": "W3121927947",
    "title": "Human-Centered Artificial Intelligence for Designing Accessible Cultural Heritage",
    "authors": [
      "Galena Pisoni",
      "Natalia D\u00edaz-Rodr\u00edguez",
      "Hannie Gijlers",
      "Linda Tonolli"
    ],
    "year": 2021,
    "abstract": "This paper reviews the literature concerning technology used for creating and delivering accessible museum and cultural heritage sites experiences. It highlights the importance of the delivery suited for everyone from different areas of expertise, namely interaction design, pedagogical and participatory design, and it presents how recent and future artificial intelligence (AI) developments can be used for this aim, i.e.,improving and widening online and in situ accessibility. From the literature review analysis, we articulate a conceptual framework that incorporates key elements that constitute museum and cultural heritage online experiences and how these elements are related to each other. Concrete opportunities for future directions empirical research for accessibility of cultural heritage contents are suggested and further discussed.",
    "doi": "10.3390/app11020870",
    "url": "https://openalex.org/W3121927947",
    "pdf_url": "https://www.mdpi.com/2076-3417/11/2/870/pdf?version=1611229675",
    "venue": "Applied Sciences",
    "citation_count": 144,
    "fields_of_study": [
      "Cultural heritage",
      "Citizen journalism",
      "Engineering",
      "Engineering ethics",
      "Sociology"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387239"
  },
  {
    "source": "openalex",
    "source_id": "W4300960556",
    "title": "Technology, Megatrends and Work: Thoughts on the Future of Business Ethics",
    "authors": [
      "Premilla D\u2019Cruz",
      "Shuili Du",
      "Ernesto Noronha",
      "K. Praveen Parboteeah",
      "Hannah Trittin\u2010Ulbrich",
      "Glen Whelan"
    ],
    "year": 2022,
    "abstract": "Abstract To commemorate 40 years since the founding of the Journal of Business Ethics, the editors in chief of the journal have invited the editors to provide commentaries on the future of business ethics. This essay comprises a selection of commentaries aimed at creating dialogue around the theme Technology, Megatrends and Work . Of all the profound changes in business, technology is perhaps the most ubiquitous. There is not a facet of our lives unaffected by internet technologies and artificial intelligence. The Journal of Business Ethics established a dedicated section that focuses on Technology and Business Ethics, yet issues related to this phenomenon run right through all the sections. Kirsten Martin, editor of the Technology and Business Ethics section, joins our interim social media editor, Hannah Trittin-UIbrich, to advance a human-centric approach to the development and application of digital technologies that places Business Ethics at centre of the analysis. For Shuili Du, technology is the defining condition for a new era of Corporate Social Responsibility\u2014CSR 3.0\u2014which she defines as \u201ca company\u2019s socially responsible strategies and practices that deal with key ethical and socio-technical issues associated with AI and related technologies on the one hand and leverage the power of AI and related technologies to tackle social and environmental problems on the other hand.\u201d It is not just technologies that are a determining feature of our lives but technology companies, an argument made by Glen Whelan as he examines Big Business and the need for a Big Business Ethics as we try to understand the impact of Big Tech on our post-work world. Indeed, as noted by Ernesto Noronha and Premilla D\u2019Cruz, megatrends in addition to advancement in technologies, namely globalization, the greening of economies, and changes in demographics and migration, are shaping the future for workers in ways previously unimaginable. Contributing to this important debate, Praveen Parboteeah considers the influence of another longstanding but oft overlooked megatrend, the role of religion in the workplace. Given the enormity of the influence of technology and other megatrends in our world, it is not surprising that this essay introduces ground-breaking ideas that speak to the future of business ethics research.",
    "doi": "10.1007/s10551-022-05240-9",
    "url": "https://openalex.org/W4300960556",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10551-022-05240-9.pdf",
    "venue": "Journal of Business Ethics",
    "citation_count": 98,
    "fields_of_study": [
      "Business ethics",
      "Quality of Life Research",
      "Work (physics)",
      "Engineering ethics",
      "Sociology"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387252"
  },
  {
    "source": "openalex",
    "source_id": "W4366588310",
    "title": "Human and artificial intelligence collaboration for socially shared regulation in learning",
    "authors": [
      "Sanna J\u00e4rvel\u00e4",
      "Andy Nguyen",
      "Allyson F. Hadwin"
    ],
    "year": 2023,
    "abstract": "Abstract Artificial intelligence (AI) has generated a plethora of new opportunities, potential and challenges for understanding and supporting learning. In this paper, we position human and AI collaboration for socially shared regulation (SSRL) in learning. Particularly, this paper reflects on the intersection of human and AI collaboration in SSRL research, which presents an exciting prospect for advancing our understanding and support of learning regulation. Our aim is to operationalize this human\u2010AI collaboration by introducing a novel trigger concept and a hybrid human\u2010AI shared regulation in learning (HASRL) model. Through empirical examples that present AI affordances for SSRL research, we demonstrate how humans and AI can synergistically work together to improve learning regulation. We argue that the integration of human and AI strengths via hybrid intelligence is critical to unlocking a new era in learning sciences research. Our proposed frameworks present an opportunity for empirical evidence and innovative designs that articulate the potential for human\u2010AI collaboration in facilitating effective SSRL in teaching and learning. Practitioner notes What is already known about this topic For collaborative learning to succeed, socially shared regulation has been acknowledged as a key factor. Artificial intelligence (AI) is a powerful and potentially disruptive technology that can reveal new insights to support learning. It is questionable whether traditional theories of how people learn are useful in the age of AI. What this paper adds Introduces a trigger concept and a hybrid Human\u2010AI Shared Regulation in Learning (HASRL) model to offer insights into how the human\u2010AI collaboration could occur to operationalize SSRL research. Demonstrates the potential use of AI to advance research and practice on socially shared regulation of learning. Provides clear suggestions for future human\u2010AI collaboration in learning and teaching aiming at enhancing human learning and regulatory skills. Implications for practice and/or policy Educational technology developers could utilize our proposed framework to better align technological and theoretical aspects for their design of adaptive support that can facilitate students' socially shared regulation of learning. Researchers and practitioners could benefit from methodological development incorporating human\u2010AI collaboration for capturing, processing and analysing multimodal data to examine and support learning regulation.",
    "doi": "10.1111/bjet.13325",
    "url": "https://openalex.org/W4366588310",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/bjet.13325",
    "venue": "British Journal of Educational Technology",
    "citation_count": 198,
    "fields_of_study": [
      "Operationalization",
      "Affordance",
      "Artificial intelligence",
      "Computer science",
      "Human intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387287"
  },
  {
    "source": "openalex",
    "source_id": "W4385417140",
    "title": "\u0397ow to Use Artificial Intelligence (AI) as a Resource, Methodological and Analysis Tool in Qualitative Research?",
    "authors": [
      "Prokopis Christou"
    ],
    "year": 2023,
    "abstract": "Artificial Intelligence (AI) has had far-reaching effects in research and the academic world. It has been used in many ways by the scientific community within the context of qualitative research, such as literature and systematic reviews, for conceptualization purposes, thematic and content analysis. It has however prompted concerns and questions about the potential for unreliable research, bias, and unethical behavior in the outcomes of AI-produced research. The purpose this paper is to examine the current use of AI in research, its strengths and limitations, dilemmas and ethical considerations from theoretical critical perspective principles, while delivering five key considerations for the appropriate, rigorous, and reliable use of AI in research practice. The first step is to become acquainted with the data generated by AI systems. The second is concerned with removing biased content and addressing ethical concerns when using AI, while the third is concerned with cross-referencing information generated by AI. The fourth step is to control the analysis process. The fifth and most important key consideration is the demonstration of cognitive input and skills by the researcher throughout the process of using AI in any qualitative research study and in reaching conclusions.",
    "doi": "10.46743/2160-3715/2023.6406",
    "url": "https://openalex.org/W4385417140",
    "pdf_url": "https://nsuworks.nova.edu/cgi/viewcontent.cgi?article=6406&context=tqr",
    "venue": "The Qualitative Report",
    "citation_count": 89,
    "fields_of_study": [
      "Conceptualization",
      "Qualitative research",
      "Thematic analysis",
      "Process (computing)",
      "Context (archaeology)"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387324"
  },
  {
    "source": "openalex",
    "source_id": "W4381684347",
    "title": "The Power of Artificial Intelligence in Recruitment: An Analytical Review of Current AI-Based Recruitment Strategies",
    "authors": [
      "Wael Abdulrahman Albassam"
    ],
    "year": 2023,
    "abstract": "Purpose: The aim of this study is to contribute to the understanding of the power of artificial intelligence (AI) in recruitment and to highlight the opportunities and challenges associated with its use. Theoretical framework: This paper provides a comprehensive analytical review of current AI-based recruitment strategies, drawing on both academic research and industry reports. Design/methodology/approach: The paper critically evaluates the potential benefits and drawbacks of using AI in recruitment and assesses the effectiveness of various AI-based recruitment strategies. Findings: The results indicate that AI-based recruitment strategies such as resume screening, candidate matching, video interviewing, chatbots, predictive analytics, gamification, virtual reality assessments, and social media screening offer significant potential benefits for organizations, including improved efficiency, cost savings, and better-quality hires. However, the use of AI in recruitment also raises ethical and legal concerns, including the potential for algorithmic bias and discrimination. Research, Practical &amp; Social implications: The study concludes by emphasizing the need for further research and development to ensure that AI-based recruitment strategies are effective, unbiased, and aligned with ethical and legal standards. Originality/value: The value of the study lies in its comprehensive exploration of AI in recruitment, synthesizing insights from academic and industry perspectives, and assessing the balance of potential benefits against ethical and legal concerns.",
    "doi": "10.26668/businessreview/2023.v8i6.2089",
    "url": "https://openalex.org/W4381684347",
    "pdf_url": "https://doi.org/10.26668/businessreview/2023.v8i6.2089",
    "venue": "International Journal of Professional Business Review",
    "citation_count": 81,
    "fields_of_study": [
      "Originality",
      "Value (mathematics)",
      "Quality (philosophy)",
      "Ethical issues",
      "Applications of artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387343"
  },
  {
    "source": "openalex",
    "source_id": "W4391820410",
    "title": "Digital transformation: A multidisciplinary perspective and future research agenda",
    "authors": [
      "Justin Paul",
      "Akiko Ueno",
      "Charles Dennis",
      "Eleftherios Alamanos",
      "Lucill J. Curtis",
      "Pantea Foroudi",
      "Agnieszka Kacprzak",
      "Werner H. Kunz",
      "Jonathan Liu",
      "Reza Marvi",
      "Sree Lekshmi Sreekumaran Nair",
      "Ozlem Ozdemir",
      "Eleonora Pantano",
      "\u0398\u03ac\u03bd\u03bf\u03c2 \u03a0\u03b1\u03c0\u03b1\u03b4\u03cc\u03c0\u03bf\u03c5\u03bb\u03bf\u03c2",
      "Olivia Petit",
      "Sapna Tyagi",
      "Jochen Wirtz"
    ],
    "year": 2024,
    "abstract": "Abstract Digital transformation has had an unprecedented influence on all sectors of business over the last decade. We are now entering an era characterized by the extensive digital transformation of businesses, society, and consumers. Therefore, digital transformation has become a pivotal focus for organizations across various sectors in recent years. Despite differing scholarly perspectives on the concept and elements of digital transformation, a consensus exists that it significantly impacts consumer decisions and necessitates organizational adaptation. Recent challenges such as the COVID\u201019 pandemic have further accelerated the need for digital transformation and its effects on consumers. This necessitates an editorial perspective on this most important topic to establish future research agenda encompassing the various dimensions of digital transformation. The purpose of this editorial perspective is to review research on digital transformation from a multidisciplinary viewpoint and provide insights into several key domains\u2014Internet\u2010of\u2010Things, social media, mobile apps, artificial intelligence, augmented and virtual reality, the metaverse, and corporate digital responsibility\u2014that are poised to fuel the pace of digital transformation. Each domain is analyzed through a lens of introduction, role, importance, multifaceted impact, and conclusions. Future research directions are suggested.",
    "doi": "10.1111/ijcs.13015",
    "url": "https://openalex.org/W4391820410",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/ijcs.13015",
    "venue": "International Journal of Consumer Studies",
    "citation_count": 141,
    "fields_of_study": [
      "Digital transformation",
      "Pace",
      "Multidisciplinary approach",
      "Perspective (graphical)",
      "Social media"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387365"
  },
  {
    "source": "openalex",
    "source_id": "W2971581810",
    "title": "Responsible AI: requirements and challenges",
    "authors": [
      "Malik Ghallab"
    ],
    "year": 2019,
    "abstract": null,
    "doi": "10.1186/s42467-019-0003-z",
    "url": "https://openalex.org/W2971581810",
    "pdf_url": "https://aiperspectives.springeropen.com/track/pdf/10.1186/s42467-019-0003-z",
    "venue": "AI Perspectives",
    "citation_count": 106,
    "fields_of_study": [
      "Interdependence",
      "Position paper",
      "Risk analysis (engineering)",
      "Position (finance)",
      "Business"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387384"
  },
  {
    "source": "openalex",
    "source_id": "W4392394652",
    "title": "Generative Artificial Intelligence in Education: From Deceptive to Disruptive.",
    "authors": [
      "Marc Alier",
      "Francisco Jos\u00e9 Garc\u00eda\u2010Pe\u00f1alvo",
      "Jorge D. Camba"
    ],
    "year": 2024,
    "abstract": "Generative Artificial Intelligence (GenAI) has emerged as a promising technology that can create original content, such as text, images, and sound. The use of GenAI in educational settings is becoming increasingly popular and offers a range of opportunities and challenges. This special issue explores the management and integration of GenAI in educational settings, including the ethical considerations, best practices, and opportunities. The potential of GenAI in education is vast. By using algorithms and data, GenAI can create original content that can be used to augment traditional teaching methods, creating a more interactive and personalized learning experience. In addition, GenAI can be utilized as an assessment tool and for providing feedback to students using generated content. For instance, it can be used to create custom quizzes, generate essay prompts, or even grade essays. The use of GenAI as an assessment tool can reduce the workload of teachers and help students receive prompt feedback on their work. Incorporating GenAI in educational settings also poses challenges related to academic integrity. With availability of GenAI models, students can use them to study or complete their homework assignments, which can raise concerns about the authenticity and authorship of the delivered work. Therefore, it is important to ensure that academic standards are maintained, and the originality of the student's work is preserved. This issue highlights the need for implementing ethical practices in the use of GenAI models and ensuring that the technology is used to support and not replace the student's learning experience.",
    "doi": "10.9781/ijimai.2024.02.011",
    "url": "https://openalex.org/W4392394652",
    "pdf_url": "https://doi.org/10.9781/ijimai.2024.02.011",
    "venue": "International Journal of Interactive Multimedia and Artificial Intelligence",
    "citation_count": 120,
    "fields_of_study": [
      "Computer science",
      "Generative grammar",
      "Artificial intelligence",
      "Data science"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387387"
  },
  {
    "source": "openalex",
    "source_id": "W4206349320",
    "title": "The social and ethical impacts of artificial intelligence in agriculture: mapping the agricultural AI literature",
    "authors": [
      "Mark Ryan"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1007/s00146-021-01377-9",
    "url": "https://openalex.org/W4206349320",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s00146-021-01377-9.pdf",
    "venue": "AI & Society",
    "citation_count": 132,
    "fields_of_study": [
      "Engineering ethics",
      "Sustainability",
      "Autonomy",
      "Thematic analysis",
      "Agriculture"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387411"
  },
  {
    "source": "openalex",
    "source_id": "W3177667502",
    "title": "Artificial Intelligence as a Service",
    "authors": [
      "Sebastian Lins",
      "Konstantin D. Pandl",
      "Heiner Teigeler",
      "Scott Thiebes",
      "C.P. Bayer",
      "Ali Sunyaev"
    ],
    "year": 2021,
    "abstract": "Artificial intelligence as a service, AIaaS, Artificial intelligence, Cloud computing, Machine learning as a service",
    "doi": "10.1007/s12599-021-00708-w",
    "url": "https://openalex.org/W3177667502",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s12599-021-00708-w.pdf",
    "venue": "Business & Information Systems Engineering",
    "citation_count": 105,
    "fields_of_study": [
      "Service (business)",
      "Computer science",
      "Artificial intelligence",
      "Engineering",
      "Business"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387416"
  },
  {
    "source": "openalex",
    "source_id": "W4283643667",
    "title": "Trust in Artificial Intelligence: Comparing Trust Processes Between Human and Automated Trustees in Light of Unfair Bias",
    "authors": [
      "Markus Langer",
      "Cornelius J. K\u00f6nig",
      "Caroline Back",
      "Victoria Hemsing"
    ],
    "year": 2022,
    "abstract": "Abstract Automated systems based on artificial intelligence (AI) increasingly support decisions with ethical implications where decision makers need to trust these systems. However, insights regarding trust in automated systems predominantly stem from contexts where the main driver of trust is that systems produce accurate outputs (e.g., alarm systems for monitoring tasks). It remains unclear whether what we know about trust in automated systems translates to application contexts where ethical considerations (e.g., fairness) are crucial in trust development. In personnel selection, as a sample context where ethical considerations are important, we investigate trust processes in light of a trust violation relating to unfair bias and a trust repair intervention. Specifically, participants evaluated preselection outcomes (i.e., sets of preselected applicants) by either a human or an automated system across twelve selection tasks. We additionally varied information regarding imperfection of the human and automated system. In task rounds five through eight, the preselected applicants were predominantly male, thus constituting a trust violation due to potential unfair bias. Before task round nine, participants received an excuse for the biased preselection (i.e., a trust repair intervention). The results of the online study showed that participants have initially less trust in automated systems. Furthermore, the trust violation and the trust repair intervention had weaker effects for the automated system. Those effects were partly stronger when highlighting system imperfection. We conclude that insights from classical areas of automation only partially translate to the many emerging application contexts of such systems where ethical considerations are central to trust processes.",
    "doi": "10.1007/s10869-022-09829-9",
    "url": "https://openalex.org/W4283643667",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10869-022-09829-9.pdf",
    "venue": "Journal of Business and Psychology",
    "citation_count": 91,
    "fields_of_study": [
      "Industrial and organizational psychology",
      "Task (project management)",
      "Excuse",
      "Context (archaeology)",
      "Psychology"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387421"
  },
  {
    "source": "openalex",
    "source_id": "W4382939841",
    "title": "Artificial Intelligence in K-12 Education: eliciting and reflecting on Swedish teachers' understanding of AI and its implications for teaching &amp; learning",
    "authors": [
      "Johanna Velander",
      "Mohammed Ahmed Taiye",
      "Nuno Otero",
      "Marcelo Milrad"
    ],
    "year": 2023,
    "abstract": null,
    "doi": "10.1007/s10639-023-11990-4",
    "url": "https://openalex.org/W4382939841",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10639-023-11990-4.pdf",
    "venue": "Education and Information Technologies",
    "citation_count": 123,
    "fields_of_study": [
      "Curriculum",
      "Literacy",
      "Mathematics education",
      "Educational technology",
      "Professional development"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387444"
  },
  {
    "source": "openalex",
    "source_id": "W2511953903",
    "title": "Evaluation in artificial intelligence: from task-oriented to ability-oriented measurement",
    "authors": [
      "Jos\u00e9 Hern\u00e1ndez\u2010Orallo"
    ],
    "year": 2016,
    "abstract": null,
    "doi": "10.1007/s10462-016-9505-7",
    "url": "https://openalex.org/W2511953903",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10462-016-9505-7.pdf",
    "venue": "Artificial Intelligence Review",
    "citation_count": 180,
    "fields_of_study": [
      "Computer science",
      "Task (project management)",
      "Artificial intelligence",
      "Adaptation (eye)",
      "Perspective (graphical)"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387447"
  },
  {
    "source": "openalex",
    "source_id": "W4399164841",
    "title": "Computer Science Curricula 2023",
    "authors": [
      "Amruth N. Kumar",
      "Rajendra K. Raj",
      "Sherif G. Aly",
      "Monica Anderson",
      "Brett A. Becker",
      "Richard Blumenthal",
      "Eric Eaton",
      "Susan L. Epstein",
      "Michael Goldweber",
      "Pankaj Jalote",
      "D. Lea",
      "Michael J. Oudshoorn",
      "Marcelo Pias",
      "Susan Reiser",
      "Christian Serv\u00edn",
      "Rahul Simha",
      "Titus Winters",
      "Qiao Xiang"
    ],
    "year": 2024,
    "abstract": null,
    "doi": "10.1145/3664191",
    "url": "https://openalex.org/W4399164841",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3664191",
    "venue": "ACM eBooks",
    "citation_count": 146,
    "fields_of_study": [
      "Curriculum",
      "Engineering ethics",
      "Computer science",
      "Mathematics education",
      "Engineering"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387453"
  },
  {
    "source": "openalex",
    "source_id": "W3041268394",
    "title": "Algorithmic fairness in education",
    "authors": [
      "Ren\u00e9 F. Kizilcec",
      "Hansol Lee"
    ],
    "year": 2022,
    "abstract": "Data-driven predictive models are increasingly used in education to support students, instructors, and administrators, which has raised concerns about the fairness of their predictions and uses of these algorithmic systems. In this introduction to algorithmic fairness in education, we draw parallels to prior literature on educational access, bias, and discrimination, and we examine core components of algorithmic systems (measurement, model learning, and action) to identify sources of bias and discrimination in the process of developing and deploying these systems. Statistical, similarity-based, and causal notions of fairness are reviewed and contrasted in how they apply in educational contexts. Recommendations for policymakers and developers of educational technology offer guidance for promoting algorithmic fairness in education.",
    "doi": "10.4324/9780429329067-10",
    "url": "https://openalex.org/W3041268394",
    "pdf_url": "https://api.taylorfrancis.com/content/chapters/edit/download?identifierName=doi&identifierValue=10.4324/9780429329067-10&type=chapterpdf",
    "venue": null,
    "citation_count": 116,
    "fields_of_study": [
      "Computer science",
      "Sociology"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387456"
  },
  {
    "source": "openalex",
    "source_id": "W4224030925",
    "title": "Reactions towards organizational change: a systematic literature review",
    "authors": [
      "Khai Wah Khaw",
      "Alhamzah Alnoor",
      "Hadi AL\u2010Abrrow",
      "Victor Tiberius",
      "Yuvaraj Ganesan",
      "Nadia A. Atshan"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1007/s12144-022-03070-6",
    "url": "https://openalex.org/W4224030925",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s12144-022-03070-6.pdf",
    "venue": "Current Psychology",
    "citation_count": 187,
    "fields_of_study": [
      "Extant taxon",
      "Categorization",
      "Psychology",
      "Resistance (ecology)",
      "Organizational change"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387469"
  },
  {
    "source": "openalex",
    "source_id": "W3112535338",
    "title": "Artificial Intelligence (AI) Deployments in Africa: Benefits, Challenges and Policy Dimensions",
    "authors": [
      "Arthur Gwagwa",
      "Erika Kraemer\u2010Mbula",
      "Nagla Rizk",
      "Isaac Rutenberg",
      "Jeremy de Beer"
    ],
    "year": 2020,
    "abstract": "The deployment of artificial intelligence (AI) technologies is proliferating on the African continent, but policy responses are still at their early stages. This article provides an overview of the main elements of AI deployment in Africa, AI's core benefits and challenges in African settings, and AI's core policy dimensions for the continent. It is argued that for AI to build, rather than undermine, socio-economic inclusion in African settings, policymakers need to be cognisant of the following key dimensions: gender equity, cultural and linguistic diversity, and labour market shifts.",
    "doi": "10.23962/10539/30361",
    "url": "https://openalex.org/W3112535338",
    "pdf_url": "http://wiredspace.wits.ac.za/bitstream/10539/30361/3/AJIC-Issue-26-2020-Gwagwa-et-al.pdf",
    "venue": "The African Journal of Information and Communication (AJIC)",
    "citation_count": 116,
    "fields_of_study": [
      "Software deployment",
      "Diversity (politics)",
      "Equity (law)",
      "Core (optical fiber)",
      "Inclusion (mineral)"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387473"
  },
  {
    "source": "openalex",
    "source_id": "W3119358510",
    "title": "Teasing out Artificial Intelligence in Medicine: An Ethical Critique of Artificial Intelligence and Machine Learning in Medicine",
    "authors": [
      "Mark Arnold"
    ],
    "year": 2021,
    "abstract": null,
    "doi": "10.1007/s11673-020-10080-1",
    "url": "https://openalex.org/W3119358510",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s11673-020-10080-1.pdf",
    "venue": "Journal of Bioethical Inquiry",
    "citation_count": 101,
    "fields_of_study": [
      "Beneficence",
      "Autonomy",
      "Paternalism",
      "Philosophy of medicine",
      "Medical law"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387484"
  },
  {
    "source": "openalex",
    "source_id": "W4385311368",
    "title": "Smart cities: the role of Internet of Things and machine learning in realizing a data-centric smart environment",
    "authors": [
      "Amin Ullah",
      "Syed Myhammad Anwar",
      "Jianqiang Li",
      "Lubna Nadeem",
      "Tariq Mahmood",
      "Amjad Rehman",
      "Tanzila Saba"
    ],
    "year": 2023,
    "abstract": null,
    "doi": "10.1007/s40747-023-01175-4",
    "url": "https://openalex.org/W4385311368",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s40747-023-01175-4.pdf",
    "venue": "Complex & Intelligent Systems",
    "citation_count": 199,
    "fields_of_study": [
      "Smart city",
      "Leverage (statistics)",
      "Big data",
      "Computer science",
      "Implementation"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387487"
  },
  {
    "source": "openalex",
    "source_id": "W3037105702",
    "title": "Approaches Based on Artificial Intelligence and the Internet of Intelligent Things to Prevent the Spread of COVID-19: Scoping Review",
    "authors": [
      "Aya Sedky Adly",
      "Afnan Sedky Adly",
      "Mahmoud Sedky Adly"
    ],
    "year": 2020,
    "abstract": "Background Artificial intelligence (AI) and the Internet of Intelligent Things (IIoT) are promising technologies to prevent the concerningly rapid spread of coronavirus disease (COVID-19) and to maximize safety during the pandemic. With the exponential increase in the number of COVID-19 patients, it is highly possible that physicians and health care workers will not be able to treat all cases. Thus, computer scientists can contribute to the fight against COVID-19 by introducing more intelligent solutions to achieve rapid control of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), the virus that causes the disease. Objective The objectives of this review were to analyze the current literature, discuss the applicability of reported ideas for using AI to prevent and control COVID-19, and build a comprehensive view of how current systems may be useful in particular areas. This may be of great help to many health care administrators, computer scientists, and policy makers worldwide. Methods We conducted an electronic search of articles in the MEDLINE, Google Scholar, Embase, and Web of Knowledge databases to formulate a comprehensive review that summarizes different categories of the most recently reported AI-based approaches to prevent and control the spread of COVID-19. Results Our search identified the 10 most recent AI approaches that were suggested to provide the best solutions for maximizing safety and preventing the spread of COVID-19. These approaches included detection of suspected cases, large-scale screening, monitoring, interactions with experimental therapies, pneumonia screening, use of the IIoT for data and information gathering and integration, resource allocation, predictions, modeling and simulation, and robotics for medical quarantine. Conclusions We found few or almost no studies regarding the use of AI to examine COVID-19 interactions with experimental therapies, the use of AI for resource allocation to COVID-19 patients, or the use of AI and the IIoT for COVID-19 data and information gathering/integration. Moreover, the adoption of other approaches, including use of AI for COVID-19 prediction, use of AI for COVID-19 modeling and simulation, and use of AI robotics for medical quarantine, should be further emphasized by researchers because these important approaches lack sufficient numbers of studies. Therefore, we recommend that computer scientists focus on these approaches, which are still not being adequately addressed.",
    "doi": "10.2196/19104",
    "url": "https://openalex.org/W3037105702",
    "pdf_url": "https://www.jmir.org/2020/8/e19104/PDF",
    "venue": "Journal of Medical Internet Research",
    "citation_count": 138,
    "fields_of_study": [
      "Coronavirus disease 2019 (COVID-19)",
      "Computer science",
      "Pandemic",
      "The Internet",
      "Control (management)"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387490"
  },
  {
    "source": "openalex",
    "source_id": "W3008680281",
    "title": "Structural racism in precision medicine: leaving no one behind",
    "authors": [
      "Lester Darryl Genevi\u00e8ve",
      "Andrea Martani",
      "David Shaw",
      "Bernice S. Elger",
      "Tenzin Wangmo"
    ],
    "year": 2020,
    "abstract": null,
    "doi": "10.1186/s12910-020-0457-8",
    "url": "https://openalex.org/W3008680281",
    "pdf_url": "https://bmcmedethics.biomedcentral.com/track/pdf/10.1186/s12910-020-0457-8",
    "venue": "BMC Medical Ethics",
    "citation_count": 120,
    "fields_of_study": [
      "Racism",
      "Philosophy of medicine",
      "Health care",
      "Health equity",
      "Public relations"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387525"
  },
  {
    "source": "openalex",
    "source_id": "W4386249236",
    "title": "ChatGPT Perpetuates Gender Bias in Machine Translation and Ignores Non-Gendered Pronouns: Findings across Bengali and Five other Low-Resource Languages",
    "authors": [
      "Sourojit Ghosh",
      "Aylin Caliskan"
    ],
    "year": 2023,
    "abstract": "In this multicultural age, language translation is one of the most performed tasks, and it is becoming increasingly AI-moderated and automated. As a novel AI system, ChatGPT claims to be proficient in machine translation tasks and in this paper, we put that claim to the test. Specifically, we examine ChatGPT's accuracy in translating between English and languages that exclusively use gender-neutral pronouns. We center this study around Bengali, the 7th most spoken language globally, but also generalize our findings across five other languages: Farsi, Malay, Tagalog, Thai, and Turkish. We find that ChatGPT perpetuates gender defaults and stereotypes assigned to certain occupations (e.g., man = doctor, woman = nurse) or actions (e.g., woman = cook, man = go to work), as it converts gender-neutral pronouns in languages to 'he' or 'she'. We also observe ChatGPT completely failing to translate the English gender-neutral singular pronoun 'they' into equivalent gender-neutral pronouns in other languages, as it produces translations that are incoherent and incorrect. While it does respect and provide appropriately gender-marked versions of Bengali words when prompted with gender information in English, ChatGPT appears to confer a higher respect to men than to women in the same occupation. We conclude that ChatGPT exhibits the same gender biases which have been demonstrated for tools like Google Translate or MS Translator, as we provide recommendations for a human centered approach for future designers of AI systems that perform machine translation to better accommodate such low-resource languages.",
    "doi": "10.1145/3600211.3604672",
    "url": "https://openalex.org/W4386249236",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3600211.3604672",
    "venue": null,
    "citation_count": 89,
    "fields_of_study": [
      "Bengali",
      "Computer science",
      "Pronoun",
      "Grammatical gender",
      "Machine translation"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387528"
  },
  {
    "source": "openalex",
    "source_id": "W2990278906",
    "title": "\u201cWhere\u2019s the I-O?\u201d Artificial Intelligence and Machine Learning in Talent Management Systems",
    "authors": [
      "Manuel F. Gonzalez",
      "John Capman",
      "Frederick L. Oswald",
      "Evan R. Theys",
      "David L. Tomczak"
    ],
    "year": 2019,
    "abstract": "Artificial intelligence (AI) and machine learning (ML) have seen widespread adoption by organizations seeking to identify and hire high-quality job applicants. Yet the volume, variety, and velocity of professional involvement among I-O psychologists remains relatively limited when it comes to developing and evaluating AI/ML applications for talent assessment and selection. Furthermore, there is a paucity of empirical research that investigates the reliability, validity, and fairness of AI/ML tools in organizational contexts. To stimulate future involvement and research, we share our review and perspective on the current state of AI/ML in talent assessment as well as its benefits and potential pitfalls; and in addressing the issue of fairness, we present experimental evidence regarding the potential for AI/ML to evoke adverse reactions from job applicants during selection procedures. We close by emphasizing increased collaboration among I-O psychologists, computer scientists, legal scholars, and members of other professional disciplines in developing, implementing, and evaluating AI/ML applications in organizational contexts.",
    "doi": "10.25035/pad.2019.03.005",
    "url": "https://openalex.org/W2990278906",
    "pdf_url": "https://scholarworks.bgsu.edu/cgi/viewcontent.cgi?article=1102&context=pad",
    "venue": "Personnel Assessment and Decisions",
    "citation_count": 101,
    "fields_of_study": [
      "Variety (cybernetics)",
      "Artificial intelligence",
      "Perspective (graphical)",
      "Personnel selection",
      "Knowledge management"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387551"
  },
  {
    "source": "openalex",
    "source_id": "W4387373263",
    "title": "Unveiling the Influence of Artificial Intelligence and Machine Learning on Financial Markets: A Comprehensive Analysis of AI Applications in Trading, Risk Management, and Financial Operations",
    "authors": [
      "Mohammad El Hajj",
      "Jamil Hammoud"
    ],
    "year": 2023,
    "abstract": "This study explores the adoption and impact of artificial intelligence (AI) and machine learning (ML) in financial markets, utilizing a mixed-methods approach that includes a quantitative survey and a qualitative analysis of existing research papers, reports, and articles. The quantitative results demonstrate the growing adoption of AI and ML technologies in financial institutions and their most common applications, such as algorithmic trading, risk management, fraud detection, credit scoring, and customer service. Additionally, the qualitative analysis identifies key themes, including AI and ML adoption trends, challenges and barriers to adoption, the role of regulation, workforce transformation, and ethical and social considerations. The study highlights the need for financial professionals to adapt their skills and for organizations to address challenges, such as data privacy concerns, regulatory compliance, and ethical considerations. The research contributes to the knowledge on AI and ML in finance, helping policymakers, regulators, and professionals understand their benefits and challenges.",
    "doi": "10.3390/jrfm16100434",
    "url": "https://openalex.org/W4387373263",
    "pdf_url": "https://www.mdpi.com/1911-8074/16/10/434/pdf?version=1696474078",
    "venue": "Journal of risk and financial management",
    "citation_count": 121,
    "fields_of_study": [
      "Financial services",
      "Workforce",
      "Finance",
      "Risk management",
      "Financial market"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387566"
  },
  {
    "source": "openalex",
    "source_id": "W2989612956",
    "title": "Opportunities and Risks for Citizen Science in the Age of Artificial Intelligence",
    "authors": [
      "Luigi Ceccaroni",
      "James Bibby",
      "Erin Roger",
      "Paul Flemons",
      "Katina Michael",
      "Laura L. Fagan",
      "Jessica L. Oliver"
    ],
    "year": 2019,
    "abstract": "Members of the public are making substantial contributions to science as citizen scientists, and advances in technologies have enabled citizens to make even more substantial contributions. Technologies that allow computers and machines to function in an intelligent manner, often referred to as artificial intelligence (AI), are now being applied in citizen science. Discussions about guidelines, responsibilities, and ethics of AI usage are already happening outside the field of citizen science. We suggest such considerations should also be explored carefully in the context of citizen science applications. To start the conversation, we offer the citizen science community an essay to introduce the state-of-play for AI in citizen science and its potential uses in the future. We begin by presenting a systematic overview of AI technologies currently being applied, highlighting exemplary projects for each technology type described. We then discuss how AI is likely to be increasingly utilised in citizen science into the future, and, through scenarios, we explore both future opportunities and potential risks. Lastly, we conclude by providing recommendations that warrant consideration by the citizen science community, such as developing a data stewardship plan to inform citizens in advance of plans and expected outcomes of using data for AI training, or adopting good practice around anonymity. Our intent is for this essay to lead to further critical discussions among citizen science practitioners, which is needed for responsible, ethical, and useful use of AI in citizen science.",
    "doi": "10.5334/cstp.241",
    "url": "https://openalex.org/W2989612956",
    "pdf_url": "http://theoryandpractice.citizenscienceassociation.org/articles/10.5334/cstp.241/galley/138/download/",
    "venue": "Citizen Science Theory and Practice",
    "citation_count": 105,
    "fields_of_study": [
      "Citizen science",
      "Stewardship (theology)",
      "Context (archaeology)",
      "Engineering ethics",
      "Conversation"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387583"
  },
  {
    "source": "openalex",
    "source_id": "W4226290207",
    "title": "A Survey of Algorithmic Recourse: Contrastive Explanations and Consequential Recommendations",
    "authors": [
      "Amir-Hossein Karimi",
      "Gilles Barthe",
      "Bernhard Sch\u00f6lkopf",
      "Isabel Valera"
    ],
    "year": 2022,
    "abstract": "Machine learning is increasingly used to inform decision making in sensitive situations where decisions have consequential effects on individuals\u2019 lives. In these settings, in addition to requiring models to be accurate and robust, socially relevant values such as fairness, privacy, accountability, and explainability play an important role in the adoption and impact of said technologies. In this work, we focus on algorithmic recourse , which is concerned with providing explanations and recommendations to individuals who are unfavorably treated by automated decision-making systems. We first perform an extensive literature review, and align the efforts of many authors by presenting unified definitions, formulations, and solutions to recourse. Then, we provide an overview of the prospective research directions toward which the community may engage, challenging existing assumptions and making explicit connections to other ethical challenges such as security, privacy, and fairness.",
    "doi": "10.1145/3527848",
    "url": "https://openalex.org/W4226290207",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3527848",
    "venue": "ACM Computing Surveys",
    "citation_count": 118,
    "fields_of_study": [
      "Computer science",
      "Accountability",
      "Focus (optics)",
      "Work (physics)",
      "Management science"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387604"
  },
  {
    "source": "openalex",
    "source_id": "W4381686136",
    "title": "Enhancing Student Engagement: Harnessing \u201cAIED\u201d\u2019s Power in Hybrid Education\u2014A Review Analysis",
    "authors": [
      "Amjad Almusaed",
      "Asaad Almssad",
      "\u0130brahim Yitmen",
      "Raad Z. Homod"
    ],
    "year": 2023,
    "abstract": "Hybrid learning is a complex combination of face-to-face and online learning. This model combines the use of multimedia materials with traditional classroom work. Virtual hybrid learning is employed alongside face-to-face methods. That aims to investigate using Artificial Intelligence (AI) to increase student engagement in hybrid learning settings. Educators are confronted with contemporary issues in maintaining their students\u2019 interest and motivation as the popularity of online and hybrid education continues to grow, where many educational institutions are adopting this model due to its flexibility, student-teacher engagement, and peer-to-peer interaction. AI will help students communicate, collaborate, and receive real-time feedback, all of which are challenges in education. This article examines the advantages and disadvantages of hybrid education and the optimal approaches for incorporating Artificial Intelligence (AI) in educational settings. The research findings suggest that using AI can revolutionize hybrid education, as it enhances both student and instructor autonomy while fostering a more engaging and interactive learning environment.",
    "doi": "10.3390/educsci13070632",
    "url": "https://openalex.org/W4381686136",
    "pdf_url": "https://www.mdpi.com/2227-7102/13/7/632/pdf?version=1687687644",
    "venue": "Education Sciences",
    "citation_count": 199,
    "fields_of_study": [
      "Popularity",
      "Flexibility (engineering)",
      "Blended learning",
      "Autonomy",
      "Student engagement"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387620"
  },
  {
    "source": "openalex",
    "source_id": "W4383817745",
    "title": "Artificial Intelligence and Public Health: Evaluating ChatGPT Responses to Vaccination Myths and Misconceptions",
    "authors": [
      "Giovanna Deiana",
      "Marco Dettori",
      "Antonella Arghittu",
      "Antonio Azara",
      "Giovanni Gabutti",
      "Paolo Castiglia"
    ],
    "year": 2023,
    "abstract": "Artificial intelligence (AI) tools, such as ChatGPT, are the subject of intense debate regarding their possible applications in contexts such as health care. This study evaluates the Correctness, Clarity, and Exhaustiveness of the answers provided by ChatGPT on the topic of vaccination. The World Health Organization\u2019s 11 \u201cmyths and misconceptions\u201d about vaccinations were administered to both the free (GPT-3.5) and paid version (GPT-4.0) of ChatGPT. The AI tool\u2019s responses were evaluated qualitatively and quantitatively, in reference to those myth and misconceptions provided by WHO, independently by two expert Raters. The agreement between the Raters was significant for both versions (p of K &lt; 0.05). Overall, ChatGPT responses were easy to understand and 85.4% accurate although one of the questions was misinterpreted. Qualitatively, the GPT-4.0 responses were superior to the GPT-3.5 responses in terms of Correctness, Clarity, and Exhaustiveness (\u0394 = 5.6%, 17.9%, 9.3%, respectively). The study shows that, if appropriately questioned, AI tools can represent a useful aid in the health care field. However, when consulted by non-expert users, without the support of expert medical advice, these tools are not free from the risk of eliciting misleading responses. Moreover, given the existing social divide in information access, the improved accuracy of answers from the paid version raises further ethical issues.",
    "doi": "10.3390/vaccines11071217",
    "url": "https://openalex.org/W4383817745",
    "pdf_url": "https://www.mdpi.com/2076-393X/11/7/1217/pdf?version=1688973439",
    "venue": "Vaccines",
    "citation_count": 149,
    "fields_of_study": [
      "CLARITY",
      "Correctness",
      "Health care",
      "Mythology",
      "Field (mathematics)"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387637"
  },
  {
    "source": "openalex",
    "source_id": "W4390638955",
    "title": "Artificial intelligence (AI) learning tools in K-12 education: A\u00a0scoping review",
    "authors": [
      "Iris Heung Yue Yim",
      "Jiahong Su"
    ],
    "year": 2024,
    "abstract": "Abstract Artificial intelligence (AI) literacy is a global strategic objective in education. However, little is known about how AI should be taught. In this paper, 46 studies in academic conferences and journals are reviewed to investigate pedagogical strategies, learning tools, assessment methods in AI literacy education in K-12 contexts, and students\u2019 learning outcomes. The investigation reveals that the promotion of AI literacy education has seen significant progress in the past two decades. This highlights that intelligent agents, including Google\u2019s Teachable Machine, Learning ML, and Machine Learning for Kids, are age-appropriate tools for AI literacy education in K-12 contexts. Kindergarten students can benefit from learning tools such as PopBots, while software devices, such as Scratch and Python, which help to develop the computational thinking of AI algorithms, can be introduced to both primary and secondary schools. The research shows that project-based, human\u2013computer collaborative learning and play- and game-based approaches, with constructivist methodologies, have been applied frequently in AI literacy education. Cognitive, affective, and behavioral learning outcomes, course satisfaction and soft skills acquisition have been reported. The paper informs educators of appropriate learning tools, pedagogical strategies, assessment methodologies in AI literacy education, and students\u2019 learning outcomes. Research implications and future research directions within the K-12 context are also discussed.",
    "doi": "10.1007/s40692-023-00304-9",
    "url": "https://openalex.org/W4390638955",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s40692-023-00304-9.pdf",
    "venue": "Journal of Computers in Education",
    "citation_count": 142,
    "fields_of_study": [
      "Computer science",
      "Artificial intelligence",
      "Literacy",
      "Learning sciences",
      "Mathematics education"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387658"
  },
  {
    "source": "openalex",
    "source_id": "W2951969346",
    "title": "Business and the Ethical Implications of Technology: Introduction to the Symposium",
    "authors": [
      "Kirsten Martin",
      "Katie Shilton",
      "J. Allen Smith"
    ],
    "year": 2019,
    "abstract": null,
    "doi": "10.1007/s10551-019-04213-9",
    "url": "https://openalex.org/W2951969346",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10551-019-04213-9.pdf",
    "venue": "Journal of Business Ethics",
    "citation_count": 95,
    "fields_of_study": [
      "Business ethics",
      "Engineering ethics",
      "Ethics of technology",
      "Value (mathematics)",
      "Sociology"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387679"
  },
  {
    "source": "openalex",
    "source_id": "W4283644014",
    "title": "Human-Centered Artificial Intelligence: The Superlative Approach to Achieve Sustainable Development Goals in the Fourth Industrial Revolution",
    "authors": [
      "David Mhlanga"
    ],
    "year": 2022,
    "abstract": "Artificial intelligence (AI) is currently being developed by large corporations, and governments all over the world are yearning for it. AI isn\u2019t a futuristic concept; it is already here, and it is being implemented in a range of industries. Finance, national security, health care, criminal justice, transportation, and smart cities are all examples of this. There are countless examples of AI having a substantial impact on the world and complementing human abilities. However, due to the immense societal ramifications of these technologies, AI is on the verge of disrupting a host of industries, so the technique by which AI systems are created must be better understood. The goal of the study was to look at what it meant to be human-centred, how to create human-centred AI, and what considerations should be made for human-centred AI to achieve sustainability and the SDGs. Using a systematic literature review technique, the study discovered that a human-centred AI strategy strives to create and implement AI systems in ways that benefit mankind and serve their interests. The study also found that a human-in-the-loop concept should be used to develop procedures for creating human-centred AI, as well as other initiatives, such as the promotion of AI accountability, encouraging businesses to use autonomy wisely, to motivate businesses to be aware of human and algorithmic biases, to ensure that businesses prioritize customers, and form multicultural teams to tackle AI research. The study concluded with policy recommendations for human-centred AI to help accomplish the SDGs, including expanding government AI investments, addressing data and algorithm biases, and resolving data access issues, among other things.",
    "doi": "10.3390/su14137804",
    "url": "https://openalex.org/W4283644014",
    "pdf_url": "https://www.mdpi.com/2071-1050/14/13/7804/pdf?version=1656331391",
    "venue": "Sustainability",
    "citation_count": 104,
    "fields_of_study": [
      "Accountability",
      "Autonomy",
      "Promotion (chess)",
      "Sustainability",
      "Sustainable development"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387682"
  },
  {
    "source": "openalex",
    "source_id": "W4387012889",
    "title": "Machine learning in precision diabetes care and cardiovascular risk prediction",
    "authors": [
      "Evangelos K. Oikonomou",
      "Rohan Khera"
    ],
    "year": 2023,
    "abstract": null,
    "doi": "10.1186/s12933-023-01985-3",
    "url": "https://openalex.org/W4387012889",
    "pdf_url": "https://cardiab.biomedcentral.com/counter/pdf/10.1186/s12933-023-01985-3",
    "venue": "Cardiovascular Diabetology",
    "citation_count": 126,
    "fields_of_study": [
      "Medicine",
      "Context (archaeology)",
      "Artificial intelligence",
      "Precision medicine",
      "Risk analysis (engineering)"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387706"
  },
  {
    "source": "openalex",
    "source_id": "W4391256306",
    "title": "How should we change teaching and assessment in response to increasingly powerful generative Artificial Intelligence? Outcomes of the ChatGPT teacher survey",
    "authors": [
      "Matt Bower",
      "Jodie Torrington",
      "Jennifer W. M. Lai",
      "Peter Petocz",
      "Mark Alfano"
    ],
    "year": 2024,
    "abstract": "Abstract There has been widespread media commentary about the potential impact of generative Artificial Intelligence (AI) such as ChatGPT on the Education field, but little examination at scale of how educators believe teaching and assessment should change as a result of generative AI. This mixed methods study examines the views of educators ( n = 318) from a diverse range of teaching levels, experience levels, discipline areas, and regions about the impact of AI on teaching and assessment, the ways that they believe teaching and assessment should change, and the key motivations for changing their practices. The majority of teachers felt that generative AI would have a major or profound impact on teaching and assessment, though a sizeable minority felt it would have a little or no impact. Teaching level, experience, discipline area, region, and gender all significantly influenced perceived impact of generative AI on teaching and assessment. Higher levels of awareness of generative AI predicted higher perceived impact, pointing to the possibility of an \u2018ignorance effect\u2019. Thematic analysis revealed the specific curriculum, pedagogy, and assessment changes that teachers feel are needed as a result of generative AI, which centre around learning with AI, higher-order thinking, ethical values, a focus on learning processes and face-to-face relational learning. Teachers were most motivated to change their teaching and assessment practices to increase the performance expectancy of their students and themselves. We conclude by discussing the implications of these findings in a world with increasingly prevalent AI.",
    "doi": "10.1007/s10639-023-12405-0",
    "url": "https://openalex.org/W4391256306",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10639-023-12405-0.pdf",
    "venue": "Education and Information Technologies",
    "citation_count": 129,
    "fields_of_study": [
      "Generative grammar",
      "Curriculum",
      "Psychology",
      "Ignorance",
      "Teaching method"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387709"
  },
  {
    "source": "openalex",
    "source_id": "W4385416665",
    "title": "The Power of Generative AI: A Review of Requirements, Models, Input\u2013Output Formats, Evaluation Metrics, and Challenges",
    "authors": [
      "Ajay Bandi",
      "Pydi Venkata Satya Ramesh Adapa",
      "Yudu Eswar Vinay Pratap Kumar Kuchi"
    ],
    "year": 2023,
    "abstract": "Generative artificial intelligence (AI) has emerged as a powerful technology with numerous applications in various domains. There is a need to identify the requirements and evaluation metrics for generative AI models designed for specific tasks. The purpose of the research aims to investigate the fundamental aspects of generative AI systems, including their requirements, models, input\u2013output formats, and evaluation metrics. The study addresses key research questions and presents comprehensive insights to guide researchers, developers, and practitioners in the field. Firstly, the requirements necessary for implementing generative AI systems are examined and categorized into three distinct categories: hardware, software, and user experience. Furthermore, the study explores the different types of generative AI models described in the literature by presenting a taxonomy based on architectural characteristics, such as variational autoencoders (VAEs), generative adversarial networks (GANs), diffusion models, transformers, language models, normalizing flow models, and hybrid models. A comprehensive classification of input and output formats used in generative AI systems is also provided. Moreover, the research proposes a classification system based on output types and discusses commonly used evaluation metrics in generative AI. The findings contribute to advancements in the field, enabling researchers, developers, and practitioners to effectively implement and evaluate generative AI models for various applications. The significance of the research lies in understanding that generative AI system requirements are crucial for effective planning, design, and optimal performance. A taxonomy of models aids in selecting suitable options and driving advancements. Classifying input\u2013output formats enables leveraging diverse formats for customized systems, while evaluation metrics establish standardized methods to assess model quality and performance.",
    "doi": "10.3390/fi15080260",
    "url": "https://openalex.org/W4385416665",
    "pdf_url": "https://www.mdpi.com/1999-5903/15/8/260/pdf?version=1690812126",
    "venue": "Future Internet",
    "citation_count": 489,
    "fields_of_study": [
      "Computer science",
      "Generative grammar",
      "Field (mathematics)",
      "Taxonomy (biology)",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387732"
  },
  {
    "source": "openalex",
    "source_id": "W2981124546",
    "title": "Psychosocial Factors Affecting Artificial Intelligence Adoption in Health Care in China: Cross-Sectional Study",
    "authors": [
      "Tiantian Ye",
      "Jiaolong Xue",
      "Mingguang He",
      "Jing Gu",
      "Haotian Lin",
      "Xu Bin",
      "Yu Cheng"
    ],
    "year": 2019,
    "abstract": "Background Poor quality primary health care is a major issue in China, particularly in blindness prevention. Artificial intelligence (AI) could provide early screening and accurate auxiliary diagnosis to improve primary care services and reduce unnecessary referrals, but the application of AI in medical settings is still an emerging field. Objective This study aimed to investigate the general public\u2019s acceptance of ophthalmic AI devices, with reference to those already used in China, and the interrelated influencing factors that shape people\u2019s intention to use these devices. Methods We proposed a model of ophthalmic AI acceptance based on technology acceptance theories and variables from other health care\u2013related studies. The model was verified via a 32-item questionnaire with 7-point Likert scales completed by 474 respondents (nationally random sampled). Structural equation modeling was used to evaluate item and construct reliability and validity via a confirmatory factor analysis, and the model\u2019s path effects, significance, goodness of fit, and mediation and moderation effects were analyzed. Results Standardized factor loadings of items were between 0.583 and 0.876. Composite reliability of 9 constructs ranged from 0.673 to 0.841. The discriminant validity of all constructs met the Fornell and Larcker criteria. Model fit indicators such as standardized root mean square residual (0.057), comparative fit index (0.915), and root mean squared error of approximation (0.049) demonstrated good fit. Intention to use (R2=0.515) is significantly affected by subjective norms (beta=.408; P&lt;.001), perceived usefulness (beta=.336; P=.03), and resistance bias (beta=\u2013.237; P=.02). Subjective norms and perceived behavior control had an indirect impact on intention to use through perceived usefulness and perceived ease of use. Eye health consciousness had an indirect positive effect on intention to use through perceived usefulness. Trust had a significant moderation effect (beta=\u2013.095; P=.049) on the effect path of perceived usefulness to intention to use. Conclusions The item, construct, and model indicators indicate reliable interpretation power and help explain the levels of public acceptance of ophthalmic AI devices in China. The influence of subjective norms can be linked to Confucian culture, collectivism, authoritarianism, and conformity mentality in China. Overall, the use of AI in diagnostics and clinical laboratory analysis is underdeveloped, and the Chinese public are generally mistrustful of medical staff and the Chinese medical system. Stakeholders such as doctors and AI suppliers should therefore avoid making misleading or over-exaggerated claims in the promotion of AI health care products.",
    "doi": "10.2196/14316",
    "url": "https://openalex.org/W2981124546",
    "pdf_url": "https://www.jmir.org/2019/10/e14316/PDF",
    "venue": "Journal of Medical Internet Research",
    "citation_count": 127,
    "fields_of_study": [
      "Structural equation modeling",
      "Confirmatory factor analysis",
      "Psychosocial",
      "Psychology",
      "Construct validity"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387758"
  },
  {
    "source": "openalex",
    "source_id": "W4385168292",
    "title": "Summary for Policymakers",
    "authors": [
      "Jim Skea",
      "P.R. Shukla",
      "Andy Reisinger",
      "Raphael Slade",
      "Minal Pathak",
      "Alaa Al Khourdajie",
      "Ren\u00e9e van Diemen",
      "Amjad Abdulla",
      "Keigo Akimoto",
      "Mustafa Babiker",
      "Quan Bai",
      "I. Bashmakov",
      "Christopher Bataille",
      "G\u00f6ran Berndes",
      "Gabriel Blanco",
      "Kornelis Blok",
      "Mercedes Bustamante",
      "Edward Byers",
      "Luisa F. Cabeza",
      "Katherine Calvin",
      "Carlo Carraro",
      "Leon Clarke",
      "Annette Cowie",
      "Felix Creutzig",
      "Diriba Korecha Dadi",
      "Dipak Dasgupta",
      "Heleen de Coninck",
      "Fatima Denton",
      "Shobhakar Dhakal",
      "Navroz K. Dubash",
      "Oliver Geden",
      "Michael Grubb",
      "C\u00e9line Guivarch",
      "Sumana Gupta",
      "Andrea N. Hahmann",
      "Kirsten Halsn\u00e6s",
      "Paulina Jaramillo",
      "Kejun Jiang",
      "Frank Jotzo",
      "Tae Yong Jung",
      "Suzana Kahn Ribeiro",
      "Smail Khennas",
      "\u015eiir K\u0131lk\u0131\u015f",
      "Silvia Kreibiehl",
      "Volker Krey",
      "Elmar Kriegler",
      "William F. Lamb",
      "Franck Lecocq",
      "Shuaib Lwasa",
      "Nagmeldin Mahmoud",
      "Cheikh Mbow",
      "David McCollum",
      "Jan C. Minx",
      "Catherine Mitchell",
      "Rachid Mrabet",
      "Yacob Mulugetta",
      "G.J. Nabuurs",
      "Gregory F. Nemet",
      "Peter J. Newman",
      "Leila Niamir",
      "Lennart Nilsson",
      "Sudarmanto Budi Nugroho",
      "Chukwumerije Okereke",
      "Shonali Pachauri",
      "Anthony Patt",
      "Ram\u00f3n Pichs-Madruga",
      "Joana Portugal\u2010Pereira",
      "Lavanya Rajamani",
      "Keywan Riahi",
      "Joyashree Roy",
      "Yamina Saheb",
      "Roberto Schaeffer",
      "Karen C. Seto",
      "Shreya Some",
      "Linda Steg",
      "Ferenc L. T\u00f3th",
      "Di\u00e1na \u00dcrge-Vorsatz",
      "Detlef P. van Vuuren",
      "Elena Verdolini",
      "Purvi Vyas",
      "Yi\u2010Ming Wei",
      "Mariama Williams"
    ],
    "year": 2023,
    "abstract": "The Working Group III (WGIII) contribution to the IPCC\u2019s Sixth Assessment Report (AR6) assesses literature on the scientific, technological, environmental, economic and social aspects of mitigation of climate change.The report reflects new findings in the relevant literature and builds on previous IPCC reports, including the WGIII contribution to the IPCC\u2019s Fifth Assessment Report (AR5), the WGI and WGII contributions to AR6 and the three Special Reports in the Sixth Assessment cycle, as well as other UN assessments.",
    "doi": "10.1017/9781009157926.001",
    "url": "https://openalex.org/W4385168292",
    "pdf_url": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/ABC31CEA863CB6AD8FEB6911A872B321/stamped-9781009157933pre2_3-48.pdf/summary-for-policymakers.pdf",
    "venue": "Cambridge University Press eBooks",
    "citation_count": 510,
    "fields_of_study": [
      "Action (physics)",
      "Content (measure theory)",
      "Computer science",
      "Mathematics",
      "Physics"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387809"
  },
  {
    "source": "openalex",
    "source_id": "W4392378814",
    "title": "Opportunities, challenges, and benefits of AI innovation in government services: a review",
    "authors": [
      "Khalifa Alhosani",
      "Saadat M. Alhashmi"
    ],
    "year": 2024,
    "abstract": "Abstract Artificial intelligence (AI) has emerged as an excellent tool across multiple industries and holds great promise for the government, society, and economy. However, the absence of a distinct consensus regarding the definition and scope of artificial intelligence hinders its practical implementation in government settings. This article examines the various methodologies, emphases, and goals within artificial intelligence, emphasizing its ability to enhance human capabilities in critical situations. Considering the present advantages and enhanced productivity brought about by AI adoption in trailblazing government departments, this study explores the possible benefits and limitations of AI usage in the public sector. By looking at the cross-disciplinary difficulties of public AI applications, such as language hurdles and service delays, this study highlights the necessity for a thorough knowledge of the risks, impediments, and incentives of employing AI for government services. The study hopes to provide insight into AI research's ultimate aims, including object manipulation, natural language processing, and reasoning. This study emphasizes the potential for greater productivity, simplified procedures, and reduced obligations by analyzing the pros and cons of using AI in the public sector. Further, organizational theory is considered a tool for figuring out how to deal with challenges and maximize possibilities associated with AI deployment. The theory is used as the conceptual framework to understand the benefits, opportunities, and challenges involved in using AI when providing government services. The results of this research help us better understand how AI may revolutionize public service delivery by stimulating new ideas and improving efficiency. This study covers critical questions about organizational theory's role in improving government AI adoption, the challenges governments have in adopting AI, and the potential benefits AI might offer public service delivery. The research recommends a strategic approach to AI adoption in the public sector, considering organizational, ethical, and societal implications while recognizing the possibility of AI's transformative impacts on governments' service provision.",
    "doi": "10.1007/s44163-024-00111-w",
    "url": "https://openalex.org/W4392378814",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s44163-024-00111-w.pdf",
    "venue": "Discover Artificial Intelligence",
    "citation_count": 86,
    "fields_of_study": [
      "Government (linguistics)",
      "Business",
      "Knowledge management",
      "Computer science",
      "Philosophy"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387820"
  },
  {
    "source": "openalex",
    "source_id": "W2579952554",
    "title": "The Vision of \u201cIndustrie 4.0\u201d in the Making\u2014a Case of Future Told, Tamed, and Traded",
    "authors": [
      "Sabine Pfeiffer"
    ],
    "year": 2017,
    "abstract": "Since industrial trade fair Hannover Messe 2011, the term \"Industrie 4.0\" has ignited a vision of a new Industrial Revolution and has been inspiring a lively, ongoing debate among the German public about the future of work, and hence society, ever since. The discourse around this vision of the future eventually spread to other countries, with public awareness reaching a temporary peak in 2016 when the World Economic Forum's meeting in Davos was held with the motto \"Mastering the Fourth Industrial Revolution.\" How is it possible for a vision originally established by three German engineers to unfold and bear fruit at a global level in such a short period of time? This article begins with a summary of the key ideas that are discussed under the label Industrie 4.0. The main purpose, based on an in-depth discourse analysis, is to debunk the myth about the origin of this powerful vision and to trace the narrative back to the global economic crisis in 2009 and thus to the real actors, central discourse patterns, and hidden intentions of this vision of a new Industrial Revolution. In conclusion, the discourse analysis reveals that this is not a case of visioneering but one of a future told, tamed, and traded.",
    "doi": "10.1007/s11569-016-0280-3",
    "url": "https://openalex.org/W2579952554",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007%2Fs11569-016-0280-3.pdf",
    "venue": "NanoEthics",
    "citation_count": 310,
    "fields_of_study": [
      "German",
      "Philosophy of technology",
      "Industrial Revolution",
      "Narrative",
      "Mythology"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387849"
  },
  {
    "source": "openalex",
    "source_id": "W3176588943",
    "title": "Questioning Racial and Gender Bias in AI-based Recommendations: Do Espoused National Cultural Values Matter?",
    "authors": [
      "Manjul Gupta",
      "Carlos M. Parra",
      "Denis Dennehy"
    ],
    "year": 2021,
    "abstract": null,
    "doi": "10.1007/s10796-021-10156-2",
    "url": "https://openalex.org/W3176588943",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10796-021-10156-2.pdf",
    "venue": "Information Systems Frontiers",
    "citation_count": 98,
    "fields_of_study": [
      "Realm",
      "Psychology",
      "Affect (linguistics)",
      "Social psychology",
      "Masculinity"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387869"
  },
  {
    "source": "openalex",
    "source_id": "W4304142408",
    "title": "Does AI Debias Recruitment? Race, Gender, and AI\u2019s \u201cEradication of Difference\u201d",
    "authors": [
      "Eleanor Drage",
      "Kerry Mackereth"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1007/s13347-022-00543-1",
    "url": "https://openalex.org/W4304142408",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s13347-022-00543-1.pdf",
    "venue": "Philosophy & Technology",
    "citation_count": 89,
    "fields_of_study": [
      "Race (biology)",
      "Meritocracy",
      "Categorization",
      "Power (physics)",
      "Outsourcing"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387873"
  },
  {
    "source": "openalex",
    "source_id": "W2760844412",
    "title": "Learning to Generalize: Meta-Learning for Domain Generalization",
    "authors": [
      "Da Li",
      "Yongxin Yang",
      "Yi-Zhe Song",
      "Timothy M. Hospedales"
    ],
    "year": 2017,
    "abstract": "Domain shift refers to the well known problem that a model trained in one source domain performs poorly when applied to a target domain with different statistics. {Domain Generalization} (DG) techniques attempt to alleviate this issue by producing models which by design generalize well to novel testing domains. We propose a novel {meta-learning} method for domain generalization. Rather than designing a specific model that is robust to domain shift as in most previous DG work, we propose a model agnostic training procedure for DG. Our algorithm simulates train/test domain shift during training by synthesizing virtual testing domains within each mini-batch. The meta-optimization objective requires that steps to improve training domain performance should also improve testing domain performance. This meta-learning procedure trains models with good generalization ability to novel domains. We evaluate our method and achieve state of the art results on a recent cross-domain image classification benchmark, as well demonstrating its potential on two classic reinforcement learning tasks.",
    "doi": "10.48550/arxiv.1710.03463",
    "url": "https://openalex.org/W2760844412",
    "pdf_url": "https://arxiv.org/pdf/1710.03463",
    "venue": "arXiv (Cornell University)",
    "citation_count": 113,
    "fields_of_study": [
      "Generalization",
      "Computer science",
      "Domain (mathematical analysis)",
      "Benchmark (surveying)",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387876"
  },
  {
    "source": "openalex",
    "source_id": "W3007819350",
    "title": "Ethical concerns around use of artificial intelligence in health care research from the perspective of patients with meningioma, caregivers and health care providers: a qualitative study",
    "authors": [
      "Melissa D. McCradden",
      "Ami Baba",
      "Ashirbani Saha",
      "Sidra Ahmad",
      "Kanwar Boparai",
      "Pantea Fadaiefard",
      "Michael D. Cusimano"
    ],
    "year": 2020,
    "abstract": "In this preliminary study, patients and caregivers reported a mixture of hopefulness and concern around the use of AI in health care research, whereas providers were generally more skeptical. These findings provide a point of departure for institutions adopting health AI solutions to consider the ethical implications of this work by understanding stakeholders' perspectives.",
    "doi": "10.9778/cmajo.20190151",
    "url": "https://openalex.org/W3007819350",
    "pdf_url": "http://www.cmajopen.ca/content/8/1/E90.full.pdf",
    "venue": "CMAJ Open",
    "citation_count": 96,
    "fields_of_study": [
      "Snowball sampling",
      "Health care",
      "Qualitative research",
      "Medicine",
      "Delegate"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387894"
  },
  {
    "source": "openalex",
    "source_id": "W2787318954",
    "title": "Using futures methods to create transformative spaces: visions of a good Anthropocene in southern Africa",
    "authors": [
      "Laura Pereira",
      "Tanja Hichert",
      "Maike Hamann",
      "Rika Preiser",
      "Reinette Biggs"
    ],
    "year": 2018,
    "abstract": "CITATION: Pereira, L. M., et al. 2018. Using futures methods to create transformative spaces : visions of a good Anthropocene in southern Africa. Ecology and Society, 23(1):19, doi:10.5751/ES-09907-230119.",
    "doi": "10.5751/es-09907-230119",
    "url": "https://openalex.org/W2787318954",
    "pdf_url": "https://www.ecologyandsociety.org/vol23/iss1/art19/ES-2017-9907.pdf",
    "venue": "Ecology and Society",
    "citation_count": 211,
    "fields_of_study": [
      "Anthropocene",
      "Vision",
      "Transformative learning",
      "Futures contract",
      "Environmental ethics"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387905"
  },
  {
    "source": "openalex",
    "source_id": "W4390564972",
    "title": "The impact of AI on accounting practices: A review: Exploring how artificial intelligence is transforming traditional accounting methods and financial reporting",
    "authors": [
      "Beryl Odonkor",
      "Simon Kaggwa",
      "Prisca Ugomma Uwaoma",
      "Azeez Olanipekun Hassan",
      "Oluwatoyin Ajoke Farayola"
    ],
    "year": 2024,
    "abstract": "This paper delves into the transformative impact of Artificial Intelligence (AI) on traditional accounting practices, examining its role in reshaping financial reporting, auditing, and decision-making processes. The study explores the evolution from manual, labor-intensive accounting methods to sophisticated, AI-driven approaches by setting it against the backdrop of rapid technological advancements. The aim is to critically assess how AI integration is redefining the landscape of accounting, highlighting both the opportunities and challenges it presents. The study meticulously analyzes peer-reviewed articles, case studies, and industry reports from the last decade by employing a systematic literature review and bibliometric analysis. This methodology ensures a comprehensive understanding of AI's integration in accounting, its effectiveness in enhancing accuracy and efficiency, and the strategic implications for accounting professionals and firms. The findings reveal that AI significantly improves the accuracy and efficiency of financial reporting, automating routine tasks and enabling predictive analytics for strategic decision-making. However, challenges such as the need for skilled personnel adept in AI, data privacy concerns, and the high costs of AI integration are notable. The study also highlights the resistance to change as a significant barrier to AI adoption in accounting practices. In conclusion, the paper recommends a balanced approach to AI integration in accounting, emphasizing the need for continuous learning, adaptation, and strategic planning. It advocates for investment in training and development to build AI competency and stresses the importance of ethical considerations and regulatory compliance. The study concludes that while AI presents challenges, its potential to revolutionize accounting practices is undeniable, offering new avenues for growth and innovation in the digital era.",
    "doi": "10.30574/wjarr.2024.21.1.2721",
    "url": "https://openalex.org/W4390564972",
    "pdf_url": "https://wjarr.com/sites/default/files/WJARR-2023-2721.pdf",
    "venue": "World Journal of Advanced Research and Reviews",
    "citation_count": 119,
    "fields_of_study": [
      "Audit",
      "Accounting",
      "Transformative learning",
      "Knowledge management",
      "Business"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387913"
  },
  {
    "source": "openalex",
    "source_id": "W4353050783",
    "title": "Artificial intelligence applied to potential assessment and talent identification in an organisational context",
    "authors": [
      "Tiago Jacob Fernandes Fran\u00e7a",
      "Henrique S\u00e3o Mamede",
      "Jo\u00e3o Barroso",
      "V\u00edtor Santos"
    ],
    "year": 2023,
    "abstract": "Our study provides valuable insights into the relationship between artificial intelligence (AI) and Human Resource Management (HRM). We have minimised bias and ensured reliable findings by employing a systematic literature review and the PRISMA statement. Our comprehensive synthesis of the studies included in this research, along with a bibliometric analysis of articles, journals, indexes, authors' affiliations, citations, keyword co-occurrences, and co-authorship analysis, has produced robust results. The discussion of our findings focuses on critical areas of interest, such as AI and Talent, AI Bias, Ethics and Law, and their impact on Human Resource (HR) management. Our research highlights the recognition by organisations of the importance of talent management in achieving a competitive advantage as higher-level skills become increasingly necessary. Although some HR managers have adopted AI technology for talent acquisition, our study reveals that there is still room for improvement. Our study is in line with previous research that acknowledges the potential for AI to revolutionise HR management and the future of work. Our findings emphasise the need for HR managers to be proactive in embracing technology and bridging the technological, human, societal, and governmental gaps. Our study contributes to the growing body of AI and HR management knowledge, providing essential insights and recommendations for future research. The importance of our study lies in its focus on the role of HR in promoting the benefits of AI-based applications, thereby creating a larger body of knowledge from an organisational perspective.",
    "doi": "10.1016/j.heliyon.2023.e14694",
    "url": "https://openalex.org/W4353050783",
    "pdf_url": "http://www.cell.com/article/S2405844023019011/pdf",
    "venue": "Heliyon",
    "citation_count": 68,
    "fields_of_study": [
      "Knowledge management",
      "Human resource management",
      "Context (archaeology)",
      "Human resources",
      "Talent management"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387938"
  },
  {
    "source": "openalex",
    "source_id": "W3025019304",
    "title": "Reinforcement Learning for Clinical Decision Support in Critical Care: Comprehensive Review",
    "authors": [
      "Siqi Liu",
      "Kay Choong See",
      "Kee Yuan Ngiam",
      "Leo Anthony Celi",
      "Xingzhi Sun",
      "Mengling Feng"
    ],
    "year": 2020,
    "abstract": "Background Decision support systems based on reinforcement learning (RL) have been implemented to facilitate the delivery of personalized care. This paper aimed to provide a comprehensive review of RL applications in the critical care setting. Objective This review aimed to survey the literature on RL applications for clinical decision support in critical care and to provide insight into the challenges of applying various RL models. Methods We performed an extensive search of the following databases: PubMed, Google Scholar, Institute of Electrical and Electronics Engineers (IEEE), ScienceDirect, Web of Science, Medical Literature Analysis and Retrieval System Online (MEDLINE), and Excerpta Medica Database (EMBASE). Studies published over the past 10 years (2010-2019) that have applied RL for critical care were included. Results We included 21 papers and found that RL has been used to optimize the choice of medications, drug dosing, and timing of interventions and to target personalized laboratory values. We further compared and contrasted the design of the RL models and the evaluation metrics for each application. Conclusions RL has great potential for enhancing decision making in critical care. Challenges regarding RL system design, evaluation metrics, and model choice exist. More importantly, further work is required to validate RL in authentic clinical environments.",
    "doi": "10.2196/18477",
    "url": "https://openalex.org/W3025019304",
    "pdf_url": "https://www.jmir.org/2020/7/e18477/PDF",
    "venue": "Journal of Medical Internet Research",
    "citation_count": 189,
    "fields_of_study": [
      "Reinforcement learning",
      "Computer science",
      "Clinical decision support system",
      "Decision support system",
      "MEDLINE"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387961"
  },
  {
    "source": "openalex",
    "source_id": "W2944361236",
    "title": "Digital Medicine: A Primer on Measurement",
    "authors": [
      "Andrea Coravos",
      "Jennifer C. Goldsack",
      "Daniel R. Karlin",
      "Camille Nebeker",
      "Eric Perakslis",
      "Noah Zimmerman",
      "Michael Kelley Erb"
    ],
    "year": 2019,
    "abstract": "Technology is changing how we practice medicine. Sensors and wearables are getting smaller and cheaper, and algorithms are becoming powerful enough to predict medical outcomes. Yet despite rapid advances, healthcare lags behind other industries in truly putting these technologies to use. A major barrier to entry is the cross-disciplinary approach required to create such tools, requiring knowledge from many people across many fields. We aim to drive the field forward by unpacking that barrier, providing a brief introduction to core concepts and terms that define digital medicine. Specifically, we contrast \u201cclinical research\u201d versus routine \u201cclinical care,\u201d outlining the security, ethical, regulatory, and legal issues developers must consider as digital medicine products go to market. We classify types of digital measurements and how to use and validate these measures in different settings. To make this resource engaging and accessible, we have included illustrations and figures throughout that we hope readers will borrow from liberally. This primer is the first in a series that will accelerate the safe and effective advancement of the field of digital medicine.",
    "doi": "10.1159/000500413",
    "url": "https://openalex.org/W2944361236",
    "pdf_url": "https://www.karger.com/Article/Pdf/500413",
    "venue": "Digital Biomarkers",
    "citation_count": 156,
    "fields_of_study": [
      "Field (mathematics)",
      "Health care",
      "Resource (disambiguation)",
      "Data science",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:13.387982"
  },
  {
    "source": "openalex",
    "source_id": "W4386724197",
    "title": "Is ChatGPT Leading Generative AI? What is Beyond Expectations?",
    "authors": [
      "\u00d6mer Ayd\u0131n",
      "Enis Karaarslan"
    ],
    "year": 2023,
    "abstract": "Generative AI has the potential to change the way we do things. The chatbot is one of the most popular implementation areas. Even though companies like Google and Meta had chatbots, ChatGPT became popular as it was made publicly available. Although ChatGPT is still in the early stages of its development, it attracted the attention of people and capital groups. It has taken the public interest; people from different fields, ages, and education levels started using ChatGPT. There have been many trials with ChatGPT. It is possible to see a lot of news and shares on the Internet. The study aims to shed light on what is happening in the literature and get an insight into the user expectations of ChatGPT and Generative AI. We also give information about the competitors of ChatGPT, such as Google\u2019s Bard AI, Claude, Meta\u2019s Wit.ai and Tencent\u2019s HunyuanAide. We describe technical and structural fundamentals and try to shed light on who will win the race. We also shared information about the GPT4 version of OpenAI's ChatGPT. We share the early stage due diligence and current situation analysis for all these points. We examine preprint papers and published articles. We also included striking posts on the LinkedIn platform and a compilation of various blogs and news. We also made use of ChatGPT in editing the content of these resources of this study. We can get an insight into the people's interests through their questions submitted to ChatGPT. We can also understand the capabilities of GPT3, GPT4 and also predict further enhancements.",
    "doi": "10.21541/apjess.1293702",
    "url": "https://openalex.org/W4386724197",
    "pdf_url": "https://dergipark.org.tr/en/download/article-file/3127764",
    "venue": "Academic Platform Journal of Engineering and Smart Systems",
    "citation_count": 150,
    "fields_of_study": [
      "Generative grammar",
      "Competitor analysis",
      "Diligence",
      "World Wide Web",
      "The Internet"
    ],
    "retrieved_at": "2026-02-02T16:58:13.388001"
  },
  {
    "source": "openalex",
    "source_id": "W3015184088",
    "title": "Managing the MNE subsidiary: Advancing a multi-level and dynamic research agenda",
    "authors": [
      "Klaus E. Meyer",
      "Chengguang Li",
      "Andreas Schotter"
    ],
    "year": 2020,
    "abstract": "Abstract Multinational enterprise (MNE) subsidiaries abroad are important organizations in their own rights. They typically hold some of the MNE\u2019s most critical resources, and operate at the forefront of complex international environments. In this review, we identify and organize theoretical and empirical research on subsidiary management based on over 600 articles in leading academic journals. We develop a conceptual framework that integrates complementary streams of theoretical and empirical research with the subsidiary as its focal unit of analysis. In particular, we review six lines of research on subsidiary scope, practices, knowledge management, engagement with local market and nonmarket actors, performance, and individuals within subsidiaries. We highlight theoretical perspectives that have contributed to, and been advanced by, research on MNE subsidiaries. Based on the review, we explore future research agendas, linking the contemporary research themes with two main thrusts. First, subsidiary management is a multi-level phenomenon that would benefit from more microfoundational research. Second, subsidiary management operates at key interfaces of technology paradigm shifts, and of disruptions in the political and institutional environment. Research into the dynamics of subsidiary management would thus enhance our understanding of international business in a volatile global economy.",
    "doi": "10.1057/s41267-020-00318-w",
    "url": "https://openalex.org/W3015184088",
    "pdf_url": "https://link.springer.com/content/pdf/10.1057/s41267-020-00318-w.pdf",
    "venue": "Journal of International Business Studies",
    "citation_count": 316,
    "fields_of_study": [
      "Subsidiary",
      "Multinational corporation",
      "International business",
      "Conceptual framework",
      "Scope (computer science)"
    ],
    "retrieved_at": "2026-02-02T16:58:13.388026"
  },
  {
    "source": "openalex",
    "source_id": "W3120171868",
    "title": "Digital transformation: What we have learned (thus far) and what is next",
    "authors": [
      "Sabrina Schneider",
      "Olga Kokshagina"
    ],
    "year": 2021,
    "abstract": "There is certainly a lot of discussion about digital technologies, their transformative nature, and their potentially disruptive impact on business and society. The number of publications on digital technologies and their impact on business and management have risen dramatically. This paper's main objective is to draw attention to practical and research\u2010related views on what we know and what we still need to learn about business and management in the digital era. We do so by combining the insights obtained from interviews with senior managers in charge of their firm's digital transformation activities in 2017 with the results of a systematic literature review covering a decade of practice\u2010oriented, academic literature on the impact of digital technologies. We identify the challenges that firms face at the beginning of their digital transformation efforts and summarize the managerial guidance offered by 242 publications over the years, 133 of which have been published since 2017. Based on the analysis conducted, we discuss the emerging solutions for a number of the key challenges identified in 2017, flag the remaining ones, and identify new themes that require attention. This leads us to propose an agenda for future, practice\u2010oriented research on digital transformation.",
    "doi": "10.1111/caim.12414",
    "url": "https://openalex.org/W3120171868",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/caim.12414",
    "venue": "Creativity and Innovation Management",
    "citation_count": 167,
    "fields_of_study": [
      "Digital transformation",
      "Transformative learning",
      "Key (lock)",
      "Digital strategy",
      "Face (sociological concept)"
    ],
    "retrieved_at": "2026-02-02T16:58:13.388044"
  },
  {
    "source": "openalex",
    "source_id": "W3012477544",
    "title": "Working in the digitized economy: HRM theory &amp; practice",
    "authors": [
      "Catherine E. Connelly",
      "Christian Fieseler",
      "Matej \u010cerne",
      "Steffen R. Giessner",
      "Sut I Wong"
    ],
    "year": 2020,
    "abstract": null,
    "doi": "10.1016/j.hrmr.2020.100762",
    "url": "https://openalex.org/W3012477544",
    "pdf_url": "https://www.sciencedirect.com/science/article/pii/S1053482220300358",
    "venue": "Human Resource Management Review",
    "citation_count": 112,
    "fields_of_study": [
      "Gig economy",
      "Human resource management",
      "Context (archaeology)",
      "Phenomenon",
      "Knowledge management"
    ],
    "retrieved_at": "2026-02-02T16:58:13.388062"
  },
  {
    "source": "openalex",
    "source_id": "W4391598857",
    "title": "A Comprehensive Review of AI Techniques for Addressing Algorithmic Bias in Job Hiring",
    "authors": [
      "Elham Albaroudi",
      "Taha Mansouri",
      "Ali Alameer"
    ],
    "year": 2024,
    "abstract": "The study comprehensively reviews artificial intelligence (AI) techniques for addressing algorithmic bias in job hiring. More businesses are using AI in curriculum vitae (CV) screening. While the move improves efficiency in the recruitment process, it is vulnerable to biases, which have adverse effects on organizations and the broader society. This research aims to analyze case studies on AI hiring to demonstrate both successful implementations and instances of bias. It also seeks to evaluate the impact of algorithmic bias and the strategies to mitigate it. The basic design of the study entails undertaking a systematic review of existing literature and research studies that focus on artificial intelligence techniques employed to mitigate bias in hiring. The results demonstrate that the correction of the vector space and data augmentation are effective natural language processing (NLP) and deep learning techniques for mitigating algorithmic bias in hiring. The findings underscore the potential of artificial intelligence techniques in promoting fairness and diversity in the hiring process with the application of artificial intelligence techniques. The study contributes to human resource practice by enhancing hiring algorithms\u2019 fairness. It recommends the need for collaboration between machines and humans to enhance the fairness of the hiring process. The results can help AI developers make algorithmic changes needed to enhance fairness in AI-driven tools. This will enable the development of ethical hiring tools, contributing to fairness in society.",
    "doi": "10.3390/ai5010019",
    "url": "https://openalex.org/W4391598857",
    "pdf_url": "https://www.mdpi.com/2673-2688/5/1/19/pdf?version=1707285598",
    "venue": "AI",
    "citation_count": 76,
    "fields_of_study": [
      "Computer science",
      "Data science",
      "Political science"
    ],
    "retrieved_at": "2026-02-02T16:58:13.388065"
  },
  {
    "source": "openalex",
    "source_id": "W4323900663",
    "title": "Quality, Usability, and Effectiveness of mHealth Apps and the Role of Artificial Intelligence: Current Scenario and Challenges",
    "authors": [
      "Alejandro D\u00e9niz-Garc\u00eda",
      "Himar Fabelo",
      "Antonio J. Rodr\u00edguez-Almeida",
      "Garlene Zamora-Zamorano",
      "Mar\u00eda Castro-Fern\u00e1ndez",
      "Mar\u00eda del Pino Alberiche-Ruano",
      "Terje Solvoll",
      "Concei\u00e7\u00e3o Granja",
      "Thomas Schopf",
      "Gustavo M. Callic\u00f3",
      "Cristina Soguero-Ru\u00edz",
      "Ana M. W\u00e4gner"
    ],
    "year": 2023,
    "abstract": "The use of artificial intelligence (AI) and big data in medicine has increased in recent years. Indeed, the use of AI in mobile health (mHealth) apps could considerably assist both individuals and health care professionals in the prevention and management of chronic diseases, in a person-centered manner. Nonetheless, there are several challenges that must be overcome to provide high-quality, usable, and effective mHealth apps. Here, we review the rationale and guidelines for the implementation of mHealth apps and the challenges regarding quality, usability, and user engagement and behavior change, with a special focus on the prevention and management of noncommunicable diseases. We suggest that a cocreation-based framework is the best method to address these challenges. Finally, we describe the current and future roles of AI in improving personalized medicine and provide recommendations for developing AI-based mHealth apps. We conclude that the implementation of AI and mHealth apps for routine clinical practice and remote health care will not be feasible until we overcome the main challenges regarding data privacy and security, quality assessment, and the reproducibility and uncertainty of AI results. Moreover, there is a lack of both standardized methods to measure the clinical outcomes of mHealth apps and techniques to encourage user engagement and behavior changes in the long term. We expect that in the near future, these obstacles will be overcome and that the ongoing European project, Watching the risk factors (WARIFA), will provide considerable advances in the implementation of AI-based mHealth apps for disease prevention and health promotion.",
    "doi": "10.2196/44030",
    "url": "https://openalex.org/W4323900663",
    "pdf_url": "https://www.jmir.org/2023/1/e44030/PDF",
    "venue": "Journal of Medical Internet Research",
    "citation_count": 190,
    "fields_of_study": [
      "mHealth",
      "Usability",
      "Health care",
      "Computer science",
      "Quality (philosophy)"
    ],
    "retrieved_at": "2026-02-02T16:58:13.388086"
  },
  {
    "source": "openalex",
    "source_id": "W4224249136",
    "title": "Digital Transformation in Smart Farm and Forest Operations Needs Human-Centered AI: Challenges and Future Directions",
    "authors": [
      "Andreas Holzinger",
      "Anna Saranti",
      "Alessa Angerschmid",
      "Carl Orge Retzlaff",
      "Andreas Gronauer",
      "Vladimir Pejakovi\u0107",
      "Francisco Medel-Jim\u00e9nez",
      "Theresa Krexner",
      "Christoph Gollob",
      "Karl Stampfer"
    ],
    "year": 2022,
    "abstract": "The main impetus for the global efforts toward the current digital transformation in almost all areas of our daily lives is due to the great successes of artificial intelligence (AI), and in particular, the workhorse of AI, statistical machine learning (ML). The intelligent analysis, modeling, and management of agricultural and forest ecosystems, and of the use and protection of soils, already play important roles in securing our planet for future generations and will become irreplaceable in the future. Technical solutions must encompass the entire agricultural and forestry value chain. The process of digital transformation is supported by cyber-physical systems enabled by advances in ML, the availability of big data and increasing computing power. For certain tasks, algorithms today achieve performances that exceed human levels. The challenge is to use multimodal information fusion, i.e., to integrate data from different sources (sensor data, images, *omics), and explain to an expert why a certain result was achieved. However, ML models often react to even small changes, and disturbances can have dramatic effects on their results. Therefore, the use of AI in areas that matter to human life (agriculture, forestry, climate, health, etc.) has led to an increased need for trustworthy AI with two main components: explainability and robustness. One step toward making AI more robust is to leverage expert knowledge. For example, a farmer/forester in the loop can often bring in experience and conceptual understanding to the AI pipeline\u2014no AI can do this. Consequently, human-centered AI (HCAI) is a combination of \u201cartificial intelligence\u201d and \u201cnatural intelligence\u201d to empower, amplify, and augment human performance, rather than replace people. To achieve practical success of HCAI in agriculture and forestry, this article identifies three important frontier research areas: (1) intelligent information fusion; (2) robotics and embodied intelligence; and (3) augmentation, explanation, and verification for trusted decision support. This goal will also require an agile, human-centered design approach for three generations (G). G1: Enabling easily realizable applications through immediate deployment of existing technology. G2: Medium-term modification of existing technology. G3: Advanced adaptation and evolution beyond state-of-the-art.",
    "doi": "10.3390/s22083043",
    "url": "https://openalex.org/W4224249136",
    "pdf_url": "https://www.mdpi.com/1424-8220/22/8/3043/pdf?version=1652184539",
    "venue": "Sensors",
    "citation_count": 154,
    "fields_of_study": [
      "Artificial intelligence",
      "Computer science",
      "Big data",
      "Leverage (statistics)",
      "Data science"
    ],
    "retrieved_at": "2026-02-02T16:58:13.388107"
  },
  {
    "source": "openalex",
    "source_id": "W3209891779",
    "title": "Scientific, Legal, and Ethical Concerns About AI-Based Personnel Selection Tools: A Call to Action",
    "authors": [
      "Nancy T. Tippins",
      "Frederick L. Oswald",
      "S. Morton McPhail"
    ],
    "year": 2021,
    "abstract": "Organizations are increasingly turning toward personnel selection tools that rely on artificial intelligence (AI) technologies and machine learning algorithms that, together, intend to predict the future success of employees better than traditional tools. These new forms of assessment include online games, video-based interviews, and big data pulled from many sources, including test responses, test-taking behavior, applications, resumes, and social media. Speedy processing, lower costs, convenient access, and applicant engagement are often and rightfully cited as the practical advantages for using these selection tools. At the same time, however, these tools raise serious concerns about their effectiveness in terms their conceptual relevance to the job, their basis in a job analysis to ensure job relevancy, their measurement characteristics (reliability and stability), their validity in predicting employee-relevant outcomes, their evidence and normative information being updated appropriately, and the associated ethical concerns around what information is being represented to employers and told to job candidates. This paper explores these concerns, concluding with an urgent call to industrial and organizational psychologists to extend existing professional standards for employment testing to these new AI and machine learning based forms of testing, including standards and requirements for their documentation.",
    "doi": "10.25035/pad.2021.02.001",
    "url": "https://openalex.org/W3209891779",
    "pdf_url": "https://scholarworks.bgsu.edu/cgi/viewcontent.cgi?article=1170&context=pad",
    "venue": "Personnel Assessment and Decisions",
    "citation_count": 103,
    "fields_of_study": [
      "Relevance (law)",
      "Computer science",
      "Personnel selection",
      "Test (biology)",
      "Normative"
    ],
    "retrieved_at": "2026-02-02T16:58:13.388138"
  },
  {
    "source": "openalex",
    "source_id": "W4225496733",
    "title": "Financial Risk Management and Explainable, Trustworthy, Responsible AI",
    "authors": [
      "Sebastian Fritz-Morgenthal",
      "Bernhard Hein",
      "Jochen Papenbrock"
    ],
    "year": 2022,
    "abstract": "This perspective paper is based on several sessions by the members of the Round Table AI at FIRM 1 , with input from a number of external and international speakers. Its particular focus lies on the management of the model risk of productive models in banks and other financial institutions. The models in view range from simple rules-based approaches to Artificial Intelligence (AI) or Machine learning (ML) models with a high level of sophistication. The typical applications of those models are related to predictions and decision making around the value chain of credit risk (including accounting side under IFRS9 or related national GAAP approaches), insurance risk or other financial risk types. We expect more models of higher complexity in the space of anti-money laundering, fraud detection and transaction monitoring as well as a rise of AI/ML models as alternatives to current methods in solving some of the more intricate stochastic differential equations needed for the pricing and/or valuation of derivatives. The same type of model is also successful in areas unrelated to risk management, such as sales optimization, customer lifetime value considerations, robo-advisory, and other fields of applications. The paper refers to recent related publications from central banks, financial supervisors and regulators as well as other relevant sources and working groups. It aims to give practical advice for establishing a risk-based governance and testing framework for the mentioned model types and discusses the use of recent technologies, approaches, and platforms to support the establishment of responsible, trustworthy, explainable, auditable, and manageable AI/ML in production. In view of the recent EU publication on AI, also referred to as the EU Artificial Intelligence Act (AIA), we also see a certain added value for this paper as an instigator of further thinking outside of the financial services sector, in particular where \u201cHigh Risk\u201d models according to the mentioned EU consultation are concerned.",
    "doi": "10.3389/frai.2022.779799",
    "url": "https://openalex.org/W4225496733",
    "pdf_url": "https://www.frontiersin.org/articles/10.3389/frai.2022.779799/pdf",
    "venue": "Frontiers in Artificial Intelligence",
    "citation_count": 87,
    "fields_of_study": [
      "Sophistication",
      "Risk management",
      "Valuation (finance)",
      "Computer science",
      "Corporate governance"
    ],
    "retrieved_at": "2026-02-02T16:58:13.388157"
  },
  {
    "source": "openalex",
    "source_id": "W4390480754",
    "title": "On the Integration of Artificial Intelligence and Blockchain Technology: A Perspective About Security",
    "authors": [
      "Alexandr Kuznetsov",
      "Paolo Sernani",
      "Luca Romeo",
      "Emanuele Frontoni",
      "Adriano Mancini"
    ],
    "year": 2024,
    "abstract": "As reliance on disruptive applications based on Artificial Intelligence (AI) and Blockchain grows, the need for secure and trustworthy solutions becomes ever more critical. Whereas much research has been conducted on AI and Blockchain, there is a shortage of comprehensive studies examining their integration from a security perspective. Hence, this survey addresses such a gap and provides insights for policymakers, researchers, and practitioners exploiting AI and Blockchain\u2019s evolving integration. Specifically, this paper analyzes the potential benefits of the integration of AI and Blockchain as well as the related security concerns, identifying possible mitigation strategies, suggesting regulatory measures, and describing the impact it has on public trust.",
    "doi": "10.1109/access.2023.3349019",
    "url": "https://openalex.org/W4390480754",
    "pdf_url": "https://ieeexplore.ieee.org/ielx7/6287639/6514899/10379100.pdf",
    "venue": "IEEE Access",
    "citation_count": 98,
    "fields_of_study": [
      "Blockchain",
      "Perspective (graphical)",
      "Computer science",
      "Computer security",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:13.388185"
  },
  {
    "source": "openalex",
    "source_id": "W4281706229",
    "title": "A reimbursement framework for artificial intelligence in healthcare",
    "authors": [
      "Michael D. Abr\u00e0moff",
      "Cybil Roehrenbeck",
      "Sylvia Trujillo",
      "Juli D. Goldstein",
      "A. S. Graves",
      "Michael X. Repka",
      "Ezequiel Silva"
    ],
    "year": 2022,
    "abstract": "Responsible adoption of healthcare artificial intelligence (AI) requires that AI systems which benefit patients and populations, including autonomous AI systems, are incentivized financially at a consistent and sustainable level. We present a framework for analytically determining value and cost of each unique AI service. The framework\u2019s processes involve affected stakeholders, including patients, providers, legislators, payors, and AI creators, in order to find an optimum balance among ethics, workflow, cost, and value as identified by each of these stakeholders. We use a real world, completed, an example of a specific autonomous AI service, to show how multiple \u201cguardrails\u201d for the AI system implementation enforce ethical principles. It can guide the development of sustainable reimbursement for future AI services, ensuring the quality of care, healthcare equity, and mitigation of potential bias, and thereby contribute to realize the potential of AI to improve clinical outcomes for patients and populations, improve access, remove disparities, and reduce cost.",
    "doi": "10.1038/s41746-022-00621-w",
    "url": "https://openalex.org/W4281706229",
    "pdf_url": "https://www.nature.com/articles/s41746-022-00621-w.pdf",
    "venue": "npj Digital Medicine",
    "citation_count": 93,
    "fields_of_study": [
      "Reimbursement",
      "Workflow",
      "Health care",
      "Equity (law)",
      "Business"
    ],
    "retrieved_at": "2026-02-02T16:58:13.388201"
  },
  {
    "source": "openalex",
    "source_id": "W4200423370",
    "title": "Perspectives on Digital Humanism",
    "authors": [
      "Hannes Werthner",
      "Erich Prem",
      "Edward A. Lee",
      "Carlo Ghezzi"
    ],
    "year": 2021,
    "abstract": "Stephanie Wogowitsch, from the e-commerce group of TU Wien",
    "doi": "10.1007/978-3-030-86144-5",
    "url": "https://openalex.org/W4200423370",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/978-3-030-86144-5.pdf",
    "venue": null,
    "citation_count": 92,
    "fields_of_study": [
      "Humanism",
      "Philosophy",
      "Theology"
    ],
    "retrieved_at": "2026-02-02T16:58:13.388217"
  },
  {
    "source": "openalex",
    "source_id": "W2941568957",
    "title": "What's Inside the Black Box? AI Challenges for Lawyers and Researchers",
    "authors": [
      "Ronald Yu",
      "Gabriele Spina Al\u00ec"
    ],
    "year": 2019,
    "abstract": "Abstract The Artificial intelligence revolution is happening and is going to drastically re-shape legal research in both the private sector and academia. AI research tools present several advantages over traditional research methods. They allow for the analysis and review of large datasets (\u2018Big Data\u2019) and can identify patterns that are imperceptible to human researchers. However, the wonders of AI legal research are not without perils. Because of their complexity, AI systems can escape the control and understanding of their operators and programmers. Therefore, especially when run by researchers with insufficient IT background, computational AI research may skew analyses or result in flawed research. Premised thus, the main goals of this paper, written by Ronald Yu and Gabriele Spina Al\u00ec, are to analyse some of the factors that can jeopardize the reliability of AI-assisted legal research and to review some of the solutions to mitigate this situation.",
    "doi": "10.1017/s1472669619000021",
    "url": "https://openalex.org/W2941568957",
    "pdf_url": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/8A547878999427F7222C3CEFC3CE5E01/S1472669619000021a.pdf/div-class-title-what-s-inside-the-black-box-ai-challenges-for-lawyers-and-researchers-div.pdf",
    "venue": "Legal Information Management",
    "citation_count": 127,
    "fields_of_study": [
      "Black box",
      "Big data",
      "Computer science",
      "Data science",
      "Reliability (semiconductor)"
    ],
    "retrieved_at": "2026-02-02T16:58:13.388221"
  },
  {
    "source": "openalex",
    "source_id": "W3136635219",
    "title": "Adoption of artificial intelligence in breast imaging: evaluation, ethical constraints and limitations",
    "authors": [
      "Sarah Hickman",
      "Gabrielle Baxter",
      "Fiona J. Gilbert"
    ],
    "year": 2021,
    "abstract": null,
    "doi": "10.1038/s41416-021-01333-w",
    "url": "https://openalex.org/W3136635219",
    "pdf_url": "https://www.nature.com/articles/s41416-021-01333-w.pdf",
    "venue": "British Journal of Cancer",
    "citation_count": 102,
    "fields_of_study": [
      "Workflow",
      "Breast imaging",
      "Health care",
      "Computer science",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:13.388236"
  },
  {
    "source": "openalex",
    "source_id": "W4394855484",
    "title": "AI and Ethics: A Systematic Review of the Ethical Considerations of Large Language Model Use in Surgery Research",
    "authors": [
      "Sophia M. Pressman",
      "Sahar Borna",
      "Cesar A. Gomez-Cabello",
      "Syed Ali Haider",
      "Clifton R. Haider",
      "Antonio J. Forte"
    ],
    "year": 2024,
    "abstract": "Introduction: As large language models receive greater attention in medical research, the investigation of ethical considerations is warranted. This review aims to explore surgery literature to identify ethical concerns surrounding these artificial intelligence models and evaluate how autonomy, beneficence, nonmaleficence, and justice are represented within these ethical discussions to provide insights in order to guide further research and practice. Methods: A systematic review was conducted in accordance with the Preferred Reporting Items for Systematic Reviews and Meta-Analyses guidelines. Five electronic databases were searched in October 2023. Eligible studies included surgery-related articles that focused on large language models and contained adequate ethical discussion. Study details, including specialty and ethical concerns, were collected. Results: The literature search yielded 1179 articles, with 53 meeting the inclusion criteria. Plastic surgery, orthopedic surgery, and neurosurgery were the most represented surgical specialties. Autonomy was the most explicitly cited ethical principle. The most frequently discussed ethical concern was accuracy (n = 45, 84.9%), followed by bias, patient confidentiality, and responsibility. Conclusion: The ethical implications of using large language models in surgery are complex and evolving. The integration of these models into surgery necessitates continuous ethical discourse to ensure responsible and ethical use, balancing technological advancement with human dignity and safety.",
    "doi": "10.3390/healthcare12080825",
    "url": "https://openalex.org/W4394855484",
    "pdf_url": "https://www.mdpi.com/2227-9032/12/8/825/pdf?version=1713249916",
    "venue": "Healthcare",
    "citation_count": 79,
    "fields_of_study": [
      "Beneficence",
      "Autonomy",
      "Dignity",
      "Confidentiality",
      "Engineering ethics"
    ],
    "retrieved_at": "2026-02-02T16:58:14.584771"
  },
  {
    "source": "openalex",
    "source_id": "W4312129526",
    "title": "Confronting racially exclusionary practices in the acquisition and analyses of neuroimaging data",
    "authors": [
      "Jocelyn A. Ricard",
      "Termara Parker",
      "Elvisha Dhamala",
      "Jasmine Kwasa",
      "AZA Stephen Allsop",
      "Avram J. Holmes"
    ],
    "year": 2022,
    "abstract": "Across the brain sciences, institutions and individuals have begun to actively acknowledge and address the presence of racism, bias, and associated barriers to inclusivity within our community. However, even with these recent calls to action, limited attention has been directed to inequities in the research methods and analytic approaches we use. The very process of science, including how we recruit, the methodologies we utilize and the analyses we conduct, can have marked downstream effects on the equity and generalizability of scientific discoveries across the global population. Despite our best intentions, the use of field-standard approaches can inadvertently exclude participants from engaging in research and yield biased brain-behavior relationships. To address these pressing issues, we discuss actionable ways and important questions to move the fields of neuroscience and psychology forward in designing better studies to address the history of exclusionary practices in human brain mapping.",
    "doi": "10.1038/s41593-022-01218-y",
    "url": "https://openalex.org/W4312129526",
    "pdf_url": "https://www.nature.com/articles/s41593-022-01218-y.pdf",
    "venue": "Nature Neuroscience",
    "citation_count": 139,
    "fields_of_study": [
      "Neurolaw",
      "Generalizability theory",
      "Psychology",
      "Social neuroscience",
      "Neuroimaging"
    ],
    "retrieved_at": "2026-02-02T16:58:14.584808"
  },
  {
    "source": "openalex",
    "source_id": "W4200460915",
    "title": "Responsible media technology and AI: challenges and research directions",
    "authors": [
      "Christoph Trattner",
      "Dietmar Jannach",
      "Enrico Motta",
      "Irene Costera Meijer",
      "Nicholas Diakopoulos",
      "Mehdi Elahi",
      "Andreas L. Opdahl",
      "Bj\u00f8rnar Tessem",
      "Nj\u00e5l Borch",
      "Morten Fjeld",
      "Lilja \u00d8vrelid",
      "Koenraad De Smedt",
      "Hallvard Moe"
    ],
    "year": 2021,
    "abstract": "Abstract The last two decades have witnessed major disruptions to the traditional media industry as a result of technological breakthroughs. New opportunities and challenges continue to arise, most recently as a result of the rapid advance and adoption of artificial intelligence technologies. On the one hand, the broad adoption of these technologies may introduce new opportunities for diversifying media offerings, fighting disinformation, and advancing data-driven journalism. On the other hand, techniques such as algorithmic content selection and user personalization can introduce risks and societal threats. The challenge of balancing these opportunities and benefits against their potential for negative impacts underscores the need for more research in responsible media technology. In this paper, we first describe the major challenges\u2014both for societies and the media industry\u2014that come with modern media technology. We then outline various places in the media production and dissemination chain, where research gaps exist, where better technical approaches are needed, and where technology must be designed in a way that can effectively support responsible editorial processes and principles. We argue that a comprehensive approach to research in responsible media technology, leveraging an interdisciplinary approach and a close cooperation between the media industry and academic institutions, is urgently needed.",
    "doi": "10.1007/s43681-021-00126-4",
    "url": "https://openalex.org/W4200460915",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s43681-021-00126-4.pdf",
    "venue": "AI and Ethics",
    "citation_count": 86,
    "fields_of_study": [
      "Disinformation",
      "Personalization",
      "Emerging technologies",
      "Social media",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:14.584824"
  },
  {
    "source": "openalex",
    "source_id": "W4388907242",
    "title": "Artificial Intelligence and Sensor Innovations: Enhancing Livestock Welfare with a Human-Centric Approach",
    "authors": [
      "Suresh Neethirajan"
    ],
    "year": 2023,
    "abstract": "Abstract In the wake of rapid advancements in artificial intelligence (AI) and sensor technologies, a new horizon of possibilities has emerged across diverse sectors. Livestock farming, a domain often sidelined in conventional AI discussions, stands at the cusp of this transformative wave. This paper delves into the profound potential of AI and sensor innovations in reshaping animal welfare in livestock farming, with a pronounced emphasis on a human-centric paradigm. Central to our discourse is the symbiotic interplay between cutting-edge technology and human expertise. While AI and sensor mechanisms offer real-time, comprehensive, and objective insights into animal welfare, it\u2019s the farmer\u2019s intrinsic knowledge of their livestock and environment that should steer these technological strides. We champion the notion of technology as an enhancer of farmers\u2019 innate capabilities, not a substitute. Our manuscript sheds light on: Objective Animal Welfare Indicators: An exhaustive exploration of health, behavioral, and physiological metrics, underscoring AI\u2019s prowess in delivering precise, timely, and objective evaluations. Farmer-Centric Approach: A focus on the pivotal role of farmers in the adept adoption and judicious utilization of AI and sensor technologies, coupled with discussions on crafting intuitive, pragmatic, and cost-effective solutions tailored to farmers' distinct needs. Ethical and Social Implications: A discerning scrutiny of the digital metamorphosis in farming, encompassing facets like animal privacy, data safeguarding, responsible AI deployment, and potential technological access disparities. Future Pathways: Advocacy for principled technology design, unambiguous responsible use guidelines, and fair technology access, all echoing the fundamental principles of human-centric computing and analytics. In essence, our paper furnishes pioneering insights at the crossroads of farming, animal welfare, technology, and ethics. It presents a rejuvenated perspective, bridging the chasm between technological advancements and their human beneficiaries, resonating seamlessly with the ethos of the Human-Centric Intelligent Systems journal. This comprehensive analysis thus marks a significant stride in the burgeoning domain of human-centric intelligent systems, especially within the digital livestock farming landscape, fostering a harmonious coexistence of technology, animals, and humans.",
    "doi": "10.1007/s44230-023-00050-2",
    "url": "https://openalex.org/W4388907242",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s44230-023-00050-2.pdf",
    "venue": "Human-Centric Intelligent Systems",
    "citation_count": 100,
    "fields_of_study": [
      "Animal welfare",
      "Transformative learning",
      "Safeguarding",
      "Responsible Research and Innovation",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:14.584842"
  },
  {
    "source": "openalex",
    "source_id": "W4387461693",
    "title": "Artificial Intelligence (AI) Trust Framework and Maturity Model: Applying an Entropy Lens to Improve Security, Privacy, and Ethical AI",
    "authors": [
      "Michael Mylrea",
      "Nikki Robinson"
    ],
    "year": 2023,
    "abstract": "Recent advancements in artificial intelligence (AI) technology have raised concerns about the ethical, moral, and legal safeguards. There is a pressing need to improve metrics for assessing security and privacy of AI systems and to manage AI technology in a more ethical manner. To address these challenges, an AI Trust Framework and Maturity Model is proposed to enhance trust in the design and management of AI systems. Trust in AI involves an agreed-upon understanding between humans and machines about system performance. The framework utilizes an \u201centropy lens\u201d to root the study in information theory and enhance transparency and trust in \u201cblack box\u201d AI systems, which lack ethical guardrails. High entropy in AI systems can decrease human trust, particularly in uncertain and competitive environments. The research draws inspiration from entropy studies to improve trust and performance in autonomous human\u2013machine teams and systems, including interconnected elements in hierarchical systems. Applying this lens to improve trust in AI also highlights new opportunities to optimize performance in teams. Two use cases are described to validate the AI framework\u2019s ability to measure trust in the design and management of AI systems.",
    "doi": "10.3390/e25101429",
    "url": "https://openalex.org/W4387461693",
    "pdf_url": "https://www.mdpi.com/1099-4300/25/10/1429/pdf?version=1696854810",
    "venue": "Entropy",
    "citation_count": 78,
    "fields_of_study": [
      "Computer science",
      "Transparency (behavior)",
      "Through-the-lens metering",
      "Entropy (arrow of time)",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:14.584870"
  },
  {
    "source": "openalex",
    "source_id": "W4387099986",
    "title": "The promise of digital healthcare technologies",
    "authors": [
      "Andy Wai Kan Yeung",
      "Ali Torkamani",
      "Atul J. Butte",
      "Benjamin S. Glicksberg",
      "Bj\u00f6rn W. Schuller",
      "Blanca Rodr\u00edguez",
      "Daniel Shu Wei Ting",
      "David W. Bates",
      "Eva Schaden",
      "Lili Yuan",
      "Harald Willschke",
      "Jeroen van der Laak",
      "Josip Car",
      "Kazem Rahimi",
      "Leo Anthony Celi",
      "Maciej Banach",
      "Maria Klete\u010dka-Pulker",
      "Oliver Kimberger",
      "Roland Eils",
      "Sheikh Mohammed Shariful Islam",
      "Stephen T.C. Wong",
      "Tien Yin Wong",
      "Wei Gao",
      "S\u00f8ren Brunak",
      "Atanas G. Atanasov"
    ],
    "year": 2023,
    "abstract": "Digital health technologies have been in use for many years in a wide spectrum of healthcare scenarios. This narrative review outlines the current use and the future strategies and significance of digital health technologies in modern healthcare applications. It covers the current state of the scientific field (delineating major strengths, limitations, and applications) and envisions the future impact of relevant emerging key technologies. Furthermore, we attempt to provide recommendations for innovative approaches that would accelerate and benefit the research, translation and utilization of digital health technologies.",
    "doi": "10.3389/fpubh.2023.1196596",
    "url": "https://openalex.org/W4387099986",
    "pdf_url": "https://www.frontiersin.org/articles/10.3389/fpubh.2023.1196596/pdf?isPublishedV2=False",
    "venue": "Frontiers in Public Health",
    "citation_count": 168,
    "fields_of_study": [
      "Digital health",
      "Health care",
      "Narrative review",
      "Emerging technologies",
      "Key (lock)"
    ],
    "retrieved_at": "2026-02-02T16:58:14.584889"
  },
  {
    "source": "openalex",
    "source_id": "W3177938779",
    "title": "Academic Integrity in Online Assessment: A Research Review",
    "authors": [
      "Olivia Leslie Holden",
      "Meghan E. Norris",
      "Valerie A. Kuhlmeier"
    ],
    "year": 2021,
    "abstract": "This paper provides a review of current research on academic integrity in higher education, with a focus on its application to assessment practices in online courses. Understanding the types and causes of academic dishonesty can inform the suite of methods that might be used to most effectively promote academic integrity. Thus, the paper first addresses the question of why students engage in academically dishonest behaviours. Then, a review of current methods to reduce academically dishonest behaviours is presented. Acknowledging the increasing use of online courses within the postsecondary curriculum, it is our hope that this review will aid instructors and administrators in their decision-making process regarding online evaluations and encourage future study that will form the foundation of evidence-based practices.",
    "doi": "10.3389/feduc.2021.639814",
    "url": "https://openalex.org/W3177938779",
    "pdf_url": "https://www.frontiersin.org/articles/10.3389/feduc.2021.639814/pdf",
    "venue": "Frontiers in Education",
    "citation_count": 259,
    "fields_of_study": [
      "Academic integrity",
      "Academic dishonesty",
      "Engineering ethics",
      "Suite",
      "Process (computing)"
    ],
    "retrieved_at": "2026-02-02T16:58:14.584899"
  },
  {
    "source": "openalex",
    "source_id": "W4327620114",
    "title": "What does the public think about artificial intelligence?\u2014A criticality map to understand bias in the public perception of AI",
    "authors": [
      "Philipp Brauner",
      "Alexander Hick",
      "Ralf Philipsen",
      "Martina Ziefle"
    ],
    "year": 2023,
    "abstract": "Introduction Artificial Intelligence (AI) has become ubiquitous in medicine, business, manufacturing and transportation, and is entering our personal lives. Public perceptions of AI are often shaped either by admiration for its benefits and possibilities, or by uncertainties, potential threats and fears about this opaque and perceived as mysterious technology. Understanding the public perception of AI, as well as its requirements and attributions, is essential for responsible research and innovation and enables aligning the development and governance of future AI systems with individual and societal needs. Methods To contribute to this understanding, we asked 122 participants in Germany how they perceived 38 statements about artificial intelligence in different contexts (personal, economic, industrial, social, cultural, health). We assessed their personal evaluation and the perceived likelihood of these aspects becoming reality. Results We visualized the responses in a criticality map that allows the identification of issues that require particular attention from research and policy-making. The results show that the perceived evaluation and the perceived expectations differ considerably between the domains. The aspect perceived as most critical is the fear of cybersecurity threats, which is seen as highly likely and least liked. Discussion The diversity of users influenced the evaluation: People with lower trust rated the impact of AI as more positive but less likely. Compared to people with higher trust, they consider certain features and consequences of AI to be more desirable, but they think the impact of AI will be smaller. We conclude that AI is still a \u201cblack box\u201d for many. Neither the opportunities nor the risks can yet be adequately assessed, which can lead to biased and irrational control beliefs in the public perception of AI. The article concludes with guidelines for promoting AI literacy to facilitate informed decision-making.",
    "doi": "10.3389/fcomp.2023.1113903",
    "url": "https://openalex.org/W4327620114",
    "pdf_url": "https://www.frontiersin.org/articles/10.3389/fcomp.2023.1113903/pdf",
    "venue": "Frontiers in Computer Science",
    "citation_count": 104,
    "fields_of_study": [
      "Perception",
      "Admiration",
      "Attribution",
      "Psychology",
      "Diversity (politics)"
    ],
    "retrieved_at": "2026-02-02T16:58:14.584911"
  },
  {
    "source": "openalex",
    "source_id": "W4283204686",
    "title": "A Virtue-Based Framework to Support Putting AI Ethics into Practice",
    "authors": [
      "Thilo Hagendorff"
    ],
    "year": 2022,
    "abstract": "Abstract Many ethics initiatives have stipulated sets of principles and standards for good technology development in the AI sector. However, several AI ethics researchers have pointed out a lack of practical realization of these principles. Following that, AI ethics underwent a practical turn, but without deviating from the principled approach. This paper proposes a complementary to the principled approach that is based on virtue ethics. It defines four \u201cbasic AI virtues\u201d, namely justice, honesty, responsibility and care, all of which represent specific motivational settings that constitute the very precondition for ethical decision making in the AI field. Moreover, it defines two \u201csecond-order AI virtues\u201d, prudence and fortitude, that bolster achieving the basic virtues by helping with overcoming bounded ethicality or hidden psychological forces that can impair ethical decision making and that are hitherto disregarded in AI ethics. Lastly, the paper describes measures for successfully cultivating the mentioned virtues in organizations dealing with AI research and development.",
    "doi": "10.1007/s13347-022-00553-z",
    "url": "https://openalex.org/W4283204686",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s13347-022-00553-z.pdf",
    "venue": "Philosophy & Technology",
    "citation_count": 82,
    "fields_of_study": [
      "Philosophy of technology",
      "Virtue",
      "Virtue ethics",
      "Philosophy of science",
      "Epistemology"
    ],
    "retrieved_at": "2026-02-02T16:58:14.584940"
  },
  {
    "source": "openalex",
    "source_id": "W4393188496",
    "title": "AI: the future of humanity",
    "authors": [
      "Soha Rawas"
    ],
    "year": 2024,
    "abstract": "Abstract Artificial intelligence (AI) is reshaping humanity's future, and this manuscript provides a comprehensive exploration of its implications, applications, challenges, and opportunities. The revolutionary potential of AI is investigated across numerous sectors, with a focus on addressing global concerns. The influence of AI on areas such as healthcare, transportation, banking, and education is revealed through historical insights and conversations on different AI systems. Ethical considerations and the significance of responsible AI development are addressed. Furthermore, this study investigates AI's involvement in addressing global issues such as climate change, public health, and social justice. This paper serves as a resource for policymakers, researchers, and practitioners understanding the complex link between AI and humans.",
    "doi": "10.1007/s44163-024-00118-3",
    "url": "https://openalex.org/W4393188496",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s44163-024-00118-3.pdf",
    "venue": "Discover Artificial Intelligence",
    "citation_count": 68,
    "fields_of_study": [
      "Humanity",
      "Environmental ethics",
      "Philosophy",
      "Theology"
    ],
    "retrieved_at": "2026-02-02T16:58:14.584959"
  },
  {
    "source": "openalex",
    "source_id": "W4362522403",
    "title": "Surveying Public Perceptions of Artificial Intelligence in Health Care in the United States: Systematic Review",
    "authors": [
      "Becca Beets",
      "Todd P. Newman",
      "Emily L. Howell",
      "Luye Bao",
      "Shiyu Yang"
    ],
    "year": 2023,
    "abstract": "Background This paper reviews nationally representative public opinion surveys on artificial intelligence (AI) in the United States, with a focus on areas related to health care. The potential health applications of AI continue to gain attention owing to their promise as well as challenges. For AI to fulfill its potential, it must not only be adopted by physicians and health providers but also by patients and other members of the public. Objective This study reviews the existing survey research on the United States\u2019 public attitudes toward AI in health care and reveals the challenges and opportunities for more effective and inclusive engagement on the use of AI in health settings. Methods We conducted a systematic review of public opinion surveys, reports, and peer-reviewed journal articles published on Web of Science, PubMed, and Roper iPoll between January 2010 and January 2022. We include studies that are nationally representative US public opinion surveys and include at least one or more questions about attitudes toward AI in health care contexts. Two members of the research team independently screened the included studies. The reviewers screened study titles, abstracts, and methods for Web of Science and PubMed search results. For the Roper iPoll search results, individual survey items were assessed for relevance to the AI health focus, and survey details were screened to determine a nationally representative US sample. We reported the descriptive statistics available for the relevant survey questions. In addition, we performed secondary analyses on 4 data sets to further explore the findings on attitudes across different demographic groups. Results This review includes 11 nationally representative surveys. The search identified 175 records, 39 of which were assessed for inclusion. Surveys include questions related to familiarity and experience with AI; applications, benefits, and risks of AI in health care settings; the use of AI in disease diagnosis, treatment, and robotic caregiving; and related issues of data privacy and surveillance. Although most Americans have heard of AI, they are less aware of its specific health applications. Americans anticipate that medicine is likely to benefit from advances in AI; however, the anticipated benefits vary depending on the type of application. Specific application goals, such as disease prediction, diagnosis, and treatment, matter for the attitudes toward AI in health care among Americans. Most Americans reported wanting control over their personal health data. The willingness to share personal health information largely depends on the institutional actor collecting the data and the intended use. Conclusions Americans in general report seeing health care as an area in which AI applications could be particularly beneficial. However, they have substantial levels of concern regarding specific applications, especially those in which AI is involved in decision-making and regarding the privacy of health information.",
    "doi": "10.2196/40337",
    "url": "https://openalex.org/W4362522403",
    "pdf_url": "https://www.jmir.org/2023/1/e40337/PDF",
    "venue": "Journal of Medical Internet Research",
    "citation_count": 110,
    "fields_of_study": [
      "Public opinion",
      "Public health",
      "Health care",
      "Relevance (law)",
      "MEDLINE"
    ],
    "retrieved_at": "2026-02-02T16:58:14.584972"
  },
  {
    "source": "openalex",
    "source_id": "W2913771223",
    "title": "Software fairness",
    "authors": [
      "Yuriy Brun",
      "Alexandra Meliou"
    ],
    "year": 2018,
    "abstract": "A goal of software engineering research is advancing software quality and the success of the software engineering process. However, while recent studies have demonstrated a new kind of defect in software related to its ability to operate in fair and unbiased manner, software engineering has not yet wholeheartedly tackled these new kinds of defects, thus leaving software vulnerable. This paper outlines a vision for how software engineering research can help reduce fairness defects and represents a call to action by the software engineering research community to reify that vision. Modern software is riddled with examples of biased behavior, from automated translation injecting gender stereotypes, to vision systems failing to see faces of certain races, to the US criminal justice sytem relying on biased computational assessments of crime recidivism. While systems may learn bias from biased data, bias can also emerge from ambiguous or incomplete requirement specification, poor design, implementation bugs, and unintended component interactions. We argue that software fairness is analogous to software quality, and that numerous software engineering challenges in the areas of requirements, specification, design, testing, and verification need to be tackled to solve this problem.",
    "doi": "10.1145/3236024.3264838",
    "url": "https://openalex.org/W2913771223",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3236024.3264838",
    "venue": null,
    "citation_count": 118,
    "fields_of_study": [
      "Computer science",
      "Software engineering",
      "Social software engineering",
      "Software construction",
      "Software development"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585010"
  },
  {
    "source": "openalex",
    "source_id": "W4383722515",
    "title": "Harnessing the Power of ChatGPT for Automating Systematic Review Process: Methodology, Case Study, Limitations, and Future Directions",
    "authors": [
      "Ahmad Alshami",
      "Moustafa Elsayed",
      "Eslam Ali",
      "Abdelrahman E. E. Eltoukhy",
      "Tarek Zayed"
    ],
    "year": 2023,
    "abstract": "Systematic reviews (SR) are crucial in synthesizing and analyzing existing scientific literature to inform evidence-based decision-making. However, traditional SR methods often have limitations, including a lack of automation and decision support, resulting in time-consuming and error-prone reviews. To address these limitations and drive the field forward, we harness the power of the revolutionary language model, ChatGPT, which has demonstrated remarkable capabilities in various scientific writing tasks. By utilizing ChatGPT\u2019s natural language processing abilities, our objective is to automate and streamline the steps involved in traditional SR, explicitly focusing on literature search, screening, data extraction, and content analysis. Therefore, our methodology comprises four modules: (1) Preparation of Boolean research terms and article collection, (2) Abstract screening and articles categorization, (3) Full-text filtering and information extraction, and (4) Content analysis to identify trends, challenges, gaps, and proposed solutions. Throughout each step, our focus has been on providing quantitative analyses to strengthen the robustness of the review process. To illustrate the practical application of our method, we have chosen the topic of IoT applications in water and wastewater management and quality monitoring due to its critical importance and the dearth of comprehensive reviews in this field. The findings demonstrate the potential of ChatGPT in bridging the gap between traditional SR methods and AI language models, resulting in enhanced efficiency and reliability of SR processes. Notably, ChatGPT exhibits exceptional performance in filtering and categorizing relevant articles, leading to significant time and effort savings. Our quantitative assessment reveals the following: (1) the overall accuracy of ChatGPT for article discarding and classification is 88%, and (2) the F-1 scores of ChatGPT for article discarding and classification are 91% and 88%, respectively, compared to expert assessments. However, we identify limitations in its suitability for article extraction. Overall, this research contributes valuable insights to the field of SR, empowering researchers to conduct more comprehensive and reliable reviews while advancing knowledge and decision-making across various domains.",
    "doi": "10.3390/systems11070351",
    "url": "https://openalex.org/W4383722515",
    "pdf_url": "https://www.mdpi.com/2079-8954/11/7/351/pdf?version=1688974508",
    "venue": "Systems",
    "citation_count": 183,
    "fields_of_study": [
      "Computer science",
      "Data science",
      "Automation",
      "Robustness (evolution)",
      "Field (mathematics)"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585027"
  },
  {
    "source": "openalex",
    "source_id": "W3201470614",
    "title": "The Application of the Principles of Responsible AI on Social Media Marketing for Digital Health",
    "authors": [
      "Rui Liu",
      "Suraksha Gupta",
      "Parth Patel"
    ],
    "year": 2021,
    "abstract": null,
    "doi": "10.1007/s10796-021-10191-z",
    "url": "https://openalex.org/W3201470614",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10796-021-10191-z.pdf",
    "venue": "Information Systems Frontiers",
    "citation_count": 86,
    "fields_of_study": [
      "Social media",
      "Scrutiny",
      "Health care",
      "Dissemination",
      "Public relations"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585053"
  },
  {
    "source": "openalex",
    "source_id": "W3174685870",
    "title": "Societal Biases in Language Generation: Progress and Challenges",
    "authors": [
      "Emily Sheng",
      "Kai-Wei Chang",
      "Prem Natarajan",
      "Nanyun Peng"
    ],
    "year": 2021,
    "abstract": "Emily Sheng, Kai-Wei Chang, Prem Natarajan, Nanyun Peng. Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers). 2021.",
    "doi": "10.18653/v1/2021.acl-long.330",
    "url": "https://openalex.org/W3174685870",
    "pdf_url": "https://aclanthology.org/2021.acl-long.330.pdf",
    "venue": null,
    "citation_count": 108,
    "fields_of_study": [
      "Computer science",
      "Joint (building)",
      "Computational linguistics",
      "Volume (thermodynamics)",
      "Natural language processing"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585057"
  },
  {
    "source": "openalex",
    "source_id": "W3102619004",
    "title": "A governance framework for algorithmic accountability and transparency",
    "authors": [
      "Ansgar Koene",
      "Chris Clifton",
      "Yohko Hatada",
      "Helena Webb",
      "Rashida Richardson"
    ],
    "year": 2019,
    "abstract": "Algorithmic systems are increasingly being used as part of decision-making processes in both the public and private sectors, with potentially significant consequences for individuals, organisations and societies as a whole. Algorithmic systems in this context refer to the combination of algorithms, data and the interface process that together determine the outcomes that affect end users. Many types of decisions can be made faster and more efficiently using algorithms. A significant factor in the adoption of algorithmic systems for decision-making is their capacity to process large amounts of varied data sets (i.e. big data), which can be paired with machine learning methods in order to infer statistical models directly from the data. The same properties of scale, complexity and autonomous model inference however are linked to increasing concerns that many of these systems are opaque to the people affected by their use and lack clear explanations for the decisions they make. This lack of transparency risks undermining meaningful scrutiny and accountability, which is a significant concern when these systems are applied as part of decision-making processes that can have a considerable impact on people's human rights (e.g. critical safety decisions in autonomous vehicles; allocation of health and social service resources, etc.). This study develops policy options for the governance of algorithmic transparency and accountability, based on an analysis of the social, technical and regulatory challenges posed by algorithmic systems. Based on a review and analysis of existing proposals for governance of algorithmic systems, a set of four policy options are proposed, each of which addresses a different aspect of algorithmic transparency and accountability: 1. awareness raising: education, watchdogs and whistleblowers; 2. accountability in public-sector use of algorithmic decision-making; 3. regulatory oversight and legal liability; and 4. global coordination for algorithmic governance.",
    "doi": "10.2861/59990",
    "url": "https://openalex.org/W3102619004",
    "pdf_url": "https://nottingham-repository.worktribe.com/output/3979928",
    "venue": "Repository@Nottingham (University of Nottingham)",
    "citation_count": 105,
    "fields_of_study": [
      "Accountability",
      "Transparency (behavior)",
      "Computer science",
      "Corporate governance",
      "Scrutiny"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585063"
  },
  {
    "source": "openalex",
    "source_id": "W4206914990",
    "title": "Data Integration Challenges for Machine Learning in Precision Medicine",
    "authors": [
      "Mireya Mart\u00ednez-Garc\u00eda",
      "Enrique Hern\u00e1ndez\u2013Lemus"
    ],
    "year": 2022,
    "abstract": "A main goal of Precision Medicine is that of incorporating and integrating the vast corpora on different databases about the molecular and environmental origins of disease, into analytic frameworks, allowing the development of individualized, context-dependent diagnostics, and therapeutic approaches. In this regard, artificial intelligence and machine learning approaches can be used to build analytical models of complex disease aimed at prediction of personalized health conditions and outcomes. Such models must handle the wide heterogeneity of individuals in both their genetic predisposition and their social and environmental determinants. Computational approaches to medicine need to be able to efficiently manage, visualize and integrate, large datasets combining structure, and unstructured formats. This needs to be done while constrained by different levels of confidentiality, ideally doing so within a unified analytical architecture. Efficient data integration and management is key to the successful application of computational intelligence approaches to medicine. A number of challenges arise in the design of successful designs to medical data analytics under currently demanding conditions of performance in personalized medicine, while also subject to time, computational power, and bioethical constraints. Here, we will review some of these constraints and discuss possible avenues to overcome current challenges.",
    "doi": "10.3389/fmed.2021.784455",
    "url": "https://openalex.org/W4206914990",
    "pdf_url": "https://www.frontiersin.org/articles/10.3389/fmed.2021.784455/pdf",
    "venue": "Frontiers in Medicine",
    "citation_count": 133,
    "fields_of_study": [
      "Computer science",
      "Data science",
      "Precision medicine",
      "Confidentiality",
      "Context (archaeology)"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585085"
  },
  {
    "source": "openalex",
    "source_id": "W4288707390",
    "title": "Drug repurposing: a systematic review on root causes, barriers and facilitators",
    "authors": [
      "Nithya Krishnamurthy",
      "Alyssa Grimshaw",
      "Sydney A. Axson",
      "Sung Hee Choe",
      "Jennifer Miller"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1186/s12913-022-08272-z",
    "url": "https://openalex.org/W4288707390",
    "pdf_url": "https://bmchealthservres.biomedcentral.com/counter/pdf/10.1186/s12913-022-08272-z",
    "venue": "BMC Health Services Research",
    "citation_count": 218,
    "fields_of_study": [
      "Medicine",
      "Repurposing",
      "MEDLINE",
      "Transparency (behavior)",
      "Cochrane Library"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585102"
  },
  {
    "source": "openalex",
    "source_id": "W3095556657",
    "title": "Artificial cognition: How experimental psychology can help generate explainable artificial intelligence",
    "authors": [
      "J Taylor",
      "Graham W. Taylor"
    ],
    "year": 2020,
    "abstract": "Artificial intelligence powered by deep neural networks has reached a level of complexity where it can be difficult or impossible to express how a model makes its decisions. This black-box problem is especially concerning when the model makes decisions with consequences for human well-being. In response, an emerging field called explainable artificial intelligence (XAI) aims to increase the interpretability, fairness, and transparency of machine learning. In this paper, we describe how cognitive psychologists can make contributions to XAI. The human mind is also a black box, and cognitive psychologists have over 150 years of experience modeling it through experimentation. We ought to translate the methods and rigor of cognitive psychology to the study of artificial black boxes in the service of explainability. We provide a review of XAI for psychologists, arguing that current methods possess a blind spot that can be complemented by the experimental cognitive tradition. We also provide a framework for research in XAI, highlight exemplary cases of experimentation within XAI inspired by psychological science, and provide a tutorial on experimenting with machines. We end by noting the advantages of an experimental approach and invite other psychologists to conduct research in this exciting new field.",
    "doi": "10.3758/s13423-020-01825-5",
    "url": "https://openalex.org/W3095556657",
    "pdf_url": "https://link.springer.com/content/pdf/10.3758/s13423-020-01825-5.pdf",
    "venue": "Psychonomic Bulletin & Review",
    "citation_count": 102,
    "fields_of_study": [
      "Interpretability",
      "Cognition",
      "Psychology",
      "Field (mathematics)",
      "Transparency (behavior)"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585104"
  },
  {
    "source": "openalex",
    "source_id": "W4390058985",
    "title": "The Limitations and Ethical Considerations of ChatGPT",
    "authors": [
      "Shangying Hua",
      "Shuangci Jin",
      "Shengyi Jiang"
    ],
    "year": 2023,
    "abstract": "ABSTRACT With the advancements of artificial intelligence technology, ChatGPT, a new practice of artificial intelligence, holds immense potential across multiple fields. Its user-friendly human-machine interface, rapid response capabilities, and delivery of high-quality answers have attracted considerable attention and widespread usage. Regarded by many as a groundbreaking advancement in AI, ChatGPT represents a new milestone in the field. However, as with any technological evolution, the emergence of ChatGPT brings not only benefits, but also inevitable security risks and ethical issues. This paper provides specific information about ChatGPT, including its technology, limitations, ethical issues, governance paths and future directions. Specifically, we firstly offered a thorough exploration of the technical implementation details of GPT series models. Next, we provided an intricate analysis elucidating the reasons for limitations and scrutinized the consequential impacts, such as malicious misuse, privacy violation, and so on. Finally, we explore diverse governance paths to mitigate the impacts of ChatGPT and present future directions. This review aims to equip users with crucial knowledge, facilitating well-informed decision-making, effectively handling of potential challenges in employing ChatGPT, and staying abreast with the rapidly evolving landscape of this technology.",
    "doi": "10.1162/dint_a_00243",
    "url": "https://openalex.org/W4390058985",
    "pdf_url": "https://direct.mit.edu/dint/article-pdf/doi/10.1162/dint_a_00243/2200207/dint_a_00243.pdf",
    "venue": "Data Intelligence",
    "citation_count": 81,
    "fields_of_study": [
      "Milestone",
      "Field (mathematics)",
      "Computer science",
      "Corporate governance",
      "Ethical issues"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585121"
  },
  {
    "source": "openalex",
    "source_id": "W3183372445",
    "title": "Exploring perceptions of healthcare technologies enabled by artificial intelligence: an online, scenario-based survey",
    "authors": [
      "Alison L. Antes",
      "Sara Burrous",
      "Bryan A. Sisk",
      "Matthew J. Schuelke",
      "Jason D. Keune",
      "James M. DuBois"
    ],
    "year": 2021,
    "abstract": null,
    "doi": "10.1186/s12911-021-01586-8",
    "url": "https://openalex.org/W3183372445",
    "pdf_url": "https://bmcmedinformdecismak.biomedcentral.com/counter/pdf/10.1186/s12911-021-01586-8",
    "venue": "BMC Medical Informatics and Decision Making",
    "citation_count": 86,
    "fields_of_study": [
      "Openness to experience",
      "Psychosocial",
      "Health care",
      "Psychology",
      "Applied psychology"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585137"
  },
  {
    "source": "openalex",
    "source_id": "W4200352435",
    "title": "Blind spots in AI ethics",
    "authors": [
      "Thilo Hagendorff"
    ],
    "year": 2021,
    "abstract": "Abstract This paper critically discusses blind spots in AI ethics. AI ethics discourses typically stick to a certain set of topics concerning principles evolving mainly around explainability, fairness, and privacy. All these principles can be framed in a way that enables their operationalization by technical means. However, this requires stripping down the multidimensionality of very complex social constructs to something that is idealized, measurable, and calculable. Consequently, rather conservative, mainstream notions of the mentioned principles are conveyed, whereas critical research, alternative perspectives, and non-ideal approaches are largely neglected. Hence, one part of the paper considers specific blind spots regarding the very topics AI ethics focusses on. The other part, then, critically discusses blind spots regarding to topics that hold significant ethical importance but are hardly or not discussed at all in AI ethics. Here, the paper focuses on negative externalities of AI systems, exemplarily discussing the casualization of clickwork, AI ethics\u2019 strict anthropocentrism, and AI\u2019s environmental impact. Ultimately, the paper is intended to be a critical commentary on the ongoing development of the field of AI ethics. It makes the case for a rediscovery of the strength of ethics in the AI field, namely its sensitivity to suffering and harms that are caused by and connected to AI technologies.",
    "doi": "10.1007/s43681-021-00122-8",
    "url": "https://openalex.org/W4200352435",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s43681-021-00122-8.pdf",
    "venue": "AI and Ethics",
    "citation_count": 87,
    "fields_of_study": [
      "Mainstream",
      "Field (mathematics)",
      "Operationalization",
      "Engineering ethics",
      "Ideal (ethics)"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585139"
  },
  {
    "source": "openalex",
    "source_id": "W4392658848",
    "title": "Generative AI in Higher Education",
    "authors": [
      "Cecilia Ka Yuk Chan",
      "Tom Colloton"
    ],
    "year": 2024,
    "abstract": "Chan and Colloton\u2019s book is one of the first to provide a comprehensive examination of the use and impact of ChatGPT and Generative AI (GenAI) in higher education.&#13;\\n&#13;\\nSince November 2022, every conversation in higher education has involved ChatGPT and its impact on all aspects of teaching and learning. The book explores the necessity of AI literacy tailored to professional contexts, assess the strengths and weaknesses of incorporating ChatGPT in curriculum design, and delve into the transformation of assessment methods in the GenAI era. The authors introduce the Six Assessment Redesign Pivotal Strategies (SARPS) and an AI Assessment Integration Framework, encouraging a learner-centric assessment model. The necessity for well-crafted AI educational policies is explored, as well as a blueprint for policy formulation in academic institutions. Technical enthusiasts are catered to with a deep dive into the mechanics behind GenAI, from the history of neural networks to the latest advances and applications of GenAI technologies.&#13;\\n&#13;\\nWith an eye on the future of AI in education, this book will appeal to educators, students and scholars interested in the wider societal implications and the transformative role of GenAI in pedagogy and research.",
    "doi": "10.4324/9781003459026",
    "url": "https://openalex.org/W4392658848",
    "pdf_url": "https://api.taylorfrancis.com/content/books/oa-mono/download?identifierName=doi&identifierValue=10.4324/9781003459026&type=webpdf",
    "venue": null,
    "citation_count": 105,
    "fields_of_study": [
      "Generative grammar",
      "Artificial intelligence",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585156"
  },
  {
    "source": "openalex",
    "source_id": "W4389559236",
    "title": "AI-Enabled Medical Education: Threads of Change, Promising Futures, and Risky Realities Across Four Potential Future Worlds",
    "authors": [
      "Michelle Knopp",
      "Eric J. Warm",
      "Danielle Weber",
      "Matthew Kelleher",
      "Benjamin Kinnear",
      "Daniel J. Schumacher",
      "Sally A. Santen",
      "Eneida A. Mendon\u00e7a",
      "Laurah Turner"
    ],
    "year": 2023,
    "abstract": "Background The rapid trajectory of artificial intelligence (AI) development and advancement is quickly outpacing society's ability to determine its future role. As AI continues to transform various aspects of our lives, one critical question arises for medical education: what will be the nature of education, teaching, and learning in a future world where the acquisition, retention, and application of knowledge in the traditional sense are fundamentally altered by AI? Objective The purpose of this perspective is to plan for the intersection of health care and medical education in the future. Methods We used GPT-4 and scenario-based strategic planning techniques to craft 4 hypothetical future worlds influenced by AI's integration into health care and medical education. This method, used by organizations such as Shell and the Accreditation Council for Graduate Medical Education, assesses readiness for alternative futures and effectively manages uncertainty, risk, and opportunity. The detailed scenarios provide insights into potential environments the medical profession may face and lay the foundation for hypothesis generation and idea-building regarding responsible AI implementation. Results The following 4 worlds were created using OpenAI\u2019s GPT model: AI Harmony, AI conflict, The world of Ecological Balance, and Existential Risk. Risks include disinformation and misinformation, loss of privacy, widening inequity, erosion of human autonomy, and ethical dilemmas. Benefits involve improved efficiency, personalized interventions, enhanced collaboration, early detection, and accelerated research. Conclusions To ensure responsible AI use, the authors suggest focusing on 3 key areas: developing a robust ethical framework, fostering interdisciplinary collaboration, and investing in education and training. A strong ethical framework emphasizes patient safety, privacy, and autonomy while promoting equity and inclusivity. Interdisciplinary collaboration encourages cooperation among various experts in developing and implementing AI technologies, ensuring that they address the complex needs and challenges in health care and medical education. Investing in education and training prepares professionals and trainees with necessary skills and knowledge to effectively use and critically evaluate AI technologies. The integration of AI in health care and medical education presents a critical juncture between transformative advancements and significant risks. By working together to address both immediate and long-term risks and consequences, we can ensure that AI integration leads to a more equitable, sustainable, and prosperous future for both health care and medical education. As we engage with AI technologies, our collective actions will ultimately determine the state of the future of health care and medical education to harness AI's power while ensuring the safety and well-being of humanity.",
    "doi": "10.2196/50373",
    "url": "https://openalex.org/W4389559236",
    "pdf_url": "https://mededu.jmir.org/2023/1/e50373/PDF",
    "venue": "JMIR Medical Education",
    "citation_count": 87,
    "fields_of_study": [
      "Engineering ethics",
      "Health care",
      "Autonomy",
      "Public relations",
      "Sociology"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585173"
  },
  {
    "source": "openalex",
    "source_id": "W4388441462",
    "title": "ChatGPT is a Remarkable Tool\u2014For Experts",
    "authors": [
      "Amos Azaria",
      "Rina Azoulay",
      "Shulamit Reches"
    ],
    "year": 2023,
    "abstract": "ABSTRACT This paper investigates the capabilities of ChatGPT as an automated assistant in diverse domains, including scientific writing, mathematics, education, programming, and healthcare. We explore the potential of ChatGPT to enhance productivity, streamline problem-solving processes, and improve writing style. Furthermore, we highlight the potential risks associated with excessive reliance on ChatGPT in these fields. These limitations encompass factors like incorrect and fictitious responses, inaccuracies in code, limited logical reasoning abilities, overconfidence, and critical ethical concerns of copyright and privacy violation. We outline areas and objectives where ChatGPT proves beneficial, applications where it should be used judiciously, and scenarios where its reliability may be limited. In light of observed limitations, and given that the tool's fundamental errors may pose a special challenge for non-experts, ChatGPT should be used with a strategic methodology. By drawing from comprehensive experimental studies, we offer methods and flowcharts for effectively using ChatGPT. Our recommendations emphasize iterative interaction with ChatGPT and independent verification of its outputs. Considering the importance of utilizing ChatGPT judiciously and with expertise, we recommend its usage for experts who are well-versed in the respective domains.",
    "doi": "10.1162/dint_a_00235",
    "url": "https://openalex.org/W4388441462",
    "pdf_url": "https://direct.mit.edu/dint/article-pdf/doi/10.1162/dint_a_00235/2170613/dint_a_00235.pdf",
    "venue": "Data Intelligence",
    "citation_count": 86,
    "fields_of_study": [
      "Computer science",
      "Overconfidence effect",
      "Reliability (semiconductor)",
      "Management science",
      "Flowchart"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585207"
  },
  {
    "source": "openalex",
    "source_id": "W4313550453",
    "title": "Artificial Intelligence-Driven Talent Management System: Exploring the Risks and Options for Constructing a Theoretical Foundation",
    "authors": [
      "Ali Faqihi",
      "Shah Jahan Miah"
    ],
    "year": 2023,
    "abstract": "AI (Artificial intelligence) has the potential to improve strategies to talent management by implementing advanced automated systems for workforce management. AI can make this improvement a reality. The objective of this study is to discover the new requirements for generating a new AI-oriented artefact so that the issues pertaining to talent management are effectively addressed. The design artefact is an intelligent Human Resource Management (HRM) automation solution for talent career management primarily based on a talent intelligent module. Improving connections between professional assessment and planning features is the key goal of this initiative. Utilising a design science methodology we investigate the use of organised machine learning approaches. This technique is the key component of a complete AI solution framework that would be further informed through a suggested moderation of technology-organisation-environment (TOE) theory with the theory of diffusion of innovation (DOI). This framework was devised in order solve AI-related problems. Aside from the automated components available in talent management solutions, this study will make recommendations for practical approaches researchers may follow to fulfil a company\u2019s specific requirements for talent growth.",
    "doi": "10.3390/jrfm16010031",
    "url": "https://openalex.org/W4313550453",
    "pdf_url": "https://www.mdpi.com/1911-8074/16/1/31/pdf?version=1674009161",
    "venue": "Journal of risk and financial management",
    "citation_count": 77,
    "fields_of_study": [
      "Knowledge management",
      "Talent management",
      "Component (thermodynamics)",
      "Automation",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585223"
  },
  {
    "source": "openalex",
    "source_id": "W4281843594",
    "title": "IMPROVING HOME SECURITY USING BLOCKCHAIN",
    "authors": [
      "Nada Ratkovi\u0107"
    ],
    "year": 2022,
    "abstract": "The major problem with the use of smart home technology is that it often leads to various security issues. This mainly happens because the devices use open internet connections that may be vulnerable and subjected to multiple threats, hackers, and viruses. Some household IoT devices are forcefully introduced to the market, exposing the customers to significant risk factors. The websites and links do not have any copyright information or any privacy policies, due to which the hackers may immediately steal the confidential information of the user. For instance, the door locking password may be hacked by cyber criminals, and they may use it to attack the home when there is nobody in the home. This paper presents how to use block-chain to improve home security.",
    "doi": "10.54489/ijcim.v2i1.72",
    "url": "https://openalex.org/W4281843594",
    "pdf_url": "https://journals.gaftim.com/index.php/ijcim/article/download/72/33",
    "venue": "International Journal of Computations Information and Manufacturing (IJCIM)",
    "citation_count": 125,
    "fields_of_study": [
      "Hacker",
      "Computer security",
      "nobody",
      "Internet privacy",
      "Password"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585239"
  },
  {
    "source": "openalex",
    "source_id": "W3157668147",
    "title": "The Biography of an Algorithm: Performing algorithmic technologies in organizations",
    "authors": [
      "Vern Glaser",
      "Neil Pollock",
      "Luciana D\u2019Adderio"
    ],
    "year": 2021,
    "abstract": "Algorithms are ubiquitous in modern organizations. Typically, researchers have viewed algorithms as self-contained computational tools that either magnify organizational capabilities or generate unintended negative consequences. To overcome this limited understanding of algorithms as stable entities, we propose two moves. The first entails building on a performative perspective to theorize algorithms as entangled, relational, emergent, and nested assemblages that use theories\u2014and the sociomaterial networks they invoke\u2014to automate decisions, enact roles and expertise, and perform calculations. The second move entails building on our dynamic perspective on algorithms to theorize how algorithms evolve as they move across contexts and over time. To this end, we introduce a biographical perspective on algorithms which traces their evolution by focusing on key \u201cbiographical moments.\u201d We conclude by discussing how our performativity-inspired biographical perspective on algorithms can help management and organization scholars better understand organizational decision-making, the spread of technologies and their logics, and the dynamics of practices and routines.",
    "doi": "10.1177/26317877211004609",
    "url": "https://openalex.org/W3157668147",
    "pdf_url": "https://doi.org/10.1177/26317877211004609",
    "venue": "Organization Theory",
    "citation_count": 118,
    "fields_of_study": [
      "Performative utterance",
      "Perspective (graphical)",
      "Performativity",
      "Computer science",
      "Key (lock)"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585251"
  },
  {
    "source": "openalex",
    "source_id": "W3134210117",
    "title": "An Action-Oriented AI Policy Toolkit for Technology Audits by Community Advocates and Activists",
    "authors": [
      "P. M. Krafft",
      "Meg Young",
      "Michael Katell",
      "Jennifer E. Lee",
      "Shankar Narayan",
      "Micah Epstein",
      "Dharma Dailey",
      "Bernease Herman",
      "Aaron Tam",
      "Vivian Guetler",
      "Corinne Bintz",
      "Daniella Raz",
      "Pa Ousman Jobe",
      "Franziska Putz",
      "Brian Robick",
      "Bissan Barghouti"
    ],
    "year": 2021,
    "abstract": "Motivated by the extensive documented disparate harms of artificial intelligence (AI), many recent practitioner-facing reflective tools have been created to promote responsible AI development. However, the use of such tools internally by technology development firms addresses responsible AI as an issue of closed-door compliance rather than a matter of public concern. Recent advocate and activist efforts intervene in AI as a public policy problem, inciting a growing number of cities to pass bans or other ordinances on AI and surveillance technologies. In support of this broader ecology of political actors, we present a set of reflective tools intended to increase public participation in technology advocacy for AI policy action. To this end, the Algorithmic Equity Toolkit (the AEKit) provides a practical policy-facing definition of AI, a flowchart for assessing technologies against that definition, a worksheet for decomposing AI systems into constituent parts, and a list of probing questions that can be posed to vendors, policy-makers, or government agencies. The AEKit carries an action-orientation towards political encounters between community groups in the public and their representatives, opening up the work of AI reflection and remediation to multiple points of intervention. Unlike current reflective tools available to practitioners, our toolkit carries with it a politics of community participation and activism.",
    "doi": "10.1145/3442188.3445938",
    "url": "https://openalex.org/W3134210117",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3442188.3445938",
    "venue": null,
    "citation_count": 72,
    "fields_of_study": [
      "Public policy",
      "Public relations",
      "Politics",
      "Audit",
      "Equity (law)"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585266"
  },
  {
    "source": "openalex",
    "source_id": "W4391617198",
    "title": "Integrating Artificial Intelligence for Drug Discovery in the Context of Revolutionizing Drug Delivery",
    "authors": [
      "Anita Ioana Vi\u0219an",
      "Irina Negu\u021b"
    ],
    "year": 2024,
    "abstract": "Drug development is expensive, time-consuming, and has a high failure rate. In recent years, artificial intelligence (AI) has emerged as a transformative tool in drug discovery, offering innovative solutions to complex challenges in the pharmaceutical industry. This manuscript covers the multifaceted role of AI in drug discovery, encompassing AI-assisted drug delivery design, the discovery of new drugs, and the development of novel AI techniques. We explore various AI methodologies, including machine learning and deep learning, and their applications in target identification, virtual screening, and drug design. This paper also discusses the historical development of AI in medicine, emphasizing its profound impact on healthcare. Furthermore, it addresses AI\u2019s role in the repositioning of existing drugs and the identification of drug combinations, underscoring its potential in revolutionizing drug delivery systems. The manuscript provides a comprehensive overview of the AI programs and platforms currently used in drug discovery, illustrating the technological advancements and future directions of this field. This study not only presents the current state of AI in drug discovery but also anticipates its future trajectory, highlighting the challenges and opportunities that lie ahead.",
    "doi": "10.3390/life14020233",
    "url": "https://openalex.org/W4391617198",
    "pdf_url": "https://www.mdpi.com/2075-1729/14/2/233/pdf?version=1707364240",
    "venue": "Life",
    "citation_count": 203,
    "fields_of_study": [
      "Drug discovery",
      "Identification (biology)",
      "Context (archaeology)",
      "Computer science",
      "Data science"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585283"
  },
  {
    "source": "openalex",
    "source_id": "W4310228395",
    "title": "Bias and Debias in Recommender System: A Survey and Future Directions",
    "authors": [
      "Jiawei Chen",
      "Hande Dong",
      "Xiang Wang",
      "Fuli Feng",
      "Meng Wang",
      "Xiangnan He"
    ],
    "year": 2020,
    "abstract": "While recent years have witnessed a rapid growth of research papers on recommender system (RS), most of the papers focus on inventing machine learning models to better fit user behavior data. However, user behavior data is observational rather than experimental. This makes various biases widely exist in the data, including but not limited to selection bias, position bias, exposure bias, and popularity bias. Blindly fitting the data without considering the inherent biases will result in many serious issues, e.g., the discrepancy between offline evaluation and online metrics, hurting user satisfaction and trust on the recommendation service, etc. To transform the large volume of research models into practical improvements, it is highly urgent to explore the impacts of the biases and perform debiasing when necessary. When reviewing the papers that consider biases in RS, we find that, to our surprise, the studies are rather fragmented and lack a systematic organization. The terminology ``bias'' is widely used in the literature, but its definition is usually vague and even inconsistent across papers. This motivates us to provide a systematic survey of existing work on RS biases. In this paper, we first summarize seven types of biases in recommendation, along with their definitions and characteristics. We then provide a taxonomy to position and organize the existing work on recommendation debiasing. Finally, we identify some open challenges and envision some future directions, with the hope of inspiring more research work on this important yet less investigated topic. The summary of debiasing methods reviewed in this survey can be found at \\url{https://github.com/jiawei-chen/RecDebiasing}.",
    "doi": "10.48550/arxiv.2010.03240",
    "url": "https://openalex.org/W4310228395",
    "pdf_url": "https://arxiv.org/pdf/2010.03240",
    "venue": "arXiv (Cornell University)",
    "citation_count": 159,
    "fields_of_study": [
      "Debiasing",
      "Computer science",
      "Recommender system",
      "Terminology",
      "Popularity"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585300"
  },
  {
    "source": "openalex",
    "source_id": "W4382318759",
    "title": "Digital innovations for\u00a0sustainable and\u00a0resilient agricultural systems",
    "authors": [
      "Robert Finger"
    ],
    "year": 2023,
    "abstract": "Abstract Digitalisation is rapidly transforming the agri-food sector. This paper investigates emerging opportunities, challenges and policy options. We show that digital innovations can contribute to more sustainable and resilient agricultural systems. For example, digital innovations enable increased productivity, reduced environmental footprints and higher resilience of farms. However, these optimistic outcomes of increasing digitalisation of the agricultural sector will not emerge on their own, but this development comes with several challenges, costs and risks, e.g. in economic, social and ethical dimensions. We provide policy recommendations to explore opportunities and avoid risks. Moreover, we discuss implications for future research in agricultural economics.",
    "doi": "10.1093/erae/jbad021",
    "url": "https://openalex.org/W4382318759",
    "pdf_url": "https://academic.oup.com/erae/advance-article-pdf/doi/10.1093/erae/jbad021/50725484/jbad021.pdf",
    "venue": "European Review of Agricultural Economics",
    "citation_count": 172,
    "fields_of_study": [
      "Agriculture",
      "Resilience (materials science)",
      "Productivity",
      "Business",
      "Agricultural productivity"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585320"
  },
  {
    "source": "openalex",
    "source_id": "W4406199489",
    "title": "Generative AI in Higher Education: Balancing Innovation and Integrity",
    "authors": [
      "Nigel Francis",
      "Sue Jones",
      "David P. Smith"
    ],
    "year": 2025,
    "abstract": "Generative Artificial Intelligence (GenAI) is rapidly transforming the landscape of higher education, offering novel opportunities for personalised learning and innovative assessment methods. This paper explores the dual-edged nature of GenAI\u2019s integration into educational practices, focusing on both its potential to enhance student engagement and learning outcomes and the significant challenges it poses to academic integrity and equity. Through a comprehensive review of current literature, we examine the implications of GenAI on assessment practices, highlighting the need for robust ethical frameworks to guide its use. Our analysis is framed within pedagogical theories, including social constructivism and competency-based learning, highlighting the importance of balancing human expertise and AI capabilities. We also address broader ethical concerns associated with GenAI, such as the risks of bias, the digital divide, and the environmental impact of AI technologies. This paper argues that while GenAI can provide substantial benefits in terms of automation and efficiency, its integration must be managed with care to avoid undermining the authenticity of student work and exacerbating existing inequalities. Finally, we propose a set of recommendations for educational institutions, including developing GenAI literacy programmes, revising assessment designs to incorporate critical thinking and creativity, and establishing transparent policies that ensure fairness and accountability in GenAI use. By fostering a responsible approach to GenAI, higher education can harness its potential while safeguarding the core values of academic integrity and inclusive education.",
    "doi": "10.3389/bjbs.2024.14048",
    "url": "https://openalex.org/W4406199489",
    "pdf_url": "https://www.frontierspartnerships.org/journals/british-journal-of-biomedical-science/articles/10.3389/bjbs.2024.14048/pdf",
    "venue": "British Journal of Biomedical Science",
    "citation_count": 85,
    "fields_of_study": [
      "Generative grammar",
      "Generative model",
      "Psychology",
      "Computer science",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585330"
  },
  {
    "source": "openalex",
    "source_id": "W3119071838",
    "title": "Privacy protections to encourage use of health-relevant digital data in a learning health system",
    "authors": [
      "Deven McGraw",
      "Kenneth D. Mandl"
    ],
    "year": 2021,
    "abstract": null,
    "doi": "10.1038/s41746-020-00362-8",
    "url": "https://openalex.org/W3119071838",
    "pdf_url": "https://www.nature.com/articles/s41746-020-00362-8.pdf",
    "venue": "npj Digital Medicine",
    "citation_count": 192,
    "fields_of_study": [
      "Health care",
      "Internet privacy",
      "Information privacy",
      "Digital health",
      "Business"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585349"
  },
  {
    "source": "openalex",
    "source_id": "W4401667275",
    "title": "Artificial intelligence for literature reviews: opportunities and challenges",
    "authors": [
      "F. J. Bola\u00f1os",
      "Angelo A. Salatino",
      "Francesco Osborne",
      "Enrico Motta"
    ],
    "year": 2024,
    "abstract": "Abstract This paper presents a comprehensive review of the use of Artificial Intelligence (AI) in Systematic Literature Reviews (SLRs). A SLR is a rigorous and organised methodology that assesses and integrates prior research on a given topic. Numerous tools have been developed to assist and partially automate the SLR process. The increasing role of AI in this field shows great potential in providing more effective support for researchers, moving towards the semi-automatic creation of literature reviews. Our study focuses on how AI techniques are applied in the semi-automation of SLRs, specifically in the screening and extraction phases. We examine 21 leading SLR tools using a framework that combines 23 traditional features with 11 AI features. We also analyse 11 recent tools that leverage large language models for searching the literature and assisting academic writing. Finally, the paper discusses current trends in the field, outlines key research challenges, and suggests directions for future research. We highlight three primary research challenges: integrating advanced AI solutions, such as large language models and knowledge graphs, improving usability, and developing a standardised evaluation framework. We also propose best practices to ensure more robust evaluations in terms of performance, usability, and transparency. Overall, this review offers a detailed overview of AI-enhanced SLR tools for researchers and practitioners, providing a foundation for the development of next-generation AI solutions in this field.",
    "doi": "10.1007/s10462-024-10902-3",
    "url": "https://openalex.org/W4401667275",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10462-024-10902-3.pdf",
    "venue": "Artificial Intelligence Review",
    "citation_count": 128,
    "fields_of_study": [
      "Computer science",
      "Usability",
      "Leverage (statistics)",
      "Systematic review",
      "Field (mathematics)"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585351"
  },
  {
    "source": "openalex",
    "source_id": "W4392162455",
    "title": "Managing the race to the moon: Global policy and governance in Artificial Intelligence regulation\u2014A contemporary overview and an analysis of socioeconomic consequences",
    "authors": [
      "Yoshija Walter"
    ],
    "year": 2024,
    "abstract": "Abstract This paper delves into the complexities of global AI regulation and governance, emphasizing the socio-economic repercussions of rapid AI development. It scrutinizes the challenges in creating effective governance structures amidst the AI race, considering diverse global perspectives and policies. The discourse moves beyond specific corporate examples, addressing broader implications and sector-wide impacts of AI on employment, truth discernment, and democratic stability. The analysis focuses on contrasting regulatory approaches across key regions\u2014the United States, European Union, Asia, Africa, and the Americas and thus highlighting the variations and commonalities in strategies and implementations. This comparative study reveals the intricacies and hurdles in formulating a cohesive global policy for AI regulation. Central to the paper is the examination of the dynamic between rapid AI innovation and the slower pace of regulatory and ethical standard-setting. It critically evaluates the advantages and drawbacks of shifting regulatory responsibilities between government bodies and the private sector. In response to these challenges, the discussion proposes an innovative and integrated regulatory model. The model advocates for a collaborative network that blends governmental authority with industry expertise, aiming to establish adaptive, responsive regulations (called \u201cdynamic laws\u201d) that can evolve with technological advancements. The novel approach aims to bridge the gap between rapid AI advancements in the industry and the essential democratic processes of law-making.",
    "doi": "10.1007/s44163-024-00109-4",
    "url": "https://openalex.org/W4392162455",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s44163-024-00109-4.pdf",
    "venue": "Discover Artificial Intelligence",
    "citation_count": 92,
    "fields_of_study": [
      "Race (biology)",
      "Socioeconomic status",
      "Corporate governance",
      "Political science",
      "Sociology"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585369"
  },
  {
    "source": "openalex",
    "source_id": "W3161310076",
    "title": "Predicting sex from retinal fundus photographs using automated deep learning",
    "authors": [
      "Edward Korot",
      "Nikolas Pontikos",
      "Xiaoxuan Liu",
      "Siegfried K. Wagner",
      "Livia Faes",
      "Josef Huemer",
      "Konstantinos Balaskas",
      "Alastair K. Denniston",
      "Anthony P. Khawaja",
      "Pearse A. Keane"
    ],
    "year": 2021,
    "abstract": "Abstract Deep learning may transform health care, but model development has largely been dependent on availability of advanced technical expertise. Herein we present the development of a deep learning model by clinicians without coding, which predicts reported sex from retinal fundus photographs. A model was trained on 84,743 retinal fundus photos from the UK Biobank dataset. External validation was performed on 252 fundus photos from a tertiary ophthalmic referral center. For internal validation, the area under the receiver operating characteristic curve (AUROC) of the code free deep learning (CFDL) model was 0.93. Sensitivity, specificity, positive predictive value (PPV) and accuracy (ACC) were 88.8%, 83.6%, 87.3% and 86.5%, and for external validation were 83.9%, 72.2%, 78.2% and 78.6% respectively. Clinicians are currently unaware of distinct retinal feature variations between males and females, highlighting the importance of model explainability for this task. The model performed significantly worse when foveal pathology was present in the external validation dataset, ACC: 69.4%, compared to 85.4% in healthy eyes, suggesting the fovea is a salient region for model performance OR (95% CI): 0.36 (0.19, 0.70) p = 0.0022. Automated machine learning (AutoML) may enable clinician-driven automated discovery of novel insights and disease biomarkers.",
    "doi": "10.1038/s41598-021-89743-x",
    "url": "https://openalex.org/W3161310076",
    "pdf_url": "https://www.nature.com/articles/s41598-021-89743-x.pdf",
    "venue": "Scientific Reports",
    "citation_count": 133,
    "fields_of_study": [
      "Fundus (uterus)",
      "Deep learning",
      "Artificial intelligence",
      "Retinal",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585388"
  },
  {
    "source": "openalex",
    "source_id": "W4385571411",
    "title": "Is GPT-3 a Good Data Annotator?",
    "authors": [
      "Bosheng Ding",
      "Chengwei Qin",
      "Linlin Liu",
      "Yew Ken Chia",
      "Boyang Li",
      "Shafiq Joty",
      "Lidong Bing"
    ],
    "year": 2023,
    "abstract": "Bosheng Ding, Chengwei Qin, Linlin Liu, Yew Ken Chia, Boyang Li, Shafiq Joty, Lidong Bing. Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2023.",
    "doi": "10.18653/v1/2023.acl-long.626",
    "url": "https://openalex.org/W4385571411",
    "pdf_url": "https://aclanthology.org/2023.acl-long.626.pdf",
    "venue": null,
    "citation_count": 127,
    "fields_of_study": [
      "Volume (thermodynamics)",
      "Computational linguistics",
      "Computer science",
      "Natural language processing",
      "Library science"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585405"
  },
  {
    "source": "openalex",
    "source_id": "W4284891135",
    "title": "The Landscape of Teaching Resources for AI Education",
    "authors": [
      "Stefania Druga",
      "Nancy Otero",
      "Amy J. Ko"
    ],
    "year": 2022,
    "abstract": "Artificial Intelligence (AI) educational resources such as training tools, interactive demos, and dedicated curriculum are increasingly popular among educators and learners. While prior work has examined pedagogies for promoting AI literacy, it has yet to examine how well technology resources support these pedagogies. To address this gap, we conducted a systematic analysis of existing online resources for AI education, investigating what learning and teaching affordances these resources have to support AI education. We used the Technological Pedagogical Content Knowledge (TPACK) framework to analyze a final corpus of 50 AI resources. We found that most resources support active learning, have digital or physical dependencies, do not include all the five big ideas defined by AI4K12 guidelines, and do not offer built-in support for assessment or feedback. Teaching guides are hard to find or require technical knowledge. Based on our findings, we propose that future AI curricula move from singular activities and demos to more holistic designs that include support, guidance, and flexibility for how AI technology, concepts, and pedagogy play out in the classroom.",
    "doi": "10.1145/3502718.3524782",
    "url": "https://openalex.org/W4284891135",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3502718.3524782",
    "venue": null,
    "citation_count": 81,
    "fields_of_study": [
      "Affordance",
      "Curriculum",
      "Computer science",
      "Flexibility (engineering)",
      "Literacy"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585410"
  },
  {
    "source": "openalex",
    "source_id": "W4394806371",
    "title": "The TESCREAL bundle: Eugenics and the promise of utopia through artificial general intelligence",
    "authors": [
      "Timnit Gebru",
      "\u00c9mile P. Torres"
    ],
    "year": 2024,
    "abstract": "The stated goal of many organizations in the field of artificial intelligence (AI) is to develop artificial general intelligence (AGI), an imagined system with more intelligence than anything we have ever seen. Without seriously questioning whether such a system can and should be built, researchers are working to create \u201csafe AGI\u201d that is \u201cbeneficial for all of humanity.\u201d We argue that, unlike systems with specific applications which can be evaluated following standard engineering principles, undefined systems like \u201cAGI\u201d cannot be appropriately tested for safety. Why, then, is building AGI often framed as an unquestioned goal in the field of AI? In this paper, we argue that the normative framework that motivates much of this goal is rooted in the Anglo-American eugenics tradition of the twentieth century. As a result, many of the very same discriminatory attitudes that animated eugenicists in the past (e.g., racism, xenophobia, classism, ableism, and sexism) remain widespread within the movement to build AGI, resulting in systems that harm marginalized groups and centralize power, while using the language of \u201csafety\u201d and \u201cbenefiting humanity\u201d to evade accountability. We conclude by urging researchers to work on defined tasks for which we can develop safety protocols, rather than attempting to build a presumably all-knowing system such as AGI.",
    "doi": "10.5210/fm.v29i4.13636",
    "url": "https://openalex.org/W4394806371",
    "pdf_url": "https://firstmonday.org/ojs/index.php/fm/article/download/13636/11606",
    "venue": "First Monday",
    "citation_count": 107,
    "fields_of_study": [
      "Eugenics",
      "Utopia",
      "Dystopia",
      "Transhumanism",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585425"
  },
  {
    "source": "openalex",
    "source_id": "W4221001772",
    "title": "How artificial intelligence might change academic library work: Applying the competencies literature and the theory of the professions",
    "authors": [
      "Andrew Cox"
    ],
    "year": 2022,
    "abstract": "Abstract The probable impact of artificial intelligence (AI) on work, including professional work, is contested, but it is unlikely to leave them untouched. The purpose of this conceptual paper is to consider the likelihood of the adoption of different approaches to AI in academic libraries. As theoretical lenses to guide the analysis the paper draws on both the library and information science (LIS) literature on librarians' competencies and the notions of jurisdiction and hybrid logics drawn from the sociological theory of the professions. The paper starts by outlining these theories and then reviews the nature of AI and the range of its potential uses in academic libraries. The main focus of the paper is on the application of AI to knowledge discovery. Eleven different potential approaches libraries might adopt to such AI applications are analyzed and their likelihood evaluated. Then it is considered how a range of internal and external factors might influence the adoption of AI. In addition to reflecting on the possible impact of AI on librarianship the paper contributes to understanding how to synthesize the competencies literature with the theory of the profession and presents a new understanding of librarians as hybrid.",
    "doi": "10.1002/asi.24635",
    "url": "https://openalex.org/W4221001772",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/asi.24635",
    "venue": "Journal of the Association for Information Science and Technology",
    "citation_count": 124,
    "fields_of_study": [
      "Sociology",
      "Computer science",
      "Work (physics)",
      "Jurisdiction",
      "Knowledge management"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585442"
  },
  {
    "source": "openalex",
    "source_id": "W4287218595",
    "title": "Is AI recruiting (un)ethical? A human rights perspective on the use of AI for hiring",
    "authors": [
      "Anna Lena Hunkenschroer",
      "Alexander Kriebitz"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1007/s43681-022-00166-4",
    "url": "https://openalex.org/W4287218595",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s43681-022-00166-4.pdf",
    "venue": "AI and Ethics",
    "citation_count": 69,
    "fields_of_study": [
      "Perspective (graphical)",
      "Human rights",
      "Engineering ethics",
      "Political science",
      "Environmental ethics"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585458"
  },
  {
    "source": "openalex",
    "source_id": "W4382246267",
    "title": "Exploring the Transformative Role of Artificial Intelligence and Metaverse in Education: A Comprehensive Review",
    "authors": [
      "Devanshu Kumar",
      "Md. Alimul Haque",
      "Khushboo Mishra",
      "Farheen Islam",
      "Binay Kumar Mishra",
      "Sultan Ahmad"
    ],
    "year": 2023,
    "abstract": "Introduction: this review paper provides a comprehensive examination of the applications and impact of artificial intelligence (AI) in the field of education. With advancements in AI technologies, the educational landscape has witnessed significant transformations. This review aims to explore the diverse AI techniques employed in education and their potential contributions to teaching, learning, assessment, and educational support. Objective: this research article aims to tracing the development of AI in education from its early beginnings to its current state. It highlights key milestones and breakthroughs that have shaped the field, including the emergence of intelligent tutoring systems and expert systems. Methods: the article provides a comprehensive overview of the various AI techniques utilized in education, such as machine learning, natural language processing, computer vision, and data mining. Each technique is discussed in detail, showcasing the algorithms, models, and methodologies used within each approach. Results: while the benefits of AI in education are substantial, the paper also addresses the challenges associated with its integration. Ethical considerations, privacy concerns, and the need for effective human-AI collaboration are discussed in-depth. Conclusion: this review underscores the transformative potential of AI in education. By harnessing AI technologies effectively and responsibly, educators and policymakers can unlock new possibilities for enhancing teaching and learning experiences, fostering personalized instruction, and driving educational advancement.",
    "doi": "10.56294/mr202355",
    "url": "https://openalex.org/W4382246267",
    "pdf_url": "https://mr.saludcyt.ar/index.php/mr/article/download/55/126",
    "venue": "Metaverse Basic and Applied Research",
    "citation_count": 104,
    "fields_of_study": [
      "Transformative learning",
      "Metaverse",
      "Psychology",
      "Engineering ethics",
      "Sociology"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585461"
  },
  {
    "source": "openalex",
    "source_id": "W4391609543",
    "title": "Does AI-Driven Technostress Promote or Hinder Employees\u2019 Artificial Intelligence Adoption Intention? A Moderated Mediation Model of Affective Reactions and Technical Self-Efficacy",
    "authors": [
      "Po\u2010Chien Chang",
      "Wenhui Zhang",
      "Qihai Cai",
      "Hongchi Guo"
    ],
    "year": 2024,
    "abstract": "Overall, our study suggests that AI-driven challenge technology stressors positively impact AI adoption intention through the cultivation of positive affect, while hindrance technology stressors impede AI adoption intention by triggering AI anxiety. Additionally, technical self-efficacy emerges as a crucial moderator in shaping these relationships. This research has the potential to make a meaningful contribution to the literature on AI adoption intention, deepening our holistic understanding of the influential mechanisms involved. Furthermore, the study affirms the applicability and relevance of Affective Events Theory (AET) and the Challenge-Hindrance Stressor Framework (CHSF). In practical terms, the research provides actionable insights for organizations to effectively manage employees' AI adoption intention.",
    "doi": "10.2147/prbm.s441444",
    "url": "https://openalex.org/W4391609543",
    "pdf_url": "https://www.dovepress.com/getfile.php?fileID=96570",
    "venue": "Psychology Research and Behavior Management",
    "citation_count": 111,
    "fields_of_study": [
      "Stressor",
      "Psychology",
      "Technostress",
      "Snowball sampling",
      "Affect (linguistics)"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585487"
  },
  {
    "source": "openalex",
    "source_id": "W4388725733",
    "title": "Large Language Models: A Comprehensive Survey of its Applications, Challenges, Limitations, and Future Prospects",
    "authors": [
      "Muhammad Usman Hadi",
      "qasem al tashi",
      "Rizwan Qureshi",
      "Abbas Shah",
      "Amgad Muneer",
      "Muhammad Irfan",
      "Anas Zafar",
      "Muhammad Bilal Shaikh",
      "Naveed Akhtar",
      "Jia Wu",
      "Seyedali Mirjalili"
    ],
    "year": 2023,
    "abstract": "&lt;p&gt;Within the vast expanse of computerized language processing, a revolutionary entity known as Large Language Models (LLMs) has emerged, wielding immense power in its capacity to comprehend intricate linguistic patterns and conjure coherent and contextually fitting responses. Large language models (LLMs) are a type of artificial intelligence (AI) that have emerged as powerful tools for a wide range of tasks, including natural language processing (NLP), machine translation, and question-answering. This survey paper provides a comprehensive overview of LLMs, including their history, architecture, training methods, applications, and challenges. The paper begins by discussing the fundamental concepts of generative AI and the architecture of generative pre- trained transformers (GPT). It then provides an overview of the history of LLMs, their evolution over time, and the different training methods that have been used to train them. The paper then discusses the wide range of applications of LLMs, including medical, education, finance, and engineering. It also discusses how LLMs are shaping the future of AI and how they can be used to solve real-world problems. The paper then discusses the challenges associated with deploying LLMs in real-world scenarios, including ethical considerations, model biases, interpretability, and computational resource requirements. It also highlights techniques for enhancing the robustness and controllability of LLMs, and addressing bias, fairness, and generation quality issues. Finally, the paper concludes by highlighting the future of LLM research and the challenges that need to be addressed in order to make LLMs more reliable and useful. This survey paper is intended to provide researchers, practitioners, and enthusiasts with a comprehensive understanding of LLMs, their evolution, applications, and challenges. By consolidating the state-of-the-art knowledge in the field, this survey serves as a valuable resource for further advancements in the development and utilization of LLMs for a wide range of real-world applications. The GitHub repo for this project is available at https://github.com/anas-zafar/LLM-Survey&lt;/p&gt;",
    "doi": "10.36227/techrxiv.23589741.v4",
    "url": "https://openalex.org/W4388725733",
    "pdf_url": "https://doi.org/10.36227/techrxiv.23589741.v4",
    "venue": null,
    "citation_count": 101,
    "fields_of_study": [
      "Interpretability",
      "Computer science",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585502"
  },
  {
    "source": "openalex",
    "source_id": "W4394964316",
    "title": "Higher Education\u2019s Generative Artificial Intelligence Paradox: The Meaning of Chatbot Mania",
    "authors": [
      "Juergen Rudolph",
      "Fadhil Mohamed Mohamed Ismail",
      "\u015etefan Popenici"
    ],
    "year": 2024,
    "abstract": "Higher education is currently under a significant transformation due to the emergence of generative artificial intelligence (GenAI) technologies, the hype surrounding GenAI and the increasing influence of educational technology business groups over tertiary education. This commentary, prepared for the Special Issue of the Journal of University Teaching &amp; Learning Practice (JUTLP) on \u201cEnhancing student engagement using Artificial Intelligence (AI) and chatbots,\u201d delves into the complex landscape of opportunities and threats that AI chatbots, including ChatGPT, introduce to the realm of higher education. We argue that while GenAI offers promise in enhancing pedagogy, research, administration, and student support, concerns around academic integrity, labour displacement, embedded biases, environmental sustainability, increased commercialisation, and regulatory gaps necessitate a critical approach. Our commentary advocates for the development of critical AI literacy among educators and students, emphasising the necessity to foster an environment of responsible innovation and informed use of AI. We posit that the successful integration of AI in higher education must be grounded in the principles of ethics, equity, and the prioritisation of educational aims and human values. By offering a critical and nuanced exploration of these issues, our commentary aims to contribute to the ongoing discourse on how higher education institutions can navigate the rise of GenAI, ensuring that technological advancements benefit all stakeholders while upholding core academic values.",
    "doi": "10.53761/54fs5e77",
    "url": "https://openalex.org/W4394964316",
    "pdf_url": "https://open-publishing.org/journals/index.php/jutlp/article/download/744/754",
    "venue": "Journal of University Teaching and Learning Practice",
    "citation_count": 88,
    "fields_of_study": [
      "Chatbot",
      "Generative grammar",
      "Meaning (existential)",
      "Mania",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585529"
  },
  {
    "source": "openalex",
    "source_id": "W4394949392",
    "title": "The Artificial Intelligence Assessment Scale (AIAS): A Framework for Ethical Integration of Generative AI in Educational Assessment",
    "authors": [
      "Mike Perkins",
      "Leon Furze",
      "Jasper Roe",
      "Jason MacVaugh"
    ],
    "year": 2024,
    "abstract": "Recent developments in Generative Artificial Intelligence (GenAI) have created a paradigm shift in multiple areas of society, and the use of these technologies is likely to become a defining feature of education in coming decades. GenAI offers transformative pedagogical opportunities, while simultaneously posing ethical and academic challenges. Against this backdrop, we outline a practical, simple, and sufficiently comprehensive tool to allow for the integration of GenAI tools into educational assessment: the AI Assessment Scale (AIAS). The AIAS empowers educators to select the appropriate level of GenAI usage in assessments based on the learning outcomes they seek to address. The AIAS offers greater clarity and transparency for students and educators, provides a fair and equitable policy tool for institutions to work with, and offers a nuanced approach which embraces the opportunities of GenAI while recognising that there are instances where such tools may not be pedagogically appropriate or necessary. By adopting a practical, flexible approach that can be implemented quickly, the AIAS can form a much-needed starting point to address the current uncertainty and anxiety regarding GenAI in education. As a secondary objective, we engage with the current literature and advocate for a refocused discourse on GenAI tools in education, one which foregrounds how technologies can help support and enhance teaching and learning, which contrasts with the current focus on GenAI as a facilitator of academic misconduct.",
    "doi": "10.53761/q3azde36",
    "url": "https://openalex.org/W4394949392",
    "pdf_url": "https://open-publishing.org/journals/index.php/jutlp/article/download/810/769",
    "venue": "Journal of University Teaching and Learning Practice",
    "citation_count": 103,
    "fields_of_study": [
      "Generative grammar",
      "Scale (ratio)",
      "Artificial intelligence",
      "Computer science",
      "Geography"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585549"
  },
  {
    "source": "openalex",
    "source_id": "W4281877842",
    "title": "STUDYING HUMAN ROBOT INTERACTION AND ITS CHARACTERISTICS",
    "authors": [
      "Maged Farouk"
    ],
    "year": 2022,
    "abstract": "The process of human-robot interaction focuses on the analysis of different forms of communication between humans and the robots through the application of technologies like artificial intelligence and machine learning. However, there can be different challenges associated with the process like security risks and challenges related to mapping environment and manufacturing procedures. For analysis of the process of mitigation of the challenges, secondary qualitative data have been collected from different journals and websites. Theoretical analysis has been done for the collected data and the application of a cognitive modelling model has been done for this study. The main results include that application of a cognitive model can help in simulating the human problem-solving process and can help to improve the human cognition techniques.",
    "doi": "10.54489/ijcim.v2i1.73",
    "url": "https://openalex.org/W4281877842",
    "pdf_url": "https://journals.gaftim.com/index.php/ijcim/article/download/73/34",
    "venue": "International Journal of Computations Information and Manufacturing (IJCIM)",
    "citation_count": 109,
    "fields_of_study": [
      "Process (computing)",
      "Computer science",
      "Robot",
      "Human\u2013computer interaction",
      "Cognition"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585567"
  },
  {
    "source": "openalex",
    "source_id": "W4386486000",
    "title": "Examining the Impact of Artificial Intelligence and Internet of Things on Smart Tourism Destinations: A Comprehensive Study",
    "authors": [
      "Aliyah",
      "Chandra Lukita",
      "Greian April Pangilinan",
      "Mochamad Heru Riza Chakim",
      "Dimas Bagus Saputra"
    ],
    "year": 2023,
    "abstract": "This research focuses on the high urgency of utilizing Artificial Intelligence (AI) and the Internet of Things (IoT) to enhance Smart Tourism Destinations (STDs). The integration of AI and IoT technologies offers unprecedented opportunities to revolutionize various aspects of tourism, from personalized recommendations to real-time data collection. The research aims to provide a comprehensive analysis of the current state, challenges, and future direction of STDs in the context of AI and IoT integration. It explores various AI techniques and IoT-enabled data collection mechanisms that can enrich the traveler experience and improve destination management. However, challenges such as privacy and data security issues need to be addressed. The research also provides foresight into future technologies like Augmented Reality (AR) and Virtual Reality (VR) that can further enhance STDs. The ultimate goal is to contribute to the development of smarter, visitor-oriented tourism destinations. The research highlights the significance of AI in shaping STDs and emphasizes the importance of addressing ethical considerations, data quality, interpretability, and human-AI collaboration to ensure responsible and effective use of AI in the tourism industry.",
    "doi": "10.34306/att.v5i2sp.332",
    "url": "https://openalex.org/W4386486000",
    "pdf_url": "https://att.aptisi.or.id/index.php/att/article/download/332/220",
    "venue": "Aptisi Transactions On Technopreneurship (ATT)",
    "citation_count": 82,
    "fields_of_study": [
      "Tourism",
      "Futures studies",
      "Context (archaeology)",
      "Visitor pattern",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585579"
  },
  {
    "source": "openalex",
    "source_id": "W4280598345",
    "title": "Incorporating <scp>AI</scp> and learning analytics to build trustworthy peer assessment systems",
    "authors": [
      "Ali Darvishi",
      "Hassan Khosravi",
      "Shazia Sadiq",
      "Dragan Ga\u0161evi\u0107"
    ],
    "year": 2022,
    "abstract": "Abstract Peer assessment has been recognised as a sustainable and scalable assessment method that promotes higher\u2010order learning and provides students with fast and detailed feedback on their work. Despite these benefits, some common concerns and criticisms are associated with the use of peer assessments (eg, scarcity of high\u2010quality feedback from peer student\u2010assessors and lack of accuracy in assigning a grade to the assessee) that raise questions about their trustworthiness. Consequently, many instructors and educational institutions have been anxious about incorporating peer assessment into their teaching. This paper aims to contribute to the growing literature on how AI and learning analytics may be incorporated to address some of the common concerns associated with peer assessment systems, which in turn can increase their trustworthiness and adoption. In particular, we present and evaluate our AI\u2010assisted and analytical approaches that aim to (1) offer guidelines and assistance to student\u2010assessors during individual reviews to provide better feedback, (2) integrate probabilistic and text analysis inference models to improve the accuracy of the assigned grades, (3) develop feedback on reviews strategies that enable peer assessors to review the work of each other, and (4) employ a spot\u2010checking mechanism to assist instructors in optimally overseeing the peer assessment process. Practitioner notes What is already known about this topic Engaging students in peer assessment has been demonstrated to have various benefits. However, there are some common concerns associated with employing peer assessment that raise questions about their trustworthiness as an assessment item. What this paper adds Methods and processes on how AI and learning analytics may be incorporated to address some of the common concerns associated with peer assessment systems, which in turn, can increase their trustworthiness and adoption. Implications for practice Presentation of a systematic approach for development, deployment and evaluation of AI and analytics approaches in peer assessment systems.",
    "doi": "10.1111/bjet.13233",
    "url": "https://openalex.org/W4280598345",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/bjet.13233",
    "venue": "British Journal of Educational Technology",
    "citation_count": 86,
    "fields_of_study": [
      "Peer assessment",
      "Computer science",
      "Peer review",
      "Peer feedback",
      "Scarcity"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585595"
  },
  {
    "source": "openalex",
    "source_id": "W4288077582",
    "title": "The Metaverse as a virtual form of data-driven smart cities: the ethics of the hyper-connectivity, datafication, algorithmization, and platformization of urban society",
    "authors": [
      "Simon Elias Bibri",
      "Zaheer Allam"
    ],
    "year": 2022,
    "abstract": "Abstract Recent advances in computing and immersive technologies have provided Meta (formerly Facebook) with the opportunity to leapfrog or expedite its way of thinking and devising a global computing platform called the \u201cMetaverse\u201d. This hypothetical 3D network of virtual spaces is increasingly shaping alternatives to the imaginaries of data-driven smart cities, as it represents ways of living in virtually inhabitable cities. At the heart of the Metaverse is a computational understanding of human users\u2019 cognition, emotion, motivation, and behavior that reduces the experience of everyday life to logic and calculative rules and procedures. This implies that human users become more knowable and manageable and their behavior more predictable and controllable, thereby serving as passive data points feeding the AI and analytics system that they have no interchange with or influence on. This paper examines the forms, practices, and ethics of the Metaverse as a virtual form of data-driven smart cities, paying particular attention to: privacy, surveillance capitalism, dataveillance, geosurveillance, human health and wellness, and collective and cognitive echo-chambers. Achieving this aim will provide the answer to the main research question driving this study: What ethical implications will the Metaverse have on the experience of everyday life in post-pandemic urban society? In terms of methodology, this paper deploys a thorough review of the current status of the Metaverse, urban informatics, urban science, and data-driven smart cities literature, as well as trends, research, and developments. We argue that the Metaverse will do more harm than good to human users due to the massive misuse of the hyper-connectivity, datafication, algorithmization, and platformization underlying the associated global architecture of computer mediation. It follows that the Metaverse needs to be re-cast in ways that re-orientate in how users are conceived; recognize their human characteristics; and take into account the moral values and principles designed to realize the benefits of socially disruptive technologies while mitigating their pernicious effects. This paper contributes to the academic debates in the emerging field of data-driven smart urbanism by highlighting the ethical implications posed by the Metaverse as speculative fiction that illustrates the concerns raised by the pervasive and massive use of advanced technologies in data-driven smart cities. In doing so, it seeks to aid policy-makers in better understanding the pitfalls of the Metaverse and their repercussions upon the wellbeing of human users and the core values of urban society. It also stimulates prospective research and further critical perspectives on this timely topic.",
    "doi": "10.1007/s43762-022-00050-1",
    "url": "https://openalex.org/W4288077582",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s43762-022-00050-1.pdf",
    "venue": "Computational Urban Science",
    "citation_count": 134,
    "fields_of_study": [
      "Metaverse",
      "Computer science",
      "Sociology",
      "Data science",
      "Smart city"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585620"
  },
  {
    "source": "openalex",
    "source_id": "W4366989571",
    "title": "Algorithmic inclusion: Shaping the predictive algorithms of artificial intelligence in hiring",
    "authors": [
      "Elisabeth Kelan"
    ],
    "year": 2023,
    "abstract": "Abstract Despite frequent claims that increased use of artificial intelligence (AI) in hiring will reduce the human bias that has long plagued recruitment and selection, AI may equally replicate and amplify such bias and embed it in technology. This article explores exclusion and inclusion in AI\u2010supported hiring, focusing on three interrelated areas: data, design and decisions. It is suggested that in terms of data, organisational fit, categorisations and intersectionality require consideration in relation to exclusion. As various stakeholders collaborate to create AI, it is essential to explore which groups are dominant and how subjective assessments are encoded in technology. Although AI\u2010supported hiring should enhance recruitment decisions, evidence is lacking on how humans and machines interact in decision\u2010making, and how algorithms can be audited and regulated effectively for inclusion. This article recommends areas for interrogation through further research, and contributes to understanding how algorithmic inclusion can be achieved in AI\u2010supported hiring.",
    "doi": "10.1111/1748-8583.12511",
    "url": "https://openalex.org/W4366989571",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/1748-8583.12511",
    "venue": "Human Resource Management Journal",
    "citation_count": 66,
    "fields_of_study": [
      "Inclusion (mineral)",
      "Replicate",
      "Audit",
      "Computer science",
      "Selection (genetic algorithm)"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585653"
  },
  {
    "source": "openalex",
    "source_id": "W4367556998",
    "title": "ChatGPT in Dentistry: A Comprehensive Review",
    "authors": [
      "Hind M Alhaidry",
      "Bader Fatani",
      "Jenan O Alrayes",
      "Aljowhara M Almana",
      "Nawaf K Alfhaed"
    ],
    "year": 2023,
    "abstract": "Chat generative pre-trained transformer (ChatGPT) is an artificial intelligence chatbot that uses natural language processing that can respond to human input in a conversational manner. ChatGPT has numerous applications in the health care system including dentistry; it is used in diagnoses and for assessing disease risk and scheduling appointments. It also has a role in scientific research. In the dental field, it has provided many benefits such as detecting dental and maxillofacial abnormalities on panoramic radiographs and identifying different dental restorations. Therefore, it helps in decreasing the workload. But even with these benefits, one should take into consideration the risks and limitations of this chatbot. Few articles mentioned the use of ChatGPT in dentistry. This comprehensive review represents data collected from 66 relevant articles using PubMed and Google Scholar as databases. This review aims to discuss all relevant published articles on the use of ChatGPT in dentistry.",
    "doi": "10.7759/cureus.38317",
    "url": "https://openalex.org/W4367556998",
    "pdf_url": "https://assets.cureus.com/uploads/review_article/pdf/154683/20230531-32312-1iw73sz.pdf",
    "venue": "Cureus",
    "citation_count": 119,
    "fields_of_study": [
      "Medicine",
      "Workload",
      "Dentistry",
      "Documentation",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585667"
  },
  {
    "source": "openalex",
    "source_id": "W4224250711",
    "title": "Toward AI Governance: Identifying Best Practices and Potential Barriers and Outcomes",
    "authors": [
      "Emmanouil Papagiannidis",
      "Ida Merete Enholm",
      "Chirstian Dremel",
      "Patrick Mikalef",
      "John Krogstie"
    ],
    "year": 2022,
    "abstract": "Abstract In recent years artificial intelligence (AI) has been seen as a technology with tremendous potential for enabling companies to gain an operational and competitive advantage. However, despite the use of AI, businesses continue to face challenges and are unable to immediately realize performance gains. Furthermore, firms need to introduce robust AI systems and mitigate AI risks, which emphasizes the importance of creating suitable AI governance practices. This study, explores how AI governance is applied to promote the development of robust AI applications that do not introduce negative effects, based on a comparative case analysis of three firms in the energy sector. The study illustrates which practices are placed to produce knowledge that assists with decision making while at the same time overcoming barriers with recommended actions leading to desired outcomes. The study contributes by exploring the main dimensions relevant to AI\u2019s governance in organizations and by uncovering the practices that underpin them.",
    "doi": "10.1007/s10796-022-10251-y",
    "url": "https://openalex.org/W4224250711",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10796-022-10251-y.pdf",
    "venue": "Information Systems Frontiers",
    "citation_count": 111,
    "fields_of_study": [
      "Corporate governance",
      "Best practice",
      "Competitive advantage",
      "Knowledge management",
      "Face (sociological concept)"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585680"
  },
  {
    "source": "openalex",
    "source_id": "W4392106982",
    "title": "AI hype as a cyber security risk: the moral responsibility of implementing generative AI in business",
    "authors": [
      "Declan Humphreys",
      "Abigail Koay",
      "Dennis Desmond",
      "Erica Mealy"
    ],
    "year": 2024,
    "abstract": "Abstract This paper examines the ethical obligations companies have when implementing generative Artificial Intelligence (AI). We point to the potential cyber security risks companies are exposed to when rushing to adopt generative AI solutions or buying into \u201cAI hype\u201d. While the benefits of implementing generative AI solutions for business have been widely touted, the inherent risks associated have been less well publicised. There are growing concerns that the race to integrate generative AI is not being accompanied by adequate safety measures. The rush to buy into the hype of generative AI and not fall behind the competition is potentially exposing companies to broad and possibly catastrophic cyber-attacks or breaches. In this paper, we outline significant cyber security threats generative AI models pose, including potential \u2018backdoors\u2019 in AI models that could compromise user data or the risk of \u2018poisoned\u2019 AI models producing false results. In light of these the cyber security concerns, we discuss the moral obligations of implementing generative AI into business by considering the ethical principles of beneficence, non-maleficence, autonomy, justice, and explicability. We identify two examples of ethical concern, overreliance and over-trust in generative AI, both of which can negatively influence business decisions, leaving companies vulnerable to cyber security threats. This paper concludes by recommending a set of checklists for ethical implementation of generative AI in business environment to minimise cyber security risk based on the discussed moral responsibilities and ethical concern.",
    "doi": "10.1007/s43681-024-00443-4",
    "url": "https://openalex.org/W4392106982",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s43681-024-00443-4.pdf",
    "venue": "AI and Ethics",
    "citation_count": 71,
    "fields_of_study": [
      "Generative grammar",
      "Business",
      "Moral responsibility",
      "Engineering ethics",
      "Political science"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585693"
  },
  {
    "source": "openalex",
    "source_id": "W4383227059",
    "title": "The State of the Art in Deep Learning Applications, Challenges, and Future Prospects: A Comprehensive Review of Flood Forecasting and Management",
    "authors": [
      "Vijendra Kumar",
      "Hazi Mohammad Azamathulla",
      "Kul Vaibhav Sharma",
      "Darshan Mehta",
      "Kiran Tota\u2010Maharaj"
    ],
    "year": 2023,
    "abstract": "Floods are a devastating natural calamity that may seriously harm both infrastructure and people. Accurate flood forecasts and control are essential to lessen these effects and safeguard populations. By utilizing its capacity to handle massive amounts of data and provide accurate forecasts, deep learning has emerged as a potent tool for improving flood prediction and control. The current state of deep learning applications in flood forecasting and management is thoroughly reviewed in this work. The review discusses a variety of subjects, such as the data sources utilized, the deep learning models used, and the assessment measures adopted to judge their efficacy. It assesses current approaches critically and points out their advantages and disadvantages. The article also examines challenges with data accessibility, the interpretability of deep learning models, and ethical considerations in flood prediction. The report also describes potential directions for deep-learning research to enhance flood predictions and control. Incorporating uncertainty estimates into forecasts, integrating many data sources, developing hybrid models that mix deep learning with other methodologies, and enhancing the interpretability of deep learning models are a few of these. These research goals can help deep learning models become more precise and effective, which will result in better flood control plans and forecasts. Overall, this review is a useful resource for academics and professionals working on the topic of flood forecasting and management. By reviewing the current state of the art, emphasizing difficulties, and outlining potential areas for future study, it lays a solid basis. Communities may better prepare for and lessen the destructive effects of floods by implementing cutting-edge deep learning algorithms, thereby protecting people and infrastructure.",
    "doi": "10.3390/su151310543",
    "url": "https://openalex.org/W4383227059",
    "pdf_url": "https://www.mdpi.com/2071-1050/15/13/10543/pdf?version=1688475575",
    "venue": "Sustainability",
    "citation_count": 156,
    "fields_of_study": [
      "Interpretability",
      "Deep learning",
      "Flood myth",
      "Computer science",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585713"
  },
  {
    "source": "openalex",
    "source_id": "W3199921441",
    "title": "Ethics of artificial intelligence in global health: Explainability, algorithmic bias and trust",
    "authors": [
      "Angeliki Kerasidou"
    ],
    "year": 2021,
    "abstract": null,
    "doi": "10.1016/j.jobcr.2021.09.004",
    "url": "https://openalex.org/W3199921441",
    "pdf_url": "https://www.sciencedirect.com/science/article/pii/S2212426821000920",
    "venue": "Journal of Oral Biology and Craniofacial Research",
    "citation_count": 67,
    "fields_of_study": [
      "Context (archaeology)",
      "Health care",
      "Set (abstract data type)",
      "Medical diagnosis",
      "Economic Justice"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585734"
  },
  {
    "source": "openalex",
    "source_id": "W3014636188",
    "title": "Ensuring trustworthy use of artificial intelligence and big data analytics in health insurance",
    "authors": [
      "Calvin Wai-Loon Ho",
      "Joseph Ali",
      "Karel Caals"
    ],
    "year": 2020,
    "abstract": "Technological advances in big data (large amounts of highly varied data from many different sources that may be processed rapidly), data sciences and artificial intelligence can improve health-system functions and promote personalized care and public good. However, these technologies will not replace the fundamental components of the health system, such as ethical leadership and governance, or avoid the need for a robust ethical and regulatory environment. In this paper, we discuss what a robust ethical and regulatory environment might look like for big data analytics in health insurance, and describe examples of safeguards and participatory mechanisms that should be established. First, a clear and effective data governance framework is critical. Legal standards need to be enacted and insurers should be encouraged and given incentives to adopt a human-centred approach in the design and use of big data analytics and artificial intelligence. Second, a clear and accountable process is necessary to explain what information can be used and how it can be used. Third, people whose data may be used should be empowered through their active involvement in determining how their personal data may be managed and governed. Fourth, insurers and governance bodies, including regulators and policy-makers, need to work together to ensure that the big data analytics based on artificial intelligence that are developed are transparent and accurate. Unless an enabling ethical environment is in place, the use of such analytics will likely contribute to the proliferation of unconnected data systems, worsen existing inequalities, and erode trustworthiness and trust.",
    "doi": "10.2471/blt.19.234732",
    "url": "https://openalex.org/W3014636188",
    "pdf_url": "https://doi.org/10.2471/blt.19.234732",
    "venue": "Bulletin of the World Health Organization",
    "citation_count": 75,
    "fields_of_study": [
      "Big data",
      "Data governance",
      "Corporate governance",
      "Analytics",
      "Data science"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585738"
  },
  {
    "source": "openalex",
    "source_id": "W4389055737",
    "title": "Defining medical liability when artificial intelligence is applied on diagnostic algorithms: a systematic review",
    "authors": [
      "Clara Cestonaro",
      "Arianna Delicati",
      "Beatrice Marcante",
      "Luciana Caenazzo",
      "Pamela Tozzo"
    ],
    "year": 2023,
    "abstract": "Artificial intelligence (AI) in medicine is an increasingly studied and widespread phenomenon, applied in multiple clinical settings. Alongside its many potential advantages, such as easing clinicians\u2019 workload and improving diagnostic accuracy, the use of AI raises ethical and legal concerns, to which there is still no unanimous response. A systematic literature review on medical professional liability related to the use of AI-based diagnostic algorithms was conducted using the public electronic database PubMed selecting studies published from 2020 to 2023. The systematic review was performed according to 2020 PRISMA guidelines. The literature review highlights how the issue of liability in case of AI-related error and patient\u2019s damage has received growing attention in recent years. The application of AI and diagnostic algorithm moreover raises questions about the risks of using unrepresentative populations during the development and about the completeness of information given to the patient. Concerns about the impact on the fiduciary relationship between physician and patient and on the subject of empathy have also been raised. The use of AI in medical field and the application of diagnostic algorithms introduced a revolution in the doctor\u2013patient relationship resulting in multiple possible medico-legal consequences. The regulatory framework on medical liability when AI is applied is therefore inadequate and requires urgent intervention, as there is no single and specific regulation governing the liability of various parties involved in the AI supply chain, nor on end-users. Greater attention should be paid to inherent risk in AI and the consequent need for regulations regarding product safety as well as the maintenance of minimum safety standards through appropriate updates.",
    "doi": "10.3389/fmed.2023.1305756",
    "url": "https://openalex.org/W4389055737",
    "pdf_url": "https://www.frontiersin.org/articles/10.3389/fmed.2023.1305756/pdf?isPublishedV2=False",
    "venue": "Frontiers in Medicine",
    "citation_count": 118,
    "fields_of_study": [
      "Systematic review",
      "Liability",
      "Intervention (counseling)",
      "Risk analysis (engineering)",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585757"
  },
  {
    "source": "openalex",
    "source_id": "W4288855525",
    "title": "Future of Business Culture: An Artificial Intelligence\u2010Driven Digital Framework for Organization Decision\u2010Making Process",
    "authors": [
      "Navaneetha Krishnan Rajagopal",
      "Naila Iqbal Qureshi",
      "S. Durga",
      "Edwin Ramirez-As\u00eds",
      "Rosario Huerta-Soto",
      "Shashi Kant Gupta",
      "Sukheja Deepak"
    ],
    "year": 2022,
    "abstract": "Technological efforts are currently being used across a broad array of industries. Through the combination of consumer choice and matching principle, the goal of this paper is to investigate the prospective implications of artificial intelligence systems on businesses\u2019 outcomes. From an entrepreneurship standpoint, the research revealed that artificial intelligence systems can help with better decision\u2010making. What impact does the introduction of AI\u2010based decision\u2010making technologies have on organizational policymaking? The quirks of human and AI\u2010based policymaking are identified in this research based on five important contextual factors: precision of the choice search area, contribution to the innovation of the policymaking process and result, volume of the replacement collection, policymaking pace, and generalizability. We create a novel paradigm comparative analysis of conventional and automation judgment along these criteria, demonstrating how both judgment modalities can be used to improve organizational judgment efficiency. Furthermore, the research shows that, by involving internal stakeholders, they can manage the correlation among AI technologies and improve decision for businessmen. Furthermore, the research shows that customer preferences and industry norms can moderate the link between AI systems and superior entrepreneurial judgment. The goal of this work is to conduct a thorough literature analysis examining the confluence of AI and marketing philosophy, as well as construct a theoretical model that incorporates concerns based on established studies in the areas. This research shows that, in a setting with artificial intelligence systems, customer expectation, industry standards, and participative management, entrepreneurial strategic decisions are enhanced. This research provides entrepreneurs with technology means for enhancing decision\u2010making, illustrating the limitless possibilities given by AI systems. A conceptual approach is also formed, which discusses the four factors of profit maximization: relationship of AI tools and IT with corporate objectives; AI, organizational learning, and decision\u2010making methodology; and AI, service development, and value. This study proposes a way to exploit this innovative innovation without destroying society. We show real\u2010world examples of each of these frameworks, indicate circumstances in which they are likely to improve decision\u2010making performance in organizations, and provide actionable implications into their constraints. These observations have a wide variety of implications for establishing new management methods and practices from both academic and conceptual viewpoints.",
    "doi": "10.1155/2022/7796507",
    "url": "https://openalex.org/W4288855525",
    "pdf_url": "https://downloads.hindawi.com/journals/complexity/2022/7796507.pdf",
    "venue": "Complexity",
    "citation_count": 119,
    "fields_of_study": [
      "Process (computing)",
      "Computer science",
      "Process management",
      "Decision-making",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585778"
  },
  {
    "source": "openalex",
    "source_id": "W4362693892",
    "title": "A guide to formulating fairness in an optimization model",
    "authors": [
      "Violet Xinying Chen",
      "John Hooker"
    ],
    "year": 2023,
    "abstract": null,
    "doi": "10.1007/s10479-023-05264-y",
    "url": "https://openalex.org/W4362693892",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s10479-023-05264-y.pdf",
    "venue": "Annals of Operations Research",
    "citation_count": 86,
    "fields_of_study": [
      "Minimax",
      "Comparability",
      "Computer science",
      "Theory of computation",
      "Axiom"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585818"
  },
  {
    "source": "openalex",
    "source_id": "W3166568332",
    "title": "A roadmap for the Human Developmental Cell Atlas",
    "authors": [
      "Muzlifah Haniffa",
      "Deanne Taylor",
      "Sten Linnarsson",
      "Bruce J. Aronow",
      "Gary D. Bader",
      "Roger A. Barker",
      "Pablo G. C\u00e1mara",
      "J. Gray Camp",
      "Alain Ch\u00e9dotal",
      "Andrew J. Copp",
      "Heather Etchevers",
      "Paolo Giacobini",
      "Berthold G\u00f6ttgens",
      "Guoji Guo",
      "Ania Hupalowska",
      "Kylie R. James",
      "Emily Kirby",
      "Arnold R. Kriegstein",
      "Joakim Lundeberg",
      "John C. Marioni",
      "Kerstin B. Meyer",
      "Kathy K. Niakan",
      "Mats Nilsson",
      "Bayanne Olabi",
      "Dana Pe\u2019er",
      "Aviv Regev",
      "Jennifer Rood",
      "Orit Rozenblatt\u2013Rosen",
      "Rahul Satija",
      "Sarah A. Teichmann",
      "Barbara Treutlein",
      "Roser Vento\u2010Tormo",
      "Simone Webb",
      "Pascal Barbry",
      "Omer Ali Bayraktar",
      "Sam Behjati",
      "Andreas Bosio",
      "Bruno Canque",
      "Fr\u00e9d\u00e9ric Chalmel",
      "Yorick Gitton",
      "Deborah J. Henderson",
      "Anne J\u00f8rgensen",
      "Steven Lisgo",
      "Jinyue Liu",
      "Emma Lundberg",
      "Jean\u2010L\u00e9on Ma\u00eetre",
      "S\u00e9verine Mazaud\u2010Guittot",
      "Elizabeth Robertson",
      "Antoine D. Rolland",
      "Rapha\u00ebl Scharfmann",
      "Mich\u00e8le Souyri",
      "Erik Sundstr\u00f6m",
      "St\u00e9phane Zaffran",
      "Matthias Zilbauer",
      "Matthias Zilbauer"
    ],
    "year": 2021,
    "abstract": null,
    "doi": "10.1038/s41586-021-03620-1",
    "url": "https://openalex.org/W3166568332",
    "pdf_url": "https://www.nature.com/articles/s41586-021-03620-1.pdf",
    "venue": "Nature",
    "citation_count": 179,
    "fields_of_study": [
      "Atlas (anatomy)",
      "Human cell",
      "Human Protein Atlas",
      "Biology",
      "Organogenesis"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585832"
  },
  {
    "source": "openalex",
    "source_id": "W2907164391",
    "title": "Big data governance of personal health information and challenges to contextual integrity",
    "authors": [
      "Jenifer Sunrise Winter",
      "Elizabeth Davidson"
    ],
    "year": 2018,
    "abstract": "Pervasive digitization and aggregation of personal health information (PHI), along with artificial intelligence (AI) and other advanced analytical techniques, hold promise of improved health and healthcare services. These advances also pose significant data governance challenges for ensuring value for individual, organizational, and societal stakeholders as well as individual privacy and autonomy. Through a case study of a controversial public-private partnership between Royal Free Trust, a National Health Service hospital system in the United Kingdom, and Alphabet\u2019s AI venture DeepMind Health, we investigate how forms of data governance were adapted, as PHI data flowed into new use contexts, to address concerns of contextual integrity, which is violated when personal information collected in one use context moves to another use&#13;\\ncontext with different norms of appropriateness.",
    "doi": "10.1080/01972243.2018.1542648",
    "url": "https://openalex.org/W2907164391",
    "pdf_url": "https://scholarspace.manoa.hawaii.edu/bitstreams/c3e18526-7fbb-4437-b9d3-2952800c9bc5/download",
    "venue": "The Information Society",
    "citation_count": 121,
    "fields_of_study": [
      "Corporate governance",
      "Data governance",
      "Information governance",
      "Autonomy",
      "Context (archaeology)"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585834"
  },
  {
    "source": "openalex",
    "source_id": "W4388103298",
    "title": "Ethical implications of artificial intelligence in accounting: A framework for responsible ai adoption in multinational corporations in Jordan",
    "authors": [
      "Ahmad Y. A. Bani Ahmad"
    ],
    "year": 2023,
    "abstract": "The accelerated progress of Artificial Intelligence (AI) within the accounting field has resulted in a heightened use of this technology in international enterprises, therefore generating noteworthy ethical concerns. This research investigates the ethical implications that arise from the use of AI in accounting practices, focusing on international corporations operating in Jordan. The objective of this research is to provide a comprehensive framework for the ethical and responsible integration of AI within the accounting domain. The research used a survey methods approach while 379 respondents were selected using cluster and proportional sampling. The qualitative component of the research investigates the viewpoints and concerns of persons pertaining to the use of AI. The study results provide significant contributions to the development of a context-specific paradigm for AI ethics that prioritizes concepts such as transparency, fairness, and accountability. The findings of this study have substantial value for multinational corporations engaged in commercial operations in Jordan and similar regions. The results provide organizations with the necessary tools to proficiently address the ethical dilemmas that emerge as a result of using artificial intelligence in accounting procedures.",
    "doi": "10.5267/j.ijdns.2023.9.014",
    "url": "https://openalex.org/W4388103298",
    "pdf_url": "https://doi.org/10.5267/j.ijdns.2023.9.014",
    "venue": "International Journal of Data and Network Science",
    "citation_count": 67,
    "fields_of_study": [
      "Multinational corporation",
      "Accountability",
      "Viewpoints",
      "Accounting",
      "Transparency (behavior)"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585847"
  },
  {
    "source": "openalex",
    "source_id": "W4317952105",
    "title": "Seeing Like a Toolkit: How Toolkits Envision the Work of AI Ethics",
    "authors": [
      "Richmond Y. Wong",
      "Michael Madaio",
      "Nick Merrill"
    ],
    "year": 2023,
    "abstract": "Numerous toolkits have been developed to support ethical AI development. However, toolkits, like all tools, encode assumptions in their design about what work should be done and how. In this paper, we conduct a qualitative analysis of 27 AI ethics toolkits to critically examine how the work of ethics is imagined and how it is supported by these toolkits. Specifically, we examine the discourses toolkits rely on when talking about ethical issues, who they imagine should do the work of ethics, and how they envision the work practices involved in addressing ethics. Among the toolkits, we identify a mismatch between the imagined work of ethics and the support the toolkits provide for doing that work. In particular, we identify a lack of guidance around how to navigate labor, organizational, and institutional power dynamics as they relate to performing ethical work. We use these omissions to chart future work for researchers and designers of AI ethics toolkits.",
    "doi": "10.1145/3579621",
    "url": "https://openalex.org/W4317952105",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3579621",
    "venue": "Proceedings of the ACM on Human-Computer Interaction",
    "citation_count": 86,
    "fields_of_study": [
      "Work (physics)",
      "Engineering ethics",
      "Information ethics",
      "Sociology",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585862"
  },
  {
    "source": "openalex",
    "source_id": "W4312621205",
    "title": "Artificial Intelligence in Emergency Medicine: Viewpoint of Current Applications and Foreseeable Opportunities and Challenges",
    "authors": [
      "Gabrielle Chenais",
      "Emmanuel Lagarde",
      "C\u00e9dric Gil\u2010Jardine"
    ],
    "year": 2022,
    "abstract": "Emergency medicine and its services have reached a breaking point during the COVID-19 pandemic. This pandemic has highlighted the failures of a system that needs to be reconsidered, and novel approaches need to be considered. Artificial intelligence (AI) has matured to the point where it is poised to fundamentally transform health care, and applications within the emergency field are particularly promising. In this viewpoint, we first attempt to depict the landscape of AI-based applications currently in use in the daily emergency field. We review the existing AI systems; their algorithms; and their derivation, validation, and impact studies. We also propose future directions and perspectives. Second, we examine the ethics and risk specificities of the use of AI in the emergency field.",
    "doi": "10.2196/40031",
    "url": "https://openalex.org/W4312621205",
    "pdf_url": "https://www.jmir.org/2023/1/e40031/PDF",
    "venue": "Journal of Medical Internet Research",
    "citation_count": 101,
    "fields_of_study": [
      "Field (mathematics)",
      "Pandemic",
      "Applications of artificial intelligence",
      "Coronavirus disease 2019 (COVID-19)",
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585876"
  },
  {
    "source": "openalex",
    "source_id": "W2301623411",
    "title": "The STM Report: An overview of scientific and scholarly journal publishing",
    "authors": [
      "Mark Ware",
      "Michael Mabe"
    ],
    "year": 2015,
    "abstract": "Contents Executive summary \u25cf Scholarly communication \u25cf The research cycle \u25cf Types of scholarly communication \u25cf Changes in scholarly communication system \u25cf The journal \u25cf What is a journal? \u25cf The journals publishing cycle \u25cf Sales channels and models \u25cf Journal economics and market size \u25cf Journal and articles numbers and trends \u25cf Global trends in scientific output \u25cf Authors and readers \u25cf Publishers \u25cf Peer review. \u25cf Reading patterns \u25cf Disciplinary differences \u25cf Citations and the Impact Factor \u25cf Costs of journal publishing \u25cf Authors\u2019 behaviour, perceptions and attitudes \u25cf Publishing ethics \u25cf Copyright and licensing \u25cf Long term preservation \u25cf TRANSFER code \u25cf Researchers\u2019 access to journals \u25cf Open access \u25cf Drivers of open access \u25cf Open access business models \u25cf Types of open access journal \u25cf Delayed open access \u25cf Open access via self-archiving (\"Green\" OA) \u25cf Other open access variants \u25cf SCOAP3 \u25cf Open access to scholarly books \u25cf Public access \u25cf System-wide and economic perspectives \u25cf Other developments in open access \u25cf Transition and sustainability issues \u25cf Effect of self-archiving on journals. \u25cf Open access impacts on use \u25cf New developments in scholarly communication \u25cf \u201cScience 2.0\u201d or \"Open Science\" \u25cf FORCE11 and \u201cScience in Transition\u201d \u25cf Publishing platforms and APIs \u25cf Social media \u25cf Mobile access and apps \u25cf Research data \u25cf Semantic web and semantic enrichment \u25cf New article formats and features. \u25cf Text and data mining \u25cf Reproducibility \u25cf Big data & analytics \u25cf Identity and disambiguation \u25cf Research management and analytics \u25cf FundRef \u25cf Library publishing \u25cf Open Annotation \u25cf Learned societies \u25cf Author services and tools \u25cf Collaborative writing and sharing tools \u25cf Open notebook science \u25cf Conclusions \u25cf Information sources \u25cf Publisher organisations \u25cf Global statistics and trends \u25cf Open access \u25cf Publishing industry research and analysis \u25cf References 180pp",
    "doi": null,
    "url": "https://openalex.org/W2301623411",
    "pdf_url": "http://digitalcommons.unl.edu/scholcom/9",
    "venue": "Lincoln (University of Nebraska)",
    "citation_count": 405,
    "fields_of_study": [
      "Publishing",
      "Scientific publishing",
      "Library science",
      "Scholarly communication",
      "Political science"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585888"
  },
  {
    "source": "openalex",
    "source_id": "W4381250863",
    "title": "A Survey of Privacy Risks and Mitigation Strategies in the Artificial Intelligence Life Cycle",
    "authors": [
      "Sakib Shahriar",
      "Sonal Allana",
      "Seyed Mehdi Hazratifard",
      "Rozita Dara"
    ],
    "year": 2023,
    "abstract": "Over the decades, Artificial Intelligence (AI) and machine learning has become a transformative solution in many sectors, services, and technology platforms in a wide range of applications, such as in smart healthcare, financial, political, and surveillance systems. In such applications, a large amount of data is generated about diverse aspects of our life. Although utilizing AI in real-world applications provides numerous opportunities for societies and industries, it raises concerns regarding data privacy. Data used in an AI system are cleaned, integrated, and processed throughout the AI life cycle. Each of these stages can introduce unique threats to individual&#x2019;s privacy and have an impact on ethical processing and protection of data. In this paper, we examine privacy risks in different phases of the AI life cycle and review the existing privacy-enhancing solutions. We introduce four different categories of privacy risk, including (i) risk of identification, (ii) risk of making an inaccurate decision, (iii) risk of non-transparency in AI systems, and (iv) risk of non-compliance with privacy regulations and best practices. We then examined the potential privacy risks in each AI life cycle phase, evaluated concerns, and reviewed privacy-enhancing technologies, requirements, and process solutions to countermeasure these risks. We also reviewed some of the existing privacy protection policies and the need for compliance with available privacy regulations in AI-based systems. The main contribution of this survey is examining privacy challenges and solutions, including technology, process, and privacy legislation in the entire AI life cycle. In each phase of the AI life cycle, open challenges have been identified.",
    "doi": "10.1109/access.2023.3287195",
    "url": "https://openalex.org/W4381250863",
    "pdf_url": "https://ieeexplore.ieee.org/ielx7/6287639/10005208/10155147.pdf",
    "venue": "IEEE Access",
    "citation_count": 86,
    "fields_of_study": [
      "Information privacy",
      "Computer science",
      "Privacy by Design",
      "Transparency (behavior)",
      "Legislation"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585913"
  },
  {
    "source": "openalex",
    "source_id": "W4395676198",
    "title": "Artificial Intelligence and Healthcare: A Journey through History, Present Innovations, and Future Possibilities",
    "authors": [
      "Rahim Hirani",
      "Kaleb Noruzi",
      "Hassan Khuram",
      "Anum S. Hussaini",
      "Esewi Aifuwa",
      "Kencie Ely",
      "Joshua M. Lewis",
      "Ahmed E. Gabr",
      "Abbas Smiley",
      "Raj K. Tiwari",
      "Mill Etienne"
    ],
    "year": 2024,
    "abstract": "Artificial intelligence (AI) has emerged as a powerful tool in healthcare significantly impacting practices from diagnostics to treatment delivery and patient management. This article examines the progress of AI in healthcare, starting from the field\u2019s inception in the 1960s to present-day innovative applications in areas such as precision medicine, robotic surgery, and drug development. In addition, the impact of the COVID-19 pandemic on the acceleration of the use of AI in technologies such as telemedicine and chatbots to enhance accessibility and improve medical education is also explored. Looking forward, the paper speculates on the promising future of AI in healthcare while critically addressing the ethical and societal considerations that accompany the integration of AI technologies. Furthermore, the potential to mitigate health disparities and the ethical implications surrounding data usage and patient privacy are discussed, emphasizing the need for evolving guidelines to govern AI\u2019s application in healthcare.",
    "doi": "10.3390/life14050557",
    "url": "https://openalex.org/W4395676198",
    "pdf_url": "https://www.mdpi.com/2075-1729/14/5/557/pdf?version=1714114729",
    "venue": "Life",
    "citation_count": 134,
    "fields_of_study": [
      "Health care",
      "Telemedicine",
      "Pandemic",
      "Coronavirus disease 2019 (COVID-19)",
      "Applications of artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585933"
  },
  {
    "source": "openalex",
    "source_id": "W4388835050",
    "title": "Machine culture",
    "authors": [
      "Levin Brinkmann",
      "Fabian Baumann",
      "Jean\u2010Fran\u00e7ois Bonnefon",
      "Maxime Derex",
      "Thomas M\u00fcller",
      "Anne-Marie Nu\u00dfberger",
      "Agnieszka Czaplicka",
      "Alberto Acerbi",
      "Thomas L. Griffiths",
      "Joseph Henrich",
      "Joel Z. Leibo",
      "Richard McElreath",
      "Pierre-Yves Oudeyer",
      "Jonathan Stray",
      "Iyad Rahwan"
    ],
    "year": 2023,
    "abstract": null,
    "doi": "10.1038/s41562-023-01742-2",
    "url": "https://openalex.org/W4388835050",
    "pdf_url": "https://arxiv.org/pdf/2311.11388",
    "venue": "Nature Human Behaviour",
    "citation_count": 83,
    "fields_of_study": [
      "Cultural transmission in animals",
      "Computer science",
      "Variation (astronomy)",
      "Perspective (graphical)",
      "Selection (genetic algorithm)"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585949"
  },
  {
    "source": "openalex",
    "source_id": "W2889858158",
    "title": "Rapid developments in Artificial Intelligence: how might the New Zealand government respond?",
    "authors": [
      "Matthew Boyd",
      "Nick Wilson"
    ],
    "year": 2017,
    "abstract": "Advances in artificial intelligence (AI) have opened opportunities in a range of human endeavours (NSTC Committee on Technology, 2016). In response to the speed of these developments there has been a burst of analysis and dialogue in New Zealand. The New Zealand Institute of Directors commissioned a white paper (Chapman Tripp, 2016); the Ministry of Business, Innovation and Employment published Building a Digital Nation and the Strategic Science Investment Fund 2017\u201324 business plan (Ministry of Business, Innovation and Employment, 2017, 2016), and supports the new Artificial Intelligence Forum of New Zealand.",
    "doi": "10.26686/pq.v13i4.4619",
    "url": "https://openalex.org/W2889858158",
    "pdf_url": "https://ojs.victoria.ac.nz/pq/article/download/4619/4105",
    "venue": "Policy Quarterly",
    "citation_count": 75,
    "fields_of_study": [
      "Christian ministry",
      "White paper",
      "Government (linguistics)",
      "Management",
      "Political science"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585952"
  },
  {
    "source": "openalex",
    "source_id": "W2740983644",
    "title": "Gender as a Variable in Natural-Language Processing: Ethical Considerations",
    "authors": [
      "Brian Larson"
    ],
    "year": 2017,
    "abstract": "Researchers and practitioners in natural-language processing (NLP) and related fields should attend to ethical principles in study design, ascription of categories/variables to study participants, and reporting of findings or results. This paper discusses theoretical and ethical frameworks for using gender as a variable in NLP studies and proposes four guidelines for researchers and practitioners. The principles outlined here should guide practitioners, researchers, and peer reviewers, and they may be applicable to other social categories, such as race, applied to human beings connected to NLP research.",
    "doi": "10.18653/v1/w17-1601",
    "url": "https://openalex.org/W2740983644",
    "pdf_url": "https://www.aclweb.org/anthology/W17-1601.pdf",
    "venue": null,
    "citation_count": 108,
    "fields_of_study": [
      "Ascription",
      "Variable (mathematics)",
      "Race (biology)",
      "Computer science",
      "Natural (archaeology)"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585962"
  },
  {
    "source": "openalex",
    "source_id": "W4387886075",
    "title": "Exploring ChatGPT Capabilities and Limitations: A Survey",
    "authors": [
      "Anis Koub\u00e2a",
      "Wadii Boulila",
      "Lahouari Ghouti",
      "Ayyub Alzahem",
      "Shahid Latif"
    ],
    "year": 2023,
    "abstract": "ChatGPT, a groundbreaking natural language processing technology released a few months ago, has attracted significant attention due to its remarkable capabilities. This AI milestone has urged researchers, industry, decision-makers, and governments to examine this technology, including its implications, threats, and benefits. Despite the short period since its release, several researchers have examined ChatGPT from different perspectives. This paper presents a comprehensive review of ChatGPT, highlighting its technical novelties compared to previous models and analyzing existing research from various perspectives. We followed a rigorous methodology to conduct a critical review of existing research on ChatGPT and developed a taxonomy for the different areas of study. Additionally, we identify future challenges and research trends associated with ChatGPT. Our paper is the first critical review of ChatGPT literature, providing valuable insights for practitioners and policymakers. This paper is a reference for researchers seeking to advance research on ChatGPT, including its applications and development.",
    "doi": "10.1109/access.2023.3326474",
    "url": "https://openalex.org/W4387886075",
    "pdf_url": "https://ieeexplore.ieee.org/ielx7/6287639/6514899/10290719.pdf",
    "venue": "IEEE Access",
    "citation_count": 76,
    "fields_of_study": [
      "Computer science"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585972"
  },
  {
    "source": "openalex",
    "source_id": "W4395007039",
    "title": "Green and sustainable AI research: an integrated thematic and topic modeling analysis",
    "authors": [
      "Raghu Raman",
      "Debidutta Pattnaik",
      "Hiran H. Lathabai",
      "Chandan Kumar",
      "Kannan Govindan",
      "Prema Nedungadi"
    ],
    "year": 2024,
    "abstract": "Abstract This investigation delves into Green AI and Sustainable AI literature through a dual-analytical approach, combining thematic analysis with BERTopic modeling to reveal both broad thematic clusters and nuanced emerging topics. It identifies three major thematic clusters: (1) Responsible AI for Sustainable Development, focusing on integrating sustainability and ethics within AI technologies; (2) Advancements in Green AI for Energy Optimization, centering on energy efficiency; and (3) Big Data-Driven Computational Advances, emphasizing AI\u2019s influence on socio-economic and environmental aspects. Concurrently, BERTopic modeling uncovers five emerging topics: Ethical Eco-Intelligence, Sustainable Neural Computing, Ethical Healthcare Intelligence, AI Learning Quest, and Cognitive AI Innovation, indicating a trend toward embedding ethical and sustainability considerations into AI research. The study reveals novel intersections between Sustainable and Ethical AI and Green Computing, indicating significant research trends and identifying Ethical Healthcare Intelligence and AI Learning Quest as evolving areas within AI\u2019s socio-economic and societal impacts. The study advocates for a unified approach to innovation in AI, promoting environmental sustainability and ethical integrity to foster responsible AI development. This aligns with the Sustainable Development Goals, emphasizing the need for ecological balance, societal welfare, and responsible innovation. This refined focus underscores the critical need for integrating ethical and environmental considerations into the AI development lifecycle, offering insights for future research directions and policy interventions.",
    "doi": "10.1186/s40537-024-00920-x",
    "url": "https://openalex.org/W4395007039",
    "pdf_url": "https://journalofbigdata.springeropen.com/counter/pdf/10.1186/s40537-024-00920-x",
    "venue": "Journal Of Big Data",
    "citation_count": 85,
    "fields_of_study": [
      "Computer science",
      "Thematic map",
      "Computational Science and Engineering",
      "Data science",
      "Thematic analysis"
    ],
    "retrieved_at": "2026-02-02T16:58:14.585986"
  },
  {
    "source": "openalex",
    "source_id": "W4224241629",
    "title": "Dismantling AI capitalism: the commons as an alternative to the power concentration of Big Tech",
    "authors": [
      "Pieter Verdegem"
    ],
    "year": 2022,
    "abstract": null,
    "doi": "10.1007/s00146-022-01437-8",
    "url": "https://openalex.org/W4224241629",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s00146-022-01437-8.pdf",
    "venue": "AI & Society",
    "citation_count": 89,
    "fields_of_study": [
      "Capitalism",
      "Commons",
      "Performing arts",
      "Power (physics)",
      "Big data"
    ],
    "retrieved_at": "2026-02-02T16:58:14.586004"
  },
  {
    "source": "openalex",
    "source_id": "W4200290977",
    "title": "Cognitive computing based ethical principles for improving organisational reputation: A B2B digital marketing perspective",
    "authors": [
      "Rajat Kumar Behera",
      "Pradip Kumar Bala",
      "Nripendra P. Rana",
      "Hatice Kizgin"
    ],
    "year": 2021,
    "abstract": "Cognitive computing is ushering in the fourth industrial revolution through its promises of improved accuracy, scalability and personalisation. Therefore, business-to-business (B2B) organisations are wavering in the decision for adoption into their digital marketing initiatives. However, embracing moral rules and/or moral judgments in their digital marketing innovation can be challenging, since making mistakes could damage reputations. Therefore, this study applies the ethical principles of cognitive computing in B2B digital marketing business-centric ethical challenges. An integrated theoretical framework grounded on multidisciplinary studies is proposed. The primary data were collected from 300 respondents within B2B businesses. The results of this research led to the conclusion that good ethical practices are essential for the improvement of both organisational effectiveness and organisational reputation. Increased organisational reputation delivers a competitive edge in fast-growing marketplaces. B2B businesses need to look for proactive ways to achieve continuous improvement.",
    "doi": "10.1016/j.jbusres.2021.11.070",
    "url": "https://openalex.org/W4200290977",
    "pdf_url": "https://research.utwente.nl/en/publications/fcdde10b-d0c4-43b4-822e-98b4c8a21e56",
    "venue": "Journal of Business Research",
    "citation_count": 74,
    "fields_of_study": [
      "Reputation",
      "Multidisciplinary approach",
      "Personalization",
      "Perspective (graphical)",
      "Business"
    ],
    "retrieved_at": "2026-02-02T16:58:14.586007"
  },
  {
    "source": "openalex",
    "source_id": "W4282920034",
    "title": "Artificial Intelligence Decision-Making Transparency and Employees\u2019 Trust: The Parallel Multiple Mediating Effect of Effectiveness and Discomfort",
    "authors": [
      "Liangru Yu",
      "Yi Li"
    ],
    "year": 2022,
    "abstract": "The purpose of this paper is to investigate how Artificial Intelligence (AI) decision-making transparency affects humans\u2019 trust in AI. Previous studies have shown inconsistent conclusions about the relationship between AI transparency and humans\u2019 trust in AI (i.e., a positive correlation, non-correlation, or an inverted U-shaped relationship). Based on the stimulus-organism-response (SOR) model, algorithmic reductionism, and social identity theory, this paper explores the impact of AI decision-making transparency on humans\u2019 trust in AI from cognitive and emotional perspectives. A total of 235 participants with previous work experience were recruited online to complete the experimental vignette. The results showed that employees\u2019 perceived transparency, employees\u2019 perceived effectiveness of AI, and employees\u2019 discomfort with AI played mediating roles in the relationship between AI decision-making transparency and employees\u2019 trust in AI. Specifically, AI decision-making transparency (vs. non-transparency) led to higher perceived transparency, which in turn increased both effectiveness (which promoted trust) and discomfort (which inhibited trust). This parallel multiple mediating effect can partly explain the inconsistent findings in previous studies on the relationship between AI transparency and humans\u2019 trust in AI. This research has practical significance because it puts forward suggestions for enterprises to improve employees\u2019 trust in AI, so that employees can better collaborate with AI.",
    "doi": "10.3390/bs12050127",
    "url": "https://openalex.org/W4282920034",
    "pdf_url": "https://www.mdpi.com/2076-328X/12/5/127/pdf?version=1651056638",
    "venue": "Behavioral Sciences",
    "citation_count": 85,
    "fields_of_study": [
      "Transparency (behavior)",
      "Psychology",
      "Artificial intelligence",
      "Computer science",
      "Business"
    ],
    "retrieved_at": "2026-02-02T16:58:14.586024"
  },
  {
    "source": "openalex",
    "source_id": "W4382520149",
    "title": "The Impact of AI on Recruitment and Selection Processes: Analysing the role of AI in automating and enhancing recruitment and selection procedures",
    "authors": [
      "Saurabh Pratap Singh Rathore"
    ],
    "year": 2023,
    "abstract": "Human resource management is the process of identifying, recruiting, hiring, and training talented individuals, as well as providing them with career advancement possibilities and critical feedback on their performance. The purpose of this study was to investigate the function of AI in HRM practises using qualitative bibliometric analysis. Scopus, emerald, and the Jstore library are used as data sources. This analysis contains adjustments to data spanning 18 years. It also showed that there is a constant improvement and introduction of new technological conveniences. In accordance with the present market climate, which promotes and celebrates process management and people management practises targeted at making the organisation economically viable and different from the competition, this is a positive development. This work advances the theoretical understanding of AI's growth in the HR sector in light of this reality. Articles and proceedings examined in this research reveal that different authors and academic institutions provide different perspectives on the problem.",
    "doi": "10.55938/ijgasr.v2i2.50",
    "url": "https://openalex.org/W4382520149",
    "pdf_url": "https://journals.icapsr.com/index.php/ijgasr/article/download/50/115",
    "venue": "International Journal for Global Academic & Scientific Research",
    "citation_count": 85,
    "fields_of_study": [
      "Scopus",
      "Selection (genetic algorithm)",
      "Human resource management",
      "Competition (biology)",
      "Process (computing)"
    ],
    "retrieved_at": "2026-02-02T16:58:14.586045"
  },
  {
    "source": "openalex",
    "source_id": "W3127194607",
    "title": "The Threats of Artificial Intelligence Scale (TAI)",
    "authors": [
      "Kimon Kieslich",
      "Marco L\u00fcnich",
      "Frank Marcinkowski"
    ],
    "year": 2021,
    "abstract": "Abstract In recent years Artificial Intelligence (AI) has gained much popularity, with the scientific community as well as with the public. Often, AI is ascribed many positive impacts for different social domains such as medicine and the economy. On the other side, there is also growing concern about its precarious impact on society and individuals, respectively. Several opinion polls frequently query the public fear of autonomous robots and artificial intelligence, a phenomenon coming also into scholarly focus. As potential threat perceptions arguably vary with regard to the reach and consequences of AI functionalities and the domain of application, research still lacks necessary precision of a respective measurement that allows for wide-spread research applicability. We propose a fine-grained scale to measure threat perceptions of AI that accounts for four functional classes of AI systems and is applicable to various domains of AI applications. Using a standardized questionnaire in a survey study (N = 891), we evaluate the scale over three distinct AI domains (medical treatment, job recruitment, and loan origination). The data support the dimensional structure of the proposed Threats of AI (TAI) scale as well as the internal consistency and factoral validity of the indicators. Implications of the results and the empirical application of the scale are discussed in detail. Recommendations for further empirical use of the TAI scale are provided.",
    "doi": "10.1007/s12369-020-00734-w",
    "url": "https://openalex.org/W3127194607",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s12369-020-00734-w.pdf",
    "venue": "International Journal of Social Robotics",
    "citation_count": 91,
    "fields_of_study": [
      "Scale (ratio)",
      "Popularity",
      "Artificial intelligence",
      "Computer science",
      "Perception"
    ],
    "retrieved_at": "2026-02-02T16:58:14.586060"
  },
  {
    "source": "openalex",
    "source_id": "W4384824281",
    "title": "Responsible artificial intelligence in human resources management: a review of the empirical literature",
    "authors": [
      "Antoine Bujold",
      "Isabelle Roberge\u2010Maltais",
      "Xavier Parent\u2010Rocheleau",
      "Jared Boasen",
      "Sylvain S\u00e9n\u00e9cal",
      "Pierre\u2010Majorique L\u00e9ger"
    ],
    "year": 2023,
    "abstract": "Abstract As it is the case for many business processes and activities disciplines, artificial intelligence (AI) is increasingly integrated in human resources management (HRM). While AI has great potential to augment the HRM activities in organizations, automating the management of humans is not without risks and limitations. The identification of these risks is fundamental to promote responsible use of AI in HRM. We thus conducted a review of the empirical academic literature across disciplines on the affordances and responsible principles of AI in HRM. This is the first review of responsible AI in HRM that focuses solely on studies containing observations, measurements, and tests about this phenomenon. The multi-domain and multidisciplinary approach and empirical focus provides a better understanding of the reality of the development, study, and deployment of AI in HRM and sheds light on how these are conducted responsibly. We conclude with a call for research based on what we identified as the most needed and promising avenues.",
    "doi": "10.1007/s43681-023-00325-1",
    "url": "https://openalex.org/W4384824281",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s43681-023-00325-1.pdf",
    "venue": "AI and Ethics",
    "citation_count": 57,
    "fields_of_study": [
      "Knowledge management",
      "Empirical research",
      "Multidisciplinary approach",
      "Affordance",
      "Identification (biology)"
    ],
    "retrieved_at": "2026-02-02T16:58:14.586081"
  },
  {
    "source": "openalex",
    "source_id": "W4378901262",
    "title": "Artificial intelligence technology, public trust, and effective governance",
    "authors": [
      "Pedro Robles",
      "Daniel J. Mallinson"
    ],
    "year": 2023,
    "abstract": "Abstract Advancement in information technology continues to evolve especially in the field of artificial intelligence (AI). Research studies have been conducted to evaluate the perceptions of Americans on the development and utilization of AI technology and if it is appropriate to use AI in public administrative duties. The research revealed that society is fragmented regarding the acceptance of AI, and whether AI decisions could have long\u2010term effects on the labor industry, legal system, and national security. The 2018 AI Public Opinion Survey revealed significant concerns among the American public regarding AI, yet also a recognition of its promise. The goal of this article is to further develop a governance framework for AI that considers the importance of public trust in AI policy. First, it discusses the necessity of public trust for the effective governance of emergent technology. Then, it evaluates public opinion on AI technology that specifically pertains to governance. The article concludes with a discussion of why public trust is central to good AI governance.",
    "doi": "10.1111/ropr.12555",
    "url": "https://openalex.org/W4378901262",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/ropr.12555",
    "venue": "Review of Policy Research",
    "citation_count": 73,
    "fields_of_study": [
      "Corporate governance",
      "Public opinion",
      "Field (mathematics)",
      "Public trust",
      "Public relations"
    ],
    "retrieved_at": "2026-02-02T16:58:14.586096"
  },
  {
    "source": "openalex",
    "source_id": "W3045898680",
    "title": "Tackling COVID-19 through Responsible AI Innovation: Five Steps in the Right Direction",
    "authors": [
      "David Leslie"
    ],
    "year": 2020,
    "abstract": "Innovations in data science and artificial intelligence/machine learning (AI/ML) have a central role to play in supporting global efforts to combat COVID-19. The versatility of AI/ML technologies enables scientists and technologists to address an impressively broad range of biomedical, epidemiological, and socioeconomic challenges. This wide-reaching scientific capacity, however, also raises a diverse array of ethical challenges. The need for researchers to act quickly and globally in tackling SARS-CoV-2 demands unprecedented practices of open research and responsible data sharing at a time when innovation ecosystems are hobbled by proprietary protectionism, inequality, and a lack of public trust. Moreover, societally impactful interventions like digital contact tracing are raising fears of 'surveillance creep' and are challenging widely held commitments to privacy, autonomy, and civil liberties. Prepandemic concerns that data-driven innovations may function to reinforce entrenched dynamics of societal inequity have likewise intensified given the disparate impact of the virus on vulnerable social groups and the life-and-death consequences of biased and discriminatory public health outcomes. To address these concerns, I offer five steps that need to be taken to encourage responsible research and innovation. These provide a practice-based path to responsible AI/ML design and discovery centered on open, accountable, equitable, and democratically governed processes and products. When taken from the start, these steps will not only enhance the capacity of innovators to tackle COVID-19 responsibly, they will, more broadly, help to better equip the data science and AI/ML community to cope with future pandemics and to support a more humane, rational, and just society.",
    "doi": "10.1162/99608f92.4bb9d7a7",
    "url": "https://openalex.org/W3045898680",
    "pdf_url": "https://hdsr.mitpress.mit.edu/pub/as1p81um/download/pdf",
    "venue": "Harvard Data Science Review",
    "citation_count": 74,
    "fields_of_study": [
      "Public relations",
      "Data sharing",
      "Political science",
      "Autonomy",
      "Citizen science"
    ],
    "retrieved_at": "2026-02-02T16:58:14.586111"
  },
  {
    "source": "openalex",
    "source_id": "W4285819700",
    "title": "Artificial Intelligence Crime: An Overview of Malicious Use and Abuse of AI",
    "authors": [
      "Ta\u00eds Fernanda Blauth",
      "Oskar Josef Gstrein",
      "Andrej Zwitter"
    ],
    "year": 2022,
    "abstract": "The capabilities of Artificial Intelligence (AI) evolve rapidly and affect almost all sectors of society. AI has been increasingly integrated into criminal and harmful activities, expanding existing vulnerabilities, and introducing new threats. This article reviews the relevant literature, reports, and representative incidents which allows to construct a typology of the malicious use and abuse of systems with AI capabilities. The main objective is to clarify the types of activities and corresponding risks. Our starting point is to identify the vulnerabilities of AI models and outline how malicious actors can abuse them. Subsequently, we explore AI-enabled and AI-enhanced attacks. While we present a comprehensive overview, we do not aim for a conclusive and exhaustive classification. Rather, we provide an overview of the risks of enhanced AI application, that contributes to the growing body of knowledge on the issue. Specifically, we suggest four types of malicious abuse of AI (integrity attacks, unintended AI outcomes, algorithmic trading, membership inference attacks) and four types of malicious use of AI (social engineering, misinformation/fake news, hacking, autonomous weapon systems). Mapping these threats enables advanced reflection of governance strategies, policies, and activities that can be developed or improved to minimize risks and avoid harmful consequences. Enhanced collaboration among governments, industries, and civil society actors is vital to increase preparedness and resilience against malicious use and abuse of AI.",
    "doi": "10.1109/access.2022.3191790",
    "url": "https://openalex.org/W4285819700",
    "pdf_url": "https://ieeexplore.ieee.org/ielx7/6287639/6514899/09831441.pdf",
    "venue": "IEEE Access",
    "citation_count": 124,
    "fields_of_study": [
      "Computer security",
      "Computer science",
      "Resilience (materials science)",
      "Misinformation",
      "Hacker"
    ],
    "retrieved_at": "2026-02-02T16:58:14.586130"
  },
  {
    "source": "openalex",
    "source_id": "W4392894584",
    "title": "A critical review towards artificial general intelligence: Challenges, ethical considerations, and the path forward",
    "authors": [
      "Sedat Sonko",
      "Adebunmi Okechukwu Adewusi",
      "Ogugua Chimezie",
      "Shedrack Onwusinkwue",
      "Akoh Atadoga"
    ],
    "year": 2024,
    "abstract": "The pursuit of Artificial General Intelligence (AGI) has captivated researchers and industry leaders alike, promising a future where machines possess human-like cognitive abilities. However, this ambitious endeavor is fraught with multifaceted challenges and ethical dilemmas that necessitate careful examination. This critical review surveys the landscape of AGI research, identifying key hurdles and ethical considerations while outlining potential pathways forward. Firstly, technical challenges loom large on the path to AGI. These encompass fundamental problems such as developing robust learning algorithms capable of generalizing across diverse domains, as well as engineering systems that can exhibit adaptive and autonomous behavior akin to human intelligence. Additionally, ensuring the safety and reliability of AGI systems presents a formidable obstacle, with concerns ranging from algorithmic bias to the potential for catastrophic outcomes in unanticipated scenarios. Ethical considerations permeate every facet of AGI development and deployment. Questions of accountability, transparency, and control surface as central concerns, as the implications of relinquishing decision-making authority to autonomous systems raise profound ethical dilemmas. Moreover, the socio-economic ramifications of widespread AGI adoption, including job displacement and inequality, demand careful scrutiny and proactive mitigation strategies. Navigating these challenges requires a concerted effort from interdisciplinary stakeholders. Collaboration between computer scientists, ethicists, policymakers, and the public is essential to establish robust frameworks for the responsible development and deployment of AGI. Moreover, fostering an inclusive dialogue that prioritizes ethical principles and societal values is paramount in shaping a future where AGI augments human capabilities while safeguarding against potential risks. While the pursuit of AGI holds immense promise, its realization demands a holistic approach that addresses technical challenges alongside ethical considerations. By charting a path forward that prioritizes safety, transparency, and ethical governance, we can harness the transformative potential of AGI while ensuring its alignment with human values and interests.",
    "doi": "10.30574/wjarr.2024.21.3.0817",
    "url": "https://openalex.org/W4392894584",
    "pdf_url": "https://wjarr.com/sites/default/files/WJARR-2024-0817.pdf",
    "venue": "World Journal of Advanced Research and Reviews",
    "citation_count": 65,
    "fields_of_study": [
      "Transparency (behavior)",
      "Accountability",
      "Engineering ethics",
      "Computer science",
      "Scrutiny"
    ],
    "retrieved_at": "2026-02-02T16:58:14.586155"
  },
  {
    "source": "openalex",
    "source_id": "W4318566811",
    "title": "Is ChatGPT Leading Generative AI? What is Beyond Expectations?",
    "authors": [
      "\u00d6mer Ayd\u0131n",
      "Enis Karaarslan"
    ],
    "year": 2023,
    "abstract": null,
    "doi": "10.2139/ssrn.4341500",
    "url": "https://openalex.org/W4318566811",
    "pdf_url": "https://doi.org/10.2139/ssrn.4341500",
    "venue": "SSRN Electronic Journal",
    "citation_count": 124,
    "fields_of_study": [
      "Generative grammar",
      "Computer science",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:14.586183"
  },
  {
    "source": "openalex",
    "source_id": "W3215043243",
    "title": "Artificial intelligence in local governments: perceptions of city managers on prospects, constraints and choices",
    "authors": [
      "Tan Yi\u011fitcanlar",
      "Duzgun Agdas",
      "Kenan Degirmenci"
    ],
    "year": 2022,
    "abstract": "Abstract Highly sophisticated capabilities of artificial intelligence (AI) have skyrocketed its popularity across many industry sectors globally. The public sector is one of these. Many cities around the world are trying to position themselves as leaders of urban innovation through the development and deployment of AI systems. Likewise, increasing numbers of local government agencies are attempting to utilise AI technologies in their operations to deliver policy and generate efficiencies in highly uncertain and complex urban environments. While the popularity of AI is on the rise in urban policy circles, there is limited understanding and lack of empirical studies on the city manager perceptions concerning urban AI systems. Bridging this gap is the rationale of this study. The methodological approach adopted in this study is twofold. First, the study collects data through semi-structured interviews with city managers from Australia and the US. Then, the study analyses the data using the summative content analysis technique with two data analysis software. The analysis identifies the following themes and generates insights into local government services: AI adoption areas, cautionary areas, challenges, effects, impacts, knowledge basis, plans, preparedness, roadblocks, technologies, deployment timeframes, and usefulness. The study findings inform city managers in their efforts to deploy AI in their local government operations, and offer directions for prospective research.",
    "doi": "10.1007/s00146-022-01450-x",
    "url": "https://openalex.org/W3215043243",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s00146-022-01450-x.pdf",
    "venue": "AI & Society",
    "citation_count": 94,
    "fields_of_study": [
      "Software deployment",
      "Popularity",
      "Local government",
      "Preparedness",
      "Public sector"
    ],
    "retrieved_at": "2026-02-02T16:58:14.586186"
  },
  {
    "source": "openalex",
    "source_id": "W4392956046",
    "title": "Heterogeneity and predictors of the effects of AI assistance on radiologists",
    "authors": [
      "Feiyang Yu",
      "Alex Moehring",
      "Oishi Banerjee",
      "Tobias Salz",
      "Nikhil Agarwal",
      "Pranav Rajpurkar"
    ],
    "year": 2024,
    "abstract": null,
    "doi": "10.1038/s41591-024-02850-w",
    "url": "https://openalex.org/W4392956046",
    "pdf_url": "https://www.nature.com/articles/s41591-024-02850-w.pdf",
    "venue": "Nature Medicine",
    "citation_count": 125,
    "fields_of_study": [
      "Subspecialty",
      "Artificial intelligence",
      "Applications of artificial intelligence",
      "Medicine",
      "Machine learning"
    ],
    "retrieved_at": "2026-02-02T16:58:14.586210"
  },
  {
    "source": "openalex",
    "source_id": "W4362468036",
    "title": "Sustainability of the Metaverse: A Transition to Industry 5.0",
    "authors": [
      "Pietro De Giovanni"
    ],
    "year": 2023,
    "abstract": "This study analyzes the sustainability of the metaverse technology by adopting a responsible digitalization perspective to drive the transition to Industry 5.0. This is motivated by the current experiences of digital transformation paths, which appear careless regarding the side effects induced when adopting digital technologies\u2014for example, the energy consumption associated with blockchain, the jobs lost due to 3D printing, and the continuous payments required by artificial intelligence systems. While very few sustainable solutions are currently available to properly address these issues, similar effects might materialize when adopting metaverse technology. Therefore, this study provides tools to undertake a responsible digital transformation path through the metaverse to properly manage the transition to Industry 5.0. Specifically, it offers a set of frameworks to analyze the metaverse either from the perspective of the triple bottom line or by adopting an environmental, social, and governance (ESG) perspective and linking it to the most impacted business strategies or by connecting the technology to the sustainable development goals (SDGs). These tools enable readers to understand how society at large can responsibly implement, adopt, and manage a metaverse. By utilizing these frameworks, businesses can identify the most impacted strategies and take action to address any potential negative impacts.",
    "doi": "10.3390/su15076079",
    "url": "https://openalex.org/W4362468036",
    "pdf_url": "https://www.mdpi.com/2071-1050/15/7/6079/pdf?version=1680265695",
    "venue": "Sustainability",
    "citation_count": 208,
    "fields_of_study": [
      "Sustainability",
      "Metaverse",
      "Perspective (graphical)",
      "Computer science",
      "Business model"
    ],
    "retrieved_at": "2026-02-02T16:58:14.586213"
  },
  {
    "source": "openalex",
    "source_id": "W4385952733",
    "title": "Age-related bias and artificial intelligence: a scoping review",
    "authors": [
      "Charlene H. Chu",
      "Simon Donato\u2010Woodger",
      "Shehroz S. Khan",
      "Rune Nyrup",
      "Kathleen Leslie",
      "Alexandra Lyn",
      "Tianyu Shi",
      "Andria Bianchi",
      "Samira Abbasgholizadeh Rahimi",
      "Amanda Grenier"
    ],
    "year": 2023,
    "abstract": null,
    "doi": "10.1057/s41599-023-01999-y",
    "url": "https://openalex.org/W4385952733",
    "pdf_url": "https://www.nature.com/articles/s41599-023-01999-y.pdf",
    "venue": "Humanities and Social Sciences Communications",
    "citation_count": 70,
    "fields_of_study": [
      "Artificial intelligence",
      "Grey literature",
      "Gender bias",
      "Computer science",
      "Machine learning"
    ],
    "retrieved_at": "2026-02-02T16:58:14.586234"
  },
  {
    "source": "openalex",
    "source_id": "W2966881923",
    "title": "Bots at the Gate: A Human Rights Analysis of Automated Decision-Making in Canada\u2019s Immigration and Refugee System",
    "authors": [
      "Petra Molnar",
      "Lex Gill"
    ],
    "year": 2018,
    "abstract": "The report finds that use of automated decision-making technologies to augment or replace human judgment threatens to violate domestic and international human rights law, with alarming implications for the fundamental human rights of those subjected to these technologies.",
    "doi": null,
    "url": "https://openalex.org/W2966881923",
    "pdf_url": "http://hdl.handle.net/1807/94802",
    "venue": "Belarusian State Pedagogical University repository (Belarusian State Pedagogical University)",
    "citation_count": 81,
    "fields_of_study": [
      "Refugee",
      "Immigration",
      "Foundation (evidence)",
      "Human rights",
      "Political science"
    ],
    "retrieved_at": "2026-02-02T16:58:14.586237"
  },
  {
    "source": "openalex",
    "source_id": "W4390837884",
    "title": "The deep learning applications in IoT-based bio- and medical informatics: a systematic literature review",
    "authors": [
      "Zahra Mohtasham\u2010Amiri",
      "Arash Heidari",
      "Nima Jafari Navimipour",
      "Mansour Esmaeilpour",
      "Yalda Yazdani"
    ],
    "year": 2024,
    "abstract": "Abstract Nowadays, machine learning (ML) has attained a high level of achievement in many contexts. Considering the significance of ML in medical and bioinformatics owing to its accuracy, many investigators discussed multiple solutions for developing the function of medical and bioinformatics challenges using deep learning (DL) techniques. The importance of DL in Internet of Things (IoT)-based bio- and medical informatics lies in its ability to analyze and interpret large amounts of complex and diverse data in real time, providing insights that can improve healthcare outcomes and increase efficiency in the healthcare industry. Several applications of DL in IoT-based bio- and medical informatics include diagnosis, treatment recommendation, clinical decision support, image analysis, wearable monitoring, and drug discovery. The review aims to comprehensively evaluate and synthesize the existing body of the literature on applying deep learning in the intersection of the IoT with bio- and medical informatics. In this paper, we categorized the most cutting-edge DL solutions for medical and bioinformatics issues into five categories based on the DL technique utilized: convolutional neural network , recurrent neural network , generative adversarial network , multilayer perception , and hybrid methods. A systematic literature review was applied to study each one in terms of effective properties, like the main idea, benefits, drawbacks, methods, simulation environment, and datasets. After that, cutting-edge research on DL approaches and applications for bioinformatics concerns was emphasized. In addition, several challenges that contributed to DL implementation for medical and bioinformatics have been addressed, which are predicted to motivate more studies to develop medical and bioinformatics research progressively. According to the findings, most articles are evaluated using features like accuracy, sensitivity, specificity, F -score, latency, adaptability, and scalability.",
    "doi": "10.1007/s00521-023-09366-3",
    "url": "https://openalex.org/W4390837884",
    "pdf_url": "https://link.springer.com/content/pdf/10.1007/s00521-023-09366-3.pdf",
    "venue": "Neural Computing and Applications",
    "citation_count": 146,
    "fields_of_study": [
      "Computer science",
      "Artificial intelligence",
      "Health informatics",
      "Machine learning",
      "Deep learning"
    ],
    "retrieved_at": "2026-02-02T16:58:14.586243"
  },
  {
    "source": "openalex",
    "source_id": "W4386526807",
    "title": "Strategic Framework for Leveraging Artificial Intelligence in Future Marketing Decision-Making",
    "authors": [
      "Nouri Hicham",
      "Habbat Nassera",
      "Sabri Karim"
    ],
    "year": 2023,
    "abstract": "Disruptive technologies such as the big data analytics, blockchain, Internet of Things, and artificial intelligence have each impacted how businesses operate. The most recent example of disruptive technology is artificial intelligence (AI), which has the most potential to revolutionize marketing completely. Practitioners worldwide are searching for artificial intelligence (AI) solutions most suited for their marketing functions. Artificial intelligence can provide marketers with assistance in a variety of ways to boost client satisfaction. This article looks at the exciting new developments in artificial intelligence (AI) and marketing that have been occurring recently, it examines the latest developments in marketing using artificial intelligence (AI). These breakthroughs encompass predictive analytics for analyzing customer behaviour, integrating chatbots to enhance customer support, and implementing AI-driven content personalization tactics. This article also covers the horizons and problems of artificial intelligence and marketing, the precise applications of AI in a range of marketing segments, and their impact on marketing sectors. Additionally, this article examines the particular applications of AI in marketing.",
    "doi": "10.56578/jimd020304",
    "url": "https://openalex.org/W4386526807",
    "pdf_url": "https://library.acadlore.com/JIMD/2023/2/3/JIMD_02.03_04.pdf",
    "venue": "Journal of Intelligent Management Decision",
    "citation_count": 112,
    "fields_of_study": [
      "Marketing and artificial intelligence",
      "Personalization",
      "Analytics",
      "Big data",
      "Variety (cybernetics)"
    ],
    "retrieved_at": "2026-02-02T16:58:14.586265"
  },
  {
    "source": "openalex",
    "source_id": "W4288758404",
    "title": "In-Processing Modeling Techniques for Machine Learning Fairness: A Survey",
    "authors": [
      "Mingyang Wan",
      "Daochen Zha",
      "Ninghao Liu",
      "Na Zou"
    ],
    "year": 2022,
    "abstract": "Machine learning models are becoming pervasive in high-stakes applications. Despite their clear benefits in terms of performance, the models could show discrimination against minority groups and result in fairness issues in a decision-making process, leading to severe negative impacts on the individuals and the society. In recent years, various techniques have been developed to mitigate the unfairness for machine learning models. Among them, in-processing methods have drawn increasing attention from the community, where fairness is directly taken into consideration during model design to induce intrinsically fair models and fundamentally mitigate fairness issues in outputs and representations. In this survey, we review the current progress of in-processing fairness mitigation techniques. Based on where the fairness is achieved in the model, we categorize them into explicit and implicit methods, where the former directly incorporates fairness metrics in training objectives, and the latter focuses on refining latent representation learning. Finally, we conclude the survey with a discussion of the research challenges in this community to motivate future exploration.",
    "doi": "10.1145/3551390",
    "url": "https://openalex.org/W4288758404",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3551390",
    "venue": "ACM Transactions on Knowledge Discovery from Data",
    "citation_count": 84,
    "fields_of_study": [
      "Computer science",
      "Categorization",
      "Machine learning",
      "Process (computing)",
      "Representation (politics)"
    ],
    "retrieved_at": "2026-02-02T16:58:14.586280"
  },
  {
    "source": "openalex",
    "source_id": "W4362458937",
    "title": "A vision transformer for decoding surgeon activity from surgical videos",
    "authors": [
      "Dani Kiyasseh",
      "Runzhuo Ma",
      "Taseen F. Haque",
      "Brian J. Miles",
      "Christian von Wagner",
      "Daniel A. Donoho",
      "Animashree Anandkumar",
      "Andrew J. Hung"
    ],
    "year": 2023,
    "abstract": null,
    "doi": "10.1038/s41551-023-01010-8",
    "url": "https://openalex.org/W4362458937",
    "pdf_url": "https://www.nature.com/articles/s41551-023-01010-8.pdf",
    "venue": "Nature Biomedical Engineering",
    "citation_count": 114,
    "fields_of_study": [
      "Decoding methods",
      "Gesture",
      "Surgical procedures",
      "Medicine",
      "Identification (biology)"
    ],
    "retrieved_at": "2026-02-02T16:58:14.586295"
  },
  {
    "source": "openalex",
    "source_id": "W4398177139",
    "title": "Exploring the Role of Artificial Intelligence in Mental Healthcare: Current Trends and Future Directions \u2013 A Narrative Review for a Comprehensive Insight",
    "authors": [
      "Ahmed M. Alhuwaydi"
    ],
    "year": 2024,
    "abstract": "Mental health is an essential component of the health and well-being of a person and community, and it is critical for the individual, society, and socio-economic development of any country. Mental healthcare is currently in the health sector transformation era, with emerging technologies such as artificial intelligence (AI) reshaping the screening, diagnosis, and treatment modalities of psychiatric illnesses. The present narrative review is aimed at discussing the current landscape and the role of AI in mental healthcare, including screening, diagnosis, and treatment. Furthermore, this review attempted to highlight the key challenges, limitations, and prospects of AI in providing mental healthcare based on existing works of literature. The literature search for this narrative review was obtained from PubMed, Saudi Digital Library (SDL), Google Scholar, Web of Science, and IEEE Xplore, and we included only English-language articles published in the last five years. Keywords used in combination with Boolean operators (\"AND\" and \"OR\") were the following: \"Artificial intelligence\", \"Machine learning\", Deep learning\", \"Early diagnosis\", \"Treatment\", \"interventions\", \"ethical consideration\", and \"mental Healthcare\". Our literature review revealed that, equipped with predictive analytics capabilities, AI can improve treatment planning by predicting an individual's response to various interventions. Predictive analytics, which uses historical data to formulate preventative interventions, aligns with the move toward individualized and preventive mental healthcare. In the screening and diagnostic domains, a subset of AI, such as machine learning and deep learning, has been proven to analyze various mental health data sets and predict the patterns associated with various mental health problems. However, limited studies have evaluated the collaboration between healthcare professionals and AI in delivering mental healthcare, as these sensitive problems require empathy, human connections, and holistic, personalized, and multidisciplinary approaches. Ethical issues, cybersecurity, a lack of data analytics diversity, cultural sensitivity, and language barriers remain concerns for implementing this futuristic approach in mental healthcare. Considering these sensitive problems require empathy, human connections, and holistic, personalized, and multidisciplinary approaches, it is imperative to explore these aspects. Therefore, future comparative trials with larger sample sizes and data sets are warranted to evaluate different AI models used in mental healthcare across regions to fill the existing knowledge gaps.",
    "doi": "10.2147/rmhp.s461562",
    "url": "https://openalex.org/W4398177139",
    "pdf_url": "https://www.dovepress.com/getfile.php?fileID=99286",
    "venue": "Risk Management and Healthcare Policy",
    "citation_count": 82,
    "fields_of_study": [
      "Narrative",
      "Narrative review",
      "Mental health",
      "Mental healthcare",
      "Health care"
    ],
    "retrieved_at": "2026-02-02T16:58:14.586297"
  },
  {
    "source": "openalex",
    "source_id": "W4283157638",
    "title": "It\u2019s Just Not That Simple: An Empirical Study of the Accuracy-Explainability Trade-off in Machine Learning for Public Policy",
    "authors": [
      "Andrew Bell",
      "Ian Ren\u00e9 Solano-Kamaiko",
      "Oded Nov",
      "Julia Stoyanovich"
    ],
    "year": 2022,
    "abstract": "To achieve high accuracy in machine learning (ML) systems, practitioners often use complex \"black-box\" models that are not easily understood by humans. The opacity of such models has resulted in public concerns about their use in high-stakes contexts and given rise to two conflicting arguments about the nature \u2014 and even the existence \u2014 of the accuracy-explainability trade-off. One side postulates that model accuracy and explainability are inversely related, leading practitioners to use black-box models when high accuracy is important. The other side of this argument holds that the accuracy-explainability trade-off is rarely observed in practice and consequently, that simpler interpretable models should always be preferred. Both sides of the argument operate under the assumption that some types of models, such as low-depth decision trees and linear regression are more explainable, while others such as neural networks and random forests, are inherently opaque.",
    "doi": "10.1145/3531146.3533090",
    "url": "https://openalex.org/W4283157638",
    "pdf_url": "https://dl.acm.org/doi/pdf/10.1145/3531146.3533090",
    "venue": "2022 ACM Conference on Fairness, Accountability, and Transparency",
    "citation_count": 74,
    "fields_of_study": [
      "Simple (philosophy)",
      "Computer science",
      "Empirical research",
      "Machine learning",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:14.586327"
  },
  {
    "source": "openalex",
    "source_id": "W4327993492",
    "title": "Data-centric Artificial Intelligence: A Survey",
    "authors": [
      "Daochen Zha",
      "Zaid Pervaiz Bhat",
      "Kwei-Herng Lai",
      "Fan Yang",
      "Zhimeng Jiang",
      "Shaochen Zhong",
      "Xia Hu"
    ],
    "year": 2023,
    "abstract": "Artificial Intelligence (AI) is making a profound impact in almost every domain. A vital enabler of its great success is the availability of abundant and high-quality data for building machine learning models. Recently, the role of data in AI has been significantly magnified, giving rise to the emerging concept of data-centric AI. The attention of researchers and practitioners has gradually shifted from advancing model design to enhancing the quality and quantity of the data. In this survey, we discuss the necessity of data-centric AI, followed by a holistic view of three general data-centric goals (training data development, inference data development, and data maintenance) and the representative methods. We also organize the existing literature from automation and collaboration perspectives, discuss the challenges, and tabulate the benchmarks for various tasks. We believe this is the first comprehensive survey that provides a global view of a spectrum of tasks across various stages of the data lifecycle. We hope it can help the readers efficiently grasp a broad picture of this field, and equip them with the techniques and further research ideas to systematically engineer data for building AI systems. A companion list of data-centric AI resources will be regularly updated on https://github.com/daochenzha/data-centric-AI",
    "doi": "10.48550/arxiv.2303.10158",
    "url": "https://openalex.org/W4327993492",
    "pdf_url": "https://arxiv.org/pdf/2303.10158",
    "venue": "arXiv (Cornell University)",
    "citation_count": 97,
    "fields_of_study": [
      "Computer science",
      "Data science",
      "Enabling",
      "Data quality",
      "Field (mathematics)"
    ],
    "retrieved_at": "2026-02-02T16:58:14.586341"
  },
  {
    "source": "openalex",
    "source_id": "W4225105833",
    "title": "Environment of Peace: Security in a New Era of Risk",
    "authors": [
      "Richard Black",
      "Joshua W. Busby",
      "Geoffrey D. Dabelko",
      "Cedric de Coning",
      "Hafsa Maalim",
      "Claire McAllister",
      "Melvis Ndiloseh",
      "D. J. B. Smith",
      "Jos\u00e9 Francisco Alvarado C\u00f3bar",
      "Anniek Barnhoorn",
      "Noah Bell",
      "Daniel Bell-Moran",
      "Emilie Broek",
      "Alexis Eberlein",
      "Karolina Ekl\u00f6w",
      "Jakob Faller",
      "Andrea Gadnert",
      "Farah Hegazi",
      "Kyungmee Kim",
      "Florian Krampe",
      "David Michel",
      "Corey Pattison",
      "Caleb Ray",
      "Elise Remling",
      "Evelyn Salas Alfaro",
      "Elizabeth Smith",
      "J\u00fcrg Staudenmann"
    ],
    "year": 2022,
    "abstract": "The environmental crisis is increasing risks to security and peace worldwide, notably in countries that are already fragile. Indicators of insecurity such as the number of conflicts, the number of hungry people and military expenditure are rising; so are indicators of environmental decline, in climate change, biodiversity, pollution and other areas. In combination, the security and environmental crises are creating compound, cascading, emergent, systemic and existential risks. Without profound changes of approach by institutions of authority, risks will inevitably proliferate quickly. Environment of Peace surveys the evolving risk landscape and documents a number of developments that indicate a pathway to solutions\u2013\u2013in international law and policy, in peacekeeping operations and among non-governmental organizations. It finds that two principal avenues need to be developed: (a) combining peace-building and environmental restoration, and (b) effectively addressing the underlying environmental issues. It also analyses the potential of existing and emerging pro-environment measures for exacerbating risks to peace and security. The findings demonstrate that only just and peaceful transitions to more sustainable practices can be effective\u2013\u2013and show that these transitions also need to be rapid.",
    "doi": "10.55163/lcls7037",
    "url": "https://openalex.org/W4225105833",
    "pdf_url": "https://www.sipri.org/sites/default/files/2022-05/environment_of_peace_security_in_a_new_era_of_risk_0.pdf",
    "venue": null,
    "citation_count": 207,
    "fields_of_study": [
      "Peacekeeping",
      "Environmental security",
      "Principal (computer security)",
      "Political science",
      "Human security"
    ],
    "retrieved_at": "2026-02-02T16:58:14.586359"
  },
  {
    "source": "openalex",
    "source_id": "W4384464462",
    "title": "Creation of the algorithmic management questionnaire: A six\u2010phase scale development process",
    "authors": [
      "Xavier Parent\u2010Rocheleau",
      "Sharon K. Parker",
      "Antoine Bujold",
      "Marie\u2010Claude Gaudet"
    ],
    "year": 2023,
    "abstract": "Abstract There is an increasing body of research on algorithmic management (AM), but the field lacks measurement tools to capture workers' experiences of this phenomenon. Based on existing literature, we developed and validated the algorithmic management questionnaire (AMQ) to measure the perceptions of workers regarding their level of exposure to AM. Across three samples (overall n = 1332 gig workers), we show the content, factorial, discriminant, convergent, and predictive validity of the scale. The final 20\u2010item scale assesses workers' perceived level of exposure to algorithmic: monitoring, goal setting, scheduling, performance rating, and compensation. These dimensions formed a higher order construct assessing overall exposure to algorithmic management, which was found to be, as expected, negatively related to the work characteristics of job autonomy and job complexity and, indirectly, to work engagement. Supplementary analyses revealed that perceptions of exposure to AM reflect the objective presence of AM dimensions beyond individual variations in exposure. Overall, the results suggest the suitability of the AMQ to assess workers' perceived exposure to algorithmic management, which paves the way for further research on the impacts of these rapidly accelerating systems.",
    "doi": "10.1002/hrm.22185",
    "url": "https://openalex.org/W4384464462",
    "pdf_url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/hrm.22185",
    "venue": "Human Resource Management",
    "citation_count": 71,
    "fields_of_study": [
      "Scale (ratio)",
      "Discriminant validity",
      "Autonomy",
      "Applied psychology",
      "Psychology"
    ],
    "retrieved_at": "2026-02-02T16:58:14.586379"
  },
  {
    "source": "openalex",
    "source_id": "W4285155368",
    "title": "Challenges and Strategies in Cross-Cultural NLP",
    "authors": [
      "Daniel Hershcovich",
      "Stella Frank",
      "Heather Lent",
      "Miryam de Lhoneux",
      "Mostafa Abdou",
      "Stephanie Brandl",
      "Emanuele Bugliarello",
      "Laura Cabello Piqueras",
      "Ilias Chalkidis",
      "Ruixiang Cui",
      "Constanza Fierro",
      "Katerina Margatina",
      "Phillip Rust",
      "Anders S\u00f8gaard"
    ],
    "year": 2022,
    "abstract": "Various efforts in the Natural Language Processing (NLP) community have been made to accommodate linguistic diversity and serve speakers of many different languages. However, it is important to acknowledge that speakers and the content they produce and require, vary not just by language, but also by culture. Although language and culture are tightly linked, there are important differences. Analogous to cross-lingual and multilingual NLP, cross-cultural and multicultural NLP considers these differences in order to better serve users of NLP systems. We propose a principled framework to frame these efforts, and survey existing and potential strategies.",
    "doi": "10.18653/v1/2022.acl-long.482",
    "url": "https://openalex.org/W4285155368",
    "pdf_url": "https://aclanthology.org/2022.acl-long.482.pdf",
    "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    "citation_count": 74,
    "fields_of_study": [
      "Computer science",
      "Natural language processing",
      "Artificial intelligence"
    ],
    "retrieved_at": "2026-02-02T16:58:14.586396"
  }
]