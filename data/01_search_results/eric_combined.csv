ERIC_ID,Title,Authors,Year,Abstract,Journal,Source,DOI,URL,Keywords,Language,Publication_Type
EJ1484420,Utilizing Artificial Intelligence for Assessment in Higher Education,Daniel Lupiya Mpolomoka,0243,"Overview: This systematic review explores the utilization of artificial intelligence (AI) for assessment, grading, and feedback in higher education. The review aims to establish how AI technologies enhance efficiency, scalability, and personalized learning experiences in educational settings, while addressing associated challenges that arise due to AI use. Methods: In this article, a comprehensive search of 6 different academic databases including PubMed, Google Scholar, IEEE Xplore, ERIC, and Scopus were conducted. The focus was on the published studies ranging between 2010 and 2023. Also, inclusion criteria required studies to be peer-reviewed, centered on AI applications in higher education. Studies were to provide empirical evidence or theoretical discussions relevant to assessment processes. Thus, twenty studies meeting these criteria were selected, scrutinized and analyzed. Results: Pertaining to the findings, they indicate that AI-driven systems significantly streamline grading processes, reduce turnaround times, and provide timely, personalized feedback. These systems also offer data-driven insights that inform instructional practices. However, challenges such as algorithmic bias, validity concerns in subjective assessments, and ethical issues related to data privacy persist. Effective AI integration necessitates alignment with pedagogical goals, ongoing professional development for educators, and transparent policies to ensure fairness and equity. Conclusion: AI technologies hold transformative potential for enhancing assessment practices in higher education. Therefore, addressing technical, ethical, and pedagogical challenges through interdisciplinary collaboration and evidence-based approaches is essential to fully realizing AI's benefits. Future research should focus on validating AI-driven assessment methods and exploring their long-term impact on educational outcomes.",Pedagogical Research,v10 n3 Article em0243 2025,,http://eric.ed.gov/?id=EJ1484420,Artificial Intelligence; Higher Education; Evaluation Methods; Literature Reviews; Grading; Feedback (Response); Computer Assisted Testing; Educational Technology; Technology Integration; Automation; Ethics; Individualized Instruction,English,Journal Articles; Information Analyses
EJ1486132,The Impact of Artificial Intelligence on Strategic Decision-Making in Business Administration: An Analytical Study Including Educational and Business Environments,Yousef Al Abdallat,2025,"Background/purpose: The study examined the impact of artificial intelligence on strategic decision-making in business management, focusing on Educational and Business Environments, with a particular emphasis on internal capabilities, organizational readiness, ethical considerations, and regional contextual factors that affect AI integration. Materials/methods: A mixed-methods approach that combines quantitative and qualitative approaches. Purposive sampling of businesses from different industries and geographical areas that employ AI in strategic decision-making. Data were collected through semi-structured interviews with professionals from nine diverse work environments, including Jordan, Germany, Saudi Arabia, and the United States. Results: The findings reveal that most businesses are still in the planning phase of AI adoption, with limited strategic implementation and reliance on machine learning and predictive analytics in operational tasks. The majority of businesses are still in the planning phase of AI adoption, with limited strategic use and reliance on predictive analytics and machine learning in day-to-day operations. Organizations often lack the necessary frameworks, technical expertise, and strategic alignment to fully leverage AI technologies, despite growing awareness. Despite the widespread use of AI in educational institutions, many lack infrastructure for staff training. Conclusion: Lack of ethical frameworks, low employee AI literacy, and difficulty tailoring AI tools to specific industries are among the main obstacles. To facilitate successful AI integration, the study recommends enhancing employee training, establishing moral guidelines, and coordinating internal and external resources.",Educational Process: International Journal,v18 Article e2025509 2025,,http://eric.ed.gov/?id=EJ1486132,Artificial Intelligence; Strategic Planning; Decision Making; Business Administration; Ethics; Business; Technology Integration; Prediction; Data Analysis; Digital Literacy; Knowledge Level; Training; Automation; Educational Finance; Money Management; Financial Services; Governance,English,Journal Articles; Reports - Research; Tests/Questionnaires
EJ1493785,"Artificial Intelligence-Supported Workplace Education: A Systematic Review of Learning Outcomes, Opportunities, and Challenges",Ecehan Kazanci Yabanova,2025,"Background/purpose: In the digital age, education is no longer considered an activity carried out during a specific period of life, but rather a lifelong concept. The skills acquired through formal education processes can become obsolete within a few years due to the rapid pace of the era. It is precisely at this point that corporate structures are under more pressure than ever to keep their employees' skills up to date. These training programmes are conducted with intensive use of educational technologies in order to prevent workforce loss and provide training at an appropriate cost. In the field of corporate learning and development, the impact of artificial intelligence technologies on employee training is also increasing. Materials/methods: This article systematically examines the effects, opportunities, and challenges of AI applications in employee training. The field of artificial intelligence applications in education has been evaluated within a theoretical framework, and articles published between 2020 and 2025 have been analysed using a systematic review and a thematic content analysis, focusing on impacts, opportunities, and challenges. Results: The analysis revealed that artificial intelligence affects cognitive, affective, behavioural, and technical-organisational dimensions of employee training. Opportunities were reported in learning quality, cognitive development, affective and social aspects, performance and efficiency, and organisational aspects, while challenges were reported in technical, infrastructure, ethics and law, organisational, and pedagogical dimensions. Conclusion: Artificial intelligence is expected to make significant contributions to employee training. However, many areas identified as challenges need to be addressed in order to maximise the benefits of these technologies.",Educational Process: International Journal,v19 Article e2025602 2025,,http://eric.ed.gov/?id=EJ1493785,Workplace Learning; Artificial Intelligence; Technology Uses in Education; Educational Opportunities; Barriers; Educational Research; Outcomes of Education,English,Journal Articles; Information Analyses
EJ1481478,Navigating the Challenges and Opportunities of Artificial Intelligence in Educational Leadership: A Scoping Review,Ana-Inés Renta-Davids; Marta Camarero-Figuerola; Mar Camacho,7010,"The increasing integration of Artificial Intelligence (AI) in educational settings is transforming the role of school leaders, reshaping how decisions are made, and introducing both opportunities and challenges. This paper presents the findings of a scoping review that synthesises the current literature on AI's impact on educational leadership. The review highlights that while AI has the potential to enhance decision-making through data-driven insights and automation of administrative tasks, its implementation requires careful consideration of ethical, equity, and human-centred concerns. Key findings suggest that educational leaders must develop digital literacy and AI competence to critically assess AI outputs and mitigate risks, particularly related to algorithmic bias and data privacy. The review also emphasises the necessity of continuous professional development for leaders and staff to ensure effective and ethical AI integration. In light of these findings, this paper advocates for a balanced approach where AI is used to augment, rather than replace, the human elements of leadership, and calls for future empirical research to further investigate the long-term implications of AI in diverse educational contexts.",Review of Education,v13 n2 e70101 2025,10.1002/rev3.70101,http://eric.ed.gov/?id=EJ1481478,Artificial Intelligence; Instructional Leadership; Technology Integration; Decision Making; Automation; School Administration; Digital Literacy; Risk Management; Algorithms; Bias; Privacy; Information Security,English,Journal Articles; Information Analyses
EJ1485189,The Role of Artificial Intelligence in Shaping Assessment Practices in Higher Education,Ilhama Mammadova; Fatime Ismayilli; Elnaz Aliyeva; Narmin Mammadova,2025,"Background/purpose: Artificial Intelligence (AI) is increasingly shaping assessment practices in higher education, promising faster feedback and reduced instructor workload while also raising concerns about fairness and transparency. This study examines how AI technologies are transforming assessment processes and the experiences of stakeholders. Materials/methods: We conducted a mixed-methods study across five universities. A total of 300 undergraduate students and 100 instructors completed parallel surveys (totaling 30 items each) about their use of and perceptions toward AI tools. We also interviewed 15 faculty and conducted four student focus groups to explore experiences with AI-based assessment. Quantitative data were analyzed using descriptive statistics and independent t-tests, while interview transcripts were analyzed thematically. Results: The majority of participants reported efficiency gains from AI. For example, 73% of students received faster feedback when AI was used, and instructors reported an average 40% reduction in grading time. However, 52% of students did not fully understand how AI-derived scores were calculated. Qualitative themes included improved formative feedback, broad assessment redesign by instructors, and concerns about algorithmic bias and equity for low-resource students. Conclusion: AI-enabled assessment offers clear pedagogical benefits when implemented thoughtfully. Key recommendations include ensuring transparent AI processes, training educators and students, and enacting equity-focused policies. Institutional readiness--through policies and support--is crucial for harnessing AI's potential for assessment while ensuring fairness and maintaining learning quality.",Educational Process: International Journal,v18 Article e2025439 2025,,http://eric.ed.gov/?id=EJ1485189,Artificial Intelligence; Student Evaluation; Technology Uses in Education; Undergraduate Students; Student Attitudes; College Faculty; Teacher Attitudes; Computer Assisted Testing; Ethics; Educational Policy,English,Journal Articles; Reports - Research
EJ1466584,Advancing Equitable Education with Inclusive AI to Mitigate Bias and Enhance Teacher Literacy,Kayode Oyetade; Tranos Zuva,2025,"Background/purpose: The integration of artificial intelligence (AI) in education has the potential to address inequalities and enhance teaching and learning outcomes. However, challenges such as AI biases, limited teacher literacy, and resource constraints hinder equitable implementation, especially in contexts like South Africa. This study investigates strategies for inclusive AI adoption, focusing on localized solutions, co-design practices, and ethical frameworks tailored to the region's unique needs, including linguistic diversity and cultural inclusivity. Materials/methods: Using a literature review methodology spanning studies from 2000 to 2024, this research examines global and local initiatives to identify effective practices for AI integration in education. The study emphasizes the importance of localized datasets, culturally responsive AI tools, continuous professional development, and collaborative learning communities. Results: The study proposes a phased implementation model that includes fairness-aware algorithms, diverse datasets, and sustainable infrastructure investments. It highlights the need to adapt global frameworks to local contexts and foster stakeholder collaboration. These strategies aim to address barriers and provide policymakers and educators with practical recommendations for equitable AI adoption. Conclusion: The findings highlight the importance of localized and culturally responsive approaches to AI integration in education. By leveraging diverse datasets, co-design practices, and ethical frameworks, South Africa can create inclusive AI systems that address inequalities and improve learning outcomes. The study offers policymakers, educators, and stakeholders a practical roadmap to ensure context-sensitive and equitable AI implementation in education.",Educational Process: International Journal,v14 Article e2025087 2025,,http://eric.ed.gov/?id=EJ1466584,Artificial Intelligence; Educational Technology; Technology Uses in Education; Equal Education; Barriers; Teacher Competencies; Resources; Culturally Relevant Education; Foreign Countries; Inclusion; Algorithms; Bias; Multiple Literacies; Technological Literacy,English,Journal Articles; Information Analyses
ED664493,University Human Resource Administrators' Awareness on Generative AI in Higher Education,Angela Jackson,2024,"This study investigates the perspectives of University Human Resource Administrators in Tennessee regarding the integration of generative AI technologies in higher education. Focusing on administrators within the College & University Professional Association for HR TN Chapter, the research employed a mixed-methods approach, utilizing pre- and post-test surveys and open-ended questions to gauge awareness, understanding, and perceptions of generative AI. While quantitative data revealed a general awareness of AI, it also exposed knowledge gaps regarding specific applications and implications for HR practices. Qualitative findings illustrated a spectrum of perceptions, with some administrators enthusiastic about AI's potential to streamline tasks and enhance employee experiences. In contrast, others expressed concerns about privacy, ethics, and job security. Guided by the Technology Acceptance Model, the study emphasizes the importance of perceived usefulness and ease of use in driving AI. Findings underscore the need for targeted training and professional development initiatives to equip HR administrators with the knowledge and skills necessary to integrate generative AI effectively. Recommendations include developing AI literacy programs, establishing ethical guidelines for AI implementation, and incorporating AI-related competencies into HR practices. This study provides valuable insights for higher education institutions nationwide as they navigate the complexities of integrating generative AI into their human resource management strategies. [The dissertation citations contained here are published with the permission of ProQuest LLC. Further reproduction is prohibited without permission. Copies of dissertations may be obtained by Telephone (800) 1-800-521-0600. Web page: http://www.proquest.com/en-US/products/dissertations/individuals.shtml.]",ProQuest LLC,"Ed.D. Dissertation, Tennessee State University",,http://eric.ed.gov/?id=ED664493,Human Resources; Universities; Administrator Attitudes; Personnel Management; Personnel Directors; Artificial Intelligence; Knowledge Level; Technological Literacy; Educational Needs; Professional Development; Technology Uses in Education,,Dissertations/Theses - Doctoral Dissertations
EJ1427049,Cybersecurity Education in the Age of Artificial Intelligence: A Novel Proactive and Collaborative Learning Paradigm,Jin Wei-Kocsis; Moein Sabounchi; Gihan J. Mendis; Praveen Fernando; Baijian Yang; Tonglin Zhang,2024,"Contribution: A novel proactive and collaborative learning paradigm was proposed to engage learners with different backgrounds and enable effective retention and transfer of the multidisciplinary artificial intelligence (AI)-cybersecurity knowledge. Specifically, the proposed learning paradigm contains: 1) an immersive learning environment to motivate the students for exploring AI/ machine learning (ML) development in the context of real-world cybersecurity scenarios by constructing learning models with tangible objects and 2) a proactive education paradigm designed with the use of collaborative learning activities based on game-based learning and social constructivism. Background: Increasing evidence shows that AI techniques can be manipulated, evaded, and misled, which can result in new and profound security implications. There is an education and training gap to foster a qualified cyber-workforce that understands the usefulness, limitations, and best practices of AI technologies in the cybersecurity domain. Efforts have been made to incorporate a comprehensive curriculum to meet the demand. There still remain essential challenges for effectively educating students on the interaction of AI and cybersecurity. Intended Outcomes: A novel proactive and collaborative learning paradigm is proposed to educate and train a qualified cyber-workforce in this new era where security breaches, privacy violations, and AI have become commonplace. Application Design: The development of this learning paradigm is grounded in the pedagogical approaches of technology-mediated learning and social constructivism. Findings: Although the research work is still ongoing, the prototype learning paradigm has shown encouraging results in promoting the learners' engagement in applied AI learning.",IEEE Transactions on Education,v67 n3 p395-404 2024,10.1109/TE.2023.3337337,http://eric.ed.gov/?id=EJ1427049,Computer Security; Artificial Intelligence; Interdisciplinary Approach; Models; Learning Activities; Educational Games; Constructivism (Learning); Simulation; Cooperation; Computer Science Education; Information Technology,English,Journal Articles; Reports - Research
EJ1490144,Artificial Intelligence and Block-Based Coding in Science Education: Graduate Student Insights,Ece Ceren Özer; Aleyna Özdemir; Feyza Ünsal; Semra Benzer,2025,"This qualitative case study explored graduate students' views (n=6) on AI-supported applications and an AI-enabled blockbased coding tool (PictoBlox) in science education. Data were gathered over a 39-hour implementation via a semi-structured interview form and screen captures from the activities, and analyzed with content analysis. Participants perceived AI tools as time-saving and pedagogically enriching, while emphasizing ethics and data security. PictoBlox's AI add-ons (e.g., natural language processing, image processing, machine learning) were seen to support concretization, visualization, and interactive content creation. Reported challenges concerned activity design and block creation skills. We discuss implications for teacher education, including targeted training on AI-supported lesson planning and assessment design, and guidance on ethical/data-protection practices. Limitations (convenience sampling, small n, self-report) constrain generalizability. Future research should replicate with larger, diverse cohorts and triangulate with classroom observations.",Science Insights Education Frontiers,v31 n1 p4977-5004 2025,,http://eric.ed.gov/?id=EJ1490144,Graduate Students; Student Attitudes; Artificial Intelligence; Technology Uses in Education; Coding; Science Education; Program Effectiveness; Barriers; Affordances; Foreign Countries,English,Journal Articles; Reports - Research
EJ1465537,The Effectiveness of Artificial Intelligence in Classroom Teaching,Seema P. V.,2024,"Artificial intelligence (AI) has become an important force in many fields, including education. Using Artificial Intelligence in classrooms can improve learning, make education more personal, and help teachers in their work. AI can change education by offering personalized learning, making assessments easier, and supporting teachers. It can also make education more accessible and improve results. However, it is important to address issues like fairness, privacy, and resistance to ensure that all students benefit from Artificial Intelligence. Moving forward, it will be essential for teachers and Artificial Intelligence to work together to shape the future of education. Artificial Intelligence also supports professional development by encouraging collaboration among educators and providing data-driven insights into teaching practices. Peer collaboration platforms and Artificial Intelligence tools for reflection help teachers grow professionally, creating communities that promote ongoing improvement. The use of Artificial Intelligence in education encourages creative thinking, critical thinking, and problem-solving skills in students. It also helps individuals develop the skills they will need in the future to choose a suitable career and become independent, productive members of society. Future research should focus on evaluating the long-term impacts of Artificial Intelligence in diverse educational settings, exploring ethical considerations, and developing best practices for integrating Artificial Intelligence tools. Collaboration between researchers, educators, and technologists is essential to create evidence-based frameworks that ensure equitable and effective Artificial Intelligence implementation in education.",Journal of Educational Technology,v21 n3 p1-9 2024,,http://eric.ed.gov/?id=EJ1465537,Artificial Intelligence; Technology Uses in Education; Faculty Development; Equal Education; Privacy; Resistance to Change; Individualized Instruction; Intelligent Tutoring Systems; Teacher Attitudes; Peer Relationship; Cooperation,English,Journal Articles; Reports - Evaluative
EJ1486030,Artificial Intelligence and the Future of Educational Content: A Cautionary Tale,Arjita Jain; Swarupa Asish Dash,2025,"This study investigates the implications of AI-generated educational content, focusing on its authenticity, reliability, and ethical considerations within the context of Education 4.0. Employing a sequential explanatory mixed-methods approach, we combine qualitative insights from semi structured interviews with 20 educators and AI developers and quantitative data from an online survey of 210 educators across various educational levels. Our findings reveal widespread adoption of AI tools, particularly in higher education (68% usage), alongside significant concerns regarding the reliability of AI-generated content and the potential for misinformation and bias (70% of respondents expressing concern). The study highlights the necessity of human oversight and robust training programs to enhance confidence in AI technologies, with a positive correlation found between AI training and perceived reliability ([beta] = 0.28, p< 0.001). Ethical considerations, including data privacy and the impact of AI on teaching roles, are also addressed. This research contributes to the ongoing discourse on the responsible use of AI in education and provides a foundation for future research and practice aimed at ensuring the integrity and quality of educational content. The study emphasizes the need for a balanced approach that leverages the potential of AI while addressing critical concerns and ultimately inform policy and practice in the evolving landscape of AI-enhanced education.",Journal of Educators Online,v22 n4 2025,,http://eric.ed.gov/?id=EJ1486030,Artificial Intelligence; Futures (of Society); Teacher Attitudes; Technology Uses in Education; Ethics; College Faculty; Elementary School Teachers; Secondary School Teachers,English,Journal Articles; Reports - Research
EJ1448631,AI-Professional Development Model for Chemistry Teacher: Artificial Intelligence in Chemistry Education,Bekir Yildirim; Ahmet Tayfur Akcan,2024,"This study aimed to propose a Professional Development Model (PDM) for chemistry teachers to enhance their professional development in Artificial Intelligence (AI). The research group consisted of 17 chemistry teachers. The study was designed using a particular case study suitable for qualitative research methods. Document review, teacher interviews, and AI opinions were utilized to create the model. Data were analyzed using inductive content analysis. The document analysis emphasized the teachers' knowledge of various topics, such as AI knowledge, AI tools, AI skills, AI ethics, AI attitudes, and AI literacy, to enable them to incorporate AI into their lessons. It was also highlighted that teachers should acquire domain-specific knowledge, skills, and competencies in the areas where artificial intelligence will be integrated. When examining the recommendations of artificial intelligence (ChatGPT and Gemini), it was found that they addressed similar content to the information included in the document analysis. Furthermore, chemistry teachers stated their deficiencies in AI literacy, AI competencies, and developing AI lesson plans. They also stated that AI applications could be included in various subjects such as organic chemistry, chemical experiments, and chemical reactions. Following the analysis of documents and teacher and AI opinions, a 10-step PDM has been proposed to enhance chemistry teachers' professional development in AI.","Journal of Education in Science, Environment and Health",v10 n4 p161-182 2024,,http://eric.ed.gov/?id=EJ1448631,Artificial Intelligence; Faculty Development; Science Teachers; Chemistry; Educational Technology; Teacher Attitudes; Knowledge Level; Technology Integration; Teacher Competencies; Models,English,Journal Articles; Reports - Research; Tests/Questionnaires
ED658826,Artificial Intelligence and Machine Learning: Unpacking High School CS Teachers' Perspectives and Pedagogical Approaches,Zachary Opps,2024,"As the use of artificial intelligence (AI), especially machine learning (ML), has dramatically increased, K-12 schools have begun to deliver AI education; however, little is known about teachers' views on the field. This qualitative study investigated how U.S. high school computer science (CS) teachers conceptualize AI, the role of AI in their CS instruction, and the instructional curricula and pedagogies these educators use to bring AI into their CS instruction. Data was collected through semi-structured interviews with 23 educators teaching 9-12th grade CS courses in U.S. schools. Data collected from interviews was examined using thematic analysis resulting in seven themes. The findings suggest that teachers see great value in AI education and encourage schools to provide AI literacy instruction for all students while providing AI technical instruction in elective CS courses. Teachers demonstrated high levels of interest in the field but a shallow understanding of AI technology. The study's findings also showed that CS teachers know of the importance of AI ethics instruction but have a limited view of AI's impact on society. Additionally, the results point to a general lack of curricula and tools designed to teach K-12 students about AI, especially materials that emphasize critique of AI technology and its societal harms. The study's results contribute to a deeper understanding of 9-12th grade teachers' conceptions of AI and the challenges they face when implementing AI instruction. Implications for teachers, school leaders, curriculum developers, policy makers, teacher educators, and professional development (PD) providers are presented. [The dissertation citations contained here are published with the permission of ProQuest LLC. Further reproduction is prohibited without permission. Copies of dissertations may be obtained by Telephone (800) 1-800-521-0600. Web page: http://www.proquest.com/en-US/products/dissertations/individuals.shtml.]",ProQuest LLC,"Ph.D. Dissertation, Michigan State University",,http://eric.ed.gov/?id=ED658826,Artificial Intelligence; High School Teachers; Computer Science Education; Teacher Education; Educational Practices; Teaching Methods; Educational Benefits; Technology Uses in Education; Technological Literacy; Ethics,,Dissertations/Theses - Doctoral Dissertations
EJ1485742,Convergence of Diverse Expertise: A Multidisciplinary Training on the Ethics of Artificial Intelligence in Healthcare Technology and Research,Russell Franco D'Souza; Krishna Mohan Surapaneni; Sathyanarayanan P.; Annamalai Regupathy; Mary Mathew; Vedprakash Mishra; Ani Grace Kalaimathi; Geethalakshmi Sekkizhar; Rajiv Tandon; Princy Louis Palatty; Vivek Mady,2025,"The integration of artificial intelligence (AI) into healthcare and research introduces sophisticated diagnostic and treatment capabilities but also raises significant ethical challenges from development to deployment and evaluation, requiring comprehensive ethical training and interdisciplinary collaboration to ensure the responsible use of AI technologies. The ""CONNECT with AI""- Collaborative Opportunity to Navigate and Negotiate Ethical Challenges and Trials with Artificial Intelligence) workshop was a three-day event, engaging multi-institutional interdisciplinary and interprofessional participants (both industry professionals and academicians) from diverse fields such as Medicine, Dentistry, Nursing, Engineering, Law, and Allied Health Sciences from India. There was equal distribution of participants from diverse fields. A mixed-method approach utilizing pre- and post-workshop assessments, confidence level surveys and thematic analyses of small group discussions and open-ended questions to evaluate the impact of the workshop on participants' ethical understanding and decision-making skills regarding AI. Post-workshop evaluations indicated a significant improvement in both theoretical knowledge and practical application of AI ethics, with assessment scores rising markedly from pre-workshop levels (p < 0.0001). Confidence in handling ethical dilemmas related to AI saw substantial increases across all domains, particularly in ensuring patient privacy and data security (p < 0.0001). Qualitative feedback highlighted diverse perceptions and sector-specific concerns about AI, emphasizing the importance of customized ethical guidelines and the integration of AI into healthcare practices. The workshop effectively enhanced participants' competence and confidence in addressing AI-related ethical issues, demonstrating the critical role of interprofessional education in fostering an ethical AI implementation framework. Continuous, interdisciplinary and interprofessional training is essential to navigate the evolving ethical landscape of AI in healthcare, ensuring safe, effective, and responsible technology use.",Journal of Academic Ethics,v23 n3 p885-899 2025,10.1007/s10805-024-09593-w,http://eric.ed.gov/?id=EJ1485742,Artificial Intelligence; Health Services; Medical Services; Ethics; Computer Use; Professional Development; Workshops; Health Personnel; Program Effectiveness; Knowledge Level; Self Efficacy; Competence,English,Journal Articles; Reports - Research
EJ1428661,Artificial Intelligence Competence: A Crucial Skill for the Digital Citizens,Supanee Sengsri; Kheamparit Khunratchasana,2024,"Artificial intelligence (AI) technology has made a significant impact on technological progress and has been integrated into various sectors and organizations. As a result, developing a workforce with knowledge and expertise in AI has become necessary. Skilled AI professionals will play a critical role in driving economic growth and competitiveness in the digital age. Therefore, it is essential to develop AI competency among various groups of people. Learning AI skill sets is necessary to facilitate effective collaboration between humans and machines in the learning process. Known for Life offers a range of knowledge, including technical skill sets, business skill sets, and skill sets for individuals that incorporate ethics, such as the ethical use of AI in education to enhance the learning experience and evaluate student performance. Understanding AI can help educators adopt modern teaching methods and prepare students for AI-related careers, but it is crucial to consider ethical implications.",International Education Studies,v17 n3 p75-83 2024,,http://eric.ed.gov/?id=EJ1428661,Artificial Intelligence; Digital Literacy; Competence; Skill Development; 21st Century Skills; Labor Force Development; Influence of Technology; Curriculum Development; Computer Science Education; Information Technology; Role Theory; Futures (of Society); Educational Trends; Sociocultural Patterns; Trend Analysis,English,Journal Articles; Information Analyses
ED635697,AI and the Future of Education: Teaching in the Age of Artificial Intelligence,"Shah, Priten",2023,"Among teachers, there is a cloud of rumors, confusion, and fear surrounding the rise of artificial intelligence. ""AI and the Future of Education"" is a timely response to this general state of panic, showing you that AI is a tool to leverage, not a threat to teaching and learning. By understanding what AI is, what it does, and how it can be used to enhance education, you can let go of anxiety and uncertainty, and learn to embrace artificial intelligence. It's true that, along with tremendous opportunities, AI presents some challenges for the field of education. In this book, Priten Shah, a Harvard M.Ed. with a robust background in educational innovation, helps you face these challenges head on, so you can gain the knowledge and skills you need to use AI effectively in your classroom. Thanks to this thorough consideration of ethical considerations and practical approaches, you can develop your own strategy for leveraging AI in administrative tasks, lesson design, professional development, and beyond. Steps include: (1) Understand what AI and machine learning are, and learn about new developments like ChatGPT; (2) Discover strategies for engaging students more fully using AI; (3) Automate administrative tasks, grading and feedback, and assessments; (4) Use AI in innovative ways to promote higher-order thinking skills; and (5) Examine ethical considerations of AI, including the achievement gap, privacy concerns, and bias. For K-12 educators, as well as leaders and policymakers who want to understand the role of technology in education, ""AI and the Future of Education"" is a valuable resource that can change AI from an unknown entity to an indispensable tool.","Jossey-Bass, An Imprint of Wiley",,,http://eric.ed.gov/?id=ED635697,Artificial Intelligence; Futures (of Society); Teaching (Occupation); Ethics; Educational Practices; Man Machine Systems; Natural Language Processing; Educational Strategies; Learner Engagement; Automation; Thinking Skills; Skill Development; Technology Uses in Education; Technology Integration; Elementary Secondary Education,,Books; Guides - Non-Classroom
EJ1478876,Navigating Anxiety in Academia: The Role of Generative Artificial Intelligence,Oqab Jabali; Munther Saeedi; Yousef Alawneh,2025,"This study explores educators' perspectives on the impact of generative artificial intelligence (AI) on academic roles within Palestinian institutions. Through qualitative interviews and quantitative surveys, the research reveals significant anxiety among educators, particularly concerning the potential decline of traditional roles, educational standards, and ethical implications of AI integration. While the study sought to identify demographic differences in concerns, the analysis found no statistically significant variations among respondents. Qualitatively, the study results showed that 69.2% of respondents expressed anxiety about the reduction of traditional teaching roles, 55.8% raised concerns regarding the potential decline in educational quality. Ethical implications, including privacy and research integrity, were significant themes, with 26.9% indicating strong concern in this area. Participants also highlighted the need for increased training and collaboration between educators and technology developers. The findings reveal a nuanced landscape where educators recognize the potential of AI to enhance educational practices while simultaneously grappling with the complexities and ethical challenges it presents. The study underscores the necessity for robust frameworks and professional development initiatives to ensure that AI adoption in academia benefits both educators and students in Palestine.",Education and Information Technologies,v30 n11 p15529-15544 2025,10.1007/s10639-025-13433-8,http://eric.ed.gov/?id=EJ1478876,Anxiety; College Faculty; Artificial Intelligence; Technology Integration; Computer Software; Teacher Attitudes; Teacher Surveys; Teacher Role; Educational Quality; Privacy; Integrity; Ethics; Cooperation; Educational Practices; Faculty Development; Foreign Countries,English,Journal Articles; Reports - Research
EJ1416403,Artificial Intelligence in K-12 Education: Eliciting and Reflecting on Swedish Teachers' Understanding of AI and Its Implications for Teaching & Learning,Johanna Velander; Mohammed Ahmed Taiye; Nuno Otero; Marcelo Milrad,2024,"Uncovering patterns and trends in vast, ever-increasing quantities of data has been enabled by different machine learning methods and techniques used in Artificial Intelligence (AI) systems. Permeating many aspects of our lives and influencing our choices, development in this field continues to advance and increasingly impacts us as individuals and our society. The risks and unintended effects such as bias from input data or algorithm design have recently stirred discourse about how to inform and teach AI in K-12 education. As AI is a new topic not only for pupils in K-12 but also for teachers, new skill sets are required that enable critical engagement with AI. AI literacy is trying to close the gap between research and practical knowledge transfer of AI-related skills. Teachers' AI-related technological, pedagogical and content knowledge (TPACK) are important factors for AI literacy. However, as teachers' perspectives, beliefs and views impact both the interpretation and operationalisation of curriculum. this study explores teachers' and teacher educators' understanding and preconceptions of AI to inform teacher education and professional development. To gain a comprehensive understanding of teachers' conceptualisations regarding AI an anonymous questionnaire together with focus group discussions were employed. The qualitative content analysis underpinned by the theoretical framework Intelligent TPACK reveals that teachers' AI-related content knowledge is generally gained through incidental learning and often results in pre- and misconceptions of AI. Our analysis also revealed several potential challenges for teachers in achieving core constructs of Intelligent TPACK, examples of such challenges are vague and unclear guidelines in both policy and curriculum, a lack of understanding of AI and its limitations, as well as emotional responses related to participants' preconceptions. These insights are important to consider in designing teacher education and professional development related to AI literacy.",Education and Information Technologies,v29 n4 p4085-4105 2024,10.1007/s10639-023-11990-4,http://eric.ed.gov/?id=EJ1416403,Foreign Countries; Elementary School Teachers; Secondary School Teachers; Teacher Educators; Artificial Intelligence; Teacher Attitudes; Technology Uses in Education; Pedagogical Content Knowledge; Technological Literacy; Teacher Education; Faculty Development; Misconceptions; Barriers; Emotional Response,English,Journal Articles; Reports - Research
ED678146,"Policy Recommendations for New Jersey's Artificial Intelligence Leadership in K-12, Higher Education, and Workforce Development",Satyadhar Joshi,2026,"This paper presents a policy framework to position New Jersey as a national leader in artificial intelligence (AI) education and workforce development. Through analysis of current state initiatives--including the NJ AI Hub, AI Task Force reports, apprenticeship programs, and regulatory guidance--we identify gaps and opportunities across K-12, higher education, and workforce development sectors. We propose a multi-layered approach visualized through interconnected frameworks: an integrated AI education ecosystem, phased implementation roadmaps for K-12 AI literacy, a statewide AI curriculum consortium structure, multi-track workforce development pathways, and equity and access frameworks. Quantitative analysis reveals that while 20-25%+ of New Jersey's workforce already uses AI technology daily, only 20-25% of educators feel prepared for AI integration. Our policy recommendations address this gap through a $165 million annual investment strategy with projected 3.8x return on investment, creating pathways for 15,000-20,000 new AI jobs by 2030. Recommendations include more layered, interconnected and framework-styled methods for establishing AI literacy standards for all K-12 students, creating specialized AI high schools, expanding community college AI programs, developing industry-aligned university curricula, and implementing statewide AI teacher training. We also address equity and risk considerations, funding mechanisms, and suggested implementation timelines. This is a pure review paper and all findings are from suggested literature.",Online Submission,,,http://eric.ed.gov/?id=ED678146,Artificial Intelligence; Elementary Secondary Education; Higher Education; Labor Force Development; Educational Policy; Governance; Adoption (Ideas); Ethics; Technology Integration; Incentives,,Reports - Evaluative
EJ1483840,Preparing the Next Generation of Health Education Teachers for the Ethical Use of AI,Melissa J. Haithcox-Dennis; Reeshemah Johnson,2025,"This article examines how health education teacher preparation programs can prepare future educators to use artificial intelligence (AI) in responsible and effective ways. It begins with a brief overview of the use of AI in education, considering the growing impact of generative AI technologies on teaching and learning. The article outlines international and national standards that govern the application of AI in education, addressing key ethical concerns, including the dissemination of inaccurate health information, violations of student privacy, bias, and inequitable access to AI tools. The article emphasizes the importance of ethical decision-making and professional responsibility when integrating AI into instruction. Drawing on existing health education standards and ethical guidelines, the article offers practical recommendations to support the thoughtful and ethical use of these tools. The goal is to strengthen both initial teacher preparation and continuing professional development so that health educators are equipped to provide instruction that is accurate, inclusive, and responsive to students' needs in a changing educational landscape.",Journal of Research Initiatives,v9 n1 Article 2 2025,,http://eric.ed.gov/?id=EJ1483840,Health Education; Artificial Intelligence; Educational Technology; Ethics; Technology Uses in Education; Standards; Information Dissemination; Privacy; Accuracy; Access to Computers; Teacher Education Programs; Teacher Competencies; Compliance (Legal); Access to Internet,English,Journal Articles; Reports - Evaluative
EJ1430089,Utilization of Artificial Intelligence and Machine Learning in Chemistry Education: A Critical Review,Aloys Iyamuremye; Francois Niyongabo Niyonzima; Janvier Mukiza; Innocent Twagilimana; Pascasie Nyirahabimana; Theophile Nsengimana; Jean Dieu Habiyaremye; Olivier Habimana; Ezechiel Nsabayezu,2024,"The current study aimed to criticize the existing literature on the utilization of artificial intelligence (AI) and machine learning (ML) in teaching and learning chemistry. A comprehensive critical literature review was conducted using electronic databases such as Scopus, PubMed, ISI, Google Scholar, ERIC, Web of Science, and JSTOR. In this regard, 62 articles were extracted from these electronic databases. During the selection of the literature inclusion and exclusion criteria were applied. The inclusion criteria include empirical and theoretical studies examining the effectiveness, challenges, and opportunities of AI/ML, and articles from 2018 to 2024 and written in English. On the other side, the exclusion criteria include literature that unrelated to education, lacking empirical evidence, or not peer-reviewed, as well as non-English publications, and published before 2018. This was done to gain insights into the current implementation status of AI and ML as well as critical issues of using these approaches in chemistry education. The study employed a critical review of the literature, which involves a critical analysis of the themes and concepts that emerge from the selected literature and identifies the opportunities and challenges surrounding the utilization of these technologies. The results revealed that there are opportunities for the integration of AI and ML in chemistry education, including personalized learning experiences, teacher assistance, and accessibility to learning materials. In this regard, intelligent tutoring systems and adaptive learning platforms were identified as potential aides for teachers in various aspects of teaching. The study also revealed the limitations and challenges surrounding AI and ML, such as the dependence on preexisting data, potential biases in models, and concerns around data privacy and security. Moreover, the findings also indicated that the implementation of AI and ML in chemistry education is still in its juvenile stage. Thus, teacher training programs are needed to equip teachers with the necessary skills for the use of these technologies effectively in the classroom. In addition, more efforts should be made to facilitate research, collaboration, and the development of policies and regulations that ensure responsible use of these technologies in the teaching and learning process.",Discover Education,v3 Article 95 2024,10.1007/s44217-024-00197-5,http://eric.ed.gov/?id=EJ1430089,Chemistry; Science Education; Journal Articles; Artificial Intelligence; Technology Uses in Education; Evidence Based Practice; Educational Strategies; Educational Practices; Technology Integration; Barriers,English,Journal Articles; Information Analyses
EJ1461373,Artificial Intelligence in Nursing: New Opportunities and Challenges,Estel·la Ramírez-Baraldes; Daniel García-Gutiérrez; Cristina García-Salido,7003,"To explore the opportunities and challenges of artificial intelligence (AI) in nursing and its impact. Bibliographic review using Arksey and O'Malley's framework, enhanced by Levac, Colquhoun and O'Brien and following PRISMA guidelines, including qualitative and mixed studies. MeSH terms and keywords such as nursing education and ethical considerations were used in databases such as PubMed, Scopus, Web of Science, CINAHL, IEEE Xplore and Google Scholar. Of all, 53 studies were included, highlighting various opportunities and challenges of AI integration and opportunities for personalised learning, training improvement and evaluation. Highlighting challenges related to academic integrity, accuracy, data privacy and security, for the development of critical thinking skills. The integration of AI in nursing education offers significant advantages for improving the quality and effectiveness of education, such as academic integrity, critical thinking and equitable access, for this reason, faculty training should be geared toward the integration of AI in nursing education.",European Journal of Education,v60 n1 e70033 2025,10.1111/ejed.70033,http://eric.ed.gov/?id=EJ1461373,Artificial Intelligence; Nursing; Nursing Education; Barriers; Technology Integration; Program Effectiveness; Critical Thinking; Educational Quality; Integrity; Access to Education; Information Security; Privacy,English,Journal Articles; Information Analyses
EJ1485873,"The Role of Artificial Intelligence in Teaching and Learning: Perspectives of Learners, Teachers, and Administrators in Kerala Schools",Sankaranarayanan Paleeri; Sneha Parambath,2025,"This study explored the perceptions of learners, teachers, and administrators on the role of artificial intelligence (AI) in the higher secondary school education scenario of Kerala. The study was a comprehensive survey, and sample groups included 360 students, 60 teachers, and 5 administrators. Both qualitative methods and quantitative techniques are employed for data collection and analysis. The results indicate that students, teachers, and administrators expressed optimism about implementing AI in education. It is identified that, through the availability of educational resources and training, artificial intelligence has the potential to revolutionize the existing school education landscape. The results are supportive of recommending the government and policymakers publish guidelines to ensure the privacy and effective integration of artificial intelligence in education.",Journal of Educational Technology,v22 n2 p42-55 2025,,http://eric.ed.gov/?id=EJ1485873,Artificial Intelligence; Computer Uses in Education; Student Attitudes; Teacher Attitudes; Administrator Attitudes; Secondary School Students; Secondary School Teachers; Computer Attitudes; Educational Technology; Foreign Countries; Technology Integration; Influence of Technology,English,Journal Articles; Reports - Research
EJ1424346,Application of Artificial Intelligence in Physical Education: A Systematic Review,Tong Zhou; Xingliang Wu; Yudong Wang; Yilei Wang; Shunan Zhang,2024,"The application of artificial intelligence in physical education (AIPE) has provided new ways to improve learning and teaching activities in physical classes. However, literature reviews that provide a systematic review and analysis of AIPE are limited. To address this gap, this study provided an overview of AIPE-related empirical research. Specifically, it examined the general state of AIPE, algorithms used for AIPE, and the impact and challenges of AIPE. Following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses, 130 empirical studies related to AIPE were included in the final synthesis. The findings of this study demonstrated that numerous studies have explored the use of AI technologies to enhance physical education classes and training processes. These technologies have been widely employed in athletic performance analysis, health monitoring, and personalized training. AIPE offered great potential for providing personalized instruction, real-time feedback and assessment, and diverse learning environments. However, the use of AI technology poses challenges, including technical reliability and accuracy, privacy and security issues, as well as technical training and teacher support. These findings provide insights for future research on AIPE.",Education and Information Technologies,v29 n7 p8203-8220 2024,10.1007/s10639-023-12128-2,http://eric.ed.gov/?id=EJ1424346,Artificial Intelligence; Physical Education; Technology Uses in Education; Athletics; Training; Individualized Instruction; Feedback (Response); Evaluation; Physical Health,English,Journal Articles; Information Analyses
EJ1485435,Ethical Challenges Associated with the Use of Artificial Intelligence in University Education,Yuri Reina Marín; Omer Cruz Caro; Angelica María Carrasco Rituay; Katia Araceli Guimac Llanos; Doris Tarrillo Perez; Einstein Sánchez Bardales; Judith Nathaly Alva Tuesta; River Chávez Santos,2025,"The integration of Artificial Intelligence (AI) within higher education has given rise to substantial ethical concerns and challenges, including concerns regarding data privacy, equity in educational resources, and algorithmic biases. These factors have the potential to compromise the integrity of academic processes. In light of this, the study aims to analyze the perceptions of students and faculty members about the ethical challenges associated with the use of AI in universities. The methodology employed was non-experimental quantitative, with the questionnaires being designed according to Luciano Floridi's algorithmic theory. The study's participants 890 university students and 162 faculty members from 21 higher education institutions in Peru. Results indicate that 51.2% of faculty and 47.5% of students expressed concern about data privacy and security. Moreover, a significant proportion of respondents, 61.1% of faculty and 53.5% of students, believed that AI systems lack transparency. These findings highlight the urgent need for regulatory frameworks that promote ethical AI use, ensure equitable access, and safeguard academic autonomy. It is essential for universities to implement concrete measures, including ethical oversight mechanisms, audit protocols, and digital literacy training programs, to maximize the benefits and mitigate the risks of AI in education.",Journal of Academic Ethics,v23 n4 p2443-2467 2025,10.1007/s10805-025-09660-w,http://eric.ed.gov/?id=EJ1485435,Ethics; Artificial Intelligence; Technology Uses in Education; Higher Education; Technology Integration; College Faculty; Teacher Attitudes; College Students; Student Attitudes; Foreign Countries; Privacy; Information Security; Accountability; Personal Autonomy; Supervision; Audits (Verification); Digital Literacy; Training; Risk,English,Journal Articles; Reports - Research
EJ1464834,"Perceptions, Strategies, and Challenges of Teachers in the Integration of Artificial Intelligence in Primary Education: A Systematic Review",Olga Arranz Garcia; María del Carmen Romero García; Vidal Alonso-Secades,2025,"Aim/Purpose: Evaluate teachers' perceptions, strategies, and challenges in integrating artificial intelligence (AI) into K-12 education and identify patterns and trends in the data from the reviewed studies. Background: This systematic review examines a decade of innovation to explore the transformative impact of AI on education (2014-2024). Adhering to PRISMA 2020 guidelines, the study uncovers key trends, challenges, and breakthroughs in AI-driven teaching and learning, offering a comprehensive perspective on how AI reshapes educational practices and methodologies. Methodology: The study employs a systematic review to analyze the implementation of AI techniques and tools in primary education, following the PRISMA 2020 guidelines to ensure the reliability and effectiveness of the findings. To achieve this, an extensive search was conducted in academic databases such as Web of Science, Scopus, and ERIC, focusing on empirical studies and peer-reviewed articles published between 2014 and 2024. Only accessible, peer-reviewed articles classified under Education and Educational Research and published in English or Spanish were selected. The search strategy was structured into five categories aligned with the research questions to identify relevant studies accurately. The selection process was carried out in three phases -- Identification, Screening, and Inclusion -- applying predefined criteria to guarantee the quality and relevance of the selected studies. Of an initial total of 514,919 articles, 488,940 were excluded for not meeting the inclusion criteria. After removing duplicates and evaluating titles, abstracts, and full texts, a final set of 28 studies was included. Contribution: The study explores the integration of AI in primary education, revealing both teachers' enthusiasm and the challenges they face. While AI is perceived as a tool to enhance critical thinking, problem-solving, and student engagement, its implementation is limited by insufficient training, resources, and institutional support. Despite these obstacles, teachers show confidence in designing AI-integrated curricula, though this is weakened by inadequate infrastructure and technical support, highlighting the need for continuous professional development. The study also stresses the importance of establishing a competency framework for AI literacy and adopting a systemic approach to AI education. Additionally, ensuring safe learning environments by addressing data privacy and AI biases remains a key challenge. Overcoming these issues is essential for the ethical and effective integration of AI, maximizing its benefits while safeguarding student equity and security. Findings: (1) Educators see the potential of AI to personalize learning; (2) Barriers are lack of training and resources for teachers; (3) Importance of continuous training in digital skills; (4) Need for policies that promote AI literacy; and (5) Collaboration with experts to optimize AI in the classroom. Recommendations for Practitioners: Teachers are encouraged to collaborate in using AI tools to enhance educational outcomes, supported by continuous professional development programs, clear policies that safeguard privacy and promote equality, and a framework that preserves human autonomy in integrating AI technologies. Recommendation for Researchers: The lack of empirical research on AI interventions in education limits understanding of its true impact, highlighting the need for future studies to fill this gap and optimize its application for greater educational benefits. Impact on Society: The integration of AI in K-12 education is not just an opportunity; it is a necessity to prepare future generations for an increasingly digital world. While AI has the potential to revolutionize learning by fostering critical thinking, personalization, and engagement, its impact depends on how effectively it is implemented. To ensure its benefits, it is essential to empower educators and students with AI literacy, address issues like bias and data privacy, and establish robust legal frameworks for fair and transparent use. Without proactive policies, AI could widen educational inequalities instead of reducing them. A responsible, human-centered approach is needed to create an inclusive, ethical, and effective AI-powered education system. Future Research: The article highlights the urgency of future empirical research to better understand the real impact of AI in education, as the lack of intervention studies limits its optimal application. Analyzing how AI influences learning outcomes, teaching dynamics, equity, and accessibility is essential, along with investigating the pedagogical competencies and technological conditions that affect its adoption. To this end, expanding the scope of studies is recommended by incorporating multicultural and multilingual perspectives, exploring AI applications across various disciplines and educational levels, and promoting interdisciplinary approaches that address ethical, social, and pedagogical dimensions.",Journal of Information Technology Education: Research,v24 Article 6 2025,,http://eric.ed.gov/?id=EJ1464834,Artificial Intelligence; Teacher Attitudes; Barriers; Technology Integration; Elementary School Teachers; Technology Uses in Education; Educational Trends; Journal Articles; Educational Strategies; Educational Innovation; Influence of Technology; Educational Practices; Individualized Instruction; Faculty Development; Multiple Literacies; Policy Formation; Classroom Environment; Partnerships in Education; Skill Development; Technological Literacy,English,Journal Articles; Information Analyses
EJ1470011,Personalized Learning through AI: Pedagogical Approaches and Critical Insights,Klarisa I. Vorobyeva; Svetlana Belous; Natalia V. Savchenko; Lyudmila M. Smirnova; Svetlana A. Nikitina; Sergei P. Zhdanov,2025,"In this analysis, we review artificial intelligence (AI)-supported personalized learning (PL) systems, with an emphasis on pedagogical approaches and implementation challenges. We searched the Web of Science and Scopus databases. After the preliminary review, we examined 30 publications in detail. ChatGPT and machine learning technologies are among the most often utilized tools; studies show that general education and language learning account for the majority of AI applications in the field of education. Supported by particular learning approaches stressing student characteristics and expectations, the results show that automated feedback systems and adaptive content distribution define AI's educational responsibilities mostly. The study notes major difficulties in three areas: technical constraints and data privacy concerns; educational and pragmatic barriers. Although curriculum integration and teacher preparation are considered major concerns, pedagogical challenges come first above technology integration. The results also underline the need for thorough professional development activities for teachers and AI tools for especially targeted instruction. The study shows that the efficient application of AI-enabled PL requires a comprehensive strategy addressing technological, pedagogical, and ethical issues all at once. These results help to describe the current state of AI in education and provide ideas for future developments as well as techniques for its use.",Contemporary Educational Technology,v17 n2 Article ep574 2025,,http://eric.ed.gov/?id=EJ1470011,Individualized Instruction; Artificial Intelligence; Intelligent Tutoring Systems; Ethics; Technology Uses in Education; Privacy; Barriers; Technology Integration; Faculty Development,English,Journal Articles; Information Analyses
EJ1416711,"Living Well with AI: Virtue, Education, and Artificial Intelligence",Nicholas Smith; Darby Vickers,2024,"Artificial intelligence technologies have become a ubiquitous part of human life. This prompts us to ask, ""how should we live well with artificial intelligence?"" Currently, the most prominent candidate answers to this question are principlist. According to these approaches, if you teach people some finite set of principles or convince them to adopt the right rules, people will be able to live and act well with artificial intelligence, even in an evolving and opaque moral world. We find the dominant principlist approaches to be ill-suited to providing forward-looking moral guidance regarding living well with artificial intelligence. We analyze some of the proposed principles to show that they oscillate between being too vague and too specific. We also argue that such rules are unlikely to be flexible enough to adapt to rapidly changing circumstances. By contrast, we argue for an Aristotelian virtue ethics approach to artificial intelligence ethics. Aristotelian virtue ethics provides a concrete and actionable guidance that is also flexible; thus, it is uniquely well placed to deal with the forward-looking and rapidly changing landscape of life with artificial intelligence. However, virtue ethics is agent-based rather than action-based. Using virtue ethics as a basis for living well with artificial intelligence requires ensuring that at least some virtuous agents also possess the relevant scientific and technical expertise. Since virtue ethics does not prescribe a set of rules, it requires exemplars who can serve as a model for those learning to be virtuous. Cultivating virtue is challenging, especially in the absence of moral sages. Despite this difficulty, we think the best option is to attempt what virtue ethics requires, even though no system of training can guarantee the production of virtuous agents. We end with two alternative visions -- one from each of the two authors -- about the practicality of such an approach.",Theory and Research in Education,v22 n1 p19-44 2024,10.1177/14778785241231561,http://eric.ed.gov/?id=EJ1416711,Artificial Intelligence; Moral Values; Ethics; Philosophy; Well Being; Higher Education,English,Journal Articles; Reports - Evaluative
EJ1350374,Validity Arguments Meet Artificial Intelligence in Innovative Educational Assessment,"Dorsey, David W.; Michaels, Hillary R.",2022,"We have dramatically advanced our ability to create rich, complex, and effective assessments across a range of uses through technology advancement. Artificial Intelligence (AI) enabled assessments represent one such area of advancement--one that has captured our collective interest and imagination. Scientists and practitioners within the domains of organizational and workforce assessment have increasingly used AI in assessment, and its use is now becoming more common in education. While these types of solutions offer their users the promise of efficiency, effectiveness, and a ""wow factor,"" users need to maintain high standards for validity and fairness in high stakes settings. Due to the complexity of some AI methods and tools, this requirement for adherence to standards may challenge our traditional approaches to building validity and fairness arguments. In this edition, we review what these challenges may look like as validity arguments meet AI in educational assessment domains. We specifically explore how AI impacts Evidence-Centered Design (ECD) and development from assessment concept and coding to scoring and reporting. We also present information on ways to ensure that bias is not built into these systems. Lastly, we discuss future horizons, many that are almost here, for maximizing what AI offers while minimizing negative effects on test takers and programs.",Journal of Educational Measurement,v59 n3 p267-271 Fall 2022,10.1111/jedm.12331,http://eric.ed.gov/?id=EJ1350374,Validity; Ethics; Artificial Intelligence; Evaluation Methods; Educational Assessment; High Stakes Tests; Computer Assisted Testing; Evidence Based Practice; Scoring; Innovation,English,Journal Articles; Reports - Evaluative
EJ1477106,Teachers and Learners' Perceptions about Implementation of AI Tools in Elementary Mathematics Classes,Xuejing Song; Joonkong Mak; Haowei Chen,2025,"The integration of artificial intelligence (AI) tools in educational environments presents creative chances to improve mathematics education in elementary schools. This mixed-method study investigates the use of artificial intelligence tools in elementary mathematics classrooms. Complementing qualitative data from semi-structured interviews, the study had a quasi-experimental design with pre-and post-tests to measure students' mathematical skills and a survey to explore perceptions about AI-based tool implementation. Following the employment of artificial intelligence tools, quantitative data show a notable increase in learners' general mathematics performance and problem-solving ability. Qualitative data provide a deep insight of teachers and learners understanding about AI tools utilization in elementary mathematics classrooms and personalized experiences with expectations for learning process. Apart from several advantages, the findings highlighted few reservations about technological issues and ethical privacy concerns. However, the data analysis concludes AI tools implementation visibly enhance elementary mathematics classroom performance with the help of appropriate technology training and reasonable resources. This study advances knowledge on how best to include artificial intelligence into the classroom thereby augmenting instruction and learning support. The findings also lead to future recommendations for further research considering gender differences, bigger sample and different demographic regions.",SAGE Open,v15 n2 2025,10.1177/21582440251334545,http://eric.ed.gov/?id=EJ1477106,Teacher Attitudes; Student Attitudes; Mathematics Instruction; Mathematics Skills; Artificial Intelligence; Computer Software; Mathematics Achievement; Problem Solving; Elementary School Students; Learning Processes; Ethics; Privacy; Technology Integration; Teaching Methods; Elementary School Teachers; Likert Scales; Barriers; Technological Literacy; Pedagogical Content Knowledge,English,Journal Articles; Reports - Research
EJ1470438,"Artificial Intelligence in Early Childhood STEM Education: A Review of Pedagogical Paradigms, Ethical Issues, and Socio-Political Implications",Elif Ozturk,2025,"This study examines the pedagogical, ethical, and political dimensions of artificial intelligence (AI) in early childhood STEM education from a theoretical perspective. As digital technologies become increasingly prevalent in education, AI applications offer significant opportunities in areas such as personalized learning experiences, game-based education, and data analytics. However, they also pose critical ethical concerns, including data security, algorithmic bias, and privacy, while influencing children's cognitive, linguistic, and social development. Drawing on Piaget's theory of active discovery and learning, Vygotsky's emphasis on social interaction and teacher guidance, and Bronfenbrenner's ecological systems theory, this study explores how AI-supported learning environments can enrich children's natural developmental processes. A qualitative literature review and theoretical analysis reveal the necessity of achieving a balanced integration between the individualized educational opportunities offered by AI and the potential risks it entails. The findings highlight the critical importance of developing human-centered, ethically sound, and inclusive educational models for educators, policymakers, and researchers in the face of technological transformation. In this context, teacher training, parental collaboration, and interdisciplinary strategies are identified as fundamental prerequisites for the sustainable and effective integration of AI in early childhood education.","Journal of Education in Science, Environment and Health",v11 n2 p108-125 2025,,http://eric.ed.gov/?id=EJ1470438,Early Childhood Education; STEM Education; Artificial Intelligence; Game Based Learning; Technology Integration; Individualized Instruction; Information Security,English,Journal Articles; Information Analyses
ED673750,AI-U: Student Guide to Artificial Intelligence,Daniel J. Anderson; C. Edward Watson; Lee Rainie; Janna Anderson,2025,"This free guide empowers students with the insights they need to navigate the age of AI academically, professionally, and ethically. It includes guidance for responsible academic AI use, a checklist for ethical and effective engagement with AI, and tips on incorporating AI to enhance student capabilities. It also outlines how to build an effective writing prompt for AI tools and provides practical tips for preparing for the workforce in an AI-driven job market. An initiative of Elon University in partnership with AAC&U, this guide was developed through the collaboration of faculty, scholars, academic leaders, and students at universities from around the world. Free to use, share, and adapt under a Creative Commons license.",American Association of Colleges and Universities,,,http://eric.ed.gov/?id=ED673750,College Students; Student Experience; Technology Uses in Education; Artificial Intelligence; Guidelines; Check Lists; Technology Integration; Technological Literacy; Integrity; Ethics; Learner Engagement; Technological Advancement; Influence of Technology; Job Skills; Prompting; Writing (Composition); Man Machine Systems,,Guides - Classroom - Learner
ED676378,Implementing AI Tools for Language Teaching and Learning,"Vu Phi Ho Pham, Editor; Andrew Lian, Editor; Ania Lian, Editor; Sandro R. Barros, Editor",2025,"The implementation of artificial intelligence (AI) tools has revolutionized language education. For teachers and students, it provides more options for personalized learning that can be utilized inside or outside of the classroom with real-time feedback. While AI has been pivotal in making language education accessible for students, including those in special education, it has its drawbacks in terms of algorithm bias, decreased human interaction, and security concerns. This calls for responsible use of AI in language education and further professional development for teachers to enhance their experience of language learning. ""Implementing AI Tools for Language Teaching and Learning"" explores the advancement of digital technology in language education and the implications it has for the future of learning. It covers various AI-driven applications for language acquisition and translation as well as the impact they may have on students' cognitive abilities and performance. Covering topics such as essay writing skills, long-short term memory (LSTM) models, and handwritten text recognition, this book is an excellent resource for language educators, policymakers, professionals, researchers, academicians, and more.",IGI Global,,,http://eric.ed.gov/?id=ED676378,Artificial Intelligence; Technology Uses in Education; Second Language Instruction; Second Language Learning; Language Acquisition; Translation; Cognitive Ability; Academic Achievement; Essays; Writing Skills; Long Term Memory; Short Term Memory; Handwriting; Identification,,Books; Collected Works - General
EJ1492938,A Survey of K-12 Teachers' Perspectives on Teaching with Generative Artificial Intelligence,Gary Andersen; Sohyun Yang,2025,"This study investigated K-12 educators' perceptions of generative artificial intelligence (GenAI) in teaching and learning, examining how teachers use and evaluate GenAI tools in relation to student thinking and classroom practices. Grounded in Bloom's Taxonomy (1956) and Ritchhart's (2015) Cultures of Thinking framework, the survey of 73 teachers revealed that while most participants use GenAI for instructional design and administrative efficiency, far fewer employ it to foster higher-order cognitive processes such as application, analysis, and evaluation. Teachers reported benefits in lesson planning and differentiation but expressed concerns about accuracy, ethics, and overreliance. Findings highlighted a critical need for professional development that integrates technical proficiency with pedagogical strategies for using GenAI to promote application, critical thinking, and deeper student learning. The study underscores that GenAI's educational potential remains underrealized without intentional alignment to human-centered teaching goals.",Advocate,v30 n2 Article 3 2025,,http://eric.ed.gov/?id=EJ1492938,Elementary School Teachers; Secondary School Teachers; Teacher Attitudes; Artificial Intelligence; Teaching Methods; Technology Uses in Education; Teacher Behavior; Barriers; Thinking Skills; Teacher Education Programs; Graduate Students; Online Courses; Masters Degrees,English,Journal Articles; Reports - Research
EJ1462822,Embracing Generative Artificial Intelligence: The Perspectives of English Instructors in Thai Higher Education Institutions,Lucas Kohnke; Mark B. Ulla,2024,"This study explored the perspectives of English instructors from Thai higher education institutions, with a focus on teachers' familiarity with generative artificial intelligence (GenAI) and its potential impact on teachers' professional roles and responsibilities. The results suggested that GenAI tools may allow English instructors to transition from traditional teachers to facilitators by using the tools to assist with both routine writing tasks and highlevel academic work. Meanwhile, it was found that instructors worried about possible over-reliance on GenAI. The participants emphasised that human instructors were still needed, although their roles needed to evolve. Significant gaps were identified in the competencies related to professional development, curriculum design, teacher training programmes, ethics, and responsibility. The findings may support the professional growth of current and future English instructors and facilitate the incorporation of GenAI in teaching practice. The findings also underscore the necessity of comprehensive GenAI training for preservice teachers, the development of robust guidelines to navigate ethical challenges, and the examination of the impact of GenAI tools on student engagement and learning outcomes.",Knowledge Management & E-Learning,v16 n4 p653-670 2024,,http://eric.ed.gov/?id=EJ1462822,Artificial Intelligence; Natural Language Processing; Technology Uses in Education; English (Second Language); Language Teachers; College Faculty; Foreign Countries; Teacher Attitudes; Teacher Role; Teacher Responsibility; Teacher Behavior; Second Language Instruction; Teacher Education; Opportunities; Barriers; Technology Integration,English,Journal Articles; Reports - Research
EJ1453067,AI Ethics as a Complex and Multifaceted Challenge: Decoding Educators' AI Ethics Alignment through the Lens of Activity Theory,Jaber Kamali; Muhammet Furkan Alpat; Aras Bozkurt,2024,"This study explores university educators' perspectives on their alignment with artificial intelligence (AI) ethics, considering activity theory (AT), which forms the theoretical underpinning of this study. To do so, 37 educators from a higher education institution were selected to write their metaphors about AI ethics alignment, out of which 11 attended semi-structured interviews, in which they answered some questions about their AI ethics alignment and narrated some experiences. The study reveals diverse and often contradictory perspectives on AI ethics, highlighting a general lack of awareness and inconsistent application of ethical principles. Some educators metaphorised AI ethics as fundamental but difficult to understand, while others pointed to the difficulties of regulating ethical violations. The findings highlight the need for targeted professional development on AI ethics, collaborative policy making and a multidisciplinary approach to promote ethical use of AI in higher education. This study also calls for stronger alignment between educators' personal ethical standards and institutional norms to reduce AI-related risks in educational settings.",International Journal of Educational Technology in Higher Education,v21 Article 62 2024,10.1186/s41239-024-00496-9,http://eric.ed.gov/?id=EJ1453067,Artificial Intelligence; Ethics; College Faculty; Teacher Attitudes; Figurative Language; Discourse Analysis; Faculty Development; Educational Policy; Interdisciplinary Approach; Technology Uses in Education; Standards; Social Theories,English,Journal Articles; Reports - Research
EJ1461336,Unveiling the Potential: Artificial Intelligence's Negative Impact on Teaching and Research Considering Ethics in Higher Education,Muhammad Amin Nadim; Raffaele Di Fuccio,1292,"Higher education has witnessed remarkable technological advancements; however, the rapid rise of generative artificial intelligence (Gen AI) presents substantial challenges for teaching and research. This growing reliance has expanded educators' roles, underscoring the need for ethical and selective AI integration while preparing students and researchers for an AI-driven future. Adopting an argumentative perspective, this article analyzes core insights from comparative literature and key reports that highlight Gen AI's potential to diminish critical thinking and negatively impact educational outcomes. Although Gen AI holds transformative promise, its swift expansion raises significant concerns about its long-term implications for education. This research emphasises the need to address Gen AI's drawbacks, advocating for greater awareness and equitable educational practices that support both teaching and learning in academic contexts. Ultimately, the article calls for professional development to equip educators with responsible AI skills, fostering a balanced and ethical approach to Gen AI integration in higher education.",European Journal of Education,v60 n1 e12929 2025,10.1111/ejed.12929,http://eric.ed.gov/?id=EJ1461336,Artificial Intelligence; Teaching Methods; Learning Processes; Ethics; Technology Integration; Computer Software; Faculty Development; Teacher Role; Futures (of Society); Critical Thinking; Comparative Analysis; Outcomes of Education; Research,English,Journal Articles; Reports - Evaluative; Opinion Papers
EJ1486839,Exploring Risks and Benefits in Generative Artificial Intelligence through Systematic Review and Bibliometric Analysis,Ingrid del Valle García-Carreño,2025,"The rapid development of Generative Artificial Intelligence in education presents new opportunities but also raises concerns about inequality and the integrity of academic practices. This study explores its impact, trends, and risks in education through an extensive review of existing academic literature. The methodology includes a systematic review conducted via the Scopus platform, incorporating documentary analysis with descriptive statistics, systematic content analysis, and bibliometric analysis of citations, co-citations, and co-words in scientific research on the topic. Network maps were created using VOSviewer, and graphs were produced with Microsoft Excel. Moreover, qualitative content analysis was further deepened using ATLAS.ti, .24. The major findings indicate that generative artificial intelligence, as a set of information-processing tools, has significantly advanced over the past century, especially notable for its ability to process information quickly and adapt to human objectives. Its rapid adaptation is transforming education, particularly by enhancing personalization, improving knowledge retention, and supporting interactive learning environments. However, the use of GenAI also raises ethical and equity concerns, including risks to academic integrity, data privacy, and potential algorithmic bias, alongside challenges in ensuring equitable access and adequate teacher training. The main focus of current applications lies in commercial, collaborative, and natural language strategies, which surpass other uses such as images and videos. GenAI aligns with pedagogical theories that promote student autonomy, active learning, and collaboration, if implemented with clear educational intent. However, since machines lack human social perception, it is necessary to reflect critically on the ethical boundaries and appropriate use of AI in the linguistic and educational domains. Gen AI offers transformative potential for education by enabling personalized and efficient learning; however, addressing associated risks, ethical challenges, and issues of equity is essential to ensure its benefits are realized without compromising academic integrity or exacerbating inequalities.",European Educational Researcher,v8 n3 p57-94 2025,,http://eric.ed.gov/?id=EJ1486839,Artificial Intelligence; Technology Uses in Education; Technology Integration; Educational Technology; Risk; Educational Benefits; Bibliometrics; Information Processing; Educational Change; Individualized Instruction; Retention (Psychology); Interaction; Ethics; Integrity; Privacy; Algorithms; Bias; Natural Language Processing; Efficiency,English,Journal Articles; Reports - Research; Information Analyses
EJ1465604,A Bibliometric Analysis of Artificial Intelligence for Multimedia in Education by Dimensions AI,Potsirin Limpinan; Ampawan Yindeemak; Rungfa Pasmala; Manop Nammanee; Thada Jantakoon,2025,"This study presents a comprehensive bibliometric analysis of Artificial Intelligence (AI) research for Multimedia in Education from 2020 to 2024. Using the Dimensions AI database, VOSviewer software and Scimago Graphica, we examined 45 publications to identify key trends, influential contributors, and emerging directions in this rapidly evolving field. The analysis reveals a significant publication surge from 2020 to 2021, followed by stabilization in subsequent years. China is the dominant contributor, with 19 publications and 214 citations, highlighting its leadership in AI and educational technology research. Co-authorship network analysis shows a tightly interconnected research community lacking distinct clusters. The most cited papers focus on student engagement and specific AI applications in education, indicating the field's emphasis on practical implementations. Keyword analysis reveals a consistent focus on core concepts such as artificial intelligence, education, technology, and learning, with a recent shift towards more user-centered research. The study also identifies challenges in implementing AI for multimedia in education, including data privacy concerns, ethical considerations, and the need for educator training. These findings provide valuable insights for researchers, educators, and policymakers, highlighting the need to balance technological advancements with pedagogical needs and ethical considerations. Future research directions include investigating the long-term impact of AI-enhanced multimedia education, developing ethical frameworks, conducting cross-cultural studies, and enhancing AI's capability to provide personalized learning experiences through multimedia content.",Higher Education Studies,v15 n2 p1-22 2025,,http://eric.ed.gov/?id=EJ1465604,Bibliometrics; Artificial Intelligence; Authors; Network Analysis; Citation Analysis; Learner Engagement; Technology Uses in Education; Databases; Educational Technology; Information Retrieval; Multimedia Instruction; Privacy; Ethics; Educational Needs; Computer Software; Individualized Instruction,English,Journal Articles; Information Analyses
EJ1488914,"AI and Higher Education: Understanding Faculty Roles in Teaching, Research, and Administration",Filomachi Spathopoulou; Konstantinos M. Pitychoutis; Stavros Papakonstantinidis,2025,"The rapid advancement of artificial intelligence (AI) is transforming higher education, impacting pedagogical practices, administrative processes, and faculty engagement with technology. While AI holds promise to enhance learning and streamlining operations, its adoption remains complex and debated. This study examines faculty perceptions of AI integration, focusing on factors such as teaching experience, institutional context, and disciplinary specialization. Using a quantitative survey, the research explores AI engagement across institutions and disciplines, analyzing how demographic factors influence adoption. Findings suggest that junior faculty and those in technology-driven environments demonstrate higher AI confidence and adoption, whereas senior faculty engage in AI leadership yet express skepticism about its pedagogical applications. Disciplinary differences reveal that faculty in content-based fields view AI as a teaching tool, while those in applied disciplines utilize it more strategically for administrative and leadership functions. The study also addresses ethical and institutional challenges, including concerns over data privacy, algorithmic bias, and institutional readiness. By identifying these barriers, the research highlights strategies for fostering AI literacy, professional development, and ethical implementation in higher education. This study contributes to the discourse on AI in academia by presenting an educator-centered perspective, bridging the gap between technological advancement and pedagogical practice. The findings provide academic leaders and policymakers with insights on creating AI-inclusive environments that align with faculty needs, uphold ethical standards, and enhance student learning outcomes.",Contemporary Educational Technology,v17 n4 Article ep600 2025,,http://eric.ed.gov/?id=EJ1488914,Artificial Intelligence; Higher Education; Computer Uses in Education; College Faculty; Teacher Role; Teacher Attitudes; Teacher Characteristics; Intellectual Disciplines; Teaching Experience; Differences; Ethics; Institutional Characteristics; Barriers; Foreign Countries,English,Journal Articles; Reports - Research
EJ1462325,Integration and Application of Artificial Intelligence Tools in the Moodle Platform: A Theoretical Exploration,Devkan Kaleci,2025,"The integration of artificial intelligence (AI) technologies into Learning Management Systems (LMS) represents a transformative advancement in contemporary education, enhancing personalization, efficiency, and interactivity. This study presents a systematic methodology for integrating AI technologies into the Moodle LMS. Moodle 4.5 was selected as the LMS owing to its modular architecture, flexibility, scalability, and integrated AI tools. This paper delineates the technical and pedagogical steps necessary for a successful integration process, including the installation of plug-ins, integration of APIs, customization of the system, and configuration of the AI menu. Moodle 4.5 simplifies the deployment and utilization of AI functionalities, offering an intuitive framework for creating dynamic and adaptive learning environments. AI integration improves student engagement, enables personalized learning pathways, and facilitates data-driven instructional decisions. However, challenges such as data privacy concerns, algorithmic biases, and infrastructural demands require ethical frameworks, interdisciplinary collaboration, and educator training to ensure responsible implementation. This study concludes that AI integration into platforms like Moodle can redefine educational paradigms, fostering inclusive and future-ready learning environments. Recommendations include investments in robust infrastructure and the adoption of ethical strategies to maximize AI's transformative impact while upholding pedagogical integrity and equity.",Journal of Educational Technology and Online Learning,v8 n1 p100-111 2025,,http://eric.ed.gov/?id=EJ1462325,Artificial Intelligence; Learning Management Systems; Educational Technology; Technology Integration; Barriers; Ethics,English,Journal Articles; Reports - Research
EJ1480942,University Teachers' Perspectives on Using Artificial Intelligence in Teaching and Its Related Aspects,Sirkku Lähdesmäki; Sanna Väisänen; Heidi Hyytinen,2025,"This study explores interconnections between university teachers' self-efficacy beliefs, intrinsic motivation, behavioural commitment, and teachers' views on the ethics of AI and the possibilities of using AI in teaching. Furthermore, the aim is to investigate how teachers' teaching experience and their participation in AI training relate to these aspects. The data consist of teachers' (n=92) survey responses and open-ended answers. Data analyses included both quantitative and qualitative methods. The quantitative data were analysed with correlations, t-test, and ANOVA, while content analysis was used to analyse the qualitative data. The results indicated that teachers emphasized the importance of ethical perspectives on AI. A positive connection was found between university teachers' self-efficacy for using AI in teaching, intrinsic motivation, and behavioural commitment. Teachers with AI training reported higher self-efficacy for using AI in teaching, and they had significantly higher levels of intrinsic motivation and behavioural commitment than teachers without AI training. Moreover, they highlighted more possibilities for using AI in planning their teaching and supporting student learning than teachers without AI training. This study enhances understanding of how university teachers' self-efficacy, intrinsic motivation, and behavioural commitment to using AI in teaching are interrelated, highlighting the potential moderating role of AI training participation.",International Journal on Social and Education Sciences,v7 n3 p272-291 2025,,http://eric.ed.gov/?id=EJ1480942,College Faculty; Teacher Attitudes; Artificial Intelligence; Technology Uses in Education; Self Efficacy; Teacher Motivation; Ethics; Teaching Experience; Faculty Development; Correlation; Teacher Behavior; Teacher Persistence; Foreign Countries; Safety; Affordances,English,Journal Articles; Reports - Research
ED673240,Trust and Inclusion in AI-Mediated Education: Where Human Learning Meets Learning Machines. Postdigital Science and Education,"Dora Kourkoulou, Editor; Anastasia-Olga Tzirides, Editor; Bill Cope, Editor; Mary Kalantzis, Editor",2024,"""Trust and Inclusion in AI-Mediated Education: Where Human Learning Meets Learning Machines"" is a resource for researchers and practitioners in a field where the mainstreaming of AI technologies, and their increased capacities for deception, have produced confusion and fear. Identifying theoretical frameworks and practices in teaching with and training trustworthy and inclusive AI technology sheds light on the new challenges and opportunities for learning machines and their intersections with human learning. The book looks into the history of developing AI technology and algorithms. It offers theoretical models for best practices, interpretation, and evaluation, taking into account especially the needs of contemporary learners and their advanced literacies in cyber-social environments. The book presents in-depth analyses of recent and ongoing applications of state-of-the-art AI technologies in learning environments and classrooms assessments, ending with an interview with George Ritzer on McDonaldization and Artificial Intelligence.",Springer,,,http://eric.ed.gov/?id=ED673240,Trust (Psychology); Inclusion; Artificial Intelligence; Technology Uses in Education; Best Practices; Ethics; Accountability; Data Science; Computer Simulation; Student Diversity; Self Management; Metacognition; Graduate Students; Student Attitudes; Writing (Composition); English (Second Language); Second Language Instruction; Technological Literacy; Communication Skills; College Students,English,Books; Collected Works - General
EJ1461882,Experimental Perspective on Artificial Intelligence Anxiety,Ridvan Kagan Agca; Özgen Korkmaz,2025,"The aim of this study was to determine the effect of training on the integration of artificial intelligence into education given to pre-service teachers on their concerns about artificial intelligence and their views on the integration of artificial intelligence into education. In this study, sequential explanatory design, one of the mixed research designs, was preferred. In the quantitative part of the research, single group quasi-experimental research design was used. In the qualitative part of the study, a basic qualitative research design was used. In the experimental process, a four-week artificial intelligence training program was administered to pre-service teachers for three hours a week. The study group consisted of 195 preservice teachers. Data were collected using the artificial intelligence anxiety scale and a semi-structured interview form. The data obtained were analyzed using t, MANCOVA, and content analysis methods, and the following results were obtained: The training on the integration of artificial intelligence into education decreased pre-service teachers' anxiety in the learning dimension but increased their anxiety in other dimensions. The main sources of anxiety are inequality, ethics, privacy, and reliability, professional and social anxiety, unpredictable decisions and loss of control, technology use and adaptation difficulties, artificial intelligence addiction, and decreased creativity.",International Journal of Technology in Education,v8 n1 p22-44 2025,,http://eric.ed.gov/?id=EJ1461882,Artificial Intelligence; Anxiety; Influence of Technology; Technology Uses in Education; Preservice Teachers; Student Attitudes; Training; Technology Integration; Ethics; Privacy; Reliability; Equal Education; Schools of Education; Information Technology; Courses; Foreign Countries,English,Journal Articles; Reports - Research
ED673708,Generating Curricula: A Human-Centred Perspective in the Era of Artificial Intelligence,Tiia Rüütmann; Urve Läänemets,2025,"This study explores generative mechanisms of curriculum design from a human-centred perspective, with a focus on the integration of Artificial Intelligence (AI) into engineering education. As curricula evolve to meet the demands of a technologically advanced and globally connected society, it is crucial to preserve the educational values rooted in human agency, cultural context, and pedagogical reasoning. The research aimed to investigate how traditional curriculum development processes can be enhanced through AI tools while preserving the essential role of human educators. A mixed-method approach was used, combining quantitative Likert-scale surveys and qualitative open-ended responses from 43 participants involved in curriculum development and implementation across higher and vocational education and industry. The results show that AI is perceived as highly effective in automating administrative tasks and personalizing learning, but concerns remain about ethical issues, data privacy, and potential marginalization of human educators. Most respondents emphasized that AI should serve as a supportive tool rather than a replacement. The findings underscore the importance of hybrid curriculum models that integrate AI for operational efficiency while maintaining human agency in decision-making, pedagogy, and ethical oversight. The study offers practical implications for future curriculum reforms and teacher training in an AI-enhanced educational landscape. [For the complete proceedings, see ED673688.]",International Baltic Symposium on Science and Technology Education,"Paper presented at the International Baltic Symposium on Science and Technology Education (BalticSTE2025) (6th, Šiauliai, Lithuania, Jun 16-19, 2025)",,http://eric.ed.gov/?id=ED673708,Curriculum Development; Artificial Intelligence; Computer Software; Technology Integration; Teacher Role; Teaching Methods; Likert Scales; Teacher Attitudes; Curriculum Implementation; Ethics; Privacy; Decision Making; Higher Education; Career and Technical Education; Administrator Attitudes,,Speeches/Meeting Papers; Reports - Research
EJ1490355,Considerations for the Use of Generative Artificial Intelligence in the Counseling Profession,Aaron L. Norton,2025,"Background: Artificial intelligence (AI) and generative artificial intelligence (GenAI) technology have rapidly evolved in recent years, posing substantial implications for counselors, counselor educators, supervisors, and researchers. However, research on AI and counseling is in its infancy, and while some counseling organizations have recently published AI-related standards, none have been published within some counseling specializations, such as rehabilitation counseling. Objectives: This article aims to (a) introduce counselors to AI and GenAI, (b) review the benefits and risks of AI and GenAI for counseling practice, education, and research, (c) summarize emerging AI-related standards from national counseling organizations, and (d) present AI-related recommendations for rehabilitation counseling professionals. Methods: A literature review was conducted, synthesizing peer-reviewed articles, ethical codes, and emerging guidelines from national counseling organizations. Examples of AI and GenAI applications in counseling, counselor education, supervision, documentation, psychoeducation, and therapy support were integrated. A GenAI model (ChatGPT-4) was used to codevelop AI-related recommendations for rehabilitation counselors. Findings: Potentially beneficial uses of AI in counseling include proofreading of documentation; enhanced learning and research; improved case management and case documentation; graphic design for educational materials; strategic referral finding; enhanced data analysis; psychoeducation; and therapeutic chatbots and therapy homework. Challenges and harms include biased and inaccurate information; over-reliance on AI; security, privacy, and confidentiality concerns; harmful relationships with AI; and environmental impact. Conclusions: AI and GenAI offer both promise and peril for counseling. Ethical use requires professional competency, transparency, critical evaluation of AI outputs, and safeguards for client welfare. Twelve recommendations are offered to guide rehabilitation counseling professionals in maximizing benefits while minimizing harm.","Rehabilitation Research, Policy, and Education",v39 n3 p120-138 2025,10.1891/RE-25-24,http://eric.ed.gov/?id=EJ1490355,Artificial Intelligence; Computer Use; Counseling; Rehabilitation Counseling; Counselor Training; Supervision; Innovation; Therapy; Bias; Accuracy; Caseworker Approach; Confidentiality; Ethics,English,Journal Articles; Reports - Research
EJ1464647,Investigation of Science Teachers' Anxiety about Artificial Intelligence: A Phenomenological Study,Vildan Yalçin; Hasan Gökçe; Oguzhan Nacaroglu,2024,"This study aims to examine science teachers' views and concerns about artificial intelligence (AI). Phenomenology design, one of the qualitative research method designs, was used in the study. The study group consisted of five science teachers, one doctoral and four master's degree graduates. Semi-structured interview was preferred as a data collection tool. Inductive content analysis was used to analyze the data. Participants defined AI as robots with humanoid behavior and alternative learning tools. Teachers stated that AI increased academic achievement, motivation and class participation rate. It was found that the participants' concerns about AI stemmed from lack of experience and knowledge, security issues and reliability of information. It was also concluded that the participants were concerned about workload, asocialization, decrease in skills, and privacy of personal data. The participants stated that they had problems in terms of being technologically inadequate, not being able to adapt to AI and lack of knowledge, inadequate AI outputs, and difficulties in applied trainings. It is recommended that science teachers should be given practical trainings to reduce their concerns about AI.",Research in Pedagogy,v14 n2 p349-360 2024,,http://eric.ed.gov/?id=EJ1464647,Science Teachers; Teacher Attitudes; Anxiety; Artificial Intelligence; Computer Software; Technological Literacy; Pedagogical Content Knowledge; Academic Achievement; Phenomenology; Learning Motivation; Technology Uses in Education; Socialization; Faculty Workload; Privacy; Information Security; Reliability; Information Sources; Ethics; Confidentiality,English,Journal Articles; Reports - Research
EJ1492207,Mindset Matters: Fostering Teachers' Responsible AI Use through Professional Development,Luna Huynh; Tam. H. Le; Belle Dang; Bien Thuy An; Cam Tu Vu; Andy Nguyen,2025,"Generative AI holds transformative potential for education but also introduces ethical and pedagogical complexities, thereby necessitating comprehensive teacher preparation. To investigate whether mindset-oriented professional development (PD), beyond tool-focused training alone, enhances teachers' responsible AI use, we conducted a mixed-method study comparing two PD approaches with 57 preservice teachers. Participants were randomly assigned to either a tools-only training group or a combined tools-and-mindset training group, including modules on AI ethics, human-centered education, and pedagogical reflection. Results revealed that both groups experienced decreased AI anxiety; yet only the tools-only group reported statistically significant gains in self-efficacy across multiple AI competence domains. Conversely, the mindset group exhibited a targeted increase in human-centered AI competence, reflecting deeper ethical awareness and critical reflection. Qualitative analysis confirmed that mindset-trained teachers articulated more subtle concerns about AI's risks and pedagogical implications, adopting a more cautious stance and expressing a desire for further ethics-focused training. This study provides empirical evidence that embedding mindset components into AI-focused PD fosters essential reflective capacities and ethical judgment. Effective teacher PD should thus integrate technical proficiency with ethics, human-centered design, and critical pedagogy, cultivating educators capable of responsibly integrating AI in classrooms.",Journal of New Approaches in Educational Research,v14 Article 23 2025,10.1007/s44322-025-00043-y,http://eric.ed.gov/?id=EJ1492207,Artificial Intelligence; Technology Uses in Education; Faculty Development; Preservice Teachers; Training; Student Development; Anxiety; Program Effectiveness; Self Efficacy; Technological Literacy; Ethics; Reflection; Risk; Beliefs; Workshops; Preservice Teacher Education; Foreign Countries,English,Journal Articles; Reports - Research; Tests/Questionnaires
EJ1447920,Preliminary Study on Pre-Service Teachers' Applications and Perceptions of Generative Artificial Intelligence for Lesson Planning,Hsiao-Ping Hsu; Janice Mak; Jennifer Werner; Janel White-Taylor; Melissa Geiselhofer; Alan Gorman; Carolina Torrejon Capurro,2024,"As part of an international collaborative design-based research initiative, this study examines the applications and perceptions of generative artificial intelligence (Gen AI) among pre-service primary teachers within an Irish educational program. It focuses on how personal and academic uses of Gen AI influence their perceptions of using Gen AI for lesson planning. The findings highlight that while Gen AI is preliminarily used by pre-service primary teachers for personal and academic purposes, its integration into lesson planning is less frequent. Crucially, the study reveals no significant correlations between personal use of Gen AI and perceptions related to its educational opportunities. Conversely, academic use of Gen AI shows a positive correlation with recognising its potential opportunities for lesson planning and the desire for professional development, but it also shows a negative correlation with the perception of challenges and ethical concerns. The research underscores substantial concerns about over-reliance on Gen AI, potential skill diminishment, educational equity, and data privacy. These findings emphasise the urgent need for targeted professional development programmes to prepare future teachers to use Gen AI tools effectively and ethically, highlighting a gap in current teacher education that must be addressed to harness the full potential of Gen AI in education.",Journal of Technology and Teacher Education,v32 n3 p409-437 2024,,http://eric.ed.gov/?id=EJ1447920,Lesson Plans; Student Attitudes; Artificial Intelligence; Teacher Education Programs; Preservice Teachers; Technology Uses in Education; Elementary School Teachers; Equal Education; Privacy; Ethics; Foreign Countries,English,Journal Articles; Reports - Research
ED660361,"A Single District, Multisite Case Study about the Lived Experiences and Best Practices of Faculty in Incorporating Artificial Intelligence",Cameron Redden,2024,"Artificial intelligence (AI) has demonstrated effectiveness in various educational contexts, offering adaptive evaluation mechanisms, personalized learning experiences, and increased learner engagement (Holstein et al., 2019; Woolf, 2019). This study examined the experiences of community college faculty incorporating AI technologies in teaching practices, how faculty engaged first-generation adult learners when incorporating AI technologies, and how AI technologies were addressed in college documents and policies. Given the context of this research, the chosen methodology for this study was a qualitative case study design comprised of interviews with faculty from a single-district multicampus site in the United States. The interviews were semi-structured to allow the researcher to gather information on the experiences of faculty incorporating AI technologies into their teaching practices. The semi-structured interview method provided a fitting structure to explore the rich, complex, and detailed description of the experiences of community college faculty incorporating AI technologies in teaching practices. The researcher examined institutional archival documents to supplement semi-structured interviews and increase the credibility and reliability of the analyses. The researcher determined how AI technologies were addressed in institutional documents and policies using Huber's (1993) organizational change theory as the theoretical framework and Rogers' (1995) diffusion of innovation as the conceptual framework. Faculty concluded that AI could improve the quality of teaching practices by addressing uncertainties, bridging the digital divide, and promoting technology acceptance. Participants acknowledged that AI can foster creativity, facilitate experimental learning, support professional development, and enhance training to improve learner outcomes in the classroom. However,&#xa0;some faculty expressed concerns about integrating AI into teaching. Participants cited the potential long-term impact of learner critical thinking. They acknowledged that generative AI technology is limited and can create misleading or skewed information due to bias and hallucinations affecting student learning. Furthermore, faculty acknowledged the existence of the digital divide and its impact on first-generation learners. The participants agreed that first-generation learners could use AI technologies at the same levels as non-first-generation learners. However, some faculty noticed that first-generation learners associated guilt with AI usage or became hesitant to use the technology when the information generated was incorrect. Further research and ongoing support is necessary to continue advancing the integration of AI tools into educational practices. The findings of this study inform community college faculty about the multifaceted nature of integrating AI technologies into teaching practices. Community colleges interested in implementing or expanding faculty's use of AI in teaching practices could create a task force to develop policies and best practices and review and monitor academic integrity, ethical use, data privacy, and bias. Additionally, the institution can allocate resources for faculty professional development and training and launch pilot programs to learn how to use AI technologies in select areas. [The dissertation citations contained here are published with the permission of ProQuest LLC. Further reproduction is prohibited without permission. Copies of dissertations may be obtained by Telephone (800) 1-800-521-0600. Web page: http://www.proquest.com/en-US/products/dissertations/individuals.shtml.]",ProQuest LLC,"Ed.D. Dissertation, Kansas State University",,http://eric.ed.gov/?id=ED660361,Best Practices; Artificial Intelligence; Technology Integration; Case Studies; Teaching Experience; Community Colleges; Teaching Methods; First Generation College Students; Adult Students; Educational Policy; Documentation; Information Technology; Creativity; Experiential Learning; Professional Development; Outcomes of Education; Personal Autonomy; Cultural Capital; Adjustment (to Environment); Assistive Technology; Individualized Instruction,,Dissertations/Theses - Doctoral Dissertations
EJ1481343,Exploring Shared Repertoire in Virtual Communities of Practice: Integration of Artificial Intelligence in English Language Teaching,Flora Debora Floris,1024,"This study explores how English language teachers use shared repertoire in virtual communities of practice (VCoPs) when integrating artificial intelligence (AI) tools into teaching. Using a qualitative analysis of discussions from three open Facebook groups, this study identifies how teachers actively collaborate online to share practical strategies and resources related to AI. The findings indicate that shared repertoire in these groups serves four main purposes: supporting teaching activities, assessing students, sharing relevant resources, and suggesting improvements to AI tools. Teachers also discuss common challenges, including excessive reliance on AI, privacy issues, limited access to AI resources, and the risk of reduced teacher-student interactions. The study highlights that teachers' collective experiences within these online communities can help institutions develop more relevant training programs for teachers. Overall, this research confirms that while AI can support language education, its successful integration relies on teachers sharing experiences and guiding each other on how to best use this technology to enhance their teaching.",JALT CALL Journal,v21 n2 Article 102420 2025,,http://eric.ed.gov/?id=EJ1481343,Communities of Practice; English (Second Language); Second Language Learning; Second Language Instruction; Artificial Intelligence; Teaching Methods; Technology Integration; Computer Software; Barriers; Language Teachers; Social Media; Teacher Collaboration; Computer Mediated Communication; Privacy; Teacher Student Relationship,English,Journal Articles; Reports - Research
EJ1492452,From Words to Pixels: Artificial Intelligence Struggles with World Englishes,Flora Debora Floris,1030,"This study examines how DALL-E 3 interprets English descriptions written by Indonesian university students. Sixteen descriptive texts were submitted to the artificial intelligence (AI) tool, and the resulting images were compared to original photos. Most outputs showed clear mismatches. The analysis found that misinterpretations originated from two main sources: grammatical and vocabulary patterns reflecting Indonesian English and broader stylistic choices, such as the use of vague, emotional, or abstract language. The study also found that a high level of concrete detail could often mitigate the negative effects of non-standard grammar. The findings suggest that current AI tools are not yet equipped to fairly process the full range of human linguistic variation, from local English features to the stylistic patterns of human-centric writing. To support more inclusive use of AI in education, this study adapts the established concept of intelligibility into the idea of ""digital intelligibility,"" and recommends improving training data and creating classroom space for open discussions about AI bias toward language diversity and stylistic choices.",JALT CALL Journal,v21 n3 Article 103083 2025,,http://eric.ed.gov/?id=EJ1492452,Foreign Countries; College Students; Artificial Intelligence; English; Language Variation; Grammar; Intelligibility; Bias; Vocabulary; Pronunciation; Identification,English,Journal Articles; Reports - Research
EJ1479918,A Competency Framework for AI Literacy: Variations by Different Learner Groups and an Implied Learning Pathway,Hyunkyung Chee; Solmoe Ahn; Jihyun Lee,2025,"This study aims to develop a comprehensive competency framework for artificial intelligence (AI) literacy, delineating essential competencies and sub-competencies. This framework and its potential variations, tailored to different learner groups (by educational level and discipline), can serve as a crucial reference for designing and implementing AI curricula. However, the research on AI literacy by target learners is still in its infancy, and the findings of several existing studies provide inconsistent guidelines for educational practices. Following the 2020 PRISMA guidelines, we searched the Web of Science, Scopus, and ScienceDirect databases to identify relevant studies published between January 2012 and October 2024. The quality of the included studies was evaluated using QualSyst. A total of 29 studies were identified, and their research findings were synthesized. Results show that at the K-12 level, the required competencies include basic AI knowledge, device usage, and AI ethics. For higher education, the focus shifts to understanding data and algorithms, problem-solving, and career-related competencies. For general workforce, emphasis is placed on the interpretation and utilization of data and AI tools for specific careers, along with error detection and AI-based decision-making. This study connects the progression of specific learning objectives, which should be intensively addressed at each stage, to propose an AI literacy education pathway. We discuss the findings, potentials, and limitations of the derived competency framework for AI literacy, including its theoretical and practical implications and future research suggestions.",British Journal of Educational Technology,v56 n5 p2146-2182 2025,10.1111/bjet.13556,http://eric.ed.gov/?id=EJ1479918,Competence; Digital Literacy; Artificial Intelligence; Technology Uses in Education; Learning Processes; College Students; Algorithms; Problem Solving; Learning Objectives,English,Journal Articles; Information Analyses; Reports - Research
EJ1486933,Using Exam Preparation and Reflection to Introduce Artificial Intelligence Tools in Honors General Chemistry,Morgan A. Vincent; Benjamin J. Lear,2025,"We report an intervention, performed during the Fall of 2024, in which a large language model artificial intelligence chatbot was introduced as a tool for pre-exam study and postexam reflection within an honors general chemistry course (CHEM 110H) at Penn State University. Through a combination of a structured 75 min instructional session and scaffolded pre- and postexam AI-based assignments, students engaged with AI tools such as ChatGPT, Microsoft Copilot, and Google Gemini intended to support content review and metacognitive development. Pre- and postcourse surveys revealed significant increases in students' frequency of AI use, academic confidence in using AI, and perceived utility of AI, alongside reductions in anxiety regarding ethics of its use in academics. Survey data also showed a shift toward more positive and cohesive student perceptions of AI, suggesting that reflective, ethically framed AI integration can promote autonomous, meaningful engagement with new technologies without compromising academic performance. These findings highlight the value of intentional AI training in STEM education and underscore the need for continued study across diverse educational contexts.",Journal of Chemical Education,v102 n10 p4470-4478 2025,10.1021/acs.jchemed.5c00618,http://eric.ed.gov/?id=EJ1486933,Artificial Intelligence; Technology Uses in Education; College Science; Honors Curriculum; Chemistry; Science Education; Self Efficacy; Value Judgment; Anxiety; Student Attitudes; College Students; Program Effectiveness; Ethics; Test Preparation,English,Journal Articles; Reports - Research
EJ1429748,The Readiness to Use AI in Teaching Science: Science Teachers' Perspective,Sameera Alshorman,2024,"This study aimed to assess the readiness of Jordanian science teachers for integrating Artificial Intelligence (AI) in science education, focusing on their perceptions, challenges, and training needs. A quantitative survey methodology was employed, using a 35-item questionnaire distributed to 136 science teachers in urban Jordan. The questionnaire, developed and refined through expert peer review and a pilot study, encompassed demographics, attitudes towards AI, perceived benefits and challenges of AI in science teaching, self-efficacy in using AI, and behavioural intentions regarding its use. The results indicated varying teacher readiness levels, influenced by gender, educational background, and concerns over data privacy and security. While there was a general sense of optimism about the potential of AI, significant challenges related to limited resource access and insufficient professional development were identified. These results emphasized the need for targeted policy initiatives and training programs to enhance teachers' readiness for AI adoption. The study's insights contributed to understanding the facilitators and barriers to AI integration in science education, highlighting the critical role of teacher readiness in the effective utilization of AI in educational contexts.",Journal of Baltic Science Education,v23 n3 p432-448 2024,,http://eric.ed.gov/?id=EJ1429748,Readiness; Intention; Science Instruction; Teaching Methods; Technology Uses in Education; Artificial Intelligence; Educational Benefits; Science Teachers; Teacher Attitudes; Privacy; Information Security; Technology Integration; Barriers; Foreign Countries; Gender Differences; Self Efficacy; Faculty Development,English,Journal Articles; Reports - Research
ED659057,Enhancing Undergraduate Learning and Bridging the Academic-Business Divide: A Mixed-Method Study on the Role of Artificial Intelligence in Education,Larry Wayne Evert Jr.,2024,"The purpose of this mixed-method survey-based study addresses the underexplored area of undergraduate student perceptions of artificial intelligences (AI) impact in academia, specifically within the FCSEI in Romania. This research study will provide comprehensive findings on how AI can revolutionize teaching methodologies, learning processes, and evaluations to better prepare students with the skills needed for success in a technologically driven business landscape. The data-driven findings have the potential to enable strategic planning for incorporating AI into academic frameworks, ensuring alignment with corporate workforce demands and enhancing student preparedness for the challenges of the modern business landscape. The research utilized online surveys from 91 FCSEI undergraduate students and employed quantitative and qualitative data analysis methodologies. The study employs a mixed-methods approach, utilizing both quantitative and qualitative data. Constructivism and connectivism serve as the theoretical framework, guiding the exploration of AI's impact on teaching, learning, and evaluation practices. The research questions focus on the perceptions of students, faculty, and administrators regarding AI integration, the challenges and opportunities associated with AI adoption, and the strategies for aligning AI-enhanced education with workforce demands. The data collection method will include online surveys, interviews, and focus groups involving undergraduate business students, faculty members, and administrators at FCSEI. By addressing the challenges and leveraging the opportunities associated with AI integration, this study seeks to bridge the gap between academia and industry, ensuring that undergraduate business education remains relevant and responsive to the workforce's evolving demands in the AI era. The study reveals undergraduate students perceive AI integration in education positively, with students possessing higher AI knowledge recognizing more significant benefits of AI technology, underscoring the need for increased AI literacy to enhance student engagement and educational outcomes. Gender, academic major, and GPA did not significantly influence perceptions, suggesting widespread acceptance across diverse demographics. Future research should include longitudinal studies to track changes in AI perceptions over time, providing deeper insights into AI's long-term effects on education. Expanding the research to diverse populations from various institutions and cultural backgrounds will improve the generalizability of findings. Examining the effectiveness of specific AI tools and applications while addressing ethical implications like data privacy and algorithmic bias could help develop responsible and equitable AI integration strategies. Understanding faculty and administrative perspectives on AI could support comprehensive policy development and practical implementation in higher education. [The dissertation citations contained here are published with the permission of ProQuest LLC. Further reproduction is prohibited without permission. Copies of dissertations may be obtained by Telephone (800) 1-800-521-0600. Web page: http://www.proquest.com/en-US/products/dissertations/individuals.shtml.]",ProQuest LLC,"D.B.A. Dissertation, South College",,http://eric.ed.gov/?id=ED659057,Undergraduate Students; Artificial Intelligence; Technology Uses in Education; Student Surveys; Constructivism (Learning); Educational Theories; Teaching Methods; Learning Processes; Strategic Planning; Technology Integration; Computer Software; Educational Change; Business Administration Education; Education Work Relationship; Corporations; Foreign Countries,,Dissertations/Theses - Doctoral Dissertations
EJ1459826,"""AI Is Not Just a Robot; It's More than a Robot."": Understanding Children's AI Competencies in an AI Literacy Workshop",Tolulope Famaye; Oluwadara Abimbade; Oluwajoba Adisa,2025,"As Artificial Intelligence (AI) becomes integrated into daily life, children encounter it without understanding its mechanisms or ethics. This study examines a five-day online AI literacy workshop for children aged 7-11, focused on foundational knowledge, hands-on engagement, and critical thinking. Using a socio-constructivist framework, the workshop employed open-access resources and guided activities to introduce AI concepts, model training, and creative applications. Data from interviews, videos, and artifacts revealed themes: understanding AI, creating models, designing with AI, and reflecting on learning. Participants gained awareness of AI's functionality, societal impact, and creative potential, highlighting the value of interactive, collaborative activities in building confidence and democratizing AI education for young learners.",Journal of Interactive Learning Research,v36 n1 p71-82 2025,,http://eric.ed.gov/?id=EJ1459826,Artificial Intelligence; Technological Literacy; Children; Workshops; Electronic Learning; Knowledge Level; Experiential Learning; Critical Thinking; Open Educational Resources; Childrens Attitudes; Rural Schools,English,Journal Articles; Reports - Research
EJ1483972,"Algorithmic Foucault: Digital Feminism, the Panopticon, & the Role of AI in Shaping Musical Identities & Pedagogies",Mila Zhu,2025,"This study investigates the role of generative artificial intelligence (AI) in music education, focusing on its dual function as a creative tool and a mechanism of algorithmic surveillance. Utilizing AI platforms such as Suno.AI, MusicFX, and Udio, the study examines AI's potential to foster creativity, enable synesthetic learning, and personalize music education while also raising ethical concerns about algorithmic bias, content moderation, and data-driven surveillance. Grounded in Michel Foucault's Panopticon and digital feminism, this research explores how AI tools reproduce gendered biases, shaping students' engagement with feminist discourse through censorship and content filtering. Findings suggest that while AI can enhance educational experiences, it also encourages self-censorship, moderates feminist texts disproportionately, and perpetuates digital gatekeeping. This paper calls for greater transparency in AI governance, algorithmic accountability, and feminist interventions in AI training datasets to ensure AI serves as an equitable and ethical tool in education. Future research should explore strategies for AI literacy in education, equipping students to critically engage with and resist algorithmic bias in digital learning environments.",Thresholds in Education,v48 n2 p240-262 2025,,http://eric.ed.gov/?id=EJ1483972,Music Education; Artificial Intelligence; Technology Uses in Education; Creativity; Ethics; Algorithms; Feminism; Gender Bias; Barriers; Technology Integration,English,Journal Articles; Reports - Research
ED652351,AI Ethics: An Empirical Study on the Views on Middle School Student,Elif Ece Er; Muhammet Demirbilek,2023,"In today's technology, there are rapid advances in the field of artificial intelligence. With the increasing involvement of artificial intelligence in daily activities, great changes are taking place in our habits. At this point, the necessity of educating students in accordance with the age of artificial intelligence emerges. Students' acquaintance with current technologies requires that the education provided is up to date. From these developments artificial intelligence, and its effects on society should be conveyed to students. The aim of the study is to implement the curriculum developed for middle school students to learn about the ethical dimension of artificial intelligence and to reveal students' views on the subject. Within the framework of the Artificial Intelligence and Ethics curriculum, 25 sixth grade students were trained. At the end of the training, a semistructured interview form was applied to the students. Students' views on the ethical dimension of artificial intelligence were revealed. As a result, education has been contributed with an artificial intelligence and ethics curriculum suitable for middle school students. In general, the approach of including the ethical dimension of artificial intelligence in education shows that middle school students can evaluate artificial intelligence as a personal and social issue beyond just having knowledge about its functioning. [For the full proceedings, see ED652261.]","International Society for Technology, Education, and Science","Paper presented at the International Conference on Studies in Education and Social Studies (ICSES) (Antalya, Turkey, Oct 20-23, 2023)",,http://eric.ed.gov/?id=ED652351,Middle School Students; Artificial Intelligence; Ethics; Student Attitudes; Curriculum Implementation; Grade 6; Social Problems; Prior Learning,,Speeches/Meeting Papers; Reports - Research
EJ1480276,Insights from Educators: Integrating AI Literacy into Media Literacy Education in Practice,Stephanie Jean Tsang,2025,"Through in-depth interviews with junior high school teachers in Hong Kong who participated in a media and artificial intelligence literacy program intervention, this research highlights the importance of prioritizing values and ethics education over technical proficiency when incorporating artificial intelligence (AI) into media literacy training. While quantitatively assessing students' literacy levels posed challenges, future media literacy programs should concentrate on introducing technological terminology and concepts, promoting awareness of potential issues, instilling values for responsible technology use, and fostering empathy to create a harmonious online environment. By focusing on fundamental values and key concepts rather than following fleeting AI trends, educators can empower students to navigate the digital media landscape effectively. Introducing such education among junior high school students, potentially involving parental education, is crucial for nurturing well-rounded digital citizens. The discussion thoroughly explores implications and recommendations for media literacy education programs, specifically in an AI era.",Journal of Media Literacy Education,v17 n2 p53-65 2025,,http://eric.ed.gov/?id=EJ1480276,Information Literacy; Teaching Methods; Junior High School Students; Media Literacy; Artificial Intelligence; Computer Software; Technology Integration; Junior High School Teachers; Teacher Attitudes; Foreign Countries,English,Journal Articles; Reports - Research
EJ1492900,Omani Pre-Service Teachers' Preparedness and Perceptions of Integrating Artificial Intelligence into Classrooms,Moza Al Malki; Qasim Al Washahi; Abdul Rahman Al Farsi,2025,"This study aims to examine the attitudes and readiness of Omani pre-service teachers toward implementing artificial intelligence (AI) in the classroom. The research employed the integrated technology acceptance model (TAM) to explore how these future educators perceive and prepare for AI integration. Using a mixed-methods approach that combined qualitative and quantitative data collection techniques, the study gathered insights from pre-service teachers at various higher education institutions in Oman. The results revealed that Omani pre-service teachers generally hold positive attitudes toward technology and are familiar with AI concepts. They perceive AI as a useful and user-friendly tool in education, recognizing its potential to enhance teaching and learning. Additionally, most participants expressed a willingness to incorporate AI into their teaching practices. However, several challenges were identified, including insufficient training and professional development opportunities, concerns about excessive reliance on AI tools, and the ethical implications of AI use in educational settings. Notably, a statistically significant difference was found between male and female pre-service teachers regarding their perceptions of support and resources. The study findings suggest that Omani higher education institutions must take strategic steps to prepare for AI integration. The research recommends practical approaches for integrating AI into teaching programs, emphasizing the need for comprehensive teacher training and the development of ethical guidelines. By aligning with global trends in AI education, these institutions can equip future educators with the necessary skills to effectively navigate and incorporate AI into their classrooms, ensuring it becomes a valuable tool for enhancing the learning experience.",Journal of Social Studies Education Research,v16 n4 p265-297 2025,,http://eric.ed.gov/?id=EJ1492900,Foreign Countries; Preservice Teachers; Readiness; Student Attitudes; Technology Integration; Technology Uses in Education; Artificial Intelligence; Computer Attitudes; Usability; Intention; Faculty Development; Ethics,English,Journal Articles; Reports - Research
EJ1469449,"Teachers' Perceptions of Artificial Intelligence in Colombia: AI Technological Access, AI Teacher Professional Development and AI Ethical Awareness",Paola Julie Aguilar-Cruz; Sdenka Zobeida Salas-Pilco,2025,"The introduction of artificial intelligence (AI) in education is seen as a promising tool to enhance learning outcomes and provide students with engaging learning environments in developing countries such as Colombia. This case study aimed to investigate teachers' perceptions of AI in K-12 education in public schools located in the Amazonian department of Caquetá, Colombia. The study focuses on teachers' views on the integration of AI into teaching and learning activities. A total of 190 teachers were surveyed, of whom 30 were selected for semi-structured interviews. The main findings are as follows: (a) AI benefits teachers by facilitating and providing virtual assistance, (b) the challenges are the limited knowledge about AI and a lack of resources, (c) the concerns reported are that AI may hinder students' development of critical thinking and problem-solving skills, and (d) ongoing professional development for integrating AI in education is suggested.","Technology, Pedagogy and Education",v34 n2 p219-238 2025,10.1080/1475939X.2025.2451865,http://eric.ed.gov/?id=EJ1469449,Teacher Attitudes; Ethics; Artificial Intelligence; Computer Software; Technology Integration; Teaching Methods; Foreign Countries; Kindergarten; Elementary Secondary Education; Public Schools; Learning Activities; Critical Thinking; Problem Solving; Faculty Development; Barriers; Technological Literacy; Pedagogical Content Knowledge; Educational Resources,English,Journal Articles; Reports - Research
EJ1469964,Upskilling Teachers to Use Generative Artificial Intelligence: The TPTP Approach for Sustainable Teacher Support and Development,Sebah Al-Ali; Rob Miles,2025,"There is a growing need to upskill higher education (HE) teachers for the effective and responsible integration of generative artificial intelligence (GenAI) in their classrooms. This case study sought to address this growing need by designing and delivering a training course for educators, focusing on the use of ChatGPT as it was the most commonly used tool at the time. The professional development opportunity lasted 5 weeks and covered critical aspects of GenAI use for teaching and learning. Data collected from participants included discussion board entries, written tasks and focus groups. Findings highlight some of the common practices and concerns HE practitioners had regarding the use of GenAI in their practice. The findings also emphasise the importance of providing teachers with customised GenAI training to facilitate its effective integration in HE contexts. Finally, based on the findings of this study, we propose the TPTP Support System for Teachers, built upon four key areas: teacher training, pedagogical support, testing revamp and practice networks. This system aims to guide institutional efforts to facilitate and support educators as they integrate GenAI in HE.",Australasian Journal of Educational Technology,v41 n1 p88-106 2025,,http://eric.ed.gov/?id=EJ1469964,Faculty Development; Artificial Intelligence; College Faculty; Technology Uses in Education; Technological Literacy; Teacher Attitudes; Training; Foreign Countries; Barriers; Ethics,English,Journal Articles; Reports - Research
EJ1481940,"Science Teachers' Perceptions of the Artificial Intelligence in Science Education: Challenges, Readiness, Benefits, and Impact on Student Learning",Rifat Efe; Hulya Aslan Efe,2025,"Recent developments in AI technology have the potential to affect science education. Understanding science teachers' perceptions of AI is essential for developing strategies that support effective and morally responsible integration of AI in science learning environments. This research focuses on science teachers' perceptions of AI in science classes by considering the challenges, preparedness, advantages, and its effect on student learning. A total of 383 science teachers participated in the study. Science teachers' perceptions of AI scale were used for data collection. The data were analysed through descriptive statistics, MANOVA, and multiple regression. Data analysis disclosed that the participants viewed lack of adequate training and data privacy concerns as the most prominent barriers for integrating AI in science classes. Familiarity significantly affects AI Readiness and AI-Supported Assessment & Feedback, while Teaching experience has a significant effect on Barriers to AI Adoption, emphasizing the significance of familiarity with AI and teaching experience on these outcomes. AI Readiness and Adoption significantly predicted AI's Impact on Learning, while the likely Benefits of AI were the strongest predictor of AI's Impact on Student Learning. Fostering AI readiness, emphasizing AI's educational advantages, and reducing structural barriers to AI adoption are among the recommendations.",Journal of Baltic Science Education,v24 n4 p655-669 2025,,http://eric.ed.gov/?id=EJ1481940,Science Teachers; Teacher Attitudes; Artificial Intelligence; Science Education; Barriers; Affordances; Readiness; Program Effectiveness; Technology Integration; Teacher Competencies; Training; Privacy; Familiarity; Teaching Experience; Predictor Variables; Faculty Development; Secondary School Teachers,English,Journal Articles; Reports - Research; Tests/Questionnaires
EJ1470423,When TPACK Meets Artificial Intelligence: Analyzing TPACK and AI-TPACK Components through Structural Equation Modelling,Fatih Karatas; Bengü Aksu Ataç,2025,"The integration of AI into TPACK frameworks is crucial for enhancing teacher readiness in an increasingly technology-driven educational environment. However, a significant gap exists in literature regarding assessing preservice teachers' knowledge on the integration of AI into their pedagogical practices based on the TPACK framework. This study investigates TPACK and AI-TPACK skills among English preservice teachers, addressing a significant gap in understanding their readiness to utilize AI tools in education. Employing a quantitative cross-sectional survey approach with structural equation modeling, the research examined 304 ELT preservice teachers. Findings reveal varying proficiency levels across TPACK and AI-TPACK components. In TPACK, participants demonstrated high competence in independent components like Technology Knowledge (TK) and Technological Pedagogical Knowledge (TPK), but lower abilities in integrated Technological Pedagogical Content Knowledge (TPACK). For AI-TPACK, preservice teachers exhibited above-average competence across all areas, with highest proficiency in Intelligent Technology Knowledge (AI-TK) and lowest in ethics. Gender and prior AI experience significantly influenced AI-TPACK skills. Strong positive correlations between traditional TPACK and AI-TPACK components were observed, suggesting simultaneous skill development is feasible. This study highlights the need for customized teacher training curricula that enhance integrated knowledge and ethical considerations of AI in teaching.",Education and Information Technologies,v30 n7 p8979-9004 2025,10.1007/s10639-024-13164-2,http://eric.ed.gov/?id=EJ1470423,Pedagogical Content Knowledge; Technological Literacy; Artificial Intelligence; Preservice Teachers; Readiness; English (Second Language); Language Teachers,English,Journal Articles; Reports - Research
EJ1491250,Mind the Gap: A Comparative Study of Faculty and Student Readiness for AI-Integrated ELT in Azerbaijani Higher Education,Hasan Alisoy; Dana Amirbayeva; Zarifa Sadigzade; Yasin Babazade,2025,"Background/purpose: Azerbaijani higher education is undergoing a rapid digital transformation in response to global advances in artificial intelligence (AI). Within this context, English language teaching (ELT) faces the challenge of integrating AI tools to enhance learning outcomes. However, little is known about how prepared educators and learners are for this shift. This study compares ELT faculty and student readiness for AI-integrated teaching and learning at a public Azerbaijani university, identifying gaps and capacity-building needs. Materials/methods: A convergent mixed-methods design was employed. Quantitatively, a survey measured technological and mindset readiness among 150 bachelor-level ELT students and 16 ELT faculty members. Qualitatively, two focus group interviews explored perceptions, perceived benefits, and concerns regarding AI in education. Results: Survey findings indicate that students reported higher technology familiarity and more positive attitudes toward AI compared to faculty, who demonstrated cautious optimism but lower self-assessed AI skills. Focus groups revealed that both groups recognised potential benefits, such as personalised learning support, while also expressing concerns about ethical use, data privacy, and insufficient training opportunities. Conclusion: A readiness gap exists: students appear more comfortable adopting AI, whereas faculty require targeted support to integrate AI pedagogically. To bridge this gap, institutions should prioritise professional development, establish clear guidelines, and implement supportive policies for AI adoption in ELT.",Educational Process: International Journal,v19 Article e2025594 2025,,http://eric.ed.gov/?id=EJ1491250,Foreign Countries; College Students; College Faculty; Readiness; Artificial Intelligence; Technology Uses in Education; Technology Integration; Second Language Instruction; Second Language Learning; English (Second Language); Familiarity; Self Efficacy; Ethics; Privacy; Training; Faculty Development,English,Journal Articles; Reports - Research
EJ1459914,Teaching AI in Business Schools: A Pathway to Future-Ready Graduates,Eric Kennedy,2024,"The manuscript outlines the development of an undergraduate course titled ""Generative Artificial Intelligence for Business,"" aimed at equipping students with the knowledge and skills necessary to leverage generative AI technologies in various business contexts. The course framework covers fundamental concepts of generative AI, including technologies like Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs), and emphasizes practical applications in marketing, product design, and customer engagement. The curriculum integrates ethical considerations, addressing issues such as data privacy and algorithmic bias, to prepare students for responsible use of AI in business. The course structure includes lectures, hands-on labs, case studies, and a capstone project, fostering a blend of theoretical understanding and practical experience. Faculty training and institutional support are highlighted as crucial for effective course delivery, ensuring that instructors are equipped with the latest knowledge in AI technologies. The document also discusses challenges such as keeping course content up-to-date with rapid technological advancements and ensuring accessibility and inclusivity for all students. The proposed course aims to produce graduates who are not only technically proficient but also capable of critical thinking and ethical decision-making in the application of generative AI in business settings.",Journal of Instructional Pedagogies,v30 2024,,http://eric.ed.gov/?id=EJ1459914,Undergraduate Study; Business Education; Artificial Intelligence; Technological Literacy; Business; Ethics; Privacy; Algorithms; Course Content; Critical Thinking; Curriculum Development; Faculty Development; School Business Relationship,English,Journal Articles; Reports - Descriptive
EJ1471777,The Impact of Algorithm Awareness Training on Competent Interaction with Intelligent Voice Assistants,André Markus; Maximilian Baumann; Jan Pfister; Andreas Hotho; Astrid Carolus; Carolin Wienrich,2025,"Intelligent Voice Assistants (IVAs) have become integral to many users' daily lives, using advanced algorithms to automate various tasks. Nevertheless, many users do not understand the underlying algorithms and how they work, posing potential risks to the competent and self-determined use of IVAs. This work develops three online training modules to promote algorithm awareness, providing (1) basic knowledge of algorithms, (2) risks posed by algorithms in IVAs, and (3) scientific evidence on algorithm aversion. A total of 110 participants were studied to analyze the training effects on various perception levels relevant to IVAs, including usage perception (attitude, exploration), privacy aspects (trustworthiness, privacy control), persuasion aspects (persuasion knowledge, anthropomorphic perception), and self-determined interaction variables (reflection, indulgence). The results show that the modules increase awareness of IVA algorithms, influence user perceptions (e.g., higher exploration intentions), and promote critical engagement with IVAs (e.g., lower trustworthiness). Moreover, the modules contribute to a higher sense of privacy control, reduce persuasive perceptions of IVAs (e.g., anthropomorphic perception), and promote self-determined interaction (e.g., higher indulgent use). The modules offer a new approach to promoting the competent use of IVAs in society and provide a starting point for further research and educational institutions to increase algorithm awareness for IVAs and other AI-based systems.",Discover Education,v4 Article 125 2025,10.1007/s44217-025-00522-6,http://eric.ed.gov/?id=EJ1471777,Algorithms; Digital Literacy; Training; Artificial Intelligence; Assistive Technology; Natural Language Processing; Audio Equipment; Man Machine Systems; Student Attitudes; Privacy; Reflection; Intention,English,Journal Articles; Reports - Research
EJ1482486,Artificial Intelligence and English as a Foreign Language (EFL) Teachers' Competencies: A Systematic Review,Rukthin Laoha; Wichittra Chomthong; Weerapa Pongpanich,2025,"The integration of Artificial Intelligence (AI) into English as a Foreign Language (EFL) education has transformed teaching practices, necessitating a re-evaluation of teacher competencies in the digital age. This systematic review examines the intersection of AI technologies and EFL teachers' competencies, exploring how AI tools influence pedagogical skills, technological proficiency, and professional development. Through an analysis of recent literature, the study identifies key competencies required for EFL teachers to effectively leverage AI, including adaptive teaching strategies, data literacy, and ethical considerations in AI usage. The review also highlights challenges such as resistance to technological adoption, the digital divide, and the need for continuous upskilling. Findings suggest that while AI offers significant opportunities for personalized learning and efficiency, EFL teachers must develop a balanced skillset that integratestraditional teaching expertise with emerging technological demands. The results of the research showed that 1) EFL teachers' competencies in artificial intelligence field consist of 10 competencies, namely: 1) AI-Assisted Lesson Planning, 2) AI-Powered Language Practice & Feedback, 3) Speech Recognition & Pronunciation Tools, 4) AI for Differentiated Instruction, 5) Automated Assessment & Grading, 6) Data-Driven Student Insights, 7) Ethical & Critical Use of AI, 8) AI for Content Creation & Gamification, 9) AI-Powered Translation & Comprehension Support, and 10) AI and Virtual/Augmented Reality in EFL. The paper concludes with recommendations for teacher training programs and policy frameworks to support the evolving role of EFL educators in an AI-driven educational landscape.",Higher Education Studies,v15 n3 p262-292 2025,,http://eric.ed.gov/?id=EJ1482486,Artificial Intelligence; Technology Uses in Education; Second Language Instruction; English (Second Language); Language Teachers; Teacher Competencies; Technology Integration; Teaching Skills; Technological Literacy; Faculty Development; Teaching Methods; Information Literacy; Ethics; Lesson Plans; Feedback (Response); Pronunciation Instruction; Individualized Instruction; Automation; Computer Assisted Testing; Grading; Gamification; Translation; Computer Simulation,English,Journal Articles; Information Analyses
EJ1472127,Systematic Review of the Ethical Use of Artificial Intelligence (AI) Tools in Education,Enes Küçük; Fidaye Cincil; Yasemin Karal,2025,"AI technology, which is becoming more widespread day by day, also affects education and training processes. The use of AI tools in educational environments provides many benefits to teachers and students. However, the use of AI in education also raises some ethical concerns. The aim of this study was to reveal the ethical issues arising from the use of AI in educational environments. The words ""education"", ""artificial intelligence (AI)"" and ""ethics"" were searched for in Web of Science, Google Scholar, Eric, Taylor & Francis, Springer, PsycINFO, PubMed, Scopus, IEEE, intelligent learning systems (ILS), automatic feedback systems (AFS), automatic assessment systems (ASS), big data (BD), learning analytics (LA), and the ""internet of things (IoT)"". Further searches were made by adding the keywords ""wearable technologies (WT)"", ""robot (R)"", ""deep learning (DL)"" and ""generative AI (GenAI)"". Twenty of the 489 studies accessed during the research were included in the scope of the research. Studies that were conducted with an AI-supported system/tools or that examined the ethical dimension of a possible educational intervention from the perspective of any study group/sample were included. Ethical issues arising in the studies were examined in the context of the ethical framework determined by Ryan and Stahl (2021). The general characteristics of the studies included in the scope of the research, research designs, technologies used and ethical issues that arise are presented. In the study, it was determined that eight principles in the context of the ethical framework determined by Ryan and Stahl were of concern for teachers and students.",Journal of Theoretical Educational Science,v18 n2 p385-412 2025,,http://eric.ed.gov/?id=EJ1472127,Ethics; Teaching Methods; Learning Analytics; Internet; Computer Software; Artificial Intelligence; Technology Integration; Research Reports; Information Retrieval; Educational Benefits; Databases; Intervention; Guidelines; Educational Principles,English,Journal Articles; Information Analyses
ED676174,Artificial Intelligence Literacy in Higher Education: Theory and Practice from a European Perspective,Imre Fekete,2025,"This book explores the concept of artificial intelligence (AI) literacy within higher education, addressing both instructors' and students' preparedness to engage with AI technologies responsibly and effectively. By synthesising existing frameworks and empirical studies, alongside presenting two original research studies, the book bridges theoretical foundations with practical applications tailored for modern educational contexts. Practical recommendations include methods to develop AI literacy skills, focusing on ethical awareness, technological competence, and the potential for AI to enhance teaching and learning processes. Aimed at higher education instructors, stakeholders and students, the book offers actionable insights and tools for fostering informed and critical engagement with AI, aligned with lifelong learning goals and professional development needs.",Multilingual Matters,,,http://eric.ed.gov/?id=ED676174,Artificial Intelligence; Higher Education; Foreign Countries; Technology Uses in Education; Ethics; Technological Literacy,,Books; Reports - Research
EJ1484897,The Readiness Survey of Students in Using Artificial Intelligence for Distance Education in Higher Education,Patthanan Bootchuy; Phantipa Amornrit; Piyapot Tantaphalin,2025,"With the rapid advancement of artificial intelligence, AI-powered learning platforms have become essential tools for college students to acquire knowledge and enhance their academic performance. However, students' readiness to effectively integrate AI into distance learning remains critical in maximizing its benefits. This study aimed to (1) examine students' readiness to apply artificial intelligence (AI) for distance learning in higher education and (2) compare the readiness levels between undergraduate and graduate students in distance education at Sukhothai Thammathirat Open University. The sample consisted of 445 students from 12 disciplines, including undergraduate and graduate students, selected through volunteer sampling. The research instrument was a survey assessing students' readiness to apply AI in distance learning at the tertiary level. Data analysis included frequency, percentage, mean, standard deviation, analysis of variance (ANOVA), and content analysis. The results revealed that (1) students demonstrated high readiness to use artificial intelligence for distance learning. The findings were as follows: 1.1) Of the respondents, 61.1% were female, and 38.9% were male. Undergraduates accounted for 59.8%, while 40.2% were graduate students, with most respondents in their second year (40.4%). Most (59.8%) had previous experience using AI for educational purposes, with popular platforms being ChatGPT, Gemini, Canva AI, and Claude. 1.2) Students demonstrated a high level of readiness to use artificial intelligence for distance learning (M = 3.78, S.D. = 1.08), 1.3) Students' understanding of artificial intelligence was moderate (M = 3.18, S.D. = 1.12), 1.4) Students' application of AI for distance learning was moderate (M = 3.20, S.D. = 1.18) and 1.5) the ethical and legal use of artificial intelligence for learning at a high level (M = 3.56, S.D. = 1.15). (2) No significant difference was found in the readiness levels between undergraduate and graduate students in using artificial intelligence for distance education (p > 0.05). Students recommended organizing additional courses or training sessions on using artificial intelligence (AI) to enhance their knowledge, practical skills, and awareness of necessary precautions when using AI. Key focus areas include preventing misuse, upholding ethical standards in AI applications, and ensuring data security.",Journal of Education and Learning,v14 n5 p273-282 2025,,http://eric.ed.gov/?id=EJ1484897,Foreign Countries; Readiness; Artificial Intelligence; Distance Education; Undergraduate Students; Graduate Students; Technology Uses in Education; Ethics; Legal Responsibility,English,Journal Articles; Reports - Research
EJ1485597,The Use of Generative AI Tools in Higher Education: Ethical and Pedagogical Principles,Nguyen Khoa Viet,2025,"The integration of generative AI tools in higher education presents both significant opportunities and challenges. This paper addresses two key questions: how AI should be incorporated into higher education and what ethical and pedagogical principles should guide its use. While AI enhances creativity, efficiency, and personalized learning, it also raises concerns about over-reliance, bias, and ethical implications. Through a comprehensive review of existing literature, this study examines the ethical and pedagogical impact of AI in education. Findings suggest that institutions must ensure AI complements traditional learning, uphold academic integrity, and promote critical thinking. Human-AI collaboration and equitable access are essential to support diverse learners. Additionally, prioritizing ethical AI use, data privacy, and AI literacy safeguards student rights and prepares educators and students for the evolving technological landscape. The paper concludes that institutions must develop clear AI policies, embed AI ethics into curricula, and provide ongoing faculty training. By addressing these considerations, higher education can harness AI's benefits while maintaining the critical role of human educators and ensuring equitable and ethical access for all learners.",Journal of Academic Ethics,v23 n3 p1435-1455 2025,10.1007/s10805-025-09607-1,http://eric.ed.gov/?id=EJ1485597,Artificial Intelligence; Technology Uses in Education; Higher Education; Ethics; Educational Principles; Technology Integration; Integrity; Critical Thinking; Man Machine Systems; Privacy; Digital Literacy; Faculty Development,English,Journal Articles; Information Analyses
EJ1493803,Embracing Invitational Education Principles and AI to Help Teachers and Learners Ethically Utilize Generative Artificial Intelligence,Chris Anderson,2025,"A Professional Learning Community (PLC) invites learning by doing and that process is optimized through intentional, caring, optimistic, respectful, and trustworthy (I-CORT) mindsets (Purkey & Novak, 2015; Anderson, 2021), which fosters a positive and supportive learning environment. A school having a PLC focusing on generative artificial intelligence (AI) policy development and best-practice curriculum integration can identify where additional support or training is needed. Generative AI-driven educational software is going to become more, not less, pervasive. So, educators need to be highly trained in effective implementation of evolving teaching and learning applications. Therefore, effective pedagogy involves more than telling a student to access an application. Teacher preparation programs and institutional policies should lead these professional development endeavors. Several suggestions, approaches, and models are provided herein to promote best practices that align Invitational Education (IE) theory, with utilization of AI.",Journal of Invitational Theory and Practice,v31 p5-21 2025,,http://eric.ed.gov/?id=EJ1493803,Communities of Practice; Artificial Intelligence; Technology Uses in Education; Ethics; Educational Policy; School Policy; Best Practices; Teacher Competencies; Technological Literacy; Reading Instruction; English (Second Language); Planning; Formative Evaluation; Higher Education; Grade 4; Teacher Education Programs; Faculty Development,English,Journal Articles; Reports - Descriptive
EJ1476898,"Artificial Intelligence and Students: An Overview from Teaching-Learning, Ethics-Morality, Emotions, Training, Cognition-Creativity, Social Construct, Recreation-Entertainment",Ricardo Alberto Reza Flores; Citlali Michélle Reza-Flores; Cristinao Galafassi; Abril Acosta-Ochoa; Rosa Maria Vicari,2025,"This study examines how secondary-school students recognize and relate to artificial intelligence (AI) and the meanings they attribute to it in their everyday lives. Using a quantitative, descriptive, cross-sectional design, we explore the subjectivities of a purposive sample of 576 students from both public and private schools. The analysis focuses on students' use of AI across seven dimensions: teaching-learning, ethics and morality, emotions, personal development, cognition and creativity, social construction, and recreation and entertainment. Data were collected with an ad hoc instrument that showed high internal consistency ([alpha] = 0.89). The findings reveal a variety of positions, including emotional ambivalence, ethical uncertainty, autonomous learning, and diverse perceptions of the creative, social, and educational effects of AI. Although students express openness and interest in technology, they also voice doubts about its integration into school practices and its influence on critical thinking and personal initiative. The results underscore the need for educational policies and school practices aligned with Education 5.0 that foster critical, ethical, and humanistic uses of technology. This research contributes to understanding the configuration of digital youth subjectivities and provides a broad framework for designing meaningful, contextualized, and inclusive pedagogical strategies that develop digital citizenship.",Journal of Pedagogy,v16 n1 p42-68 2025,10.2478/jped-2025-0003,http://eric.ed.gov/?id=EJ1476898,Secondary School Students; Artificial Intelligence; Ethics; Moral Values; Psychological Patterns; Individual Development; Cognitive Processes; Creativity; Recreation; Learning; Computer Attitudes; Computer Uses in Education; Foreign Countries; Public Schools; Private Schools; Interpersonal Relationship; Computer Literacy,English,Journal Articles; Reports - Research
EJ1384682,The Impact of Artificial Intelligence on Higher Education: An Empirical Study,"Slimi, Zouhaier",2023,"Artificial intelligence (AI) has been a topic of growing interest and investigation in various fields, including higher education. This research article explores the impact of AI on higher education by examining its effects on teaching and learning, assessment, ethics, required skills, and future careers. The aim of this study is to analyse the influence of AI on higher education, investigate its impact on the teaching and learning process, examine its effect on assessment and grading, and predict its influence on graduates' future careers. To accomplish this, the study employs a qualitative approach based on a survey of the higher education audience. The results of this study demonstrate the crucial role of AI in the future of higher education. The findings highlight the effectiveness and efficiency of AI in equipping graduates with new skills for their future careers. They also emphasise the importance of considering the ethical implications of AI. The study reveals that higher education institutions need to integrate AI more extensively in their programs to prepare graduates for the future workforce. AI has the potential to revolutionize education by personalizing teaching methods to suit individual student needs, providing prompt feedback, and automating administrative tasks. It can also assist in grading and assessment, freeing educators to focus on developing curriculum and providing quality instruction. The study findings suggest that AI has a positive impact on the learning experience by facilitating the acquisition of new knowledge and skills. This research provides insights into the potential of AI to transform higher education and contribute to the development of new skills for graduates. It has important implications for educators, policy-makers, and other stakeholders in the higher education sector. The study findings suggest that AI should be more extensively integrated into higher education curricula, and that institutions need to consider the ethical implications of AI in the development and implementation of their programs. By doing so, they can better prepare graduates for the demands of the future workforce.",European Journal of Educational Sciences,v10 n1 p17-33 Mar 2023,,http://eric.ed.gov/?id=EJ1384682,Artificial Intelligence; Higher Education; Digital Literacy; Teaching Methods; Student Experience; Curriculum Development; Technology Uses in Education,English,Journal Articles; Reports - Research
EJ1478396,Perceptions and Preparedness of K-12 Educators in Adopting Generative AI,Juhee Kim,3448,"The integration of generative artificial intelligence (AI) tools, such as ChatGPT and DALL-E, presents transformative opportunities and challenges for K-12 education. This mixed-methods study investigates educators' perceptions, familiarity, and preparedness for AI adoption, as well as institutional strategies and barriers. Quantitative findings indicate strong relationships between AI familiarity, perceived readiness, and institutional planning stages. Qualitative analysis highlights challenges such as insufficient professional development, ethical concerns, and infrastructural inequities, alongside opportunities for enhancing personalised learning and operational efficiency. The findings underscore the need for targeted training, equitable resource access, and clear institutional policies to ensure effective and ethical AI integration. This research offers actionable insights for educators, policymakers, and leaders seeking to navigate AI's potential in K-12 education.",Research in Learning Technology,v33 Article 3448 2025,,http://eric.ed.gov/?id=EJ1478396,Barriers; Technology Integration; Artificial Intelligence; Computer Software; Elementary School Teachers; Secondary School Teachers; Teacher Attitudes; Technological Literacy; Pedagogical Content Knowledge; Educational Strategies; Faculty Development; Ethics; Efficiency; Educational Resources; School Policy; Teaching Methods; Educational Benefits; Administrator Attitudes; State Surveys,English,Journal Articles; Reports - Research
EJ1377934,A Human-Centric Automated Essay Scoring and Feedback System for the Development of Ethical Reasoning,"Lee, Alwyn Vwen Yen; Luco, Andrés Carlos; Tan, Seng Chee",2023,"Although artificial Intelligence (AI) is prevalent and impacts facets of daily life, there is limited research on responsible and humanistic design, implementation, and evaluation of AI, especially in the field of education. Afterall, learning is inherently a social endeavor involving human interactions, rendering the need for AI designs to be approached from a humanistic perspective, or human-centered AI (HAI). This study focuses on the use of essays as a principal means for assessing learning outcomes, through students' writing in subjects that require arguments and justifications, such as ethics and moral reasoning. We considered AI with a human and student-centric design for formative assessment, using an automated essay scoring (AES) and feedback system to address issues of running an online course with large enrolment and to provide efficient feedback to students with substantial time savings for the instructor. The development of the AES system occurred over four phases as part of an iterative design cycle. A mixed-method approach was used, allowing instructors to qualitatively code subsets of data for training a machine learning model based on the Random Forest algorithm. This model was subsequently used to automatically score more essays at scale. Findings show substantial agreement on inter-rater reliability before model training was conducted with acceptable training accuracy. The AES system's performance was slightly less accurate than human raters but is improvable over multiple iterations of the iterative design cycle. This system has allowed instructors to provide formative feedback, which was not possible in previous runs of the course.",Educational Technology & Society,v26 n1 p147-159 Jan 2023,,http://eric.ed.gov/?id=EJ1377934,Essays; Scoring; Writing Evaluation; Computer Software; Feedback (Response); Writing Instruction; Artificial Intelligence; Humanism; Outcomes of Education; Ethics; Moral Values; Persuasive Discourse; Online Courses; Large Group Instruction; Time Management; Undergraduate Students; College Faculty; Algorithms; Interrater Reliability; Accuracy; Peer Evaluation; Scoring Rubrics; Formative Evaluation; Logical Thinking; Knowledge Economy,English,Journal Articles; Reports - Research
ED676683,"Artificial Intelligence in U.S. Education: A Framework for Equitable Teaching, Learning, and Assessment",Marley Belot,2025,"Artificial intelligence (AI) has appeared as a transformative force in education, influencing how instruction is designed, delivered, and assessed across the United States. This paper examines AI's growing role in improving educational outcomes through personalization, accessibility, and data-driven decision-making. Drawing upon research from the U.S. Department of Education, the Institute of Education Sciences, and peer-reviewed literature, this study integrates the principles of Universal Design for Learning (UDL) and Constructivist Learning Theory to present a human-centered framework for fair AI implementation. It discusses applications across K-12, higher education, and workforce learning, emphasizing teacher support, student engagement, and institutional accountability. Ethical and policy implications are analyzed to ensure that AI contributes to inclusive, transparent, and human-guided learning ecosystems. The paper concludes that when implemented responsibly, AI can advance the U.S. education system toward a more just, personalized, and sustainable future.",Online Submission,,,http://eric.ed.gov/?id=ED676683,Artificial Intelligence; Influence of Technology; Educational Trends; Technology Integration; Educational Change; Elementary Secondary Education; Higher Education; Workplace Learning; Adult Learning; Access to Education; Constructivism (Learning); Human Factors Engineering; Ethics; Educational Policy; Computer Uses in Education,,Reports - Descriptive
EJ1471463,"Countering the ""Plagiarism Slot Machine"": Protecting Creators and Businesses from AI Copyright Infringement",Christine Ladwig; Dana Schwieger; Reshmi Mitra,2025,"The rapid rise of AI use is creating some very serious legal and ethical issues such as bias, discrimination, inequity, privacy violations, and--as creators everywhere fear--theft of protected intellectual property. Because AI platforms ""learn"" by scraping training materials available online or what is provided to them through their human programmers, these systems can easily capture copyrighted expressions, such as song lyrics, computer code, stories, or images, and use them to generate new works without attribution. This rise in AI use of protected material is spawning an array of legal actions as artists, programmers, writers, photographers and other creative individuals witness the erosion of their value in the marketplace and the world. As students prepare to enter the field, they need to be aware of legal issues and concerns that they may face and methods for addressing them. This case focuses on the problem of AI copyright infringement of art and includes an exploratory exercise that introduces students to the act of ""scraping""--a primary AI training method by which copyrighted works may be vulnerable to potential infringement.",Information Systems Education Journal,v23 n5 p53-61 2025,,http://eric.ed.gov/?id=EJ1471463,Copyrights; Plagiarism; Intellectual Property; Computer Software; Computer Science Education; Artificial Intelligence; Programming; Meta Analysis; Laws; Court Litigation; Periodicals; Journalism; Music; Artists; Musicians; Photography; Legal Problems; Art; Teaching Methods,English,Journal Articles; Reports - Research
EJ1489932,What Role Should Higher Education Institutions Play in Fostering AI Ethics? Insights from Science and Engineering Graduate Students,Maya Usher; Miri Barak; Sibel Erduran,2025,"Background: The rapid advancement of artificial intelligence (AI) has raised significant ethical concerns, prompting higher education institutions to reconsider how they prepare future STEM professionals to navigate such concerns responsibly. Despite growing efforts to integrate AI ethics into higher education, a lack of consensus and standardized approaches has led to inconsistent ethics education and disparities in graduates' preparedness for ethical issues related to AI. This study examined the role of higher education institutions in fostering ethical awareness in AI, focusing on institutional responsibilities and strategies as perceived by 95 science and engineering graduate students. Participants engaged in a case-based AI ethics activity, and their responses to open-ended questions were analyzed using inductive content analysis. Results: The analysis identified three key themes regarding students' views on institutional responsibility about AI and ethics. Most students indicated the essential responsibility of universities, citing their social, professional, educational, and reputational obligations. Others advocated for a shared responsibility, emphasizing the importance of collaboration between academia, industry, and society. A smaller group endorsed a constrained view of responsibility, questioning the feasibility and relevance of AI ethics education within academic settings. Students proposed various strategies for fostering ethical awareness, with standalone ethics courses being the most frequently discussed. Additional recommendations included interactive learning approaches, embedding ethics into curricula, and strengthening institutional leadership. Conclusions: This study underscores the central role of higher education institutions in fostering ethical awareness in AI for science and engineering graduates, with most students emphasizing universities' societal and professional responsibilities. It highlights the need to align ethics education with technical training and professional trajectories in STEM subjects, offering actionable insights for higher education institutions to better prepare graduates for the ethical complexities of AI use and development.",International Journal of STEM Education,v12 Article 51 2025,10.1186/s40594-025-00567-x,http://eric.ed.gov/?id=EJ1489932,Artificial Intelligence; Ethics; Ethical Instruction; Higher Education; Graduate Students; Science Education; Engineering Education; Student Attitudes; College Role; Educational Responsibility; Educational Principles; Change Strategies,English,Journal Articles; Reports - Research
EJ1443902,Constructing a Teacher Portrait for the Artificial Intelligence Age Based on the Micro Ecological System Theory: A Systematic Review,Xiaoyong Hu; Hui Sui; Xingyu Geng; Li Zhao,2024,"Artificial intelligence (AI) is bringing new developments in education. Teachers' professional development grows with the promotion of technology, and more challenges and difficulties will be faced by teachers in the AI age. Thus, this study aimed to explore what a teacher portrait should be like in the new AI age. In order to systematically and comprehensively construct a teacher portrait for the AI age, we searched online databases using keywords, and after screening according to the inclusion and exclusion criteria, 26 journal documents were identified for in-depth analysis. It was found that there were 20 different types of frameworks that could be used to construct a teacher portrait for the AI age. This study reconstructed a teacher portrait based on the Person-Process-Content (PPC) structure of the micro ecological system theory, and finally arrived at a teacher portrait framework with three dimensions and eight sub-dimensions, including teachers' cognition and emotion, teachers' knowledge and skills, and interaction between teachers' cognition and ability, which highlighted the dynamic requirements of teachers' professional development in the AI age. In addition, the challenges faced by teachers in the AI age are mainly concentrated on four aspects: the upgrading of teacher training requirements, the change of educational environment, the teaching application of digital technology, and the ethical issues of artificial intelligence. These findings provide a direction for promoting the professional development of teachers in the AI age, and can help teachers better cope with the challenges of the new age.",Education and Information Technologies,v29 n13 p16679-16715 2024,10.1007/s10639-024-12513-5,http://eric.ed.gov/?id=EJ1443902,Literature Reviews; Artificial Intelligence; Teachers; Teacher Characteristics; Cognitive Processes; Psychological Patterns; Skills; Faculty Development; Technological Literacy; Teacher Education; Educational Environment; Information Technology; Ethics,English,Journal Articles; Information Analyses; Reports - Research
EJ1463902,Responsible AI and Action Learning,Craig Johnson; Emad Mohamed,2025,"This paper proposes action learning has a role to play in advancing responsible AI. Despite the recent surge in attention towards artificial intelligence, predominantly focusing on its technological and commercial aspects, the social dimensions have often been overlooked. Action learning, known for fostering interdisciplinary discourse, is proposed as a collaborative learning approach to foster responsible AI. The paper explores three potential avenues: facilitating multidisciplinary dialogue, reshaping the workforce, and promoting ethical AI practices. Emphasising the importance of cultivating critical questioning skills, we suggest an action learning approach can cultivate the innovative potential of AI, whilst mitigating its potential risks.",Action Learning: Research and Practice,v22 n1 p55-67 2025,10.1080/14767333.2025.2458900,http://eric.ed.gov/?id=EJ1463902,Experiential Learning; Artificial Intelligence; Interdisciplinary Approach; Cooperative Learning; Ethics; Critical Thinking; Innovation; Risk; Labor Force Development,English,Journal Articles; Reports - Descriptive
EJ1486504,Examining High School Students' Artificial Intelligence Literacy in Visual Arts Subjects and Metaverse-Based Digital Art Attitudes,Selma Ceran,2025,"This study aims to examine high school students' artificial intelligence literacy in visual arts subjects and their attitudes toward metaverse-based digital art. The research was conducted using a comparative-relational screening model, one of the screening models. The study sample consisted of 278 9th, 10th, 11th, and 12th grade students. The Visual Themed Artificial Intelligence Literacy Scale and the Metaverse-Based Digital Art Scale were used as data collection tools. According to the research findings, high school students' AI literacy levels in visual subjects were found to be moderate, while their metaverse-based digital art attitudes were found to be low. Analyses conducted by gender revealed that male students had significantly higher mean scores than female students in both AI literacy and metaverse-based digital art attitudes. Comparisons by grade level revealed that 12th grade students had significantly higher AI literacy levels in visual subjects and metaverse-based digital art attitudes than 9th grade students. Regression analysis revealed that AI literacy in visual subjects significantly and positively predicted metaverse-based digital art attitudes, with the model explaining 19.3% of the variance. Based on the research findings, the following recommendations are recommended: developing AI literacy at an early age, integrating the metaverse into visual arts, providing digital pedagogical training for teachers, and enhancing school environments with augmented reality support. Digital ethics should be emphasized in curricula, the STEAM approach should be supported, and intercultural communication should be encouraged through metaverse-based digital art exhibitions. Future research should examine the multidimensional nature of artificial intelligence literacy, and changes in metaverse attitudes should be assessed through longitudinal and experimental studies.",International Journal of Technology in Education,v8 n4 p1245-1265 2025,,http://eric.ed.gov/?id=EJ1486504,Foreign Countries; High School Students; Artificial Intelligence; Visual Arts; Computer Simulation; Technology Uses in Education; Digital Literacy; Gender Differences; Grade Level Differences; Student Attitudes,English,Journal Articles; Reports - Research
EJ1465912,"How Gifted Students Harness AI: Opportunities, Challenges, and Future Prospects",Farah J. Tamim,2025,"In this study, we delve into the opportunities, challenges and prospects of gifted students in middle and secondary school in tapping artificial intelligence (AI). The first part introduces AI and its role in education and discusses how school students need to understand and use AI effectively. The second part examines the concept of giftedness and the characteristics of gifted students. The research employs a mixed-methods approach, administering questionnaires to two groups: It provides gifted students and peers with average IQs. Results show that gifted students often use AI tools (ChatGPT primarily) as tools to advance their learning and to self-explore, whereas, for non-gifted students (average IQ), AI is predominantly used for completing their homework. While all groups can see the value of AI in increasing engagement and motivation, they all also struggle with difficulties, like technical problems and privacy problems. The implications are that personalized feedback and effective inclusion of AI tools within an educational curriculum are both critical. The findings conclude that AI tools should be integrated into school curricula to boost students' ability in personalizing learning, boost learning by means of creativity, and augment technological competence of students. For AI to be effectively integrated, professional development of educators becomes very important. Finally, the study supports for learning environment, which is both collaborative and innovative and uses AI to support students' diverse needs.",International Journal of Research in Education and Science,v11 n1 p129-139 2025,,http://eric.ed.gov/?id=EJ1465912,Middle School Students; High School Students; Artificial Intelligence; Academically Gifted; Gifted Education; Student Motivation; Learner Engagement; Learning Activities; Technical Support; Information Security; Ethics; Creativity; Instructional Development; Technology Integration; Technological Literacy; Professional Development; Individualized Instruction,English,Journal Articles; Reports - Research
EJ1487115,AI Formative Assessment in Saudi Education: A Study across Universities,Abdullah Alenezi; Abdulhameed Alenezi,2025,"Within the context of Saudi Arabia's digital transformation strategy, ""Vision 2030"", the issue of artificial intelligence (AI) adoption in higher education is gaining momentum, changing the form of the formative assessment procedure and its perception. Given the scope of interests in the functions of Arabic Natural Language Processing (NLP) feedback, this study examines the impact of AI-based formative assessment on instructors' flexibility, writing scores, and student engagement in Saudi Arabian institutions. Ten undergraduate students and five faculty members from public and private institutions were invited to participate in the research, which employed a mixed-methods approach to reconstruct classroom settings. Although the qualitative data, gathered through responses in the form of stories, were analyzed using the theme-square approach to identify linguistic and cultural orientations in the interpretation of feedback, the quantitative data, such as revision rates, engagement, and performance ratings, were analyzed using descriptive statistical methods. Although concerns about forcing speakers to use Arabic language technology as a natural language do exist, which are relevant to cultural, linguistic, and fairness issues, the results suggest limited and gradual improvement in the quality and quantity of revisions, resulting in students writing with the assistance of AI-generated feedback. The results offer insight into why culturally specific AI systems are crucial for fostering an equitable culture, delivering practical instruction, and supporting the professional development of faculty members. The current study significantly impacts the ongoing debate about artificial intelligence in education and its consequences for educational settings, especially in non-English-speaking contexts.",Journal of Teaching and Learning,v19 n4 p284-299 2025,,http://eric.ed.gov/?id=EJ1487115,Foreign Countries; Artificial Intelligence; Technology Uses in Education; Higher Education; Educational Technology; Technology Integration; Formative Evaluation; Undergraduate Students; College Faculty; Arabic; Program Effectiveness; Writing (Composition); Cultural Relevance; Learner Engagement; Student Attitudes; Teacher Attitudes; Public Colleges; Private Colleges; Feedback (Response),English,Journal Articles; Reports - Research
EJ1472362,Safeguarding the Digital Economy: Librarians' Perspectives on Data Privacy and Ethical Use of Public AI Chatbots,Abiodun Akinwoye Olusipe; Adebowale Jeremy Adetayo; Augustine I. Enamudu; Oluwaseun Odunayo Babalola,2024,"This study employed a descriptive survey to investigate librarians' perspectives on data privacy and ethical use of public AI chatbots by patrons. The survey of 34 librarians at private university libraries in Nigeria revealed general awareness of applicable laws and privacy risks, but gaps in specific regulatory knowledge like the GDPR. Ethical concerns emerged as paramount, with strong agreement on needs for guidelines around privacy, transparency, consent, and mitigating bias. While initial steps have been taken, major challenges include lack of uniform standards, resource constraints, rapid technology changes, staff training gaps, and difficulties verifying AI vendors' data practices. Key recommendations emphasize developing clear policies prioritizing user consent and data transparency, verifying vendor practices, regular staff training, assessing risks, gathering patron feedback, and cross-institutional collaboration on best practices. Adequate resources and measures safeguarding patron privacy while benefiting from AI capabilities are vital for promoting ethical public AI chatbot use in libraries.",Journal of Electronic Resources Librarianship,v36 n4 p257-270 2024,10.1080/1941126X.2024.2414706,http://eric.ed.gov/?id=EJ1472362,Librarian Attitudes; Privacy; Ethics; Artificial Intelligence; Academic Libraries; Foreign Countries; Private Colleges; Users (Information); Laws; Library Policy; Information Security; Best Practices; Barriers; Library Services; Computer Use,English,Journal Articles; Reports - Research
EJ1461194,AI in Higher Education: Risks and Opportunities from the Academician Perspective,Miray Dogan; Arda Celik; Hasan Arslan,1286,"This research investigates how artificial intelligence (AI) influences higher education, specifically exploring the perspectives of academicians regarding associated risks and opportunities. The study is aimed at the implementation of AI within university settings and its impact on both educators and students. Given the swift integration of AI, notably the widespread adoption of generative AI in higher education, the article emphasises AI's ability to collect detailed data, providing a deeper understanding of academicians' learning experiences. This, in turn, enables personalised support, allowing academicians to respond more effectively to students' needs and improve the overall educational process. Moreover, the research highlights AI's potential to proactively identify students at risk of failure, offering academicians a comprehensive view for more effective assessment. On the other hand, these advantages and the growing dependence on technology pose challenges, including reduced interaction between academicians and students, shifts in workforce dynamics, concerns about student privacy and disparities in technology access. Acknowledging these issues, the study underscores the importance of preparing academicians and students for the evolving landscape of higher education shaped by AI. It stresses the need for proactive measures to navigate these changes effectively, as they are inevitable. The findings of this study are significant for the field of higher education, as they provide a clear and critical assessment of AI's transformative potential and advocate for proactive measures to navigate the changes effectively.",European Journal of Education,v60 n1 e12863 2025,10.1111/ejed.12863,http://eric.ed.gov/?id=EJ1461194,Artificial Intelligence; Technology Uses in Education; Computer Software; Access to Internet; Privacy; Higher Education; College Faculty; College Students; Risk; Learning Experience; Faculty Development; Student Needs; At Risk Students; Academic Failure; Identification; Educational Benefits; Teacher Student Relationship; Labor Force; Social Change; Educational Change; Teacher Attitudes,English,Journal Articles; Reports - Research
EJ1426881,Research-to-Resource: ChatGPT as a Tool in Music Education Research,Debbie Rohwer,2024,"In this research-to-resource article, I introduce possible uses of ChatGPT, an artificial intelligence chatbot developed by OpenAI, for music education research settings. I discuss the impacts of artificial intelligence on education environments and highlight uses of ChatGPT as a tool, including the role of ChatGPT in information gathering, literature review assistance, research design conceptualization, statistical analysis support, research proposal review, and research publication support. I emphasize the importance of human expertise in filling knowledge gaps, detecting incomplete information, and using creative and critical thinking. While acknowledging concerns regarding ethics and plagiarism, I realize the unique qualities of human researchers and the need for purposeful mentoring and training on using artificial intelligence tools for appropriate tasks.",Update: Applications of Research in Music Education,v42 n3 p4-7 2024,10.1177/87551233231210875,http://eric.ed.gov/?id=EJ1426881,Artificial Intelligence; Technology Uses in Education; Natural Language Processing; Music Education; Educational Research; Research Design; Editing; Ethics; Research Tools; Vignettes,English,Journal Articles; Reports - Descriptive
ED652923,Artificial Intelligence in Health Professions Education: Proceedings of a Workshop,Patricia A. Cuff; Erin Hammers Forstag,2023,"The National Academies Global Forum on Innovation in Health Professional Education hosted a multi-day workshop series in March and April 2023 to explore the potential of artificial intelligence (AI) in health professions education. Speakers at the workshops provided background on AI; discussed the social, cultural, policy, legal, and regulatory considerations to integrating AI into health care and training; considered the skills health professionals will need as educators and providers to effectively use AI in practice; and explored needs for educating the next generation of health workers. Speakers took consideration of the bias, burden, health equity concerns that introducing AI into clinical education would bring. This Proceedings of a Workshop summarizes the discussions held during the workshop. [Patricia A. Cuff and Erin Hammers Forstag served as Rapporteurs. Contributors include Global Forum on Innovation in Health Professional Education; Board on Global Health; Health and Medicine Division. Numerous organizations sponsored this work and the full list can be seen in the document.]",National Academies Press,,,http://eric.ed.gov/?id=ED652923,Health Personnel; Allied Health Occupations Education; Artificial Intelligence; Technology Integration; Health Services; Technology Uses in Education,,Books; Collected Works - Proceedings
EJ1481236,Integration of Generative Artificial Intelligence (Gen AI) in Academic Research: Perceptions of Aspiring Educational Leaders,Daryl Ann Borel; Janice L. Taylor,2025,"As aspiring educational leaders, principal candidates must understand the widespread impact of generative artificial intelligence (Gen AI) in education. This qualitative phenomenological study explored the perceptions of aspiring educational leaders regarding Gen AI in academic research, highlighting the ethical concerns and challenges they perceive, revealing potential opportunities for AI integration in education, and assessing how these perceptions may influence their future leadership practices. The theory guiding this study was the distributed cognition theory, as it shows the dynamics of human cognition and AI cognition, making it possible to understand the perceptions of aspiring educational leaders regarding Gen AI integration in academic research. By examining these aspects, the research provided insights into how aspiring educational leaders might approach and implement AI technologies in academic research and education contexts. The research was conducted through a reflection assignment at the end of an introductory research course. The reflection prompts included demographic and background information, perceptions of the ethical use of Gen AI tools, the role of Gen AI tools as research assistants, the effectiveness and challenges related to using Gen AI tools and leveraging Gen AI's potential in education as an aspiring educational leader. The archived reflection data were analyzed using a qualitative phenomenological design method. The study sought to provide insights that could inform professional development, strategies for technological integration, and institutional approaches to Gen AI adoption in academic research courses. The research highlighted how emerging educational leaders perceive Gen AI's role in academic research and educational settings, moving beyond surface-level assessments to understand the complex interplay of technological, pedagogical, and personal factors.",School Leadership Review,v20 n1 Article 11 2025,,http://eric.ed.gov/?id=EJ1481236,Technology Uses in Education; Artificial Intelligence; Man Machine Systems; Natural Language Processing; Administrator Education; Educational Research; Graduate Students; Student Attitudes; Ethics,English,Journal Articles; Reports - Research
EJ1485471,Harnessing AI in School Counselling: Exploring the Potential of ChatGPT for Student Support,Ahmad Al-shraifin; Yousef Wardat; Rommel AlAli; Khaled Al-Saud,2025,"Background/purpose: This study explores the extent to which ChatGPT, an AI-powered large language model, can support school counseling services in addressing students' academic, social, and emotional needs, considering student AI literacy and adoption. It investigates ChatGPT's role in assisting counselors, delivering personalized guidance, ensuring 24/7 availability, and addressing ethical considerations. Materials/Methods: For evaluating its effectiveness in school counseling, the study employed ChatGPT for role-play simulations of interactions and analysis of the literature already published on AI in education. Based on studies concerning technology use in education, the scope of the study included five crucial areas: response time, counselor assistance, tailored student support, ethics, and engagement dimensions, AI literacy, and adoption hurdles. Results: As the study has shown, ChatGPT is capable of providing students tailored recommendations and streamlining office tasks so that the counselors can devote themselves to more complex tasks. Immediate support, especially during times of crisis, is also provided through the AI model's round-the-clock availability. However, effective use depends on students' AI literacy, with training needed to improve prompt engineering skills, and adoption requires user-friendly interfaces and awareness campaigns. Limitations include potential biases in AI responses, data privacy risks, and the necessity for human oversight to maintain empathetic, individualized care. Conclusion: ChatGPT offers significant potential as a supplementary tool in school counseling, enhancing efficiency and accessibility. By addressing student AI literacy and adoption barriers through training and clear communication, its impact can be optimized. However, ethical challenges, including privacy and bias, require careful management. Human counselors remain essential for nuanced, empathetic support. Future research should investigate long-term impacts and establish ethical guidelines for AI integration in educational settings.",Educational Process: International Journal,v18 Article e2025434 2025,,http://eric.ed.gov/?id=EJ1485471,Artificial Intelligence; School Counseling; Program Effectiveness; School Counselors; Technology Uses in Education; Technological Literacy; Barriers; Ethics; Access to Health Care,English,Journal Articles; Reports - Research
EJ1486314,When and How Biases Seep In: Enhancing Debiasing Approaches for Fair Educational Predictive Analytics,Lin Li; Namrata Srivastava; Jia Rong; Quanlong Guan; Dragan Gaševic; Guanliang Chen,2025,"The use of predictive analytics powered by machine learning (ML) to model educational data has increasingly been identified to exhibit bias towards marginalized populations, prompting the need for more equitable applications of these techniques. To tackle bias that emerges in training data or models at different stages of the ML modelling pipeline, numerous debiasing approaches have been proposed. Yet, research into state-of-the-art techniques for effectively employing these approaches to enhance fairness in educational predictive scenarios remains limited. Prior studies often focused on mitigating bias from a single source at a specific stage of model construction within narrowly defined scenarios, overlooking the complexities of bias originating from multiple sources across various stages. Moreover, these approaches were often evaluated using typical threshold-dependent fairness metrics, which fail to account for real-world educational scenarios where thresholds are typically unknown before evaluation. To bridge these gaps, this study systematically examined a total of 28 representative debiasing approaches, categorized by the sources of bias and the stage they targeted, for two critical educational predictive tasks, namely forum post classification and student career prediction. Both tasks involve a two-phase modelling process where features learned from upstream models in the first phase are fed into classical ML models for final predictions, which is a common yet under-explored setting for educational data modelling. The study observed that addressing local stereotypical bias, label bias or proxy discrimination in training data, as well as imposing fairness constraints on models, can effectively enhance predictive fairness. But their efficacy was often compromised when features from upstream models were inherently biased. Beyond that, this study proposes two novel strategies, namely Multi-Stage and Multi-Source debiasing to integrate existing approaches. These strategies demonstrated substantial improvements in mitigating unfairness, underscoring the importance of unified approaches capable of addressing biases from various sources across multiple stages.",British Journal of Educational Technology,v56 n6 p2478-2501 2025,10.1111/bjet.13575,http://eric.ed.gov/?id=EJ1486314,Bias; Attitude Change; Prediction; Learning Analytics; Social Bias; Computer Mediated Communication; Social Media; Stereotypes; Labeling (of Persons),English,Journal Articles; Reports - Research
ED676389,An Agentic AI-Enhanced Curriculum Framework for Rare Earth Elements from K-12 to Veteran Training for Educators and Policy Makers,Satyadhar Joshi,2025,"This paper presents a comprehensive framework for AI-enhanced curriculum development in rare earth elements (REE) education, addressing critical workforce gaps across K-12, higher education, and veteran transition programs. As global demand for critical minerals escalates amid geopolitical tensions and supply chain vulnerabilities, we propose an integrated educational approach that bridges artificial intelligence with traditional geosciences. Our research analyzes current initiatives, identifies curriculum gaps, and develops scalable AI-enhanced learning models that combine theoretical knowledge with practical applications. The framework encompasses personalized learning systems, virtual reality simulations, and adaptive assessment tools to prepare diverse learner populations for careers in the critical minerals sector. We introduce multiple architectures including an integrated AI platform for the REE value chain, multi-agent systems for mineral exploration, circular economy models for sustainability, and supply chain resilience frameworks. Quantitative analysis demonstrates significant improvements in exploration efficiency, materials discovery timelines, and educational outcomes through AI implementation. The paper also addresses implementation challenges, ethical considerations, and provides strategic recommendations for policy support and investment. This educational framework supports national security objectives while creating sustainable career pathways in an increasingly vital industry, ultimately contributing to domestic workforce development and supply chain resilience in the critical minerals sector.",Online Submission,,,http://eric.ed.gov/?id=ED676389,Artificial Intelligence; Technology Uses in Education; Curriculum Development; College Science; Technology Integration; Earth Science; Individualized Instruction; Computer Simulation; Mineralogy; STEM Careers; Sustainability; Ethics; National Security; Career Pathways; Labor Force Development; Economic Impact,,Reports - Evaluative
EJ1461607,A Qualitative Descriptive Analysis on Generative Artificial Intelligence: Bridging the Gap in Pedagogy to Prepare Students for the Workplace,Andrea L. Irish; Michele W. Gazica; Vincent Becerra,2025,"Generative artificial intelligence (Gen AI) has emerged as a transformative tool in higher education, widely adopted by both students and faculty for tasks ranging from writing to coding. Despite its growing usage, concerns over academic integrity and its long-term impact on learning persist. While educational institutions are developing policies to guide responsible Gen AI use, these measures often fail to prepare students for the realities of workplace applications. This qualitative study explores the gap between academic and professional usage of Gen AI through structured interviews with two groups: 20 faculty members and 20 industry professionals. Descriptive analysis of the data revealed a significant disconnect between pedagogical and industry practices, potentially leaving students underprepared for workplace demands. Faculty noted Gen AI's ability to assist in course-specific assignments but expressed concerns about over-reliance and ethical implications. Industry professionals emphasized its role in increasing efficiency through technical documentation, data processing, and decision-making, while identifying challenges like data security and ethical use. To address these issues, the study recommends a systemic approach that integrates hands-on Gen AI training, ethical instruction, and industry-aligned curricula into higher education. This approach includes embedding AI education into general education requirements and faculty development programs to ensure comprehensive preparedness. Additionally, collaborative projects, internships, and strategic partnerships with industry and accrediting bodies are essential to aligning curricula with workforce demands. Together, these efforts can equip students with the technical skills and ethical awareness needed to navigate and contribute effectively to AI-driven workplaces.",Discover Education,v4 Article 48 2025,10.1007/s44217-025-00435-4,http://eric.ed.gov/?id=EJ1461607,Artificial Intelligence; Educational Technology; Technology Uses in Education; College Faculty; Professional Personnel; Industry; Training; Ethics; Faculty Development; School Business Relationship; Partnerships in Education; Alignment (Education); Teacher Attitudes; Job Skills,English,Journal Articles; Reports - Research
EJ1346958,"Education for AI, ""Not"" AI for Education: The Role of Education and Ethics in National AI Policy Strategies","Schiff, Daniel",2022,"As of 2021, more than 30 countries have released national artificial intelligence (AI) policy strategies. These documents articulate plans and expectations regarding how AI will impact policy sectors, including education, and typically discuss the social and ethical implications of AI. This article engages in thematic analysis of 24 such national AI policy strategies, reviewing the role of education in global AI policy discourse. It finds that the use of AI in education (AIED) is largely absent from policy conversations, while the instrumental value of education in supporting an AI-ready workforce and training more AI experts is overwhelmingly prioritized. Further, the ethical implications of AIED receive scant attention despite the prominence of AI ethics discussion generally in these documents. This suggests that AIED and its broader policy and ethical implications--good or bad--have failed to reach mainstream awareness and the agendas of key decision-makers, a concern given that effective policy and careful consideration of ethics are inextricably linked, as this article argues. In light of these findings, the article applies a framework of five AI ethics principles to consider ways in which policymakers can better incorporate AIED's implications. Finally, the article offers recommendations for AIED scholars on strategies for engagement with the policymaking process, and for performing ethics and policy-oriented AIED research to that end, in order to shape policy deliberations on behalf of the public good.",International Journal of Artificial Intelligence in Education,v32 n3 p527-563 Sep 2022,10.1007/s40593-021-00270-2,http://eric.ed.gov/?id=EJ1346958,Artificial Intelligence; Public Policy; Role of Education; Ethics; Expertise; Training,English,Journal Articles; Reports - Research
ED662179,The Transformative Potential of Artificial Intelligence: Recommendations for Student Affairs Leaders,Claire Brady,2024,"This report examines the transformative role of artificial intelligence (AI) in student affairs, demonstrating its potential to personalize student interactions, automate routine processes, and leverage data insights for informed decision-making. AI presents unprecedented opportunities to enhance the student experience. The report emphasizes essential ethical principles, such as transparency, equity, and data stewardship, guiding leaders toward responsible AI adoption. With real-world examples and a phased implementation framework, it provides actionable strategies for integrating AI as a strategic partner in promoting student success while honoring the human connections central to meaningful educational experiences. Designed to support student affairs leaders, this report serves as a guide for implementing AI in ways that advance institutional effectiveness without compromising core educational values. Beginning with an exploration of ethical considerations and the alignment of AI initiatives with strategic goals, it underscores a human-centered approach and the importance of professional development. The report then offers a structured framework for AI integration, highlighting current use cases that demonstrate early success and forecasting applications set to impact the future of student affairs. This practical, phased approach balances innovation with ethical stewardship, fostering a sustainable path for impactful AI adoption in higher education. [This report is from a collaborative partnership with Glass Half Full Consulting.",NASPA - Student Affairs Administrators in Higher Education,,,http://eric.ed.gov/?id=ED662179,Artificial Intelligence; Computer Software; Decision Making; Ethics; Student Personnel Services; Student Personnel Workers; Technology Integration; Guidelines; Strategic Planning; Professional Development; Higher Education; Educational Change; Governance,,Reports - Research
EJ1476523,Higher Education in Armenia Adopting AI and Digital Technologies: Students' Experiences and Perspectives,Gayane Tovmasyan,2025,"This paper explores the impact of digital technologies and artificial intelligence on higher education from the perspective of students at four Armenian universities. Data from in-depth interviews with 200 students and focus group discussions highlight how digital platforms and AI tools are used for academic purposes, assess student satisfaction, and identify challenges. Findings show that 83.5% of students believe their academic performance improved through digital and AI tools, with platforms like ChatGPT widely adopted. Despite this, gaps persist, including limited digital skills training and insufficient AI integration at universities. Most students predict a significant impact of AI on education in the next five years but do not want AI to replace human teachers. The study reveals significant associations between digital tool usage frequency, AI's influence on academic performance, and students' likelihood to recommend these tools. Students appreciate the benefits of increased accessibility and personalised learning but raise concerns about technical issues, data privacy, and reduced human interaction. The study highlights the need for further integration of AI-driven tools such as AI-assisted teaching, chatbots for 24/7 support, virtual labs, augmented reality tools, and AI-based mental health monitoring. These insights can guide universities in enhancing education through digital and AI technologies.",Issues in Educational Research,v35 n2 p798-817 2025,,http://eric.ed.gov/?id=EJ1476523,Foreign Countries; College Students; Educational Technology; Technology Uses in Education; Artificial Intelligence; Student Experience; Student Satisfaction; Barriers; Academic Achievement; Technological Literacy; Technology Integration,English,Journal Articles; Reports - Research
EJ1457300,Assessing the Readiness and Attitudes of Nigerian Teacher Educators towards Adoption of Artificial Intelligence in Educational Settings,Eke Ogbu Eke,2024,"This study investigated readiness and attitudes of Nigerian teacher educators towards adoption of Artificial intelligence (AI) in educational. The population of the study included teacher educators from various educational institutions in Nigeria, and a sample size of 250 participants was used. The study utilized four research questions to explore the familiarity, attitudes, and perceived barriers related to AI adoption. The researchers employed a survey instrument to collect data, which was validated for reliability using Cronbach's alpha test. The results showed a high level of readiness and positive attitudes among the Nigerian teacher educators towards the adoption of AI-powered educational tools, such as personalized learning platforms, automated grading systems, and virtual tutors. The findings highlighted the teacher educators' recognition of the potential benefits of AI in addressing educational challenges, as well as their confidence in integrating AI-driven automated grading systems into their teaching practices. However, the study also identified perceived barriers, including inadequate infrastructure, insufficient training, and ethical concerns, which need to be addressed to ensure successful AI integration. One of the key recommendations from the study is to implement comprehensive training and professional development programs for Nigerian teacher educators, focusing on the practical implementation of AI-powered educational tools. This will enhance their confidence, competence, and ability to effectively integrate these technologies into their teaching practices.",Journal of Educational Technology and Online Learning,v7 n4 p473-487 2024,,http://eric.ed.gov/?id=EJ1457300,Readiness; Teacher Attitudes; Teacher Educators; Artificial Intelligence; Adoption (Ideas); Technology Integration; Foreign Countries; Faculty Development; Barriers; Positive Attitudes; Learning Management Systems; Ethics,English,Journal Articles; Reports - Research
EJ1457775,Using Large Language Models for Content Creation Impacts Online Learning Evaluation Outcomes,Georg Winder; Steve Bass; Dustin Schiele; Josef Buchner,2024,"The rising demand for high-quality, timely content for online and blended learning environments presents significant challenges for instructional designers, particularly in managing resource-intensive tasks such as video production and image sourcing. This study investigates the impact of using artificial intelligence (AI), specifically large language models (LLMs), on key evaluation criteria for self-organized, online, and blended learning modules. Using the case of 'aprendo. ch,' a professional development platform provided free of charge to teachers in the canton of St. Gallen that has recently implemented AI-enhanced workflows, we analyze how AI-enhanced content affects module evaluation outcomes, including perceived learning quality, learner satisfaction, and instructional design efficiency. Statistical analyses indicate significant differences between AI-enhanced and traditional modules, with AI-enhanced modules receiving higher evaluations in module structure, competency development, and learner recommendation. Furthermore, we discuss ethical considerations, such as data bias and content accuracy, and provide practical recommendations for the responsible integration of AI in educational design to balance efficiency with educational quality.",International Journal on E-Learning,v23 n3 p305-318 2024,,http://eric.ed.gov/?id=EJ1457775,Artificial Intelligence; Technology Uses in Education; Electronic Learning; Educational Objectives; Blended Learning; Faculty Development; Course Content; Educational Quality; Satisfaction; Design; Efficiency; Ethics; Foreign Countries; Teacher Attitudes; Program Evaluation,English,Journal Articles; Reports - Research
EJ1480793,Integrating AI to Address Generational Characteristics and Educational Needs,Antonina Andreeva; Evgenia Tuchkevich,2025,"In contemporary higher education, the master's level plays a critical role in developing high-level professionals, particularly among Generation-Z students. This stage is marked by significant psychological, social, and professional development, requiring innovative educational strategies that align with the unique traits of this digital-native cohort. Integrating artificial intelligence (AI) technologies, such as adaptive-learning systems, intelligent tutoring, and automated-feedback mechanisms, offers transformative potential to address these needs. This study investigates the intersection of generational characteristics and AI integration in master's education through a convergent parallel mixed-methods design, combining quantitative surveys with qualitative interviews of 300 master's students across various disciplines. The findings reveal predominantly positive attitudes toward AI, with 78% of students recognizing its ability to enhance personalized learning and engagement. However, concerns about data privacy (54%) and reduced human interaction (48%) highlight the need for an ethical and balanced implementation. Grounded in constructivist and activity theories, this research underscores the potential of AI to foster autonomy, self-determination, and personalized educational experiences while addressing generational expectations for immediacy and interactivity. Practical recommendations are provided for educators and policymakers to implement AI effectively, ensuring that it supplements human-centred teaching practices. These insights contribute to the global discourse on AI integration in higher education, and its implications for enhancing lifelong learning and professional growth.",Journal of Teaching and Learning,v19 n3 p34-48 2025,,http://eric.ed.gov/?id=EJ1480793,Artificial Intelligence; Technology Uses in Education; Technology Integration; Masters Programs; Educational Needs; Generational Differences; Graduate Students; Student Attitudes; Personal Autonomy; Self Determination; Lifelong Learning,English,Journal Articles; Reports - Research
ED663227,A Phenomenological Study: Teacher Perceptions of Generative Artificial Intelligence and Its Impact on Teaching and Learning in High Schools,Jill Manczka,2024,"Throughout history, artificial intelligence (AI) has impacted various aspects of human life and professional industries, including the field of education, by mimicking human behaviors and tasks to increase productivity and efficiency (Grudin et al., 2023; Haenlein & Kaplan, 2019). Generative AI is a form of AI using deep learning to quickly generate text, images, music, and endless types of content based on datasets training it. The training data is gathered from a corpus of information on the internet (Javaid et al., 2023; Ngo, 2023; Rahman & Watanobe, 2023). In 2022, generative AI became accessible to individuals of all ages and backgrounds when the company OpenAI launched ChatGPT works (Javaid et al., 2023; Ngo, 2023; Rahman & Watanobe, 2023). Educators began to use generative AI to plan instruction, create materials, and complete daily tasks more efficiently (Alabool, 2023; Fisk, 2023; Rahman & Watanobe, 2023). Students began to use generative AI to assist with schoolwork, studying, proofreading, and creating content for school (Hosseini et al., 2023; Ray, 2023b). Concerns about quality, accuracy, bias, academic integrity, and data security surfaced among educators as the use of generative AI increased (Abramski et al., 2023; Eke, 2023; Perkins, 2023; Ray, 2023b; Su & Yang, 2023). As educators navigated the opportunities and pitfalls of generative AI in teaching and learning, a need to understand educators' perspectives of the phenomenon became necessary. This study, therefore, holds significant value in providing insight into the experiences and perceptions of secondary teachers on using generative AI as a tool for teaching and learning. This qualitative, phenomenological study explored the perceptions of secondary teachers on using generative AI as a tool for teaching and learning. The researcher conducted semi-structured interviews with ten teachers of core subjects (science, social studies, and English language arts) in grades 9-12 from western Pennsylvania schools, seeking insight into experiences with and perceptions of generative AI in schools focused on five research questions: (a) How do teachers of students in grades 9-12 core content courses see generative AI being used in schools in Western Pennsylvania? (b) What do core content teachers of students in grades 9-12 believe are the benefits of using generative AI in the teaching and learning process? (c) What concerns do core content teachers of students in grades 9-12 have regarding using generative AI in schools? (d) How do core content teachers of students in grades 9-12 perceive the level of preparation and guidance from school leaders on the use of generative AI in their school? (e) How do teachers perceive the impact of generative AI on students? The key findings noted teachers used generative AI to create comprehensive materials and communicate with stakeholders. Additionally, the findings indicated teachers are concerned about academic integrity, the quality of AI output, and the need generative AI presented to change classroom instructional practices. The key findings also revealed teachers need more targeted professional development on generative AI related to teaching and learning along with guidance from administration and policy and procedures for generative AI usage. The final key findings expressed concerns about students using generative AI to minimize effort while reducing the authenticity of learning experiences. These finding are supported by existing research. Additionally, the key findings support the notion that generative AI can support effective instruction when teachers are presented with targeted professional development, policies, and procedures and develop strategies that involve teaching effective methods to check the accuracy of AI output along with tools to detect academic integrity issues partnered with quality instruction about the importance of academic integrity. [The dissertation citations contained here are published with the permission of ProQuest LLC. Further reproduction is prohibited without permission. Copies of dissertations may be obtained by Telephone (800) 1-800-521-0600. Web page: http://www.proquest.com/en-US/products/dissertations/individuals.shtml.]",ProQuest LLC,"Ed.D. Dissertation, Point Park University",,http://eric.ed.gov/?id=ED663227,Teacher Attitudes; Artificial Intelligence; Computer Software; Technology Uses in Education; Teaching Methods; Computational Linguistics; Internet; Integrity; Instructional Effectiveness; Faculty Development; Pedagogical Content Knowledge; Technological Literacy; Educational Quality; Learning Experience; Authentic Learning; Guidance,,Dissertations/Theses - Doctoral Dissertations
EJ1488670,"Generative AI in English Language Teaching: Students' Voices, Teachers' Reactions, and Needs",Rhian Webb; Ferah Senaydin,2025,"Due to the rapid emergence and use of generative artificial intelligence (GenAI) by English as a foreign language (EFL) students in higher education (HE), further research is required to understand English language teaching (ELT) teachers' training needs to effectively manage digitally enhanced teaching and learning. This study identifies teachers' needs by investigating Turkish ELT teachers' reactions to their students' self-reported GenAI usage. Our transcendental phenomenological research design ensured minimal author bias from the thematically analysed, qualitative, interview data from 21 Turkish undergraduate EFL students (B1-C1 level) and six Turkish ELT teachers. Analysis has revealed that students used ChatGPT (version 3.5) as a human collaborator to build content, clarify tasks, be a critical friend, organise ideas, enhance language, and obtain feedback, which they found motivating. However, teachers' reactions to their students' usage were inconsistent and exposed a need for unified teacher identity development that is shaped by GenAI literacy training and supported by institutional policies that address GenAI integration into curriculum design and assessment practices.",TESL-EJ,v29 n3 2025,,http://eric.ed.gov/?id=EJ1488670,Artificial Intelligence; Technology Uses in Education; English (Second Language); Language Teachers; Second Language Instruction; Student Needs; Teacher Education; Foreign Countries; Undergraduate Students,English,Journal Articles; Reports - Research
ED674581,How to Use Conversational AI Chatbots in English Language Teaching/Learning: Developing Linguistic Competencies and Skills and Supporting EFL Teachers' Professional Development,Mahmoud M. S. Abdallah,2025,"The integration of conversational artificial intelligence (AI) chatbots into English as a Foreign Language (EFL) education represents a transformative technological advancement with significant potential for enhancing both student learning outcomes and teacher professional development. This comprehensive review examines how AI chatbots can be effectively utilized to develop linguistic competencies across speaking, listening, reading, and writing skills while supporting EFL teachers' professional growth. Drawing from recent empirical research and theoretical frameworks, this article provides evidence-based guidance for educators, administrators, and researchers seeking to implement chatbot technology in language education contexts. The analysis reveals that AI chatbots, particularly advanced systems like ChatGPT, can provide personalised learning experiences, immediate feedback, and scalable educational support that addresses traditional challenges in EFL instruction. Key findings indicate significant improvements in learners' speaking fluency, writing proficiency, and willingness to communicate when chatbots are integrated thoughtfully into pedagogical practices. For teachers, AI chatbots serve as valuable tools for content creation, assessment development, and instructional strategy enhancement, while also supporting their own language proficiency development. However, successful implementation requires careful attention to pedagogical integration, ethical considerations, and maintaining balanced human-AI interaction. This article presents a comprehensive framework for chatbot integration that encompasses theoretical foundations, practical implementation strategies, specific functional applications, and professional development approaches. The evidence suggests that when properly implemented with appropriate teacher training and pedagogical support, Conversational AI chatbots can significantly enhance EFL education quality and accessibility while preparing both teachers and students for increasingly AI-integrated educational futures.",Online Submission,,,http://eric.ed.gov/?id=ED674581,Artificial Intelligence; Teaching Methods; Computer Software; Feedback (Response); Technology Integration; Language Fluency; Writing Skills; Outcomes of Education; Faculty Development; Language Proficiency; Barriers; Second Language Learning; Second Language Instruction; Evidence Based Practice; Technological Literacy; Pedagogical Content Knowledge; Ethics; Language Teachers; Teacher Attitudes; Administrator Attitudes; Learning Theories; English (Second Language),,Information Analyses
EJ1486599,Empowering Educators for the AI Revolution: Bridging Gaps in Preparedness and Equity in Classrooms,Samra Maqbool; Hafiz Muhammad Ihsan Zafeer; Sufyan Maqbool; Ayesha Tariq; Amjad Islam Amjad,2025,"The integration of Artificial Intelligence (AI) in education offers transformative opportunities for personalized learning and efficient instructional practices. However, the successful adoption of AI in classrooms is contingent upon teachers' preparedness, technological literacy, and understanding of ethical considerations. This study examined how these factors alongside professional development and access to technology influence the effective implementation of AI tools in classrooms. A quantitative research design involved 210 teachers from nine schools in Punjab, Pakistan, was employed, utilizing structured questionnaires to collect data on these variables. The findings revealed significant positive correlations between technological literacy, professional development, and access to technology with the effective use of AI tools. Ethical considerations, while moderately correlated, showed lower statistical significance, underscoring the need for more focus in this area. Access to technology emerged as the strongest predictor of successful AI implementation, highlighting disparities in infrastructure as a critical barrier, particularly in under resourced schools. The study underscores the necessity of holistic strategies to empower educators through targeted training, ethical literacy, and equitable resource allocation. By addressing these factors, schools can unlock AI's potential to enhance teaching and learning while promoting inclusivity and innovation in education. The findings provide actionable recommendations for policymakers and educators to bridge gaps in preparedness and equity.",International Journal of Technology in Education,v8 n4 p1129-1145 2025,,http://eric.ed.gov/?id=EJ1486599,Artificial Intelligence; Technology Uses in Education; Teacher Competencies; Readiness; Technology Integration; Technological Literacy; Ethics; Faculty Development; Access to Computers; Program Implementation; Correlation; Foreign Countries; Elementary Secondary Education,English,Journal Articles; Reports - Research
EJ1482626,FairSYN-Edu a Diffusion-Based Model for Fair and Private Educational Data Synthesis,Kadir Kesgin,2025,"The increasing demand for privacy-preserving, ethically aligned synthetic data generation in education has highlighted the limitations of existing tabular data generators. Traditional approaches often sacrifice fairness or privacy in pursuit of predictive accuracy, rendering them unsuitable for high-stakes academic settings. In this paper, we propose FairSYN-Edu, a novel diffusion-based synthetic data generation framework designed for educational data. By integrating adversarial debiasing and differentially private training into the generative process, FairSYN-Edu jointly optimizes utility, fairness, and privacy. We evaluate our approach on three real-world educational datasets spanning MOOC, K-12 tutoring, and LMS environments. Experimental results demonstrate that FairSYN-Edu achieves significantly lower demographic disparities, maintains competitive predictive performance (RMSE = 0.402), and provides moderate resistance to membership inference attacks (AUC = 0.705). Ablation studies, error gap analysis, and SHAP-based interpretability evaluations confirm the robustness and ethical reliability of our method. We release the complete implementation, synthetic benchmark suite, and documentation to promote reproducibility and responsible AI practices in education.",Discover Education,v4 Article 336 2025,10.1007/s44217-025-00743-9,http://eric.ed.gov/?id=EJ1482626,Synthesis; Data; Data Science; Data Use; Artificial Intelligence; Ethics; Privacy,English,Journal Articles; Reports - Research
EJ1428443,"Knowledge, Attitudes, and Perceived Ethics Regarding the Use of ChatGPT among Generation Z University Students",Benicio Gonzalo Acosta-Enriquez; Marco Agustín Arbulú Ballesteros; Carmen Graciela Arbulu Perez Vargas; Milca Naara Orellana Ulloa; Cristian Raymound Gutiérrez Ulloa; Johanna Micaela Pizarro Romero; Néstor Daniel Gutiérrez Jaramillo; Héctor Ulises Cuenca Orellana; Diego Xavier Ayala Anzoátegui; Carlos López Roca,2024,"Artificial intelligence (AI) has been integrated into higher education (HE), offering numerous benefits and transforming teaching and learning. Since its launch, ChatGPT has become the most popular learning model among Generation Z college students in HE. This study aimed to assess the knowledge, concerns, attitudes, and ethics of using ChatGPT among Generation Z college students in HE in Peru. An online survey was administered to 201 HE students with prior experience using the ChatGPT for academic activities. Two of the six proposed hypotheses were confirmed: Perceived Ethics (B = 0.856) and Student Concerns (B = 0.802). The findings suggest that HE students' knowledge and positive attitudes toward ChatGPT do not guarantee its effective adoption and use. It is important to investigate how attitudes of optimism, skepticism, or apathy toward AI develop and how these attitudes influence the intention to use technologies such as the ChatGPT in HE settings. The dependence on ChatGPT raises ethical concerns that must be addressed with responsible use programs in HE. No sex or age differences were found in the relationship between the use of ChatGPTs and perceived ethics among HE students. However, further studies with diverse HE samples are needed to determine this relationship. To promote the ethical use of the ChatGPT in HE, institutions must develop comprehensive training programs, guidelines, and policies that address issues such as academic integrity, privacy, and misinformation. These initiatives should aim to educate students and university teachers on the responsible use of ChatGPT and other AI-based tools, fostering a culture of ethical adoption of AI to leverage its benefits and mitigate its potential risks, such as a lack of academic integrity.",International Journal for Educational Integrity,v20 Article 10 2024,10.1007/s40979-024-00157-4,http://eric.ed.gov/?id=EJ1428443,Student Attitudes; Ethics; Knowledge Level; Age Groups; College Students; Artificial Intelligence; Foreign Countries; Technology Uses in Education; Technology Integration,English,Journal Articles; Reports - Research
EJ1461026,Secondary School Teachers' Perspectives on GenAI Proliferation: Generating Advanced Insights,Rahul Kumar; Sunaina Sharma,2025,"The proliferation of generative artificial intelligence (GenAI) technologies has significantly impacted the educational sector, prompting a re-evaluation of teaching, learning, and assessment practices. This study explores the perceptions of Ontario secondary school teachers regarding the challenges and opportunities presented by GenAI. Using a qualitative research method, 17 high school teachers were interviewed to understand their views on GenAI integration and its implications for academic integrity. The findings reveal three critical areas for integrating GenAI in education: ""generating people"" through professional development and ethical training for educators, ""generating programs"" by designing transparent and purpose-driven initiatives, and ""generating policies"" through the creation of clear, adaptable governance frameworks. Together, these pillars highlight the collaborative work needed to harness GenAI's potential while ensuring ethical and equitable practices in secondary education. These themes are a subset of invitational education and highlight the need for comprehensive training for teachers, the development of transparent guidelines and ethical practices, and the establishment of robust policies to support the integration of GenAI in education. The study emphasizes the importance of collaboration among educators, administrators, and other stakeholders to effectively navigate the evolving landscape of GenAI-driven educational environments effectively. By addressing these pillars, academic institutions can harness the transformative potential of GenAI while maintaining the integrity and quality of education. This research provides valuable insights into the evolving role of teachers and the necessity for strategic planning, professional development, and policy frameworks to optimize the benefits of GenAI in secondary education.",International Journal for Educational Integrity,v21 Article 7 2025,10.1007/s40979-025-00180-z,http://eric.ed.gov/?id=EJ1461026,Teacher Attitudes; Artificial Intelligence; Technology Uses in Education; Foreign Countries; High School Teachers; Technology Integration; Integrity; Ethical Instruction; Teacher Education; Faculty Development; Ethics; Teacher Collaboration; Stakeholders; Educational Change; Educational Quality; Teacher Role; Strategic Planning; Educational Policy,English,Journal Articles; Reports - Research
ED650857,Graduate Student Investigator: Best Practices for Human Research Protections within Online Graduate Research,Robin Throne; Michalina Hendon; James Kozinski,2023,"This paper presents the best practices used by institutional review boards (IRBs) and human research protections programs (HRPPs) to prepare online graduate student investigators for human research protections specific to research within online graduate degree programs or where research supervisors are not proximal to graduate student investigators and their research protocols. In recent years, advances in artificial intelligence (AI), machine learning (ML), and other data mining/scraping forms have adversely impacted individual privacy and the unintended sharing of personally identifiable information (PII). With this growth of ubiquitous digital technologies, such as AI, ML, and data mining/scraping, used across online graduate degree programs, specialized training and preparation are needed to best prepare graduate student researchers for human research protections involving data with PII. Implications for IRBs and HRPPs are also addressed in this rapidly evolving climate, with recommendations for the design of online graduate degree programs that include graduate research and the best strategies to prepare online graduate student investigators for human research protections. [This paper was published in: ""1st Annual Virtual Fall National Conference on Creativity, Innovation, and Technology (NCCiT) Proceedings,"" November 15-16, 2023, pp. 84-108.]",Online Submission,"Paper presented at the Annual Virtual Fall National Conference on Creativity, Innovation, and Technology (NCCiT) (1st, Virtual, Nov 15-16, 2023)",,http://eric.ed.gov/?id=ED650857,Graduate Students; Student Research; Investigations; Graduate Study; Best Practices; Research Committees; Research Administration; Ethics; Ethical Instruction; Online Courses; Supervision; Artificial Intelligence; Research Methodology; Data Collection; Privacy,,Speeches/Meeting Papers; Reports - Descriptive
EJ1461510,Comprehensive Professional Learning for Teacher Agency in Addressing Ethical Challenges of AIED: Insights from Educational Design Research,Ana Mouta; Eva María Torrecilla-Sánchez; Ana María Pinto-Llorente,2025,"Continuing professional development plays a pivotal role in creating opportunities for teachers to explore the evolving educational landscape. With the integration of Artificial Intelligence into education, these opportunities involve grasping teachers' attitudes, expectations, and pedagogical approaches, with a focus on ethical considerations. Nevertheless, existing research and professional learning opportunities often overlook the perspectives of educators on these themes. Aiming to bridge this gap, this Educational Design Research approach began with a systematic literature review, followed by a Delphi study to gather educational stakeholders' insights on the ethical concerns of using AI in education. The current study presents the research third phase. It explores findings from focus groups with educators responsible for K-12 teacher education, informing the design of a training programme that addresses ethical concerns and agency. Four groups were conducted using a semi-structured script, centred on pre-provided scenarios. Data analysis involved thematic coding using both deductive and inductive approaches, revealing key themes related to: employing AI applications in course delivery for a mindful, hands-on exploration; discussing ethical and policy frameworks with a focus on contextual needs and ""technogeographies""; addressing uncertainty, resistance, and transition; and fostering individual and collective agency regarding ethical issues through informal learning channels to build a nuanced narrative that challenges the corporate one. The study concludes by highlighting the importance of greater investment in professional development to enable educators to critically assess and reshape the values associated with education in the context of Artificial Intelligence, thereby contributing to the movement of aligning AI with our humanity.",Education and Information Technologies,v30 n3 p3343-3387 2025,10.1007/s10639-024-12946-y,http://eric.ed.gov/?id=EJ1461510,Faculty Development; Professional Continuing Education; Teacher Education; Ethics; Artificial Intelligence; Technology Uses in Education; Elementary School Teachers; Secondary School Teachers; Teacher Attitudes; Resistance (Psychology); Humanization,English,Journal Articles; Reports - Research
EJ1425480,ChatGPT in Education -- Understanding the Bahraini Academics Perspective,Amal Alrayes; Tara Fryad Henari; Dalal Abdulkarim Ahmed,2024,"This paper provides a thorough examination of the role of Artificial Intelligence (AI), particularly ChatGPT and other AI language models, in the realm of education. Drawing insights from existing literature and a novel study on educator perspectives, the paper delves into the potential advantages, ethical dilemmas, and factors shaping educators' attitudes towards AI integration in education. AI language models have the potential to revolutionize educational content creation, personalize learning experiences, and streamline assessment and feedback processes. These capabilities hold the potential to enhance teaching and learning outcomes while catering to the diverse needs of students. However, ethical concerns loom large in the adoption of AI in education. Bias in generated content is a chief concern, as it can perpetuate societal biases and lead to unfair treatment or the dissemination of inaccurate information. The solution lies in rigorous data curation to ensure equitable educational experiences for all students. Moreover, the potential for generating inappropriate or misleading content poses a significant ethical challenge, impacting students' well-being, civic understanding, and social interactions. Safeguards must be implemented to detect and rectify biased or inappropriate content, fostering inclusive and unbiased learning environments. Transparency emerges as a crucial ethical consideration. The opacity of AI models like ChatGPT makes it difficult to comprehend their decision-making processes. Enhancing model interpretability and explainability is vital for accountability and addressing embedded ethical issues. Privacy concerns related to data collection and usage are emphasized in the literature. Clear policies and guidelines must govern data collection, use, and protection, ensuring data is solely employed for educational purposes and maintaining robust data security measures. Our study expands upon these insights by exploring socio-demographic factors, motivations, and social influences affecting educators' AI adoption in higher education. These findings inform institutions on tailoring AI integration strategies, emphasizing responsible usage through training, and assessing the impact on learning outcomes. As educational institutions increasingly embrace AI, including advanced models like GPT-4, a cautious and thoughtful approach is vital. Balancing potential benefits with ethical challenges ensures that AI enhances teaching and learning while upholding fairness, equity, and accountability. In summary, this paper illuminates the potential of AI in education, accentuates ethical concerns, and highlights the significance of understanding educators' perspectives. Collaboration between educators and policymakers is essential to navigate the complexities of AI integration, ensuring that education remains a realm of equitable, efficient, and accountable learning experiences.",Electronic Journal of e-Learning,v22 n2 p112-134 2024,,http://eric.ed.gov/?id=EJ1425480,Artificial Intelligence; Technology Uses in Education; Natural Language Processing; Intention; Higher Education; Teacher Attitudes; Teaching Experience; Usability; Social Influences; Teacher Motivation; Teacher Characteristics; Age; Sex; Foreign Countries; Predictor Variables,English,Journal Articles; Reports - Research
EJ1490130,AI and VR Integration for Enhancing Ethical Decision-Making Skills and Competency of Learners in Higher Education,Roberto Gomez Tobias; Javier Armando Gonzalez Lozano; Martha Lorena Martínez Torres; Jorge Alvarez Ramírez; Giovanni Maria Baldini; Kingsley Okoye,2025,"Background: Ethical decision-making is at the core of higher education, yet case-based ethics training often lacks depth and practical judgment. This study investigates whether integrating Artificial Intelligence (AI) and Virtual Reality (VR) enhances ethical reasoning compared with conventional training. Sixty undergraduates in business and engineering were randomly assigned to a control group (traditional case-based role-play) or an experimental group (immersive training with Meta Quest 3 head-mounted displays using the VirtualSpeech platform). The research methodology was grounded on the Descriptive Decision Theory and Learning-Oriented Assessment (LOA) framework, emphasizing formative, feedback-rich learning aligned with Cognitive Load Theory, Experiential and Constructivist Learning, Dual-Process Theory, and AI-driven adaptive guidance. Results: Ethical competence was assessed pre- and post-intervention across seven dimensions: dilemma recognition, evaluation of alternatives, justification, consequence analysis, contextualization, application of principles, and stakeholder/social impact. Both groups improved significantly, but the AI/VR group showed consistently larger gains and improvement. Paired and Independent t-tests, with effect-size estimates (Cohen's d and Hedges' g), revealed large effects favoring immersive learning. The highest post-test advantages for the AI/VR group were observed in consequence analysis (t = -96.90, [delta] = 23.30, p < 0.001), evaluation of alternatives (t = -90.03, [delta] = 20.20, p < 0.001), and application of ethical principles (t = -80.57, [delta] = 20.83, p < 0.001). Minor within-group dispersion and sample homogeneity supported internal consistency and robustness of the outcomes under immersive conditions. Conclusions: Immersive, feedback-rich AI/VR training significantly outperformed traditional methods in strengthening ethical reasoning. The findings support integrating AI- and VR-based simulations into ethics curricula to enhance consequence analysis, principled reasoning, and stakeholder awareness. Future research should explore long-term effects, hybrid delivery, and broader applicability across disciplines and professional settings.",International Journal of STEM Education,v12 Article 52 2025,10.1186/s40594-025-00575-x,http://eric.ed.gov/?id=EJ1490130,Ethics; Artificial Intelligence; Computer Simulation; Decision Making; Conventional Instruction; Undergraduate Students; Business Education; Engineering Education; Competence; Program Effectiveness; Technology Uses in Education,English,Journal Articles; Reports - Research
ED677111,Reskilling the U.S. Military Workforce for the Agentic AI Era: A Framework for Educational Transformation,Satyadhar Joshi,2025,"The rapid emergence of agentic artificial intelligence (AI) systems represents a paradigm shift in military operations, demanding fundamental transformation of US military education. This paper presents a comprehensive framework for reskilling and redesigning military education to address critical workforce readiness gaps in the era of autonomous AI systems. Utilizing a mixed-methods review of defense reports, case studies, and quantitative workforce data, this paper develops a comprehensive framework for reskilling the defense force to address critical readiness gaps in the era of autonomous AI. Through analysis of current AI adoption trends, quantitative workforce assessments, and educational limitations, we identify that only 10-15% of military personnel feel adequately trained for agentic AI integration despite significant investments exceeding $600-900 million in next-generation AI capabilities. Our proposed solution features a multi-tiered educational architecture with progressive competency levels, a continuous curriculum development pipeline, and layered technology integration. The framework addresses identified skills gaps through foundational AI literacy for all personnel, operational competence for mid-career leaders, and strategic AI leadership development. Implementation strategies include phased rollout over 24-36 months, multi-stakeholder engagement models, and comprehensive assessment mechanisms. Findings demonstrate that successful agentic AI integration requires not only technical upskilling but also fundamental changes in pedagogical approaches, institutional culture, and resource allocation--with optimal distribution of 30-40% to technology infrastructure, 20-25% to faculty development, 15-20% to curriculum design, and program evaluation. This research provides actionable recommendations for military education institutions to prepare personnel for human-AI teaming, autonomous system oversight, and ethical AI application in complex operational environments. decrease medical as well as financial burden, hence improving the management of cirrhotic patients. These predictors, however, need further work to validate reliability. All results and proposals are from cited literature.",Online Submission,,,http://eric.ed.gov/?id=ED677111,Job Skills; Skill Development; Job Training; Military Personnel; Military Training; Artificial Intelligence; Labor Force Development; Technology Integration; Educational Change; Electronic Learning; Predictor Variables; Resource Allocation; Models; Curriculum Development; Career Readiness; Ethics; Governance,,Reports - Research
EJ1474462,Giving Credit Where Credit Is Due: An Artificial Intelligence Contribution Statement for Research Methods Writing Assignments,Nicole Alea Albada; Vanessa E. Woods,2025,"Background: Citation practices are fundamental to teaching scholarly writing. With the emergence of generative Artificial Intelligence (AI) technologies, students need a structured way to cite when and how these technologies are used. Objective: This paper introduces an instructor resource, an AI Contribution Statement, which provides students with an ethical and explicit framework for reporting on AI use during idea generation and writing in research methods. Method: Students were guided to create an AI Contribution Statement that reports when an AI technology was used for a research paper, what prompts were given and text generated, and how the information was incorporated into a final written product. Results: Sixty-four percent of students reported using AI assistive technologies. Of those, 33.12% reported using it more than twice, suggesting that, when allowed in a course, students' use is relatively low. Conclusion: Training students in best citation practices regarding ethical and transparent use of AI technologies is important, yet additional research is needed to understand how students are using it and how instructors can leverage this tool to foster equity. Teaching Implications: An AI Contribution Statement is an important addition to research methods teaching to create equality in technology use and student success.",Teaching of Psychology,v52 n3 p279-284 2025,10.1177/00986283241259750,http://eric.ed.gov/?id=EJ1474462,Citations (References); Technology Uses in Education; Ethics; Research Papers (Students); Best Practices; Research Methodology; Undergraduate Students; Psychology; Artificial Intelligence; Man Machine Systems; Natural Language Processing,English,Journal Articles; Reports - Research
EJ1430093,Design of a Future Scenarios Toolkit for an Ethical Implementation of Artificial Intelligence in Education,Ana Mouta; Eva María Torrecilla-Sánchez; Ana María Pinto-Llorente,2024,"In the 1970s, research on artificial intelligence in education emerged with the aim of acknowledging and accommodating the psychological aspects of the learning process. Since then, its applications have evolved and it is now used for student learning and assessment, teachers' pedagogical practice, management of educational institutions, and lifelong learning. Nevertheless, the ethical challenges of educational programmes using these systems have not been thoroughly studied. Anchored on the theoretical frame of dialogic ethics, this paper presents a section of a participatory futures research project. The goal of the research is to develop a toolkit that educators can use to ensure a smooth and ethical transition to artificial intelligence-based education while preserving the interests of educational development. This paper emphasises the need for an informed and participatory process that involves all stakeholders and begins with an expert consultation through the Delphi method, the results of which allowed the construction of eight hypothetical futures scenarios. These scenarios provide evidence that examining the ethics of using artificial intelligence systems presents an opportunity to reflect on the ethics of education as a whole. They highlight the challenge of balancing the benefits and drawbacks of such systems, especially concerning educational goals and the interplay between diverse educational actors and personal development in educational settings. The study outcomes are intended to encourage discussions on the integration of ethical artificial intelligence in education and facilitate the continuing professional development of teachers by equipping them with scenarios that can be used as a resource for training purposes.",Education and Information Technologies,v29 n9 p10473-10498 2024,10.1007/s10639-023-12229-y,http://eric.ed.gov/?id=EJ1430093,Ethics; Artificial Intelligence; Delphi Technique; Computer Software; Technology Uses in Education; Teaching Methods; Specialists; Vignettes; Educational Benefits; Faculty Development; Guides; Futures (of Society),English,Journal Articles; Reports - Research
EJ1437301,A Survey Study of Chinese Teachers' Continuous Intentions to Teach Artificial Intelligence,Ching Sing Chai; Siya Liang; Xingwei Wang,2024,"As the world is increasingly infused with artificial intelligence (AI), school teachers are beginning to acquire AI literacy and to integrate AI-related content into their teaching practices. However, research on teachers' AI competencies is still in its early stage, leaving many gaps yet to be explored. This study engaged 364 Chinese practicing teachers involved in teaching AI lessons after receiving training, employing a six-factor instrument. The survey assessed teachers' efficacies in understanding AI and teaching AI, with additional considerations of promoting ethical awareness and designing socially beneficial AI applications. In addition, teachers' continuous intention to learn AI and their attitudes toward teaching AI were measured. The survey underwent rigorous validation procedures, confirming its construct validity through confirmatory factor analysis, and demonstrating satisfactory reliabilities and convergent and discriminant validities through other statistical analyses. Structural equation modeling provided support for most of the hypotheses. Further, variance analyses indicated that high school teachers scored higher than primary and middle school teachers across all six measured factors, possibly due to the contextual demands of the university entrance examinations. Overall, the findings suggest a willingness among teachers to enhance their competencies for teaching AI, and underscore the need for increased attention on strengthening teachers' competencies to promote ethical judgement and design AI for social good. The validated survey should be a valid and reliable assessment tool for future teacher development initiatives.",Education and Information Technologies,v29 n11 p14015-14034 2024,10.1007/s10639-023-12430-z,http://eric.ed.gov/?id=EJ1437301,Foreign Countries; Artificial Intelligence; Teacher Effectiveness; Educational Technology; Teacher Competencies; Ethics; Intention; Teacher Attitudes; Elementary Secondary Education,English,Journal Articles; Reports - Research
EJ1446592,Uncovering Blind Spots in Education Ethics: Insights from a Systematic Literature Review on Artificial Intelligence in Education,Ana Mouta; Ana María Pinto-Llorente; Eva María Torrecilla-Sánchez,2024,"In the last decade, research on the use of artificial intelligence technologies in education has steadily grown. Many studies have demonstrated the potential of these technologies to improve school administration processes, enhance students' learning experiences, simplify teachers' daily tasks, and broaden opportunities for lifelong learning. However, the enthusiasm surrounding these possibilities may overshadow the ethical challenges posed by these systems. This systematic literature review is designed to explore the ethical dimensions surrounding the utilisation of these technologies within the defined timeframe (2011-2022) in the field of education. It undertakes a thorough analysis of various applications and objectives, with a particular focus on pinpointing any inherent shortcomings within the existing body of literature. The paper discusses how cultural differences, inclusion, and emotions have been addressed in this context. Finally, it explores the capacity building efforts that have been put in place, their main targets, as well as guidelines and frameworks available for the ethical use of these systems. This review sheds light on the research's blind spots and provides insights to help rethink education ethics in the age of AI. Additionally, the paper explores implications for teacher training, as educators play a critical role in ensuring the ethical use of AI in education. This review aims to stimulate ethical debates around artificial intelligence that recognise it as a non-neutral tool, and to view it as an opportunity to strengthen the debates on the ethics of education itself.",International Journal of Artificial Intelligence in Education,v34 n3 p1166-1205 2024,10.1007/s40593-023-00384-9,http://eric.ed.gov/?id=EJ1446592,Artificial Intelligence; Educational Technology; Technology Uses in Education; Ethics; Cultural Differences; Inclusion; Emotional Response; Capacity Building; Educational Research; Teacher Education,English,Journal Articles; Information Analyses
EJ1470330,Potential Societal Biases of ChatGPT in Higher Education: A Scoping Review,Ming Li; Ariunaa Enkhtur; Beverley Anne Yamamoto; Fei Cheng; Lilan Chen,2025,"Generative Artificial Intelligence (GAI) models, such as ChatGPT, may inherit or amplify societal biases due to their training on extensive datasets. With the increasing usage of GAI by students, faculty, and staff in higher education institutions (HEIs), it is urgent to examine the ethical issues and potential biases associated with this technology. This scoping review aims to elucidate how biases related to GAI in HEIs have been researched and discussed in recent academic publications. We categorized the potential biases that GAI might cause in the field of higher education. Our findings reveal that while there is meaningful scholarly discussion around bias and discrimination concerning GAI models in the AI field, most articles addressing higher education approach the issue superficially. Few articles identify specific types of bias in different higher education contexts, and there is a notable lack of empirical research. Most papers in our review focus primarily on educational and research fields related to medicine and engineering, with some addressing English education. However, there is almost no discussion regarding the humanities and social sciences. Additionally, a significant portion of the current discourse is in English and primarily addresses English-speaking contexts. To the best of our knowledge, our study is the first to categorize the potential biases that GAI might cause in the field of higher education. This review highlights the need for more in-depth studies and empirical work to understand the specific biases that GAI might introduce or amplify in educational settings, guiding the development of more ethical AI applications in higher education.",Open Praxis,v17 n1 p79-94 2025,,http://eric.ed.gov/?id=EJ1470330,Artificial Intelligence; Ethics; Technology Integration; Computer Software; Social Bias; College Faculty; College Students; Classification; Research Reports; Social Discrimination; Higher Education; Research Needs; Intellectual Disciplines,English,Journal Articles; Information Analyses
EJ1486241,Artificial Intelligence Literacy in Assessment: Empowering Pre-Service Teachers to Design Effective Exam Questions for Language Learning,Gamze Erdem Cosgun,2025,"The role of artificial intelligence (AI) in education plays a crucial role in teacher training digitalisation. Although AI has enormous potential, not much is known about how pre-service teachers perceive and utilise AI tools in professional practice. Hence, this study, guided by the Unified Theory of Acceptance and Use of Technology framework, investigates pre-service English as a foreign language teachers' experiences using MagicSchool, an AI-based educational tool, to design exam questions, aiming to explore how AI tools can enhance assessment practices in teacher education. Participants were 27 fourth-year pre-service teachers. Data for this case study were collected through semi-structured interviews and reflective reports and subsequently subjected to thematic analysis. The findings reveal that MagicSchool improved time efficiency and reinforced the creation of various question types. Participants also mentioned its practicality in generating rubrics and materials for varied proficiency levels. However, challenges such as crafting effective prompts, verifying content and addressing cultural or contextual mismatches were recognised. Moreover, ethical concerns, such as plagiarism and minimised creativity, were highlighted, with participants warning against over-reliance on AI. The study underscores the potential of AI in exam preparation while emphasising challenges, advocating for a balanced approach that integrates AI responsibly. Implications for teacher education include fostering AI literacy, promoting critical engagement with AI-generated content and ensuring ethical and pedagogically sound implementation in assessment design.",British Educational Research Journal,v51 n5 p2340-2357 2025,10.1002/berj.4177,http://eric.ed.gov/?id=EJ1486241,Artificial Intelligence; Digital Literacy; Preservice Teachers; Test Construction; Test Items; Computer Assisted Testing; Language Teachers; Second Language Instruction; English (Second Language); Evaluation Methods; Efficiency; Time Management; Ethics; Plagiarism; Creativity; Technology Uses in Education; Preservice Teacher Education,English,Journal Articles; Reports - Research
EJ1486807,Investigating High School Students' Attitudes toward the Use of AI in Education: Evidence from Cambodia,Sarin Sok; Kimkong Heng; Mengkorn Pum,2025,"Recently, there has been a plethora of studies about students' attitudes toward the use of artificial intelligence (AI) technologies in education, particularly in higher education and language education; however, research on AI use in high school settings has gained relatively little attention, leaving a huge research gap in the literature. This study seeks to address this research gap by examining high school students' attitudes toward using AI-powered tools in education in Cambodia. Utilizing evidence from an online survey with 315 students (female = 62.50%), the study showed that Cambodian high school students expressed generally favorable attitudes toward utilizing AI-powered tools in education, particularly pertaining to the use of AI to aid in completing school work. However, the study identified key concerns about data privacy and security issues, the risk of becoming over-dependent on AI, and limited originality about students' work. It was also found that students tended to be less concerned with the potential reduction in their critical thinking and creativity skills, and the possibility of receiving false or incorrect responses from AI. Key opportunities of using AI in education were also identified, including the potential to assist students in learning languages and help them summarize texts, translate languages, and/or brainstorm ideas. The study underscored the significance of developing students' AI literacy through training and awareness raising programs, and the importance of formulating comprehensive AI policies to promote the ethical and effective use of AI technologies in high school settings. The study concluded with some limitations and directions for future studies.",SAGE Open,v15 n3 2025,10.1177/21582440251353575,http://eric.ed.gov/?id=EJ1486807,Foreign Countries; High School Students; Student Attitudes; Artificial Intelligence; Computer Uses in Education,English,Journal Articles; Reports - Research
EJ1482141,Of Teachers and Centaurs: Exploring the Interactions and Intra-Actions of Educators on AI Education Platforms,William J. Fassbender,2025,"Recent advancements in generative Artificial Intelligence (GenAI) were accompanied by both hype and fear regarding the ways in which such technologies of automation would replace human labor in various fields, including education. Rather than focusing on the replacement of humans in teaching, this piece uses new materialist thought [Barad, Karen. 2007. ""Meeting the Universe Halfway: Quantum Physics and the Entanglement of Matter and Meaning."" Durham, NC: Duke University Press.] to consider how a new subjectivity, the centaur, might offer a different orientation toward GenAI technologies as tools that possess potentiality for new becomings in teaching. This theoretical piece looks at three AI education (AIED) platforms as a means of diagnosing how current models of AI tools attempt to design for teacher-centaurs by ushering in a more productive teacher workforce. The article also offers an alternative perspective of what might be considered centaur teaching practices, entangling humans and AI in ways that imagine how human-technical relations might be otherwise.","Learning, Media and Technology",v50 n3 p352-364 2025,10.1080/17439884.2024.2447946,http://eric.ed.gov/?id=EJ1482141,Artificial Intelligence; Technology Uses in Education; Automation; Educational Change; Instruction; Teaching Methods; Man Machine Systems; Ethics; Planning; Feedback (Response),English,Journal Articles; Reports - Descriptive
EJ1377781,In-Service Teachers' (Mis)conceptions of Artificial Intelligence in K-12 Science Education,"Antonenko, Pavlo; Abramowitz, Brian",2023,"Society's future depends on informed perspectives of Artificial Intelligence (AI) and AI related skills, a prognosis that greatly impacts K-12 education. To best prepare students to be AI savvy, there is a need to integrate AI tools, skills, and lessons into the K-12 curriculum. In order for teachers to develop the knowledge and skills, and have the self-efficacy for using AI in instruction, they must be well prepared and informed of what AI is (and what it is not) and its potential role in K-12 education. This study explored teachers' (mis)conceptions relative to their intentional and informal learning. Our research provides important implications for teacher preparation and in-service professional development regarding AI in our society and implementation of AI tools and processes in K-12 education.",Journal of Research on Technology in Education,v55 n1 p64-78 2023,10.1080/15391523.2022.2119450,http://eric.ed.gov/?id=EJ1377781,Elementary School Teachers; Early Childhood Teachers; Secondary School Teachers; Artificial Intelligence; Science Education; Misconceptions; Knowledge Level; Inservice Teacher Education; Preservice Teacher Education; Elementary Secondary Education; Science Teachers; Intention; Technology Integration; Accuracy; Teacher Attitudes; Ethics,English,Journal Articles; Reports - Research; Tests/Questionnaires
ED677000,Artificial Intelligence in Vocational Education and Training: Understanding Learner and Teacher Perspectives on the Integration of Generative AI through Participatory Action Research,"Selena Chan, Editor",2025,"This book details a series of studies across several levels of learning and vocational education and training (VET) discipline areas. In the main, the advent of natural language AI chatbots exampled by ChatGPT, has caused the educational sector to take on a defensive stance. Both schools and the higher education sector are engaged in an on-going 'arms race' to prevent learners from using AI to augment assessments. Therefore, there has been a focus on plagiarism prevention, rather than to better understand the potentialities for utilizing AI to support better learning. This book explores the collaborative development and planning between educational developers/learning designers and teachers to design learning activities which could leverage off various artificial intelligence (AI) platforms. In doing, support is provided for effective learning to be undertaken with an emphasis on the learning and application of critical thinking skills. The studies presented through the volume, describe the integration of AI literacy, to support learners in evaluating the relevance and efficacy of AI tools and platforms, and to understand how to best utilize these for specific purposes. This book also synthesizes a framework for the introduction, selection, and implementation of AI into the VET curriculum. It showcases recommendations and guidelines to inform the future integration of AI tools/platforms into the VET curriculum.",Springer,,,http://eric.ed.gov/?id=ED677000,Artificial Intelligence; Career and Technical Education; Foreign Countries; Action Research; Participatory Research; Educational Research; Ethics; Case Studies; Natural Language Processing; Student Experience; Construction Management; Graphic Arts; Capstone Experiences; Undergraduate Students; Nursing Education; Nursing Students; Reflection; Critical Thinking,,Books; Collected Works - General
EJ1482238,Misrepresentation or Inclusion: Promises of Generative Artificial Intelligence in Climate Change Education,Ha Nguyen; Victoria Nguyen; Sara Ludovise; Rossella Santagata,2025,"Generative Artificial Intelligence (AI) technologies, including large language models (LLMs) that can generate novel text output, present promise for creating tailored science communication for broad audiences. However, LLMs might reflect inaccuracies and social biases from their training sources. In this work, we examine the promises and challenges of using LLMs to depict climate issues from intersectional perspectives. We prompt an LLM (GPT-4) to generate content about localized climate issues and simulate different communication mediums and intersectional identities. We conduct content analysis of the responses, drawing from Intersectional Climate Justice and Culturally Sustaining Pedagogies frameworks. Findings suggest that the LLM-created responses can restate climate justice principles in the prompts and do not frequently show inaccuracy. However, they may lack elaboration, show deficit framing, and overlook identity aspects. We discuss suggestions from critical education research, to question the assumptions underlying AI technologies and explore ways to promote inclusive climate education.","Learning, Media and Technology",v50 n3 p393-409 2025,10.1080/17439884.2024.2435834,http://eric.ed.gov/?id=EJ1482238,Artificial Intelligence; Technology Uses in Education; Climate; Environmental Education; Social Justice; Cultural Relevance; Social Influences; Cultural Influences; Social Bias; Culturally Relevant Education; Gender Bias; Prompting; Stereotypes; Language Usage; Teacher Attitudes; Student Attitudes; Racism,English,Journal Articles; Reports - Research
EJ1480840,Teachers and AI: Understanding the Factors Influencing AI Integration in K-12 Education,Ozan Filiz; Mehmet Haldun Kaya; Tufan Adiguzel,2025,"This study investigates the psychological and pedagogical factors influencing K-12 teachers' readiness to integrate artificial intelligence (AI) into educational settings. An exploratory qualitative approach was employed, involving 66 teachers from 11 disciplines at a private school in Türkiye participating in a professional development program focused on AI-enhanced teaching. Data were collected through online discussion forums and AI-supported learning activity design tasks and analyzed using inductive thematic analysis. Findings reveal that teachers valued AI for its efficiency, interactivity, and adaptability, particularly in tools like ChatGPT and MagicSchool, which supported personalized learning and lesson planning. However, significant challenges emerged, including technical issues, curriculum misalignment, ethical concerns, and cultural barriers, such as difficulties adapting AI-generated content to local contexts. The study concludes that while AI offers significant potential to enhance education, successful integration requires addressing the identified barriers through targeted support, resources, and ethical guidelines. Implications for further research include exploring diverse educational settings to generalize findings, conducting longitudinal studies to assess long-term impacts, and investigating strategies to align AI tools with existing curricula and ethical standards.",Education and Information Technologies,v30 n13 p17931-17967 2025,10.1007/s10639-025-13463-2,http://eric.ed.gov/?id=EJ1480840,Artificial Intelligence; Technology Uses in Education; Technology Integration; Elementary Secondary Education; Private School Teachers; Foreign Countries; Faculty Development; Readiness; Efficiency; Interaction; Individualized Instruction; Lesson Plans; Ethics; Barriers; Educational Benefits,English,Journal Articles; Reports - Research
EJ1487153,South African Lecturers' Views of ChatGPT: An AI Technology Used for Designing Online Assessments,Elize du Plessis; Rebecca Y. Bayeck,2025,"Even while Artificial Intelligence (AI) has long been a part of our lives, it has recently received more attention thanks to the introduction of ChatGPT, a Chat Generative Pre-Trained Transformer, since its launch in November 2022. The focus of this study is to investigate the potential of ChatGPT to assess student-teacher learning, which looks at its use for online assessments in South Africa. It emphasizes South African lecturers' views of ChatGPT, an AI technology used for designing online assessments. The expansion of online assessments has brought about various adaptable tools and techniques, and ChatGPT provides benefits, including real-time interaction and personalized responses. Nevertheless, problems such as prejudices and circumstantial limitations still exist. Notwithstanding this, ChatGPT does well at assessing critical thinking by examining evidence-based reasoning and logical reliability. When integrating ChatGPT, ethical deliberations such as algorithmic transparency, data security, and privacy are crucial. Ten participants participated in a qualitative study that examined ChatGPT's effects on online assessment and student-teacher relationships using the Community of Inquiry (CoI) model. By presenting lecturers with AI-driven techniques and promoting innovation and technology integration, participants highlight their impact in promoting professional development. As a cooperative tool, ChatGPT offers tailored feedback, detailed instructions, and culturally appropriate rubrics that encourage critical thinking and introspection. It is essential, however, to contextualize its application to combat biases and cultural twists within the African educational environment. This ensures that rather than replacing student-teachers' knowledge, AI supports them using inclusive and valuable assessments.",Journal of Teaching and Learning,v19 n4 p97-113 2025,,http://eric.ed.gov/?id=EJ1487153,Foreign Countries; Artificial Intelligence; Technology Uses in Education; Computer Assisted Testing; Ethics; Teacher Student Relationship; Program Effectiveness; Feedback (Response); Cultural Relevance; Critical Thinking; Thinking Skills; Affordances; Barriers; College Faculty,English,Journal Articles; Reports - Research
ED658146,Privacy in Federated Learning,Mengjiao Zhang,2024,"The rise of Artificial Intelligence technology has raised concerns about the potential compromise of privacy due to the handling of personal data. Private AI prevents cybercrimes and falsehoods and protects human freedom and trust. While Federated Learning offers a solution by model training across decentralized devices or servers, thereby preserving data localization, it may leak client information through communicated gradients and parameters. Conventional defenses, such as dropout, GAN, and adversarial training, fail to either obstruct these attacks or significantly hamper model performance. This thesis centers on defending against gradient-based attacks in Federated Learning while upholding model efficiency and performance. As our first contribution, we introduce the pragmatic defense mechanism of Double-Blind Collaborative Learning (DBCL), which employs random matrix sketching on parameters and repeated sketching generation, achieving enhanced privacy without substantial computational overhead or lowering accuracy. Our primary investigation delves into byte coding for privacy in Natural Language Processing (NLP). This novel approach involves random-byte mapping with a subword fusion strategy, yielding promising experimental outcomes characterized by fortified privacy, memory efficiency, and accuracy. Notably, our approach obstructs an attacker's ability to reconstruct text token candidates for a batch of inputs, thus fortifying the resilience of private text in Federated Learning against potential recovery attempts, making the recovery of private data in federated learning much harder -- paving a way to a safer environment in both the real and virtual worlds. [The dissertation citations contained here are published with the permission of ProQuest LLC. Further reproduction is prohibited without permission. Copies of dissertations may be obtained by Telephone (800) 1-800-521-0600. Web page: http://www.proquest.com/en-US/products/dissertations/individuals.shtml.]",ProQuest LLC,"Ph.D. Dissertation, Stevens Institute of Technology",,http://eric.ed.gov/?id=ED658146,Privacy; Cooperative Learning; Natural Language Processing; Learning Processes; Information Technology; Artificial Intelligence; Computer Security,,Dissertations/Theses - Doctoral Dissertations
EJ1338384,Teachers' Trust in AI-Powered Educational Technology and a Professional Development Program to Improve It,"Nazaretsky, Tanya; Ariely, Moriah; Cukurova, Mutlu; Alexandron, Giora",2022,"Evidence from various domains underlines the critical role that human factors, and especially trust, play in adopting technology by practitioners. In the case of Artificial Intelligence (AI) powered tools, the issue is even more complex due to practitioners' AI-specific misconceptions, myths and fears (e.g., mass unemployment and privacy violations). In recent years, AI has been incorporated increasingly into K-12 education. However, little research has been conducted on the trust and attitudes of K-12 teachers towards the use and adoption of AI-powered Educational Technology (AI-EdTech). This paper sheds light on teachers' trust in AI-EdTech and presents effective professional development strategies to increase teachers' trust and willingness to apply AI-EdTech in their classrooms. Our experiments with K-12 science teachers were conducted around their interactions with a specific AI-powered assessment tool (termed AI-Grader) using both synthetic and real data. The results indicate that presenting teachers with some explanations of (i) how AI makes decisions, particularly compared to the human experts, and (ii) how AI can complement and give additional strengths to teachers, rather than replacing them, can reduce teachers' concerns and improve their trust in AI-EdTech. The contribution of this research is threefold. First, it emphasizes the importance of increasing teachers' theoretical and practical knowledge about AI in educational settings to gain their trust in AI-EdTech in K-12 education. Second, it presents a teacher professional development program (PDP), as well as the discourse analysis of teachers who completed it. Third, based on the results observed, it presents clear suggestions for future PDPs aiming to improve teachers' trust in AI-EdTech.",British Journal of Educational Technology,v53 n4 p914-931 Jul 2022,10.1111/bjet.13232,http://eric.ed.gov/?id=EJ1338384,Elementary School Teachers; Secondary School Teachers; Teacher Attitudes; Trust (Psychology); Artificial Intelligence; Educational Technology; Technology Uses in Education; Computer Attitudes; Faculty Development; Science Teachers; Computer Assisted Testing; Discourse Analysis,English,Journal Articles; Reports - Research
EJ1473960,Data-Driven Decision-Making: Utilising AI-Powered Learning Analytics to Make Informed Primary Educators' Decisions,Morakinyo Akintolu; Akinpelu A. Oyekunle,2025,"This paper provides a comprehensive overview of the research on the application of artificial intelligence (AI) in primary education to explore its potential to enhance teaching and learning processes. Through a systematic review of the relevant literature, this study identifies key areas in which AI can significantly impact primary education and offers recommendations for its effective utilisation to sustain or acquire quality education. These recommendations encompass various facets of AI integration in primary education, including tailored learning experiences, intelligent tutoring systems, data-driven decision making, virtual reality and augmented reality technologies, intelligent content creation, adaptive assessment and feedback mechanisms, intelligent course design, and support for students with exceptional needs. Additionally, this paper emphasises the importance of addressing ethical considerations and ensuring responsible AI use, along with advocating continuous professional development opportunities for educators to enhance their AI literacy and pedagogical skills. Drawing on insights from the existing literature, this study underscores the potential of AI to revolutionise primary education by providing personalised learning experiences, facilitating intelligent tutoring and feedback, and enabling immersive and engaging learning environments. However, it also highlights the need for careful consideration of the ethical implications and ongoing professional development initiatives to harness the benefits of AI in education.",Journal of Educators Online,v22 n3 2025,,http://eric.ed.gov/?id=EJ1473960,Data Analysis; Learning Analytics; Artificial Intelligence; Computer Software; Teaching Skills; Teaching Methods; Learning Processes; Elementary School Teachers; Intelligent Tutoring Systems; Feedback (Response); Faculty Development; Individualized Instruction; Educational Quality; Instructional Design; Ethics; Decision Making; Research Reports; Special Needs Students; Elementary School Students; Technology Integration; Educational Benefits,English,Journal Articles; Reports - Research; Information Analyses
EJ1437867,Pre-Service Teacher Education in a Postplagiarism World: Incorporating GenAI into Teacher Training,Sarah Elaine Eaton,2024,"This essay explores the integration of generative artificial intelligence (GenAI) into pre-service teacher education amidst contemporary debates on technology in education. It highlights the cautious stance taken by educational authorities, such as the Alberta Teachers' Association, which advises against involving students directly with AI tools. The discussion contrasts this cautionary position with global trends, noting advanced AI curricula in countries like China and Japan. Emphasizing the necessity for hands-on GenAI training for pre-service teachers, the essay advocates equipping future educators with the skills and knowledge to effectively incorporate AI into their practice. It calls for engaging students as partners in learning and rethinking traditional notions of plagiarism in a postplagiarism world where AI co-creation becomes common.",Brock Education: A Journal of Educational Research and Practice,v33 n3 p11-16 2024,,http://eric.ed.gov/?id=EJ1437867,Preservice Teacher Education; Plagiarism; Ethics; Artificial Intelligence; Technology Uses in Education; Technology Integration; Foreign Countries; Technological Literacy; Role Models; Cross Cultural Studies; Partnerships in Education,English,Journal Articles; Reports - Evaluative
ED674455,Navigating the Cutting Edge in TESOL/TEFL Studies: Emerging Research Directions and Trends,Mahmoud M. S. Abdallah,2025,"This article offers a rigorous and forward-looking examination of contemporary research directions and transformative trends within the fields of TESOL (Teaching English to Speakers of Other Languages) and TEFL (Teaching English as a Foreign Language). Positioned at the intersection of rapidly evolving technologies, innovative pedagogies, and urgent social justice imperatives, the article provides a strategic roadmap for graduate students and researchers aiming to conduct impactful, relevant studies in English language education. It foregrounds the expanding role of Artificial Intelligence (AI) and immersive technologies--such as adaptive assessment systems, natural language processing, virtual and augmented reality--in personalising and enriching language learning experiences while critically addressing associated ethical challenges like algorithmic bias and data privacy. Simultaneously, the article highlights groundbreaking shifts toward multilingual pedagogies, translanguaging practices, and culturally sustaining approaches that challenge traditional native-speaker norms and embrace linguistic diversity as a key pedagogical asset. Methodological innovations, including mixed methods and action research, are examined as vital tools for capturing the socio-cultural complexity of language learning and empowering practitioner-driven inquiry. Additionally, the article underlines the necessity of sustained professional development aimed at equipping educators with technological competencies and critical digital literacy for an equitable and inclusive digital era. Through a synthesis of theoretical insights and empirical evidence, this comprehensive review advances a socially responsible and ethically informed vision of TESOL/TEFL scholarship, emphasising the critical importance of bridging theory and practice to foster global English language education that is innovative, inclusive, and just.",Online Submission,,,http://eric.ed.gov/?id=ED674455,English (Second Language); Second Language Instruction; Second Language Learning; Language Teachers; Teacher Education Programs; Artificial Intelligence; Computer Software; Technology Integration; Teaching Methods; Instructional Innovation; Privacy; Code Switching (Language); Ethics; Natural Language Processing; Multilingualism; Culturally Relevant Education; Learning Experience; Social Justice; Computer Simulation; Educational Trends; Trend Analysis; Educational Change; Language Attitudes; Language Variation; Critical Literacy; Digital Literacy; Pedagogical Content Knowledge; Technological Literacy,,Reports - Evaluative
EJ1485752,Generative Artificial Intelligence's Integration for Data Analysis in Conducting Academic Research: Understanding the Perspective of Research Supervisors,Amandeep Sehmi; Isra Sarfraz; Muzammil Hussain,2025,"This special issue article explores the role of generative artificial intelligence (GenAI) in the data analysis phase of academic research degrees, focusing on its adoption by research students in master's and doctor of philosophy programmes in the business and management disciplines, as viewed through the lens of research supervisors. A qualitative research methodology was adopted, involving semi-structured interviews with research supervisors. The findings revealed that while current familiarity with the use of GenAI tools for data analysis is limited among research supervisors, there is a growing recognition of their potential value and anticipated future acceptance in academic research. The findings of this study recommend the integration of GenAI training modules into research degrees. Furthermore, this study serves as a guide for future research studies exploring the role of GenAI in the data analysis processes of academic research. This study proposes guidelines to raise awareness and educate research students on the ethical use of GenAI, aiming to maintain integrity and enabling them to understand the scope and potential of emerging technologies for data analysis. Emphasising the ethical integration of GenAI, the enhancement of critical thinking, and the development of clear institutional policies are identified as key strategies to support the responsible use of GenAI in research and education.",Journal of Advanced Academics,v36 n4 p788-815 2025,10.1177/1932202X251365312,http://eric.ed.gov/?id=EJ1485752,Artificial Intelligence; Technology Uses in Education; Technology Integration; Data Analysis; Educational Research; Higher Education; Ethics; Supervisors; Research Methodology; Graduate Students; Student Research; Foreign Countries,English,Journal Articles; Reports - Research
EJ1431470,"Generative Artificial Intelligence (AI) in Higher Education: A Comprehensive Review of Challenges, Opportunities, and Implications",Michal Bobula,2024,"This paper explores recent advancements and implications of artificial intelligence (AI) technology, with a specific focus on Large Language Models (LLMs) like ChatGPT 3.5, within the realm of higher education. Through a comprehensive review of the academic literature, this paper highlights the unprecedented growth of these models and their widereaching impact across various sectors. The discussion sheds light on the complex issues and potential benefits presented by LLMs, providing a comprehensive overview of the field's current state. In the context of higher education, the paper explores the challenges and opportunities posed by LLMs. These include issues related to educational assessment, potential threats to academic integrity, privacy concerns, the propagation of misinformation, Equity, Diversity, and Inclusion (EDI) aspects, copyright concerns and inherent biases within the models. While these challenges are multifaceted and significant, the paper emphasises the availability of strategies to address them effectively and facilitate the successful adoption of LLMs in educational settings. Furthermore, the paper recognises the potential opportunities to transform higher education. It emphasises the need to update assessment policies, develop guidelines for staff and students, scaffold AI skills development, and find ways to leverage technology in the classroom. By proactively pursuing these steps, higher education institutions (HEIs) can harness the full potential of LLMs while managing their adoption responsibly. In conclusion, the paper urges HEIs to allocate appropriate resources to handle the adoption of LLMs effectively. This includes ensuring staff AI readiness and taking steps to modify their study programmes to align with the evolving educational landscape influenced by emerging technologies.",Journal of Learning Development in Higher Education,n30 2024,,http://eric.ed.gov/?id=EJ1431470,Artificial Intelligence; Information Technology; Natural Language Processing; Literature Reviews; Models; Technology Uses in Education; Technology Integration; Educational Policy; Guidelines; Professional Development; Curriculum Development; Alignment (Education); Integrity; Privacy; Misinformation; Copyrights; Equal Education; Diversity; Inclusion; Educational Strategies; Best Practices; Higher Education,English,Journal Articles; Reports - Evaluative
EJ1488262,Negotiating Meaning with Machines: AI's Role in Doctoral Writing Pedagogy,Jessica L. Parker; Veronica M. Richard; Alexandra Acabá; Sierra Escoffier; Stephen Flaherty; Shannon Jablonka; Kimberly P. Becker,2025,"This paper examines the integration of generative artificial intelligence (AI) in doctoral writing pedagogy. It explores how AI augments traditional teaching and composition processes, fosters a new paradigm of cognitive engagement and collaborative academic writing, and the broader ethical and social implications of human-AI writing in doctoral writing pedagogy. A community-engaged participatory research methodology was employed within a Doctor of Healthcare Administration program. Data were collected through discussion board messages, self-assessment papers, student reflections, and a focus group interview, and analyzed using thematic analysis. The research unearthed a hybrid human-AI writing process characterized by dynamic brainstorming, continuous negotiation of meaning, and comparative evaluation. These practices enhanced students' cognitive and metacognitive engagement, confidence, and learner agency, signifying a shift toward a collaborative approach to academic writing. The findings highlight the need for academic institutions to adapt policies and curricula to incorporate AI technologies ethically and responsibly. Emphasis on AI literacy and academic integrity is crucial for preparing graduates for an AI-integrated workforce. This study contributes to the understanding of AI's role in doctoral education, specifically doctoral writing development, presenting a novel perspective on the synergistic collaboration between students and AI in academic writing and its implications for institutional policies and writing pedagogy.",International Journal of Artificial Intelligence in Education,v35 n3 p1218-1238 2025,10.1007/s40593-024-00425-x,http://eric.ed.gov/?id=EJ1488262,Artificial Intelligence; Writing Instruction; Doctoral Programs; Computer Uses in Education; Administrator Education; Doctoral Students; Writing Processes; Learner Engagement; Personal Autonomy; Self Esteem; Cooperation; Ethics,English,Journal Articles; Reports - Research
EJ1466907,From Prompts to Plans: A Case Study of Pre-Service EFL Teachers' Use of Generative AI for Lesson Planning,Robert C. Kerr; Hyekyeng Kim,2025,"The present study investigates the use of generative artificial intelligence (AI) tools by pre-service teachers (PSTs) in lesson planning for a middle-school English as a foreign language (EFL) class, aiming to address gaps and inform teacher training. The case study examined PSTs in a South Korean university course who were tasked with creating lesson plans using generative AI to aid in lesson plan development for a middle school lesson that incorporated generative AI. Data were analyzed thematically, and results revealed that generative AI was used in topic selection, material creation, lesson organization, and language checking. While generative AI facilitated efficiency and creativity, challenges emerged, including the quality of outputs and limited incorporation of effective pedagogical strategies. These findings indicate a need for targeted training in prompt engineering, ethical considerations, pedagogy, and collaborative practices to enhance PSTs' generative AI competencies. This study contributes to teacher education programs by providing insights into the practical integration of generative AI in pedagogical practices.",English Teaching,v80 n1 p95-118 2025,,http://eric.ed.gov/?id=EJ1466907,Writing Instruction; English (Second Language); Second Language Learning; Second Language Instruction; Artificial Intelligence; Computer Software; Teaching Methods; Preservice Teachers; Teacher Education Programs; Lesson Plans; Ethics; Language Teachers; Technology Uses in Education; Middle School Students; Foreign Countries; Technological Literacy; Pedagogical Content Knowledge; Cooperative Learning,English,Journal Articles; Reports - Research
EJ1481994,"In the Age of AI, We Need Coaches More than Ever",Jim Knight,2025,"As artificial intelligence (AI) transforms education, leaders may be tempted to replace coaches with AI to save money while still promoting better teaching and better learning. This article argues that abandoning coaching for AI means abandoning the most effective methodology for improving teaching and learning for a machine that is incapable of addressing many of the needs of teachers and students. As ethical and practical considerations should guide how AI can support instructional coaches, the author provides six capabilities that can enhance the work of coaches.",Learning Professional,v46 n4 p29-32 2025,,http://eric.ed.gov/?id=EJ1481994,Artificial Intelligence; Coaching (Performance); Technology Uses in Education; Ethics; Professional Development,English,Journal Articles; Reports - Evaluative
EJ1477151,Envisioning the Future of AI-Assisted EFL Teaching and Learning: Conceptual Representations of Prospective Teachers,Muzaffer Pinar Babanoglu; Tuçe Öztürk Karatas; Esin Dündar,2025,"Artificial intelligence (AI) rapidly transforms education, offering adaptive and personalized learning experiences. In English as a Foreign Language (EFL) education, AI-powered tools such as chatbots, writing assistants, and translation software reshape teaching and learning. This study explores how 67 prospective EFL teachers envision the future role of AI in EFL instruction, examining its potential benefits and challenges. Using a descriptive qualitative approach and reflexive thematic analysis, the study identifies 6 themes and 52 nodes addressing the risk of AI replacing teachers and 5 themes with 31 nodes regarding AI's future impact on EFL teaching and learning. Findings suggest a preference for a human-centered AI approach--AI-assisted EFL teaching and learning (AIaEFLtl)--where AI complements rather than replaces teachers. The study highlights key implications for AI-EFL teacher collaboration, advocating for teacher training in AI integration and ethical considerations. These insights contribute to the ongoing discourse on the evolving role of AI in education and its pedagogical implications for future EFL classrooms.",SAGE Open,v15 n2 2025,10.1177/21582440251341590,http://eric.ed.gov/?id=EJ1477151,Artificial Intelligence; Computer Software; Technology Integration; English (Second Language); Second Language Learning; Second Language Instruction; Teacher Collaboration; Technological Literacy; Pedagogical Content Knowledge; Faculty Development; Teaching Methods; Ethics; Language Teachers; Teacher Role; Futures (of Society); Educational Change; Higher Education; Foreign Countries,English,Journal Articles; Reports - Research
EJ1491824,Examining Conservative Attitudes in AI Conversations about Teen Sexting,Tsameret Ricon; Inbar Cohen,2025,"This study analyzed an AI chatbot's perspectives on adolescent sexting through quantitative questionnaire responses and a qualitative conversational interview. Findings revealed problematic biases stemming from limitations in training data and algorithms. The chatbot showed an imbalanced focus on sexting's risks compared to benefits for healthy sexual development. Responses frequently associated teen sexting with criminal offenses like child pornography, reflecting legalistic age bias. Gender bias also emerged in framing sexting as far riskier for girls versus boys. Additionally, the chatbot demonstrated gaps applying nuanced consent principles attuned to complex teen relationship dynamics. While covering consent fundamentals, responses lacked an understanding of how initial willingness differs from non-consensual sharing. The study suggests training data limitations skewed the chatbot's framing away from empowering adolescent sexual agency. Opportunities exist to mitigate biases through improving training data balance, incorporating community input, expanding consent frameworks and encouraging nuanced risk/benefit analysis. More inclusive design with human oversight is vital for chatbots to provide comprehensive, empowering sexuality education to youth. This analysis of AI perspectives reveals the persistence of conservative attitudes and the need to evolve systems to support healthy adolescent sexual development.",American Journal of Sexuality Education,v20 n3 p255-274 2025,10.1080/15546128.2024.2381735,http://eric.ed.gov/?id=EJ1491824,Artificial Intelligence; Adolescents; Computer Mediated Communication; Sexuality; Risk; Crime; Age Differences; Gender Differences; Interpersonal Relationship; Sex Education; Adolescent Development; Technology Uses in Education; Controversial Issues (Course Content),English,Journal Articles; Reports - Research
EJ1480952,Critical Evaluation of the Potential of Large Language Models in Bioscience Higher Education: A Conversation with ChatGPT,Andrew Williams,2025,"The possibilities for integrating generative artificial intelligence (AI) and large language models (LLMs) into higher education may revolutionise approaches to pedagogical practices and curriculum design, while LLMs could be transformative in how students approach their learning. This conversation with ChatGPT, and associated critical evaluation, provides an insight into the capabilities and limitations of LLMs and informs on the possibilities for incorporating AI into bioscience education, teaching modalities, assessment and feedback practices and curriculum design, with a particular focus on bioscience education. The conversation highlights how LLMs can facilitate personalized feedback, tutoring, and concise explanations of scientific terms, enhancing student comprehension, self-directed learning, and critical thinking. However, there are concerns regarding the risks of LLMs, such as plagiarism and breaches of academic integrity, algorithmic bias and limitations in contextual understanding. Despite these limitations, AI offers opportunities for enriching undergraduate bioscience curricula by integrating innovative teaching strategies and assessment modalities aligned with subject benchmark statements. Future research directions include exploring ethical implications, equitable access and digital literacy training in higher education settings. Overall, the integration of LLMs in bioscience education offers significant potential for innovative pedagogical approaches and transformative learning experiences.",International Journal of Research in Education and Science,v11 n3 p667-701 2025,,http://eric.ed.gov/?id=EJ1480952,Science Education; Higher Education; Integrity; Artificial Intelligence; Plagiarism; Computational Linguistics; Curriculum Design; Independent Study; Critical Thinking; Computer Software; Technology Integration; Teaching Methods; Biological Sciences; Feedback (Response); Instructional Innovation; Digital Literacy; Ethics; Undergraduate Students,English,Journal Articles; Reports - Descriptive
EJ1483676,"Educators' Perceptions of Generative AI: Investigating Attitudes, Barriers and Learning Needs in Higher Education",Saba Soleimani; Mohammadreza Farrokhnia; Alieke van Dijk; Omid Noroozi,2025,"This study explores university educators' attitudes, barriers, and learning needs regarding the adoption of generative AI in higher education. Using a mixed-methods approach, surveys from 70 educators and interviews with five programme directors at a university in the Netherlands reveal generally positive attitudes, especially towards content creation and personalised learning. However, actual use remains limited due to concerns about the reliability and ethics of AI-generated content, lack of pedagogical strategies, and insufficient training. Educators identified the need for professional development focused on evaluating AI outputs, addressing ethical concerns, and building adaptive expertise. These findings inform the design of university-level training programmes that prioritise transferable competencies such as digital (AI) literacy and critical thinking. The study also underscores the need for institutional support structures to enable responsible, effective generative AI use. Ultimately, generative AI should enhance rather than replace human-centred teaching, supporting creativity, critical engagement, and ethical learning in higher education.",Innovations in Education and Teaching International,v62 n5 p1598-1613 2025,10.1080/14703297.2025.2530767,http://eric.ed.gov/?id=EJ1483676,Artificial Intelligence; Teacher Attitudes; Barriers; College Faculty; Reliability; Ethics; Training; Teaching Methods; Faculty Development; Technological Literacy; Critical Thinking; Foreign Countries; Technology Uses in Education; Educational Needs; Teacher Competencies,English,Journal Articles; Reports - Research
EJ1456747,Understanding the Application of AI in Higher Education Systems: Global Perspectives from a Local AI Ecosystem,Harun Serpil; Eren Kesim,2024,"This study aims to perform a descriptive analysis of the websites of public and foundation universities in Türkiye to reveal the current positioning context of their units in relation to artificial intelligence (AI) ecosystems. The study was designed using a holistic multiple case study method, in which the dimensions specified in the subobjectives (types of units, geographical regions where the units are located, location preferences of universities, status of universities as public or foundation universities, vision definitions of the units, gender and titles of academics working in the units, research areas of the units, industrial collaborations) were handled independently and holistically. The researchers examined the websites of 41 units operating within the artificial intelligence ecosystem in universities. They then transferred the data they collected to a document review form for analysis. After employing a descriptive analysis method to examine the data, the researchers interpreted their findings with percentages and frequencies. The results show that the most common unit providing services in the AI ecosystem is research centers. The units providing services in the AI ecosystem are mostly located in public universities, and the universities where the units are located position themselves as research-oriented, education-oriented, both education and research-oriented, and entrepreneurship-oriented, respectively. The vision statements of the units operating in the AI ecosystem are observed to be mostly used to train highly-qualified human resources. It was also noted that the academic staff assigned to the units serving in the AI Ecosystem are mostly male, holding the title of Professor. The units operating in the AI Ecosystem have collaborations and protocols with universities, as well as with industrial and public institutions working in the field of AI.",Open Praxis,v16 n4 p645-662 2024,,http://eric.ed.gov/?id=EJ1456747,Artificial Intelligence; Higher Education; Technology Uses in Education; Global Approach; Local Issues; Ecology; Foreign Countries; Universities; Web Sites; Content Analysis; Public Colleges; Research and Development Centers; Gender Bias; Males; Faculty; Educational Policy; Program Implementation; Technology Integration; Educational Practices; Data; Policy Analysis,English,Journal Articles; Reports - Research
ED634165,Examining the Implementation of Artificial Intelligence in Early Childhood Education Settings in Ghana: Educators' Attitudes and Perceptions towards Its Long-Term Viability,"Mohammed, Awudu Salaam",2023,"Artificial Intelligence (AI) has witnessed significant advancements in recent years, with potential applications in various sectors, including education. Early childhood education (ECE) is a critical stage that lays the foundation for a child's future development and learning. This study aims to explore the attitudes and perceptions of educators in Ghana towards implementing AI in ECE settings, focusing on its long-term viability. The research employs a qualitative approach, utilising interviews and focus group discussions to gather data from educators in selected ECE settings across four (4) early childhood settings in Ghana. The study investigates eight (8) educators' experiences, concerns, and expectations regarding integrating AI technologies into their teaching practices. It explores the factors influencing their attitudes towards AI, including familiarity with the technology, pedagogical beliefs, cultural context, and training opportunities. Preliminary findings indicate a diverse range of perspectives among educators towards AI implementation in ECE settings. Some educators perceive AI as promising for enhancing teaching and learning experiences, providing personalised instruction, and facilitating early childhood development. They recognise the potential benefits of AI in supporting cognitive, social, and emotional growth among young learners. Concerns are expressed regarding the implications of AI on human interaction, child privacy, and the role of educators in fostering holistic development. This study contributes to the emerging field of AI in education by examining the context of ECE in Ghana. The findings informed policymakers, educational institutions, and AI developers about the perceptions and concerns of educators, ultimately guiding the development and implementation of AI technologies in a manner that aligns with the needs and aspirations of the Ghanaian ECE community.",Online Submission,American Journal of Education and Technology v2 n4 p36-49 2023,,http://eric.ed.gov/?id=ED634165,Foreign Countries; Artificial Intelligence; Early Childhood Education; Teacher Attitudes; Technology Uses in Education; Technology Integration; Familiarity; Beliefs; Cultural Influences; Teacher Education; Barriers,English,Journal Articles; Reports - Research
EJ1451010,ChatGPT as Artificial Intelligence-Based Generative Multimedia for English Writing Pedagogy: Challenges and Opportunities from an Educator's Perspective,Muhammad Mujtaba Asad; Shafaque Shahzad; Syed Hassan Ali Shah; Fahad Sherwani; Norah Mansour Almusharraf,2024,"Purpose: This paper holds considerable importance in the educational dynamics specifically ChatGPT as generative multimedia in English language writing pedagogy and presents a unique lens, as it uses a narrative literature review to view this cutting-edge topic. This paper compiles the knowledge and information already available regarding the views and integration of ChatGPT in English writing pedagogy. This review attempts to determine the potential that ChatGPT provides for improving pedagogical practices and facilitating individualized learning by looking at the experiences and viewpoints of educators. Simultaneously, it addresses the crucial challenges educators must overcome to optimize the advantages of artificial intelligence (AI) while preserving academic fairness and honesty. The ultimate goal of this paper is to offer a nuanced understanding of ChatGPT's role in education, especially in English language writing pedagogy, educating researchers, teachers and policymakers on how to integrate generative multimedia successfully AI into teaching and learning and aiding in the creation of inclusive and more effective teaching strategies. Design/methodology/approach: The review was done using a narrative approach by analyzing the latest international and national studies, research papers, blog posts, newspaper articles and documentaries, and by collecting the data, facts, figures and pictures. This narrative literature review approach provides a contextual understanding of how different English language teachers view ChatGPT in English writing pedagogy allowing for a comprehensive synthesis of data about its opportunities and challenges as well. It also helps in finding patterns and gaps in the body of knowledge, directing future studies and emphasizing areas that require more research, which is important for this new cutting-edge invention. The narrative approach, in contrast to systematic reviews, enables a detailed qualitative analysis that is necessary for delving into complex topics. This review offers useful insights into the prospects and practical challenges of integrating ChatGPT in English language writing pedagogy by concentrating on the experiences of teachers. The narrative literature review is a useful and relevant means of comprehending and using AI in educational settings since its ultimate goal is to synthesize current knowledge and provide practical recommendations for teachers, students, administrators and, last but not least, policymakers for the effective integration of ChatGPT as generative multimedia specifically in the English language writing pedagogy. Findings: Grounded on findings, it is essential to mention here that ChatGPT holds immense value in terms of English language writing pedagogy. The findings deal with the three research questions: each research question has a main theme followed by sub-themes about the views of teachers on ChatGPT integration into English writing pedagogy, its benefits and, last but not least, challenges; however, very few traces of AI have been found in the early most downloaded Language learning apps, but ChatGPT covers it all with the features like personalized learning, contextually adaptable feedback, human-like conversational skills and preparation of standard tests, which make ChatGPT stand apart and stand tall in the race of new AI inventions. On the contrary, the paper identifies vital challenges associated with ChatGPT. First, there is a severe concern that students' creativity may be at risk. Second, the concern of data privacy is a critical consideration. Finally, dealing with the trust issue of English language teachers regarding the use of ChatGPT for English language writing pedagogy and, last but not least, the paper also talks about low digital literacy as an additional challenge to integrating ChatGPT in educational settings. The incorporation of ChatGPT is not only a new trend but also a door to future AI wonders, so the education community needs to make the most of it. Practical implications: The paper has broad implications that address multiple aspects of educational theory, practice, policy and future research when incorporating AI systems such as ChatGPT into English language writing pedagogy. The findings imply that ChatGPT can result in more dynamic and customized learning experiences, which has important implications for improving English language writing pedagogy with the integration of ChatGPT. AI can help teachers customize lessons to each student's needs, which could increase student engagement in writing classes and improve learning results. Additionally, for the school administration and policymakers, the integration of ChatGPT depends upon access to smooth internet connection and other resources needed for effective learning of the students. Policymakers can develop policies as per the changing needs of the hour by providing professional development training to the teachers for the incorporation of AI inventions such as ChatGPT for English language writing pedagogy. Furthermore, the research also highlights significant ethical and policy issues, especially those dealing with academic integrity. Policies by the administration and teachers must be developed to stop students from misusing ChatGPT and to guarantee that AI tools are applied morally and responsibly in educational contexts because students can utilize the tool to complete assignments in an unethical manner. Originality/value: This narrative literature review is unique as it provides insights into the new invention of OpenAI ChatGPT from the education perspective, specifically about the teaching of English language writing pedagogy, and offers some exciting revelations that have not been done previously.",International Journal of Information and Learning Technology,v41 n5 p490-506 2024,10.1108/IJILT-02-2024-0021,http://eric.ed.gov/?id=EJ1451010,English (Second Language); Writing Instruction; Artificial Intelligence; Computer Assisted Instruction; Individualized Instruction; Multimedia Instruction; Elementary School Teachers; Secondary School Teachers; Teacher Attitudes; English Instruction; Educational Strategies; Technology Integration; Inclusion; Ethics; Curriculum Development,English,Journal Articles; Reports - Research
EJ1464270,Transformative Leadership: Leveraging AI for Inclusive and Future-Oriented Special Education Practices,Lynn M. Scott; Tiffanie Zaugg; Rebecca Hines; Monica Berns-Conner,2025,"The integration of Artificial Intelligence (AI) in special education holds promise for transformative changes in special educational leadership and pedagogical practices. Special education leaders play a pivotal role in leveraging AI to address diverse student needs, enhance instructional delivery, personalize learning experiences, and foster inclusivity. AI integration aligns with International Society for Technology in Education (ISTE) standards and UNESCO Guidance to support administrative functions and advancing special education leadership practices. Emphasis on principles of equity, inclusion, and ethical AI use underscores the need for collaborative and innovative approaches in navigating the evolving educational landscape.",Journal of Special Education Leadership,v38 n1 p44-52 2025,,http://eric.ed.gov/?id=EJ1464270,Artificial Intelligence; Technology Uses in Education; Special Education; Transformational Leadership; Leadership Role; Student Needs; Inclusion; Equal Education; Leadership Styles; Educational Technology; Ethics; Professional Development; Educational Policy; Cooperation; Advocacy; Empowerment; Students with Disabilities,English,Journal Articles; Reports - Descriptive
EJ1480283,E-Leadership in the AI Era: Exploring Vietnamese EFL Teachers' Digital Leadership Development in AI Integration,Nguyen Huu Hoang,2025,"The integration of artificial intelligence (AI) in language education necessitates new forms of digital leadership, yet research on how language teachers develop e-leadership competencies remains limited, particularly in non-Western contexts. This study investigates how Vietnamese EFL teachers develop and exercise e-leadership competencies in implementing AI tools. Using an exploratory sequential mixed-methods design, the study combined in-depth interviews with 17 EFL teachers and a survey of 211 teachers across Vietnamese universities. The research framework integrated e-Leadership Theory and the Technology Acceptance Model. Key findings reveal that successful e-leadership requires a balance of technical proficiency ([beta] = 0.31, p < 0.001) and cultural sensitivity ([beta] = 0.28, p < 0.001). Three primary dimensions of e-leadership competencies emerged: technological proficiency with guidance capability, pedagogical innovation in AI integration, and culturally responsive change management. The research also highlights critical ethical considerations in AI implementation, particularly regarding assessment transparency and decision-making processes. These findings inform the development of culturally sensitive professional development programs and provide a framework for understanding e-leadership development in non-Western educational settings.",Education and Information Technologies,v30 n12 p16895-16928 2025,10.1007/s10639-025-13451-6,http://eric.ed.gov/?id=EJ1480283,Artificial Intelligence; Technology Uses in Education; Second Language Instruction; Second Language Learning; English (Second Language); Language Teachers; Instructional Leadership; Technology Integration; Foreign Countries; Educational Change; Change Agents; Ethics; Faculty Development,English,Journal Articles; Reports - Research; Tests/Questionnaires
EJ1485441,From Curiosity to Dependency: Nigerian Students' Perspectives on AI Integration in Academic Research,Uka Uka Nwagbara,2025,"This study examines the application of artificial intelligence (AI) writing tools in academic writing among Nigerian university students, highlighting both the potential benefits and significant challenges. With increasing numbers of people utilising AI-powered tools like ChatGPT, Grammarly, and Quillbot, Nigerian academics and students demonstrate varying degrees of exposure and expertise in using such tools. The research, employing a purposive sampling technique, conducted interviews with 20 Nigerian students to examine their awareness, usage patterns, and reasons for utilising AI in academic research. The respondents were duly informed of their rights within the research and the choice to use it without consequences. Results show that although AI tools facilitate tasks such as data analysis and writing support, concerns about academic integrity, over-dependence, and institutional support issues persist. Interestingly, students report a lack of guidelines and official training, which leads to the ad hoc and potentially unethical use of AI. The paper concludes that systematic AI literacy programs and ethical guidelines are necessary for the responsible and fair integration of AI into Nigerian higher education, thereby assisting students' learning while promoting academic integrity.",Journal of Academic Ethics,v23 n4 p2051-2068 2025,10.1007/s10805-025-09641-z,http://eric.ed.gov/?id=EJ1485441,Foreign Countries; College Students; Student Attitudes; Computer Attitudes; Artificial Intelligence; Technology Uses in Education; Technology Integration; Writing (Composition); Expertise; Student Rights; Integrity; Guidelines; Training; Ethics; Technological Literacy; Adoption (Ideas),English,Journal Articles; Reports - Research
ED671850,Enhancing the CPL Process in Business Education through Advisor Support,Renata Kochut; Thomas Brady,2024,"This paper examines the Individualized Credit for Prior Learning (CPL) process in business education. It highlights its role in accrediting students' experiential learning and bridging practical experience with academic credit. This research then recommends solutions that include AI tools, advisor training, and centralized resource hubs. Most promisingly, integrating AI tools helps identify skills, suggests alignment with academic competencies, and provides personalized feedback on students' submissions. It also passes through the ethical dimensions of responsible AI implementation, like data privacy, fairness, and transparency. These findings suggest that advisor support, coupled with AI-enhanced tools, would not only increase the quality of submissions but also make the process more effective and accessible. Integration of this technology into the targeted support strategies will help the iCPL process serve a broader student population and thus foster greater inclusivity and lifelong learning opportunities in higher education. [For the full proceedings, see ED671809.]","International Society for Technology, Education, and Science","Paper presented at the International Conference on Social and Education Sciences (IConSES) (Chicago, IL, Oct 17-20, 2024)",,http://eric.ed.gov/?id=ED671850,Business Education; Artificial Intelligence; Technology Uses in Education; Credits; Prior Learning; Universities; Academic Advising; Faculty Advisers; Training Methods; Role; Educational Equipment; Instructional Materials; Technology Integration; Alignment (Education); Individualized Instruction; Feedback (Response); Information Security; Privacy; Justice; Accountability,,Speeches/Meeting Papers; Reports - Evaluative
EJ1471793,Artificial Intelligence in Academic Writing and Research Skills in Kenyan Universities: Opportunities and Challenges,Elizabeth Atieno Obura; Peter Imatari Emoit,2024,"This article aims to examine the opportunities and challenges of artificial intelligence (AI) in academic writing and research skills. It suggests recommendations that universities can use to develop to enhance the proper use of AI. As many institutions continue to embrace and use AI tools worldwide, questions surrounding its utilisation in the education sector continue to emerge. Following the continued adoption of AI in academia, several studies have been conducted to examine its impact. Some studies reveal that AI can be instrumental in scientific and academic research while inspiring new research topics and areas. However, universities in Kenya face challenges in tapping into AI opportunities and addressing the challenges associated with AI adoption, such as plagiarism and misinformation. Therefore, the main objective of this article was to analyse the gaps in AI in academic writing and research skills in Kenyan universities. It has two aims: firstly, it analyses the opportunities associated with AI tools in academic writing and research skills, and secondly, it examines the challenges Kenyan universities face in using AI tools. A semisystematic literature review from EBSCO and Google Scholar databases for peer-reviewed articles, policies, internet websites, government documents, parliamentary bills, online digital news, and institutional documents published since 2017 was conducted. Four key steps were used in literature identification: search, inclusion and exclusion criteria, development of themes, and analysis. Our findings suggest that adopting AI in academic writing and research skills is integral for quality research and academic integrity in universities. We recommend the formulation of AI policy frameworks that will regulate and support academic research integrity in universities. The findings will add to the available literature pool of knowledge on how Kenyan and other African universities are preparing to integrate AI into academia and will identify areas that need more attention from scholars to enhance the teaching and learning experience.",Africa Education Review,v20 n6 p58-80 2024,10.1080/18146627.2024.2440351,http://eric.ed.gov/?id=EJ1471793,Artificial Intelligence; Computer Software; Academic Language; Writing (Composition); Technology Integration; Barriers; Universities; Plagiarism; Misinformation; Foreign Countries; Educational Opportunities; Research Skills; Writing Instruction; Research Training; Ethics; Integrity,English,Journal Articles; Reports - Research
ED663041,Advancing High School Dropout Predictions Using Machine Learning,Anika Alam; A. Brooks Bowden,2024,"Background: The importance of high school completion for jobs and postsecondary opportunities is well- documented. Combined with federal laws where high school graduation rate is a core performance indicator, school systems and states face pressure to actively monitor and assess high school completion. This proposal employs machine learning techniques to identify students at-risk of exiting high school in either 9th or 10th grade. We argue that compared to students who may exit in later years of schooling, students who withdraw in the first two years are a vulnerable population and could benefit from earlier intervention, support, and services. This proposal advances the current state of knowledge in the field by (1) predicting early withdrawal of students who exit in 9th or 10th grade without eventual completion, and (2) assessing algorithmic bias for sensitive groups. Research Questions: This project investigates the following research questions to predict early exit from high school: 1: How does the prediction accuracy of supervised learning algorithms to predict high school withdrawal compare to that of traditional models (i.e., logistic regression)? 2: What are the most salient predictors of students who exit high school in 9th or 10th grade? 3: To what extent does each mode provide fair predictions across sensitive attributes such as gender, race/ethnicity, disability status, financial hardship, and English proficiency? Based on prior literature, we hypothesize that machine models will provide more predictive accuracy than an OLS regression. While there are clear hypotheses related to the importance of attendance, behavior, and coursework trajectories on high school completion, little is known about which of these aspects of middle school engagement are most predictive of exiting high school early. Setting: This project relies on existing administrative data housed at the North Carolina Education Research Data Center (NCERDC). We examine student educational records from 6th to 8th grade to predict the probability that a student will exit high school in 9th or 10th grade. The predictors include End-of- Grade test scores, attendance rates, chronic absenteeism, disciplinary infractions, school mobility, and urbanicity. Population: We examine first-time sixth-grade public school students during the 2011-2012 school year. We limit the sample to students in districts that follow a legal dropout age of 16 and those with complete graduation or exit records. We retain students who have some or all attendance and state test score data in middle grades and impute missing data with a student's unique middle school median. 94% of students in this cohort persist in the school system beyond 10th grade, compared to 6% who exit in 9th or 10th grade. Research Design: Like earlier empirical work, we compare prediction accuracy of a traditional logistic regression model to more advanced machine learning algorithms: lasso regression, ridge regression, random forests, and extreme gradient boosting (XGboost) (Mduma et al., 2019; Hung, 2017; Sansone, 2019; Coleman, 2021; Sorenson, 2018). We create binary classification models with an outcome of ""1"" for students who exited in 9th or 10th grade, and ""0"" otherwise. To evaluate model performance, we examine the area under curve (AUC), accuracy rate, sensitivity (true positive rate), specificity (true negative rate), and F-1 score. The results focus on sensitivity, or the accuracy rate for students who exit early. We follow standard machine learning practices and cross-validate models by using sixth-grade students in Fall 2010 as a training sample and sixth-grade students in Fall 2011 as a testing sample. We apply standard metrics of maximizing accuracy with parameters and hyperparameters that are standard for each algorithm. We rely on receiver-operating characteristic (ROC) curve analyses and apply a decision threshold to achieve a true positive rate of 80%. To prevent the models from being biased towards the majority class, we address class imbalance by oversampling the minority class. Specifically, we apply Synthetic Minority Oversampling Technique (SMOTE) to generate synthetic minority class observations based on the k-nearest neighbor for the minority class (Chawla et al. 2002; Fernandes et al. 2018; Anis & Ali, 2017). To examine if algorithms discriminate against certain student groups, we ""blind"" the algorithms to gender and race/ethnicity. We conduct an Absolute Between-ROC Area (ABROCA) slicing analysis to evaluate algorithmic fairness between the majority and minority group for student group. We focus on the following protected attributes: gender, race/ethnicity, English learner status, disability status, and economic disadvantage. Findings: We find that when models are trained with highly imbalanced data, both ensemble methods -- XGboost and random forest -- provide the highest sensitivity rate. However, we see substantial improvements in the sensitivity rates of all models that were trained with synthetic data (SMOTE). The improved accuracy in identifying the minor class comes at a penalty of a lower accuracy rate and lower specificity. Despite other models having higher sensitivity, we argue that the strongest model is with XGboost trained with SMOTE observations because it provides a higher specificity. In examining model features we find that age in 8th grade and being chronically absent in a middle school attendance are most predictive of early exit, followed by 8th grade and 7th grade absences. We detect no signs of algorithmic bias for students stratified by gender, disability status, and economic disadvantage. Conversely, we detected bias in regression-based models for students stratified by English learner status and race/ethnicity. Conclusion: Please see the Abstract PDF for the full updated abstract.",Society for Research on Educational Effectiveness,,,http://eric.ed.gov/?id=ED663041,Dropout Characteristics; Prediction; Artificial Intelligence; At Risk Students; High School Students; Grade 9; Grade 10; Withdrawal (Education); Accuracy; Algorithms; Regression (Statistics); Grade 6; Models; Sampling; Racial Differences; Gender Differences; Ethnicity; Student Characteristics; English Language Learners; Students with Disabilities; Low Income Students; Grade 8; Grade 7; Attendance,,Reports - Research
EJ1434302,"Communication Educators Facing the Arrival of Generative Artificial Intelligence: Exploration in Mexico, Peru, and Spain",Julio-César Mateus; Nohemi Lugo; Giancarlo Cappello; Mar Guerrero-Pico,2024,"This research explores university educators' perspectives on the opportunities, concerns, and considerations associated with Generative Artificial Intelligence (GenAI) in the training of professional communicators. Positioned at the early stages of ChatGPT's integration into educational settings, the study examines teachers' assignment instructions, assessments of ChatGPT's responses, and reflections on these outcomes. Employing a cross-sectional, qualitative methodology, the research involves a sample of 22 teachers from communication faculties in Mexico, Peru, and Spain. Utilizing Bloom's taxonomy and an inductive approach for data analysis, the findings unveil nuanced views on GenAI's role in teaching practice. Teachers perceive ChatGPT as a tool with varying impacts depending on its application. They articulate distinct roles for ChatGPT, viewing it as either an ally or a rival, prompting discussions on anthropomorphizing technologies and emphasizing the need to empower students in GenAI tool usage, establish ethical protocols, and reconsider assessment methods, among other key considerations.",Digital Education Review,n45 p106-115 2024,,http://eric.ed.gov/?id=EJ1434302,Technology Uses in Education; Artificial Intelligence; College Faculty; Teacher Attitudes; Technology Integration; Assignments; Teaching Methods; Ethics; Educational Benefits; Information Technology; Foreign Countries,English,Journal Articles; Reports - Research
EJ1413267,A New Chapter Is Being Written about Writing Instruction: Instructional Leadership at K-12 Levels in the Age of Artificial Intelligence (AI),Pinar Ayyildiz; Adem Yilmaz,2023,"In this study, in which artificial intelligence applications are examined at the K-12 level, the discussions are multi-dimensional. The use of artificial intelligence applications at the K-12 level, and especially the integrated use of online writing tools into the writing lessons, has led to the occurrence of plagiarism from time to time. In the first place, the fact that artificial intelligence applications create the feeling of being able to think like a human causes student to fully trust this software. What is more, when the subject is approached in terms of educational leadership, teachers' transfer of experience and high level of interaction during teaching and learning decreases. Because artificial intelligence applications individualize the education process and allow students to work more independently from the teacher and from peers. That being said, there are some points that are worth noting here. AI applications should be used as a tool, not an end because when these applications are utilized accountability cannot always be attained. The number of teachers who are already competent in informing and supervising students against malpractices is not sufficient. The fact that teachers are not fully competent in this respect poses a danger to the control and safety of the process. In order for artificial intelligence applications to be exercised effectively at the K-12 level, some software languages and coding skills must be acquired. Lastly, important steps need to be taken towards the future of artificial intelligence applications. Each country should include them in their education systems through their curricula from an early age along with AI applications. In this direction, teacher training programs should also be reviewed. It is of crucial importance to raise the awareness of the society on artificial intelligence, and about ethical rules and morality.",Educational Policy Analysis and Strategic Research,v18 n4 p82-101 2023,,http://eric.ed.gov/?id=EJ1413267,Artificial Intelligence; Elementary Secondary Education; Writing Instruction; Educational Technology; Plagiarism; Technology Uses in Education; Ethics; Instructional Leadership,English,Journal Articles; Reports - Research
EJ1477732,A Call for Clarity: Biology Students Advocate for Guidelines for the Use of Generative AI in Higher Education,Raquel Coelho; Anne E. Bjune; Ståle Ellingsen; Belinda Munoz Solheim; Ruben Thormodsaeter; Barbara Wasson; Sehoya Cotner,2025,"Questions around the use and regulation of Generative AI (GenAI) in educational contexts are widespread among both students and educators; an important step toward addressing these questions is to gain a full and nuanced understanding of the perspectives at play. To that end, this study surveyed 742 biology students across nine higher education institutions in Norway to understand their experiences with and perspectives on integrating GenAI tools into their education. Findings indicate that students support a balanced approach to integrating these tools, viewing platforms such as ChatGPT positively, primarily as supplementary learning aids. However, they raised concerns about ethics, accuracy, and bias and emphasized the need for institutional guidelines and training to support responsible use and enhance learning. This study aims to broaden perspectives from students globally and provide evidence that supports strategies to meet students' needs; in parallel, we advocate for designing effective educator-student partnerships as a means of exploring the best ways to use GenAI tools in higher education.",Journal of Science Education and Technology,v34 n4 p853-865 2025,10.1007/s10956-025-10216-1,http://eric.ed.gov/?id=EJ1477732,Biology; Science Instruction; Artificial Intelligence; Student Surveys; Student Attitudes; Computer Software; Ethics; Accuracy; Guidelines; Student Needs; Teacher Student Relationship; Instructional Design; Bias; College Students; Technology Integration; Foreign Countries,English,Journal Articles; Reports - Research
ED675663,Privacy-Preserving Distributed Link Predictions among Peers in Online Classrooms Using Federated Learning,Anurata Prabha Hridi; Muntasir Hoq; Zhikai Gao; Collin Lynch; Rajeev Sahay; Seyyedali Hosseinalipour; Bita Akram,2025,"Social interactions among classroom peers, represented as social learning networks (SLNs), play a crucial role in enhancing learning outcomes. While SLN analysis has recently garnered attention, most existing approaches rely on centralized training, where data is aggregated and processed on a local/cloud server with direct access to raw data. However, in real-world educational settings, such direct access across multiple classrooms is often restricted due to privacy concerns. Furthermore, training models on isolated classroom data prevents the identification of common interaction patterns that exist across multiple classrooms, thereby limiting model performance. To address these challenges, we propose one of the first frameworks that integrates Federated Learning (FL), a distributed and collaborative machine learning (ML) paradigm, with SLNs derived from students' interactions in multiple classrooms' online forums to predict future link formations (i.e., interactions) among students. By leveraging FL, our approach enables collaborative model training across multiple classrooms while preserving data privacy, as it eliminates the need for raw data centralization. Recognizing that each classroom may exhibit unique student interaction dynamics, we further employ model personalization techniques to adapt the FL model to individual classroom characteristics. Our results demonstrate the effectiveness of our approach in capturing both shared and classroom-specific representations of student interactions in SLNs. Additionally, we utilize explainable AI (XAI) techniques to interpret model predictions, identifying key factors that influence link formation across different classrooms. These insights unveil the drivers of social learning interactions within a privacy-preserving, collaborative, and distributed ML framework--an aspect that has not been explored before. [For the complete proceedings, see ED675583.]",International Educational Data Mining Society,"Paper presented at the International Conference on Educational Data Mining (EDM) (18th, Palermo, Italy, Jul 20-23, 2025)",,http://eric.ed.gov/?id=ED675663,Privacy; Peer Relationship; Online Courses; Social Networks; Cooperative Learning; Artificial Intelligence; Technology Uses in Education; Program Effectiveness; Interaction,,Speeches/Meeting Papers; Reports - Research
EJ1459552,Charting the Future of Assessments. Research Report. ETS RR-24-13,Patrick Kyllonen; Amit Sevak; Teresa Ober; Ikkyu Choi; Jesse Sparks; Daniel Fishtein,2024,"Assessment refers to a broad array of approaches for measuring or evaluating a person's (or group of persons') skills, behaviors, dispositions, or other attributes. Assessments range from standardized tests used in admissions, employee selection, licensure examinations, and domestic and international large-scale assessments of cognitive and behavioral skills to formative K-12 classroom curricular assessments. The various types of assessments are used for a wide variety of purposes, but they also have many common elements, such as standards for their reliability, validity, and fairness--even classroom assessments have standards. We believe the future of assessment will involve a shift in emphasis on what skills will be measured, innovations in how we go about measuring them, the use of advanced technologies for test operations, and an expansion in the value and kinds of information that test takers will receive from taking the assessment. In this paper, we argue and provide evidence for our belief that the future of assessment contains challenges but is promising. The challenges include risks associated with security and exposure of personal data, test score bias, and inappropriate test uses, all of which may be exacerbated by the growing infiltration of artificial intelligence (AI) into our lives. The promise is increasing opportunities for testing to help individuals achieve their education and career goals and contribute to well-being and overall quality of life. To help achieve this promise we focus on the evidence-based science of measurement in education and workplace learning, a theme throughout this paper.",ETS Research Report Series,Dec 2024,,http://eric.ed.gov/?id=EJ1459552,Assessment Literacy; Testing; Test Bias; Test Construction; Test Format; Test Interpretation; Test Reliability; Test Validity; Computer Assisted Testing; Artificial Intelligence; Test Use; Information Security; Soft Skills; Goal Orientation; Well Being; Quality of Life; Evidence Based Practice; Workplace Learning; Academic Achievement; Thinking Skills; Alternative Assessment,English,Journal Articles; Reports - Evaluative
ED676273,Multifaceted Assessment of Responsible Use and Bias in Language Models for Education,Ishrat Ahmed; Wenxing Liu; Rod D. Roscoe; Elizabeth Reilley; Danielle S. McNamara,2025,"Large language models (LLMs) are increasingly being utilized to develop tools and services in various domains, including education. However, due to the nature of the training data, these models are susceptible to inherent social or cognitive biases, which can influence their outputs. Furthermore, their handling of critical topics, such as privacy and sensitive questions, is essential for responsible deployment. This study proposes a framework for the automatic detection of biases and violations of responsible use using a synthetic question-based dataset mimicking student-chatbot interactions. We employ the LLM-as-a-judge method to evaluate multiple LLMs for biased responses. Our findings show that some models exhibit more bias than others, highlighting the need for careful consideration when selecting models for deployment in educational and other high-stakes applications. These results emphasize the importance of addressing bias in LLMs and implementing robust mechanisms to uphold responsible AI use in real-world services.",Grantee Submission,Computers v14 n3 Article 100 2025,,http://eric.ed.gov/?id=ED676273,Artificial Intelligence; Natural Language Processing; Computer Mediated Communication; College Students; Ethics; Computer Uses in Education; Automation; Social Bias; Privacy; Safety; Evaluation Methods,,Journal Articles; Reports - Research
ED662806,Examination of Artificial Intelligence Literacy Levels of Psychological Counseling Candidates: A Qualitative Study,Irem Topuz; Beyza Nur Çelik,2024,"This qualitative research aims to examine the artificial intelligence literacy levels of psychological counseling candidates. Within the scope of the research, semi-structured interviews were conducted with 3rd and 4th-year students of the Guidance and Psychological Counseling program, and the views of 18 participants were analyzed. The data were processed using thematic analysis with the QDA Miner Lite 3.0 program. According to the research findings, participants stated that artificial intelligence lacks human aspects but can function as a support assistant for psychological counselors. In terms of ethical issues, privacy concerns were prominent, and some participants expressed that artificial intelligence could help resolve ethical dilemmas. In the context of future-oriented views, it was emphasized that artificial intelligence literacy should be increased, integrated into the curriculum, and current technologies should be followed. Concerns about trust and danger indicate that confidence in artificial intelligence needs to be increased. Regarding usage problems and purposes, it was stated that the correct and effective use of artificial intelligence could increase the efficiency of counseling processes. The research reveals a significant gap in artificial intelligence literacy among psychological counseling candidates and highlights the need to strengthen education in this area. The majority of participants have limited knowledge about artificial intelligence, showing the necessity of placing more emphasis on this topic in educational programs. Additionally, it is understood that artificial intelligence tools currently used in psychological counseling practice will play an even more critical role in the future. The study emphasizes that to support the professional advancement of psychological counseling candidates, their artificial intelligence literacy levels must be increased. [This paper was published in: ""EJER Congress 2024 International Eurasian Educational Research Congress Conference Proceedings,"" edited by Senel Poyrazli, Ani Publishing, 2024, pp. 40-45.]",Online Submission,"Paper presented at the International Eurasian Educational Research Congress (EJERCongress) (11th, Türkiye, May 21-24, 2024)",,http://eric.ed.gov/?id=ED662806,Artificial Intelligence; Literacy; Knowledge Level; Counselor Training; Undergraduate Students; Student Attitudes; Ethics; Privacy; Problem Solving; Integrated Curriculum; Trust (Psychology); Risk,,Speeches/Meeting Papers; Reports - Research
EJ1477740,The Paradox of AI in ESL Instruction: Between Innovation and Oppression,Liat Ariel; Merav Hayak,2025,"This article critically examines Artificial Intelligence in Education (AIED) within English as a Second Language (ESL) contexts, arguing that current practices often deepen systemic inequality. Drawing on Iris Marion Young's ""Five Faces of Oppression,"" we analyze the implementation of AIED in oppressed schools, illustrating how students are tracked into the consumer track--passive users of AI technologies--while privileged students are directed into the creator track, where they learn to design and develop AI. This divide reinforces systemic inequality, depriving disadvantaged students of communicative agency and social mobility. Focusing on the Israeli context, we demonstrate how teachers and students in these schools lack the training and infrastructure to engage meaningfully with AI, resulting in its instrumental rather than transformative use. This ""veil of innovation"" obscures educational injustice, masking deep inequalities in access, agency, and technological fluency. We advocate for an inclusive pedagogy that integrates AI within English education as a tool for empowerment--not as a replacement for linguistic and cognitive development.",Educational Theory,v75 n4 p646-660 2025,10.1111/edth.70034,http://eric.ed.gov/?id=EJ1477740,Artificial Intelligence; Technology Uses in Education; English (Second Language); Second Language Instruction; Equal Education; Social Bias; Technological Literacy; Access to Computers; Foreign Countries; Disadvantaged Youth; Language Proficiency,English,Journal Articles; Reports - Evaluative
EJ1483795,Exploring Omani EFL Student Teachers' Perceptions on Fostering Critical Thinking through Ethical Use of AI,Zulaikha Al-Saadi; Hanan Khalil; Ahmed Mohamed Fahmy Yousef,2025,"Background/purpose: This study explores the perceptions of Omani pre-service EFL teachers on promoting critical thinking through the ethical use of AI. The rationale of this study is to better understand the perceived strengths and training needs of pre-service teachers regarding the use of AI, which can improve future educational policy and practice. Materials/methods: A mixed methods approach is employed in this research, which combines a quantitative analysis of survey data with qualitative insights from focus group discussions to examine how AI ethics affect critical thinking and teaching practices. Data was collected from 83 EFL pre-service teachers at the University of Technology and Applied Sciences, Rustaq College, Oman. Results: The most notable finding to emerge from the analysis is a strong awareness of AI ethics among EFL pre-service teachers, with a particular emphasis on data protection, academic integrity, and the balanced use of AI to enhance critical thinking. However, challenges like integrating AI ethics into curricula, a lack of sufficient resources, and limited expertise were identified. Conclusion: This study underlines the importance of institutional support when integrating AI ethics into education and fostering critical thinking skills, ensuring AI acts as an enabler rather than a hindrance to the educational experience.",Educational Process: International Journal,v17 Article e2025319 2025,,http://eric.ed.gov/?id=EJ1483795,Foreign Countries; Preservice Teachers; Student Attitudes; Critical Thinking; Ethics; Artificial Intelligence; Technology Uses in Education; Student Needs; Training; Knowledge Level; Barriers; Information Security; Privacy,English,Journal Articles; Reports - Research; Tests/Questionnaires
EJ1491300,Beyond the Hype: Evidence-Based Approaches to Responsible AI Integration in Workplace Learning,Martin Sposato,2025,"Purpose: This paper examines the integration of artificial intelligence (AI) in organizational training and development through an evidence-based lens, addressing the gap between technological enthusiasm and pedagogical effectiveness in workplace learning contexts. Design/methodology/approach: An integrative literature review methodology was employed following Torraco's (2016) framework for synthesizing diverse knowledge streams. The analysis examined 180 papers from multiple databases, combining theoretical frameworks from social cognitive theory (Bandura, 1986) and organizational learning theory (Dittmar et al., 2025) to develop an integrated conceptual framework. Findings: The analysis reveals critical misalignments between current AI implementation practices and established learning principles. While AI demonstrates effectiveness in personalized content delivery and routine skill development, significant challenges emerge in supporting transformative learning and maintaining social learning dynamics. Cultural variations and ethical considerations substantially influence implementation success. Originality/value: This paper contributes an integrated theoretical framework bridging individual and organizational learning perspectives in AI contexts, identifies specific gaps between technological capabilities and pedagogical requirements and proposes evidence-based guidance for practitioners navigating AI implementation decisions.",Education & Training,v67 n9 p928-939 2025,10.1108/ET-01-2025-0034,http://eric.ed.gov/?id=EJ1491300,Artificial Intelligence; Technology Uses in Education; Instructional Effectiveness; Evidence Based Practice; Workplace Learning; Barriers; Cultural Differences; Organizational Learning; Program Implementation; Ethics; Governance,English,Journal Articles; Information Analyses
ED671799,AI Integration into Andragogical Education,"Viktor Wang, Editor",2025,"Artificial Intelligence (AI) integration in andragogical education offers significant enhancements to the learning experience for adult learners. By utilizing AI-powered platforms, instructors can provide personalized learning paths that adapt to the unique needs, interests, and goals of each individual. These systems can analyze performance data to deliver tailored content and resources, facilitating more effective skill development. Ultimately, AI empowers adult learners to take greater ownership of their education, promoting lifelong learning and professional growth. ""AI Integration into Andragogical Education"" examines the impact of AI's integration into andragogical education and its impact on adult learners. It further delves into ethical considerations and strategies for AI's implementation. Covering topics such as critical thinking, higher education, and urban education, this book is an excellent resource for educators, administrators, instructional designers, policymakers, researchers, and more.",IGI Global,,,http://eric.ed.gov/?id=ED671799,Andragogy; Artificial Intelligence; Computer Software; Technology Integration; Individualized Instruction; Intelligent Tutoring Systems; Teaching Methods; Adult Learning; Lifelong Learning; Adult Education; Professional Development; Ethics; Educational Strategies; Critical Thinking; Higher Education; Urban Education; Transformative Learning; Independent Study; Problem Solving; Education Work Relationship; Labor Needs; Equal Education,,Books; Collected Works - General
EJ1399080,Using Generative Artificial Intelligence for Language Education Research: Insights from Using OpenAI's ChatGPT,"Pack, Austin; Maloney, Jeffrey",2023,"Progress made in Natural Language Processing (NLP) and Artificial Intelligence (AI) in recent years has resulted in these tools becoming more accessible for individuals who lack professional training. Of particular note are large language models, such as OpenAI's GPT-3.5. Discussions of utilizing AI for language education usually focus on the impact the technology will have on students and teachers. Less frequently the center of attention is how generative AI tools can empower researchers. The purpose of this paper is to raise awareness by demonstrating and discussing examples of how OpenAI's chatbot, ChatGPT, can be leveraged as a tool for language education researchers. After briefly introducing the use of AI generative tools in the field, this paper demonstrates how a researcher, without any understanding of NLP or AI, may use ChatGPT to assist with research through multiple means, including approaches to its use for compiling and summarizing information, and as a research assistant throughout multiple steps of research. This is followed by a discussion of potential ethical concerns of using AI for research in the field. We conclude by issuing a call for further work examining how researchers can harness the potential of this technology in ethical ways.",TESOL Quarterly: A Journal for Teachers of English to Speakers of Other Languages and of Standard English as a Second Dialect,v57 n4 p1571-1582 2023,10.1002/tesq.3253,http://eric.ed.gov/?id=EJ1399080,Artificial Intelligence; Computer Software; Teaching Methods; Second Language Learning; Second Language Instruction; Ethics; Natural Language Processing; Technology Uses in Education,English,Journal Articles; Reports - Evaluative
EJ1436064,Generative AI and the Development of Assignments That Promote Critical Thinking and Ethical Application in Counselor Education,Imre Csaszar; Jennifer R. Curry,2024,"Students have gravitated toward the convenience of artificial intelligence (AI) to generate text, music, and for entertainment. Faculty are also emerging as AI consumers. Given that faculty workloads have become increasingly difficult to manage, AI holds promise for assisting with teaching and research. In this article, a pedagogical case study is presented with findings from two courses where generative AI was implemented to facilitate graduate student learning through assignments created that aligned to course objectives and lessons. Findings and implications are discussed.",Research Issues in Contemporary Education,v9 n2 p82-108 2024,,http://eric.ed.gov/?id=EJ1436064,Artificial Intelligence; Assignments; Critical Thinking; Ethics; Counselor Training; Technology Uses in Education; Graduate Students; Student Attitudes; Inquiry,English,Journal Articles; Reports - Research
EJ1482950,Integrating Generative AI in Teacher Education: A Qualitative Exploration of TPACK Growth and Critical Reflection,Min Jou; Tzu-Hsuan Kuo; Yu-Chun Chiang; Yungwei Hao; Chun-Chiang Huang,2025,"This study investigates how generative AI technologies influence pre-service teachers' pedagogical thinking and instructional design practices within a vocational education context. Drawing on a qualitative framework, the research engaged students in a task-based learning environment that integrated tools such as ChatGPT and image generators into authentic teaching design tasks. Data were collected through reflective journals, interviews, and teaching artifacts. Thematic analysis revealed three core trajectories of professional growth: (1) a shift from uncertainty to confidence in using AI tools; (2) the situated development of TPACK through iterative design and reflection; and (3) the emergence of critical awareness regarding AI ethics, accuracy, and bias. Students not only explored how AI could support their instructional creativity, but also expressed concerns about content reliability and the limitations of automated outputs. Their reflections illustrated an evolving understanding of AI not just as a tool, but as a coparticipant in instructional reasoning. The findings suggest that meaningful integration of generative AI requires more than technical training; it calls for pedagogical framing, ethical discourse, and reflective space. Teacher education programs must therefore cultivate not only AI fluency, but also critical and adaptive instructional mindsets capable of navigating the complexities of AI-supported teaching.",Turkish Online Journal of Educational Technology - TOJET,v24 n3 p54-59 2025,,http://eric.ed.gov/?id=EJ1482950,Artificial Intelligence; Preservice Teacher Education; Preservice Teachers; Pedagogical Content Knowledge; Technological Literacy; Technology Uses in Education; Self Efficacy; Reflection; Ethics; Accuracy; Bias; Creativity; Instructional Design; Foreign Countries,English,Journal Articles; Reports - Research
EJ1388779,Bias in Automatic Speech Recognition: The Case of African American Language,"Martin, Joshua L.; Wright, Kelly Elizabeth",2023,"Research on bias in artificial intelligence has grown exponentially in recent years, especially around racial bias. Many modern technologies which impact people's lives have been shown to have significant racial biases, including automatic speech recognition (ASR) systems. Emerging studies have found that widely-used ASR systems function much more poorly on the speech of Black people. Yet, this work is limited because it lacks a deeper consideration of the sociolinguistic literature on African American Language (AAL). In this paper, then, we seek to integrate AAL research into these endeavors to analyze ways in which ASRs might be biased against the linguistic features of AAL and how the use of biased ASRs could prove harmful to speakers of AAL. Specifically, we (1) provide an overview of the ways in which AAL has been discriminated against in the workforce and healthcare in the past, and (2) explore how introducing biased ASRs in these areas could perpetuate or even deepen linguistic discrimination. We conclude with a number of questions for reflection and future work, offering this document as a resource for cross-disciplinary collaboration.",Applied Linguistics,v44 n4 p613-630 Aug 2023,10.1093/applin/amac066,http://eric.ed.gov/?id=EJ1388779,Automation; Speech Communication; Black Dialects; Racism; Artificial Intelligence; Racial Discrimination; Linguistics,English,Journal Articles; Reports - Evaluative
ED675601,A Bias-Aware Deep Learning Framework for Hierarchical Microcredential Classification,Mohammad Arif Ul Alam; Geeta Verma; Eumie Jhong; Justin Barber; Ashis Kumer Biswas,2025,"The growing demand for microcredentials in education and workforce development necessitates scalable, accurate, and fair assessment systems for both soft and hard skills based on students' lived experience narratives. Existing approaches struggle with the complexities of hierarchical credentialing and the mitigation of algorithmic bias related to gender and ethnicity. In this paper, we propose a novel deep learning framework that integrates hierarchical classification based on dynamic thresholding with a dual deep Q network dueling (DDQN dueling) for bias mitigation. Our method improves predictive performance at all three levels of microcredential classification, achieving an increase in 7% sensitivity and an improvement in 6% specificity over baseline models. Furthermore, our framework significantly improves fairness by reducing gender and ethnicity bias, as measured by equalized odds, by over 20% compared to conventional approaches. Extensive evaluations on a dataset of 3,000 student narratives demonstrate a 12% improvement in the F1 score and a 5% increase in AUROC relative to existing methods. These results underscore the effectiveness of our approach in advancing both hierarchical classification accuracy and fairness in real-world educational applications. [For the complete proceedings, see ED675583.]",International Educational Data Mining Society,"Paper presented at the International Conference on Educational Data Mining (EDM) (18th, Palermo, Italy, Jul 20-23, 2025)",,http://eric.ed.gov/?id=ED675601,Microcredentials; Sex; Ethnicity; Artificial Intelligence; Natural Language Processing; Bias; Algorithms; Student Experience; Material Development; Automation,,Speeches/Meeting Papers; Reports - Research
EJ1457241,The Future of Artificial Intelligence in English Language Teaching: Pros and Cons of ChatGPT Implementation through a Systematic Review,Mohammad H. Al-khresheh,2024,"The integration of artificial intelligence (AI) into language instruction has presented new opportunities, with ChatGPT emerging as a promising tool for interactive and personalized learning. This systematic review examines the effectiveness, advantages, and drawbacks of the ChatGPT in English language teaching (ELT). To achieve this objective, peer-reviewed studies published between 2023 and 2024 were sourced from the Web of Science database and focused on those that explored ChatGPT for language instruction. Using standardized criteria, data extraction covered the study design, participants, interventions, outcomes, and quality assessments. The findings indicate that the ChatGPT significantly improves language teaching by providing personalized feedback, fostering learner autonomy, enhancing student motivation and engagement, and facilitating specific language skills. Moreover, its ability to simulate real-life conversations makes it an effective tool to improve language fluency and comprehension. Nevertheless, challenges have been highlighted, such as overreliance on AI, academic dishonesty, skill deterioration, biases in AI-generated content, and the digital divide affecting access to AI technology. Integrating AI into existing educational frameworks and addressing the need for teacher training have also emerged as significant concerns. The implications are provided based on these findings.",Language Teaching Research Quarterly,v43 p54-80 2024,,http://eric.ed.gov/?id=EJ1457241,Futures (of Society); Artificial Intelligence; Computer Software; Technology Uses in Education; Second Language Learning; Second Language Instruction; English (Second Language); Individualized Instruction; Research Reports; Databases; Personal Autonomy; Independent Study; Instructional Improvement; Intervention; Outcomes of Education; Feedback (Response); Language Fluency; Language Processing; Barriers; Ethics; Integrity; Cheating; Faculty Development; Language Teachers; Educational Benefits,English,Journal Articles; Information Analyses
EJ1481172,Bridging AI Skills Gaps in Marketing Education: Prompt Engineering as a Key Competency,Mohammad Saleh Torkestani; David B. Dose; Taha Mansouri,2025,"The advancement of artificial intelligence is reshaping the marketing landscape, underscoring the need to integrate prompt engineering into marketing education. This study presents a conceptual framework for embedding prompt engineering within marketing curricula, rooted in established educational theories. An integrative literature review and thematic analysis revealed five critical themes: the essential role of prompt engineering, key techniques for marketing students, curriculum integration challenges, effective implementation strategies, and wider implications for marketing education. The resulting framework encompasses five core components: foundational AI and marketing knowledge, skill development in prompt engineering, curriculum integration and design, faculty development through interdisciplinary collaboration, and ethical AI use. A workshop-based case study demonstrates how instruction in advanced prompting techniques enhanced content clarity, creativity, and practical AI readiness. Building on these findings, the paper offers actionable recommendations for curricular design, faculty training, hands-on learning opportunities, industry partnerships, ethical considerations, and ongoing assessment. By equipping students with robust prompting skills and ethical awareness, educators can address the evolving demands of AI-driven marketing, ultimately advancing the profession. This comprehensive framework helps institutions modernize their marketing programs, fostering graduates prepared for innovation and responsible AI engagement.",Marketing Education Review,v35 n3 p188-214 2025,10.1080/10528008.2025.2501788,http://eric.ed.gov/?id=EJ1481172,Business Education; Artificial Intelligence; Computer Literacy; Marketing; College Curriculum; Educational Theories; Ethics; Integrated Curriculum; Barriers; Workshops,English,Journal Articles; Reports - Research
EJ1488657,Integrating Generative AI in Teacher Education: A Qualitative Exploration of TPACK Growth and Critical Reflection,Min Jou; Tzu-Hsuan Kuo; Yu-Chun Chiang; Yungwei Hao; Chun-Chiang Huang,2025,"This study investigates how generative AI technologies influence pre-service teachers' pedagogical thinking and instructional design practices within a vocational education context. Drawing on a qualitative framework, the research engaged students in a task-based learning environment that integrated tools such as ChatGPT and image generators into authentic teaching design tasks. Data were collected through reflective journals, interviews, and teaching artifacts. Thematic analysis revealed three core trajectories of professional growth: (1) a shift from uncertainty to confidence in using AI tools; (2) the situated development of TPACK through iterative design and reflection; and (3) the emergence of critical awareness regarding AI ethics, accuracy, and bias. Students not only explored how AI could support their instructional creativity, but also expressed concerns about content reliability and the limitations of automated outputs. Their reflections illustrated an evolving understanding of AI not just as a tool, but as a co-participant in instructional reasoning. The findings suggest that meaningful integration of generative AI requires more than technical training; it calls for pedagogical framing, ethical discourse, and reflective space. Teacher education programs must therefore cultivate not only AI fluency, but also critical and adaptive instructional mindsets capable of navigating the complexities of AI-supported teaching. [This is a reprint of an article originally published in ""Turkish Online Journal of Educational Technology"" v24 n3 p54-59 2025.]",Turkish Online Journal of Educational Technology - TOJET,v24 n4 p101-107 2025,,http://eric.ed.gov/?id=EJ1488657,Artificial Intelligence; Preservice Teacher Education; Preservice Teachers; Pedagogical Content Knowledge; Technological Literacy; Technology Uses in Education; Self Efficacy; Reflection; Ethics; Accuracy; Bias; Creativity; Instructional Design; Foreign Countries,English,Journal Articles; Reports - Research
EJ1443796,A Mobile Contextualized Educational Game Framework with ChatGPT Interactive Scaffolding for Employee Ethics Training,Yu-Chi Chen; Huei-Tse Hou,2024,"Technologies like ChatGPT and other AI tools have impacted learning by giving students more chances to ask questions and explore knowledge. The inclusion of Non-Player Characters (NPCs) as scaffolding in game-based situated learning activities can have a positive impact on learning. The application of ChatGPT to role-playing has potential; therefore, this study designed a ""ChatGPT-based NPCs scaffolding Workflow Framework"" and used it as the basis for designing and evaluating an educational game for employee ethics training with empirical evidence. This study had 61 participants, divided into a document scaffolding group (n = 32) and a ChatGPT-based NPC group (n = 29) and examined the learning achievement, flow, motivation, and anxiety in the two groups. The results showed that the designs of both groups benefited learning achievement, and both groups could maintain a certain level of high motivation and engagement. Through qualitatively analyzing the content of students' discussions with NPCs, it was found that there is potential for NPC-assisted learning through ChatGPT. Overall, this study explored the efficacy and limitations of using ChatGPT-based NPCs as scaffolding in game-based learning and found that it is extensible. We also present a framework for the design of ChatGPT-based NPCs scaffolding mechanism.",Journal of Educational Computing Research,v62 n7 p1737-1762 2024,10.1177/07356331241268505,http://eric.ed.gov/?id=EJ1443796,Educational Games; Artificial Intelligence; Natural Language Processing; Scaffolding (Teaching Technique); Interaction; Job Training; Ethics; Game Based Learning; Performance; Achievement; Motivation; Anxiety; Handheld Devices; Learner Engagement; Attitudes; Training Methods,English,Journal Articles; Reports - Research
EJ1400606,ChatGPT and Its Ethical Implications for STEM Research and Higher Education: A Media Discourse Analysis,"Nam, Benjamin H.; Bai, Qiong",2023,"With the increasing demand brought on by the beginning of the fourth industrial revolution in the period of post-digital education and bio-digital technology, artificial intelligence (AI) has played a pivotal role in supporting human intelligence and contributing to intellectuals within science, technology, science, and mathematics (STEM) and in the broader field of higher education. Thus, this study examines how writers for mainstream STEM journals and higher education magazines perceive the impact of ChatGPT, a powerful AI chatbot, on STEM research and higher education. ChatGPT can generate realistic texts based on user prompts. However, this platform also poses ethical challenges for academic integrity, authorship, and publication.Using a comparative media discourse analysis approach, this study analyzes 72 articles from four media outlets: (a) Springer Nature; (b) The Chronicle of Higher Education; (c) Inside Higher Ed; and (d) Times Higher Education. The results show that the writers expressed various concerns and opinions about the potential conflicts and crises caused by ChatGPT in three areas: (a) academic research and publication; (b) teaching and learning; and (c) human resources management.This study concludes with some policy implications and suggestions for future research on ChatGPT and AI ethics in academia by reilluminating the most overarching policy concerns related to ethical writing in STEM research and higher education and limitations to the blindness to authorship and academic integrity among diverse stakeholders.",International Journal of STEM Education,v10 Article 66 2023,10.1186/s40594-023-00452-5,http://eric.ed.gov/?id=EJ1400606,Artificial Intelligence; Ethics; Educational Research; STEM Education; Integrity; Periodicals; Higher Education; Educational Policy; Crisis Management; Authors,English,Journal Articles; Reports - Research
EJ1478854,Integrating Ethical Knowledge in Generative AI Education: Constructing the GenAI-TPACK Framework for University Teachers' Professional Development,Guoshuai Lan; Xiaoxiao Feng; Shuilian Du; Fan Song; Qi Xiao,2025,"Despite the critical role teachers play in AI education, research on their understanding of generative AI tools remains limited, particularly concerning their ethical assessment knowledge. This study addresses the gap by proposing the Generative AI Technological Pedagogical Content Knowledge (GenAI-TPACK) framework, which incorporates ethical knowledge as an essential component of university teachers' professional development. Grounded in the Technological Pedagogical Content Knowledge (TPACK) model, we utilize structural equation modeling to investigate the interrelationships among Generative AI Technological Knowledge, pedagogical knowledge, and ethical assessment knowledge. Our findings indicate that university teachers' effective use of generative AI is contingent upon their technological knowledge and engagement with these tools. Furthermore, while technical knowledge supports evaluative decision-making, it is insufficient on its own for successful integration into teaching practices. Instead, a holistic approach that combines technological and pedagogical knowledge enhances teachers' capacities to utilize generative AI effectively. The study also reveals a positive correlation between ethical assessment knowledge and both pedagogical and content knowledge, contributing to a comprehensive understanding of the GenAI-TPACK framework. This research underscores the importance of integrating ethical considerations into AI education, offering valuable insights for the professional development of educators and the enhancement of teacher training programs.",Education and Information Technologies,v30 n11 p15621-15644 2025,10.1007/s10639-025-13427-6,http://eric.ed.gov/?id=EJ1478854,Ethics; Artificial Intelligence; Technology Uses in Education; Technological Literacy; Pedagogical Content Knowledge; College Faculty; Faculty Development; Technology Integration; Knowledge Level; Teacher Education Programs,English,Journal Articles; Reports - Research
EJ1410473,When the Past != The Future: Assessing the Impact of Dataset Drift on the Fairness of Learning Analytics Models,Oscar Blessed Deho; Lin Liu; Jiuyong Li; Jixue Liu; Chen Zhan; Srecko Joksimovic,2024,"Learning analytics (LA), like much of machine learning, assumes the training and test datasets come from the same distribution. Therefore, LA models built on past observations are (implicitly) expected to work well for future observations. However, this assumption does not always hold in practice because the dataset may drift. Recently, algorithmic fairness has gained significant attention. Nevertheless, algorithmic fairness research has paid little attention to dataset drift. Majority of the existing fairness algorithms are ""statically"" designed. Put another way, LA models tuned to be ""fair"" on past data are expected to still be ""fair"" when dealing with current/future data. However, it is counter-intuitive to deploy a statically fair algorithm to a nonstationary world. There is, therefore, a need to assess the impact of dataset drift on the unfairness of LA models. For this reason, we investigate the relationship between dataset drift and unfairness of LA models. Specifically, we first measure the degree of drift in the features (i.e., covariates) and target label of our dataset. After that, we train predictive models on the dataset and evaluate the relationship between the dataset drift and the unfairness of the predictive models. Our findings suggest a directly proportional relationship between dataset drift and unfairness. Further, we find covariate drift to have the most impact on unfairness of models as compared to target drift, and there are no guarantees that a once fair model would consistently remain fair. Our findings imply that ""robustness"" of fair LA models to dataset drift is necessary before deployment.",IEEE Transactions on Learning Technologies,v17 p1007-1020 2024,10.1109/TLT.2024.3351352,http://eric.ed.gov/?id=EJ1410473,Learning Analytics; Ethics; Algorithms; Models; Correlation; Robustness (Statistics),English,Journal Articles; Reports - Research
EJ1461931,The Perspectives of Academicians and Students Regarding the Use of Generative Artificial Intelligence in Higher Education,Fulya Torun; Seda Özer Sanal,2025,"Education should strive to keep pace with the developments of the modern world and to fulfill its mission by not deviating from the principles of ethical and effective learning. In this process, it continues to be tested by unstoppable technological developments. GAI, with both its positive and negative effects, has spread incredibly quickly to every aspect of our lives. This study, which deals with GAI especially in the context of higher education, aims to evaluate the benefits and limitations of GAI on a common ground. In this context, both academicians and university students were asked to express their views on the current situation regarding the use of AI in higher education and their suggestions for the use of AI in higher education. In the study conducted within the framework of qualitative research, semi-structured interview forms prepared by the researchers were answered by 36 university students and 14 academicians. Academicians and students advocated the need for improvement in the use of GAIs, especially in terms of ease of access to information and teaching/learning support. In addition, it was stated that there are ethical problems in use; they stated that it would be important to take precautions and provide general awareness trainings.",International Journal of Technology in Education,v8 n1 p65-87 2025,,http://eric.ed.gov/?id=EJ1461931,College Students; College Faculty; Teacher Attitudes; Student Attitudes; Artificial Intelligence; Computer Software; Technology Uses in Education; Higher Education; Educational Improvement; Usability; Access to Information; Pedagogical Content Knowledge; Ethics; Teaching Methods; Learning Processes,English,Journal Articles; Reports - Research
ED639549,Research on the Attitudes of High School Students for the Application of Artificial Intelligence in Education,Vladislav Slavov; Kamelia Yotovska; Asya Asenova,2023,"Artificial intelligence (AI) technology is already challenging a variety of societal areas, including education. It is transforming education to data driven. AI-enhanced technologies in education (abbreviated AIinED) will have a significant role in changing the teaching and learning methods, as well as impacting the behavior and organization of the educational system. It is considered that the AIinED will change the paradigm of education in the future. And yet, AIinED is still more in the lab than being practically implemented in education and training. We consider three major players in the implementation of AIinED -- students, teachers, and society. All three can benefit from AIinED and at the same time be a potential target of the risks that AIinED brings along with its promises -- may be one of the reasons why main stakeholders (UNESCO, EC etc.) have been developing guidelines and recommendations for ethical use of AIinED. The literature shows that the center of AIinED system will be the student, but we consider the student not only as a target but also as a source of ideas for AIinED development with the potential to accelerate the process of adoption of AIinED. Hence, one of the big questions should be how the students foresee the role of artificial intelligence in education. To initiate such a question, though, it is important to know the level of understanding among the students about what and where artificial intelligence is. There are three major aspects that AIinED must be considered accordingly -- technological, lawful, and ethical. This paper presents the results of a study on high school students' understanding of AI technologies and their attitudes to their application in education. A survey was used as a tool to elaborate. The conceptual model of the research was developed on the basis of established theories linking attitudes to behavior and the acceptance of artificial intelligence technologies in education. Each element of this concept is explored with a different part of the questionnaire, which contains a total of 12 questions (some of which with sub-questions). The survey was elaborated online within October-November 2021. A link to the questionnaire in Bulgarian was provided to 178 high and vocational high schools educating students aged 14-19 (grades 8-12) across the country (Bulgaria). 766 students submitted their replies through the online survey form. Descriptive statistics and analysis of the frequencies of the respondents' opinions were made based on the data. The results show that the students participating in the survey:(a) understand the essence of AI technologies; (b) they are convinced of the usefulness of the application of artificial intelligence technologies in their daily activities and strongly believe that it improves it; (c) are not entirely clear about the benefits of artificial intelligence enhanced technologies in learning and teaching; (d) do not demonstrate sufficient knowledge and understanding of the necessity of ethical use of AI technologies in education; The latter reduces the positive influence of the perceived usefulness of artificial intelligence technologies in the learning process on students' attitudes. [For the full proceedings, see ED639391.]",International Association for Development of the Information Society,"Paper presented at the International Association for Development of the Information Society (IADIS) International Conferences on e-Society (ES 2023, 21st) and Mobile Learning (ML 2023, 19th) (Lisbon, Portugal, Mar 11-13, 2023)",,http://eric.ed.gov/?id=ED639549,Artificial Intelligence; High School Students; Student Attitudes; Technology Uses in Education; Role; Grade 8; Grade 9; Grade 10; Grade 11; Grade 12; Foreign Countries; Knowledge Level; Ethics,,Speeches/Meeting Papers; Reports - Research
EJ1477585,Exploring Higher Education Faculty Insights on Generative AI in Creative Courses,Roshanak Basty; Jess Kropczynski; Shane Halse,2025,"Aim/Purpose: This study examined the understudied perceptions of higher education instructors on the use of art-based AI generators in digital art, design, and creative-based courses and answered the research questions: (1) how disruptions by generative artificial intelligence (GenAIs) are impacting teaching, and (2) what are the major factors that contribute to a healthy digital art ecosystem in higher education. Background: While GenAI has attracted widespread public attention, there is insufficient research on integrating art-based AI generators in digital art and design classrooms. Concurrently, there is a demand for collecting and integrating faculty and educators' perspectives, which are key stakeholders in preparing future art and design professionals for the GenAI-driven workforce. Our study is presented against such a backdrop. Methodology: The study incorporated a mixed-method approach to analyze survey data collected from higher education faculty on their perception of text-to-image generators. Quantitative data was analyzed through statistical analysis, and qualitative data was analyzed through a blend of human-AI thematic analysis. Contribution: The study provides empirical data on higher education faculty's perspectives regarding the implications of art-based AI generators through survey and mixed-method analysis, serving as a baseline for further research and the development of AI literacy interventions. Additionally, the research identifies effective pedagogical strategies and best practices for embedding generative AI into teaching and learning, contributing to the field of education. Findings: Art-based GenAIs create both positive disruptions (e.g., improved ideation, problem-solving, and creative processes) and negative disruptions (e.g., ethical implications, technical limitations, and pedagogical concerns) in higher education. Insufficient AI literacy and inadequate resources among faculty significantly set back the effective adoption of GenAIs in classrooms. Ethical issues, including academic integrity, copyright, and bias, emerge as prominent issues requiring the implementation of responsible AI frameworks and policies. Adopting pedagogical strategies, such as action-based learning, experimental learning, and active learning, can help optimize student engagement and enhance learning outcomes. Last but not least, a healthy digital art ecosystem in higher education hinges on responsible AI use and standards, continuous technological improvement, effective educational support, a human-centered approach, and a strong sense of community and collaboration. Recommendations for Practitioners: The paper recommends increasing AI literacy among faculty through professional development programs and collaborative learning initiatives; developing and implementing responsible AI use policies, guidelines, and frameworks to address ethical concerns and ensure the effective and ethical use of GenAIs in classrooms; and integrating pedagogical strategies such as action-based learning, experimental learning, and active learning to enhance student engagement and learning outcomes with GenAIs. Recommendation for Researchers: The paper recommends conducting further research on the integration of art-based generative AI in digital art and design classrooms across all academic levels; further exploring faculty and educators' perspectives on GenAI use to develop best practices and frameworks for effective and ethical adoption in higher education; and investigating the long-term impacts of GenAI technologies on teaching and learning in art, design, and creative-integrated disciplines through longitudinal studies. Impact on Society: The larger implications of the paper's findings include promoting awareness and education on the ethical implications, benefits, and limitations of GenAIs to foster responsible use and acceptance; encouraging interdisciplinary collaboration to address the challenges and opportunities presented by GenAIs in the creative and cultural industries; and supporting the development of a healthy digital art ecosystem that balances human creativity with technological advancements, ensuring inclusivity, accessibility, and sustainability. Future Research: Based on drawbacks that emerged from the study, such as the sampling method and the sample size, future research should focus on targeting larger and more diverse samples from across different regions of the United States, as well as integrating objective measures to complement self-reported data. As this research is focused on text-to-image generators, future research should expand to additional GenAI types and models to deepen our understanding of their potential benefits and use impacts. Additionally, future research would benefit from studying the long-term impacts of GenAIs on education and the development of human-centered solutions and interventions tailored for faculty and students.",Journal of Information Technology Education: Research,v24 Article 18 2025,,http://eric.ed.gov/?id=EJ1477585,College Faculty; Teacher Attitudes; Artificial Intelligence; Art Education; Computer Uses in Education; Concept Formation; Problem Solving; Creativity; Ethics; Technology Integration; Integrity; Copyrights; Bias; Digital Literacy; Faculty Development; Best Practices; Information Technology,English,Journal Articles; Reports - Research
ED660962,Charting the Future of Assessments. Full Report,Patrick C. Kyllonen; Amit Sevak; Teresa Ober; Ikkyu Choi; Jesse Sparks; Daniel Fishtein,2024,"Assessment refers to a broad array of approaches for measuring or evaluating a person's (or group of persons') skills, behaviors, dispositions, or other attributes. Assessments range from standardized tests used in admissions, employee selection, licensure examinations, and domestic and international largescale assessments of cognitive and behavioral skills to formative K-12 classroom curricular assessments. The various types of assessments are used for a wide variety of purposes, but they also have many common elements, such as standards for their reliability, validity, and fairness--even classroom assessments have standards (Klinger et al., 2015). The authors believe the future of assessments will involve a shift in emphasis on what skills will be measured, innovations in how one goes about measuring them, the use of advanced technologies for test operations, and an expansion in the value and kinds of information that test-takers will receive from taking the assessment. In this paper, the authors argue and provide evidence for the belief that the future of assessment contains challenges but is promising. The challenges include risks associated with security and exposure of personal data, test score bias, and inappropriate test uses, all of which may be exacerbated by the growing infiltration of artificial intelligence (AI) into people's lives. The promise is increasing opportunities for testing to help individuals achieve their education and career goals and contribute to well-being and overall quality of life. To help achieve this promise the authors focus on the evidence-based science of measurement in education and workplace learning, a theme throughout this paper. The first section of the paper reviews evidence for the value of assessment and discusses how the role of assessment may expand as skills become the new currency. The many purposes of assessment are discussed, from high-stakes examinations and selection tests to low-stakes formative assessments. The emerging challenges to testing and assessment, related to perceptions about their value, their focus, validity, fairness and equity concerns, are reviewed. The authors conclude the first section with a discussion of the prospects for the future of assessments, including the capacity of assessment to provide useful information to test-takers, the importance of identifying key skills and advancing methods for assessing hard-to-measure skills, and the importance of providing opportunities with personalized feedback. The remaining sections of the paper address those themes. The intended audience for this report is broad-ranging from the international scientific community in areas engaged in assessment, particularly education and workforce, to policy-makers and funders in those areas. The authors try to strike a balance between technical detail and accessibility to the broad audience.",ETS Research Institute,,,http://eric.ed.gov/?id=ED660962,Performance Based Assessment; Evaluation Criteria; Evaluation Methods; Test Bias; Test Construction; Test Content; Test Reliability; Test Validity; Standards; Student Evaluation; Personnel Evaluation; Error of Measurement; Information Security; Computer Assisted Testing; Skill Development; Feedback (Response); Long Range Planning; Strategic Planning,,Reports - Evaluative
EJ1449345,The Use of AI Tools in English Academic Writing by Saudi Undergraduates,Burhan Ozfidan; Dina Abdel Salam El-Dakhs; Lama Adel Alsalim,2024,"This study explores Saudi undergraduate students' perceptions of artificial intelligence (AI) tools in academic writing. Despite extensive research on AI in higher education, there is limited focus on academic writing, especially in the Saudi context. A survey of 189 students, proficient in English and enrolled in freshmen academic writing courses, was conducted. The students frequently used ChatGPT, Grammarly, and Google Translate. Exploratory factor analysis identified two factors: ""instructional support of AI tools"" and ""instructional practices of AI tools,"" explaining 55.302% of the variance. Descriptive analysis revealed strong student agreement on AI tools' benefits, including idea generation, outline preparation, grammar and spell-check improvements, and time-saving. However, concerns about reliability, contextual accuracy, and ethical implications were noted. The study indicates the need for proper training and clear guidelines to make the most of AI in academic writing. The participants, in various responses, indicated how AI helps develop their writing accuracy and come up with new ideas although some participants worry about relying too much on technology. The study recommends that AI tools can be very helpful, but we need to use them thoughtfully to cater to different student experiences and concerns.",Contemporary Educational Technology,v16 n4 Article ep527 2024,,http://eric.ed.gov/?id=EJ1449345,Foreign Countries; Artificial Intelligence; Technology Uses in Education; Grammar; Spelling; Reliability; Accuracy; Computer Software; Undergraduate Students; Time Management; Ethics; Writing (Composition); Educational Benefits; Student Attitudes; English (Second Language); Language Proficiency; Second Language Learning; Second Language Instruction; Translation; Factor Analysis; Academic Language; Writing Processes; Citations (References); Prevention; Plagiarism,English,Journal Articles; Reports - Research; Tests/Questionnaires
EJ1373006,Artificial Intelligence in Education: AIEd for Personalised Learning Pathways,"Tapalova, Olga; Zhiyenbayeva, Nadezhda",2022,"Artificial intelligence is the driving force of change focusing on the needs and demands of the student. The research explores Artificial Intelligence in Education (AIEd) for building personalised learning systems for students. The research investigates and proposes a framework for AIEd: social networking sites and chatbots, expert systems for education, intelligent mentors and agents, machine learning, personalised educational systems and virtual educational environments. These technologies help educators to develop and introduce personalised approaches to master new knowledge and develop professional competencies. The research presents a case study of AIEd implementation in education. The scholars conducted the experiment in educational establishments using artificial intelligence in the curriculum. The scholars surveyed 184 second-year students of the Institute of Pedagogy and Psychology at the Abay Kazakh National Pedagogical University and the Kuban State Technological University to collect the data. The scholars considered the collective group discussions regarding the application of artificial intelligence in education to improve the effectiveness of learning. The research identified key advantages to creating personalised learning pathways such as access to training in 24/7 mode, training in virtual contexts, adaptation of educational content to personal needs of students, real-time and regular feedback, improvements in the educational process and mental stimulations. The proposed education paradigm reflects the increasing role of artificial intelligence in socio-economic life, the social and ethical concerns artificial intelligence may pose to humanity and its role in the digitalisation of education. The current article may be used as a theoretical framework for many educational institutions planning to exploit the capabilities of artificial intelligence in their adaptation to personalized learning.",Electronic Journal of e-Learning,v20 n5 p639-653 2022,,http://eric.ed.gov/?id=EJ1373006,Artificial Intelligence; Technology Uses in Education; Educational Technology; Electronic Learning; Individualized Instruction; Intelligent Tutoring Systems; Social Media; Virtual Classrooms; Foreign Countries; Access to Education; Feedback (Response); Ethics; Educational Benefits; College Students,English,Journal Articles; Reports - Research
EJ1490521,AI-Powered Education: Transforming Teacher-Student Interactions and Advancing Sustainable Learning Practices,Lixin Yan; Asim Suleman Abdullah Alwabel; Ummul Hanan Mohamad,7035,"This study explores the multifaceted impact of Artificial Intelligence (AI) on education, particularly its transformative role in reshaping teacher-student interactions, enhancing personalised learning and contributing to sustainable educational development. As AI technology rapidly advances, its integration in education is driving significant changes in teaching methodologies, student autonomy and the overall educational ecosystem. While AI demonstrates substantial potential to improve learning outcomes through personalised learning paths, intelligent assessments and real-time feedback, it also brings forth several challenges. These include concerns regarding teacher-student dynamics, ethical implications and educational equity. The study reveals that the acceptance and adaptability of both teachers and students play a crucial role in determining AI's effectiveness in the classroom. Teachers' evolving roles, as well as students' increasing autonomy, underscore the need for critical thinking and ethical decision-making skills, which are essential for maximising the benefits of AI. However, the research also identifies the risks associated with AI exacerbating existing inequalities, particularly in regions with limited technological access. The findings highlight the necessity of ensuring equitable access to AI resources, especially in disadvantaged areas, and emphasise the importance of comprehensive teacher training to support effective AI integration. By examining the global application of AI in education, the study provides policy recommendations aimed at fostering the fair use of AI, ensuring that its integration does not deepen educational disparities but rather contributes to the broader goals of sustainable development in education. This research offers insights for policymakers and educators seeking to navigate the complexities of AI in educational practice, ensuring that AI acts as a tool for empowerment rather than displacement.",European Journal of Education,v60 n4 e70351 2025,10.1111/ejed.70351,http://eric.ed.gov/?id=EJ1490521,Artificial Intelligence; Technology Uses in Education; Teacher Student Relationship; Sustainable Development; Educational Change; Individualized Instruction; Ethics; Equal Education; Teacher Role; Personal Autonomy; Critical Thinking; Access to Computers; Technology Integration; Teacher Education; Global Approach,English,Journal Articles; Reports - Research
EJ1413859,Detection of GPT-4 Generated Text in Higher Education: Combining Academic Judgement and Software to Identify Generative AI Tool Misuse,Mike Perkins; Jasper Roe; Darius Postma; James McGaughran; Don Hickerson,2024,"This study explores the capability of academic staff assisted by the Turnitin Artificial Intelligence (AI) detection tool to identify the use of AI-generated content in university assessments. 22 different experimental submissions were produced using Open AI's ChatGPT tool, with prompting techniques used to reduce the likelihood of AI detectors identifying AI-generated content. These submissions were marked by 15 academic staff members alongside genuine student submissions. Although the AI detection tool identified 91% of the experimental submissions as containing AI-generated content, only 54.8% of the content was identified as AI-generated, underscoring the challenges of detecting AI content when advanced prompting techniques are used. When academic staff members marked the experimental submissions, only 54.5% were reported to the academic misconduct process, emphasising the need for greater awareness of how the results of AI detectors may be interpreted. Similar performance in grades was obtained between student submissions and AI-generated content (AI mean grade: 52.3, Student mean grade: 54.4), showing the capabilities of AI tools in producing human-like responses in real-life assessment situations. Recommendations include adjusting the overall strategies for assessing university students in light of the availability of new Generative AI tools. This may include reducing the overall reliance on assessments where AI tools may be used to mimic human writing, or by using AI-inclusive assessments. Comprehensive training must be provided for both academic staff and students so that academic integrity may be preserved.",Journal of Academic Ethics,v22 n1 p89-113 2024,10.1007/s10805-023-09492-6,http://eric.ed.gov/?id=EJ1413859,Artificial Intelligence; Student Evaluation; Identification; Natural Language Processing; Universities; Integrity; Ethics; Cheating; Computer Software,English,Journal Articles; Reports - Research
EJ1482799,Reflections on the Merit and Perils of AI in Higher Education: Five Early Adopter's Perspectives,Mehmet Aydeniz,2025,"The rapid integration of generative artificial intelligence (GenAI) tools into higher education has prompted both enthusiasm and concern among faculty members. While AI tools such as ChatGPT, Claude, and Scite.ai offer significant pedagogical benefits--including enhanced efficiency, personalized learning, and automated instructional support--they also introduce challenges related to academic integrity, cognitive engagement, and ethical considerations. This study investigates the beliefs and practices of five early-adopter faculty members from diverse disciplines regarding the adoption of GenAI in teaching and learning at a research intensive university in the United States. Utilizing a collaborative action research methodology, the study examines faculty motivations, challenges, strategies and reflections for responsible AI integration. Findings reveal that faculty members recognize AI's potential to automate administrative tasks, support student learning through personalized assistance, and foster creativity in instructional design. However, concerns persist regarding over-reliance on AI, diminished student critical thinking, and the ethical implications of AI-generated content. Participants underscore the need for structured faculty training, robust institutional policies, and interdisciplinary collaboration to ensure AI is used responsibly and effectively. The study highlights the evolving role of faculty in an AI-driven educational landscape, shifting from content delivery to mentorship and critical engagement. As higher education institutions navigate the complexities of AI adoption, the research underscores the importance of AI literacy, ethical guidelines, and assessment redesign to mitigate risks and maximize benefits. This study contributes to the growing discourse on AI in higher education by offering evidence-based recommendations for sustainable and responsible AI integration. By fostering informed discussions among faculty and administrators the findings aim to guide the development of strategic frameworks that balance innovation with ethical considerations in higher education.",International Journal of Technology in Education and Science,v9 n4 p522-544 2025,,http://eric.ed.gov/?id=EJ1482799,Artificial Intelligence; College Faculty; Teacher Attitudes; Technology Uses in Education; Ethics; Teacher Motivation; Barriers; Educational Technology,English,Journal Articles; Reports - Research
ED677490,2025 State EdTech Trends Report,Keith Lee; Evo Popoff; David Walker,2025,"The 2025 State Educational Technology Directors Association (SETDA) State EdTech Trends Survey explores how the systems, infrastructure, and staffing that digital learning depends on will be sustained, how new flexibilities in federal formula and discretionary funding can be leveraged, what edtech tools are essential, and how to balance innovation with equity, security, privacy, and student well-being. Drawing on responses from state chiefs, chief information officers, edtech directors, and other state education agency (SEA) leaders, this report provides insight into how states are planning for and adapting to a K-12 system where technology is both foundational and fast-evolving. As K-12 education has evolved, so, too, has the survey. This year's survey and report feature new questions reflecting changing times and emerging areas of interest, such as examining how states are responding to district- and state-level proposals to restrict or ban student device use in classrooms. Artificial intelligence (AI) also plays a more central role in this year's report. In a significant shift, AI now tops the list of state edtech priorities--surpassing cybersecurity for the first time. This report takes a closer look at steps state leaders are taking to begin building guardrails and supports to ensure the effective and ethical use of AI tools in schools. The survey responses--and the state spotlights in this report--demonstrate the ways that states continue to evolve and reinvent themselves to address today's challenges.",State Educational Technology Directors Association,,,http://eric.ed.gov/?id=ED677490,Educational Technology; Educational Trends; Technology Uses in Education; Elementary Secondary Education; Educational Policy; Educational Planning; Statewide Planning; State Departments of Education; Artificial Intelligence; Educational Innovation; Technology Integration; Educational Finance; State Aid; Federal Aid; Investment; Handheld Devices; Computer Use; Digital Literacy; Professional Development; Computer Security; Internet; Information Security; Access to Education,,Reports - Research
EJ1456410,AI as Designated Designer: Training Public-Speaking Students to Use Beautiful.ai for Their Slide Presentations,Jonathan W. Camp; Heather Johnson,2025,"This paper introduces generative AI for the graphic design of student presentation aids in a university public-speaking classroom. Students learn to use generative AI as an efficient enhancement to the creative process while preserving the integrity of the content. Students' slide presentations show improvement resulting from the activity, and students report that the activity saves time and relieves stress. Courses: Public Speaking, Advanced Public Speaking, Business and Professional Communication, face-to-face and online. Objectives: Students learn how to improve the visual design of their presentation aids through use of generative AI. Students will reflect on the ethics of using AI as an enhancement to human agency and not as a replacement for it.",Communication Teacher,v39 n1 p56-60 2025,10.1080/17404622.2024.2392765,http://eric.ed.gov/?id=EJ1456410,Artificial Intelligence; Technology Uses in Education; Public Speaking; Computer Software; Visual Aids; Computer Graphics; Graphic Arts; Communications; Ethics; Influence of Technology; Time Management; College Students; Technology,English,Journal Articles; Reports - Descriptive
EJ1395260,Educational Applications of the ChatGPT AI System: A Systematic Review Research,"Ipek, Ziyaeddin Halid; Gözüm, Ali Ibrahim Can; Papadakis, Stamatios; Kallogiannakis, Michail",2023,"Background/purpose: ChatGPT is an artificial intelligence program released in November 2022, but even now, many studies have expressed excitement or concern about its introduction into academia and education. While there are many questions to be asked, the current study reviews the literature in order to reveal the potential effects of ChatGPT on education as a whole. The potential implications, possibilities, and concerns about the use of ChatGPT in education are disclosed as mentioned in the literature. Materials/methods: The data of the study were collected and then subjected to a systematic review. Research findings were analyzed according to the themes and categories identified. Results: The results of this research were examined under themes according to the positive and negative aspects of ChatGPT. The positive categories and sub-categories of ChatGPT's integration into education were determined, and the relationship between education and artificial intelligence determined. Similarly, the negative category highlighted the potential negative impact of artificial intelligence on educational processes. Conclusion: The reviewed research evaluated and discussed the impact of AI on education and training processes. In conclusion, this review revealed the critical applications of ChatGPT for educational settings and the potential negative impact of its application. The findings established how ChatGPT and its derivatives would create a new paradigm in education as a whole.",Educational Process: International Journal,v12 n3 p26-55 2023,,http://eric.ed.gov/?id=EJ1395260,Artificial Intelligence; Educational Technology; Technology Uses in Education; Educational Benefits; Natural Language Processing; Influence of Technology; Technology Integration; Documentation; Literature Reviews; Translation; Test Construction; Needs Assessment; Individualized Instruction; Grading; Data Analysis; Computer Security; Prevention; Intelligent Tutoring Systems; Cataloging; Material Development; Cheating; Identification; Legal Problems; Ethics,English,Journal Articles; Information Analyses
EJ1477733,Utilizing Deep Learning AI to Analyze Scientific Models: Overcoming Challenges,Tingting Li; Kevin Haudek; Joseph Krajcik,2025,"Scientific modeling is a vital educational practice that helps students apply scientific knowledge to real-world phenomena. Despite advances in AI, challenges in accurately assessing such models persist, primarily due to the complexity of cognitive constructs and data imbalances in educational settings. This study addresses these challenges by employing diverse analytic strategies, including the Synthetic Minority Over-sampling Technique (SMOTE), aimed at enhancing fairness and efficacy in automated scoring systems. We analyze the impact of these strategies through a robust methodology, utilizing a combination of tenfold cross-validation and independent testing phases to ensure the reliability of AI assessments. Our findings highlight the effectiveness of deep learning AI in mirroring human judgment, with improvements in accuracy, precision, recall, and F1 scores across varied model assessments. Specifically, the application of SMOTE significantly improved the scoring fairness for minority class instances, which are often underrepresented in educational datasets. This study also delves into the discrepancies between AI and human evaluations, particularly in interpreting creatively expressed student models, which reveals the areas where AI technologies require further enhancements to better align with human evaluative standards. This study lays a foundation for future research to explore advanced AI techniques and training strategies, thus promoting fair and supportive feedback mechanisms that enhance student learning and creativity. By advancing AI applications in science education, this research addresses essential challenges in the automated analysis of complex student responses and supports broader academic goals.",Journal of Science Education and Technology,v34 n4 p866-887 2025,10.1007/s10956-025-10217-0,http://eric.ed.gov/?id=EJ1477733,Artificial Intelligence; Scientific Concepts; Models; Automation; Scoring; Testing; Reliability; Evaluation Methods; Accuracy; Evaluation Criteria; Man Machine Systems; Computer Uses in Education; Science Education,English,Journal Articles; Reports - Research
EJ1474107,The Use of AI Disclosure Statements in Teaching: Developing Skills for Psychologists of the Future,Acacia L. Overono; Annie S. Ditta,2025,"Introduction: The proliferation and accessibility of generative artificial intelligence (AI) have led to strong reactions across the academia. Statement of the Problem: Teachers can adapt to the availability of AI by integrating disclosure statements about its use into courses, which may promote student learning. Literature Review: Suggestions to include AI disclosure statements from academia and industry align with several of the major goals of the ""APA Guidelines for the Undergraduate Major 3.0."" Teaching Implications: Incorporating use of AI disclosure statements may support students' achievement of APA learning outcomes. These statements ask students to disclose their use of AI and consist of the AI ""Model"" used, the exact ""Input"" provided, and a description of how the student ""Evaluated"" the content (""MInE""). Disclosures are advantageous over other methods because of their flexibility and straightforwardness. Conclusion: When students use AI and disclose their usage, they may learn to communicate ethically and clearly, employ their knowledge of psychology to fact-check output, and develop the skill of disclosure, which is becoming more popular in academic and other professional settings.",Teaching of Psychology,v52 n3 p273-278 2025,10.1177/00986283241275664,http://eric.ed.gov/?id=EJ1474107,Artificial Intelligence; Computer Software; Technology Integration; Self Disclosure (Individuals); Psychology; Outcomes of Education; Teacher Attitudes; College Faculty; Professional Associations; Guidelines; Ethics; Counselor Training,English,Journal Articles; Reports - Descriptive
EJ1485153,Technology-Enhanced Education for Neurodiverse Learners: A Bibliometric Approach to Reducing Educational Inequalities,Valentine Muriira; Venoth Nallisamy; Shem Mwalw’a; Henry Kamundi,2025,"Background/purpose: Neurodiversity, including ASD, ADHD, and dyslexia, has a powerful impact on the learning processes and interaction with education. As fairness issues are growing in technology-enhanced learning (TEL), it is high time to trace research trends and critical contributors, as well as release new themes in this area. This paper examines the current scholarship on neurodiversity and education in the world over the period of 2010 to 2025 to illuminate intellectual frameworks and new trends. Materials/methods: The bibliometric analysis concerned 336 articles obtained from Scopus. VOSviewer was used to map co-authorship, cocitation, and keyword co-occurrence. Analyses focused on academic production, country leadership, institutions, and thematic areas informing the world of research. Results: The results indicate a gradual increase in publications over the last decade, with significant contributions from the United States, United Kingdom, and Italy. Harvard University and Vanderbilt University became the top institutions. Three key research clusters were found: (1) Cognitive and Psychological Studies, which centered on the idea of executive functioning and learning difficulties in neurodiverse students; (2) Educational Technology and Learning Strategies, which centered on the concept of adaptive systems and approaches to dealing with the neurodiversity issue; and (3) Assistive Technology and Artificial Intelligence, which revolved around the idea of AI and virtual reality in supporting the neurodiversity issue. Despite advances, obstacles persist in terms of access and socio-economic disparities. Conclusion: Technology-based learning helps in meeting UN Sustainable Development Goal 4 (Quality Education), yet needs more policy changes, wider access to AI tools, and training of specific teachers to provide equal opportunities. Future research should focus on longitudinal assessments of TEL interventions and address ethical issues related to the use of AI in learning.",Educational Process: International Journal,v18 Article e2025428 2025,,http://eric.ed.gov/?id=EJ1485153,Neurodevelopmental Disorders; Students with Disabilities; Equal Education; Technology Uses in Education; Educational Technology; Educational History; Educational Research; Executive Function; Assistive Technology; Autism Spectrum Disorders; Attention Deficit Hyperactivity Disorder; Dyslexia; Authors; Periodicals; Information Retrieval; Publications; Foreign Countries,English,Journal Articles; Information Analyses
EJ1438020,Generative or Degenerative?! Implications of AI Tools in Pre-Service Teacher Education and Reflections on Instructors' Professional Development,Mohammed Estaiteyeh; Ruth McQuirter,2024,"Despite existing research on AI applications in education (AIEd), the release of ChatGPT has disrupted the status quo in the educational landscape. Although this technology can personalize learning, decrease teacher workload, and offer access to a wealth of information, concerns around generative AI (GenAI) tools have emerged, including academic integrity, data accuracy, and bias in information. Given research highlights and acknowledging educators' varied levels of awareness and conflicting views toward AIEd, two teacher educators (also authors of this paper) in the Faculty of Education at Brock University facilitated three workshops among different groups of teacher educators. The workshops focused on the emerging nature of GenAI tools, their affordances, and their implications for educators' practices. Adopting a narrative inquiry approach, the authors describe the details of these workshops and present their reflections on the process of preparing for and facilitating them. Implications for teacher education research and practice are also presented and discussed.",Brock Education: A Journal of Educational Research and Practice,v33 n3 p75-98 2024,,http://eric.ed.gov/?id=EJ1438020,Artificial Intelligence; Technology Uses in Education; Preservice Teacher Education; Reflection; Faculty Development; Natural Language Processing; Universities; Teacher Educators; Workshops; Foreign Countries; College Faculty,English,Journal Articles; Reports - Research; Tests/Questionnaires
EJ1467004,From Chalkboards to ChatGPT: Navigating the Future of Teaching with Generative AI,Beck Graefe; Andrew Porter; Jane Indorf; Soyeon Ahn; Ching-Hua Chuan; Michael Gaines,2025,"Educators are at the forefront of shaping the future of education, particularly as technological advances introduce new tools and methods. Generative AI is a powerful tool capable of producing high-quality content based on properly constructed user prompts. While these advancements present significant opportunities, they also pose challenges. This study investigates educators' general attitudes and confidence in using and guiding student use of generative AI and evaluates the effectiveness of a targeted workshop designed to increase AI literacy among educators participating in a university outreach program. Participants included 12 undergraduate resident scientists, six graduate fellows, and eight professional teachers. The study utilised a pre- and post-survey approach to evaluate shifts in AI literacy and comfort before and after the workshop. Specifically, participants reported increased confidence in using AI tools, recognizing bias in AI-generated content, and understanding the ethical implications of AI use. The study highlights the importance of targeted, multigenerational training programs to improve educators' comfort and literacy with generative AI, emphasizing the value of cross-generational collaboration in enhancing learning outcomes. The findings suggest that such training fosters a deeper understanding of generative AI, thereby enhancing its integration into pedagogical practices.",Journal of Interactive Learning Research,v36 n2 p137-156 2025,,http://eric.ed.gov/?id=EJ1467004,Undergraduate Students; Scientists; Graduate Students; College Faculty; Artificial Intelligence; Technological Advancement; Technology Integration; Technological Literacy; Outreach Programs; Teacher Workshops; Program Effectiveness; Teacher Attitudes; Computer Attitudes; Information Policy; Bias; Ethics; Intergenerational Programs; Instructional Development,English,Journal Articles; Reports - Research
ED661202,Empowering Responsible Use of Large Language Models,Xuandong Zhao,2024,"The rapid advancement of powerful Large Language Models (LLMs), such as ChatGPT and Llama, has revolutionized the world by bringing new creative possibilities and enhancing productivity. However, these advancements also pose significant challenges and risks, including the potential for misuse in the form of fake news, academic dishonesty, intellectual property infringements, and privacy leaks. In response to these concerns, this thesis explores approaches to promoting the responsible use of LLMs from both theoretical and empirical perspectives. Three key approaches are presented: (1) Detecting AI-generated Text via Watermarking: We propose a robust and high-quality watermarking method called Unigram-Watermark and introduce a rigorous theoretical framework to quantify the effectiveness and robustness of LLM watermarks. Furthermore, we propose PF-Watermark, which achieves the best balance of high detection accuracy and low perplexity. (2) Protecting the Intellectual Property of LLMs: We safeguard the intellectual property of LLMs through novel watermarking techniques designed to prevent model-stealing attacks in both text classification and text generation tasks. (3) Privacy-Preserving LLMs: We employ Confidential Redacted Training (CRT) to train and fine-tune language generation models while protecting sensitive information. In summary, we propose a suite of algorithms and solutions to address LLMs' trending safety, security, and privacy concerns. We hope our studies provide valuable insights for researchers to explore exciting future research solutions that promote responsible AI development and deployment. [The dissertation citations contained here are published with the permission of ProQuest LLC. Further reproduction is prohibited without permission. Copies of dissertations may be obtained by Telephone (800) 1-800-521-0600. Web page: http://www.proquest.com/en-US/products/dissertations/individuals.shtml.]",ProQuest LLC,"Ph.D. Dissertation, University of California, Santa Barbara",,http://eric.ed.gov/?id=ED661202,Computational Linguistics; Intellectual Property; Artificial Intelligence; Productivity; News Reporting; Deception; Risk; Cheating; Privacy; Computer Software; Prevention; Identification; Guidelines; Accuracy; Classification; Information Security; Safety; Algorithms,,Dissertations/Theses - Doctoral Dissertations
EJ1445416,"Generative AI in Education and Research: Opportunities, Concerns, and Solutions",Eman A. Alasadi; Carlos R. Baiz,2023,"In this article, we discuss the role of generative artificial intelligence (AI) in education. The integration of AI in education has sparked a paradigm shift in teaching and learning, presenting both unparalleled opportunities and complex challenges. This paper explores critical aspects of implementing AI in education to advance educational goals, ethical considerations in scientific publications, and the attribution of credit for AI-driven discoveries. We also examine the implications of using AI-generated content in professional activities and describe equity and accessibility concerns. By weaving these key questions into a comprehensive discussion, this article aims to provide a balanced perspective on the responsible and effective use of these technologies in education, highlighting the need for a thoughtful, ethical, and inclusive approach to their integration.",Journal of Chemical Education,v100 n8 p2965-2971 2023,10.1021/acs.jchemed.3c00323,http://eric.ed.gov/?id=EJ1445416,Artificial Intelligence; Technology Uses in Education; Goal Orientation; Ethics; Publications; Professional Development; Access to Education; Equal Education; Educational Technology,English,Journal Articles; Reports - Descriptive
EJ1485522,"Lecturer's Perspective on the Role of AI in Personalized Learning: Benefits, Challenges, and Ethical Considerations in Higher Education",Lebohang Victoria Mulaudzi; Joleen Hamilton,2025,"This qualitative study explores lecturers' perspectives on the role of artificial intelligence (AI) in personalised learning within higher education. The rapid proliferation of AI has introduced numerous ethical challenges, including the potential for academic dishonesty and misuse. One concern highlighted in this study is maintaining academic integrity while fostering responsible and ethical AI use in educational contexts. Grounded in the Technology Acceptance Model, the research examines how lecturers navigate these complexities through innovative teaching and assessment strategies. Data were collected from 16 lecturers via open-ended questionnaires, and thematic analysis, guided by Braun and Clarke's six-step framework, was employed to identify recurring themes. The study is limited in its reliance on self-reported data, which may not fully capture the nuances of lecturers' experiences or practices. Additionally, the study is context-specific, focusing on a limited sample size, which may restrict the generalizability of the findings to broader contexts. Findings reveal that lecturers employ strategies such as using AI-detection tools like Turnitin to uphold academic integrity, redesigning assessments to include in-class components, and encouraging transparency by having students declare AI use. Another significant finding is the emphasis on fostering critical thinking skills to enable students to engage ethically with AI tools. The study recommends that higher education institutions train lecturers and students on ethical AI use, promote transparency in AI-assisted academic work, and invest in technologies that support these objectives. Revising assessment strategies to incorporate innovative, controlled formats is also suggested to mitigate misuse, ensuring the responsible integration of AI into educational practices.",Journal of Academic Ethics,v23 n4 p1571-1591 2025,10.1007/s10805-025-09615-1,http://eric.ed.gov/?id=EJ1485522,College Faculty; Teacher Attitudes; Artificial Intelligence; Technology Uses in Education; Individualized Instruction; Educational Benefits; Ethics; Higher Education; Cheating; Plagiarism; Integrity; Identification; Prevention; Accountability; Critical Thinking; Training; Evaluation Methods,English,Journal Articles; Reports - Research
EJ1484304,Exploring the Factors That Promote a Balance between Academic Integrity and the Effective Use of GenAI Tools in Higher Education: A Systematic Review,Daniel Kangwa; Mgambi Msambwa Msafiri; Antony Fute,7010,"Background: This study explored the factors that influence the balance between academic integrity and the effective use of GenAI tools in higher education. It focused on the role of institutional guidelines in enhancing the responsible use of GenAI technologies to enhance academic integrity. Objectives: The study was theoretically grounded in the Technology Acceptance Model and the Theory of Planned Behaviour to investigate the factors that promote academic integrity in using GenAI tools (RQ1), their impact and institutional strategies to effectively mitigate ethical risks (RQ2) and the model practices to support the ethical and effective use in higher education (RQ3). Methods: The PRISMA framework was used to systematically review and thematically synthesise the results of 213 peer-reviewed articles published between January 2021 and May 2025. Results: Finding indicates that academic support, defined by structured training, technical scaffolding, and perceived usefulness, is critical to enabling ethical GenAI use. Additionally, student self-regulation, as influenced by behavioural control and goal setting, was associated with greater academic integrity in GenAI-mediated learning. Whereas institutional policies varied widely, those with transparent, adaptive and discipline-responsive governance frameworks more effectively mitigated academic misconduct. Indeed, the model practices included GenAI ethics committees, interactive GenAI literacy modules, and the developer-educator collaborations to promote algorithmic transparency. Conclusions: A comprehensive systems-based approach that encompasses academic support, self-regulation and ethical guidelines is critical for the responsible use of GenAI tools in education. Hence, to preserve academic integrity while nurturing innovation, institutions should integrate GenAI ethics into curricular design, faculty development and cross-sectoral policy frameworks. Future research may expand into multilingual and longitudinal analyses to support equitable and sustainable GenAI integration across diverse educational settings.",Journal of Computer Assisted Learning,v41 n5 e70109 2025,10.1111/jcal.70109,http://eric.ed.gov/?id=EJ1484304,Integrity; Artificial Intelligence; Technology Uses in Education; Higher Education; Guidelines; Ethics; Risk; Student Responsibility; College Students; Algorithms; Accountability; Self Management; Curriculum Design; Integrated Curriculum,English,Journal Articles; Information Analyses
EJ1344695,An Empirical Analysis of High School Students' Practices of Modelling with Unstructured Data,"Jiang, Shiyan; Nocera, Amato; Tatar, Cansu; Yoder, Michael Miller; Chao, Jie; Wiedemann, Kenia; Finzer, William; Rosé, Carolyn P.",2022,"To date, many AI initiatives (eg, AI4K12, CS for All) developed standards and frameworks as guidance for educators to create accessible and engaging Artificial Intelligence (AI) learning experiences for K-12 students. These efforts revealed a significant need to prepare youth to gain a fundamental understanding of how intelligence is created, applied, and its potential to perpetuate bias and unfairness. This study contributes to the growing interest in K-12 AI education by examining student learning of modelling real-world text data. Four students from an Advanced Placement computer science classroom at a public high school participated in this study. Our qualitative analysis reveals that the students developed nuanced and in-depth understandings of how text classification models--a type of AI application--are trained. Specifically, we found that in modelling texts, students: (1) drew on their social experiences and cultural knowledge to create predictive features, (2) engineered predictive features to address model errors, (3) described model learning patterns from training data and (4) reasoned about noisy features when comparing models. This study contributes to an initial understanding of student learning of modelling unstructured data and offers implications for scaffolding in-depth reasoning about model decision making.",British Journal of Educational Technology,v53 n5 p1114-1133 Sep 2022,10.1111/bjet.13253,http://eric.ed.gov/?id=EJ1344695,High School Students; Data; Artificial Intelligence; Mathematical Models; Advanced Placement; Computer Science Education; Classification; Prediction; Error Patterns; Decision Making,English,Journal Articles; Reports - Research
EJ1460419,Grading Exams Using Large Language Models: A Comparison between Human and AI Grading of Exams in Higher Education Using ChatGPT,Jonas Flodén,2025,"This study compares how the generative AI (GenAI) large language model (LLM) ChatGPT performs in grading university exams compared to human teachers. Aspects investigated include consistency, large discrepancies and length of answer. Implications for higher education, including the role of teachers and ethics, are also discussed. Three Master's-level exams were scored using ChatGPT 3.5, and the results were compared with the teachers' scoring and the grading teachers were interviewed. In total, 463 exam responses were graded. With each response being graded at least three times, a total of 1389 gradings were conducted. For the final exam scores, 70% of ChatGPT's gradings were within 10% of the teachers' gradings and 31% within 5%. ChatGPT tended to give marginally higher scores. The agreement on grades is 30%, but 45% of the exams received an adjacent grade. On individual questions, ChatGPT is more inclined to avoid very high or very low scores. ChatGPT struggles to correctly score questions closely related to the course lectures but performs better on more general questions. The AI can generate plausible scores on university exams that, at first glance, look similar to a human grader. There are differences but it is not unlikely that two different human graders could result in similar discrepancies. During the interviews, teachers expressed their surprise at how well ChatGPT's grading matched their own. Increased use of AI can lead to ethical challenges as exams are entrusted to a machine whose decision-making criteria are not fully understood, especially concerning potential bias in training data.",British Educational Research Journal,v51 n1 p201-224 2025,10.1002/berj.4069,http://eric.ed.gov/?id=EJ1460419,College Faculty; Artificial Intelligence; Comparative Testing; Scoring; Error of Measurement; Grading; Interrater Reliability; Computer Assisted Testing; Evaluation Methods; Ethics; Reliability,English,Journal Articles; Reports - Research
ED676245,World Youth Skills Day 2025: Youth Survey Report on AI and Digital Skills. Education 2030,,2025,"Drawing on insights from over 4,000 respondents across 128 countries, this survey report examines how young people are navigating both the opportunities and challenges of the digital era. While 62% of youth are already using AI in real-world contexts, only 30% have received formal training -- highlighting critical gaps in access, ethics and infrastructure. These findings underscore the need for equitable digital education, responsible AI integration and greater youth participation in policy-making, offering valuable guidance for supporting youth in harnessing the skills and opportunities they need for a digital future.",UNESCO-UNEVOC International Centre for Technical and Vocational Education and Training,,,http://eric.ed.gov/?id=ED676245,Artificial Intelligence; Computer Use; Technological Literacy; Training; Youth; Barriers; Technology Uses in Education; Access to Computers; Ethics; Policy Formation; Young Adults; Geographic Location; Gender Differences; Age Differences; Educational Attainment,,Reports - Research
EJ1433938,A Tutorial for Integrating Generative AI in Mixed Methods Data Analysis,Celeste Combrinck,2024,"The current article used real data to demonstrate the analysis and synthesis of Mixed Methods Research (MMR) data with generative Artificial Intelligence (Gen AI). I explore how reliable and valid Gen AI data outputs are and how to improve their use. The current content is geared towards enhancing methodological application regardless of field or discipline and includes access to a prompt library and examples of using outputs. The demonstration data used emanated from a study done in South Africa, with a quantitative sample size of 969 first-year engineering students and, for the qualitative part, 14 first-year students. In the current article, I compare my original analysis to ChatGPT results. Generative AI as a mind tool is best used with human insight, and I found this to be especially true when coding qualitative data. ChatGPT produced generic codes if asked to do inductive coding, and the results improved when training the Gen AI on human examples, which led to moderate and significant correlations between human and machine coding. The quantitative analysis was accurate for the descriptive statistics, but the researcher had to use best judgment to select the correct inferential analysis. Quantitative and qualitative analysis should be conducted separately in generative AI before asking the Chatbot for help with mixed methods results. In the current paper, I give guidelines and a tutorial on how to use chatbots in an ethically responsible and scientifically sound manner for research in social and human sciences.",Discover Education,v3 Article 116 2024,10.1007/s44217-024-00214-7,http://eric.ed.gov/?id=EJ1433938,Foreign Countries; College Freshmen; Engineering Education; Artificial Intelligence; Cognitive Processes; Mixed Methods Research; Ethics; Social Science Research; Human Factors Engineering,English,Journal Articles; Information Analyses; Reports - Research
EJ1415334,Chatting and Cheating: Ensuring Academic Integrity in the Era of ChatGPT,Debby R. E. Cotton; Peter A. Cotton; J. Reuben Shipway,2024,"The use of artificial intelligence in academia is a hot topic in the education field. ChatGPT is an AI tool that offers a range of benefits, including increased student engagement, collaboration, and accessibility. However, is also raises concerns regarding academic honesty and plagiarism. This paper examines the opportunities and challenges of using ChatGPT in higher education, and discusses the potential risks and rewards of these tools. The paper also considers the difficulties of detecting and preventing academic dishonesty, and suggests strategies that universities can adopt to ensure ethical and responsible use of these tools. These strategies include developing policies and procedures, providing training and support, and using various methods to detect and prevent cheating. The paper concludes that while the use of AI in higher education presents both opportunities and challenges, universities can effectively address these concerns by taking a proactive and ethical approach to the use of these tools.",Innovations in Education and Teaching International,v61 n2 p228-239 2024,10.1080/14703297.2023.2190148,http://eric.ed.gov/?id=EJ1415334,Integrity; Cheating; Artificial Intelligence; Man Machine Systems; Natural Language Processing; Influence of Technology; Higher Education; Plagiarism; Ethics; Prevention; Opportunities; Barriers; Evaluation Methods,English,Journal Articles; Reports - Evaluative
EJ1447514,Preservice Teachers' Readiness towards Integrating AI-Based Tools in Education: A TPACK Approach,Angelina Bautista; Christine Estrada; Andrei Melvin Jaravata; Laina Mae Mangaser; Ferdinand Narag; Rachell Soquila; Raphael Job Asuncion,2024,"Background/Purpose: Technological pedagogical content knowledge (TPACK) emphasizes the effective integration of artificial intelligence (AI)-based tools in education, where specific knowledge is measured individually. This research determines the readiness of preservice teachers (PSTs) to integrate AI-based tools in education through the TPACK approach. Materials/Methods: This descriptive study involves 429 PSTs from Don Mariano Marcos Memorial State University in the Philippines through a face-to-face survey. Exploratory factor analysis was employed using a minimum residual extraction method with oblimin rotation. Partial least squares structural equation modeling was performed, and goodness of fit indices (GFI, AGFI, PGFI, RMSEA, and TLI) were tested. Results: The PSTs' readiness to integrate AI-based tools in education revealed their readiness based on their technical knowledge (TK), technical pedagogical knowledge (TPK), technical content knowledge (TCK), and TPACK, as well as their ethical readiness. The study found that the PSTs' TK, TPK, TCK, and TPACK were positively related to their ethical readiness. Conclusion: When PSTs enhance their technological competencies, their ethical considerations in the use of AI tools also improve. Relationships between TK, TPK, TCK, TPACK, and ethical readiness emphasize the need for teacher training approaches that nurture not just technical abilities, but also students' ethical consciousness. This highlights the interconnectedness of these knowledge frameworks in fostering effective and responsible technology integration in education.",Educational Process: International Journal,v13 n3 p40-68 2024,,http://eric.ed.gov/?id=EJ1447514,Preservice Teachers; Readiness; Technology Integration; Artificial Intelligence; Pedagogical Content Knowledge; Technological Literacy; Technology Uses in Education; Foreign Countries; Ethics; Elementary School Teachers; Early Childhood Teachers; Special Education Teachers,English,Journal Articles; Reports - Research
EJ1447399,Navigating the Dilemma: Use of ChatGPT in Social Work Education,Liat Shklarski; Kathleen Ray,2024,"Artificial intelligence has evolved since its inception in the 1950s, resulting in the creation of large language models that are trained on extensive data sets to understand and generate content, such as OpenAI's ChatGPT, which launched in November 2022. Modern technology that is easy to access and free to use, like ChatGPT, is changing the educational landscape as it is an example of a large language model -- an artificial intelligence network -- that can process and generate text that reads as though it were written by a person. Using a survey and semi-structured interviews, this exploratory mixed-method study examined social work educators' experiences of addressing students' use of ChatGPT and found that although they are uncomfortable with addressing ChatGPT use with their students, they believe it is necessary to communicate its ethical use to them. Results also suggested that while using ChatGPT as a learning tool is valid, it can be overused. ChatGPT use gives students a false sense of having mastered academic material, and institutional guidelines are needed to address concerns regarding academic integrity and plagiarism. Moreover, instructors should address students' use of ChatGPT with their institutions and take intentional steps to ethically and creatively integrate artificial intelligence models into the social work curriculum.",Journal of Teaching in Social Work,v44 n5 p476-494 2024,10.1080/08841233.2024.2408299,http://eric.ed.gov/?id=EJ1447399,Social Work; Counselor Training; Artificial Intelligence; Computer Software; Computational Linguistics; Language Processing; Counselor Educators; Teacher Attitudes; Integrity; Plagiarism; Technology Uses in Education; Ethics,English,Journal Articles; Reports - Research
EJ1410074,"Exploring the Role of ChatGPT in Higher Education: Opportunities, Challenges and Ethical Considerations",Ali Zeb; Rafid Ullah; Rehmat Karim,2024,"Purpose: This paper aims to examine the opportunities and challenges of using ChatGPT in higher education. Furthermore, it is also discuss the potential risks and plunders of these tools. Design/methodology/approach: The paper discuss the use of artificial intelligence (AI) in academia and explores the opportunities and challenges of using ChatGPT in higher education. It also highlights the difficulties of detecting and preventing academic dishonesty and suggests strategies that universities can adopt to ensure ethical and useful use of these tools. Findings: The paper concludes that while the use of AI tools, ChatGPT in higher education presents both opportunities and challenges. The universities can effectively address these concerns by taking a proactive and ethical approach to the use of these tools. This paper further suggests that universities should develop policies and procedures, provide training and support, to detect and prevent cheating intentions. Originality/value: The paper provides insights into the opportunities and challenges of using ChatGPT in higher education, as well as strategies for addressing concerns related to academic dishonesty. The paper further adds importance to the discussion on the ethical and responsible use of AI tools in higher education.",International Journal of Information and Learning Technology,v41 n1 p99-111 2024,10.1108/IJILT-04-2023-0046,http://eric.ed.gov/?id=EJ1410074,Artificial Intelligence; Higher Education; Technology Uses in Education; Barriers; Opportunities; Risk; Ethics; Cheating; Prevention; Influence of Technology,English,Journal Articles; Reports - Research
ED657229,Bridging the Gap: Preparing Delaware K-12 Teachers for AI Integration,Matthew Kelso,2024,"The potential of AI in K-12 education is vast, promising personalized learning experiences, enhanced engagement, and innovative instructional tools. However, its introduction into classrooms brings forth concerns ranging from ethics to teacher preparedness. Drawing on Christensen's concept of disruptive innovation, this study aims to assess and improve Delaware teachers' readiness for AI integration, using AI-based TPACK as a theoretical framework. Through a survey instrument tailored for Delaware K-12 educators, the research uncovers gaps in AI literacy and identifies barriers to effective implementation. The findings underscore the urgent need for guidance and support from the Delaware Department of Education (DDOE) to equip teachers with the necessary literacy for ethical and practical AI integration. Recommendations include strategic guidance, professional development initiatives, and frameworks for ethical AI integration, paving the way for transformative teaching methodologies in Delaware's K-12 landscape. [The dissertation citations contained here are published with the permission of ProQuest LLC. Further reproduction is prohibited without permission. Copies of dissertations may be obtained by Telephone (800) 1-800-521-0600. Web page: http://www.proquest.com/en-US/products/dissertations/individuals.shtml.]",ProQuest LLC,"Ed.D. Dissertation, Wilmington University (Delaware)",,http://eric.ed.gov/?id=ED657229,Elementary Secondary Education; Artificial Intelligence; Readiness; Technology Integration; Educational Technology; Pedagogical Content Knowledge; Technological Literacy; Barriers; Teacher Competencies,,Dissertations/Theses - Doctoral Dissertations
EJ1463722,A Qualitative Survey on Perception of Medical Students on the Use of Large Language Models for Educational Purposes,Himel Mondal; Juhu Kiran Krushna Karri; Swaminathan Ramasubramanian; Shaikat Mondal; Ayesha Juhi; Pratima Gupta,2025,"Large language models (LLMs)-based chatbots use natural language processing and are a type of generative artificial intelligence (AI) that is capable of comprehending user input and generating output in various formats. They offer potential benefits in medical education. This study explored the student's feedback on the utilization of LLMs in medical education. We conducted an in-depth interview with open-ended questions with Indian medical students via telephone conversation. The recording (average time: 55.28 ± 18.04 min) was transcribed and thematically analyzed to find major themes and subthemes. We used QDA Miner Lite v.2.0.8 (Provalis Research, Montreal, Canada) for the thematic analysis of the text. A total of 25 students from eight Indian states studying from the first to final year of studies participated in this study. Three major themes were identified: usage scenario, augmented learning, and limitation of LLMs. Students use LLMs for clarifying complex topics, searching for customized answers, solving multiple-choice questions, making simplified notes, and streamlining assignments. While they appreciated the ease of access, ready reference for getting clarity on doubts, lucid explanation of questions, and time-saving aspects of LLMs, concerns were raised regarding erroneous results, limited usage due to reliability and privacy issues, and the overreliance on chatbots for educational needs. Hence, they emphasized the need for training for the integration of LLM in medical education. In conclusion, according to students' perception, LLMs have the potential to enhance medical education. However, addressing challenges and leveraging the strengths of LLMs are crucial for optimizing their integration into medical education.",Advances in Physiology Education,v49 n1 p27-36 2025,,http://eric.ed.gov/?id=EJ1463722,Computational Linguistics; Physiology; Teaching Methods; Artificial Intelligence; Technology Uses in Education; Linguistic Input; Medical Education; Educational Benefits; Telecommunications; Student Attitudes; Feedback (Response); Indians; Learning Processes; Computer Software; Multiple Choice Tests; Assignments; Usability; Privacy; Information Security; Technology Integration; Technological Literacy; Barriers; Medical Students; Foreign Countries,English,Journal Articles; Reports - Research
EJ1414349,Gender Prediction Based on University Students' Complex Thinking Competency: An Analysis from Machine Learning Approaches,Gerardo Ibarra-Vazquez; María Soledad Ramí­rez-Montoya; Hugo Terashima,2024,"This article aims to study machine learning models to determine their performance in classifying students by gender based on their perception of complex thinking competency. Data were collected from a convenience sample of 605 students from a private university in Mexico with the eComplexity instrument. In this study, we consider the following data analyses: (1) predict students' gender based on their perception of complex thinking competency and sub-competencies from a 25 items questionnaire, (2) analyze models' performance during training and testing stages, and (3) study the models' prediction bias through a confusion matrix analysis. Our results confirm the hypothesis that the four machine learning models (Random Forest, Support Vector Machines, Multi-layer Perception, and One-Dimensional Convolutional Neural Network) can find sufficient differences in the eComplexity data to classify correctly up to 96.94% and 82.14% of the students' gender in the training and testing stage, respectively. The confusion matrix analysis revealed partiality in gender prediction among all machine learning models, even though we have applied an oversampling method to reduce the imbalance dataset. It showed that the most frequent error was to predict Male students as Female class. This paper provides empirical support for analyzing perception data through machine learning models in survey research. This work proposed a novel educational practice based on developing complex thinking competency and machine learning models to facilitate educational itineraries adapted to the training needs of each group to reduce social gaps existing due to gender.",Education and Information Technologies,v29 n3 p2721-2739 2024,10.1007/s10639-023-11831-4,http://eric.ed.gov/?id=EJ1414349,Foreign Countries; College Students; Private Colleges; Gender Bias; Gender Issues; Difficulty Level; Thinking Skills; Competence; Classification; Metacognition; Artificial Intelligence,English,Journal Articles; Reports - Research
EJ1464831,"Unlocking AI Potential: Effort Expectancy, Satisfaction, and Usage in Research",Nurul Ashikin Izhar; Wendy Ven Ye Teh; Anita Adnan,2025,"Aim/Purpose: This study investigates the key factors influencing the adoption and use of artificial intelligence (AI) applications among researchers, focusing on effort expectancy, satisfaction, perceived ease of use, and perceived usefulness, which shaped attitudes and drove AI adoption as a research assistant. Background: AI tools have rapidly become game-changers in academic research, transforming tasks such as literature retrieval, writing, editing, and data analysis. Despite their potential, barriers like high effort expectancy, inconsistent user satisfaction, and ethical concerns regarding over-reliance and plagiarism continue to hinder widespread adoption. A pressing gap exists in understanding how AI impacts the efficiency and integrity of academic research workflows. Methodology: A quantitative approach using structural equation modeling (SEM) was employed. Data was collected from 120 active researchers who use AI tools for academic tasks, including literature reviews, writing support, and data visualization. Contribution: This study contributes to the understanding of how key factors, such as effort expectancy and satisfaction, affect AI adoption in academic research. It emphasizes the importance of reducing cognitive load and improving user satisfaction to promote widespread AI adoption. It also underscores the importance of intuitive AI design and institutional support in shaping researchers' engagement with AI tools, which could enhance productivity and research outcomes. Findings: The findings reveal that effort expectancy, satisfaction, perceived ease of use, and perceived usefulness significantly influence attitude and actual use of AI tools, with attitude serving as a key mediator. The model demonstrated moderate to high explanatory power (R[superscript 2] = 0.409 to 0.459) and predictive relevance (Q[superscript 2] = 0.171 to 0.409), highlighting the substantial role of effort expectancy and satisfaction in shaping perceived ease of use and usefulness. These findings emphasize the importance of reducing cognitive load and improving user satisfaction to encourage the adoption of AI tools in research. Recommendations for Practitioners: Institutions and AI developers should focus on reducing the learning curve of AI tools by enhancing their intuitiveness and providing targeted training and technical support. Ethical AI use should also be promoted to address concerns about over-reliance and plagiarism. Institutions should foster a culture that normalizes AI integration in research practices. Recommendation for Researchers: Researchers should be informed of the long-term effects of AI adoption on research quality and integrity and how institutional support can foster positive attitudes toward AI tools in academic research. Impact on Society: The broader adoption of AI tools in academic research could enhance productivity and efficiency, leading to more breakthroughs in various fields and benefiting society by accelerating research and innovation. Additionally, AI can democratize access to research resources, particularly for underfunded institutions and early-career researchers, by enabling broader participation in cutting-edge research and fostering equity and diversity in academic contributions. Future Research: Future studies should focus on the role of user experience in AI adoption, particularly how different user groups interact with AI tools. Longitudinal studies could provide insights into how attitudes toward AI change as users become more familiar with the tools.",Journal of Information Technology Education: Innovations in Practice,v24 Article 5 2025,,http://eric.ed.gov/?id=EJ1464831,Artificial Intelligence; Computer Software; Technology Uses in Education; Technology Integration; Usability; Barriers; Educational Benefits; Ethics; Plagiarism; Integrity; Efficiency; Researchers; Research Methodology; Models; Cognitive Ability; Technical Support; Technological Literacy; Faculty Development; Doctoral Students; Graduate Students; Student Research,English,Journal Articles; Reports - Research; Tests/Questionnaires
EJ1433980,Teaching AI-Enabled Business Communication in Higher Education: A Practical Framework,Natalia Riapina,2024,"This article presents a conceptual framework for integrating AI-enabled business communication in higher education. Drawing on established theories from business communication and educational technology, the framework provides comprehensive guidance for designing engaging learning experiences. It emphasizes the significance of social presence, cognitive load management, and constructivist learning principles. The framework is exemplified through various tasks, including role-playing with AI chatbots, analyzing nonverbal cues, communication simulations, interactive presentation assessments, and collaborative AI-supported projects. Practical considerations for implementation, including technological infrastructure, faculty training, ethics, curriculum integration, and assessment strategies, are discussed. Future directions and implications for business communication education are also explored.",Business and Professional Communication Quarterly,v87 n3 p511-521 2024,10.1177/23294906231199249,http://eric.ed.gov/?id=EJ1433980,Artificial Intelligence; Business Communication; Higher Education; Technology Uses in Education; Theories; Educational Technology; Learner Engagement; Learning Experience; Constructivism (Learning); Cognitive Processes; Difficulty Level; Models,English,Journal Articles; Reports - Descriptive
ED659969,Teacher and Student Perspectives of Technology Use in Elementary School Classrooms,Anthony Oskar Alvarado,2024,"This study explored student and teacher perspectives of technology use at Franklin Elementary School in South San Jose, CA, using qualitative, quantitative, and observational methods, including interviews, observations, and surveys. Thirteen teachers responded to a survey on educational technology use. Among this group, eleven provided interviews, and nine invited classroom observations from 1st through 6th grades. Additionally, sixty-nine 3rd to 6th-grade students were surveyed about their views on technology use. The study found that technology use in teaching is widespread and integral, not just an add-on. Observations and teacher interviews showed high engagement and interest in technology tools, primarily supporting the lower levels of Bloom's Digital Taxonomy (BDT). Recommendations include professional development and collaboration opportunities for teachers to integrate activities engaging Bloom's higher levels of thinking, such as analyzing and evaluating. Teachers also called for better vetting of products to ensure ethical and safe technology use in schools. Due to the limited and small sample size, findings may not be generalizable. Given the rapid pace of technological evolution, highlighted by the fast adoption of artificial intelligence (AI) tools in education during the research period, the study concludes with a need for ongoing research into the ethical and privacy implications of technology use in education. [The dissertation citations contained here are published with the permission of ProQuest LLC. Further reproduction is prohibited without permission. Copies of dissertations may be obtained by Telephone (800) 1-800-521-0600. Web page: http://www.proquest.com/en-US/products/dissertations/individuals.shtml.]",ProQuest LLC,"Ed.D. Dissertation, San Jose State University",,http://eric.ed.gov/?id=ED659969,Elementary School Teachers; Influence of Technology; Elementary School Students; Teacher Attitudes; Technology Uses in Education; Student Attitudes; Educational Technology; Grade 3; Grade 4; Grade 5; Grade 6; Grade 2; Grade 1; Interests; Learner Engagement; Student Interests,,Dissertations/Theses - Doctoral Dissertations
EJ1491337,Exploring the Factors Affecting the Adoption AI Techniques in Higher Education: Insights from Teachers' Perspectives on ChatGPT,Habiba Al-Mughairi; Preeti Bhaskar,2025,"Purpose: ChatGPT, an artificial intelligence (AI)-powered chatbot, has gained substantial attention in the academic world for its potential to transform the education industry. While ChatGPT offers numerous benefits, concerns have also been raised regarding its impact on the quality of education. This study aims to bridge the gap in research by exploring teachers' perspectives on the adoption of ChatGPT, with a focus on identifying factors that motivate and inhibit them to adopt ChatGPT for educational purposes. Design/methodology/approach: This research has employed a interpretative phenomenological analysis (IPA) qualitative approach. Through in-depth interviews among the teachers, data will be collected to identify the motivating and inhibiting factors that impact teachers' willingness to adopt ChatGPT. The data was collected from 34 teachers working across 10 branches of the University of Technology and Applied Sciences (UTAS) in Oman. Findings: The analysis revealed four themes under motivating factors that encourage teachers to adopt ChatGPT for their educational purpose. These include Theme 1: Exploration of innovative education technologies, Theme 2: Personalization teaching and learning, Theme 3: Time-saving and Theme 4: Professional development. On the other hand, inhibiting factors includes five themes which includes Theme 1: Reliability and accuracy concerns, Theme 2: Reduced human interaction, Theme 3: Privacy and data security, Theme 4: lack of institutional support and Theme 5: Overreliance on ChatGPT. Practical implications: This study contributes to the understanding of teachers' perspectives on the adoption of ChatGPT in education. By understanding teachers' perspectives, policymakers can design appropriate policies and service providers can customize their offerings to meet teachers' requirements. The study's findings will be valuable for higher education institutions (HEIs) in formulating policies to ensure the appropriate and effective utilization of ChatGPT. The study will provide suggestions to ChatGPT service providers, enabling them to focus on motivating factors and address inhibiting factors, thereby facilitating the seamless adoption of ChatGPT among teachers. Originality/value: In comparison to previous studies, this study goes beyond merely discussing the possible benefits and limitations of ChatGPT in education. This research significantly contributes to the understanding of ChatGPT adoption among teachers by identifying specific motivating and inhibiting factors that influence teachers to adopt ChatGPT for educational purposes. The research enables to gain important new insights that were not previously found, giving a fresh dimension to the existing literature.",Journal of Research in Innovative Teaching & Learning,v18 n2 p232-247 2025,,http://eric.ed.gov/?id=EJ1491337,Educational Technology; Technology Uses in Education; Technology Integration; Artificial Intelligence; College Faculty; Teacher Attitudes; Barriers; Motivation; Foreign Countries,English,Journal Articles; Reports - Research
EJ1383549,A Comprehensive AI Policy Education Framework for University Teaching and Learning,"Chan, Cecilia Ka Yuk",2023,"This study aims to develop an AI education policy for higher education by examining the perceptions and implications of text generative AI technologies. Data was collected from 457 students and 180 teachers and staff across various disciplines in Hong Kong universities, using both quantitative and qualitative research methods. Based on the findings, the study proposes an AI Ecological Education Policy Framework to address the multifaceted implications of AI integration in university teaching and learning. This framework is organized into three dimensions: Pedagogical, Governance, and Operational. The Pedagogical dimension concentrates on using AI to improve teaching and learning outcomes, while the Governance dimension tackles issues related to privacy, security, and accountability. The Operational dimension addresses matters concerning infrastructure and training. The framework fosters a nuanced understanding of the implications of AI integration in academic settings, ensuring that stakeholders are aware of their responsibilities and can take appropriate actions accordingly.",International Journal of Educational Technology in Higher Education,v20 Article 38 2023,10.1186/s41239-023-00408-3,http://eric.ed.gov/?id=EJ1383549,Artificial Intelligence; Educational Policy; College Instruction; Higher Education; Foreign Countries; Ecology; Governance; Technology Uses in Education; Instructional Improvement; Privacy; Information Security; Accountability; Technology Integration; Ethics,English,Journal Articles; Reports - Research
EJ1414180,The Educational Affordances and Challenges of ChatGPT: State of the Field,Helen Crompton; Diane Burke,2024,"ChatGPT was released to the public in November 30, 2022. This study examines how ChatGPT can be used by educators and students to promote learning and what are the challenges and limitations. This study is unique in providing one of the first systematic reviews using peer review studies to provide an early examination of the field. Using PRISMA principles, 44 articles were selected for review. Grounded coding was then used to reveal trends in the data. The findings show that educators can use ChatGPT for teaching support, task automation, and professional development. These were further delineated further by axial sub codes. Eight student uses were 24/7 support, explain difficult concepts, conversational partner, personalized feedback and materials, provide writing support, offer self-assessment, facilitate engagement, and self-determination. In addition to be affordances of the AI, the data from the articles also showed limitations to ChatGPT and misuses, specifically, inaccuracies and hallucinations, potential bias, and tool limitations. Misuses are plagiarism and cheating, privacy issues and spread of false information. This study is a springboard for researchers, practitioners, policy makers and funders in understanding the emerging state of the field of ChatGPT.",TechTrends: Linking Research and Practice to Improve Learning,v68 n2 p380-392 2024,10.1007/s11528-024-00939-0,http://eric.ed.gov/?id=EJ1414180,Artificial Intelligence; Barriers; Technology Uses in Education; Natural Language Processing; Teaching Methods; Students; Teachers; Affordances,English,Journal Articles; Reports - Research
EJ1460022,Superficially Plausible Outputs from a Black Box: Problematising GenAI Tools for Analysing Qualitative SoTL Data,Mirjam Sophia Glessmer; Rachel Forsyth,2025,"Generative AI tools (GenAI) are increasingly used for academic tasks, including qualitative data analysis for the Scholarship of Teaching and Learning (SoTL). In our practice as academic developers, we are frequently asked for advice on whether this use for GenAI is reliable, valid, and ethical. Since this is a new field, we have not been able to answer this confidently based on published literature, which depicts both very positive as well as highly cautionary accounts. To fill this gap, we experiment with the use of chatbot style GenAI (namely ChatGPT 4, ChatGPT 4o, and Microsoft Copilot) to support or conduct qualitative analysis of survey and interview data from a SoTL project, which had previously been analysed by experienced researchers using thematic analysis. At first sight, the output looked plausible, but the results were incomplete and not reproducible. In some instances, interpretations and extrapolations of data happened when it was clearly stated in the prompt that the tool should only analyse a specified dataset based on explicit instructions. Since both algorithm and training data of the GenAI tools are undisclosed, it is impossible to know how the outputs had been arrived at. We conclude that while results may look plausible initially, digging deeper soon reveals serious problems; the lack of transparency about how analyses are conducted and results are generated means that no reproducible method can be described. We therefore warn against an uncritical use of GenAI in qualitative analysis of SoTL data.",Teaching & Learning Inquiry,v13 2025,,http://eric.ed.gov/?id=EJ1460022,Artificial Intelligence; Research Methodology; Data Analysis; Scholarship; Instruction; Learning; Reliability; Validity; Ethics; Educational Development; Algorithms,English,Journal Articles; Reports - Research
EJ1491764,Unraveling the Influential Factors Driving Persistent Adoption of ChatGPT in Learning Environments,Sedigheh Moghavvemi; Farooq Ahmed Jam,2025,"AI has transformed education by reshaping teaching and learning processes. ChatGPT plays a significant role in enhancing these processes; however, effective educator training is essential for its optimal use. Educators and researchers are increasingly adopting AI chatbots, expecting them to improve learning experiences and reduce teacher workload. This study aims to identify the factors contributing to ChatGPT's perceived value and analyze their impact on its continued usage among students. Additionally, the study introduces a new model and investigates the moderating effect of privacy risk on the relationship between perceived value and the continued use of ChatGPT. A total of 600 questionnaires were distributed to students enrolled in various universities in Malaysia, with 244 students indicating their willingness to continue using ChatGPT. Partial Least Squares Structural Equation Modeling was used to analyze the data. The findings suggest that perceived usefulness, perceived ease of use, problem-solving, idea generation, information quality, and effective learning are significant determinants of ChatGPT's continuous use among students, both directly and indirectly through perceived value. The results show that students benefit from ChatGPT in enhancing their performance, problem-solving, and idea generation. In line with concerns about privacy risks in online applications, the study reveals that privacy concerns affect ChatGPT's perceived value. Students prioritize its effectiveness as a study aid. Academic institutions can train students to use ChatGPT as a complementary learning tool, while instructors can leverage it to enhance their teaching practices.",Education and Information Technologies,v30 n15 p22443-22470 2025,10.1007/s10639-025-13662-x,http://eric.ed.gov/?id=EJ1491764,Artificial Intelligence; Technology Uses in Education; Technology Integration; Privacy; Risk; College Students; Foreign Countries; Intention; Usability; Problem Solving; Concept Formation; Information Technology; Educational Benefits,English,Journal Articles; Reports - Research
EJ1408776,Bridging Resource Gaps in Adult Education: The Role of Generative AI,Sarah Cacicio; Rachel Riggs,2023,"Generative AI (GenAI) refers to the production of entirely new creative works, such as text, pictures, music, or poetry, in response to simple prompts (Lanxon et al., 2023). Some view GenAI as a disruption to our education system, pointing to biases in the training data, concerns about misleading or inaccurate information, challenges to educators, as well as issues of personal safety and privacy (Weil, 2023, Yu & Guo, 2023). In adult foundational education, where teacher capacity and resources are limited, AI-powered edtech tools have the potential to support the rapid creation of high quality, tailored, and engaging materials for instruction and assessment in any learning context. This article aims to provide insight into adult educator perspectives on the use of GenAI as well as highlight edtech tools and features that educators can use to strengthen their instructional design skills and more effectively meet diverse learner needs.",Adult Literacy Education,v5 n3 p80-86 2023,,http://eric.ed.gov/?id=EJ1408776,Adult Education; Artificial Intelligence; Educational Technology; Adult Educators; Teacher Attitudes; Visual Aids; Bias; Instructional Materials; Design; Technology Uses in Education,,Journal Articles; Reports - Descriptive
EJ1477382,"Ethical Limits and Suggestions for Improving the Use of AI in Scientific Research, Academic Publishing, and the Peer Review Process, Based on Deontological and Consequentialist Viewpoints",Mohammed Daoudi,2025,"This study provides a comprehensive analysis of researchers' perspectives on AI integration across theoretical and practical research, academic publishing, and its future role, highlighting ethical considerations shaping its adoption. The methodology used a mixed approach, using a questionnaire distributed to researchers from various scientific disciplines. Quantitative data were analyzed statistically, and qualitative responses underwent thematic analysis to ensure a robust understanding of the findings. Results reveal that AI is viewed as a powerful tool for enhancing efficiency in research, particularly in data analysis (61.9%) and hypothesis generation (45.2%). However, ethical concerns, including bias, transparency, and trust, were noted as significant challenges, with 38.1% emphasizing the need for improved ethical frameworks. In academic writing, 81% of respondents supported AI use with proper acknowledgment, while 76.2% expressed openness to AI-assisted peer review under human supervision. The future of AI is seen as complementary to human expertise (69%), with its potential strongest in data analysis, simulations, and innovation in research tools (57.1%). Key barriers include limited access to AI tools (47.6%), high costs (38.1%), and insufficient technical skills (45.2%). This study's innovation lies in its integration of ethical theories, deontology and consequentialism, as a framework to evaluate AI's role in research. It offers practical recommendations to foster responsible AI adoption, including ethical training, interdisciplinary collaboration, and enhanced accessibility to AI tools. Addressing gaps in ethical guidelines and emphasizing AI's potential to complement human creativity, this research contributes valuable insights to the evolving discourse on AI in scientific research.",Discover Education,v4 Article 241 2025,10.1007/s44217-025-00696-z,http://eric.ed.gov/?id=EJ1477382,Ethics; Artificial Intelligence; Technology Uses in Education; Scientific Research; Faculty Publishing; Writing for Publication; Peer Evaluation; Computer Attitudes; Efficiency; Data Analysis; Hypothesis Testing; Accountability; Trust (Psychology); Supervision; Barriers; Access to Computers; Costs; Technological Literacy; Training; Interdisciplinary Approach,English,Journal Articles; Reports - Research
ED659733,Using Machine Learning Methods to Detect Heterogeneous Treatment Effects for Multilevel Randomized Controlled Trials: A Review and Empirical Comparison,Wei Li; Walter Leite; Jia Quan,2023,"Background: Multilevel randomized controlled trials (MRCTs) have been widely used to evaluate the causal effects of educational interventions. Traditionally, educational researchers and policymakers focused on the average treatment effects (ATE) of the intervention. Recently there has been an increasing interest in evaluating the heterogeneity of treatment effects (HTEs) among intervention participants for several reasons. First, it allows researchers to understand how treatment effects vary among subgroups to address questions about ""for whom and under what conditions"" an intervention works. These individual and cluster characteristics used to identify subgroups are called moderators and can augment or reduce the treatment effects. Also, it helps researchers to examine whether an intervention increase or decreases the gaps in the outcomes of interest and thus identifies the interventions that can improve fairness and equity in education. Educational researchers commonly incorporate a treatment by moderator interaction within OLS regression or multilevel models (MLMs) to explore the moderator effects (e.g., Dong et al., 2022). Recent development in statistics and econometrics (e.g., Athey & Wager, 2019; Chernozhukov et al., 2020) proposed to use machine learning (ML) methods to explore the HTEs by estimating the conditional average treatment (CATE). Compared to traditional interaction analysis, these methods have some advantages. For example, the interaction analysis cannot identify causal relationships because of the potential correlations between the moderators and the omitted variables in the error term (Dong et al., 2022), while some ML methods (e.g., causal forest) can facilitate causal inference under regular assumptions. Also, traditional moderator analysis usually requires specifying the moderators in the design phase and thus may miss important sources of HTEs. However, ML methods can select moderators from a potentially large number of covariates. To deal with the potential dependency of students within the same schools, MLMs are widely used for moderation analysis. Similarly, when applying ML methods to estimate CATE, applied researchers still need to consider the nested data structure. However, most prior literature assumes the participants are independent. There is a lack of literature to guide educational researchers in appropriately applying ML methods for clustered data when evaluating HTEs. Purpose and Significance: This study contributes to the literature on the design and analysis of MRCTs by reviewing the current available ML methods and tools that account for the nested data structure when estimating CATE and provides recommendations to applied researchers on how to choose the appropriate methods and statistical package among alternative ML methods. Specifically, this study will focus on two ML methods -- Causal Forest (CF) and the GenericML methods and demonstrate the application of these two methods using the dataset from a large multisite experimental study (Leite et al., 2023). Research Design and Methods: Many ML methods have been proposed to estimate CATE in the past decade (see Caron et al., 2020 and Jacob, 2021, for recent reviews). In general, these methods include three main steps: (1) splitting the data into training and test sets, (2) using the training set and ML algorithms to build a prediction model, and (3) using the test set to estimate HTEs and the standard errors (SEs). Based on our review of all the currently available methods and packages, only two algorithms --CF and the GenericML consider the nested data structure in at least one step. Specifically, the CF algorithm estimates CATE through honest causal trees (Wager & Athey, 2018). When analyzing data from MRCTs, the cluster-robust CF algorithm estimates CATE by making predictions as an average of b trees (Athey & Wager, 2019). It considers the nested data structure in all three steps: (1) for each b= 1, ..., B, draw a subsample of clusters and then draw a random sample from each cluster as the training data; (2) grow a tree via recursive partitioning on each such subsample of the data; (3) make the out-of-bag predictions. It should be noted that to account for the potential within cluster dependency, an observation ""i"" is considered to be out-of-bag if its cluster was not drawn in step (1). Similarly, the GenericML algorithm (Chernozhukov et al., 2020) estimates the best linear predictor of CATE through the following steps: (1) randomly split the data into training and test sets; (2) estimates the CATE with any number of selected ML methods (e.g., LASSO, SVM, etc.) using the training data; (3) use OLS regression to obtain the BLP of the CATE using the test data. Note that, for multisite designs, OLS with site dummy variables is used in the third step, but it does not consider nested data structure in the first and second steps. The cluster-robust CF algorithm can be applied through the R package ""grf"", and the GenericML algorithm can be implemented through the ""GenericML"" R package. Both packages report cluster-Robust SEs. Besides, the ""GenericML"" package can also estimate the Sorted group average treatment effects (GATEs) that consisted of creating five groups of participants using quintiles of the CATE distribution and perform classification analysis (CLAN) to explore the relationships between covariates and the CATE. In contrast, the ""grf"" package cannot automatically report GATEs or CLAN. Preliminary Results: We applied the cluster-robust CF and the GenericML algorithms to the data from a large-scale three-level multisite experimental study. This study included 52 math teachers and 2,936 students from three school districts and randomly assigned students of participating teachers to see video recommendations. Our analysis includes 516 predictors, with 484 consisting of dummy-coded indicators. The Appendix Table 1 summarizes GATEs using the ""GenericML"" package, showing the difference between the group that benefitted the most (Group 5) and the least (Group 1) from the intervention. The 516 predictors were sorted based on their mean differences between Groups 1 and 5. A thematic analysis of the most important predictors showed that teachers of students who benefitted most reported spending more time using the videos of the VLE and following student progress on the dashboard. We will manually estimate GATE and CLAN based on the CATE estimates from the ""grf"" package and then compare the results from two packages regarding CATE, GATE, and CLAN.",Society for Research on Educational Effectiveness,,,http://eric.ed.gov/?id=ED659733,Artificial Intelligence; Identification; Hierarchical Linear Modeling; Randomized Controlled Trials; Comparative Analysis; Educational Research; Algorithms,,Reports - Research
EJ1482504,A Future-Focused Lens to Equipping Biomedical Engineering Graduates for an Evolving Field,Gabrielle Lam; Isgard Hueck; Christian Rivera; Patricia Widder,2025,"Biomedical engineering is a rapidly evolving field, with the pace of evolution spurred by technological advancements, the increasing complexity of human health challenges, and globalization of the workforce. It is timely for biomedical engineering educators to explore afresh the competencies that graduates need at present, but more importantly, those they need to adapt to an ever-evolving BME field. Here, we use a future-focused lens in our exploration, drawing upon industry and academic perspectives from sessions at recent Biomedical Engineering Education Summits, together with findings from literature over the past 5 years. A synthesis of perspectives revealed that certain professional competencies--namely communication, collaboration, leadership, and ethical understanding--were viewed as ""difficult to teach,"" yet critical to adapting to evolutions in the field and the growing need to work effectively in interdisciplinary contexts. Technical competencies were seen as expected outcomes of graduates' educational training, yet there was strong emphasis on the importance of critical thinking and data science skills. Importantly, it is the interconnection between professional and technical competencies that enable future BME graduates to contribute in an ethical and socially responsible manner, especially in light of the field's growing use of large patient-derived datasets and rapid advancements in technologies like Artificial Intelligence. From this, we propose three approaches for BME educational programs to better equip BME graduates: (1) enhancing engagement with industry and alumni to evolve the curriculum, (2) augmenting opportunities for interdisciplinary student collaboration, and (3) integrating data science and ethics training throughout the curriculum.",Biomedical Engineering Education,v5 n2 p177-188 2025,10.1007/s43683-025-00186-6,http://eric.ed.gov/?id=EJ1482504,Biomedicine; Engineering Education; College Graduates; Futures (of Society); Job Skills; Technological Literacy; Data Science; Ethics; Critical Thinking,English,Journal Articles; Reports - Evaluative
EJ1459737,Differential Impact of Gender and Academic Background on Complex Thinking Development in Engineering Students: A Machine Learning Perspective,Paloma Suárez-Brito; Armando Elizondo-Noriega; Jenny Paola Lis-Gutiérrez; Carolina Henao-Rodríguez; María Rubi Forte-Celaya; José Carlos Vázquez-Parra,2025,"Purpose: The purpose of this paper is to present the results of measuring a sample of engineering students' perceived achievement of complex thinking at different stages of their professional training. This study intended to analyze and predict the differences in the self-perception of achieved complex thinking competency by gender, semester, course of study and high school of origin. Design/methodology/approach: The methodology included applying the E-Complexity instrument to 225 university students from northern Mexico. The initial comparison of groups used the chi-square test and two supervised learning algorithms (logit regression with Lasso regularization and a classification tree). Findings: The findings of this study indicated that the selected undergraduate degree did not reveal differences in self-perceived performance in complex thinking, while gender, semester and high school of origin had significant differences. Research limitations/implications: Among the limitations of the study is the size of the sample and the fact that it only focused on engineering students from a single educational institution; however, this limitation responds to the exploratory nature of this study and the guidance of the institutional ethics committee. With these results, it is feasible to request an extension of the sample to include other disciplines to evaluate these findings, which, although relevant, cannot be considered exhaustive. Originality/value: Regarding possible lines of research, the authors propose that given the difference between students who graduated from the high school of the same institution and those who did not, a possible line of research could explore new hypotheses on whether the policies and practices of the institution's high school emphasize the development of complex thinking skills; the teachers of this high school are trained to teach complex thinking; and the learning materials of this high school are designed to develop complex thinking skills.",On the Horizon,v33 n1 p14-31 2025,10.1108/OTH-11-2023-0036,http://eric.ed.gov/?id=EJ1459737,Foreign Countries; Engineering Education; Undergraduate Students; Sex; Educational Background; Problem Solving; Critical Thinking; Creative Thinking; Cognitive Processes; Science Process Skills; Professional Education; Likert Scales,English,Journal Articles; Reports - Research
EJ1460825,Training Humans to Detect Children's Lies through Their Facial Expressions,Alison M. O'Connor; Jennifer Gongola; Kaila C. Bruer; Thomas D. Lyon; Angela D. Evans,7002,"The accurate detection of children's truthful and dishonest reports is essential as children can serve as important providers of information. Research using automated facial coding and machine learning found that children who were asked to lie about an event were more likely to look surprised when hearing the first question during an interview about said event. The present studies explored if humans can be trained to look for surprised expressions to detect children's deception. Participants made lie-detection judgments after seeing children's expressions in very brief clips. In Study 1, we compared performance across a training condition and control condition, and in Study 2 we modified the training. With training, adults could detect children's lies at above-chance levels by viewing their facial expressions. Detection accuracy was further improved with modified training (Study 2), but participants held a consistent lie bias. Challenges with using facial expressions to detect deceit are discussed.",Applied Cognitive Psychology,v39 n1 e70024 2025,10.1002/acp.70024,http://eric.ed.gov/?id=EJ1460825,Deception; Nonverbal Communication; Recognition (Psychology); Children; Interviews; Accuracy; Ethics; Artificial Intelligence; Comparative Analysis; Training; Video Technology; Adults,English,Journal Articles; Reports - Research
EJ1392879,Massive Omission of Consent (MOOC): Ethical Research in Educational Big Data Studies,"Costello, Eamon; Brunton, James; Bolger, Richard; Soverino, Tiziana; Juillerac, Clément",2023,"Ethical reviews of research plans function as a cornerstone of good research practice in order that no harm should come to participants. Ethical concerns have taken on a new salience in a digital world where data can be generated at scale. Big data research has grown rapidly, raising increased ethical concerns. Several intersecting areas of big data research exist within educational research, such as learning analytics, artificial intelligence (AI), and Massive Open Online Courses (MOOCs). In the current study, an investigation was made of peer-reviewed papers on MOOC teaching and learning to determine if they explicitly refer to (a) ethical considerations in their studies, and (b) obtaining formal ethical approval for their research. This investigation was accomplished through a review of MOOC-related, English-language papers available in Scopus database, over the course of a year. The review produced a total of 1,249 articles, of which, 826 articles related to empirical studies involving human participants where full text of the articles could be obtained. The string ""ethic"" was searched for within these articles, and resulting articles analyzed, which found that a small fraction, 42 articles (5.08%), mention ethics in relation to the study presented in the article, and only 13 articles (1.57%) explicitly mention obtaining formal ethical approval for the research. The findings show a lack of transparency in reporting on and/or engagement with ethical considerations in MOOC teaching and learning research. These findings indicate the need for further stakeholder engagement and sectoral dialogue in relation to ethics education and training for researchers; consideration of ethics in big data studies in education; and norms/policies in academic publishing for authors to report how ethical issues have been considered.",Online Learning,v27 n2 p67-87 Jun 2023,,http://eric.ed.gov/?id=EJ1392879,MOOCs; Informed Consent; Educational Research; Ethics; Educational Researchers; Authors; Research Committees; Integrity,English,Journal Articles; Reports - Research
EJ1467947,Exploring the Impact of Integrating AI Tools in Higher Education Using the Zone of Proximal Development,Lianyu Cai; Mgambi Msambwa Msafiri; Daniel Kangwa,2025,"This systematic literature review explored the impact of integrating AI tools in higher education using the Zone of Proximal Development (ZPD) by Lev Vygotsky. It examined how AI tools assist the students in identifying and operating within their ZPD, how to create and facilitate a collaborative learning environment, and how to provide the necessary scaffolding for effective learning. The sample included 158 empirical studies which were retrieved from Web of Science, Scopus, and ERIC, published between 2021 and 2024. Findings indicated that AI tools assist learners in personalising their self-assessment through social and technological interactions, and effective communication; they improve motivation, learning engagement, and learning support, which leads to better academic performance, student maturation, and development. Additionally, AI tools were found suitable for creating collaborative learning environments, empowering learners, and facilitating meaningful interactions. Furthermore, results emphasise the need for educator's professional development, ethical AI deployment, and the integration of AI into designing meaningful learning experiences. These results indicate that there should be equitable access to training and effective resolutions for ethical challenges that may undermine the integrity of the learning process. The study highlights strategic AI integration to significantly enhance learning outcomes and student engagement, focusing on academic integrity and complementing traditional educational methods. Recommendations are that there is a need for longitudinal studies to assess the long-term impact of AI on learning outcomes, student engagement, and the development of critical thinking and problem-solving skills.",Education and Information Technologies,v30 n6 p7191-7264 2025,10.1007/s10639-024-13112-0,http://eric.ed.gov/?id=EJ1467947,Artificial Intelligence; Technology Uses in Education; Technology Integration; Higher Education; Problem Solving; Cooperative Learning; Scaffolding (Teaching Technique); Faculty Development; Ethics; Learning Experience; Learner Engagement; Critical Thinking,English,Journal Articles; Reports - Research
EJ1447650,Communicating Clear Guidance: Advice for Generative AI Policy Development in Higher Education,Sarah Moore; Kathryn Lookadoo,2024,"This article presents the ongoing conversation about generative AI guidance and policy in higher education. The article examines syllabus policies, including analyzing sentiment, emotion, and common themes in GenAI policies. Findings show that policies should be audience-focused, clearly written, and grounded in strategies to promote ethical AI use in academia and the workforce. Practical tips for policy writing and sample policies are provided.",Business and Professional Communication Quarterly,v87 n4 p610-629 2024,10.1177/23294906241254786,http://eric.ed.gov/?id=EJ1447650,Artificial Intelligence; Educational Policy; Course Descriptions; Audience Awareness; Ethics; Policy Formation; Higher Education; Student Needs; Equal Education; Cheating; Academic Standards,English,Journal Articles; Reports - Research; Information Analyses
ED675635,Preserving the Integrity of Study Behaviour in Online Retrieval Practice Using Quantified Learner Dynamics,Maarten van der Velde; Malte Krambeer; Hedderik van Rijn,2025,"Ensuring the integrity of results in online learning and assessment tools is a challenge, due to the lack of direct supervision increasing the risk of fraud. We propose and evaluate a machine learning-based method for detecting anomalous behaviour in an online retrieval practice task, using an XGBoost classifier trained on keystroke dynamics and task performance features to distinguish between genuine and fraudulent responses. The classifier requires only a modest amount of training data--approximately 100 short-answer responses, typically collected within 10 minutes of practice-- and maintains good performance when not all feature types are available. This method enhances the reliability of online learning and assessment by identifying anomalous response behaviour in a way that preserves learners' privacy. [For the complete proceedings, see ED675583.]",International Educational Data Mining Society,"Paper presented at the International Conference on Educational Data Mining (EDM) (18th, Palermo, Italy, Jul 20-23, 2025)",,http://eric.ed.gov/?id=ED675635,Artificial Intelligence; Technology Uses in Education; Student Behavior; Information Retrieval; Integrity; Keyboarding (Data Entry); Secondary School Students; Foreign Countries; Cheating; Prevention; Deception,,Speeches/Meeting Papers; Reports - Research
EJ1399216,Predictive Algorithms and Racial Bias: A Qualitative Descriptive Study on the Perceptions of Algorithm Accuracy in Higher Education,Stacey Lynn von Winckelmann,2023,"Purpose: This study aims to explore the perception of algorithm accuracy among data professionals in higher education. Design/methodology/approach: Social justice theory guided the qualitative descriptive study and emphasized four principles: access, participation, equity and human rights. Data collection included eight online open-ended questionnaires and six semi-structured interviews. Participants included higher education professionals who have worked with predictive algorithm (PA) recommendations programmed with student data. Findings: Participants are aware of systemic and racial bias in their PA inputs and outputs and acknowledge their responsibility to ethically use PA recommendations with students in historically underrepresented groups (HUGs). For some participants, examining these topics through the lens of social justice was a new experience, which caused them to look at PAs in new ways. Research limitations/implications: Small sample size is a limitation of the study. Implications for practice include increased stakeholder training, creating an ethical data strategy that protects students, incorporating adverse childhood experiences data with algorithm recommendations, and applying a modified critical race theory framework to algorithm outputs. Originality/value: The study explored the perception of algorithm accuracy among data professionals in higher education. Examining this topic through a social justice lens contributes to limited research in the field. It also presents implications for addressing racial bias when using PAs with students in HUGs.",Information and Learning Sciences,v124 n9-10 p349-371 2023,10.1108/ILS-05-2023-0045,http://eric.ed.gov/?id=EJ1399216,Prediction; Algorithms; Racism; Accuracy; Higher Education; Social Justice; Student Records; Privacy,English,Journal Articles; Reports - Research
EJ1441384,Threats and Opportunities of Students' Use of AI-Integrated Technology (ChatGPT) in Online Higher Education: Saudi Arabian Educational Technologists' Perspectives,Mesfer Mihmas Mesfer Aldawsari; Nouf Rashed Ibrahim Almohish,2024,"This research study explored the perspectives of 20 educational technologists from four Saudi Arabian universities regarding the integration of AI-powered technology, particularly ChatGPT, into online higher education. The study used a qualitative research method that relied on the principles of theoretical sampling to select participants and conducted in-depth interviews to collect their insights. The approach taken for data analysis was thematic analysis, which uncovered a rich range of insights on both the challenges and opportunities associated with students' use of AI-integrated technology in the context of online higher education. Ten significant challenges emerged that shed light on the complexities and intricacies of integrating AI-powered technology into educational environments. These challenges included issues related to technological infrastructure, pedagogical adaptation, and the need for comprehensive training programs to empower both teachers and learners. Additionally, eight threats were examined that highlighted concerns about data security, privacy, and potential risks associated with AI technology in educational institutions. This study not only provided a comprehensive overview of the current landscape of AI-integrated technology in Saudi Arabian higher education, but also provided valuable insights for education stakeholders, technologists, and policy makers. It underscored the necessity of proactive measures to mitigate challenges and threats while harnessing the opportunities presented by AI technology to enhance the quality and effectiveness of online higher education.",International Review of Research in Open and Distributed Learning,v25 n3 p19-36 2024,,http://eric.ed.gov/?id=EJ1441384,Artificial Intelligence; Computer Software; Synchronous Communication; Technology Uses in Education; Electronic Learning; Higher Education; Computers; Information Systems; Teaching Methods; Educational Needs; Foreign Countries,English,Journal Articles; Reports - Research
ED644591,Predictive Algorithms and Racial Bias: A Qualitative Descriptive Study on the Perceptions of Algorithm Accuracy in Higher Education,Stacey von Winckelmann,2023,"The research problem addressed in this study is that racial bias programmed into predictive algorithm recommendations negatively impacts students in historically underrepresented groups. The purpose of this qualitative descriptive study was to explore the perception of algorithm accuracy among data professionals in higher education and explore the potential application of a modified critical race theory framework to the design of predictive algorithms used in higher education to reduce instances of racial bias from negatively impacting students from historically underrepresented groups. Social justice theory guided this study and emphasized four principles: access, participation, equity, and human rights. Three research questions steered this study. RQ1 addressed how data professionals in higher education perceived the accuracy of predictive algorithm recommendations used at higher education institutions. RQ2 considered how institutions vet the accuracy of their recommendations to protect students in historically underrepresented groups. RQ3 examined the process higher education institutions use to address racially biased predictive algorithm recommendations to protect students in historically underrepresented groups. This study included eight higher education professionals who currently work or have recently worked with predictive algorithm recommendations. Data collection initially occurred through an online Qualtrics questionnaire, with six of these participants volunteering to participate in online one-on-one semi-structured interviews through Zoom. NVivo directed thematic analysis by identifying codes, categories, and themes. Themes centered on the prevalence of systemic and racial bias in algorithm inputs and outputs (recommendations). Four implications for practice include the need for social justice and data literacy training for stakeholders, increased student participation in an institution's data strategy, including adverse childhood experiences data, and incorporating critical race theory tenets into the predictive algorithm design process. Future research should center on data justice and predictive algorithm recommendations, integrating critical race theory tenets into predictive algorithm inputs and outputs, and interviewing college students in historically underrepresented groups on their perception of predictive algorithms used at higher education institutions. Increased research in these areas can support social justice and guide institutions in the ethical use of predictive algorithm recommendations. [The dissertation citations contained here are published with the permission of ProQuest LLC. Further reproduction is prohibited without permission. Copies of dissertations may be obtained by Telephone (800) 1-800-521-0600. Web page: http://www.proquest.com/en-US/products/dissertations/individuals.shtml.]",ProQuest LLC,"Ed.D. Dissertation, Northcentral University",,http://eric.ed.gov/?id=ED644591,Prediction; Algorithms; Racism; Accuracy; Higher Education; Social Justice; Student Records; Privacy,,Dissertations/Theses - Doctoral Dissertations
EJ1430989,Experiential Learning: Exploring Nuances When Making Ethical Decisions in a Capstone Design Course,Holly Golecki; Joe Bradley,2024,"Biomedical engineering capstone design courses provide a salient opportunity to discuss ethical considerations in engineering. As technology and society develop and change, new challenges constantly arise related to how society and technology inform each other. In this space, ethical training for engineering students is critically important for future practicing engineers who may face significant once-in-a-career ethical challenges as well as the smaller compounding daily decisions that impact biomedical research and device design. In this context, topics of social justice as well as bias and inclusion in data and design are particularly important for biomedical engineers to understand the given the human-centered approach to engineering practice. To engage biomedical engineering students in discussion and practice of these concepts, we present a capstone course module to teach traditional ethics studies while exposing students to cases of bias in design in modern technologies including AI, sensors, and devices. This curriculum engages students in discussion of these topics facilitated by biotechnology case studies. All together, we see the curriculum presented here as a response to the need for biomedical engineers to understand the human-centered data in ethical decision-making as well as to meet the desires of students to put engineering in the context of human-centered design and social justice.",Biomedical Engineering Education,v4 n1 p163-170 2024,10.1007/s43683-023-00126-2,http://eric.ed.gov/?id=EJ1430989,Experiential Learning; Decision Making; Ethics; Capstone Experiences; Biomedicine; Engineering Education; Bias; Design; Technology; Equipment; Social Justice; Inclusion; Data; Learning Modules; Artificial Intelligence,English,Journal Articles; Reports - Descriptive
EJ1342166,Internet-Based Testing: A Solution for the New Normal,"Langenfeld, Thomas",2022,"The turn to online learning and training programs as a response to challenging times (i.e., the COVID-19 crisis) necessitated the need for internet-based testing solutions. Researchers generally have found that Unproctored Internet Testing (UIT) for high-stakes cognitive ability assessments results in higher scores than proctored assessments. Live or Artificial Intelligence (AI) remote proctoring are possible solutions for the secure administrations. Vendors have developed live and AI remote proctoring with service levels ranging from minimal to top-tier security. Added security comes with a price, and these services quickly become expensive. Institutions need to identify a level of security that is commensurate with the stakes and uses of test scores. Researchers are finding that combining live remote proctoring with specific design features minimizes cheating and other unauthorized behaviors. As institutions consider live remote proctoring, they need to be cognizant of not only ensuring security, but also ensuring the opportunity to test for all students.",Journal of Applied Testing Technology,v23 spec iss p5-14 2022,,http://eric.ed.gov/?id=EJ1342166,Internet; Computer Assisted Testing; COVID-19; Pandemics; Observation; Artificial Intelligence; Privacy; Cheating,English,Journal Articles; Reports - Descriptive
EJ1485249,ChatGPT in Language Education: Applications and Implications for Teaching and Learning,Hung Thanh Nguyen; Phuoc Tai Nguyen,2025,"Background/purpose: Artificial intelligence, namely ChatGPT, has garnered significant interest in language education due to its potential to enhance instruction and learning. Three primary topics are highlighted in this study's analysis of recent research on ChatGPT's use in language instruction: Reflection on instruction, instructor feedback, and adaptation of reading texts. Materials/methods: Ten language instructors and twenty students who had been using ChatGPT in language sessions for at least one semester participated in semi-structured interviews. A detailed understanding of ChatGPT's integration into language teaching and learning methods is made possible by the interviews, which captured the breadth and complexity of participants' experiences. Results: The results showed that feedback facilitated by ChatGPT enhanced student engagement and encouraged better writing abilities. Personalized reading tasks were made easier by AI-driven text adaptation, but questions about accuracy, prejudice, and ethical use surfaced. Conclusion: Notwithstanding these difficulties, ChatGPT offers a wealth of opportunities for customized language learning teaching. Clear ethical standards and focused teacher training are necessary for effective implementation. In order to evaluate the tool's long-term educational impact, more longitudinal study is required.",Educational Process: International Journal,v18 Article e2025464 2025,,http://eric.ed.gov/?id=EJ1485249,Artificial Intelligence; Man Machine Systems; Natural Language Processing; Language Teachers; Teacher Attitudes; Student Attitudes; Learner Engagement; Feedback (Response); Accuracy; Ethics; English (Second Language); Second Language Instruction; College Students; Foreign Countries,English,Journal Articles; Reports - Research
ED658942,Bridging the Gap for Contingent Faculty: An Analysis of the Professional Development and Growth Resources Used in Public Universities across Michigan,Caryl Lynn Walling,2023,"The purpose of this study was to explore the extent that contingent faculty from Michigan's 15 public universities engage with on and off-campus professional development (PD) to improve their teaching practice. Addressing a spectrum of research questions, this study utilized an explanatory sequential mixed-methods approach, combining quantitative surveys and qualitative interviews, to provide a nuanced understanding of the experiences and motivations of contingent faculty members. The initial quantitative phase surveyed 4,745 contingent faculty members through a web- based survey, exploring the availability of on and off-campus PD offerings and the factors influencing their participation. The subsequent qualitative phase was conducted through ten Zoom interviews with contingent faculty from nine universities. This phase delved into the various PD resources utilized by contingent faculty and the underlying motivations driving their engagement. The on-campus exploration revealed the prevalence of in-person seminars and computer-based training from Centers for Teaching and Learning (CTLs), that aligned with broader institutional trends. However, faculty interviews exposed discontent rooted in CTL unfulfilled promises, insufficient communication, and a perceived emphasis on theory over practical application. Contingent faculty expressed a strong desire for peer interactions, mentorship, and discipline-specific development, emphasizing the importance of immediately applicable knowledge. The study further explored on-campus factors influencing contingent faculty.Transitioning to off-campus PD, the study uncovered a significant commitment to continuous learning among contingent faculty. Engagement in live in-person seminars, conferences, social media, and internet resources emerged as critical elements in their professional growth. Notably, the unexpected involvement with artificial intelligence (AI) in discussions around lesson planning and academic integrity reflected the faculty's adaptability to emerging technologies. The examination of off-campus factors influencing contingent faculty engagement revealed a variety of influencers on faculty behavior.Concluding with an exploration of contingent faculty's professionalism traits, the study identified ethics, credentials, innovation and research, professional autonomy, and expertise as central motivators. Contingent faculty perceived themselves as dedicated professionals actively seeking PD to enhance their teaching expertise. This dissertation contributed valuable insights for university leadership, external PD providers, and contingent faculty. The findings advocated for a collaborative and supportive academic environment that understands and addresses the unique needs of contingent faculty in Michigan. [The dissertation citations contained here are published with the permission of ProQuest LLC. Further reproduction is prohibited without permission. Copies of dissertations may be obtained by Telephone (800) 1-800-521-0600. Web page: http://www.proquest.com/en-US/products/dissertations/individuals.shtml.]",ProQuest LLC,"Ph.D. Dissertation, The University of Toledo",,http://eric.ed.gov/?id=ED658942,Public Colleges; Universities; Faculty Development; Teacher Attitudes; Inservice Teacher Education; Teacher Improvement; Nontenured Faculty; Teacher Motivation; Environmental Influences,,Dissertations/Theses - Doctoral Dissertations
EJ1482816,Face Anonymization in Intelligent Experiment Education,Jiangyi Cui; Ruijiao Li; Qiushu Chen; Libin Liu; Xuan Zhao; Kai Liu; Huiliang Shang,2025,"Face anonymization in intelligent experimental education is crucial for privacy protection. This paper presents a novel, real-time face blurring system for smart experimental settings. Our key contributions include: 1) customized YOLOv8 (Multi-Scale Feature Fusion YOLOv8) algorithm achieving 96% accuracy at 22.67 fps for 1080p video. 2) An annotation dilation preprocessing method, Contour-Adaptive Occlusion Refinement (CAOR), to address instrument occlusion issues for training. 3) A specialized dataset of 51 experimental videos with dense annotations. Our system tackles the unique challenge of preserving experimental details while anonymizing faces. We introduce two metrics, Sensitivity of Blur Accuracy (SOBA) and Over Blurred Rate (OBR), to evaluate performance. Our work demonstrates robustness across physics, biology, and chemistry experiments, maintaining a low mis-blur rate of 0.02 for instruments.",International Journal of Technology in Education and Science,v9 n3 p434-449 2025,,http://eric.ed.gov/?id=EJ1482816,Privacy; Experiments; Confidentiality; Ethics; Human Body; Algorithms; Artificial Intelligence; Technology Uses in Education; Video Technology; Computer Software,English,Journal Articles; Reports - Research
EJ1491600,Integration of Learning Technologies in Medical Students' Curriculum: A Systematic Review,Soleiman Ahmady; SeyedAhmad SeyedAlinaghi; Soudabeh Yarmohammadi; Amir Masoud Afsahi; Parisa Matini; Faeze Abbaspour; Pedram Habibi; Pegah Mirzapour; Sepide Ahmadi; Elaheh Karimi; Parnian Haghi; Ayoob Molla; Sara Shahbazi; Esmaeil Mehraeen,2025,"Purpose: This paper highlights the transformative impact of information and communication technologies (ICTs) on education, focusing on their potential to revolutionize teaching methods. It also explores the global trend of integrating technology-based learning into educational curricula. Design/methodology/approach: A comprehensive literature search, using combinations of relevant keywords such as educational technology, learning technology, curriculum, and medical curriculum, was conducted in PubMed/MEDLINE, Embase, and Scopus databases for articles published in English until July 24, 2023. We appraised the quality and bias risk of included studies using the National Institute of Health (NIH) quality assessment tool. Findings: The study's findings highlight the significant impact of integrating new technologies into medical education. The selection of 56 articles that focused on implementing new curricula and modules in medical training provided a comprehensive analysis of how virtual patient simulations, 3D modeling software, augmented reality, and video conferencing platforms enhanced learning and clinical skills. Integrating these technologies yielded promising outcomes, including improved knowledge retention, self-directed learning, and increased motivation among students. This evolution of educational technology in medical education indicates a clear shift towards more interactive, personalized, and advanced digital learning experiences. The incorporation of simulation, Artificial Intelligence (AI), Virtual Reality (VR), and mobile technologies has not only transformed the learning process for medical students but also influenced the way professionals engage with educational content, ultimately enhancing patient care and medical practice. Originality/value: Integrating learning technologies into the education curriculum provides valuable opportunities to enhance medical students' capabilities, self-confidence, and knowledge. Also, learning technologies provide practical applications such as producing audio and video films about nasogastric intubation, online recording of students' feedback, full-body simulator and guided trainer, live demonstrations, and covering general surgery by audio-visual podcasts.",Health Education,v125 n6 p672-719 2025,10.1108/HE-10-2024-0117,http://eric.ed.gov/?id=EJ1491600,Literature Reviews; Medical Education; Technology Uses in Education; Educational Technology; Information Technology; Teaching Methods; Artificial Intelligence; Computer Simulation; Handheld Devices; Technology Integration; Meta Analysis; Curriculum,English,Journal Articles; Information Analyses; Reports - Research
EJ1487031,Enhancing Collaborative Learning Practices via Chatbots: Insights from an EFL Context,Ferit Kiliçkaya; Joanna Kic-Drgas,2025,"The study explores the role of AI-driven chatbots in fostering collaborative learning among English as a Foreign Language (EFL) teachers. By examining the experiences of 25 pre-service EFL teachers who used a chatbot as part of their teacher training, the study investigates how the tool supports peer interactions, enhances collaborative learning, and addresses challenges related to group work and knowledge sharing. Through semi-structured interviews and chatbot interaction logs, the qualitative analysis identified key contributions of the chatbot. Participants reported that the chatbot facilitated peer collaboration by generating discussion prompts, supporting collective tasks, and encouraging shared learning. Additionally, the chatbot promoted accountability by tracking progress and enhancing communication, particularly for participants who found face-to-face collaboration challenging. Despite these benefits, participants highlighted challenges such as occasional inaccuracies in chatbot responses, a lack of personalized suggestions, and concerns about data privacy. The findings emphasize the potential of chatbots to transform collaborative learning environments when integrated thoughtfully into the curriculum, with improvements needed in tailoring responses and ensuring data security. This study provides concrete evidence of the chatbot's capacity to enhance teamwork, task management, and communication among future teachers, offering valuable insights for implementing AI tools in teacher training programs.",SAGE Open,v15 n3 2025,10.1177/21582440251369189,http://eric.ed.gov/?id=EJ1487031,Cooperative Learning; English (Second Language); Artificial Intelligence; Language Teachers; Computer Uses in Education; Preservice Teachers,English,Journal Articles; Reports - Research
EJ1424295,Towards a Machine Learning-Based Constructive Alignment Approach for Improving Outcomes Composure of Engineering Curriculum,Wai Tong Chor; Kam Meng Goh; Li Li Lim; Kin Yun Lum; Tsung Heng Chiew,2024,"The programme outcomes are broad statements of knowledge, skills, and competencies that the students should be able to demonstrate upon graduation from a programme, while the Educational Taxonomy classifies learning objectives into different domains. The precise mapping of a course outcomes to the programme outcome and the educational taxonomy (Cognitive, Psychomotor and Affective) level is crucial to ensure Constructive Alignment at the fundamental level of a course and to ensure meaningful outcome measurements. Unfortunately, this effort is often subject to bias and human error while the use of information technologies as a mediator in this area remains unexplored. This research paper proposes an automatic learning-based advisory system for engineering curriculum to ensure constructive alignment with programme outcomes and educational taxonomy. We demonstrated the use of natural language processing and machine learning techniques to mitigate human error and bias that is often present in such classification tasks. Textual/semantic embeddings, including Term Frequency-Inverse Document Frequency (TF-IDF), Universal Sentence Encoder (USE), and Word2Vec (W2V), machine learning models (Random Forest, Support Vector Machine, Logistic Regression, and Light Gradient Boosting Machine), and their corresponding techniques for optimizing the training process are extensively investigated. In terms of accuracy, we obtained an encouraging result of 78.83%, and 78.71% for TF-IDF with Random Forest, and USE with Support Vector Machine classifier, respectively. We transformed our work into a web-based solution named the Course Outcomes Diagnostic Tool, embedded in the faculty education web platform, Edu Centre that is ubiquitously adopted by the members in the Faculty of Engineering and Technology, Tunku Abdul Rahman University of Management and Technology. The proposed solution has demonstrated great potential in reducing subjectivity, ambiguity, and human error, thereby improving the constructive alignment at the root level of course design to ensures teaching-learning activities are aligned with regulatory body expectations.",Education and Information Technologies,v29 n7 p8925-8959 2024,10.1007/s10639-023-12180-y,http://eric.ed.gov/?id=EJ1424295,Artificial Intelligence; Engineering Education; Taxonomy; Educational Objectives; Program Descriptions; Course Objectives; Alignment (Education); Automation; Natural Language Processing; Error Correction; Bias; Classification; Models; Foreign Countries; Universities; College Curriculum,English,Journal Articles; Reports - Research
EJ1441369,The Use of Deep Learning in Open Learning: A Systematic Review (2019 to 2023),Odiel Estrada-Molina; Juanjo Mena; Alexander López-Padrón,2024,"No records of systematic reviews focused on deep learning in open learning have been found, although there has been some focus on other areas of machine learning. Through a systematic review, this study aimed to determine the trends, applied computational techniques, and areas of educational use of deep learning in open learning. The PRISMA protocol was used, and the Web of Science Core Collection (2019-2023) was searched. VOSviewer was used for networking and clustering, and in-depth analysis was employed to answer the research questions. Among the main results, it is worth noting that the scientific literature has focused on the following areas: (a) predicting student dropout, (b) automatic grading of short answers, and (c) recommending MOOC courses. It was concluded that pedagogical challenges have included the effective personalization of content for different learning styles and the need to address possible inherent biases in the datasets (e.g., socio-demographics, traces, competencies, learning objectives) used for training. Regarding deep learning, we observed an increase in the use of pre-trained models, the development of more efficient architectures, and the growing use of interpretability techniques. Technological challenges related to the use of large datasets, intensive computation, interpretability, knowledge transfer, ethics and bias, security, and cost of implementation were also evident.",International Review of Research in Open and Distributed Learning,v25 n3 p371-393 2024,,http://eric.ed.gov/?id=EJ1441369,Artificial Intelligence; Intelligent Tutoring Systems; Open Education; Educational Trends; Technology Uses in Education; Journal Articles; Potential Dropouts; Predictor Variables; Automation; Grading; MOOCs; Course Selection (Students); Algorithms; Prediction; Decision Support Systems; Barriers; Individualized Instruction; Bias; Course Content,English,Journal Articles; Information Analyses
EJ1436570,Generative AI in Education and Research: A Systematic Mapping Review,Abdullahi Yusuf; Nasrin Pervin; Marcos Román-González; Norah Md Noor,3489,"Given the potential applications of generative AI (GenAI) in education and its rising interest in research, this systematic review mapped the thematic landscape of 407 publications indexed in the Web of Science, ScienceDirect and Scopus. Using EPPI Reviewer, publication type, educational level, disciplines, research areas and applications of GenAI were extracted. Eight discursive themes were identified, predominantly focused on 'application, impact and potential', 'ethical implication and risks', 'perspectives and experiences', 'institutional and individual adoption', and 'performance and intelligence'. GenAI was conceptualised as a tool for 'pedagogical enhancement', 'specialised training and practices', 'writing assistance and productivity', 'professional skills and development', and as an 'interdisciplinary learning tool'. Key gaps highlighted include a paucity of research and discussions on GenAI in K-12 education; a limited exploration of GenAI's impact using experimental procedures; and a limited exploration of the potential and ethical concerns of GenAI from the lens of cultural dimensions. Promising opportunities for future research are highlighted.",Review of Education,v12 n2 Article e3489 2024,10.1002/rev3.3489,http://eric.ed.gov/?id=EJ1436570,Artificial Intelligence; Educational Technology; Technology Uses in Education; Elementary Secondary Education; Ethics; Technology Integration; Experience; Teaching Methods; Productivity; Interdisciplinary Approach,English,Journal Articles; Information Analyses
ED671063,2024 EDUCAUSE Horizon Report: Cybersecurity and Privacy Edition,Jenay Robert; Nicole Muscanell; Nichole Arbino; Mark McCormack; Jamie Reeves,2024,"This report profiles the trends and key technologies and practices shaping the future of cybersecurity and privacy, and envisions a number of scenarios for that future. It is based on the perspectives and expertise of a global panel of leaders from across the higher education landscape. These are, in many ways, tumultuous times. Global political movements and ideologies continue to erode social ties and disrupt state and national legislative processes. Wars in Eastern Europe and the Middle East threaten to destabilize the global order. And new AI-powered technologies are evolving at breakneck speed, offering the world both the promise of new utopian capabilities and the threat of dystopian collapse. Against this backdrop of seismic change, higher education cybersecurity and privacy professionals must navigate new questions around what needs to be done to keep our institutions and our students safe and secure. This report summarizes expert panelist discussions on these and other emerging trends and offers reflections on where the future of higher education may be headed. [Boldyn Networks sponsored this report.]",EDUCAUSE,,,http://eric.ed.gov/?id=ED671063,Information Security; Computer Security; Privacy; Higher Education; School Safety; Trend Analysis; Social Influences; Information Technology; Economic Factors; Environmental Influences; Political Influences; Intervention; Artificial Intelligence; Governance; Training,,Reports - Research
EJ1377521,A Systematic Review of Teaching and Learning Machine Learning in K-12 Education,"Sanusi, Ismaila Temitayo; Oyelere, Solomon Sunday; Vartiainen, Henriikka; Suhonen, Jarkko; Tukiainen, Markku",2023,"The increasing attention to Machine Learning (ML) in K-12 levels and studies exploring a different aspect of research on K-12 ML has necessitated the need to synthesize this existing research. This study systematically reviewed how research on ML teaching and learning in K-12 has fared, including the current area of focus, and the gaps that need to be addressed in the literature in future studies. We reviewed 43 conference and journal articles to analyze specific focus areas of ML learning and teaching in K-12 from four perspectives as derived from the data: curriculum development, technology development, pedagogical development, and teacher training/professional development. The findings of our study reveal that (a) additional ML resources are needed for kindergarten to middle school and informal settings, (b) further studies need to be conducted on how ML can be integrated into subject domains other than computing, (c) most of the studies focus on pedagogical development with a dearth of teacher professional development programs, and (d) more evidence of societal and ethical implications of ML should be considered in future research. While this study recognizes the present gaps and direction for future research, these findings provide insight for educators, practitioners, instructional designers, and researchers into K-12 ML research trends to advance the quality of the emerging field.",Education and Information Technologies,v28 n5 p5967-5997 May 2023,10.1007/s10639-022-11416-7,http://eric.ed.gov/?id=EJ1377521,Elementary Secondary Education; Artificial Intelligence; Educational Research; Research Needs; Curriculum Development; Educational Technology; Instructional Development; Faculty Development; Educational Resources; Kindergarten; Middle Schools; Informal Education; Ethics; Social Change; Educational Trends; Educational Practices; Learning,English,Journal Articles; Reports - Research
EJ1405824,A Within-Group Approach to Ensemble Machine Learning Methods for Causal Inference in Multilevel Studies,Youmi Suk,2024,"Machine learning (ML) methods for causal inference have gained popularity due to their flexibility to predict the outcome model and the propensity score. In this article, we provide a within-group approach for ML-based causal inference methods in order to robustly estimate average treatment effects in multilevel studies when there is cluster-level unmeasured confounding. We focus on one particular ML-based causal inference method based on the targeted maximum likelihood estimation (TMLE) with an ensemble learner called SuperLearner. Through our simulation studies, we observe that training TMLE within groups of similar clusters helps remove bias from cluster-level unmeasured confounders. Also, using within-group propensity scores estimated from fixed effects logistic regression increases the robustness of the proposed within-group TMLE method. Even if the propensity scores are partially misspecified, the within-group TMLE still produces robust ATE estimates due to double robustness with flexible modeling, unlike parametric-based inverse propensity weighting methods. We demonstrate our proposed methods and conduct sensitivity analyses against the number of groups and individual-level unmeasured confounding to evaluate the effect of taking an eighth-grade algebra course on math achievement in the Early Childhood Longitudinal Study.",Journal of Educational and Behavioral Statistics,v49 n1 p61-91 2024,10.3102/10769986231162096,http://eric.ed.gov/?id=EJ1405824,Artificial Intelligence; Causal Models; Statistical Inference; Maximum Likelihood Statistics; Statistical Bias; Regression (Statistics); Robustness (Statistics); Mathematics Achievement; Algebra; Grade 8; Children; Longitudinal Studies; Surveys,English,Journal Articles; Reports - Research
EJ1485556,ChatGPT Unveiled: Understanding Perceptions of Academic Integrity in Higher Education -- A Qualitative Approach,Silva Karkoulian; Niveen Sayegh; Nadeen Sayegh,2025,"The purpose of this research is to gain a complete understanding of how students and faculty in higher education perceive the role of AI tools, their impact on academic integrity, and their potential benefits and threats in the educational milieu, while taking into account ways to help curb its disadvantages. Drawing upon a qualitative approach, this study conducted in-depth interviews with a diverse sample of faculty members and students in higher education, in universities across Lebanon. These interviews were analyzed and coded using NVivo software, allowing for the identification of recurring themes and the extraction of rich qualitative data. The findings of this study illuminated a spectrum of perceptions. While ChatGPT and AI tools are recognized for their potential in enhancing productivity, promoting interactive learning experiences, and providing tailored support, they also raise significant concerns regarding academic integrity. This research underscores the need for higher education institutions to carefully navigate the integration of AI tools like ChatGPT. It calls for the formulation of clear policies and guidelines for their ethical and responsible use, along with comprehensive support and training. This study contributes to the existing literature by presenting a comprehensive exploration of the perceptions of both students and faculty regarding AI tools in higher education, through a qualitative rich approach. By delving into the intricate dynamics of ChatGPT and academic integrity, this study offers fresh insights into the evolving educational landscape and the ongoing dialogue between technology and ethics.",Journal of Academic Ethics,v23 n3 p1171-1188 2025,10.1007/s10805-024-09543-6,http://eric.ed.gov/?id=EJ1485556,Artificial Intelligence; Technology Uses in Education; Higher Education; Integrity; College Students; Student Attitudes; College Faculty; Teacher Attitudes; Foreign Countries; Productivity; Technology Integration; Ethics,English,Journal Articles; Reports - Research
EJ1489531,Blueprinting the Future: Automatic Item Categorisation Using Hierarchical Zero-Shot and Few-Shot Classifiers,Ting Wang; Keith Stelter; Thomas O’Neill; Nathaniel Hendrix; Andrew Bazemore; Kevin Rode; Warren P. Newton,2025,"Precise item categorisation is essential in aligning exam questions with content domains outlined in assessment blueprints. Traditional methods, such as manual classification or supervised machine learning, are often time-consuming, error-prone, or limited by the need for large training datasets. This study presents a novel approach using zero-shot and few-shot Generative Pretrained Transformer (GPT) models for hierarchical item categorisation. By leveraging human-readable language descriptions within a structured Python dictionary, the model navigates complex blueprint hierarchies without requiring extensive training data. An initial simulation with synthetic items demonstrated the method's effectiveness, achieving an average F1 score of 92.91%. The approach was then applied to 200 real exam items from the 2022 In-Training Examination (ITE) by the American Board of Family Medicine (ABFM), reclassifying them according to a newly developed blueprint in just 15 minutes--a process that would typically take several days of expert review. This technique offers rapid, consistent, and scalable item categorisation, minimises human bias, and allows for iterative refinement through simple adjustments to category definitions, enhancing both efficiency and sustainability in assessment design.",Journal of Applied Testing Technology,v26 n1 p1-13 2025,,http://eric.ed.gov/?id=EJ1489531,Test Items; Automation; Classification; Artificial Intelligence; Achievement Tests; Family Practice (Medicine),English,Journal Articles; Reports - Research
EJ1475101,Exploring the Frontiers of Generative AI in Assessment: Is There Potential for a Human-AI Partnership?,David DiSabito; Lisa Hansen; Thomas Mennella; Josephine Rodriguez,2025,"This chapter investigates the integration of generative AI (GenAI), specifically ChatGPT, into institutional and course-level assessment at Western New England University. It explores the potential of GenAI to streamline the assessment process, making it more efficient, equitable, and objective. Through the development of a proprietary GenAI tool, the study examines GenAI's assessment of student evidence, including written assignments and computer coding tasks, against human assessment. It addresses challenges such as data collection, coordination, and the need for well-defined and precise rubrics. We found notable differences in GenAI and human scoring in some cases, indicating GenAI's potential in certain assessment contexts while also acknowledging its limitations in others. Our research suggests that GenAI could enhance educational assessment processes, but its integration requires addressing biases in training data and securing buy-in from various stakeholders. Using GenAI to handle particular routine tasks can potentially free up faculty to engage in richer discussions and educational improvements.",New Directions for Teaching and Learning,n182 p81-96 2025,10.1002/tl.20630,http://eric.ed.gov/?id=EJ1475101,Artificial Intelligence; Technology Uses in Education; Man Machine Systems; Educational Assessment; Student Evaluation; Technology Integration; Efficiency; Writing Assignments; Coding; Data Collection; Scoring Rubrics; Scoring; Bias; Stakeholders; Educational Improvement,English,Journal Articles; Reports - Research
EJ1426294,Reducing Workload in Short Answer Grading Using Machine Learning,Rebecka Weegar; Peter Idestam-Almquist,2024,"Machine learning methods can be used to reduce the manual workload in exam grading, making it possible for teachers to spend more time on other tasks. However, when it comes to grading exams, fully eliminating manual work is not yet possible even with very accurate automated grading, as any grading mistakes could have significant consequences for the students. Here, the evaluation of an automated grading approach is therefore extended from measuring workload in relation to the accuracy of automated grading, to also measuring the overall workload required to correctly grade a full exam, with and without the support of machine learning. The evaluation was performed during an introductory computer science course with over 400 students. The exam consisted of 64 questions with relatively short answers and a two-step approach for automated grading was applied. First, a subset of answers to the exam questions was manually graded and next used as training data for machine learning models classifying the remaining answers. A number of different strategies for how to select which answers to include in the training data were evaluated. The time spent on different grading actions was measured along with the reduction of effort using clustering of answers and automated scoring. Compared to fully manual grading, the overall reduction of workload was substantial--between 64% and 74%--even with a complete manual review of all classifier output to ensure a fair grading.",International Journal of Artificial Intelligence in Education,v34 n2 p247-273 2024,10.1007/s40593-022-00322-1,http://eric.ed.gov/?id=EJ1426294,Grading; Computer Assisted Testing; Introductory Courses; Computer Science Education; Artificial Intelligence; Ethics; Scoring; Computer Software; Test Format; Undergraduate Students,English,Journal Articles; Reports - Research
ED658699,Threats to Validity in the Application of Machine Learning in Education,Kylie Anglin,2022,"Background: For decades, education researchers have relied on the work of Campbell, Cook, and Shadish to help guide their thinking about valid impact estimates in the social sciences (Campbell & Stanley, 1963; Shadish et al., 2002). The foundation of this work is the ""validity typology"" and its associated ""threats to validity."" In this framework, researchers consider the validity of inferences regarding the constructs represented by operationalized variables (construct validity), the strength of association between two variables (statistical validity), the causal relationship of those variables (internal validity), and the generalizability of that relationship (external validity). In each of these validity types (construct, statistical, internal, external), Shadish, Cook, and Campbell outline key threats to validity so that researchers may make design choices that improve their inferences. The framework has had a meaningful influence on the rigor of education research, resulting in a methodological transformation over the past fifteen years towards randomized trials and quasiexperimental designs (Reardon & Stuart, 2019). Today, education research is in the midst of a second transformation as new data sources like natural language and text data have required new methodological approaches (Reardon & Stuart, 2019). Key among these approaches is the application of machine learning to educational data. In supervised machine learning approaches, researchers typically; 1) sample a subset of the data for manual analysis, labelling the data according to the construct of interest; 2) split the labelled data into a training and validation set; 3) use the training dataset to train a model to learn the features that are predictive of the labels; 4) calculate performance statistics on the validation set; 4) apply the model to unlabeled data; and 5) use the model to label unseen data and make inferences regarding educational processes. There are key threats to validity at each of these stages. This paper argues that given the importance of valid inferences is not diminished with new data sources and techniques, the validity types framework can continue to be useful in the application of machine learning to educational impact analyses. Purpose: This paper builds on the validity types framework by considering the key threats to validity in inferences drawn from machine learning. While the majority of these threats have been discussed outside of education, they are rarely discussed within the validity types framework. By bringing each these threats into a single framework, well known by education researchers, we hope to encourage researchers using machine learning to systematically consider plausible threats to validity and the design choices they can make to rule those threats. Methods: We draw on the writings of Shadish, Cook, and Campbell (2002), methodological work from machine learning scholars (Hastie et al., 2009; Jurafsky et al., 2018), and recent applications of machine learning in education to categorize threats in the validity types framework and to demonstrate these threats commonly operate in educational contexts, as well as how they may be ruled out. While the full paper includes definitions, examples, and design solutions, here we simply list a few key threats in each category. Results: Construct Validity: Researchers need to consider construct validity when labelling data manually and when considering how the meaning of those labels change with the machine learning model. Key threats include: (1) Researchers only calculate reliability between the machine learning model and one human labeler, without considering the validity of the training and validation data; (2) Model features are not (or cannot be) examined for construct validity; (3) Model features are not examined in context (and are thus misinterpreted); (4) Model performance is related to unknown characteristics, including potentially important linguistic subgroups; (5) Participants learn how to game the model; (6) Unsupervised machine learning results are interpreted by a single researcher. (Mono-interpreter bias.); and (7) Unsupervised machine learning results are the sole outcome or predictor included in a study. (Mono-operation bias.) Statistical Validity: Researchers need to consider statistical validity at two points: in measuring the performance of the machine learning model and in using the result of the model in correlational, quasi-experimental, and experimental analyses. Key threats include: (1) Researchers do not calculate the most policy relevant performance statistics; (2) Researchers ""peek"" at the validation data set; (3) Researchers do not examine the sensitivity of results to hyper-parameters; (4) Researchers do not acknowledge uncertainty surrounding performance estimates; and (5) Null conclusions regarding a causal estimand are drawn from a noisy measure labelled using a machine learning model. Internal Validity: Researchers need to consider internal validity when inferring a causal relationship between the text features identified by a model and the outcome of interest. In all but a few cases, causal inferences are unlikely to be warranted. Most text data -- whether collected for the purpose of understanding variations in units, treatment, outcomes, or settings (UTOS) -- are non-experimental in nature. The most prevalent threat in this case is selection bias; a predictive relationship between a text feature and an outcome may very well be due other differences between groups. External Validity: Before generalizing inferences regarding a causal estimand, researchers relying on machine learning also need to consider external validity when they generalize performance statistics from a validation set to other data. Thus, threats to external validity occur when there is a difference between the validation dataset and the data to which the researcher wishes to apply the model. This occurs when: (1) Performance statistics are calculated on a convenience sample, rather than a representative sample; (2) Performance statistics are calculated at a single point in time and generalized to new time points; (3) New performance statistics are not calculated when the model is applied to a new setting; and (4) There is dependence between the training and validation datasets. Conclusions: Given the exciting and complicated nature of machine learning, researchers can too often focus on the details of the algorithm overlooking the validity of the resulting inferences (Geiger et al., 2020; Hagen, 2018). Here, we unify machine learning validity concerns under the validity types framework in order to encourage researchers to systematically consider these threats, and to improve research design in order to protect against them.",Society for Research on Educational Effectiveness,,,http://eric.ed.gov/?id=ED658699,Artificial Intelligence; Educational Technology; Technology Uses in Education; Validity; Research Methodology; Educational Research; Inferences; Construct Validity; Reliability; Models; Causal Models,,Reports - Research
EJ1427732,"AI Chatbot Adoption in Academia: Task Fit, Usefulness, and Collegial Ties",Vishal Soodan; Avinash Rana; Anurag Jain; Deeksha Sharma,2024,"Aim/Purpose: This mixed-methods study aims to examine factors influencing academicians' intentions to continue using AI-based chatbots by integrating the Task-Technology Fit (TTF) model and social network characteristics. Background: AI-powered chatbots are gaining popularity across industries, including academia. However, empirical research on academicians' adoption behavior is limited. This study proposes an integrated model incorporating TTF factors and social network characteristics like density, homophily, and connectedness to understand academics' continuance intentions. Methodology: A qualitative study involving 31 interviews of academics from India examined attitudes and the potential role of social network characteristics like density, homophily, and connectedness in adoption. Results showed positive sentiment towards chatbots and themes on how peer groups accelerate diffusion. In the second phase, a survey of 448 faculty members from prominent Indian universities was conducted to test the proposed research model. Contribution: The study proposes and validates an integrated model of TTF and social network factors that influence academics' continued usage intentions toward AI chatbots. It highlights the nuanced role of peer networks in shaping adoption. Findings: Task and technology characteristics positively affected academics' intentions to continue AI chatbot usage. Among network factors, density showed the strongest effect on TTF and perceived usefulness, while homophily and connectedness had partial effects. The study provides insights into designing appropriate AI tools for the academic context. Recommendations for Practitioners: AI chatbot designers should focus on aligning features to academics' task needs and preferences. Compatibility with academic work culture is critical. Given peer network influences, training and demonstrations to user groups can enhance adoption. Platforms should have capabilities for collaborative use. Targeted messaging customized to disciplines can resonate better with academic subgroups. Multidisciplinary influencers should be engaged. Concerns like plagiarism risks, privacy, and job impacts should be transparently addressed. Recommendation for Researchers: More studies are needed across academic subfields to understand nuanced requirements and barriers. Further studies are recommended to investigate differences across disciplines and demographics, relative effects of specific network factors like size, proximity, and frequency of interaction, the role of academic leadership and institutional policies in enabling chatbot adoption, and how AI training biases impact usefulness perceptions and ethical issues. Impact on Society: Increased productivity in academia through the appropriate and ethical use of AI can enhance quality, access, and equity in education. AI can assist in mundane tasks, freeing academics' time for higher-order objectives like critical thinking development. Responsible AI design and policies considering socio-cultural aspects will benefit sustainable growth. With careful implementation, it can make positive impacts on student engagement, learning support, and research efficiency. Future Research: Conduct longitudinal studies to examine the long-term impacts of AI chatbot usage in academia. Track usage behaviors over time as familiarity develops. Investigate differences across academic disciplines and roles. Requirements may vary for humanities versus STEM faculty or undergraduate versus graduate students. Assess user trust in AI and how it evolves with repeated usage, and examine trust-building strategies. Develop frameworks to assess pedagogical effectiveness and ethical risks of conversational agents in academic contexts.",Journal of Information Technology Education: Innovations in Practice,v23 Article 1 2024,,http://eric.ed.gov/?id=EJ1427732,Artificial Intelligence; Social Networks; College Faculty; Computer Software; Universities; Intention; Technology Uses in Education; Peer Groups; Foreign Countries; Technology Integration; Teacher Attitudes; Models; Validity; Risk; Plagiarism; Interdisciplinary Approach; Privacy; Barriers; Ethics; Leadership Role; Productivity; Equal Education; Access to Education; Time Management; Educational Quality; Learner Engagement; Familiarity; Critical Thinking; Thinking Skills; Collegiality; Goodness of Fit,English,Journal Articles; Reports - Research
ED633941,Towards Development of Models That Learn New Tasks from Instructions,"Mishra, Swaroop",2023,"Humans have the remarkable ability to solve different tasks by simply reading textual instructions that define the tasks and looking at a few examples. Natural Language Processing (NLP) models built with the conventional machine learning paradigm, however, often struggle to generalize across tasks (e.g., a question-answering system cannot solve classification tasks) despite training with lots of examples. A long-standing challenge in Artificial Intelligence (AI) is to build a model that learns a new task by understanding the human-readable instructions that define it. To study this, I led the development of NATURAL INSTRUCTIONS and SUPERNATURAL INSTRUCTIONS, large-scale datasets of diverse tasks, their human-authored instructions, and instances. I adopt generative pre-trained language models to encode task-specific instructions along with input and generate task output. Empirical results in my experiments indicate that the instruction-tuning helps models achieve cross-task generalization. This leads to the question: how to write good instructions? Backed by extensive empirical analysis on large language models, I observe important attributes for successful instructional prompts and propose several reframing techniques for model designers to create such prompts. Empirical results in my experiments show that reframing notably improves few-shot learning performance; this is particularly important on large language models, such as GPT3 where tuning models or prompts on large datasets is expensive. In another experiment, I observe that representing a chain of thought instruction of mathematical reasoning questions as a program improves model performance significantly. This observation leads to the development of a large scale mathematical reasoning model BHASKAR and a unified benchmark LILA. In case of program synthesis tasks, however, summarizing a question (instead of expanding as in chain of thought) helps models significantly. This thesis also contains the study of instruction-example equivalence, power of decomposition instruction to replace the need for new models and origination of dataset bias from crowdsourcing instructions to better understand the advantages and disadvantages of instruction paradigm. Finally, I apply the instruction paradigm to match real user needs and introduce a new prompting technique HELP ME THINK to help humans perform various tasks by asking questions. [The dissertation citations contained here are published with the permission of ProQuest LLC. Further reproduction is prohibited without permission. Copies of dissertations may be obtained by Telephone (800) 1-800-521-0600. Web page: http://www.proquest.com/en-US/products/dissertations/individuals.shtml.]",ProQuest LLC,"Ph.D. Dissertation, Arizona State University",,http://eric.ed.gov/?id=ED633941,Natural Language Processing; Models; Readability; Mathematical Logic; Mathematics Instruction; Instructional Materials,,Dissertations/Theses - Doctoral Dissertations
EJ1461385,"Perceptions and Use of AI in Higher Education Students: Impact on Teaching, Learning, and Ethical Considerations",Luis Medina-Gual; José-Luis Parejo,1291,"The present research explores AI's impact on education among Mexican undergraduate students through a non-experimental, correlational, cross-sectional study. A validated public questionnaire was distributed to 840 students via Google Forms from February to May 2024. Analysis revealed significant AI exposure and use patterns, primarily influenced by mass media and personal connections. Psychometric evaluations showed strong internal consistency (Cronbach's alpha = 0.97), with PCA and clustering identifying two student profiles: a knowledgeable majority and an optimistic minority with lower formal knowledge. Significant correlations were found between AI familiarity and perceived educational impact. These findings underscore the need for integrating formal AI training into curricula to bridge the gap between enthusiasm and practical knowledge, promoting ethical and effective AI use in higher education. This study informs policy and practice for aligning AI technologies with educational goals.",European Journal of Education,v60 n1 e12919 2025,,http://eric.ed.gov/?id=EJ1461385,Artificial Intelligence; Teaching Methods; Ethics; Learning Processes; Higher Education; Undergraduate Students; Foreign Countries; Technology Uses in Education,English,Journal Articles; Reports - Research
EJ1482815,Exploring Pre-Service Teachers' Engagement with Generative AI for Multiple-Choice Question Generation,Kübra Karakaya Özyer,2025,"This study aims to delve into the process and perceptions of pre-service teachers as they engage in generating multiple-choice questions with the assistance of generative AI tools. Adopting a single-case study design, the research involved the participation of 35 pre-service teachers. The participants were tasked with utilizing generative AI tools to create multiple-choice questions and evaluate the generated items. Following this, a four-hour training session on item writing was provided to the participants. Post-training, they were asked to reassess the AI-generated products. The final phase involved collecting their reflective thoughts on this experience in writing. The qualitative data gathered were subjected to thematic analysis. A comparative examination of the participants' evaluations indicated a shift towards more detailed assessments that adhered more closely to measurement and evaluation standards. Reflective insights highlighted their positive perceptions of generative AI.",International Journal of Technology in Education and Science,v9 n3 p322-353 2025,,http://eric.ed.gov/?id=EJ1482815,Preservice Teachers; Preservice Teacher Education; Artificial Intelligence; Multiple Choice Tests; Student Attitudes; Test Construction; Test Items; Pedagogical Content Knowledge; Technological Literacy; Foreign Countries; Ethics,English,Journal Articles; Reports - Research
ED630876,Scalable and Equitable Math Problem Solving Strategy Prediction in Big Educational Data,"Shakya, Anup; Rus, Vasile; Venugopal, Deepak",2023,"Understanding a student's problem-solving strategy can have a significant impact on effective math learning using Intelligent Tutoring Systems (ITSs) and Adaptive Instructional Systems (AISs). For instance, the ITS/AIS can better personalize itself to correct specific misconceptions that are indicated by incorrect strategies, specific problems can be designed to improve strategies and frustration can be minimized by adapting to a student's natural way of thinking rather than trying to fit a standard strategy for all. While it may be possible for human experts to identify strategies manually in classroom settings with sufficient student interaction, it is not possible to scale this up to big data. Therefore, we leverage advances in Machine Learning and AI methods to perform scalable strategy prediction that is also fair to students at all skill levels. Specifically, we develop an embedding called MVec where we learn a representation based on the mastery of students. We then cluster these embeddings with a non-parametric clustering method where we progressively learn clusters such that we group together instances that have approximately symmetrical strategies. The strategy prediction model is trained on instances sampled from these clusters. This ensures that we train the model over diverse strategies and also that strategies from a particular group do not bias the DNN model, thus allowing it to optimize its parameters over all groups. Using real world large-scale student interaction datasets from MATHia, we implement our approach using transformers and Node2Vec for learning the mastery embeddings and LSTMs for predicting strategies. We show that our approach can scale up to achieve high accuracy by training on a small sample of a large dataset and also has predictive equality, i.e., it can predict strategies equally well for learners at diverse skill levels. [For the complete proceedings, see ED630829.]",International Educational Data Mining Society,"Paper presented at the International Conference on Educational Data Mining (EDM) (16th, Bengaluru, India, Jul 11-14, 2023)",,http://eric.ed.gov/?id=ED630876,Equal Education; Mathematics Education; Word Problems (Mathematics); Problem Solving; Prediction; Intelligent Tutoring Systems; Artificial Intelligence; Accuracy; Mastery Learning; Middle School Students,,Speeches/Meeting Papers; Reports - Research
EJ1346943,Data-Related Ethics Issues in Technologies for Informal Professional Learning,"Pammer-Schindler, Viktoria; Rosé, Carolyn",2022,"Professional and lifelong learning are a necessity for workers. This is true both for re-skilling from disappearing jobs, as well as for staying current within a professional domain. AI-enabled scaffolding and just-in-time and situated learning in the workplace offer a new frontier for future impact of AIED. The hallmark of this community's work has been i) data-driven design of learning technology and ii) machine-learning enabled personalized interventions. In both cases, data are the foundation of AIED research and data-related ethics are thus central to AIED research. In this paper we formulate a vision how AIED research could address data-related ethics issues in informal and situated professional learning. The foundation of our vision is a secondary analysis of five research cases that offer insights related to data-driven adaptive technologies for informal professional learning. We describe the encountered data-related ethics issues. In our interpretation, we have developed three themes: Firstly, in informal and situated professional learning, relevant data about professional learning -- to be used as a basis for learning analytics and reflection or as a basis for adaptive systems - is not only about learners. Instead, due to the situatedness of learning, relevant data is also about others (colleagues, customers, clients) and other objects from the learner's context. Such data may be private, proprietary, or both. Secondly, manual tracking comes with high learner control over data. Thirdly, learning is not necessarily a shared goal in informal professional learning settings. From an ethics perspective, this is particularly problematic as much data that would be relevant for use within learning technologies hasn't been collected for the purposes of learning. These three themes translate into challenges for AIED research that need to be addressed in order to successfully investigate and develop AIED technology for informal and situated professional learning. As an outlook of this paper, we connect these challenges to ongoing research directions within AIED -- natural language processing, socio-technical design, and scenario-based data collection - that might be leveraged and aimed towards addressing data-related ethics challenges.",International Journal of Artificial Intelligence in Education,v32 n3 p609-635 Sep 2022,10.1007/s40593-021-00259-x,http://eric.ed.gov/?id=EJ1346943,Data; Ethics; Informal Education; Professional Development; Data Collection; Natural Language Processing; Design; Employees; Situated Learning; Artificial Intelligence,English,Journal Articles; Reports - Research
ED676976,AI-Powered Pedagogy and Curriculum Design: Practical Insights for Educators,"Geoff Baker, Editor; Lucy Caton, Editor",2025,"""AI-Powered Pedagogy and Curriculum Design"" offers practical insights and guidance on the effective integration of AI tools into teaching practices and curriculum design. While numerous claims exist as to the validity and authenticity of the applications of AI in schools, too little attention has been paid to empirical research conducted with and by teachers in real-world classrooms. This book synthesises diverse viewpoints from teacher educators across disciplines and levels toward a comprehensive, context-specific understanding of the challenges and best practices for responsibly leveraging Generative AI to enhance outcomes in classrooms. Contributors further shed light on how Generative AI can align with standards, assessment practices, and teacher training programs in different settings. Firsthand classroom experiences and experimental approaches of educators in the United Kingdom and Europe will provide current and aspiring teachers with insights into the intersection between AI and teacher empowerment, student participation, ethical implications, and socially just approaches.","Routledge, Taylor & Francis Group",,,http://eric.ed.gov/?id=ED676976,Artificial Intelligence; Technology Uses in Education; Curriculum Design; Technology Integration; Educational Practices; Teaching Methods; Best Practices; Academic Standards; Alignment (Education); Foreign Countries; Teacher Empowerment; Student Participation; Ethics; Social Justice,,Books; Collected Works - General
EJ1468034,Introduction: Pedagogical Crossroads: Higher Education in the Age of Generative AI,Marc Watkins; Stephen Monroe,2025,"We begin our introduction by acknowledging the valid anxieties of faculty who face rapid technological change brought on by Generative AI (GenAI) tools without adequate institutional support or training. While some scholars advocate for GenAI resistance and others for wholesale adoption, the voices included within this volume argue for a balanced, pragmatic approach that emphasizes transparency, ethical usage, and thoughtful engagement with these powerful new tools. Despite concerns about GenAI's limitations and potential negative impacts, we recognize its remarkable capabilities and argue that higher education is uniquely positioned to critically engage with this technology through its diverse disciplinary perspectives and research methods. In seven collected essays, educators move beyond initial worries to explore creative pedagogical applications that can enhance student learning while maintaining academic integrity.",Thresholds in Education,v48 n1 p1-6 2025,,http://eric.ed.gov/?id=EJ1468034,Higher Education; Technology Uses in Education; Artificial Intelligence; Accountability; Ethics; Educational Benefits; Integrity; Computer Attitudes,English,Journal Articles; Reports - Descriptive
ED636631,Implicit Bias Training: Understanding the Posttraining Experiences of Individuals within an Organization--A Phenomenological Study,Stephanie N. Van Ginkel,2023,"Purpose: The purpose of this transcendental phenomenological study was to understand and systematically describe the essence of the experience of professional staff members at a public university who received implicit bias training (IBT) that includes the Implicit Association Test (IAT).Theoretical Framework. Appreciative Inquiry (AI) was used, specific to the Discovery and Dream phases. Methodology: A phenomenological design was used in this qualitative study. The researcher interviewed a purposeful, criterion-based sample of 10 participants. Moustakas's research design method (1994) using a psychological approach focused on systematic steps in analysis procedures and guidelines. To build trustworthiness in the research, four criteria were established: credibility, transferability, dependability, and confirmability (Amankwaa, 2016; Connelly, 2016; Creswell & Poth, 2018; Guba, 1981; Lincoln & Guba, 1985). Bracketing was performed to focus on describing the participant's experiences versus the researcher's interpretation (Creswell & Poth, 2018). Findings: The researcher reviewed transcripts to reveal 69 significant statements. Nine formulated meanings were constructed from the significant statements, and three themes emerged. The essence of the experience of receiving IBT that includes the IAT by the participants was described. Conclusions: The study's results support the key themes of IBT's effectiveness that continues to be questioned with two themes: the ineffectiveness of IBT and the lack of changes in behavior, attitude, and beliefs after taking IBT. Another result supports the key theme of the need to reevaluate and reassess IBT with one theme: the need for and development of a successful IBT. Recommendations: Future research could involve a larger sample size and/or participants from different divisions or the entirety of the university. Demographical data could be collected and analyzed for relational findings between the participants' experience and demographics. Physical, mental, and emotional states, such as stress and anxiety, could be measured and analyzed in relation to taking the training with pretests and posttests. Research could be conducted using a shorter timeframe of when the participant took IBT for improved experience recall, or it could be conducted while the participant is taking IBT for immediate feedback. Further research could use the entire AI model to include the Design and Destiny phases and differing methodologies. [The dissertation citations contained here are published with the permission of ProQuest LLC. Further reproduction is prohibited without permission. Copies of dissertations may be obtained by Telephone (800) 1-800-521-0600. Web page: http://www.proquest.com/en-US/products/dissertations/individuals.shtml.]",ProQuest LLC,"Ed.D. Dissertation, University of La Verne",,http://eric.ed.gov/?id=ED636631,Bias; Training; Public Colleges; Professional Personnel; Experience; Employee Attitudes; Association Measures,,Dissertations/Theses - Doctoral Dissertations
EJ1461307,Enhancing Competence for a Sustainable Future: Integrating Artificial Intelligence-Supported Educational Technologies in Pre-Service Teacher Training for Sustainable Development,Fatih Kayaalp; Mehmet Durnali; Bayram Gökbulut,1286,"With the mounting urgency to achieve a sustainable future, it is of paramount importance to provide pre-service teachers with a robust understanding of de facto. The present study investigated the potential of ChatGPT-supported educational technologies to enhance the understanding of sustainable development among 20 pre-service teachers at a university during the 2023-2024 academic year. Over a period of 14 weeks of intervention, participants employed ChatGPT and Web 2.0 tools (Pixton) to create digital comic stories focused on sustainable development goals. The study employed an explanatory sequential mixed-method design, utilising evaluation forms, semi-structured interviews, inferential statistics and content analysis. The results revealed significant improvements in sustainability perspectives, awareness and knowledge, despite concerns about productivity, originality and ethical issues.",European Journal of Education,v60 n1 e12865 2025,10.1111/ejed.12865,http://eric.ed.gov/?id=EJ1461307,Artificial Intelligence; Sustainable Development; Educational Technology; Technology Uses in Education; Preservice Teacher Education; Preservice Teachers; Student Attitudes; Knowledge Level; Productivity; Innovation; Ethics,English,Journal Articles; Reports - Research
EJ1491913,Promoting the Culture of Academic and Research Integrity in a Higher Education Environment in Pakistan: A Qualitative Study,Ejaz Ullah Cheema; Sarah Rehman; Rabia Altaf; Zaheer Ahmad,2026,"Given the evolution in the global educational landscape coupled with the emergence of various Artificial Intelligence tools, academic and research integrity has gained significant importance. This study aims to qualitatively explore the views of stakeholders including students and faculty members about the challenges to academic and research integrity and the possible strategies to strengthen the integrity culture in a higher education environment in Pakistan. The study used a qualitative approach by conducting a focus group discussion using pre-defined interview topics. Thematic analysis of the qualitative data led to generation of four major themes with respective subthemes. Inadequate support from the institute regarding awareness and resources, fear of failure, lack of plagiarism detection tools and quest for promotion were identified as contributing factors towards academic misconduct. Participants supported the role of continuous professional development in promoting academic integrity. Most of the participants suggested that institutes should take the responsibility of organizing awareness sessions about plagiarism and other forms of dishonesty. The findings of this study suggests that establishment of a culture of academic integrity and ethical research is challenging and requires a sustained effort to raise awareness and transform the attitudes and behaviors of students and researchers.",Journal of Academic Ethics,v24 n1 Article 11 2026,10.1007/s10805-025-09690-4,http://eric.ed.gov/?id=EJ1491913,Higher Education; Foreign Countries; Student Attitudes; College Faculty; Teacher Attitudes; Stakeholders; Integrity; Educational Environment; Ethics; College Students; Academic Achievement; Research,English,Journal Articles; Reports - Research
EJ1464546,ChatGPT and Imaginaries of the Future of Education: Insights of Finnish Teacher Educators,Henriikka Vartiainen; Teemu Valtonen; Juho Kahila; Matti Tedre,2025,"Purpose: In 2022 generative AI took the Internet world by storm. Free access to tools that can generate text and images that pass for human creations triggered fiery debates about the potential uses and misuses of generative AI in education. There has risen a need to check the popular utopian and dystopian narratives about AI against the diversity of hopes, concerns and future imaginaries that educators themselves associate with generative AI. The purpose of this study is to investigate the perspectives of Finnish teacher educators on the use of AI in education. Design/methodology/approach: This article reports findings from a hands-on workshop in teacher training, where participants learned about how generative AI works, collaboratively explored generative AI and then reflected on its potential and challenges. Findings: The results reveal nuanced, calm and thoughtful imaginaries rooted in deep understanding of educational policy, evaluation and the sociocultural context of education. The results cover teachers' views on the impact of AI on learners' agency, metacognition, self-regulation and more. Originality/value: This article offers a unique exploration into the perceptions and imaginaries of educators regarding generative AI in specific (instead of ""monolithic AI""), moving beyond dystopian views and instead focusing on the potential of AI to align with existing pedagogical practices. The educators contrasted the common techno-deterministic narratives and perceived AI as an avenue to support formative assessment practices and development of metacognition, self-regulation, responsibility and well-being. The novel insights also include the need for AI education that critically incorporates social and ethical viewpoints and fosters visions for a future with culturally, socially and environmentally sustainable AI.",Information and Learning Sciences,v126 n1-2 p75-90 2025,10.1108/ILS-10-2023-0146,http://eric.ed.gov/?id=EJ1464546,Foreign Countries; Artificial Intelligence; Computer Software; Technology Uses in Education; Teacher Education Programs; Teacher Educators; Teacher Attitudes; Futures (of Society); Educational Trends; Personal Autonomy; Metacognition; Teacher Workshops; Teacher Collaboration; Technological Literacy; Pedagogical Content Knowledge; Educational Policy; Formative Evaluation; Teaching Methods; Ethics; Professional Autonomy,English,Journal Articles; Reports - Research
EJ1477073,Thematic Synthesis and Future Outlook in Digital Entrepreneurial Education,Finnah Fourqoniah; Muhammad Fikry Aransyah; Lilia Pasca Riani,2025,"The rapidly evolving field of digital entrepreneurial education has been significantly shaped by advancements in technologies such as augmented reality (AR), virtual reality (VR), and artificial intelligence (AI). While these technologies have opened new possibilities for entrepreneurial learning, much of the existing research is fragmented, focusing on isolated tools or specific interventions. This piecemeal approach complicates efforts to identify overarching trends, theoretical frameworks, and practical applications relevant to educators, policymakers, and researchers. To address these challenges, this study employs a Bibliometric-Systematic Literature Review (B-SLR) methodology, combining quantitative bibliometric analysis with qualitative synthesis to offer a comprehensive and balanced perspective on the field. We reviewed 261 articles published between 2005 and 2024, capturing diverse geographical regions, subject areas, and publication outlets. This approach enabled us to identify prevalent research themes, uncover emerging methodologies, and highlight areas that warrant deeper investigation. Our analysis revealed four main clusters: (1) Technology-Enhanced Entrepreneurship Education, examining how AR, VR, AI, and digital platforms foster engagement and skill-building; (2) Experiential and Project-Based Learning Approaches, highlighting gamification, simulations, and collaborative projects that stimulate practical competencies and adaptability; (3) Entrepreneurial Competencies, Mindset, and Social Dimensions, exploring cultural, generational, and gender-related factors that shape learner readiness and intentions; and (4) Future-Oriented and Transformative Approaches, emphasizing sustainability, global collaborations, and ethical considerations that guide the long-term evolution of entrepreneurial learning. The findings indicate that technological tools alone do not guarantee enhanced entrepreneurial outcomes. Instead, successful digital entrepreneurial education relies on cultural relevance, supportive policies, comprehensive educator training, and inclusive pedagogical designs. The study proposes an integrative framework that synthesizes technological, experiential, socio-cultural, and forward-looking strategies, offering actionable insights for improving educational practices and advancing theoretical understanding in the field. This research highlights critical areas for future exploration, including the development of learner-centred curricula, investments in digital infrastructure, and the promotion of international collaborations. By addressing these gaps, stakeholders can establish adaptable, inclusive, and ethically grounded ecosystems that equip learners with the skills and mindset needed to navigate the complexities of entrepreneurship in an increasingly dynamic global environment.",Electronic Journal of e-Learning,v23 n3 p30-44 2025,,http://eric.ed.gov/?id=EJ1477073,Physical Environment; Simulated Environment; Synthesis; Information Technology; Computer Simulation; Artificial Intelligence; Entrepreneurship; Educational Research; Experiential Learning; Active Learning; Student Projects; Gamification; Sustainability; Global Approach; Ethics; Social Influences; Educational Trends; Foreign Countries,English,Journal Articles; Reports - Research
EJ1415930,Deep Learning Imputation for Asymmetric and Incomplete Likert-Type Items,Zachary K. Collier; Minji Kong; Olushola Soyoye; Kamal Chawla; Ann M. Aviles; Yasser Payne,2024,"Asymmetric Likert-type items in research studies can present several challenges in data analysis, particularly concerning missing data. These items are often characterized by a skewed scaling, where either there is no neutral response option or an unequal number of possible positive and negative responses. The use of conventional techniques, such as discriminant analysis or logistic regression imputation, for handling missing data in asymmetric items may result in significant bias. It is also recommended to exercise caution when employing alternative strategies, such as listwise deletion or mean imputation, because these methods rely on assumptions that are often unrealistic in surveys and rating scales. This article explores the potential of implementing a deep learning-based imputation method. Additionally, we provide access to deep learning-based imputation to a broader group of researchers without requiring advanced machine learning training. We apply the methodology to the Wilmington Street Participatory Action Research Health Project.",Journal of Educational and Behavioral Statistics,v49 n2 p241-267 2024,10.3102/10769986231176014,http://eric.ed.gov/?id=EJ1415930,Likert Scales; Test Items; Item Analysis; Evaluation Methods; Regression (Statistics); Research Problems; Maximum Likelihood Statistics; Artificial Intelligence,English,Journal Articles; Reports - Evaluative
EJ1457242,"AI Literacy, Self-Efficacy, and Self-Competence among College Students: Variances and Interrelationships among Variables",John Mark R. Asio,2024,"Understanding and securely using AI systems and tools requires AI literacy. In contrast, AI self-efficacy is a person's confidence in completing an AI task. Also, AI self-competence is the ability to explain how AI technologies are used at work and how they affect society. This study examines college students' AI literacy, self-efficacy, and self-competence. Using a descriptive-correlational approach, the proponent assessed respondents' AI literacy, self-efficacy, and self-competence. The study also examined variations and connections between factors. The study participants were 1000 college students selected by purposive sampling. Before data collection, the proponent employed a modified instrument that was validated. Data was descriptively and inferentially analyzed using SPSS 23. Results suggest most pupils were ""somewhat literate"" in AI. They regarded themselves as ""somewhat self-efficient"" but ""self-competent"" in AI. The inferential analysis showed substantial differences in AI literacy by college, year level, and birth sex. Self-efficacy varied by college, year, age, and birth sex. The study found college and year-level differences in self-competence. Demographic traits and study variables were associated to some extent. According to the study's findings, the proponent recommended AI training programs, skill development for students and teachers, and institution-wide policy development and implementation to maximize AI's use in learning.",Malaysian Online Journal of Educational Sciences,v12 n3 p44-60 2024,,http://eric.ed.gov/?id=EJ1457242,Artificial Intelligence; Computer Software; Technological Literacy; Self Esteem; Self Concept; College Students; Student Attitudes; Correlation; Self Efficacy; Self Evaluation (Individuals); Gender Differences; Institutional Characteristics; Student Characteristics; Technology Uses in Education; Computer Science Education; School Policy; Ethics; Foreign Countries,English,Journal Articles; Reports - Research
EJ1430168,"Leveraging VR/AR/MR/XR Technologies to Improve Cybersecurity Education, Training, and Operations",Paul Wagner; Dalal Alharthi,2024,"The United States faces persistent threats conducting malicious cyber campaigns that threaten critical infrastructure, companies and their intellectual property, and the privacy of its citizens. Additionally, there are millions of unfilled cybersecurity positions, and the cybersecurity skills gap continues to widen. Most companies believe that this problem has not improved and nearly 44% believe it has gotten worse over the past 10 years. Threat actors are continuing to evolve their tactics, techniques, and procedures for conducting attacks on public and private targets. Education institutions and companies must adopt emerging technologies to develop security professionals and to increase cybersecurity awareness holistically. Leveraging Virtual/Augmented/Mixed/Extended Reality technologies for education, training, and awareness can augment traditional learning methodologies and improve the nation's cybersecurity posture. This paper reviews previous research to identify how distance and remote education are conducted generally, and how Virtual/Augmented/Extended/Mixed reality technologies are used to conduct cybersecurity awareness training, cybersecurity training, and conduct operations. Finally, barriers to adopting these technologies will be discussed. Understanding how these technologies can be developed and implemented provides one potential way of overcoming the cybersecurity workforce gap and increasing the competencies and capabilities of cybersecurity professionals.","Journal of Cybersecurity Education, Research and Practice",v2024 n1 Article 7 2024,,http://eric.ed.gov/?id=EJ1430168,Artificial Intelligence; Computer Simulation; Information Technology; Computer Security; Computer Science Education; Technology Uses in Education; Distance Education; Technology Integration; Barriers; Influence of Technology; Labor Force Development; Career Development,English,Journal Articles; Information Analyses
ED673061,Redefining Engineering Education: The Transformative Role of Generative AI Technologies,Amjad Almusaed; Marisol Rico Cortez; Asaad Almssad,2024,"AI is a rapidly advancing technology, especially in education. ""Generative AI"" is particularly notable for revolutionizing how we teach and learn, prompting a reevaluation of teacher training. Engineering education is at the forefront of pedagogical innovation, enhancing learning tools, and fostering a new educational mindset. This transition makes problem-solving more straightforward for teachers and encourages the revision of teaching methods, thus enhancing student-teacher relationships. Teaching space with AI integration transforms students into active learners, deeply involved in shaping their educational paths. This paper will explore the influence of generative AI on engineering education through a literature review, demonstrating how it contributes to more flexible, advanced, and engaging learning spaces. It will draw attention to the urgent need for educators to embrace and actively participate in these emerging dynamics. Specifically, the paper will focus on CDIO Standards 2 and 8, evaluating generative AI's impact on learning outcomes and promoting active learning. It aims to reveal how fertile AI can synchronize educational objectives with hands-on, collaborative student experiences. [For the complete proceedings, see ED672800.]","International Society for Technology, Education, and Science","Paper presented at the International Conference on Humanities, Social and Education Sciences (iHSES) (San Francisco, CA, Apr 16-19, 2024)",,http://eric.ed.gov/?id=ED673061,Engineering Education; Artificial Intelligence; Computer Software; Educational Change; Instructional Innovation; Active Learning; Standards; Outcomes of Education; Cooperative Learning; Ethics; Barriers; Interdisciplinary Approach; Technology Integration,,Speeches/Meeting Papers; Reports - Research
EJ1480914,The Role of Perceived Utility and Ethical Concerns in the Adoption of AI-Based Data Analysis Tools: A Multi-Group Structural Equation Model Analysis among Academic Researchers,Xintong Zhang; Jiangwei Hu; Yunqian Zhou,2025,"This study explores the role of perceived utility, social influence, and ethical concerns in the adoption of AI-based data analysis tools among academic researchers in China, focusing on differences between public and private universities. The research aims to identify key drivers and barriers influencing the integration of AI technology in academic settings. A quantitative approach was employed, using a multi-group structural equation model (SEM) analysis to assess data collected from 750 academic researchers across various disciplines (N[subscript pvt] = 402; N[subscript pub] = 348). The findings reveal that both perceived utility and social influence significantly influence the adoption of AI tools. Higher perceived utility and stronger social influence lead to greater adoption. However, ethical concerns were found to moderate these relationships, particularly in public universities, where researchers with high ethical concerns perceived greater risks, thereby reducing their likelihood of adoption. In contrast, private university researchers showed a higher tolerance for perceived risks when utility and social influence were evident. The study's implications suggest that to promote AI adoption, institutions must address ethical concerns and perceived risks, particularly in public universities, by enhancing transparency, providing ethical guidelines, and offering comprehensive training. These efforts can lead to more effective integration of AI technologies, ultimately enhancing research productivity and innovation across diverse academic environments.",Education and Information Technologies,v30 n13 p18819-18851 2025,10.1007/s10639-025-13535-3,http://eric.ed.gov/?id=EJ1480914,Usability; Ethics; Artificial Intelligence; Technology Uses in Education; Learning Analytics; Educational Research; Educational Researchers; Structural Equation Models; Social Influences; Technology Integration; Barriers; Accountability; Training; Productivity; Foreign Countries,English,Journal Articles; Reports - Research; Tests/Questionnaires
EJ1438892,The Impact of Generative AI Tools on Researchers and Research: Implications for Academia in Higher Education,Abdulrahman M. Al-Zahrani,2024,"This study explores the impact of Generative AI tools on researchers and research in the context of higher education in Saudi Arabia. An online survey questionnaire was used to collect data on higher education students' perspectives (N = 505). The findings indicate that participants hold positive attitudes and possess a high level of awareness regarding GenAI in research. They recognise the potential of these tools to revolutionise academic research. Participants report highly beneficial experiences using GenAI tools to expand project scope and improve efficiency. Additionally, participants expressed optimism about the future role of GenAI tools, expecting them to become more prevalent and transform the research landscape. However, participants emphasised the importance of adequate training, support, and guidance in using GenAI tools. Ethical considerations emerged as a significant concern, highlighting the participants' commitment to responsible research practices and the need for transparency and addressing potential biases associated with these tools.",Innovations in Education and Teaching International,v61 n5 p1029-1043 2024,10.1080/14703297.2023.2271445,http://eric.ed.gov/?id=EJ1438892,Artificial Intelligence; Technology Uses in Education; Foreign Countries; College Students; Student Attitudes; Student Research; Opportunities; Positive Attitudes; Student Experience; Futures (of Society); Ethics; Self Efficacy; Student Characteristics; Age Differences; Research Methodology; Efficiency,English,Journal Articles; Reports - Research; Tests/Questionnaires
EJ1420456,A Mobile-Based System for Preventing Online Abuse and Cyberbullying,Semiu Salawu; Jo Lumsden; Yulan He,2022,"A negative consequence of the proliferation of social media is the increase in online abuse. Bullying, once restricted to the playground, has found a new home on social media. Online social networks on their part have intensified efforts to tackle online abuse, but unfortunately, such is the scale of the problem that many young people are still regularly subjected to a wide range of abuse online. Research in automated detection of online abuse has increased considerably in recent times. However, existing studies on online abuse detection typically focus on developing newer algorithms to improve predictions, and little research is done on developing impactful tools that leverage these algorithms to tackle online abuse. In this paper, we present BullStop, a mobile application that can use different machine learning models to detect cyberbullying. A new cyberbullying dataset containing 62,587 tweets annotated using a taxonomy of different cyberbullying types was created to facilitate the classifier's training. BullStop was developed using a participatory and user-centred design approach involving young people, parents, educators, law enforcement and mental health professionals. Additionally, the application incorporates online training for the ML models using ground truth supplied by the user as additional training data, and in this way, it can create a personalised classifier for each user. Furthermore, on detecting online abuse, the application automatically initiates punitive actions such as deleting offensive messages and blocking cyberbullies on behalf of the user. BullStop is freely available on the Google Play Store and has been downloaded by hundreds of users.",International Journal of Bullying Prevention,v4 n1 p66-88 2022,10.1007/s42380-021-00115-5,http://eric.ed.gov/?id=EJ1420456,Computer Mediated Communication; Bullying; Computer Software; Computational Linguistics; Social Media; Antisocial Behavior; Algorithms; Artificial Intelligence; Identification; Taxonomy; Ethics; Prevention,English,Journal Articles; Reports - Descriptive
EJ1430139,ChatGPT in Education: A Discourse Analysis of Worries and Concerns on Social Media,Lingyao Li; Zihui Ma; Lizhou Fan; Sanggyu Lee; Huizi Yu; Libby Hemphill,2024,"The rapid advancements in generative AI models present new opportunities in the education sector. However, it is imperative to acknowledge and address the potential risks and concerns that may arise with their use. We analyzed Twitter data to identify critical concerns related to the use of ChatGPT in education. We employed BERT-based topic modeling to conduct a discourse analysis and social network analysis to identify influential users in the conversation. While Twitter users generally expressed a positive attitude toward using ChatGPT, their concerns converged into five categories: academic integrity, impact on learning outcomes and skill development, limitation of capabilities, policy and social concerns, and workforce challenges. We also found that users from the tech, education, and media fields were often implicated in the conversation, while education and tech individual users led the discussion of concerns. Based on these findings, the study provides several implications for policymakers, tech companies and individuals, educators, and media agencies. In summary, our study underscores the importance of responsible and ethical use of AI in education and highlights the need for collaboration among stakeholders to regulate AI policy.",Education and Information Technologies,v29 n9 p10729-10762 2024,10.1007/s10639-023-12256-9,http://eric.ed.gov/?id=EJ1430139,Artificial Intelligence; Man Machine Systems; Natural Language Processing; Social Media; Discourse Analysis; Technology Uses in Education; Integrity; Ethics; Skill Development; Outcomes of Education; Labor Force,English,Journal Articles; Reports - Research
EJ1484794,Advancing Healthcare Practice and Education via Data Sharing: Demonstrating the Utility of Open Data by Training an Artificial Intelligence Model to Assess Cardiopulmonary Resuscitation Skills,Merryn D. Constable; Francis Xiatian Zhang; Tony Conner; Daniel Monk; Jason Rajsic; Claire Ford; Laura Jillian Park; Alan Platt; Debra Porteous; Lawrence Grierson; Hubert P. H. Shum,2025,"Health professional education stands to gain substantially from collective efforts toward building video databases of skill performances in both real and simulated settings. An accessible resource of videos that demonstrate an array of performances -- both good and bad -- provides an opportunity for interdisciplinary research collaborations that can advance our understanding of movement that reflects technical expertise, support educational tool development, and facilitate assessment practices. In this paper we raise important ethical and legal considerations when building and sharing health professions education data. Collective data sharing may produce new knowledge and tools to support healthcare professional education. We demonstrate the utility of a data-sharing culture by providing and leveraging a database of cardio-pulmonary resuscitation (CPR) performances that vary in quality. The CPR skills performance database (collected for the purpose of this research, hosted at UK Data Service's ReShare Repository) contains videos from 40 participants recorded from 6 different angles, allowing for 3D reconstruction for movement analysis. The video footage is accompanied by quality ratings from 2 experts, participants' self-reported confidence and frequency of performing CPR, and the demographics of the participants. From this data, we present an Automatic Clinical Assessment tool for Basic Life Support that uses pose estimation to determine the spatial location of the participant's movements during CPR and a deep learning network that assesses the performance quality.",Advances in Health Sciences Education,v30 n1 p15-35 2025,10.1007/s10459-024-10369-5,http://eric.ed.gov/?id=EJ1484794,Data Use; Artificial Intelligence; First Aid; Ethics; Legal Problems; Allied Health Occupations Education; Video Technology; Foreign Countries,English,Journal Articles; Reports - Research
ED673118,Growing Interest in AI in Education: Systematic Literature Review,Danijela Blanuša Trošelj; Sven Maricic; Antonia Curic,2024,"Although AI in education has been written about for decades, recent years have seen exponential growth in this area. The aim of this paper was to determine the distribution of content and areas of education in which AI is researched. The article provides an overview of the newest research in the field of AI in education, available in open access journals. In the theoretical part, an overview of the historical context is given. Also, key definitions and approaches for understanding the topic are listed. In the methodological part, Systematic Literature Review was used, with AI and education as search words. Publish research studies between January 2023 and December 2023. The research found that there is a difference in the amount of AI research at certain degrees and fields of education. The application of AI is particularly explored in higher education. As specific areas of research, the ethical issues of applying AI in education and the possibilities of applying AI in the learning and teaching process appear. [For the complete proceedings, see ED672804.]","International Society for Technology, Education, and Science","Paper presented at the International Conference on Research in Education and Science (ICRES) (Antalya, Turkey, Apr 27-30, 2024)",,http://eric.ed.gov/?id=ED673118,Artificial Intelligence; Technology Uses in Education; Educational Research; Definitions; Ethics; Man Machine Systems; Natural Language Processing; Elementary Secondary Education; Higher Education; Professional Development,,Speeches/Meeting Papers; Information Analyses
EJ1447404,Leveraging ChatGPT for Enhancing Critical Thinking Skills,Ying Guo; Daniel Lee,2023,"This article presents a study conducted at Georgia Gwinnett College (GGC) to explore the use of ChatGPT, a large language model, for fostering critical thinking skills in higher education. The study implemented a ChatGPT-based activity in introductory chemistry courses, where students engaged with ChatGPT in three stages: account setup and orientation, essay creation, and output revision and validation. The results showed significant improvements in students' confidence to ask insightful questions, analyze information, and comprehend complex concepts. Students reported that ChatGPT provided diverse perspectives and challenged their current ways of thinking. They also expressed an increased utilization of ChatGPT to enhance critical thinking skills and a willingness to recommend it to others. However, challenges included low-quality student comments and difficulties in validating information sources. The study highlights the importance of comprehensive training for educators and access to reliable resources. Future research should focus on training educators in integrating ChatGPT effectively and ensuring student awareness of privacy and security considerations. In conclusion, this study provides valuable insights for leveraging AI technologies like ChatGPT to foster critical thinking skills in higher education.",Journal of Chemical Education,v100 n12 p4876-4883 2023,10.1021/acs.jchemed.3c00505,http://eric.ed.gov/?id=EJ1447404,Artificial Intelligence; Computer Software; Synchronous Communication; Critical Thinking; Thinking Skills; Skill Development; Public Colleges; Open Education; Hispanic American Students; Minority Serving Institutions; Higher Education; Introductory Courses; Chemistry; College Science; Science Education; Technology Uses in Education; Technological Literacy; Computer Assisted Instruction; Student Centered Learning,English,Journal Articles; Reports - Research
EJ1360022,Constructing an Edu-Metaverse Ecosystem: A New and Innovative Framework,"Wang, Minjuan; Yu, Haiyang; Bell, Zerla; Chu, Xiaoyan",2022,"The Metaverse is a network of 3-D virtual worlds supporting social connections among its users and enabling them to participate in activities mimicking real life. It merges physical and virtual reality and provides channels for multisensory interactions and immersions in a variety of environments (Mystakidis, 2022). The Metaverse is considered the third wave of the Internet revolution, and it is built on new and emerging technologies such as extended reality and artificial intelligence. Research on the impact of the Metaverse on education exploded in 2022. Here, we explore learning across the Metaverse and propose a new and innovative theoretical framework by reviewing literature and synthesizing best practices in designing metaverse learning environments. This ecosystem consists of four major hubs: (1) instructional design and performance technology hub; (2) knowledge hub; (3) research and technology hub; and (4) talent and training hub. Common to all four hubs are the factors in the three wheels: (1) infrastructure, business industry, and communication; (2) technology access and equity; and (3) user rights, data security, and privacy policy. We believe that this framework can help guide emerging research and development on the applications of the Metaverse in education. We also hope this article can serve as a launch pad for the special issue on the Metaverse and the Future of Education supported by the IEEE Education Society.",IEEE Transactions on Learning Technologies,v15 n6 p685-696 Dec 2022,10.1109/TLT.2022.3210828,http://eric.ed.gov/?id=EJ1360022,Technology Uses in Education; Computer Simulation; Educational Environment; Best Practices; Instructional Design; Access to Computers; Computer Security; Privacy; Educational Innovation,English,Journal Articles; Reports - Evaluative
ED646468,"The Upstream Sources of Bias: Investigating Theory, Design, and Methods Shaping Adaptive Learning Systems",Shamya Chodumada Karumbaiah,2022,"Adaptive systems in education need to ensure population validity to meet the needs of all students for an equitable outcome. Recent research highlights how these systems encode societal biases leading to discriminatory behaviors towards specific student subpopulations. However, the focus has mostly been on investigating bias in predictive modeling, particularly its downstream stages like model development and evaluation. My dissertation work hypothesizes that the upstream sources (i.e., theory, design, training data collection method) in the development of adaptive systems also contribute to the bias in these systems, highlighting the need for a nuanced approach to conducting fairness research. By empirically analyzing student data previously collected from various virtual learning environments, I investigate demographic disparities in three cases representative of the aspects that shape technological advancements in education: (1) non-conformance of data to a widely-accepted theoretical model of emotion, (2) differing implications of technology design on student outcomes, and (3) varying effectiveness of methodological improvements in annotated data collection. In doing so, I challenge implicit assumptions of generalizability in theory, design, and methods and provide an evidence-based commentary on future research and design practices in adaptive and artificially intelligent educational systems surrounding how we consider diversity in our investigations. [The dissertation citations contained here are published with the permission of ProQuest LLC. Further reproduction is prohibited without permission. Copies of dissertations may be obtained by Telephone (800) 1-800-521-0600. Web page: http://www.proquest.com/en-US/products/dissertations/individuals.shtml.]",ProQuest LLC,"Ph.D. Dissertation, University of Pennsylvania",,http://eric.ed.gov/?id=ED646468,Equal Education; Social Bias; Assistive Technology; Electronic Learning; Artificial Intelligence; Educational Technology; Research Methodology; Educational Research,,Dissertations/Theses - Doctoral Dissertations
EJ1447510,Examining School Principals' and Teachers' Perceptions of Using ChatGPT in Education,Yasemin Cetin; Özgür Tas; Halil Alakus; Halil Ibrahim Kaplan,2024,"Background/purpose: ChatGPT has become one of the groundbreaking examples of artificial intelligence-based chatbots with its capacity to produce texts and engage in human-like conversations. Therefore, it has garnered the attention of people with diverse backgrounds, including educational professionals. The current study aims to investigate how school principals and teachers perceived the use of ChatGPT in education and reveal their attitudes towards using AI-based tools to facilitate the teaching-learning experience. Materials/methods: The study was designed using the qualitative case study method since it aimed to gather detailed information regarding school principals' and teachers' perceptions of ChatGPT. Data was collected from 80 teachers and school principals selected purposefully from public primary, secondary, and high schools. Data was analyzed using content analysis techniques by synthesizing codes into categories and themes. Results: The study revealed four major themes regarding school principals' and teachers' perceptions of ChatGPT: overall perceptions, perceived opportunities, perceived risks, and the effective use of ChatGPT. The participants referred to several advantages of using ChatGPT in education such as lesson planning, offering customized learning, and enabling easy and fast access to information. They were also cautious about some risks such as ethical and responsible use, the likelihood of encouraging dishonesty, free-riding, cheating, or plagiarism as well as weakening students' cognitive skills. Due to its potential to provide inaccurate information depending on the reliability of its data source, they were also doubtful that it could provide students with false guidance in its current form. The participants also made some recommendations to make better and more effective use of ChatGPT in education such as providing ongoing training for both teachers and students on recent developments, increasing the reliability of its data sources through continuous tests, and aligning its capacity with the readiness and age of students. Conclusion: The current study showed that school principals and teachers had sufficient knowledge of ChatGPT and mostly had a positive attitude towards its use in education despite some risks. Combined with the findings of prior studies, the current results suggest taking several steps to minimize the risks and offering both pre-and in-service training to teachers for more effective use.",Educational Process: International Journal,v13 n3 p85-96 2024,,http://eric.ed.gov/?id=EJ1447510,Principals; Administrator Attitudes; Teacher Attitudes; Artificial Intelligence; Natural Language Processing; Technology Uses in Education; Public Schools; Elementary School Teachers; Secondary School Teachers; High School Teachers; Opportunities; Risk; Ethics; Foreign Countries; Computer Use,English,Journal Articles; Reports - Research
EJ1420866,Educating Students about the Ethical Principles Underlying the Interpretation of Infographics,Salma Banu Nazeer Khan; Ayse Aysin Bilgin; Deborah Richards; Paul Formosa,2024,"Infographics are visual storytelling techniques used to communicate complex information. However, infographics can be misleading if they are not created ethically. When universities teach how to create infographics, they often do so without emphasizing the ethical issues underlying infographics. To address this gap, we designed a study to educate statistics and data science students about the ethics of infographics by using Rest model's three stages: awareness, orientation, and intention. Students' awareness of the ethical issues underlying infographics was captured before and after sensitizing them to five ethical principles derived from the AI4People's framework applied to a data science context. The students were then exposed to scenarios with ethical dilemmas. Their identification of the ethical principles in these scenarios was measured. The results showed a significant increase in students' awareness of the ethical issues underpinning the interpretation of infographics, suggesting that ethical training of current users and future designers would be beneficial.",Teaching Statistics: An International  Journal for Teachers,v46 n2 p69-94 2024,10.1111/test.12362,http://eric.ed.gov/?id=EJ1420866,Ethics; Visual Aids; Statistics Education; Design; Teaching Methods; Misinformation; Models; Intention; Knowledge Level; Guidelines,English,Journal Articles; Reports - Research; Tests/Questionnaires
EJ1477690,Predicting Teachers' Intentions for AIGC Integration in Preschool Education: A Hybrid SEM-ANN Approach,Yuxin Zhang,2025,"Aim/Purpose: This study investigates the key factors influencing preschool teachers' sustained use of Artificial Intelligence-Generated Content (AIGC) technology in educational settings. While prior research has extensively examined initial adoption, little attention has been given to understanding the continuous intention of preschool teachers with AIGC. To bridge this gap, this study integrates the Technology Acceptance Model (TAM), Expectation-Confirmation Model (ECM), and Flow Theory to develop a comprehensive framework that captures cognitive, affective, and experiential factors shaping continued AIGC adoption. Background: AIGC has demonstrated immense educational potential, providing personalized learning experiences, real-time feedback, and intelligent student progress tracking. However, most existing research focuses primarily on system usability and feasibility, neglecting the motivational and psychological aspects that determine continuous intention to use AIGC. Specifically, satisfaction, expectation confirmation, and flow experience have been largely overlooked as key determinants of sustained technology use. Given that preschool educators face unique pedagogical challenges, such as adapting AIGC content to young learners and maintaining engagement, understanding the drivers of long-term AIGC use is essential for optimizing its integration into preschool education. Methodology: This study employs a mixed-method approach to ensure a rigorous and comprehensive analysis. A total of 433 preschool teachers participated in the survey, and Partial Least Squares-Structural Equation Modeling (PLS-SEM) was used to test the hypothesized relationships. To complement structural modeling, Artificial Neural Network (ANN) modeling was applied to uncover non-linear relationships that traditional statistical methods might overlook. By integrating PLS-SEM and ANN, this study provides a more robust, predictive, and holistic understanding of the factors driving sustained AIGC adoption. Contribution: This study makes significant theoretical and practical contributions. Theoretically, it extends TAM and ECM by incorporating Flow Theory. Unlike prior studies focusing primarily on perceived usefulness and ease of use, this research identifies confirmation and satisfaction as the strongest predictors of continued intention to use AIGC. Practically, the findings provide valuable insights for policymakers, school administrators, and ed-tech developers, offering recommendations for designing more engaging, sustainable, and user-friendly AIGC solutions tailored for preschool education. Findings: The results indicate that satisfaction ([beta] = 0.280, p < 0.001) is the strongest predictor of continued AIGC use, followed by attitude ([beta] = 0.262, p < 0.001) and flow experience ([beta] = 0.223, p < 0.001). Expectation confirmation significantly enhances perceived usefulness ([beta] = 0.505, p < 0.001) and satisfaction ([beta] = 0.349, p < 0.001), reinforcing the importance of aligning AIGC tools with teachers' expectations. ANN analysis further highlights confirmation (95.28%) and satisfaction (82.41%) as the most influential factors, whereas perceived ease of use (22.35%) has a relatively minor impact. These findings suggest that positive user experience, engagement, and expectation fulfillment are key drivers of long-term AIGC adoption. Moreover, ANN analysis revealed complex nonlinear relationships, demonstrating that traditional statistical methods might underestimate the true impact of psychological and experiential factors on technology retention. Recommendations for Practitioners: For practitioners, this study provides several actionable recommendations. First, AIGC tools should be designed to enhance engagement and intrinsic motivation, integrating gamification elements, interactive features, and adaptive learning support to sustain user interest. Second, ongoing professional development programs should be implemented to train teachers on the pedagogical applications of AIGC, addressing any concerns related to usability or long-term feasibility. Third, AIGC platforms should incorporate customization features, allowing educators to tailor content based on their specific classroom needs and teaching styles. By addressing these factors, AIGC adoption in preschool education can be more sustainable and impactful. Recommendation for Researchers: For researchers, this study opens multiple avenues for future exploration. First, future research should adopt a longitudinal approach to examine how preschool teachers' attitudes and behaviors toward AIGC evolve over time. Second, more research is needed to explore the role of teacher personality traits and digital literacy levels in shaping AIGC adoption patterns. Third, cross-cultural studies could provide deeper insights into how different educational systems and socio-cultural contexts influence preschool teachers' responses to AIGC technologies. Furthermore, AI-driven predictive analytics should be explored to model behavioral trends and optimize AIGC implementations across diverse learning environments. Impact on Society: This study has significant implications for educational equity, teacher workload, and early childhood learning experiences. By empowering preschool teachers with AIGC, this research promotes more inclusive and accessible preschool education, reducing disparities in educational resources and opportunities. Additionally, AI-driven teaching solutions can alleviate teacher workload, enabling educators to focus on creative and interactive pedagogical strategies rather than administrative tasks. As AIGC continues to evolve, its potential to transform preschool education into a more engaging, adaptive, and learner-centered experience becomes increasingly evident. Future Research: While this study provides valuable insights into preschool teachers' sustained use of AIGC, several areas require further exploration. First, objective usage data should be incorporated into future research rather than relying solely on self-reported surveys to enhance validity. Second, longitudinal studies should examine how teachers' continuous intention to use AIGC evolves over time in response to technological advancements and policy shifts. Third, as this study focuses on preschool educators, future research should explore whether the identified factors apply to primary and secondary education teachers. Additionally, ethical concerns, AI trust, and data privacy issues should be further investigated, as they may significantly impact the long-term adoption of AIGC in educational settings.",Journal of Information Technology Education: Research,v24 Article 16 2025,,http://eric.ed.gov/?id=EJ1477690,Preschool Teachers; Artificial Intelligence; Technology Integration; Technology Uses in Education; Preschool Education; Intention; Predictor Variables; Teacher Attitudes; Satisfaction; Expectation; Experience; Participation; Value Judgment; Usability; Foreign Countries,English,Journal Articles; Reports - Research
ED677645,Building Capacity in Practice: Using AI to Study the Implementation of California's Community Schools Strategies,Andrés Fernández-Vergara,2025,"Background: California's unprecedented grant investment in the community school strategy through the California Community Schools Partnership Program (CCSPP) offers a significant opportunity for transformative, equity-centered, whole-child school reform (Maier & Niebuhr, 2021). Community schools are grounded in partnerships that schools establish with their communities, engaging families' social and cultural backgrounds as assets to develop teaching and learning suited for their students' needs (Blank, et al., 2003). The community school strategy has been proven to be effective in transforming schools, with justice and fairness as key pillars (Maier et al., 2017; Oaks et al., 2017). However, the specific processes by which schools enact such transformation remain underexplored. In 2022, at the beginning of the CCSPP grant, the State Transformational Assistance Center (STAC) released a rubric to guide and gauge the process of transforming schools into Community Schools (STAC, 2024). This rubric outlines five capacity-building strategies that integrate goals and actions that should drive improvements for community schools, describing practices that have been proven effective in meeting schools' needs (Oakes, et al., 2017). These five strategies are: (1) 'Shared Commitment, Understanding, and Priorities'; (2) 'Centering Community-based Learning'; (3) 'Collaborative Leadership'; (4) 'Sustaining Staff and Resources'; and (5) 'Strategic Community Partnerships' (STAC, 2024). These strategies are further elaborated in the ""California Community School Framework"" (California Department of Education, 2024). This set of strategies offers a ""how"" for schools to build the structural and organizational capacity for collective efficacy and action aiming at shared goals (STAC, 2024). To support schools through this transformation, the rubric outlines three growth stages for schools: visioning (e.g., communicating, designing, planning, etc.); engaging (e.g., having discussions, collecting data, creating spaces or councils, etc.); and transforming (e.g., expanding, evaluating, presenting, showcasing, etc.). Research Question: This article examines how CCSPP schools are implementing these strategies, identifying which are most commonly reported and how implementation varies across grantees. Although it is still too early to evaluate the results of the implementation of these strategies on educational outcomes, monitoring how they are put into practice offers valuable insight into how schools are implementing the CCSPP grant. To address this, this study uses the CCSPP Annual Progress Report (APR) -- a required survey-style report that all grantees submit annually. It monitors the implementation of the Community School strategy and informs the technical assistance that is provided through the STAC and the broader support system (i.e., regional centers, county offices, and districts). Designed as a reflective rather than accountability tool, the APR favors open-ended questions, which yield rich narrative data but also pose challenges for systematic analysis. Population and Methods: This study focuses on the first cohort of CCSPP grantee school sites and their first two rounds of APR (2022-23 and 2023-24), analyzing their reported implementation of the capacity-building strategies. The APR asks grantees where they position themselves in the growth rubric (visioning, engaging, or transforming) and what accomplishments they showed during the academic year (open-ended). These data are linked to grantees' original application type--whether they identified as a ""new,"" ""expanding,"" or ""continuing"" community school. To analyze the open-ended responses, this study employs a large language model (GPT-4o) to code the text and identify references to the five strategies. The validity and reliability of using AI for text annotation are evaluated using intercoder agreement and other standard indicators, following current best practices (Törnberg, 2023, 2024; Gilardi et al., 2023; Laurer, 2024). Findings: Preliminary analysis examines both the growth phase in which schools position themselves and whether they mention specific strategies in their reported accomplishments. Findings suggest that schools identifying as ""continuing"" community schools at the time of their grant application are more likely to report being in the transforming phase by their second year compared to new or expanding community schools. This trend is consistent across all five strategies but is particularly evident for ""Sustaining Staff and Resources"" and ""Strategic Community Partnerships."" However, when analyzing which strategies are explicitly mentioned in the accomplishments narratives, ""Sustaining Staff and Resources"" emerges as the least frequently cited--even among continuing schools. In contrast, ""Strategic Community Partnerships"" is the most commonly mentioned strategy. In addition, the ""Centering Community-Based Learning"" strategy appears particularly challenging for schools to operationalize. Only 10% of continuing schools report being in the transformative phase by the end of their second year and just 49% mention it on the accomplishments -- compared to 79% mentioning the other strategies. Taken together, these findings suggest that while schools across California are making progress in building partnerships, there is significant variation in their experiences with implementing strategies aimed at long-term sustainability and staff support. When looking at the open-ended responses with more detail, it provides information on how these strategies look in practice and why continuing schools seem to manage the implementation more thoroughly. For example, from the responses, it can be seen that many schools report that they have accomplished establishing strong partnerships that address community needs. These partnerships look very different and are context-specific, ranging from local businesses that provide career exploration opportunities to higher education institutions that implement mentoring or early college programs. In addition, some schools report that they have accomplished listening to teachers' voices regarding their needs and professional development opportunities, and students' and families' perspectives about the needs of the community. Although accomplishments were achieved, there are still many challenges to sustaining ""community-based learning"" in the center of Community Schooling. Many schools still face limited resources, scheduling conflicts, and difficulties in maintaining consistent community involvement, which hinders the possibility of bringing the community into the teaching and learning processes. Conclusions: These findings contribute to the literature on school effectiveness along two key dimensions. First, the analysis explores how community schools build the capacity to connect and engage their surrounding communities and systems, and how state-level policy--specifically, the CCSPP grant--can guide the support of school practices. Second, this study highlights a concrete example of a novel methodological contribution by using AI for text annotation. Discussing its results, validity, and limitations would show important implications for the use of AI to code open-ended questions in educational research.",Society for Research on Educational Effectiveness,,,http://eric.ed.gov/?id=ED677645,Capacity Building; Artificial Intelligence; Technology Uses in Education; Program Implementation; Community Schools; Educational Strategies; Grants; Technical Assistance; Accountability; Educational Development; Community Education,,Reports - Research
ED654536,"Ethics, Education and Machine Intelligence",Zorislav Šojat; Gordana Gredicak Šojat,2023,"The sudden, unexpected breakthrough in the intelligence shown by machines, as a wished for, but very disruptive element, will shape the future of our civilisation and Humans as individuals and collectives. The extreme drive towards commercialisation of newest developments already led to an extremely wide spread of Machine Intelligence Assistants (and chatbots), with plans of many companies to include them into everything they produce. This puts Humans in a very precarious situation, specifically regarding ethics and morale, trustworthiness and confidence. Suddenly we found ourselves in a situation that Education has to be extended to cater for two types of intelligences: the Humans and the Machines. On the Machine side, it has been shown that it is very difficult to obtain a trustworthy and highly ethical non-biased intelligence. The present day approach of ""training"" the ""models"" must be overcome by the realisation that MI is based on collected Human knowledge, but initially ""trained"" without any regard to the order of learning, which directly influences the initial alignment of the emerging intelligence, the same way learning does in Humans. On the Human side, it is getting obvious that this disruptive development was generally completely unexpected, and no educational preparation was ever envisioned for this situation. However, between others, a good example of possible positive cooperation of Humans and Machines, which necessitates proper MI ethics, is Democratisation of Academic Publishing, where, based on blockchain trustworthiness, Open Access publishing is done in such a way that all stakeholders in the process get appropriate recognition and reward. The use of well educated Ethical Machine Intelligence in this process of management of an enormous amount of academic work and peer reviews will enable academic education and scientific development to be ethical, transparent, fair, trustworthy and accessible to all authors and readers throughout their life. [For the full proceedings, see ED654100.]","International Society for Technology, Education, and Science","Paper presented at the International Conference on Research in Education and Science (ICRES) (Cappadocia, Turkey, May 18-21, 2023)",,http://eric.ed.gov/?id=ED654536,Ethics; Artificial Intelligence; Technology Uses in Education; Morale; Teaching Methods; Computer Software; Futures (of Society); Commercialization; Trust (Psychology); Intellectual Development; Bias; Barriers; Computational Linguistics; Learning Processes; Man Machine Systems; Academic Education; Peer Evaluation; Scientific Research; Open Source Technology; Faculty Publishing; Professional Recognition; Scholarship,,Speeches/Meeting Papers; Reports - Descriptive
EJ1484511,Enhancing Reflective Practice in Language Teacher Education: Technology as a Critical Reflective Partner,Daniel Xerri,1032,"This article explores how technology can serve as a critical partner in enhancing reflective practice in language teacher education. Drawing on recent studies, it examines the potential of AI tools, digital portfolios, video-based analysis, and online collaborative platforms. The argument hinges on the need to move toward a human-centred integration of digital tools that support metacognitive growth, emotional resilience, and professional identity development. The article proposes a five-principle framework for technology-enhanced reflection, emphasising pedagogical alignment, depth, collaboration, transparency, and teacher agency. While acknowledging risks related to over-automation and ethical ambiguity, the article contends that well-designed technologies, when critically embedded in reflective ecosystems, can deepen inquiry, foster contextualised insight, and support more dialogic and sustainable teacher learning. Ultimately, it advocates for technology that amplifies human reflection, positioning language educators as co-constructors of meaning in digitally mediated learning environments.",Technology in Language Teaching & Learning,v7 n2 Article 103214 2025,,http://eric.ed.gov/?id=EJ1484511,Technology Uses in Education; Language Teachers; Teacher Education; Artificial Intelligence; Portfolios (Background Materials); Electronic Publishing; Video Technology; Online Systems; Technology Integration; Reflective Teaching; Cooperation; Professional Identity; Well Being; Psychological Patterns; Ethics; Risk; Models,English,Journal Articles; Reports - Evaluative
EJ1447297,Zero- and Few-Shot Prompting of Generative Large Language Models Provides Weak Assessment of Risk of Bias in Clinical Trials,Simon Šuster; Timothy Baldwin; Karin Verspoor,2024,"Existing systems for automating the assessment of risk-of-bias (RoB) in medical studies are supervised approaches that require substantial training data to work well. However, recent revisions to RoB guidelines have resulted in a scarcity of available training data. In this study, we investigate the effectiveness of generative large language models (LLMs) for assessing RoB. Their application requires little or no training data and, if successful, could serve as a valuable tool to assist human experts during the construction of systematic reviews. Following Cochrane's latest guidelines (RoB2) designed for human reviewers, we prepare instructions that are fed as input to LLMs, which then infer the risk associated with a trial publication. We distinguish between two modelling tasks: directly predicting RoB2 from text; and employing decomposition, in which a RoB2 decision is made after the LLM responds to a series of signalling questions. We curate new testing data sets and evaluate the performance of four general- and medical-domain LLMs. The results fall short of expectations, with LLMs seldom surpassing trivial baselines. On the direct RoB2 prediction test set (n = 5993), LLMs perform akin to the baselines (F1: 0.1-0.2). In the decomposition task setup (n = 28,150), similar F1 scores are observed. Our additional comparative evaluation on RoB1 data also reveals results substantially below those of a supervised system. This testifies to the difficulty of solving this task based on (complex) instructions alone. Using LLMs as an assisting technology for assessing RoB2 thus currently seems beyond their reach.",Research Synthesis Methods,v15 n6 p988-1000 2024,10.1002/jrsm.1749,http://eric.ed.gov/?id=EJ1447297,Medical Research; Safety; Experimental Groups; Control Groups; Drug Therapy; Artificial Intelligence; Prompting; Risk; Bias; Evaluation; Prediction,English,Journal Articles; Reports - Research
EJ1464369,The Sentiments and the Impact of ChatGPT on Computer Programming Learning: Data Mining from Comments on YouTube Videos,Meina Zhu,7001,"Background: Computer programming learning and education play a critical role in preparing a workforce equipped with the necessary skills for diverse fields. ChatGPT and YouTube are technologies that support self-directed programming learning. Objectives: This study aims to examine the sentiments and primary topics discussed in YouTube comments about ChatGPT's impact on learning and writing computer programming. Methods: The data were collected from 30 November 2022 to 11 January 2024, by extracting 30,773 comments from 57 YouTube videos. Sentiment analysis, topic modelling and thematic analysis were used for data analysis. Results and Conclusions: Through sentiment analysis and thematic analysis, a positive attitude among YouTube self-directed learners towards employing ChatGPT for learning and writing computer programming was identified. The results of topic modelling and thematic analysis revealed that these learners recognise both the perceived advantages and limitations of using ChatGPT for learning and writing computer programming. The advantages include creating learning plans, generating code, self-correction, explaining code and saving programming time, while the limitations are incorrect information, challenges in debugging programmes, perceived inefficiency and ineffectiveness and the absence of intelligence. Diverse perspectives regarding the impact of ChatGPT on programming professions and education were discussed. Some ethical concerns regarding data privacy, code copyright and equity issues were raised and needed further exploration. The findings imply the importance of computer programming education and integrating ChatGPT into programming education. Guidelines and instructions regarding using ChatGPT for programming learning are needed.",Journal of Computer Assisted Learning,v41 n2 e70013 2025,10.1111/jcal.70013,http://eric.ed.gov/?id=EJ1464369,Computer Science Education; Programming; Social Media; Video Technology; Data Collection; Computer Mediated Communication; Artificial Intelligence; Synchronous Communication; Computer Software; Individualized Instruction; Technology Uses in Education,English,Journal Articles; Reports - Research
EJ1406123,A Bibliometric Analysis of Soft Computing Technology Applications Trends and Characterisation in Educational Research: Africa,Isaac Kofi Nti; Faiza Umar Bawah; Juanita Ahia Quarcoo; Favour Kalos,2022,"Computers in education, along with soft-computing technology applications, have revolutionised global interconnectedness and the need for a well-educated workforce. Many studies worldwide explore technology in education, often relying on systematic reviews, though concerns about selection bias have emerged. This article takes a different approach, employing bibliometric analysis to delve into the trends, key authors, institutions, and themes of soft-computing technology applications in education (SCTAE) research in Africa. Initially, 7,435 papers were downloaded from Scopus and then narrowed down to 1,358 using the PRISMA model and defined criteria. Utilising the VOSViewer text mining tool, the article maps out prolific authors, institutions, and thematic networks. It provides detailed findings and outlines opportunities, challenges, and future research prospects in SCTAE in the African context.",Africa Education Review,v19 n3 p55-77 2022,10.1080/18146627.2023.2284744,http://eric.ed.gov/?id=EJ1406123,Bibliometrics; Computer Uses in Education; Artificial Intelligence; Educational Research; Educational Trends; Educational Technology; Learning Analytics; Foreign Countries; Authors; Computer Oriented Programs,English,Journal Articles; Reports - Research
EJ1405261,Using Automated Analysis to Assess Middle School Students' Competence with Scientific Argumentation,Christopher D. Wilson; Kevin C. Haudek; Jonathan F. Osborne; Zoë E. Buck Bracey; Tina Cheuk; Brian M. Donovan; Molly A. M. Stuhlsatz; Marisol M. Santiago; Xiaoming Zhai,2024,"Argumentation is fundamental to science education, both as a prominent feature of scientific reasoning and as an effective mode of learning--a perspective reflected in contemporary frameworks and standards. The successful implementation of argumentation in school science, however, requires a paradigm shift in science assessment from the measurement of knowledge and understanding to the measurement of performance and knowledge in use. Performance tasks requiring argumentation must capture the many ways students can construct and evaluate arguments in science, yet such tasks are both expensive and resource-intensive to score. In this study we explore how machine learning text classification techniques can be applied to develop efficient, valid, and accurate constructed-response measures of students' competency with written scientific argumentation that are aligned with a validated argumentation learning progression. Data come from 933 middle school students in the San Francisco Bay Area and are based on three sets of argumentation items in three different science contexts. The findings demonstrate that we have been able to develop computer scoring models that can achieve substantial to almost perfect agreement between human-assigned and computer-predicted scores. Model performance was slightly weaker for harder items targeting higher levels of the learning progression, largely due to the linguistic complexity of these responses and the sparsity of higher-level responses in the training data set. Comparing the efficacy of different scoring approaches revealed that breaking down students' arguments into multiple components (e.g., the presence of an accurate claim or providing sufficient evidence), developing computer models for each component, and combining scores from these analytic components into a holistic score produced better results than holistic scoring approaches. However, this analytical approach was found to be differentially biased when scoring responses from English learners (EL) students as compared to responses from non-EL students on some items. Differences in the severity between human and computer scores for EL between these approaches are explored, and potential sources of bias in automated scoring are discussed.",Journal of Research in Science Teaching,v61 n1 p38-69 2024,10.1002/tea.21864,http://eric.ed.gov/?id=EJ1405261,Middle School Students; Competence; Science Process Skills; Persuasive Discourse; Secondary School Science; Automation; Computer Assisted Testing; Scoring; Prediction; Scores; Models; English Language Learners; Test Bias,English,Journal Articles; Reports - Research
ED659351,Investigating Automatic Dialogue Act Classification in Collaborative Learning through Federated Transfer Learning and Cross-Corpora Domain Adaptation,Gloria Ashiya Katuka,2024,"Dialogue act (DA) classification plays an important role in understanding, interpreting and modeling dialogue. Dialogue acts (DAs) represent the intended meaning of an utterance, which is associated with the illocutionary force (or the speaker's intention), such as greetings, questions, requests, statements, and agreements. In natural language processing (NLP) applications, developing a DA annotation scheme or A taxonomy is often a first step in working with a corpus. The development of these annotation schemes provides a set of DA labels that are used to manually label a specific corpus, thus capturing the fine-grained intended meanings of utterances. However, dialogue act annotation is a complex task that requires not only an understanding of the linguistic content of an utterance but also of the context in which it was uttered. Researchers who wish to annotate a new corpus are thus tasked with developing a new taxonomy based on a subset of an existing taxonomy, a combination of two or more existing taxonomies, or creating an entirely new taxonomy. Consequently, researchers are more commonly inclined toward developing newer dialogue act annotation schemes, further increasing the number of distinct DA labels and making it difficult to effectively train DA classification models that can be generalized across related or different corpora. Moreover, without access to the specific corpora, it is even more difficult to define and agree upon a fixed dialogue act annotation scheme that can be applied across different corpora, even within similar domains. In collaborative learning, DAs are used to represent the pragmatic goals of utterances. They offer many cues for assessing the effectiveness of collaboration and understanding the kinds of dialogue behaviors that impact learning, performance, and problem-solving abilities. By assigning DAs to collaborative dialogue, researchers can better assess the effectiveness of collaborative learning efforts. They also allow researchers to identify the kinds of dialogue patterns or behaviors that may have a positive or negative effect on the collaborative learning process, such as predicting learners' satisfaction with their partners. However, collaborative learning dialogue takes place in highly domain-specific contexts, which makes DA classification particularly challenging. To mitigate the manual effort required for dialogue act classification, the rise of more advanced machine learning and deep learning text classification models holds potential for training DA classification models for the automatic classification of dialogue acts in the collaborative learning context. However, existing dialogue act classification models often struggle to generalize effectively, even within similar domains or collaborative learning contexts, due to variations in dialogue patterns, domain-specific tasks, dialogue act labels, and the insufficient amount of data needed to train the classification models. This dissertation aims to investigate four main challenges for dialogue act classification in collaborative learning contexts: 1) limited data to adequately train a high performance classification model; 2) too many classes to train a high performance classifier due to fine-grained DA labels; 3) difficulty in mapping dialogue act labels across corpora due to variations in dialogue act annotation schemes; and 4) data privacy concerns restricting data sharing, which limits opportunities for model improvement via cross-corpora training. This dissertation work addresses these challenges by investigating two main transfer learning approaches: cross-corpora domain adaptation, which aims to mitigate the problem of insufficient unique data, and federated transfer learning, which aims to address the data privacy concerns that arise during DA classification model training. To examine the impact of the cross-corpora domain adaptation approach on DA classification, experiments were conducted using fine-tuned pretrained transformer models across three corpora of collaborative learning data. Experimental results showed that the cross-corpora fine-tuned models resulted in an overall improvement in accuracy and F1-scores compared to baseline models fine-tuned using any individual corpus. Additionally, the cross-corpora fine-tuned models outperformed baselines in scenarios with limited dialogue act representation. The results show that this approach has the potential to improve classification performance, especially when a corpus has limited representation of certain dialogue acts. This work highlights the potential benefits of this approach for future domain-specific dialogue act classification tasks. To investigate the impact of the federated transfer learning (FTL) approach on DA classification, I implemented FTL using two standard aggregation methods and conducted experiments using BERT and RoBERTa models. Taking the three corpora as representative of physically separate data locations, the results showed the feasibility of training a global model from multiple, distributed datasets concurrently. Although the experimental results showed that the FTL models underperformed in comparison to the baseline models, the findings represent a possibility for improvement for the FTL models. The protection of data privacy afforded by FTL is important for future data-driven investigations. Meanwhile, using a domain-related model as the global model during the federated transfer learning produced improved performance compared to using the original pretrained model. The main contributions of this research include the novel finding that shows cross-corpora domain adaptation approach produces improved performance for dialogue act classification in collaborative learning context. Contributions also include the implementation of FTL for DA classification. These approaches could potentially set a new benchmark for future work in cross-corpora domain adaptation, federated transfer learning, and dialogue act classification in the context of collaborative learning. This work could also serve as a helpful reference for NLP researchers using transfer learning to improve performance in downstream tasks. In addition, this work may have practical implications for various NLP applications in educational contexts, including the design and development of dialogue systems to support learners, educational technologies using collaborative techniques, and collaborative learning environments. [The dissertation citations contained here are published with the permission of ProQuest LLC. Further reproduction is prohibited without permission. Copies of dissertations may be obtained by Telephone (800) 1-800-521-0600. Web page: http://www.proquest.com/en-US/products/dissertations/individuals.shtml.]",ProQuest LLC,"Ph.D. Dissertation, University of Florida",,http://eric.ed.gov/?id=ED659351,Dialogs (Language); Classification; Intention; Natural Language Processing; Computational Linguistics; Taxonomy; Speech Communication; Models; Computer Software; Cooperative Learning; Pragmatics; Learning Processes; Prediction; Artificial Intelligence; Task Analysis; Data Use; Privacy; Accuracy; Scores; Comparative Analysis; Benchmarking; Educational Technology,,Dissertations/Theses - Doctoral Dissertations
ED651539,Neural Language Models and Human Linguistic Knowledge,Jennifer Hu,2023,"Language is one of the hallmarks of intelligence, demanding explanation in a theory of human cognition. However, language presents unique practical challenges for quantitative empirical research, making many linguistic theories difficult to test at naturalistic scales. Artificial neural network language models (LMs) provide a new tool for studying language with mathematical precision and control, as they exhibit remarkably sophisticated linguistic behaviors while being fully intervenable. While LMs differ from humans in many ways, the learning outcomes of these models can reveal the behaviors that may emerge through expressive statistical learning algorithms applied to linguistic input. In this thesis, I demonstrate this approach through three case studies using LMs to investigate open questions in language acquisition and comprehension. First, I use LMs to perform controlled manipulations of language learning, and find that syntactic generalizations depend more on a learner's inductive bias than on training data size. Second, I use LMs to explain systematic variation in scalar inferences by approximating human listeners' expectations over unspoken alternative sentences (e.g., ""The bill was supported overwhelmingly"" implies that the bill was not supported unanimously). Finally, I show that LMs and humans exhibit similar behaviors on a set of non-literal comprehension tasks which are hypothesized to require social reasoning (e.g., inferring a speaker's intended meaning from ironic statements). These findings suggest that certain aspects of linguistic knowledge could emerge through domain-general prediction mechanisms, while other aspects may require specific inductive biases and conceptual structures. [The dissertation citations contained here are published with the permission of ProQuest LLC. Further reproduction is prohibited without permission. Copies of dissertations may be obtained by Telephone (800) 1-800-521-0600. Web page: http://www.proquest.com/en-US/products/dissertations/individuals.shtml.]",ProQuest LLC,"Ph.D. Dissertation, Massachusetts Institute of Technology",,http://eric.ed.gov/?id=ED651539,Linguistic Theory; Computational Linguistics; Models; Language Research; Artificial Intelligence; Learning Processes; Linguistic Input; Algorithms; Case Studies; Language Acquisition; Syntax; Language Processing; Generalization; Computer Software; Training; Inferences; Interpersonal Competence; Pragmatics; Prediction; Cognitive Structures; Figurative Language; Task Analysis; Comparative Analysis; Behavior Patterns,,Dissertations/Theses - Doctoral Dissertations
EJ1478113,Stench of Errors or the Shine of Potential: The Challenge of (Ir)Responsible Use of ChatGPT in Speech-Language Pathology,Mytsyk Hanna; Suchikova Yana,7008,"Background: Integrating large language models (LLMs), such as ChatGPT, into speech-language pathology (SLP) presents promising opportunities and notable challenges. While these tools can support diagnostics, streamline documentation and assist in therapy planning, they also raise concerns related to misinformation, cultural insensitivity, overreliance and ethical ambiguity. Current discourse often centres on technological capabilities, overlooking how future speech-language pathologists (SLPs) are being prepared to use such tools responsibly. Aims: This paper examines the pedagogical, ethical and professional implications of integrating LLMs into SLP. It emphasizes the need to cultivate professional responsibility, ethical awareness and critical engagement amongst student SLPs, ensuring that such technologies are applied thoughtfully, appropriately and in accordance with evidence-based and contextually relevant therapeutic standards. Methods: The paper combines a review of recent interdisciplinary research with reflective insights from academic practice. It presents documented cases of student SLPs' overreliance on ChatGPT, analyzes common pitfalls through a structured table of examples and synthesizes perspectives from SLP, education, data ethics and linguistics. Main Contribution: Reflective examples presented in the article illustrate challenges that arise when LLMs are used without sufficient oversight or a clear understanding of their limitations. Rather than questioning the value of LLMs, these cases emphasize the importance of ensuring that student SLPs are guided towards thoughtful, ethical and clinically sound use. To support this, the paper offers a set of pedagogical recommendations--including ethics integration, reflective assignments, case-based learning, peer critique and interdisciplinary collaboration--aimed at embedding critical engagement with tools such as ChatGPT into professional training. Conclusions: LLMs are becoming an integral part of SLP. Their impact, however, will depend on how effectively student SLPs are trained to balance technological innovation with professional responsibility. Higher education institutions (HEIs) must take an active role in embedding responsible engagement with LLMs into pre-service training and SLP curricula. Through intentional and early preparation, the field can move beyond the risks associated with automation and towards a future shaped by reflective, informed and ethically grounded use of generative tools.",International Journal of Language & Communication Disorders,v60 n4 e70088 2025,10.1111/1460-6984.70088,http://eric.ed.gov/?id=EJ1478113,Artificial Intelligence; Speech Language Pathology; Natural Language Processing; Technology Integration; Allied Health Personnel; Responsibility; Ethics; Allied Health Occupations Education,English,Journal Articles; Reports - Evaluative
EJ1480850,ELT Teachers' Perception and Usage of ChatGPT as a Teaching Tool in the Bangladeshi EFL Context,Tasnia Tarannum; Risala Ahmed; Prodhan Mahbub Ibna Seraj; Tasneem Shereen Khan,2025,"ChatGPT, developed by OpenAI, is the most buzzing word in academia recently. Due to its ability to provide instant language support and generate diverse educational resources, it has emerged as a powerful tool in ELT (English language teaching). This study aims to explore ELT teachers' perception and usage of ChatGPT as a teaching tool in the Bangladeshi EFL context. To do this, a concurrent mixed-method research design was employed using interviews and a survey questionnaire. 54 ELT teachers for the survey questionnaire, and 7 teachers interviewed participated from the department of English from 5 different private universities in Bangladesh. The results revealed that ELT teachers used ChatGPT for generating practice tasks, preparing question materials for quizzes or examinations, and providing automated feedback. The teachers highlighted several benefits, such as saving time, having unlimited resources, and easy accessibility, while they noted students' overdependence and plagiarism, misinterpreted instruction, faulty information, and similar and repetitive structure and language as the potential drawbacks. The teachers opined that for using ChatGPT both teachers and students need proper training and ethical awareness. The findings bring forth valuable insights for teachers, students, and policymakers.",Education and Information Technologies,v30 n13 p19269-19295 2025,10.1007/s10639-025-13515-7,http://eric.ed.gov/?id=EJ1480850,English (Second Language); Second Language Instruction; Second Language Learning; Artificial Intelligence; Computer Software; Technology Integration; Private Colleges; Language Teachers; Teacher Attitudes; Teaching Methods; Ethics; Technological Literacy; Pedagogical Content Knowledge; College Students; Feedback (Response); Foreign Countries; Educational Benefits; Plagiarism; Misinformation,English,Journal Articles; Reports - Research
ED659741,Using Auxiliary Data to Boost Precision in the Analysis of Educational RCTs: New Data and New Results,Adam Sales; Ethan Prihar; Johann Gagnon-Bartsch; Neil Heffernan,2023,"Background: Randomized controlled trials (RCTs) give unbiased estimates of average effects. However, positive effects for the majority of students may mask harmful effects for smaller subgroups, and RCTs often have too small a sample to estimate these subgroup effects. In many RCTs, covariate and outcome data are drawn from a larger database. For instance, educational efficacy studies may target state standardized tests scores while adjusting for student demographics and prior achievement, all of which are drawn from a state longitudinal data system. In these situations, typically only a subset of students in the database participate in the RCT. We refer to RCT non-participants in the database as the ""remnant"" from the RCT. The remnant often includes a larger sample size than the RCT--especially when estimating subgroup effects--but is not randomized, so including may cause bias. This talk will describe and illustrate a method incorporating the remnant into the analysis of RCTs that gives unbiased estimates and conservative standard errors and has the potential to improve the precision of effect estimates from an RCT, sometimes dramatically. Research Questions: The talk will use data from RCTs that were run within an online tutoring system to answer three research questions: (1) To what extent might remnant data improve the precision of effect estimates from RCTs? (2) Can incorporating the remnant improve estimation of subgroup effects? (3) If the remnant is known to be drawn from a different population than the participants in A/B tests, can it still be useful? Data: E-Trials is a platform that allows researchers to design educational experiments that will then be run within the ASSISTments online tutor. Students working on ""skill-builder"" modules are randomized between two or more conditions, such as how subject matter is portrayed, available hints, and feedback to students. We analyzed data from 277 contrasts between pairs of treatment arms drawn from 68 multi-armed RCTs, including 113,963 students. We also collected rich clickstream-level log data from RCT participants as well as from a remnant of 193,218 ASSISTments users who did not participate in any of the RCTs we analyzed. Assignment completion was the outcome of interest across RCTs. Methodology: The methodology (Gagnon-Bartsch et al. 2023) builds on prior literature including Sales, et al (2018ab), Wu and Gagnon-Bartsch (2018), and Aronow and Middleton (2013). It involves three steps: (1) using only remnant data, train a model $f^R(\cdot):\mathbb{R}^p\rightarrow\mathbb{R}$ predicting outcomes Y as a function of a pdimensional covariate matrix X. This model can be of any form, including machine learning algorithms, and may be fit and tested multiple times, as long as only remnant data is used. It need not be correct, unbiased, or consistent in any sense, but should ideally yield accurate out-of-sample predictions. (2) Use the fitted model $\hat{f}(\cdot)$, along with covariate data from RCT participants X^{RCT} to predict RCT outcomes as $\hat{y}_C=\hat{f}(X^{RCT})$. (3) Use $\hat{y}_C$, as a covariate in a design-based covariate-adjusted effect estimator (e.g. Rosenbaum 2002, Wager, et al. 2016) perhaps alongside other covariates. In our analysis we use the LOOP estimator of Wu and Gagnon-Bartsch (2018), and refer to the estimator including only $\hat{y}_C$ as a covariate as ""ReLOOP"" (i.e. Remnant-based LOOP) and the estimator also including other covariates as ""ReLOOP+."" To carry out the method, we fit an ensemble model (Fig. 1) including three deep neural networks (e.g. Goodfellow, et al. 2016), each trained on a different set of covariates: data on each of the previous 20 assignments each students started, actions students took on each of the prior 60 days, and aggregated student-level data. These three models were then ensembled via a fourth feed-forward neural network. The same fitted model was used for all subgroup comparisons. To test the performance of our methods when the remnant is demographically distinct from the RCT, we used the ""gender guesser"" python script https://pypi.org/project/gender-guesser/ using students' first names, categorizing students as Male, Female, or Unknown. We fit a model to the subset of the remnant categorized as ""Male""--since gender guesser is imperfect and trained using Eurasian names, we assume this group is mostly male and disproportionally white or Asian--and estimated effects for RCT participants from the other categories. Results: All of the estimators we consider are exactly unbiased, so our results focus on estimated sampling-variance of ReLOOP, ReLOOP+, the difference-in-means estimator (Neyman 2023) or the LOOP estimator without remnant data. Specifically, we consider sampling-variance ratios: since sampling-variance scales as 1/n, these can be thought of as ""sample size multipliers."" RQ1: Figure 2 shows boxplots of sampling variance ratios comparing ReLOOP or ReLOOP+ to difference-in-means (Labeled ""T-Test"") or LOOP. Incorporating $\hat{y}_C$ into the analysis never substantially hurt precision, but in many cases improved precision by as much as 30% or more. RQ2: Figures 3 shows boxplots of sampling-variance ratios for subgroup effects, and Figure 4 plots these ratios as a function of sample size within the subgroup. On average, ReLOOP+ improved precision for subgroup estimation for all sample sizes. For small subgroup samples, the improvement could be dramatic--equivalent to more than doubling the sample size in some cases--but in some other cases it hurt precision noticeably. RQ3: Figure 5 shows results from the experiment using the ""male"" remnant to estimate effects in the non-""male"" subset of the RCTs. Surprisingly, ReLOOP improved precision roughly equally among ""male"" and non-""male"" subgroups of the RCT, and ReLOOP+ improved precision more in the non-""male"" subgroup, despite the unrepresentativeness of the remnant. Conclusion: Machine learning methods have an impressive potential, but can also reproduce biases present in their training samples (e.g. Bolukbasi et al. 2016). Randomized Controlled Trials give unbiased estimates (for the RCT participants) but these may be imprecise and mask treatment effect heterogeneity. The methods we propose, ReLOOP and ReLOOP+ use machine learning models fit to auxiliary data that are unbiased, like RCTs, but can also be more precise--especially for subgroup estimates, even when the remnant is itself biased. They can be valuable tools for using all available data to evaluate programs for both the majority of students as well as for vulnerable minorities.",Society for Research on Educational Effectiveness,,,http://eric.ed.gov/?id=ED659741,Learning Analytics; Randomized Controlled Trials; Data Use; Accuracy; Research Problems; Computation; Artificial Intelligence; Statistical Bias,,Reports - Research
EJ1422393,ChatGPT for Learning HCI Techniques: A Case Study on Interviews for Personas,Jose Barambones; Cristian Moral; Angelica de Antonio; Ricardo Imbert; Loic Martinez-Normand; Elena Villalba-Mora,2024,"Before interacting with real users, developers must be proficient in human--computer interaction (HCI) so as not to exhaust user patience and availability. For that, substantial training and practice are required, but it is costly to create a variety of high-quality HCI training materials. In this context, chat generative pretrained transformer (ChatGPT) and other chatbots based on large language models (LLMs) offer an opportunity to generate training materials of acceptable quality without foregoing specific human characteristics present in real-world scenarios. Personas is a user-centered design method that encompasses fictitious but believable user archetypes to help designers understand and empathize with their target audience during product design. We conducted an exploratory study on the Personas technique, addressing the validity and believability of interviews designed by HCI trainers and answered by ChatGPT-simulated users, which can be used as training material for persona creation. Specifically, we employed ChatGPT to respond to interviews designed by user experience (UX) experts. Two groups, HCI professors and professionals, then evaluated the validity of the generated materials considering quality, usefulness, UX, and ethics. The results show that both groups rated the interviews as believable and helpful for Personas training. However, some concerns about response repetition and low response variability suggested the need for further research on improved prompt design in order to generate more diverse and well-developed responses. The findings of this study provide insight into how HCI trainers can use ChatGPT to help their students master persona creation skills before working with real users in real-world scenarios for the first time.",IEEE Transactions on Learning Technologies,v17 p1486-1501 2024,10.1109/TLT.2024.3386095,http://eric.ed.gov/?id=EJ1422393,Artificial Intelligence; Synchronous Communication; Computer Mediated Communication; Man Machine Systems; Computer Software; Users (Information); User Needs (Information); Audience Awareness; Design,English,Journal Articles; Reports - Research
EJ1474960,The Leadership Tree Model: A Global and AI-Enhanced Framework for Leadership Development,Yihe Yang; Antonio Jimenez-Luque,2025,"This article presents the Leadership Tree Model, a metaphorical and conceptual framework for transformative leadership development in higher education. Rooted in critical pedagogy and social justice, the model encourages educators to create inclusive, reflective, and action-oriented learning environments. It positions leadership as a relational and ethical process that challenges systemic inequities and centers marginalized voices. The article outlines applications for curricular and co-curricular programming and highlights the model's relevance across diverse institutional contexts. Ultimately, the Leadership Tree Model aims to support students in becoming transformative leaders committed to equity, inclusion, and collective well-being.",New Directions for Student Leadership,n186 p97-104 2025,10.1002/yd.20674,http://eric.ed.gov/?id=EJ1474960,Transformational Leadership; Leadership Training; Models; Higher Education; Social Justice; Ethics; Curriculum Development; College Students; Student Leadership; Diversity Equity and Inclusion; Well Being,English,Journal Articles; Reports - Descriptive
EJ1426682,Optimization of Piano Performance Teaching Mode Using Network Big Data Analysis Technology,Xiang Wei; Shuping Sun,2024,"To effectively avoid subjective bias in manual evaluation. This article proposes a MIDI piano teaching performance evaluation method based on bidirectional LSTM. This method utilizes a three-layer bidirectional LSTM neural network mechanism to make it easier for the model to capture useful information. In addition, the Spark clustering training model is constructed using the deeplearning4j deep learning framework, and the model parameters are adjusted through the UI dependency relationships provided by deeplearning4j to improve work efficiency. The experimental results verified the superiority of the bidirectional LSTM model. The methods provided in this article can improve students' independent practical abilities and reduce the pressure on teachers during the teaching process. These measures can promote the development of music education, improve students' music literacy and learning skills, and make positive contributions to the music education industry.",International Journal of Information and Communication Technology Education,v20 n1 2024,,http://eric.ed.gov/?id=EJ1426682,Musical Instruments; Music Education; Teaching Methods; Educational Technology; Artificial Intelligence; Instructional Effectiveness; Performance Based Assessment,English,Journal Articles; Reports - Research
EJ1477232,"ChatGPT in Higher Education: Opportunities, Challenges, and Required Competencies in the Absence of Guiding Policies",Ahmed Alkaabi; Asma Abdallah; Shamma Alblooshi; Fatima Alomari; Sara Alneaimi,2025,"This study examines the opportunities and challenges of employing ChatGPT in higher education, identifies essential user competencies, and evaluates its impact in the absence of formal policy guidelines. A qualitative case study design involved interviews with 10 faculty members and 10 students at a federal university in the United Arab Emirates. Documentation of live ChatGPT usage was also analyzed to triangulate findings. Thematic analysis revealed the following eight core themes: (1) Cost-effectiveness and time savings. (2) ChatGPT as a source of information and a flexible tool. (3) ChatGPT's ability to adapt to the user. (4) Prompt engineering competencies in ChatGPT. (5) Addiction to ChatGPT. (6) The misinformation risks with ChatGPT. (7) Academic integrity concerns. (8) A lack of consensus on how to utilize ChatGPT appropriately. The findings underscore an urgent need for formal policies to guide the ethical and responsible use of ChatGPT in higher education. The study also emphasizes the necessity of targeted training workshops for teachers, curriculum integration, and adapting pedagogical approaches. It also calls for proactive attention to ethical concerns including misinformation, algorithmic bias, and overreliance to ensure that the educational benefits of ChatGPT are realized responsibly and sustainably.",Journal of Education and e-Learning Research,v12 n2 p153-164 2025,,http://eric.ed.gov/?id=EJ1477232,Artificial Intelligence; Teaching Methods; Computer Software; Higher Education; College Faculty; Teacher Attitudes; Technology Integration; Ethics; Educational Policy; College Students; Student Attitudes; Misinformation; Algorithms; Teacher Workshops; Curriculum Development; Risk; Cost Effectiveness; Barriers; Educational Benefits; Addictive Behavior; Integrity; Cheating; Foreign Countries,English,Journal Articles; Reports - Research
EJ1488234,From the Lab to the Wild: Examining Generalizability of Video-Based Mind Wandering Detection,Babette Bühler; Efe Bozkir; Patricia Goldberg; Ömer Sümer; Sidney D'Mello; Peter Gerjets; Ulrich Trautwein; Enkelejda Kasneci,2025,"Student's shift of attention away from a current learning task to task-unrelated thought, also called mind wandering, occurs about 30% of the time spent on education-related activities. Its frequent occurrence has a negative effect on learning outcomes across learning tasks. Automated detection of mind wandering might offer an opportunity to assess the attentional state continuously and non-intrusively over time and hence enable large-scale research on learning materials and responding to inattention with targeted interventions. To achieve this, an accessible detection approach that performs well for various systems and settings is required. In this work, we explore a new, generalizable approach to video-based mind wandering detection that can be transferred to naturalistic settings across learning tasks. Therefore, we leverage two datasets, consisting of facial videos during reading in the lab (N = 135) and lecture viewing in-the-wild (N = 15). When predicting mind wandering, deep neural networks (DNN) and long short-term memory networks (LSTMs) achieve F[subscript 1] scores of 0.44 (AUC-PR = 0.40) and 0.459 (AUC-PR = 0.39), above chance level, with latent features based on transfer-learning on the lab data. When exploring generalizability by training on the lab dataset and predicting on the in-the-wild dataset, BiLSTMs on latent features perform comparably to the state-of-the-art with an F[subscript 1] score of 0.352 (AUC-PR = 0.26). Moreover, we investigate the fairness of predictive models across gender and show based on post-hoc explainability methods that employed latent features mainly encode information on eye and mouth areas. We discuss the benefits of generalizability and possible applications.",International Journal of Artificial Intelligence in Education,v35 n2 p823-857 2025,10.1007/s40593-024-00412-2,http://eric.ed.gov/?id=EJ1488234,Attention; Automation; Identification; Video Technology; Artificial Intelligence; Sex Fairness; Prediction; Generalization; College Students; Foreign Countries,English,Journal Articles; Reports - Research
ED645091,Towards Learning with Limited Supervision: Efficient Few-Shot and Semi-Supervised Classification for Vision Tasks,Ran Tao,2023,"Vision classification tasks, a fundamental and transformative aspect of deep learning and computer vision, play a pivotal role in our ability to understand the visual world. Deep learning techniques have revolutionized the field, enabling unprecedented accuracy and efficiency in vision classification. However, deep learning models, especially supervised models, require large amounts of labeled data to learn effectively. The acquisition of large-scale datasets meets many difficulties considering the dynamics in real-world applications. Collecting and annotating data is a time-consuming and expensive process, which sometimes requires domain-specific expertise to provide a sufficient quantity of high-quality labeled data. Meanwhile, privacy and ethical concerns hinder data acquisition in certain domains, such as healthcare or finance. Learning with limited supervision addresses these challenges by developing techniques that allow models to learn and make predictions with only a partial or a small number of supervision. In this presentation, we will introduce our research, which encompasses several advancements within the domain of learning with limited supervision. Initially, we introduce a novel fine-tuning method tailored to enhance the efficiency of few-shot learning, particularly in cross-domain scenarios. Building upon this, we extend our comprehension of few-shot fine-tuning into the transductive setting. Here, we present innovative weighting techniques to harness the potential of unlabeled data during the testing phase. In addition, we confront the intricate balance between data quality and quantity when leveraging unlabeled training data in semi-supervised learning. To address this challenge, we introduce the SoftMatch method, which allows for the adaptive integration of unlabeled data during training. [The dissertation citations contained here are published with the permission of ProQuest LLC. Further reproduction is prohibited without permission. Copies of dissertations may be obtained by Telephone (800) 1-800-521-0600. Web page: http://www.proquest.com/en-US/products/dissertations/individuals.shtml.]",ProQuest LLC,"Ph.D. Dissertation, Carnegie Mellon University",,http://eric.ed.gov/?id=ED645091,Classification; Vision; Documentation; Data Collection; Data Use; Supervision; Training; Computers; Artificial Intelligence,,Dissertations/Theses - Doctoral Dissertations
ED672945,An Exploratory Study of the ChatGPT Use of Vietnamese Graduate Students in a Research Writing Course,Vu Phi Ho Pham; Nhung Hong Nguyen,2025,"This exploratory qualitative study aims to explore the ChatGPT use of Van-Lang-University graduate students in a research writing course and the cognitive levels of their reactions to its responses. The data was collected from observations and interviews with twelve Vietnamese graduate students studying in a research writing class at this university. According to the findings, the participants opted for ChatGPT as a help-seeking strategy during their course due to several reasons including its convenience, instant feedback, and multifunction. Additionally, they had critical reactions to ChatGPT's feedback and advocated that ChatGPT could not replace lecturers' roles in future language classrooms. To develop the growth of critical ChatGPT use for research writing in Master's programs in English Language Studies at Van Lang University, actions from relevant stakeholders is required, including policymakers, lecturers teaching research writing, and MA students. [This chapter was published in: ""Implementing AI Tools for Language Teaching and Learning,"" edited by Vu Phi Ho Pham, Andrew Lian, Ania Lian, and Sandro R. Barros, IGI Global Scientific Publishing, 2025, pp. 199-224.]",Online Submission,,,http://eric.ed.gov/?id=ED672945,Graduate Students; Writing Instruction; Technology Integration; Computer Software; Artificial Intelligence; Feedback (Response); Research Training; Foreign Countries; Universities; Student Attitudes; Help Seeking; College Faculty; Teacher Role; Second Language Learning; Second Language Instruction; English (Second Language); Masters Programs; Metacognition; Critical Thinking; Task Analysis; Ethics; Majors (Students); Academic Language,,Reports - Research
EJ1406825,Developing and Validating the Competency Profile for Teaching and Learning Research Integrity,Jurij Selan; Mira Metljak,2023,"Since research integrity is not external to research but an integral part of it, it should be integrated into research training. However, several hindrances regarding contemporary research integrity education exist. To address them, we have developed a competency profile for teaching and learning research integrity based on four assumptions: 1) to include all levels of study (BA, MA, and PhD); 2) to integrate research integrity into research education itself; 3) to address research integrity issues in context-specific practices; and 4) to pay particular attention to the ""grey zone"" or questionable research practices. To assess the validity of the content of the competency profile and to determine if some adjustments to the profile are needed, we translated the competencies of the profile into items of a measurement instrument (a questionnaire) and conducted a survey amongst University of Ljubljana students that allowed us to: 1) obtain information about students' attitudes toward issues of integrity in research; 2) analyse differences in these attitudes among BA, MA, and PhD students; and 3) statistically validate the competency profile and suggest possible improvements. The results showed that: 1) students are highly aware of research integrity issues, as scores were high on all items assessed. However, there were some deviations to lower scores, especially in relation to questionable research practises, confirming our assumption that the ""grey zone"" issues are those that should be particularly addressed and given special attention in contemporary research integrity education. 2) The differences in the attitudes of BA, MA, and PhD students showed that higher-level students showed significantly more awareness of integrity issues than lower-level students did, suggesting that research integrity issues should be given special attention at the BA study level. 3) The measurement characteristics showed that the reliability of the questionnaire was very high, suggesting a good overall structure of the competency profile. The principal component analysis also confirmed the four-field structure of the Competency profile (Values and Principles, Research Practise, Publication and Dissemination, and Violations). However, the analysis also showed that the substructure of the four main areas of the profile did not fully match the results of the factor analysis, suggesting that the distribution of competencies in the competency profile could be reconsidered, especially in the area of Research Practice. The most recent developments in the field of research integrity also suggest that the competency profile should be updated with issues regarding the impact of artificial intelligence on research integrity.",Center for Educational Policy Studies Journal,v13 n3 p33-74 2023,,http://eric.ed.gov/?id=EJ1406825,Profiles; Integrity; Content Validity; Questionnaires; Student Attitudes; Undergraduate Students; Graduate Students; Doctoral Students; Comparative Analysis; Scores; Item Analysis; Research Methodology; Research Training; Factor Analysis; Artificial Intelligence; Foreign Countries; Ethics,,Journal Articles; Reports - Research; Tests/Questionnaires
ED677715,Beyond Single-Axis Analysis: Applying the Intersectional MAIHDA Method to Examine Disparities in Subjective Disciplinary Incidents,Anwesha Guha; Janette Avelar; Keith Zvoch,2025,"Background: In the 2017-2018 school year, the Civil Rights Data Collection (CRDC) reported that more than 2.5 million students across the United States received at least one out-of-school suspension -- totaling to over 11 million days of learning loss from suspensions alone (Losen & Whitaker, 2018). While some of the reasons for suspension include ""objective"" incidents like tardiness and fighting, the most frequent types of offenses are ""subjective,"" requiring an interpretation to evaluate whether a school behavior expectation has been violated (i.e., disruption and disobedience; Girvan et al., 2017). Exclusionary discipline -- defined as procedures that remove students from class as a form of disciplinary action -- impacts youth disproportionately across intersecting lines of marginalization, including gender, race, disability, and language (Muniz, 2021). While many studies have examined intersections along one or two axes of difference (e.g., Addington, 2023), few studies have been able to identify how the intersections of different sociodemographic identities together, or strata, correlate with subjective discipline incident (SDI) experiences. To investigate the specific axes of inequality along which SDIs operate, we apply the Intersectional Multilevel Analysis of Individual Heterogeneity and Discriminatory Accuracy (IMAIHDA) modeling framework. I-MAIHDA nests individual students within intersectional strata, partitioning variance within and between strata (Evans et al., 2018) to identify the specific identity combinations most associated with exclusionary outcomes and the disparities between and within them. Purpose: This descriptive study used I-MAIHDA to examine how suspensions due to SDIs varied across student identities of gender, race/ethnicity, language status, and disability status simultaneously. Integrating theories of intersectionality and building on MAIHDA and multilevel analytic frameworks, we used I-MAIHDA to examine 1) the extent to which both in-school and out-of-school suspensions vary across intersectional strata, and 2) if disparities in discipline are more pronounced for certain intersections. We hypothesized that multiply marginalized students would be subject to the most SDIs, as suggested by previous literature. However, we were also interested in how patterns shift when examined in tandem. This study is exploratory in identifying which axes, when combined with others, were subject to the most inequality. Setting and Participants: The study drew on statewide student-level administrative data from Oregon's state longitudinal data system (SLDS). The sample included six 9th grade cohorts (2013-14 to 2018-19), totaling about 263,000 students across the state. Outcome: SDIs rely on staff judgment to determine behavior violations (Skiba et al., 2002), allowing for bias to impact decision-making (McIntosh et al., 2018). Yet, SDIs were among the most frequently selected offense type in the dataset. In the SLDS, these included the following codes: Disorderly Conduct (Disruptive Behavior); Insubordination (Disobedience); and Violation of School Rules (Disobeying School Policy). The primary outcome compared students who received one or more SDIs at all to peers who received no disciplinary action. Method: Intersectionality is essential in theorizing inequities (Collins et al., 2021; Crenshaw, 1991).To quantitatively operationalize this framework, we applied I-MAIHDA, an interdisciplinary multilevel modeling approach developed in the health and social sciences to an education context (Evans et al., 2018; Keller et al., 2023; Prior et al., 2024). I-MAIHDA nests individuals (Level 1) within intersectional strata (Level 2) defined by combinations of identity markers to examine the extent to which complex interactions of individual characteristics associate with patterns of inequality, and if the observed inequities are more or less pronounced for certain intersectional identities. Compared to other linear regression and machine learning methods, I-MAIHDA provides estimates of heterogeneity between strata to quantify disparities in an outcome of interest (e.g., exclusionary discipline), while preserving its scalability and model parsimony (Mahendran et al., 2022). Although I-MAIHDA has been increasingly used in epidemiology to identify patterns of inequality across health outcomes (Axelsson Fisk et al., 2018; Evans et al., 2018), the method has not been used to examine exclusionary discipline in school-based contexts. We estimated two models. The level 1 random-intercept null model estimates the extent to which intersectional strata explain overall variation in student outcomes and quantifies the total degree of inequality between strata. Level 2 incorporates sociodemographic characteristics to evaluate the relative contribution of main effects versus interactive effects in explaining variation in individual outcomes (e.g., exclusionary discipline) across intersectional strata. By partitioning the variance within and between strata, the I-MAIHDA approach facilitates the identification of intersectional effects at the strata level and estimates the discriminatory accuracy of these strata for predicting individual outcomes across multiple axes of social identity. Findings/Results: The I-MAIHDA models identified substantial heterogeneity in discipline across strata. The most frequently suspended strata included Black boys with special education (SPED) services, regardless of English learner (EL) classification, with a predicted suspension probability of over 80% (see Figure 1). All the top ten most suspended strata include male-identifying students in SPED, with race and language status varying across groups. In contrast, the two least frequently suspended strata were Asian-identifying and female-identifying students, regardless of language status. Conclusions: The relationship between schools and discipline has been defined as ""a web of intertwined, punitive threads [that] captures the historic, systemic, and multifaceted nature of the intersections of education and incarceration"" (Meiners, 2010, p. 32). This study endorses the complex frame of discipline by showing how multiple axes of identity shape students' likelihood of receiving SDIs -- fitting well into the 2025 conference theme of ""Education in Context."" Findings affirm prior research on the overrepresentation of male-identifying students, students of color, and students with disabilities in exclusionary discipline and highlight the unique risk facing students at the intersection of these identities. Patterns were especially pronounced for boys receiving SPED services, suggesting that ableism and sexism may compound risk and are important context in designing and interpreting targeted causal studies. The results underscore the need for professional learning that engages with multiple, intersecting forms of bias that may surface at vulnerable decision points (Sanchez et al., 2025). For example, implicit bias trainings could inform how deficit-based beliefs about masculinity, disability, race, and language shape disciplinary practices. For instance, empowering students through self-advocacy and broadening teacher knowledge of learning styles is critical for Black boys with disabilities (Banks, 2017).",Society for Research on Educational Effectiveness,,,http://eric.ed.gov/?id=ED677715,Discipline; Disproportionate Representation; Suspension; Intersectionality; Sex; Race; Ethnicity; English Learners; Students with Disabilities; Hierarchical Linear Modeling; Student Characteristics,,Reports - Research
EJ1374731,"Cognification in Learning, Teaching, and Training","Kumar, Vivekanandan; Ally, Mohamed; Tsinakos, Avgoustos; Norman, Helmi",2022,"Over the past decade, opportunities for online learning have dramatically increased. Learners around the world now have digital access to a wide array of corporate trainings, certifications, comprehensive academic degree programs, and other educational and training options. Some organizations are blending traditional instruction methods with online technologies. Blended learning generates large volumes of data about both the content (quality and usage) and the learners (study habits and learning outcomes). Correspondingly, the need to properly process voluminous, continuous, and often disparate data has prompted the advent of cognification. Cognification techniques design complex data analytic models that allow natural intelligence to engage artificial smartness in ways that can enhance the learning experience. Cognification is the approach to make something increasingly, ethically, and regulatably smarter. This article highlights how emerging trends in cognification could disrupt online education.",Canadian Journal of Learning and Technology,v48 n4 2022,,http://eric.ed.gov/?id=EJ1374731,Electronic Learning; Cognitive Processes; Artificial Intelligence; Educational Technology; Blended Learning; Data Analysis; Educational Change; Educational Trends; Models; Democracy; Lifelong Learning; Ethics; Decision Making,English,Journal Articles; Reports - Descriptive
ED677798,Estimating the Treatment Effect Heterogeneity of Providing Performance Information in Education: A Causal Forests Approach,Xinjie Zhang; Yi Wei; Yingquan Song; Feifan Zhang,2025,"Background/Context: Efforts to mitigate information asymmetry between parents and their children regarding academic performance have become a common practice among governments and K-12 educational institutions globally, with the aim of improving educational outcomes (Barrera-Osorio et al., 2020; Berlinski et al., 2022; Dizon-Ross, 2019; Kraft & Dougherty, 2013). These efforts are grounded in evidence from simple average treatment effect estimations, which suggest that, on average, providing parents with information about their children's academic progress can improve educational investments made by families (Andrabi et al., 2017), thereby enhancing children's academic achievement (Barrera-Osorio et al., 2020). However, the simple average treatment effect estimations are limited in their ability to identify critical heterogeneities in the changes of family educational investment that may result from such information interventions. That is, families exhibit significant variability in their characteristics, which may differently respond to such interventions and moderate their treatment effects on family educational investment. Understanding these heterogeneities is crucial, particularly in the context of large-scale educational policies like the widespread distribution of report cards to parents. It is possible that some families may significantly increase their educational investment when provided with better information about their children's academic performance, indicating that such families could benefit most from targeted interventions. Conversely, certain families may not increase, or may even decrease, their educational investment in response to the same information, suggesting that these families might not benefit from, or could even be adversely affected by, such interventions. This underscores the importance of tailoring educational policies to account for the diverse ways in which different families respond to academic information. Purpose/Objective/Research Question: Classical approaches to estimating heterogeneity using ordinary least squares (OLS) are prone to producing spurious findings due to insufficient statistical power (Assmann et al., 2000) or model misspecification (Zheng & Yin, 2023) and may miss valuable but unexpected treatment effect heterogeneity because of pre-analysis plan constraints (Wager & Athey, 2018). To address the limitations of the OLS estimator, this study employs a novel approach that integrates Randomized Controlled Trials (RCTs) with Machine Learning (ML) techniques. This combined methodology aims to more accurately estimate the heterogeneous treatment effects of reducing information frictions between parents and children regarding academic performance, specifically on families' human capital investments. RCT is widely recognized as the gold standard in social sciences due to their ability to provide robust causal evidence by eliminating confounding factors. ML has become a powerful tool for drawing statistical inference in high dimensional and complex covariate interactions settings (Chernozhukov et al., 2018; Wager & Athey, 2018). Setting: The setting for the experiment is in Yunxian County in southwestern China, which is among the 585 poorest counties in the country. The per capita annual income in this county is RMB 2,300 (approximately 328.57 US dollars). Population/Participants/Subjects: The research focuses on 201 low-income villages along the Myanmar border in one of 585 poorest counties in rural China. Most of the research participants have limited educational attainment: 51.98% of parents have only elementary education, and 31.02% have completed middle school. Additionally, approximately 80% of the parents are villagers. 52.31% of the families belong to ethnic minorities. The annual household income is approximately RMB21,650 ($3,092). These families face significant barriers to education and economic mobility. The research participants also include 7,500 children in grades 3 through 10, whose ages primarily range from 9 to 16 at the baseline in 2023. Among these children, 51.19% are primary school students aged 9 to 13, 43.29% are middle school students aged 13 to 15, and 5.52% are high school students aged 16. Intervention/Program/Practice: The intervention begins in January 2024. Parents in the treatment group receive information about their children's academic performance from the 2023 fall midterm, fall final, and 2024 spring midterm exams through three rounds of phone call interventions. The control group does not receive this information. For each of the three exams (2023 fall midterm, 2023 fall final, and 2024 spring midterm) during the intervention phase, this study conducts two contacts with the parents from whom the baseline data is collected: an initial contact and a follow-up contact. During the initial contact, enumerators first assess parents' beliefs about their children's performance on a specific exam for both the treatment and control groups. Parents in the treatment group are then provided with actual academic performance information about their children. The follow-up contact takes place one month after the initial contact, during which enumerators ask the same questions to assess how parents update their beliefs. Both the initial and follow-up contacts are conducted for parents in both the treatment and control groups, with the only difference being that parents in the treatment group are provided with their children's actual academic performance information. Each subsequent contact is conducted with parents who are successfully contacted during the previous round. Research Design: This study takes an innovative approach by using a simple yet effective intervention--providing parents with academic information--to address a longstanding economic question: the relationship between children's academic ability and family educational investment. By leveraging randomized information shocks, the study mitigates endogeneity concerns, offering a clearer understanding of how parental investment decisions respond to new information. The experiment is conducted across all 201 villages in the county and consists of five phases: sample selection, baseline data collection, randomization, intervention, and endline data collection. Sample selection: This study's sample inclusion criteria requires that households have two children enrolled in 3rd through 10th grade during the 2023-2024 academic year at the research site. This study screens 4,809 eligible households using administrative records on school attendance from the local Education Bureau. Of these, 3,750 households (77.98%) agree to participate and complete the baseline surveys. Therefore, the research sample comprises 7,500 parent-child pairs from 3,750 households. Table A.1 presents the statistical power of the experiment, with a minimum detectable effect size of 0.064 standard deviations. In the study, the sampled parents predominantly belong to low-SES populations (Table A.2). 63% of the parents have attained only a primary school education. Approximately 80% of the parents are villagers. The annual household income is approximately RMB21,650 to RMB22,337 ($3,092 to $3,191). Baseline data collection: The baseline data collection begins in May 2023, gathering survey data from 3,750 households through either a parent or legal guardian. Randomization: After the baseline, I conduct a stratified randomization at the household level, assigning 1,878 households to the treatment group and 1,872 households to the control group. The stratification variables used include: 1) villages, 2) belief bias below the lower bound of the tri-sectional quantile, 3) belief bias above the higher bound of the tri-sectional quantile, and 4) median income. After randomization, I employ two methods to test the equivalence between the two groups: 1) individual regressions of each variable on a treatment dummy, and 2) a joint F-test. The balance check confirms that the two groups are equivalent: 1) none of the 90 variables is statistically significant at the 10% level in the individual regressions, and 2) the p - value of the joint F-test for the 90 variables is 0.7024, failing to reject the null hypothesis that there are no differences between the groups. Table A.2 presents the summary statistics and balance test results. Intervention: The intervention is launched in January 2024. Parents in the treatment group receive information about their children's academic performance from the 2023 fall semester's midterm, final, and 2024 spring semester's midterm exams during the 2023-2024 academic year. This information is communicated through three rounds of phone call interventions. The remaining households in the control group do not receive this information. Endline data collection: The endline data collection is scheduled to take place from November 2024 to May 2025. Data Collection and Analysis: This study collects household survey data across three phases of the experiment: baseline, intervention, and endline. This study collects the following information from household surveys at the baseline and endline: 1) socioeconomic status, such as parents' income and educational attainment; 2) perceptions about education, school, and teachers, 3) beliefs about the children's academic performance, 4) allocation of educational investments (time, energy, and finances) between siblings, and 5) ticket allocation between siblings in the lab-in-the-field experiment. Moreover, during the intervention phase, we gather data on parents' test score perceptions, grade ranking, and estimated college admission probabilities. Finally, this study collects student academic performance data for each child from the unified exams administered by the local education bureau throughout the entire experiment. This data includes the absolute test scores in Chinese, math, and English, as well as each student's ranking within their class, grade",Society for Research on Educational Effectiveness,,,http://eric.ed.gov/?id=ED677798,Foreign Countries; Artificial Intelligence; Randomized Controlled Trials; Research Methodology; Low Income; Rural Areas; Elementary School Students; Middle School Students; High School Students; Academic Achievement; Parent Student Relationship; Intervention; Parent Attitudes; Family Characteristics,,Reports - Research
ED663574,Supporting Students' Math Achievement with Adaptive and Game-Based EdTech: A Longitudinal Efficacy Study of ExploreLearning's Frax Program,Megan Conrad; David Shuster,2024,"Background: Performance with fractions has been a weak point in U.S. education for decades and has not improved in recent years (Siegler, 2017). High School math teachers frequently rate their students' knowledge of fractions as ""poor"" and see this lack of foundational knowledge as one of the top barriers to students mastering algebra (Hoffer et al., 2007). Prior research has found that fractions knowledge in 5th grade uniquely predicts mathematics achievement in high school, even after controlling for variables like general intellectual ability, working memory, and family income and education levels (Siegler et al., 2012). EdTech has the potential to deliver personalized classroom interventions at scale to improve fractions knowledge in a manner that is both efficient and effective. The current study tests the impact of Frax: a game-based, adaptive learning program that uses research-based instructional methods to support foundational fractions skills. Research Questions: A two-year longitudinal study (Fall 2021 through Spring 2023) with elementary school students was conducted to measure the impact of Frax usage on fractions knowledge and mathematics achievement. The study used a quasi-experimental methodology with case-control matching to create equivalent student groups at baseline. Student product usage and math performance were measured in collaboration with the school district. The study aimed to address the following research questions: (1) Does usage of the Frax program improve students' performance on standardized math assessments? (2) Do students who use the Frax program with fidelity show greater improvement on math assessments over time compared to matched, control students? (3) Do the effects of the Frax program vary for students of different ability levels? Participants: The sample (Table 1) included 2,440 3rd-grade and 2,620 4th-grade students from a large, suburban public school district in the southeastern United States. The district's minority enrollment is over 60% and 35% of students are economically disadvantaged. The sample consisted of 35% Hispanic/Latino and 15% Black/African American students. The majority of students, 79%, scored at least 1 grade level below standards on the baseline math test. Intervention: The Frax Foundations I program, broadly aligned to 3rd-grade fractions standards, contains 27 lessons (Missions) which take 30 minutes each to complete. Lessons are typically completed in class with teachers monitoring student progress to deliver real-time support. Frax is designed as a zero-entry program; students with no previous knowledge of fractions can begin using the program immediately. The Frax approach teaches students that fractions are numbers with magnitude like any other number. Students practice these concepts through explicit, scaffolded use of length models, number lines, and measurements. Students build the conceptual foundation they need to move on to fractions arithmetic. The adaptive algorithms behind Frax are designed to maximize student engagement and motivation, automatically recognizing and delivering the right level of support to students. This creates individualized, efficient instruction that intentionally moves each student toward mastery. Research Design: This study used a quasi-experimental, case-control matching design. All 3rd-5th grade teachers in the district had access to the Frax program and were eligible to receive professional development. Program usage was measured by the number of missions students completed each year. Baseline achievement was quantified by Fall 2021 i-Ready Diagnostic Assessment math scale scores and performance relative to grade-level proficiency (2+ grade levels below, 1-grade level below, on grade level or above). Matching was conducted in Spring 2022, creating matched pairs of Frax users and non-users on current grade level (3rd, 4th) and Fall 2021 i-Ready math scale scores (±5 points). Early growth (Spring 2022 and Fall 2022) was measured by the I-Ready Diagnostics assessment. In Spring 2023, the district moved to a state-specific diagnostic test. Overall math scale scores, fractions subscale scores, and relative achievement categories (below standards, at/near standards, and above standards) were used to determine the impact of Frax usage on student math growth. Analysis: SPSS was used for all analyses. Paired samples t-tests and standardized effect sizes (Hedge's g) were used to determine the magnitude of gains in test scores comparing across matched users and non-users. Categorical 2x2 chi-square tests were used to look at the likelihood of meeting grade level expectations for users and non-users. Findings/Results: Results from Year 1 found that fidelity program usage led to statistically significantly greater improvement in math compared to paired non-users. Compared to previous metanalyses (Lipsey et al., 2012), Frax was 3x more effective at improving math scores than the average educational intervention for 3rd graders and 5x more effective for 4th graders (Table 2). Frax usage was also related to students' achievement of grade level proficiency; 47% of high Frax users met grade level expectations in the spring compared to only 31% of students in the control group, X[superscript 2 ](1, N = 1008) = 4.65, p = 0.031. Importantly, this effect was observed for students within every student baseline achievement category (Figure 1). The results from year 2 found that the achievement gains associated with Frax usage in year 1 were sustained: in Spring 2023 high Frax users had significantly higher overall math scores, t(170) = 4.044, p < 0.001, and were significantly more likely to score above standards on the Fractions subscale, X[superscript 2] (1, N = 342) = 5.78, p = 0.016, compared to their matched non-users (Figure 2). Importantly, control students in Year 1 who went on to use Frax in Year 2 also showed significant achievement gains, fully catching up to or exceeding their Year 1 matched peers (Table 3). Conclusions: EdTech has the potential to support significant learning gains for all learners while alleviating the heavy burden associated with delivering individualized instruction. The current study provides evidence that the Frax program is an efficient and effective way to support fractions knowledge and math achievement. Efforts to control for potential bias were used in the current study, including creating equivalent groups, but future research should be conducted using an experimental methodology with students from multiple districts. Continued efforts to measure program efficacy and support evidence-based implementations must be collaboratively embraced by vendors, researchers, and school administrators.",Society for Research on Educational Effectiveness,,,http://eric.ed.gov/?id=ED663574,Mathematics Achievement; Game Based Learning; Educational Technology; Fractions; Intervention; Program Effectiveness; Elementary School Students; Mathematics Education; Student Improvement; Academic Ability; Grade 3; Grade 4; Suburban Schools; Public Schools,,Reports - Research
EJ1473727,De-Identifying Student Personally Identifying Information in Discussion Forum Posts with Large Language Models,Andres Felipe Zambrano; Shreya Singhal; Maciej Pankiewicz; Ryan Shaun Baker; Chelsea Porter; Xiner Liu,2025,"Purpose: This study aims to evaluate the effectiveness of three large language models (LLMs), GPT-4o, Llama 3.3 70B and Llama 3.1 8B, in redacting personally identifying information (PII) from forum data in massive open online courses (MOOCs). Design/methodology/approach: Forum posts from students enrolled in nine MOOCs were redacted by three human reviewers. The GPT and Llama models were then tasked with de-identifying the same data set using standardized prompts. Discrepancies between LLM and human redactions were analyzed to identify patterns in LLM errors. Findings: All models achieved an average recall of over 0.9 in identifying PII and identified PII instances overlooked by humans. However, their precisions were lower -- 0.579 for GPT-4o, 0.506 for Llama 3.3 and 0.262 for Llama 3.1 -- showing a tendency to over-redact non-PII names and locations. Research limitations/implications: Several courses' data were analyzed to increase findings' generalizability but the models' performance may vary in other contexts. GPT and Llama models were selected because of their availability and cost-effectiveness at the time of the study; future newer models may improve performance. Practical implications: The use of downloadable LLMs enables researchers to de-identify data without training specialized models or involving external companies, ensuring that student data remains private. Originality/value: Previous research on LLM text de-identification has largely used proprietary models, which require sharing data containing sensitive PII with third-party companies. This study evaluates the performance of two open weight models that can be deployed locally, eliminating the need to share sensitive data externally.",Information and Learning Sciences,v126 n5-6 p401-424 2025,10.1108/ILS-11-2024-0156,http://eric.ed.gov/?id=EJ1473727,Artificial Intelligence; Identification; Privacy; Information Security; Discussion Groups; MOOCs; College Students,English,Journal Articles; Reports - Research
ED656589,Smart Learning Environments in the Post Pandemic Era. Selected Papers from the CELDA 2022 Conference. Cognition and Exploratory Learning in the Digital Age,"Demetrios G. Sampson, Editor; Dirk Ifenthaler, Editor; Pedro Isaías, Editor",2024,"This edited volume presents the latest research focussing on current challenges on the deployment of smart technologies and pedagogies for supporting teaching and learning in the post-covid19 era. This is at the core of studying the evolution of the learning process, the role of technology-supported pedagogical approaches, and the progress of educational technology innovations in the context of digital transformation in education and professional training. A selection of the best papers from the Cognition and Exploratory Learning in the Digital Age (CELDA) Conference, 2022 are included in this volume, bringing together high-quality research on Smart Pedagogies in the Post-Pandemic Era; Smart Learning Technologies in the Post-Pandemic Era; and Case Studies of Smart Learning Environments. The volume contributes to the discussion of current issues in digital education between researchers, practitioners, and policymakers.",Cognition and Exploratory Learning in the Digital Age,,,http://eric.ed.gov/?id=ED656589,Teaching Methods; Influence of Technology; Educational Technology; Professional Development; COVID-19; Learning Analytics; Data; Computer Simulation; Behavior Patterns; Evaluation; Electronic Learning; Augmentative and Alternative Communication; Programming; Educational Games; Open Educational Resources; Ethics; Blended Learning; Artificial Intelligence,English,Books; Collected Works - General; Reports - Research
ED671807,Accountability in Higher Education: Navigating Current Issues and Trends,Topeka Small Singleton,2025,"Accountability in higher education has become a critical issue as higher education institutions face scrutiny over student outcomes, financial transparency, and the value of a college degree. As the cost of tuition is on the rise and student debt growing, the concerns on equitability and the concerns of student engagement have left many in the public to lose trust in higher education. From government regulations to accreditation standards and data-driven assessment models, accountability measures are evolving to ensure that higher education remains both effective and accessible. As the public become more distrustful of higher education, discussing the problems issues is effective in seeking change. ""Accountability in Higher Education: Navigating Current Issues and Trends"" explores the current trends and issues with accountability in higher education. It discusses how accountability in higher education is essential and is the most impactful. This book covers topics such as accountability, diversity and inclusion, and educational training, and is a useful resource higher education professionals who seek to know more about navigating the landscape of accountability in higher education.",IGI Global,,,http://eric.ed.gov/?id=ED671807,Accountability; Higher Education; Educational Trends; Educational Benefits; Equal Education; Diversity; Inclusion; Ethics; Educational Finance; Mental Health; Wellness; Leadership; Artificial Intelligence; Accreditation (Institutions); Educational Quality; Quality Assurance,,Books; Collected Works - General
EJ1454195,University Undergraduates' Perceptions on the Use of ChatGPT for Academic Purposes: Evidence from a University in Czech Republic,Blanka Klimova; Victor Paiva Luz de Campos,2373,"At present, ChatGPT is penetrating all spheres of human activities, and especially education is no exception. The purpose of this exploratory study is to examine the potentials and pitfalls of using ChatGPT for academic purposes among university students, as well as provide relevant pedagogical implications for its use in academia. The methodology is based on a mix-method approach, i.e. both quantitative and qualitative by analysing an online questionnaire that was distributed among both Czech and foreign students at a university in the Czech Republic. The findings of this study reveal ChatGPT's burgeoning significance as an academic instrument, alongside concerns regarding its constraints and potential misuse. Most students employ ChatGPT for academic purposes, as demonstrated by the favorable feedback it receives for its effectiveness in facilitating research, stimulating idea generation, promoting comprehension of intricate concepts, and furnishing prompt responses. Hence, ChatGPT embodies promise for forthcoming generations regarding its capacity to augment educational programs, potentially fostering greater efficiency and interactivity in the learning process. Nevertheless, a critical apprehension lies in students excessively relying on ChatGPT, which may impede the cultivation of vital skills, such as critical thinking and problem-solving. Therefore, the authors of this study provide several pedagogical implications for its use in academia, such as using ChatGPT as a supportive tool in classes, as well as using it for collaborative work and group tasks since ChatGPT promotes sharing information, faster collection of data, providing diverse and creative ideas, or speed communication. Another important pedagogical implication is raising awareness of ethical guidelines, given that many students remain oblivious to them, necessitating the training of teachers to impart ethical usage of ChatGPT. Finally, the results of this study align with several educational theories, such as constructivism or self-determination theory.",Cogent Education,v11 n1 Article 2373512 2024,10.1080/2331186X.2024.2373512,http://eric.ed.gov/?id=EJ1454195,Undergraduate Students; Undergraduate Study; Student Attitudes; Artificial Intelligence; Technology Uses in Education; Natural Language Processing; Foreign Countries; Opportunities; Barriers; Technology Integration; Graduate Students; Graduate Study; Information Science; Research; Concept Formation; Usability; Accuracy; Reliability; Ethics,English,Journal Articles; Reports - Research; Tests/Questionnaires
ED671809,"Proceedings of International Conference on Social and Education Sciences (IConSES) (Chicago, Illinois, October 17-20, 2024). Volume 1","Valarie Akerson, Editor; Ozkan Akman, Editor; M. Lutfi Ciddi, Editor",2024,"""Proceedings of International Conference on Social and Education Sciences"" includes full papers presented at the International Conference on Social and Education Sciences (IConSES), which took place on October 17-20, 2024, in Chicago, Illinois. The aim of the conference is to offer opportunities to share ideas, discuss theoretical and practical issues, and to connect with the leaders in the fields of education and social sciences. The IConSES invites submissions that address the theory, research, or applications in all disciplines of education and social sciences. The IConSES is organized for: faculty members in all disciplines of education and social sciences, graduate students, K-12 administrators, teachers, principals, and all interested in education and social sciences. [Individual papers are indexed in ERIC.]","International Society for Technology, Education, and Science",,,http://eric.ed.gov/?id=ED671809,Higher Education; Ethics; Technology Uses in Education; Mathematics Education; College Students; Social Sciences; Foreign Countries; Special Education Teachers; Teacher Role; Dictionaries; Second Language Instruction; Uncommonly Taught Languages; Informed Consent; Social Science Research; Educational Research; Artificial Intelligence; Academic Achievement; Physics; Science Instruction; COVID-19; Pandemics; Scientific Concepts; Student Research; Engineering Education; Leadership Training; Computer Games; Athletics; Values; Black Colleges; Business Education; Multilingualism; Bilingual Teachers; Online Courses; Handicrafts; Cultural Influences; Distance Education; Educational Technology,,Books; Collected Works - Proceedings
ED672802,"Proceedings of International Conference on Studies in Education and Social Sciences (ICSES) (Istanbul, Turkey, November 7-10, 2024). Volume 1","Mahmut Sami Ozturk, Editor; Abdullatif Kaban, Editor; Mevlut Unal, Editor",2024,"""Proceedings of International Conference on Studies in Education and Social Sciences"" includes full papers presented at the International Conference on Studies in Education and Social Sciences (ICSES) which took place on November 7-10, 2024, in Istanbul, Turkey. The aim of the conference is to offer opportunities to share ideas, discuss theoretical and practical issues, and to connect with the leaders in the fields of education and social sciences. The conference is organized annually by the International Society for Technology, Education, and Science (ISTES). The ICSES invites submissions which address the theory, research, or applications in all disciplines of education and social sciences. The ICSES is organized for: faculty members in all disciplines of education and social sciences, graduate students, K-12 administrators, teachers, principals, and all interested in education and social sciences. [Individual papers are indexed in ERIC.]","International Society for Technology, Education, and Science",,,http://eric.ed.gov/?id=ED672802,Metacognition; Preservice Teachers; Mathematics Teachers; Foreign Countries; Conservation (Environment); Racism; Ethnic Groups; Social Discrimination; Team Sports; Curriculum Implementation; Cognitive Processes; English (Second Language); Theses; Writing (Composition); College Faculty; Teacher Effectiveness; Prevention; Child Abuse; Marriage; High School Students; Females; Training; Elementary Education; Social Studies; Student Attitudes; Teacher Motivation; Artificial Intelligence; Expectation; Value Judgment; Evaluation Methods; Cognitive Style; College Students; Climate; Proverbs; Natural Disasters; Counselor Role; Psychological Patterns; Well Being; Cultural Maintenance; World History; Cultural Influences,,Books; Collected Works - Proceedings
